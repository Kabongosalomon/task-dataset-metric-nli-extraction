<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ICD Coding from Clinical Text Using Multi-Filter Residual Convolutional Neural Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Li</surname></persName>
							<email>feili@uml.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Lowell</orgName>
								<address>
									<settlement>Lowell</settlement>
									<region>MA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yu</surname></persName>
							<email>hongyu@uml.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Lowell</orgName>
								<address>
									<settlement>Lowell</settlement>
									<region>MA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Healthcare Organization and Implementation Research</orgName>
								<orgName type="institution">Bedford Veterans Affairs Medical Center</orgName>
								<address>
									<settlement>Bedford</settlement>
									<region>MA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Medicine</orgName>
								<orgName type="institution">University of Massachusetts Medical School</orgName>
								<address>
									<settlement>Worcester</settlement>
									<region>MA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
									<region>MA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ICD Coding from Clinical Text Using Multi-Filter Residual Convolutional Neural Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated ICD coding, which assigns the International Classification of Disease codes to patient visits, has attracted much research attention since it can save time and labor for billing. The previous state-of-the-art model utilized one convolutional layer to build document representations for predicting ICD codes. However, the lengths and grammar of text fragments, which are closely related to ICD coding, vary a lot in different documents. Therefore, a flat and fixed-length convolutional architecture may not be capable of learning good document representations. In this paper, we proposed a Multi-Filter Residual Convolutional Neural Network (Mul-tiResCNN) for ICD coding. The innovations of our model are two-folds: it utilizes a multi-filter convolutional layer to capture various text patterns with different lengths and a residual convolutional layer to enlarge the receptive field. We evaluated the effectiveness of our model on the widely-used MIMIC dataset. On the full code set of MIMIC-III, our model outperformed the state-of-the-art model in 4 out of 6 evaluation metrics. On the top-50 code set of MIMIC-III and the full code set of MIMIC-II, our model outperformed all the existing and state-of-the-art models in all evaluation metrics. The code is available at https://github.com/foxlf823/Multi-Filter-Residual-Convolutional-Neural-Network.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The International Classification of Diseases (ICD), which is organized by the World Health Organization, is a common coding method used in various healthcare systems such as hospitals. It includes many pre-defined ICD codes which can be assigned to patients' files such as electronic health records (EHRs). These codes represent diagnostic and procedural information during patient visits. Healthcare providers and insurance companies need these information to diagnose patients and bill for services <ref type="bibr" target="#b1">(Bottle and Aylin 2008)</ref>. However, manual ICD coding has been demonstrated to be labor-consuming and costly <ref type="bibr">(O'malley et al. 2005)</ref>.</p><p>The research community has investigated a number of approaches for automated ICD coding, including the models based on both traditional machine learning <ref type="bibr" target="#b12">(Perotte et al. 2013;</ref><ref type="bibr" target="#b6">Kavuluru, Rios, and Lu 2015)</ref> and deep learning <ref type="bibr">(Shi Copyright c 2020</ref>, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.  <ref type="bibr" target="#b17">Xie and Xing 2018)</ref>. In terms of data, prior work utilized different domains of data such as radiology reports <ref type="bibr" target="#b13">(Pestian et al. 2007</ref>) and death certificates <ref type="bibr" target="#b6">(Koopman et al. 2015)</ref>, and different modal data such as structured <ref type="bibr" target="#b12">(Perotte et al. 2013)</ref> and unstructured text <ref type="bibr" target="#b15">(Scheurwegs et al. 2017)</ref>. Moreover, some previous work adopted full ICD codes to perform this task <ref type="bibr" target="#b0">(Baumel et al. 2018</ref>) while other work adopted partial codes <ref type="bibr" target="#b17">(Xu et al. 2018)</ref>. Due to such situation, it is difficult to directly compare different work. In this paper, we followed the line of predicting ICD codes from unstructured text of the MIMIC dataset <ref type="bibr" target="#b6">(Johnson et al. 2016</ref>), because it is widely studied and publicly available.</p><p>The state-of-the-art model for this line of work is the combination of the convolutional neural network (CNN) and the attention mechanism <ref type="bibr" target="#b10">(Mullenbach et al. 2018)</ref>. However, this model only contains one convolutional layer to build document representations for subsequent layers to predict ICD codes. As shown in <ref type="table" target="#tab_0">Table 1</ref>, ICD-related text spans and patterns vary in different examples. Therefore, it may not be sufficient to learn decent document representations from a flat and fixed-length convolutional architecture.</p><p>In this paper, we proposed a Multi-Filter Residual Convolutional Neural Network (MultiResCNN) for ICD coding using clinical discharge summaries. Our Mul-arXiv:1912.00862v1 [cs.CL] 25 Nov 2019 tiResCNN model is composed of five layers: the input layer leverages word embeddings pre-trained by word2vec <ref type="bibr" target="#b9">(Mikolov et al. 2013)</ref>; the multi-filter convolutional layer consists of multiple convolutional filters (Kim 2014); the residual convolutional layer contains multiple residual blocks <ref type="bibr" target="#b5">(He et al. 2016)</ref>; the attention layer keeps the interpretability for the model following <ref type="bibr" target="#b10">(Mullenbach et al. 2018)</ref>; the output layer utilizes the sigmoid function to predict the probability of each ICD code.</p><p>Our main contribution is that we proposed a novel CNN architecture that combines the multi-filter CNN (Kim 2014) and residual CNN <ref type="bibr" target="#b5">(He et al. 2016)</ref>. The advantages are two-folds: MultiResCNN not only captures various text patterns with different lengths via the multi-filter CNN, but also enlarges the receptive field 1 <ref type="bibr" target="#b4">(Garcia and Delakis 2004)</ref> via the residual CNN. Thus, our model can benefit from rich patterns, the large receptive field and deep architecture. Such method has achieved great success in natural language processing <ref type="bibr" target="#b16">(Vaswani et al. 2017</ref>) and computer vision <ref type="bibr" target="#b6">(Krizhevsky, Sutskever, and Hinton 2012)</ref>.</p><p>To evaluate our model, we employed the MIMIC dataset <ref type="bibr" target="#b6">(Johnson et al. 2016</ref>) which has been widely used for automated ICD coding. Compared with 5 existing and stateof-the-art models <ref type="bibr" target="#b12">(Perotte et al. 2013;</ref><ref type="bibr" target="#b14">Prakash et al. 2017;</ref><ref type="bibr" target="#b16">Shi et al. 2017;</ref><ref type="bibr" target="#b0">Baumel et al. 2018;</ref><ref type="bibr" target="#b10">Mullenbach et al. 2018)</ref>, our model outperformed them in nearly all the evaluation metrics (i.e., macro-and micro-AUC, macro-and micro-F1, precision at K). Concretely, in the MIMIC-III experiment using full codes, our model outperformed these models in macro-AUC, micro-F1 and precision at 8 and 15. In the MIMIC-III experiment using top-50 codes and the MIMIC-II experiment using full codes, our model outperformed these models in all evaluation metrics. Moreover, hyper-parameter tuning experiments show that the multifilter and residual convolutional layers help our model to improve its performance significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>To the best of our knowledge, the earliest work of automated ICD coding was proposed by <ref type="bibr" target="#b7">Larkey and Croft (1996)</ref>. They combined three classifiers, K-nearest-neighbor, relevance feedback and Bayesian independence, to assign ICD9 codes to inpatient discharge summaries. However, their method only assigns one code to each discharge summary. <ref type="bibr" target="#b13">Pestian et al. (2007)</ref> organized a shared task of assigning ICD-9 codes to radiology reports and their task requires models to assign a large set of codes to each report.</p><p>Early work usually used supervised machine learning approaches for ICD coding. <ref type="bibr" target="#b12">Perotte et al. (2013)</ref> leveraged "flat" and "hierarchical" Support Vector Machines (SVMs) for automatically assigning ICD9 codes to the discharge summaries of the MIMIC-II repository <ref type="bibr" target="#b6">(Johnson et al. 2016)</ref>. Their results show that the hierarchical SVM performs better than the flat one. <ref type="bibr" target="#b6">Kavuluru et al. (2015)</ref> used the unstructured text in 71,463 EMRs, which come from the University of Kentucky Medical Center, to evaluate supervised learning approaches such as multi-label clas-sification and learning to rank for the ICD9 code assignment. <ref type="bibr" target="#b6">Koopman et al. (2015)</ref> employed the SVM to identify cancer-related causes of death from 447,336 death certificates. Their model is cascaded: the first one identified the presence of cancer and the second identified the type of cancer according to the ICD-10 classification system. <ref type="bibr" target="#b15">Scheurwegs et al. (2017)</ref> evaluated coverage-based feature selection methods and Random Forests on seven medical specialties for ICD9 code prediction and two for ICD10, incorporating structured and unstructured text.</p><p>With the development of deep learning, researchers also explored neural networks for this task. <ref type="bibr" target="#b16">Shi et al. (2017)</ref> utilized the long short-term memory (LSTM) and attention mechanism for automated ICD coding from diagnosis descriptions. <ref type="bibr" target="#b17">Xie and Xing (2018)</ref> also adopted the LSTM but they introduced the tree structure and adversarial learning to utilize code descriptions. <ref type="bibr" target="#b14">Prakash et al. (2017)</ref> exploited condensed memory neural networks and evaluated it on the free-text medical notes of the MIMIC-III dataset. <ref type="bibr" target="#b0">Baumel et al. (2018)</ref> proposed a hierarchical gated recurrent unit (GRU) network, which encodes sentences and documents with two stacked layers, to assign multiple ICD codes to discharge summaries of the MIMIC II and III datasets. <ref type="bibr" target="#b10">Mullenbach et al. (2018)</ref> incorporated the convolutional neural network (CNN) with per-label attention mechanism. Their model achieved the state-of-the-art performance among the work using only unstructured text of the MIMIC dataset. Xu et al. (2018) built a hybrid system that includes the CNN, LSTM and decision tree to predict ICD codes from unstructured, semi-structured and structured tabular data. In addition, <ref type="bibr" target="#b8">Lipton et al. (2015)</ref> utilized LSTMs to predict diagnostic codes from time series of clinical measurements, while our work focuses on text data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>In this section, we will introduce our Multi-filter Residual Convolutional Neural Network (MultiResCNN), whose architecture is shown in <ref type="figure">Figure 1</ref>. Throughout this paper, we employed the following notation rules: matrices are written as italic uppercase letters (e.g., X); vectors and scalars are written as italic lowercase letters (e.g., x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input Layer</head><p>Our model leverages a word sequence w = {w 1 , w 2 , ..., w n } as input, where n denotes the sequence length. Assuming that? denotes the word embedding matrix, which is pretrained via word2vec <ref type="bibr" target="#b9">(Mikolov et al. 2013</ref>) from the raw text of the dataset. A word w n will correspond to a vector e n by looking up?. Therefore, the input will be a matrix E = {e 1 , e 2 , ..., e n } ? R n?d e .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Filter Convolutional Layer</head><p>To capture the patterns with different lengths, we leveraged the multi-filter convolutional neural network (Kim 2014), where each filter has a different kernel size (i.e., word window size). Assuming we have m filters f 1 , f 2 , ..., f m and their kernel sizes denote as k 1 , k 2 , ..., k m . Therefore, m 1-  <ref type="figure">Figure 1</ref>: The architecture of our MultiResCNN model. "Conv1d" represents the 1-dimensional convolution, "Res-Block" represents the residual block, "?" represents the concatenation operation and "?" represents the matrix multiplication. Here we use orange and green for U and W to denote they are learnable parameters, and to distinguish with other matrices (e.g., H) which are not parameters.</p><formula xml:id="formula_0">? " # " $ Conv1d f 1 ResBlock r 11 % &amp; ' ( ? ? ? ? ? ? ? ? ? ? Conv1d f m</formula><p>dimensional convolutions can be applied to the input matrix E. The convolutional procedure can be formalized as:</p><formula xml:id="formula_1">H 1 = f 1 (E) = n j=1 tanh(W T 1 E j:j+k1?1 ), ... H m = f m (E) = n j=1 tanh(W T m E j:j+km?1 ),<label>(1)</label></formula><p>where n j=1 indicates the convolutional operations from left to right. Here we forced the row number n of the output H 1 or H m ? R n?d f to be the same as that of the input E, because we aimed to keep the sequence length unchanged after convolution. It is simple to implement such goal, e.g., setting the kernel size, padding and stride as k, f loor(k/2) and 1. d f indicates the out-channel size of a filter and every filter has the same output size.</p><p>Moreover, E j:j+k1?1 ? R k1?d e and E j:j+km?1 ? R km?d e indicate the sub-matrices of E, starting from the j-th row and ending at the j + k 1 ? 1 or j + k m ? 1 row.</p><formula xml:id="formula_2">W 1 ? R (k1?d e )?d f</formula><p>and W m ? R (km?d e )?d f indicate the weight matrices of corresponding filters. Throughout this paper, the biases of all layers are ignored for conciseness. The overview of a 1-dimensional convolution filter f m is shown in <ref type="figure">Figure 2</ref>.</p><formula xml:id="formula_3">! " ! # ? $ % &amp; ! ' ! ( ) ! ( ) *" ? + &amp; $ ":( ) $ ':( ) *" ? ? ? ? ? /01? /01? /01?</formula><p>Figure 2: The architecture of a 1-dimensional convolution filter f m . "?" represents the concatenation operation and "?" represents the matrix multiplication. </p><formula xml:id="formula_4">!"#? % Conv1d r mi &amp; '( ) Conv1d r mi &amp; '( * Conv1d r mi &amp; '( + + !"#? -'(</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Residual Convolutional Layer</head><p>On top of each filter in the multi-filter convolutional layer, there is a residual convolutional layer which consists of p residual blocks <ref type="bibr" target="#b5">(He et al. 2016)</ref>. Take the m-th filter as an example, the computational procedure of its corresponding residual blocks r m1 , r m2 , ..., r mp can be formalized as:</p><formula xml:id="formula_5">1: X = H m 2: for i = 1 to p do 3: H mi = r mi (X) 4: X = H mi 5: return H mp</formula><p>For the residual block r mi <ref type="figure" target="#fig_1">(Figure 3</ref>), it consists of three convolutional filters, namely r mi1 , r mi2 and r mi3 . The computational procedure can be denoted as:</p><formula xml:id="formula_6">X 1 = r mi1 (X) = n j=1 tanh(W T mi1 X j:j+km?1 ), X 2 = r mi2 (X 1 ) = n j=1 W T mi2 X j:j+km?1 1 , X 3 = r mi3 (X) = n j=1 W T mi3 X j:j , H mi = tanh(X 2 + X 3 ),<label>(2)</label></formula><p>where n j=1</p><p>indicates the convolutional operations. X denotes the input matrix of this residual block and X j:j+km?1 ? R km?d i?1 indicate the sub-matrices of X, starting from the j-th row and ending at the j + k m ? 1 row. H mi ? R n?d i denotes the output matrix of the residual block. d i?1 and d i denote the in-channel and out-channel sizes of this residual block. Therefore, the in-channel size of the first residual block r m1 should be d f and the out-channel size of the last residual block r mp is defined as d p . Similar with the multifilter convolutional layer, we let the row numbers of H mi as well as X 1 , X 2 and X 3 ? R n?d i be n, which is identical to that of the input X.</p><p>Moreover</p><formula xml:id="formula_7">, W mi1 ? R (km?d i?1 )?d i , W mi2 ? R (km?d i )?d i and W mi3 ? R (1?d i?1 )?d i</formula><p>denote the weight matrices of the three convolutional filters, r mi1 , r mi2 and r mi3 . Thereinto, r mi1 and r mi2 have the same kernel size k m with the corresponding filter f m in the multi-filter convolutional layer, but they have different in-channel sizes. r mi3 is a special convolutional filter whose kernel size is 1.</p><p>Because the m-th filter f m in the multi-filter convolutional layer corresponds to p residual blocks r m1 , r m2 , ..., r mp in the residual convolutional layer, we employed the output H mp ? R n?d p of the p-th residual block r mp as the output of these residual blocks. Since there are totally m filters in the multi-filter convolutional layer, the final output of the residual convolutional layer is a concatenation of the output of m residual blocks, namely</p><formula xml:id="formula_8">H = H 1p ? H 2p ...H mp ? R n?(m?d p ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Layer</head><p>Following <ref type="bibr" target="#b10">Mullenbach et al. (2018)</ref>, we employed the perlabel attention mechanism to make each ICD code attend to different parts of the document representation H. The attention layer is formalized as:</p><formula xml:id="formula_9">A = sof tmax(HU ), V = A T H,<label>(3)</label></formula><p>where U ? R (m?d p )?l represents the parameter matrix of the attention layer, A ? R n?l represents the attention weights for each pair of an ICD code and a word, V ? R l?(m?d p ) represents the output of the attention layer. Here l denotes the number of ICD codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output Layer</head><p>In the output layer, V is first fed into a linear layer followed by the sum-pooling operation to obtain the score vector? for all ICD codes, and then the probability vector? is calculated from? by the sigmoid function. This process can be formalized as:</p><formula xml:id="formula_10">Y = V W, where Y ? R l?l , y = pooling(Y ), where? i = l j=1 Y ij , y = sigmoid(?),<label>(4)</label></formula><p>where W ? R (m?d p )?l is the weight matrix of the output layer. For training, we treated the ICD coding task as a multi-label classification problem following previous work <ref type="bibr" target="#b8">(McCallum 1999;</ref><ref type="bibr" target="#b10">Mullenbach et al. 2018)</ref>. The training objective is to minimize the binary cross entropy loss between the prediction? and the target y:</p><formula xml:id="formula_11">L(w, y, ?) = ? l j=1 y j log(? j ) + (1 ? y j )log(1 ?? j ),<label>(5)</label></formula><p>where w denotes the input word sequence and ? denotes all the parameters. We utilized the back-propagation algorithm and Adam optimizer (Kingma and Ba 2014) to train our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>Datasets MIMIC-III In this paper, we employed the third version of Medical Information Mart for Intensive Care (MIMIC-III) <ref type="bibr" target="#b6">(Johnson et al. 2016</ref>) as the first dataset to evaluate our models. Following <ref type="bibr" target="#b10">Mullenbach et al. (2018)</ref>, we used discharge summaries, split them by patient IDs, and conducted experiments using the full codes as well as the top-50 most frequent codes. Finally, the MIMIC-III dataset using 8,921 ICD-9 codes consists of 47,719, 1,631 and 3,372 discharge summaries for training, development and testing respectively. The dataset using top-50 codes has 8,067 discharge summaries for training, 1,574 for development, and 1,730 for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIMIC-II</head><p>Besides the MIMIC-III dataset, we also leveraged the MIMIC-II dataset to compare our models with the ones in previous work <ref type="bibr" target="#b12">(Perotte et al. 2013;</ref><ref type="bibr" target="#b10">Mullenbach et al. 2018;</ref><ref type="bibr" target="#b0">Baumel et al. 2018)</ref>. Follow their experimental setting, there are 20,533 and 2,282 clinical notes for training and testing, and 5,031 unique ICD-9 codes in the dataset.</p><p>Preprocessing Following previous work <ref type="bibr" target="#b10">(Mullenbach et al. 2018)</ref>, the text was tokenized, and each token were transformed into its lowercase. The tokens that contain no alphabetic characters were removed such as numbers and punctuations. The maximum length of a token sequence is 2,500 and the one that exceeds this length will be truncated. We </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>To compare with previous work, we utilized different evaluation metrics in different experiments. In the MIMIC-III experiment using full ICD codes, we utilized macro-averaged and micro-averaged AUC (area under the ROC, i.e., receiver operating characteristic curve), macro-averaged and micro-averaged F1, precision at 8 (P@8) and precision at 15 (P@15). When computing macro-averaged AUC or F1, we first computed the performance for each label and then averaged them. When computing micro-averaged AUC or F1, we considered every pair of a clinical note and a code as an independent prediction. The precision at K (P@K) indicates the proportion of the correctly-predicted labels in the top-K predicted labels.</p><p>In the MIMIC-III experiment using the top-50 ICD codes, we employed the P@5 besides macro-averaged and microaveraged AUC, macro-averaged and micro-averaged F1. In the MIMIC-II experiment using full codes, we employed the same evaluation metrics except that P@5 was changed to P@8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-parameter Tuning</head><p>Since our model has a number of hyper-parameters, it is infeasible to search optimal values for all hyper-parameters. Therefore, some hyper-parameter values were chosen empirically or following prior work <ref type="bibr" target="#b10">(Mullenbach et al. 2018</ref>). The word embedding size d e is 100, the out-channel size d f of a filter in the multi-filter convolutional layer is 100, the learning rate is 0.0001, the batch size is 16 and the dropout rate is 0.2.</p><p>To explore a better configuration for the filter number m and the kernel sizes k 1 , k 2 , ..., k m in the multi-filter convolutional layer, and the residual block number p in the residual convolutional layer, we conducted the following experiments. First, we developed three variations:</p><p>? CNN, which only has one convolutional filter and is equivalent to the CAML model <ref type="bibr" target="#b10">(Mullenbach et al. 2018</ref>).</p><p>2 https://github.com/jamesmullenbach/caml-mimic</p><p>? MultiCNN, which only has the multi-filter convolutional layer.</p><p>? ResCNN, which only has the residual convolutional layer.</p><p>Then we tried several configurations for these models on the development set of MIMIC-III using the full and top-50 code settings. The experimental results are shown in <ref type="table" target="#tab_1">Table 2</ref>. For each configuration, we tried three runs by initializing the model parameters randomly. The results shown in the table are the means of three runs. We selected such kernel sizes since they do not only capture various text patterns from different granularities, but also keeps the sequence length unchanged after convolution (e.g., setting the padding and stride sizes as floor(k/2) and 1). In addition, we pre-defined the in-channel and out-channel sizes of residual blocks empirically:</p><formula xml:id="formula_12">? p=1: d 0 =100, d 1 =50 ? p=2: d 0 =100, d 1 =100, d 2 =50 ? p=3: d 0 =100, d 1 =150, d 2 =100, d 3 =50</formula><p>As shown in <ref type="table" target="#tab_1">Table 2</ref>, MultiCNN performs better than CNN. As the kernel number increases, the performance increases consistently in both full and top-50 code settings. The performance reaches a peak when the kernel sizes are <ref type="bibr">3,</ref><ref type="bibr">5,</ref><ref type="bibr">9,</ref><ref type="bibr">15,</ref><ref type="bibr">19,</ref><ref type="bibr">25</ref>. Moreover, ResCNN also performs better than CNN, but the difference is that the performances deteriorate as the residual block number increases. ResCNN achieves the best performance when the residual block number is 1. Therefore, we applied the best configuration of Mul-tiCNN and ResCNN to MultiResCNN. The results show that the performance of MultiResCNN was further improved after combining MultiCNN and ResCNN. Therefore, we kept such configuration in other experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines</head><p>CAML &amp; DR-CAML The Convolutional Attention network for Multi-Label classification (CAML) was proposed by <ref type="bibr" target="#b10">Mullenbach et al. (2018)</ref>. It has achieved the state-of-theart results on the MIMIC-III and MIMIC-II datasets among the models using unstructured text. It consists of one convolutional layer and one attention layer to generate label-aware features for multi-label classification (McCallum 1999). The  Description Regularized CAML (DR-CAML) is an extension of CAML and incorporates the text description of each code to regularize the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C-MemNN</head><p>The Condensed Memory Neural Network was proposed by <ref type="bibr" target="#b14">Prakash et al. (2017)</ref>, which equips the neural network with iterative condensed memory representations. The model achieved competitive results to predict the top-50 ICD codes for the medical notes in the MIMIC-III dataset. <ref type="bibr" target="#b16">Shi et al. (2017)</ref> proposed a Characteraware LSTM-based Attention model to assign ICD codes to clinical notes. They employed LSTM-based language models to generate representations of clinical notes and ICD codes, and proposed an attention method to address the mismatch between notes and codes. They also focused on predicting the top-50 ICD codes for the medical notes in the MIMIC-III dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C-LSTM-Att</head><p>SVM <ref type="bibr" target="#b12">Perotte et al. (2013)</ref> experimented two approaches: one treats each ICD9 code independently (flat SVM) and the other uses the hierarchical nature of ICD9 codes (hierarchy SVM). Their results show that the hierarchy SVM performs better than the flat one, yielding 29.3% f1-measure in the MIMIC-II dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HA-GRU Baumel et al. (2018) presented a model named</head><p>Hierarchical Attention Gated Recurrent Unit (HA-GRU) for automatic ICD coding of clinical documents. HA-GRU includes two main layers: the first one encodes sentences and the second one encodes documents. They reported their results in the MIMIC-II dataset, following the data split from <ref type="bibr" target="#b12">Perotte et al. (2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In this section, we compared our model with existing work for automated ICD coding. We ran our model three times for each experiment and each time we used different random seeds for parameter initialization. The final results are the means and standard deviations of three runs. Following prior work <ref type="bibr" target="#b10">(Mullenbach et al. 2018)</ref>, we compared our model with existing work using the MIMIC-III and MIMIC-II dataset. For the MIMIC-III dataset, we also performed the comparisons with two experimental settings, namely using the full codes and top-50 codes. For the MIMIC-II dataset, only the full codes were employed. <ref type="table" target="#tab_2">Table 3</ref>, we can see that our model obtained better results in the macro-AUC, micro-F1, precision@8 and precision@15, compared with the state-of-the-art models, CAML and DR-CAML. Our model improved the macro-AUC by 0.013, the micro-F1 by 0.013, the precision@8 by 0.025, the precision@15 by 0.023. In addition, our model achieved comparable performance on the micro-AUC and a slightly worse macro-F1. More importantly, we observed that our model is able to attain stable good results from the standard deviations. <ref type="table" target="#tab_3">Table 4</ref>, we observed that our model outperformed all the baselines, namely C-MemNN <ref type="bibr" target="#b14">(Prakash et al. 2017</ref>), C-LSTM-Att <ref type="bibr" target="#b16">(Shi et al. 2017)</ref>, CAML and DR-CAML <ref type="bibr" target="#b10">(Mullenbach et al. 2018)</ref>, in all evaluation metrics. Our model improves the macro-AUC, micro-AUC, macro-F1, micro-F1 and preci-sion@5 by 0.015, 0.012, 0.030, 0.037 and 0.023, respectively. Our model outperformed the C-MemNN by 0.221 and 0.066 in precision@5 and macro-AUC. It also outperformed the C-LSTM-Att by 0.138 and 0.028 in micro-F1 and micro-AUC. Its precision@5 is 0.032 and 0.023 higher than those of CAML and DR-CAML. <ref type="table" target="#tab_4">Table 5</ref> shows the results on the full code set of MIMIC-II. <ref type="bibr" target="#b12">Perotte et al. (2013)</ref> used the SVM to predict ICD codes from clinical text and their method obtained 0.293 micro-F1. By contrast, our model outperformed their method by 0.171 in micro-F1. <ref type="bibr" target="#b0">Baumel et al. (2018)</ref> utilized the attention mechanism and GRU  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIMIC-III Results (full codes) As shown in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIMIC-III Results (top-50 codes) From</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIMIC-II Results (full codes)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computational Cost Analysis</head><p>In this section, we analyzed the computational cost between the state-of-the-art model, CAML and our model, Mul-tiResCNN. The analysis was conducted from four aspects, namely the parameter amount, training time, training epoch, inference speed. Our experimental settings are as follows.</p><p>For CAML, we used the optimal hyper-parameter setting reported in their paper <ref type="bibr" target="#b10">(Mullenbach et al. 2018)</ref>. For Mul-tiResCNN, we used six filters and 1 residual block, which obtained the best result in our hyper-parameter tuning experiments. The batch size, learning rate and dropout rate are identical in every experiment. We used the training set and development set of MIMIC-III (full codes) as experimental data. The experiments were conducted on NVIDIA Tesla P40 GPUs. Training will terminate if the performance on the development set does not increase for 10 times. As shown in <ref type="table" target="#tab_5">Table 6</ref>, the parameter of MultiResCNN is approximately 1.9 times as many as that of CAML. The training time of MultiResCNN is about 2.3 times more than that of CAML. It is reasonable since MultiResCNN has more filters and layers. Interestingly, MultiResCNN needs much less epochs to converge. Considering the inference speed, CAML is approximately 1.5 times faster than MultiResCNN. Overall, the computational cost of Mul-tiResCNN is larger than that of CAML, but we hold the opinion that the increased cost is still acceptable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Truncating Data</head><p>During preprocessing, we truncated the discharge summaries that are longer than 2,500 tokens. To investigate the effect of the length limitation, we further conducted the experiments using 3,500, 4,500, 5,500 and 6,500. We selected these values because the maximum length of the discharge summaries in the development set is approximately 6,300. Results show that the performance differences between different settings are not significant. P@8 ranges between 0.736 and 0.741, and micro-F1 ranges between 0.557 and 0.566. 2,500 seems to be a decent selection considering the tradeoff between performance and cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>In this study, the performance improvement mostly comes from deep and diversified representations of text. In the future, we will explore how to incorporate BERT <ref type="bibr" target="#b3">(Devlin et al. 2019</ref>) into this task effectively and efficiently. In our preliminary experiments, BERT did not perform well due to the limitations of hardware and its fixed-length context. Therefore, potential solutions include recurrent Transformer <ref type="bibr" target="#b2">(Dai et al. 2019</ref>) and hierarchical BERT (Zhang, Wei, and Zhou 2019). Moreover, we chose the kernel sizes of the multi-filter layer and channel sizes of the residual layer empirically, which should be further studied and optimized in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In this paper, we proposed a multi-filter residual convolutional neural network for ICD coding. We conducted three experiments on the widely-used MIMIC-III and MIMIC-II datasets. Results show that our model achieved the stateof-the-art performance compared with several competitive baselines. We found that both multi-filter convolution and residual convolution helped the performance improvement with acceptable computational cost. This shows deep and diversified text representations could benefit the ICD coding from clinical text. Our model can be a strong baseline for not only ICD coding, but also other text classification tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>The architecture of a residual block r mi . "+" represents the element-wise addition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Examples of clinical text fragments and their corresponding ICD codes. 998.32: Disruption of external operation wound ... wound infection, and wound breakdown ... 428.0: Congestive heart failure ... DIAGNOSES: 1. Acute congestive heart failure 2. Diabetes mellitus 3. Pulmonary edema ... 202.8: Other malignant lymphomas ... a 55 year-old female with non Hodgkin's lymphoma and acquired C1 esterase inhibitor deficiency ... 770.6: Transitory tachypnea of newborn ... Chest x-ray was consistent with transient tachypnea of the newborn ... 424.1: Aortic valve disorders ... mild aortic stenosis with an aortic valve area of 1.9 cm squared and 2+ aortic insufficiency ... et al. 2017;</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance comparisons using different configurations in the multi-filter and residual convolutional layers. k denotes the kernel sizes k 1 , k 2 , ..., k m and p denotes the residual block number.</figDesc><table><row><cell>Model</cell><cell>Config</cell><cell cols="4">MIMIC-III, full codes P@8 Micro-F1 Macro-F1 P@5 Micro-F1 Macro-F1 MIMIC-III, top-50 codes</cell></row><row><cell>CNN</cell><cell>k=9</cell><cell>0.706 0.508</cell><cell>0.053</cell><cell>0.590 0.592</cell><cell>0.519</cell></row><row><cell></cell><cell>k=5,9,15</cell><cell>0.731 0.534</cell><cell>0.061</cell><cell>0.616 0.633</cell><cell>0.556</cell></row><row><cell>MultiCNN</cell><cell>k=3,5,9,15,19</cell><cell>0.735 0.542</cell><cell>0.067</cell><cell>0.630 0.646</cell><cell>0.576</cell></row><row><cell></cell><cell cols="2">k=3,5,9,15,19,25 0.736 0.545</cell><cell>0.068</cell><cell>0.633 0.652</cell><cell>0.584</cell></row><row><cell></cell><cell>p=1</cell><cell>0.714 0.532</cell><cell>0.063</cell><cell>0.618 0.645</cell><cell>0.560</cell></row><row><cell>ResCNN</cell><cell>p=2</cell><cell>0.713 0.532</cell><cell>0.059</cell><cell>0.589 0.601</cell><cell>0.531</cell></row><row><cell></cell><cell>p=3</cell><cell>0.710 0.529</cell><cell>0.059</cell><cell>0.575 0.585</cell><cell>0.500</cell></row><row><cell>MultiResCNN</cell><cell cols="2">k=3,5,9,15,19,25 0.741 0.561 p=1</cell><cell>0.073</cell><cell>0.638 0.673</cell><cell>0.608</cell></row><row><cell cols="3">utilized the scripts 2 provided by Mullenbach et al. (2018)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>for preprocessing.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>MIMIC-III results (full codes). The results of MultiResCNN are shown in means ? standard deviations.</figDesc><table><row><cell>AUC</cell><cell>F1</cell><cell>P@K</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>. The results of MultiResCNN are shown in means ? standard deviations.</figDesc><table><row><cell>AUC</cell><cell>F1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>MIMIC-II results (full codes). The results of MultiResCNN are shown in means ? standard deviations.</figDesc><table><row><cell>AUC</cell><cell>F1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Analysis of the computational cost between CAML</figDesc><table><row><cell cols="3">and MultiResCNN. "m", "s", "ep" and "d" denote million,</cell></row><row><cell cols="3">second, epoch and document respectively.</cell></row><row><cell></cell><cell>CAML</cell><cell>MultiResCNN</cell></row><row><cell cols="2">Parameter Amount 6.2m</cell><cell>11.9m</cell></row><row><cell>Training Time</cell><cell>438s/ep</cell><cell>1026s/ep</cell></row><row><cell>Training Epoch</cell><cell>85</cell><cell>26</cell></row><row><cell>Inference Speed</cell><cell cols="2">108.7d/s 70.9d/s</cell></row><row><cell cols="3">for automated ICD coding. Our model outperformed their</cell></row><row><cell cols="3">model by 0.098 in micro-F1. Our model also outperformed</cell></row><row><cell cols="3">the state-of-the-art model, CAML or DR-CAML, by 0.024,</cell></row><row><cell cols="3">0.002, 0.003, 0.007 and 0.021 in all evaluation metrics.</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://cs231n.github.io/convolutional-networks/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by the Center for Intelligent Information Retrieval, R01DA045816, R01HL125089, R01HL137794, R01HL135219, and R01LM012817. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multi-label classification of patient notes: case study on icd code assignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baumel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Intelligent information: a national system for monitoring clinical performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bottle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aylin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health services research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1p1</biblScope>
			<biblScope unit="page" from="10" to="31" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Transformer-XL: Attentive language models beyond a fixed-length context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the ACL</title>
		<meeting>the 57th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2978" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Devlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convolutional face finder: A neural architecture for fast and robust face detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Delakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1408" to="1423" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Garcia and Delakis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An empirical evaluation of supervised learning approaches in assigning diagnosis codes to electronic medical records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<editor>Pereira, F.</editor>
		<editor>Burges, C. J. C.</editor>
		<editor>Bottou, L.</editor>
		<editor>and Weinberger, K. Q.</editor>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Kim; Ba; Hinton</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Advances in Neural Information Processing Systems 25</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Combining classifiers in text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Larkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SI-GIR</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="289" to="297" />
		</imprint>
	</monogr>
	<note>Larkey and Croft</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-label text classification with a mixture model trained by em</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lipton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.03677</idno>
	</analytic>
	<monogr>
		<title level="m">Learning to diagnose with lstm recurrent neural networks</title>
		<meeting><address><addrLine>McCallum</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>AAAI workshop on Text Learning</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Explainable prediction of medical codes from clinical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mullenbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1101" to="1111" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Measuring diagnoses: Icd code accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>O&amp;apos;malley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health services research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5p2</biblScope>
			<biblScope unit="page" from="1620" to="1639" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Diagnosis code assignment: models and evaluation metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Perotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="237" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A shared task involving multi-label classification of clinical free text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pestian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing</title>
		<meeting>the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="97" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Condensed memory networks for clinical diagnostic inferencing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Farri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Selecting relevant features from the electronic health record for clinical code prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Scheurwegs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cule</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luyckx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Luyten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="92" to="103" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04075</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Towards automated icd coding using deep learning</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">HIBERT: Document level pre-training of hierarchical bidirectional transformers for document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.13348</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5059" to="5069" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Proceedings of the 57th Annual Meeting of the ACL</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
