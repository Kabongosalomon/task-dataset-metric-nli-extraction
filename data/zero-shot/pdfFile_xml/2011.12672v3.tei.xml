<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Batch Normalization Embeddings for Deep Domain Generalization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mattia</forename><surname>Segu</surname></persName>
							<email>msegu@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessio</forename><surname>Tonioni</surname></persName>
							<email>alessiot@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><forename type="middle">Tombari</forename><surname>Google</surname></persName>
						</author>
						<title level="a" type="main">Batch Normalization Embeddings for Deep Domain Generalization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Domain generalization aims at training machine learning models to perform robustly across different and unseen domains. Several recent methods use multiple datasets to train models to extract domain-invariant features, hoping to generalize to unseen domains. Instead, first we explicitly train domain-dependant representations by using adhoc batch normalization layers to collect independent domain's statistics. Then, we propose to use these statistics to map domains in a shared latent space, where membership to a domain can be measured by means of a distance function. At test time, we project samples from an unknown domain into the same space and infer properties of their domain as a linear combination of the known ones. We apply the same mapping strategy at training and test time, learning both a latent representation and a powerful but lightweight ensemble model. We show a significant increase in classification accuracy over current state-of-the-art techniques on popular domain generalization benchmarks: PACS, Office-31 and Office-Caltech.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Machine learning models trained on a certain data distribution often fail to generalize to samples from different distributions. This phenomenon is commonly referred to in literature as domain shift between training and testing data <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b33">34]</ref>, and is one of the biggest limitations of data driven algorithms. Assuming the availability of few annotated samples from the test domain, the problem can be mitigated by fine-tuning the model with explicit supervision <ref type="bibr" target="#b52">[53]</ref> or with domain adaptation techniques <ref type="bibr" target="#b50">[51]</ref>. Unfortunately, this assumption does not always hold in practice as it is often unfeasible in real scenarios to collect samples for any possible environment.</p><p>Domain generalization refers to algorithms to solve the domain shift problem by learning models robust to unseen domains. Several works leverage different domains at training time to learn a domain-invariant feature extractor <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b27">28]</ref>. Other works focus on optimizing the  At test time, we project each target sample independently in the domain space and locate it with respect to the known domains using the corresponding distances D a,t , D p,t , and D c,t . Properties of the unknown domain are revealed by the location of the unseen sample. We leverage these hints to improve classification of each test sample by means of a linear combination of domain specific classifiers, weighted by the inverse of the distances. model parameters to obtain consistent performance across domains via ad-hoc training policies <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b26">27]</ref>, while a different line of work requires modifications to the model architecture to achieve domain invariance <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>While these methods try to extract domain-invariant features, we go in the opposite direction and explicitly leverage domain-specific representations by collecting domaindependent batch normalization (BN) statistics for each of the domains available at training time. By doing so, we train a lightweight ensemble of domain-specific models sharing all parameters except for BN statistics. Peculiarly to our proposal, we use the accumulated statistics to map each domain as a point in a latent space of domains. We will re-fer to this mapping as the Batch Normalization Embedding (BNE) of a domain. <ref type="figure" target="#fig_1">Fig. 1</ref> sketches a visualization of such space for the case of three domains available at training time (e.g. Photo, Art Painting and Cartoon). At convergence, each training domain is mapped to a single point in the domain space. Then, at test time unseen samples from unknown domains can be mapped to the same space by means of their instance normalization statistics. By measuring the distances between the instance normalization statistics of the test sample (black dot) and the accumulated population statistics of each domain (colored dots), we can infer properties of the unknown test domain. Specifically, we leverage the reciprocal of such distances at test time to weigh the domain-specific predictions of our lightweight ensemble and accurately classify an unseen sample from an unknown domain. The same combination of domain-specific models can be used at training time on samples from the known domains to force the ensemble to learn a meaningful latent space and logits that can be linearly combined according to the proposed weighting strategy.</p><p>To sum up the contributions of our work: (i) we propose to accumulate domain-specific batch normalization statistics accumulated on convolutional layers to map image samples into a latent space where membership to a domain can be measured according to a distance from domain BNEs; (ii) we propose to use this concept to learn a lightweight ensemble model that shares all parameters excepts the normalization statistics and can generalize better to unseen domains; (iii) compared to previous work, we do not discard domain-specific attributes but exploit them to learn a domain latent space and map unknown domains with respect to known ones; (iv) our method can be applied to any modern Convolutional Neural Network (CNN) that relies on batch normalization layers, and scales gracefully to the number of domains available at training time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Domain Generalization. Most domain generalization works attempt to expose the model to domain shift at training time to generalize to unseen domains. Invariance can be encouraged at multiple levels:</p><p>Feature-level, denotes methods deriving domaininvariant features by minimizing a discrepancy between multiple training domains. Ghifary et al. <ref type="bibr" target="#b13">[14]</ref> brought domain generalization to the attention of the deep learning community by training multi-task autoencoders to transform images from one source domain into different ones, thereby learning invariant features. Analogously, Li et al. <ref type="bibr" target="#b27">[28]</ref> extended adversarial autoencoders by minimizing the Maximum Mean Discrepancy measure to align the distributions of the source domains to an arbitrary prior distribution via adversarial feature learning. Conditional Invariant Adversarial Networks <ref type="bibr" target="#b29">[30]</ref> have been proposed to learn domain-invariant representations, whereas Deep Separation Networks <ref type="bibr" target="#b3">[4]</ref> extract image representations partitioned into two sub-spaces: one unique to each domain and one shared. Differently, Motiian et al. <ref type="bibr" target="#b40">[41]</ref> propose to learn a discriminative embedding subspace via a Siamese architecture <ref type="bibr" target="#b22">[23]</ref>. Episodic training <ref type="bibr" target="#b26">[27]</ref> was proposed to train a generic model while exposing it to domain shift. In each episode, a feature extractor is trained with a badly tuned classifier (or vice-versa) to obtain robust features. Recently, <ref type="bibr" target="#b39">[40]</ref> proposed a method to simultaneously discover latent domains by clustering featuring together and minimizing feature discrepancy between them. For all these methods, the limited variety of domains to which the model can be exposed at training time can limit the magnitude of the shift to which the model learns invariance.</p><p>Data-level, denotes methods attempting to reduce the training set domain bias by augmenting the cardinality and variety of the samples. Data augmentation methods based on domain-guided perturbations of input samples <ref type="bibr" target="#b45">[46]</ref> or on adversarial examples <ref type="bibr" target="#b49">[50]</ref> have been proposed with the purpose of training a model to be robust to distribution shift. Domain randomization was adopted <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b32">33]</ref> to solve the analogous problem of transferring a model from synthetic to real data by extending synthetic data with random renderings. By performing data augmentation those methods force the feature extractor to learn domain-invariant features, while we argue that discarding domain-specific information might be detrimental for performance.</p><p>Model-based, denotes methods relying on ad-hoc architectures to tackle the domain generalization problem. <ref type="bibr" target="#b24">[25]</ref> introduced a low-rank parameterized CNN model, a dynamically parameterized neural network that generalizes the shallow binary undo bias method <ref type="bibr" target="#b20">[21]</ref>. Similarly, a structured low-rank constraint is exploited to align multiple domain-specific networks and a domain-invariant one in <ref type="bibr" target="#b9">[10]</ref>. Mancini et al. <ref type="bibr" target="#b35">[36]</ref> train multiple domain-specific classifiers and estimate the probabilities that a target sample belongs to each source domain to fuse the classifiers' predictions. A recent work <ref type="bibr" target="#b5">[6]</ref> proposes an alternative approach to tackle domain generalization by teaching a model to simultaneously solve jigsaw puzzles and perform well on a task of interest. Most of these methods require changes to state-of-the-art architectures, resulting in an increased number of parameters or complexity of the network.</p><p>Meta-learning, denotes methods relying on special training policies to train models robust to domain shift. <ref type="bibr" target="#b25">[26]</ref> extend to domain generalization the widely used model agnostic meta learning framework <ref type="bibr" target="#b12">[13]</ref>. <ref type="bibr" target="#b1">[2]</ref> propose a novel regularization function in a meta-learning framework to make the model trained on one domain perform well on another domain. <ref type="bibr" target="#b18">[19]</ref> propose a training heuristic that iteratively discards the dominant features activated on the training data, challenging the model to learn more robust rep-resentations. A gradient-based meta-train procedure was introduced by <ref type="bibr" target="#b10">[11]</ref> to expose the optimization to domain shift while regularizing the semantic structure of the feature space. These methods simulate unseen domains by splitting the training data in a meta-training set and meta-test set, therefore are inherently bounded by the variety of the samples available at training time. Batch Normalization for distribution alignment. The use of separate batch normalization statistics to align a training distribution to a test one has been firstly introduced for domain adaptation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b30">31]</ref>. The same domain-dependent batchnorm layer has been adapted to the multi-domain scenario <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b36">37]</ref> and exploited in a graph-based method <ref type="bibr" target="#b37">[38]</ref> that leverages domain meta-data to better align unknown domains to the known ones. All these works, however, require some representation of the target domain to perform the alignment during training, using either samples or metadata describing the target domain. Our approach instead does not rely on any external source of information regarding the target domain. Domain-specific normalization layers have only recently been proposed for domain generalization in <ref type="bibr" target="#b44">[45]</ref>, where a cluster of networks is trained to learn an optimal mixture of instance and batch normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>The core idea of our method is to exploit domain-specific batch normalization statistics to map known and unknown domains in a shared latent space, where domain membership of samples can be measured according to their distance from the domain embeddings of the known domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem Formulation</head><p>Let X and Y denote the input (e.g. images) and the output (e.g. object categories) spaces of a model. Let D = {d i } K i=1 denote the set of the K source domains available at training time. Each domain d i can be described by an unknown conditional probability distribution p y x,di = p(y|x, i) over the space X ? Y. The aim of a machine learning model is to learn the probability distribution p y x = p(y|x) of the training set <ref type="bibr" target="#b4">[5]</ref> by training models to learn a mapping X ? Y. We propose to use a lightweight ensemble of models to learn a mapping (X , D) ? Y that leverages the domain label to model a set of conditional distributions {p y x,di } K i=1 , each conditioned on the domain membership. Let t be a generic target domain available only at testing time and following the unknown probability distribution p y x,t over the same space. Since it is not possible to learn the target distribution p y x,t during training, the goal of our method is to accurately estimate it as a mixture (i.e. linear combination) of the learned source distributions p y x,di . For each source domain d ? D, a training set S d = {(x 1 d , y 1 d ), ..., (x n d , y n d )} containing n d labelled samples is provided. The test set T = {x 1t , ..., x nt } is composed of m t unlabelled samples collected from the unknown marginal distribution p x t of the target domain t. As opposed to the domain adaptation setting, we assume that target samples are not available at training time, and that each of them might belong to a different unseen domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Multi-Source Domain Alignment Layer</head><p>Neural networks are particularly prone to capture dataset bias in their internal representations <ref type="bibr" target="#b31">[32]</ref>, making internal features distributions highly domain-dependent. To capture and alleviate the distribution shift that is inherent in the multi-source setting, we draw inspiration from <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b44">45]</ref> and adopt batch normalization layers <ref type="bibr" target="#b19">[20]</ref> to normalize the activations of each domain to the same reference distribution via domain-specific normalization statistics.</p><p>At inference time, the activations of a certain domain d are normalized by matching their first and second order moments, nominally (? d , ? 2 d ), to those of a reference Gaussian with zero mean and unitary variance:</p><formula xml:id="formula_0">BN (z; d) = z ? ? d ? 2 d + ,<label>(1)</label></formula><p>where z is an input activation extracted from the marginal distribution q z d of the activations from the domain d;</p><formula xml:id="formula_1">? d = E z?q z d [z] and ? 2 d = V ar z?q z d [z]</formula><p>are the population statistics for the domain d, and &gt; 0 is a small constant to avoid numerical instability. At training time, the layer collects and applies domain-specific batch statistics (? d ,? 2 d ), while updating the corresponding moving averages to approximate the domain population statistics.</p><p>At inference time, if the domain label d of a test sample is unknown or it does not belong to D, we can still rely on normalization by instance statistics, i.e. the degenerate case of batch statistics with batch size equal to 1. <ref type="figure" target="#fig_3">Fig. 2</ref> (a) depicts the functioning of a multi-source domain generalization layer. Our method builds on the observation that for convolutional layers instance statistics and batch statistics are approximations of the same underlying distribution with different degrees of noise. Since the population statistics are a temporal integration of the batch statistics, the validity of this statement extends to the comparison with them. For example, statistics for a single channel in the case of a batch normalization layer applied on a 2D feature map of size H ? W , for a generic batch size B (batch statistics) and for B = 1 (instance statistics), are computed as:  collects domain-specific population statistics and compute instance statistics for test samples. After training, the population and instance statistics map respectively the source domains and the test samples into a latent space, where domain similarity can be measured by distances between embedding vectors. In (b), we visualize the learned domain space L 1 by means of a t-SNE plot of instance normalization and population statistics for a model trained with our method. Each test sample from the unseen domain sketch can be localized through its instance statistics (cyan dots) with respect to the known domains, embedded by the population statistics (green dots). Considering a test sample embedding, e.g. r t , the estimated distances (orange arrows) will be used to weigh the predictions of domain-specific classifiers.</p><formula xml:id="formula_2">? = 1 B ? H ? W b,h,w z b,h,w (B=1) = 1 H ? W h,w z h,w<label>(2)</label></formula><formula xml:id="formula_3">? 2 = 1 B ? H ? W b,h,w (z b,h,w ??) 2 (B=1) = 1 H ? W h,w (z h,w ??) 2 ,<label>(3)</label></formula><p>where? and? 2 are respectively the batch mean and variance and z b,h,w is the value of a single element of the feature map. If we consider z b,h,w to be described by a normally distributed random variable Z ? N (?, ? 2 ), then the instance and batch statistics are an estimate of the parameters of the same gaussian computed over a different number of samples, H ? W and B ? H ? W respectively. In the next section, we explain how we exploit this property to map source domains and unseen samples from unknown domain into the same latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Domain Localization in the Batchnorm Latent Space</head><p>The domain alignment layers described in Sec. 3.2 allow to learn the multiple source distributions {p y x,d } d?D distinctly. By leveraging them, we can learn a lightweight ensemble of domain-specific models, where every network shares all the weights except for the normalization statistics. Since such a lightweight ensemble nicely embodies the multiple source distributions, we propose to reduce the domain shift on the unknown target domain by interpolating across these distributions to estimate the unknown distribution p y x,t . The resulting target distribution is a weighted mixture of the distributions in the ensemble, for which the choice of the weights depends on the similarity of a test sample to each source domain.</p><p>We denote with a l ? B = {1, 2, ..., L} in superscript notation the different batch normalization layers in the model. For each of them we can define a latent space L l spanned by the activation statistics at the l ? th layer of the model. In this space, we observe that single samples x are mapped via their instance statics (?,? 2 ), whereas the population statistics accumulated for each domain (? d , ? 2 d ) are used to represent domain centroids. <ref type="figure" target="#fig_3">Fig. 2-(b)</ref> shows a visualization of the latent space L 1 for the PACS dataset <ref type="bibr" target="#b24">[25]</ref>, composed of 4 domains, and 3 of which (e.g. Art Painting, Cartoon, Photo) assumed available at training time. Population (big green dots) and instance (small dots) statistics are respectively used to project domains and individual samples. We rely on t-SNE <ref type="bibr" target="#b34">[35]</ref> to visualize instance and population statistics of source and target samples, and we observe how the latent space that we propose allows a spontaneous and stark division between domain clusters. Considering all latent spaces at different layers, we define a batch normalization embedding (BNE) for a certain domain d as the stack-ing of the population statistics computed at every layer:</p><formula xml:id="formula_4">e d = [e 1 d , e 2 d , ..., e L d ] (4) = [(? 1 d , ? 1 d 2 ), (? 2 d , ? 2 d 2 ), ..., (? L d , ? L d 2 )].</formula><p>For a target sample x t from an unknown domain t, we can derive a projection to the same space by forward propagating it through the network and computing its instance statistics. The latent embedding r t of x t is defined as the stacked vector of its instance statistics at different batch normalization layers in the network:</p><formula xml:id="formula_5">r t = [r 1 t , r 2 t , ..., r L t ] (5) = [(? 1 t , ? 1 t 2 ), (? 2 t , ? 2 t 2 ), ..., (? L t , ? L t 2 )].</formula><p>Each r l t represents the instance statistics collected at a certain layer l during forward propagation and can be used to map the sample x t in the latent space L l of layer l. Once the BNE for the test sample is available, it is possible to measure the similarity of a target sample x t to one of the known domains d as the inverse of the distance between r t and e d . By extension, this allows a soft 1-Nearest Neighbour domain classification of any test sample.</p><p>To compute a distance between two points in L l , we consider the means and variances of the corresponding batch normalization layer as the parameters of a multivariate Gaussian distribution. We can hence adopt a distance on the space of probability measures, i.e. a symmetric and positive definite function that satisfies the triangle inequality. We select the Wasserstein distance for the special case of two multivariate gaussian distributions, but we report a comparison to alternative distances in the supplementary material. Let p ? N (? p , C p ) and q ? N (? q , C q ) be two normal distributions on R n , with expected value ? p and ? q ? R n respectively and C p , C q ? R n?n covariance matrices. Denoting with || ? || 2 the Euclidean norm on R n , the 2-Wasserstein distance is:</p><formula xml:id="formula_6">W(p, q) = ?((? p , C p ), (? q , C q )) (6) = ||? p ? ? q || 2 2 + T r(C p + C q ? 2(C 1 2 q C p C 1 2 q ) 1 2 ),</formula><p>T r being the trace of the matrix. We rely on Eq. 6 to measure the distance between a test sample x t and the domain d by summing over the batch normalization layers l ? B the distance between the activation embeddings r l t and e l d :</p><formula xml:id="formula_7">D L (e d , r t ) = l?B W(e l d , r l t ) (7) = l?B ?((? l d , Diag(? l d 2 )), (? l xt , Diag(? l xt 2 ))).</formula><p>Eq. 2 shows that instance and batch statistics differ only for the number of samples over which they are estimated, making the comparison meaningful. The similarity of a test sample x t to the domain d is defined as the reciprocal of the distance from that domain and denoted as w t d . Once the similarity to each source domains is computed, we can use them to recover the unknown target distribution p y</p><p>x,t as a mixture (i.e. a linear combination) of the learned source distributions p y x,d weighted by the corresponding domain similarity:</p><formula xml:id="formula_8">p y x,t = d?D w t d p y x,d d?D w t d .<label>(8)</label></formula><p>We denote with f (?) the result of a forward pass in a neural network. We get the final prediction of our lightweight ensemble model f (x t ) as a linear combination of the domain dependant models f (x t |d): </p><formula xml:id="formula_9">f (x t ) = d?D w t d f (x t |d) d?D w t d ,<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Training Policy</head><p>To encourage a well-defined latent space for every batch normalization layer, we replicate at training time the distance weighting procedure described in Eq. 9 to compute predictions on samples from known domains. Each training batch is composed of K domain batches with an equal number of samples. During every training step, (i) the domain batches are first propagated to update the corresponding domain population statistics (? d , ? 2 d , ). Then, (ii) all individual samples are propagated assuming an unknown domain to collect their instance statistics and compute the domain similarities w t d , as in Sec. 3.3. Finally, (iii) each sample is propagated under K different domain assumptions (i.e. through the corresponding domain-specific branches) and the resulting domain-specific predictions are weighted according to Eq. 9. Applying this procedure during training promotes the creation of a well-defined latent space.</p><p>Since we initialize our model with weights pre-trained on ImageNet <ref type="bibr" target="#b8">[9]</ref>, each domain-specific batch normalization branch needs to be specialized before starting the distance training (DT) procedure described above, otherwise convergence problems might occur. We thus warm-up domainspecific batch normalization statistics by pre-training the model on the whole dataset following the standard procedure, except for the accumulation and application of domain-specific batch normalization statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Settings</head><p>By means of a synecdoche, we name our method after BNE, its main component. Datasets. We evaluate our method on three domain generalization benchmarks: PACS <ref type="bibr" target="#b24">[25]</ref> features 4 domains (Art Painting, Cartoon, Photo, Sketch) with a significant domain shift. Each domain includes samples from 7 different categories, for a total of 9991 samples. Some examples are shown in <ref type="figure" target="#fig_3">Fig. 2</ref>. Office-31 <ref type="bibr" target="#b43">[44]</ref> was originally introduced for domain adaptation and has been subsequently used for domain generalization. The dataset is composed of 3 different sources and 31 categories, representing images captured with a Webcam and a dSLR camera or collected from the Amazon website. Office-Caltech <ref type="bibr" target="#b14">[15]</ref> is a variant of Office-31 featuring one additional domain, derived from the Caltech-256 dataset <ref type="bibr" target="#b15">[16]</ref>. The dataset is composed of the 10 categories shared between Caltech-256 and the domains in Office-31. Evaluation Protocol. Coherently with other works, we evaluate both the AlexNet <ref type="bibr" target="#b23">[24]</ref> and the ResNet-18 <ref type="bibr" target="#b16">[17]</ref> architectures. For the experiments on PACS and Office-31 we follow the standard leave-one-domain-out evaluation procedure, where the model is trained on all domains but one, and tested on the left-out one. For Office-Caltech we do the same but also test following a leave-two-domain-out procedure. Since the original version of AlexNet does not include batch normalization layers, we adopt a variant with batch normalization applied on the activations of each convolutional layer <ref type="bibr" target="#b46">[47]</ref>. Since the goal of domain generalization is to leverage multiple sources to learn models that are robust on any target domain, the natural deep-learning baseline to compare against consists in training directly on the merged set of source domains. We will refer to it as (DeepAll). We compare our method against this strong baseline and several deep-learning based state-of-the-art methods for domain generalization. Since different methods rely on different initializations of network weights, which result in different baselines, we compare with methods providing their own baseline and report for every competitor: the performance on each unseen domain, the average baseline performance (Avg. DA), the average performance of the method itself (Avg.) and the relative gain (?%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Domain Generalization for Classification</head><p>We compare BNE against several methods for object classification on commonly used benchmarks. Additional experiments are reported in the supplementary material. PACS. We first benchmark our method on the PACS dataset <ref type="bibr" target="#b24">[25]</ref>, which presents a challenging domain generalization setting for object recognition. Every test uses 3 domains as training set and one as unknown test set; for each of this leave-one-out configurations, we train a model from the same initialization for 60 epochs. We test our method using the ResNet-18 architecture and report the results in Tab. 1. Overall, our proposal obtains the best absolute accuracy on 1 out of 4 target sets, with the second best average accuracy (Avg.) of 83.1% and a relative gain (?%) of +5.86 making it the second most effective algorithm on this dataset. Since all the networks are initialized with weights trained on ImageNet, they are implicitly biased towards the Photo domain, as testified by the higher accuracy on it when treated as test set. Sketch, instead, is arguably the more challenging domain, as testified by the lower accuracy achieved by all methods. It is in this scenario that our method is able to provide the bigger gain (+9.6% absolute gain in accuracy over our baseline). The best perfomance on this datasets is obtained by DSON <ref type="bibr" target="#b44">[45]</ref>, which proposes to learn an ad-hoc mixture of instance and batch normalization statics to improve generalization. This characteristic makes it a perfect candidate to be extended with the domain embedding strategy that we propose in Sec. 3.3. An in-depth discussion on this topic is provided in Sec. 4.4. Office-31. We evaluate our method on Office-31 <ref type="bibr" target="#b43">[44]</ref> and follow the leave-one-domain-out protocol. To compare with published results, we use AlexNet initialized with Im-ageNet weights and train it with our method for 100 epochs with learning rate 10 ?4 . Tab. 2 shows that our approach obtains the best absolute accuracy in two out of three test scenarios and a relative gain comparable or better than the alternatives. The Amazon target domain proves to be the most challenging setting, as the images are acquired in ideal conditions (i.e. white backgrounds, studio lighting. . . ) that are fairly different from the ImageNet domain. In this challening generalization scenario, BNE boosts the absolute accuracy with respect to the baseline by an impressive +11.2% and +2.3% with respect to the closest competitor. Office-caltech. We evaluate our method also on Office-Caltech <ref type="bibr" target="#b14">[15]</ref> and follow the standard evaluation procedure for this dataset, enumerating cases with a single target domain, either Amazon or Caltech, and scenarios with pairs of target domains: Dslr-Webcam and Amazon-Caltech. We use AlexNet initialized with ImageNet weights to compare with published results, and train BNE for 100 epochs. Tab. 3 shows that our approach achieves the best average accuracy and the best gain with respect to the baseline. The performance boost delivered with our method is especially evident  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>To measure the impact on performance of the different components of our method, we run ablation experiments on the PACS dataset using the ResNet-18 backbone, and report the results in Tab. 4. We compare again with the DeepAll baseline and against a DiscoveryNet (DNet, row (d)), a variant of BNE inspired by <ref type="bibr" target="#b36">[37]</ref>. While in BNE we propose to assign domain membership by looking at the distance between the latent batch normalization embeddings, with DNet domain membership is learned through a domain classification network. On row (a) we show the performance gain attributable to the usage of separate batchnorm statistics for each training domain, while using at inference time the projection and weighting strategy described in Sec. 3.3; row (b) extends the this approach by leveraging distance weighting (DT) at training time, as described in Sec. 3.4; finally, row (c) includes a warm-up phase in the initial training phase to help population statistics to converge to stable values before starting distance training. By comparing the average accuracy (Avg.) across the four possible target sets, it is clear how every component contributes to an increase in performance with respect to the baseline. By comparing line (c) to (d), we can notice how our proposal is more effective than the variant DNet inspired by the domain mapping strategy from <ref type="bibr" target="#b36">[37]</ref>, while also requiring less parameters. More details on DNet and extensive comparisons are reported in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Choosing a Distance Metric</head><p>A crucial component of our method is the distance function, used to locate each test sample with respect to the known domains. As mentioned in Sec. 3.3, we picked the Wasserstein distance for this task after a detailed preliminary study among different options, reported in Tab. 5. We considered three different distances: using a fixed value for the distance (Uniform), equivalent to averaging predictions of domain specific branches; using the Bhattacharya distance; using the Wasserstein distance. The basic Uniform distance setting is similar to <ref type="bibr" target="#b44">[45]</ref>, with the main difference being the normalization layer used: a domain-specific batchnorm in our case, a learned mixture of instance and batch normalizations for <ref type="bibr" target="#b44">[45]</ref>. Their approach thus also require to learn additional parameters. In our experiments, the   Wasserstein distance proves to be a more principled choice, consistently delivering the best performance both on average and on any specific left-out domain. Measuring the similarity of all samples to one of the training domain by means of a distance function is always more effective than blindly averaging predictions, therefore the effectiveness of our method derives from the accurate sample-wise domain attribution rather than from the chosen normalization layer.</p><p>This observation leaves open the opportunity of combining our distance weighting scheme with other recently proposed normalization methods, e.g. <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>Our method allows to navigate in the latent space of batch normalization statistics, describing unknown domains as a combination of the known ones. We rely on domain-specific normalization layers to disentangle independent representations for each training domain, and then use such implicit embeddings to localize unseen samples from unknown domains. Our method outperforms many alternatives on a number of domain generalization benchmarks ( <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b14">15]</ref>), underlining the advantage of maintaining specific domain representations over forcing invariant representations. We believe that our work highlights interesting properties of batch normalization layers, not extensively explored yet. Our formulation could also be easily extended to the domain adaptation setting by injecting unlabelled samples from the target domain during training. If few target samples happened to be available at the same time, they could all be used to retrieve a less biased estimate of the statistics of the unseen domain. We plan to explore these directions in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Supplementary Material</head><p>We provide supplementary material to further validate our method and complement the experimental section included in the main paper. Sec. 6.1 provides an algorithmic overview of the proposed training policy and additional training details are reported in Sec. 6.2; Sec. 6.3 shows additional results obtained with ResNet-18 <ref type="bibr" target="#b16">[17]</ref> on Office-31 <ref type="bibr" target="#b43">[44]</ref> and Office-Caltech <ref type="bibr" target="#b14">[15]</ref>, and with AlexNet on PACS <ref type="bibr" target="#b24">[25]</ref>; In Sec. 6.4, we conduct a qualitative analysis to verify our choices in terms of batch sizes and distance measures. Moreover, we validate BNE against other popular normalization strategies. In Sec. 6.5, we validate quantitatively our latent space proposal. Finally, we extensively compare the performance of BNE against the variant DNet that leverages a domain discovery network.</p><p>N.B.: Blue references point to the original manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Training Policy</head><p>We here provide a formalization of the distance training policy described in Sec. 3.4.</p><p>Let T = {b d } d?D be a training batch composed of K domain batches, each containing n samples from the cor-</p><formula xml:id="formula_10">responding domain d: b d = {(x i d , y i d )} n i=1 .</formula><p>In Alg. 1, we illustrate the training procedure for a single training batch T using the same notation as in the original manuscript.</p><p>During every training step, first, the domain batches are propagated to update the corresponding domain embedding e d (l:2-6). Then, each individual sample x t is propagated using instance normalization to collect its instance statistics (? l t , ?1 l t 2 ) ?l ? B (l:8). Given the statistics we compute the target embedding r t (l:9-10) and the domain similarities w t d (l:12), as in Sec. 3.3. Each sample is propagated under K different domain assumptions (i.e. through the corresponding domain-specific branches) (l:13). The resulting domain-specific predictions are weighted according to Eq. 11 to compute the final prediction (l:14). Finally, the cross-entropy loss between the final predictions f (x t ) and the corresponding ground truth y t is computed (l:15) and back-propagated to update the weights ? of the model (l: <ref type="bibr" target="#b15">16)</ref>. Applying this procedure during training encourages the creation of a batch normalization latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Training Settings</head><p>Coherently with other works, we evaluate both the AlexNet <ref type="bibr" target="#b23">[24]</ref> and the more recent ResNet-18 <ref type="bibr" target="#b16">[17]</ref> architecture. Before training each network, we initialize them with pre-trained weights on ImageNet and fine-tune the last fully-connected layer on the dataset of interest for 20 epochs. To train AlexNet <ref type="bibr" target="#b23">[24]</ref>, we use SGD as optimizer with momentum 0.95 and L2 regularization on network weights with weight decay 5 ? 10 ?5 . The initial learning rate is 10 ?3 , exponentially decayed with decay rate 0.95. ResNet-18 is trained with Adam <ref type="bibr" target="#b21">[22]</ref> and weight decay 10 ?6 . The initial learning rate is 10 ?4 . Coherently with previous works ( <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b38">39]</ref>), we also compute gradients through the mean and standard deviation computation for the batch normalization layers. All the input images are normalized according to the statistics computed on ImageNet. At training time, data augmentation is performed by first resizing the input image to 256, then randomly cropping to 224?224 for ResNet-18 and 227?227 for AlexNet; finally, a random horizontal flip is performed. Every training batch is composed of 16 samples per domain for ResNet-18 and 6 for AlexNet.</p><p>All the models are implemented in Tensorflow 2.0 ([1]). We initialize both AlexNet and ResNet-18 using the publicly available Caffe weights pre-trained on ImageNet, after carefully converting them. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Additional Results</head><p>We here provide additional results with the ResNet-18 <ref type="bibr" target="#b16">[17]</ref> architecture for the dataset Office-31 <ref type="bibr" target="#b43">[44]</ref> and with the AlexNet <ref type="bibr" target="#b46">[47]</ref> architecture for PACS <ref type="bibr" target="#b24">[25]</ref>. In the original manuscript, we already provide results with AlexNet and ResNet-18 respectively to compare against recently published works. Moreover, we expand the experimental setting with the addition of the dataset Office-Caltech <ref type="bibr" target="#b14">[15]</ref>, for which we present results with both ResNet-18 and AlexNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">PACS</head><p>In Tab. 6, we extend the comparison on PACS considering AlexNet to compare against a vast literature of published works relying on this older architecture. Once again our proposal achieves absolute performance comparable to the state of the art even if starting from a weaker baseline. Indeed when comparing the relative gain in performance provided by our method (?%), we are clearly outperforming any previously published solutions with an increase of +6.33%, while the second best obtains +4.88%. Once again, when considering Sketch as unseen domain our method can boost the performance by a +13% absolute gain in accuracy over our baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Office-31</head><p>In Tab. 7, we extend the comparison on Office-31 considering ResNet-18 as it is a good example of a modern architecture with native batch normalization layers. The results confirms that our method is able to improve performances over DeepAll across all three tests.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Ablation Study</head><p>We here provide additional ablation studies to better highlight different characteristics of our method with respect to the chosen batch size and the distance measures used in the latent space. The experiments are conducted on the PACS dataset <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.1">Batch Size</head><p>We study the impact of different batch sizes on the performance of our method in Tab. 9. As expected and already documented in several recent works leveraging batch normalization layers <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b51">52]</ref>, the larger the batch size is the better the generalization capability. In particular for our method the bigger is the batch size used at training time, the better are the approximation of the true population statistics (i.e., the better are the domain embeddings e d ). This translates in better final performance as detailed in Tab. 9 where we can observe an increment of +2.9 Average accuracy between using batch size 16 and 64.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.2">Method Components</head><p>In the main paper we measured the contribution in achieving the final performance of the different components of our methods. The proposed setting leveraged the PACS dataset and the ResNet-18 architecture. We here consider ablation experiments on the PACS dataset using the AlexNet architecture and report the results in Tab.3, comparing again with the DeepAll baseline. On row (a) we show the performance gained by using separate batchnorm statistics for the different train domains and using the projection and weighting strategy described in Sec. 3.3; row (b) extends the method above by using the distance weighting at training time (DT) as described in Sec. 3.4; finally, row (c) includes a warmup phase in the training of the model to make population statistics converge to stable values before starting the distance training. By comparing the average accuracy (Avg.) across the four possible target sets, it is clear how every component contributes to an increase in performance with respect to the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.3">Normalization Strategies</head><p>BNE can be interpreted as a peculiar normalization technique to achieve better generalization. We hence provide a quantitative comparison of our method against other popular normalization strategies: (a) InstanceNorm <ref type="bibr" target="#b30">[31]</ref>; (b) BatchNorm <ref type="bibr" target="#b19">[20]</ref>; (c) Freeze BatchNorm <ref type="bibr" target="#b19">[20]</ref> (i.e., keeping the population statistics as the one computed after the imagenet pre-training); (d) BNE(Ours).</p><p>Results for this comparison are shown in Tab. 11. Freezing batch normalization statistics (c) to those accumulated on ImageNet provides better generalization than finetuning population statistics on the training datasets (b), which might lead to overfitting and is equivalent to the baseline DeepAll. This is coherent with what highlighted in <ref type="bibr" target="#b44">[45]</ref>, Among the analysed normalization techniques, In-stanceNorm (a) achieves the poorest results. Our proposal (d) instead, by combining instance and batch normalization properties in a principled way, achieves the best results. We can indeed notice how BNE outperforms by a large margin all other normalization strategies, both overall (+3.5% over Freeze BatchNorm) and on any specific domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Latent Space Validation</head><p>We now want to investigate how well we are able to collect domain specific attributes of samples by projecting them to the batchnorm latent space. We trained ResNet-18 until convergence without distance training and warm-up on the PACS dataset considering Photo or Sketch as unseen domains. Once trained, we forward every training sample through the network and compute its instance statistics to project it to the batchnorm latent space. After the projection we measure the distance from every domain embedding: if the closest domain matches the real domain, then the latent space effectively represents membership to a certain domain. In Tab. 12 we report the average value of the reciprocal of the distance for every training sample with respect to the centroid of the three training domains. The higher values on the diagonal confirm our intuition that the batchnorm latent space can be used to implicitly encode domain attributes.</p><p>Furthermore, we investigate the relationship between measured distances and the prediction accuracy on the same ResNet-18 trained on PACS without DT. For each test sam-    ple we measure the prediction accuracy obtained using only the predictions from either the closest domain branch, the second closest or the third (i.e., the farthest away). We run the test for all 4 possible unseen domains following the leave-one-domain-out protocol and report in Tab. 13 the average accuracy. The results show a clear correlation between distances and accuracy, as trusting the "closest" domain branch clearly results in a higher accuracy than the others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6.">Domain Discovery Net</head><p>In Sec 4.3, we compared the performance of BNE with DNet. For this purpose, we follow <ref type="bibr" target="#b36">[37]</ref> and implement a domain discovery network (DNet) that takes as input the activations after the first convolutional block and directly outputs the probability for the input sample to belong to each one of the training domains. This probability distribution is used to weigh the domain-specific predictions of our lightweight ensemble. Analogously to <ref type="bibr" target="#b36">[37]</ref> we implemented DNet as a lateral branch to our lightweight ensemble that is composed of a global pooling layer, followed by a ReLU non linearity, a fully-connected layer and a softmax activation. DNet is trained in an end-to-end fashion together with the main classifier. We considered two options: (i) training DNet applying only a cross-entropy loss on the image classification logits with respect to the input categories; (ii) training DNet directly supervising the clas- <ref type="table" target="#tab_1">Table 13</ref>: Analysis of the classification accuracy considering predictions from the closest, second-closest (second) and thirdclosest (third) domain branches to target sample. We also report the average accuracy (Avg.) over all leave-one-domain-out tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Art sification of samples in the correct domain using domain labels.</p><p>In Tab. 14 we compare the domain classification accuracy (Avg. Domain) of BNE and that of DNet with or without applying a cross entropy loss over the domain labels across four tests considering different unseen domains on PACS. When cross-entropy is not applied on domain logits, BNE largely outperforms DNet. The 33% Avg. Domainfor DNet without cross-entropy on domain logits denotes that the discovery network learns to disregard the multidomain BN layer, always predicting the same domain class and thus leveraging only one branch of the multidomain BN layer. However, when cross-entropy is applied also on domain logits, the domain classification branch of DNet can adapt its parameters to predict well the domain classes (Avg. Domain). This, however, comes at the cost of a remarkable drop in image classification accuracy (Avg. Class) that can may be partially explained by DNet overfitting more to the training data and being less able to generalize to the test one. BNE instead provides a meaningful domain representation even without cross-entropy on domain logits, largely outperforming the image classification accuracy of DNet. Nevertheless, since our representation is not parametric, we cannot witness a visible increase in Avg. Domainwhen applying a cross-entropy loss also on the domain membership assigned through our representation.</p><p>The advantages of BNE over DNet are clear, since BNE leverages all the activations throughout the network to get an estimate of the domain membership, while DNet must rely only on the activations of the first layer due to the fixed input size of the domain classification branch. Moreover, our method allows a parameter-free domain representation, while DNet relies on a lateral branch to the main network. Finally, BNE allows to map samples in a latent space where distances from domain embeddings are computed, while DNet can only output the distance of the input sample from the training domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Photo</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Visualization of our method on the PACS dataset when the domains Art Painting, Photo and Carton are available at training time. We propose to use batch normalization layers to implicitly learn a domain space onto which map both known (training) and unknown (testing) domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) Multi-Source Domain Alignment Layer. t-SNE plot of instance and population statistics for seen and unseen domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Our method on PACS ([25]) with Sketch as unknown domain. A Multi-Source Domain Alignment Layer (a)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 Df (x t ) = d?D w t d f t d d?D w t d compute final predictions 15 :</head><label>115</label><figDesc>L (e d ,rt) f (x t |d) ?d ? D compute domain-specific predictions 14: L(?; T ) = (xt,yt)?T XE(f (x t ), y t )compute cross-entropy loss16:  ? ?? ? ? ? ? L(?; T )update weights</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Fig. 2-(b)shows a visualization of our localization technique superimposed over the t-SNE plot of instance and population statistics. By measuring the distance of a test samples (yellow dot) from the training domain embeddings (big green dots), we obtain ad-hoc mixture coefficients for each test sample.Our formulation allows to navigate in the latent space of the batchnorm statistics. Specifically, if a test sample belongs to one of the source domains, our method assigns a high weight to the prediction of the corresponding domainspecific model. On the other hand, if the test sample does not belong to any of the source domains, the final prediction will be expressed as a linear combination of the domaindependant models embodied in our lightweight ensemble.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>State-of-the-art comparison on PACS with ResNet-18. Methods with * do not use domain labels.MethodArt Cartoon Photo Sketch Avg. DA Avg. ?%</figDesc><table><row><cell cols="2">CrossGrad -[46] 78.7</cell><cell>73.3</cell><cell>94.0</cell><cell>65.1</cell><cell>79.1</cell><cell cols="2">77.8 -1.64</cell></row><row><cell cols="2">MetaReg -[2] 79.9</cell><cell>75.1</cell><cell>95.2</cell><cell>69.5</cell><cell>79.9</cell><cell cols="2">81.7 +2.25</cell></row><row><cell>MLDG -[26]</cell><cell>79.5</cell><cell>77.3</cell><cell>94.3</cell><cell>71.5</cell><cell>79.1</cell><cell cols="2">80.7 +2.02</cell></row><row><cell cols="2">Epi-FCR -[27] 82.1</cell><cell>77.0</cell><cell>93.9</cell><cell>73.0</cell><cell>79.1</cell><cell cols="2">81.5 +3.03</cell></row><row><cell>JiGen* -[6]</cell><cell>79.4</cell><cell>75.3</cell><cell>96.0</cell><cell>71.4</cell><cell>79.1</cell><cell cols="2">80.5 +1.77</cell></row><row><cell>MASF -[11]</cell><cell>80.3</cell><cell>77.1</cell><cell cols="2">94.99 71.69</cell><cell>79.2</cell><cell cols="2">81.0 +1.01</cell></row><row><cell cols="2">D-SAM -[12] 77.3</cell><cell>72.4</cell><cell>95.3</cell><cell>77.8</cell><cell>79.5</cell><cell cols="2">80.7 +1.47</cell></row><row><cell cols="2">MMLD* -[40] 81.3</cell><cell>77.2</cell><cell>96.1</cell><cell>72.3</cell><cell>78.7</cell><cell cols="2">81.8 +3.93</cell></row><row><cell>DSON -[45]</cell><cell>84.7</cell><cell>77.6</cell><cell>95.9</cell><cell>82.2</cell><cell>78.9</cell><cell cols="2">85.1 +7.85</cell></row><row><cell>DeepAll</cell><cell>75.8</cell><cell>73</cell><cell>94.4</cell><cell>70.9</cell><cell>-</cell><cell>78.5</cell><cell>-</cell></row><row><cell>BNE (Ours)</cell><cell>78.8</cell><cell>78.9</cell><cell>94.8</cell><cell>79.7</cell><cell>78.5</cell><cell cols="2">83.1 +5.86</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell>Method</cell><cell cols="6">Amazon Dslr Webcam Avg. DA Avg. ?%</cell></row><row><cell>UB -[21]</cell><cell>42.4</cell><cell>98.5</cell><cell>93.4</cell><cell>74.2</cell><cell cols="2">78.1 +5.26</cell></row><row><cell>DSN -[4]</cell><cell>44.0</cell><cell>99.0</cell><cell>94.5</cell><cell>74.2</cell><cell cols="2">79.2 +6.74</cell></row><row><cell>MTAE -[14]</cell><cell>43.7</cell><cell>99.0</cell><cell>94.2</cell><cell>74.2</cell><cell cols="2">79.0 +6.47</cell></row><row><cell>DGLRC -[10]</cell><cell>45.4</cell><cell>99.4</cell><cell>95.3</cell><cell>74.2</cell><cell cols="2">80.0 +7.82</cell></row><row><cell>MCIT -[43]</cell><cell>51.7</cell><cell>97.9</cell><cell>94.0</cell><cell>74.2</cell><cell cols="2">81.2 +9.43</cell></row><row><cell>DeepAll</cell><cell>43.8</cell><cell>94.1</cell><cell>88.4</cell><cell>-</cell><cell>75.4</cell><cell>-</cell></row><row><cell>BNE (Ours)</cell><cell>54.0</cell><cell>99.4</cell><cell>92.3</cell><cell>75.4</cell><cell cols="2">81.9 +8.62</cell></row></table><note>State-of-the-art comparison on Office-31 with AlexNet.in the challenging scenario where 2 domains are treated as targets, e.g. +6.4% absolute accuracy on Dslr-Webcam.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>State-of-the-art comparison on Office-Caltech with AlexNet.</figDesc><table><row><cell>Method</cell><cell cols="2">Amazon Caltech</cell><cell>Dslr,</cell><cell cols="4">Amazon, Avg. DA Avg. ?%</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Webcam Caltech</cell><cell></cell><cell></cell><cell></cell></row><row><cell>UB -[21]</cell><cell>91.0</cell><cell>86.0</cell><cell>80.5</cell><cell>70.0</cell><cell>84.5</cell><cell cols="2">81.9 -3.08</cell></row><row><cell>DSN -[4]</cell><cell>-</cell><cell>-</cell><cell>85.8</cell><cell>81.2</cell><cell>84.5</cell><cell>-</cell><cell>-</cell></row><row><cell>MTAE -[14]</cell><cell>93.1</cell><cell>86.2</cell><cell>85.3</cell><cell>80.5</cell><cell>84.5</cell><cell cols="2">86.3 +2.13</cell></row><row><cell>DGLRC -[10]</cell><cell>94.2</cell><cell>87.6</cell><cell>86.3</cell><cell>82.2</cell><cell>84.5</cell><cell cols="2">87.6 +3.67</cell></row><row><cell>MDA -[18]</cell><cell>93.5</cell><cell>86.9</cell><cell>84.9</cell><cell>82.6</cell><cell>84.5</cell><cell cols="2">87.0 +2.96</cell></row><row><cell>CIDG -[29]</cell><cell>93.2</cell><cell>85.1</cell><cell>83.7</cell><cell>65.91</cell><cell>84.5</cell><cell cols="2">82.0 -2.96</cell></row><row><cell>MCIT -[43]</cell><cell>93.3</cell><cell>86.3</cell><cell>85.2</cell><cell>82.7</cell><cell>84.5</cell><cell cols="2">86.9 +2.84</cell></row><row><cell>DeepAll</cell><cell>91.7</cell><cell>82.1</cell><cell>83.4</cell><cell>84.5</cell><cell>-</cell><cell>85.4</cell><cell>-</cell></row><row><cell>BNE (Ours)</cell><cell>93.7</cell><cell>85.9</cell><cell>89.8</cell><cell>87.7</cell><cell>85.4</cell><cell cols="2">89.3 +4.57</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison of different variants of our method on PACS with Resnet.</figDesc><table><row><cell cols="8">Method DT Warm-up Art Cartoon Photo Sketch Avg.</cell><cell>?%</cell></row><row><cell>DeepAll</cell><cell>-</cell><cell>-</cell><cell>75.8</cell><cell>73.0</cell><cell>94.4</cell><cell>70.9</cell><cell>78.5</cell><cell>-</cell></row><row><cell>(a) BNE</cell><cell></cell><cell></cell><cell>74.7</cell><cell>71.7</cell><cell>93.0</cell><cell>74.8</cell><cell>78.6</cell><cell>+0.03</cell></row><row><cell>(b) BNE</cell><cell></cell><cell></cell><cell>79.8</cell><cell>76.0</cell><cell>92.5</cell><cell>72.5</cell><cell>80.2</cell><cell>+2.13</cell></row><row><cell>(c) BNE</cell><cell></cell><cell></cell><cell>78.8</cell><cell>78.9</cell><cell>94.8</cell><cell>79.7</cell><cell>83.1</cell><cell>+5.86</cell></row><row><cell>(d) DNet</cell><cell></cell><cell></cell><cell>77.3</cell><cell>73.8</cell><cell>94.2</cell><cell>71.2</cell><cell>79.1</cell><cell>+0.08</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Comparison of different distance measures with our method on PACS with Alexnet.</figDesc><table><row><cell>Method</cell><cell>Distance</cell><cell>Art</cell><cell cols="2">Cartoon Photo</cell><cell cols="2">Sketch Average</cell></row><row><cell>DeepAll</cell><cell>-</cell><cell>64.4</cell><cell>65.4</cell><cell>88.0</cell><cell>53.8</cell><cell>67.9</cell></row><row><cell>BNE (Ours)</cell><cell>Uniform</cell><cell>64.9</cell><cell>64.0</cell><cell>88.7</cell><cell>61.7</cell><cell>69.8</cell></row><row><cell cols="2">BNE (Ours) Bhattacharyya</cell><cell>66.3</cell><cell>64.6</cell><cell>89.4</cell><cell>64.3</cell><cell>71.2</cell></row><row><cell>BNE (Ours)</cell><cell>Wasserstein</cell><cell>66.7</cell><cell>65.7</cell><cell>89.5</cell><cell>66.8</cell><cell>72.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>State-of-the-art comparison on PACS with AlexNet.</figDesc><table><row><cell>Method</cell><cell>Art</cell><cell cols="5">Cartoon Photo Sketch Avg. DA Avg.</cell><cell>?%</cell></row><row><cell>DICA -[42]</cell><cell>64.6</cell><cell>64.5</cell><cell>91.8</cell><cell>51.1</cell><cell>68.7</cell><cell>68.0</cell><cell>-1.02</cell></row><row><cell>D-MTAE -[14]</cell><cell>60.3</cell><cell>58.7</cell><cell>91.1</cell><cell>47.9</cell><cell>68.7</cell><cell>64.5</cell><cell>-6.11</cell></row><row><cell>DSN -[4]</cell><cell>61.1</cell><cell>66.5</cell><cell>83.3</cell><cell>58.6</cell><cell>68.7</cell><cell>67.4</cell><cell>-1.89</cell></row><row><cell>TF-CNN -[25]</cell><cell>62.9</cell><cell>67.0</cell><cell>89.5</cell><cell>57.5</cell><cell>67.1</cell><cell>69.2</cell><cell>+3.13</cell></row><row><cell>CIDDG -[30]</cell><cell>62.7</cell><cell>69.7</cell><cell>78.7</cell><cell>64.5</cell><cell>71.7</cell><cell>68.9</cell><cell>-3.91</cell></row><row><cell>Fusion -[36]</cell><cell>64.1</cell><cell>66.8</cell><cell>90.2</cell><cell>60.1</cell><cell>67.1</cell><cell>70.3</cell><cell>+4.77</cell></row><row><cell>CrossGrad -[46]</cell><cell>64.1</cell><cell>66.8</cell><cell>90.2</cell><cell>60.1</cell><cell>68.7</cell><cell>70.3</cell><cell>+2.33</cell></row><row><cell>MetaReg -[2]</cell><cell>69.8</cell><cell>70.4</cell><cell>91.1</cell><cell>59.3</cell><cell>69.3</cell><cell>72.6</cell><cell>+4.76</cell></row><row><cell>MLDG -[26]</cell><cell>66.2</cell><cell>66.9</cell><cell>88.0</cell><cell>59.0</cell><cell>67.2</cell><cell>70.0</cell><cell>+4.17</cell></row><row><cell>Epi-FCD -[27]</cell><cell>64.7</cell><cell>72.3</cell><cell>86.1</cell><cell>65.0</cell><cell>68.7</cell><cell>72.0</cell><cell>+4.80</cell></row><row><cell>JiGen -[6]</cell><cell>67.6</cell><cell>71.7</cell><cell>89.0</cell><cell>65.2</cell><cell>71.5</cell><cell>73.4</cell><cell>+2.66</cell></row><row><cell>MASF -[11]</cell><cell>70.4</cell><cell>72.5</cell><cell>90.7</cell><cell>67.3</cell><cell>71.7</cell><cell>75.2</cell><cell>+4.88</cell></row><row><cell>DeepAll</cell><cell>64.4</cell><cell>65.4</cell><cell>88.0</cell><cell>53.8</cell><cell>-</cell><cell>67.9</cell><cell>-</cell></row><row><cell>BNE (Ours)</cell><cell>66.7</cell><cell>65.7</cell><cell>89.5</cell><cell>66.8</cell><cell>67.9</cell><cell>72.2</cell><cell>+6.33</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>State-of-the-art comparison on Office-31 with ResNet-18.</figDesc><table><row><cell>Method</cell><cell>Amazon</cell><cell>Dslr</cell><cell cols="2">Webcam Avg. DA</cell><cell>Avg.</cell><cell>?%</cell></row><row><cell>DeepAll</cell><cell>55.1</cell><cell>99.0</cell><cell>92.6</cell><cell>-</cell><cell>82.2</cell><cell>-</cell></row><row><cell>BNE (Ours)</cell><cell>55.5</cell><cell>99.3</cell><cell>95.4</cell><cell>82.2</cell><cell>83.4</cell><cell>+1.42</cell></row><row><cell>6.3.3 Office-Caltech</cell><cell></cell><cell></cell><cell cols="4">ResNet as architecture in Tab. 8, with a clear +5.5% gain</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">over DeepAll.</cell><cell></cell><cell></cell></row><row><cell cols="3">In Tab. 8 we show additional results for Office-Caltech us-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">ing the ResNet-18 architecture. The same good property</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">observed using Alexnet is confirmed also when considering</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>State-of-the-art comparison on Office-Caltech with ResNet-18.</figDesc><table><row><cell>Method</cell><cell cols="6">Amazon Caltech Dslr, Amazon, Avg. DA Avg.</cell><cell>?%</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Webcam Caltech</cell><cell></cell><cell></cell><cell></cell></row><row><cell>DeepAll</cell><cell>92.7</cell><cell>83.1</cell><cell>85.3</cell><cell>80.7</cell><cell>-</cell><cell>85.5</cell><cell>-</cell></row><row><cell>BNE (Ours)</cell><cell>92.9</cell><cell>87.4</cell><cell>93.0</cell><cell>87.3</cell><cell>85.5</cell><cell>90.2</cell><cell>+5.50</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>Comparison of different batch sizes (per domain) on PACS with Alexnet.</figDesc><table><row><cell>Method</cell><cell>Batch Size</cell><cell>Art</cell><cell cols="2">Cartoon Photo</cell><cell cols="2">Sketch Average</cell></row><row><cell>DeepAll</cell><cell>-</cell><cell>64.4</cell><cell>65.4</cell><cell>88.0</cell><cell>53.8</cell><cell>67.9</cell></row><row><cell>BNE (Ours)</cell><cell>16</cell><cell>65.7</cell><cell>66.5</cell><cell>88.9</cell><cell>56.0</cell><cell>69.3</cell></row><row><cell>BNE (Ours)</cell><cell>32</cell><cell>67.9</cell><cell>65.7</cell><cell>89.4</cell><cell>62.3</cell><cell>71.3</cell></row><row><cell>BNE (Ours)</cell><cell>64</cell><cell>66.7</cell><cell>65.7</cell><cell>89.5</cell><cell>66.8</cell><cell>72.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Comparison of different variants of our method on PACS with Alexnet.</figDesc><table><row><cell>Method</cell><cell cols="2">DT Warm-up</cell><cell>Art</cell><cell cols="2">Cartoon Photo</cell><cell>Sketch</cell><cell>Avg.</cell></row><row><cell>DeepAll</cell><cell>-</cell><cell>-</cell><cell>64.4</cell><cell>65.4</cell><cell>88.0</cell><cell>53.8</cell><cell>67.9</cell></row><row><cell>(a) BNE</cell><cell></cell><cell></cell><cell>64.4</cell><cell>65.9</cell><cell>89.6</cell><cell>54.2</cell><cell>68.53</cell></row><row><cell>(b) BNE</cell><cell></cell><cell></cell><cell>63.7</cell><cell>67.9</cell><cell>84.6</cell><cell>66.6</cell><cell>70.7</cell></row><row><cell>(c) BNE</cell><cell></cell><cell></cell><cell>66.7</cell><cell>65.7</cell><cell>89.5</cell><cell>66.8</cell><cell>72.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 :</head><label>11</label><figDesc>Comparison of different normalization strategies on PACS with ResNet-18.</figDesc><table><row><cell>Method</cell><cell>Art</cell><cell cols="2">Cartoon Photo</cell><cell cols="2">Sketch Average</cell></row><row><cell>(a) InstanceNorm</cell><cell>62.6</cell><cell>72.7</cell><cell>79.7</cell><cell>71.7</cell><cell>71.7</cell></row><row><cell>(b) BatchNorm</cell><cell>75.8</cell><cell>73.0</cell><cell>94.4</cell><cell>70.9</cell><cell>78.5</cell></row><row><cell>(c) Freeze BatchNorm</cell><cell>75.0</cell><cell>76.8</cell><cell>92.6</cell><cell>73.9</cell><cell>79.6</cell></row><row><cell>(d) BNE (Ours)</cell><cell>78.8</cell><cell>78.9</cell><cell>94.8</cell><cell>79.7</cell><cell>83.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 :</head><label>12</label><figDesc>Analysis of the average similarity value as domain classification metrics with ResNet-18 on PACS without distance training. Classified domain is in bold.</figDesc><table><row><cell></cell><cell cols="2">(a) Photo unseen.</cell><cell></cell></row><row><cell>Source</cell><cell>Art</cell><cell cols="2">Cartoon Sketch</cell></row><row><cell>Art</cell><cell>8.24</cell><cell>5.35</cell><cell>4.21</cell></row><row><cell>Cartoon</cell><cell>6.58</cell><cell>7.02</cell><cell>5.97</cell></row><row><cell>Sketch</cell><cell>3.94</cell><cell>4.56</cell><cell>10.19</cell></row><row><cell></cell><cell cols="2">(b) Sketch unseen.</cell><cell></cell></row><row><cell>Source</cell><cell>Art</cell><cell cols="2">Cartoon Photo</cell></row><row><cell>Art</cell><cell>1.18</cell><cell>0.70</cell><cell>1.15</cell></row><row><cell>Cartoon</cell><cell>0.94</cell><cell>1.02</cell><cell>0.90</cell></row><row><cell>Photo</cell><cell>1.19</cell><cell>0.70</cell><cell>1.25</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 14 :</head><label>14</label><figDesc>Comparison BNE and DNet with or without cross-entropy loss applied also on domain logits. We report the domain classification accuracy for different runs with different unseen domains, the average domain classification accuracy (Avg. Domain) and the average image classification accuracy (Avg. Class).</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Painting</cell><cell>Cartoon</cell><cell>Photo</cell><cell>Sketch</cell><cell>Avg.</cell></row><row><cell></cell><cell>Closest</cell><cell></cell><cell>68.02</cell><cell>63.10</cell><cell>92.75</cell><cell>71.09</cell><cell>72.20</cell></row><row><cell></cell><cell>Second</cell><cell></cell><cell>65.14</cell><cell>60.75</cell><cell>86.83</cell><cell>57.11</cell><cell>64.58</cell></row><row><cell></cell><cell>Third</cell><cell></cell><cell>47.95</cell><cell>60.66</cell><cell>67.31</cell><cell>57.90</cell><cell>58.08</cell></row><row><cell>Method</cell><cell>XE</cell><cell>Art</cell><cell cols="2">Cartoon Photo</cell><cell cols="3">Sketch Avg. Domain Avg. Class</cell></row><row><cell>BNE</cell><cell></cell><cell>71.2</cell><cell>82.2</cell><cell>75.0</cell><cell>60.1</cell><cell>72.1</cell><cell>83.1</cell></row><row><cell>DNet</cell><cell></cell><cell>33.3</cell><cell>33.3</cell><cell>33.3</cell><cell>33.3</cell><cell>33.3</cell><cell>79.1</cell></row><row><cell>BNE</cell><cell></cell><cell>75.9</cell><cell>82.7</cell><cell>74.5</cell><cell>58.7</cell><cell>73.0</cell><cell>80.8</cell></row><row><cell>DNet</cell><cell></cell><cell>96.0</cell><cell>87.8</cell><cell>62.7</cell><cell>84.3</cell><cell>82.7</cell><cell>74.9</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">ResNet-18 and AlexNet ImageNet weights available at https : //github.com/heuritech/convnets-keras and https:// github.com/cvjena/cnn-models.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>update domain layer embeddings <ref type="bibr" target="#b5">6</ref>:</p><p>update domain embedding <ref type="bibr">7:</ref> for (x t , y t ) ? T do for every sample <ref type="bibr">8:</ref> Collect instance statistics (? t , ? t 2 ) forward propagation <ref type="bibr">9:</ref> r l t ?? (? l t , ? l t 2 ) ?l ? B define target layer embeddings <ref type="bibr">10:</ref> r t ?? [r 1 t , r 2 t , ..., r L t ] define target embedding <ref type="bibr">11:</ref> D L (e d , r t ) = l?B W(e l d , r l t ) ?d ? D compute domain distances <ref type="bibr">12:</ref> w t d =</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Metareg: Towards domain generalization using metaregularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Understanding batch normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Bjorck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carla</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7694" to="7705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>John S Bridle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurocomputing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fabio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio D&amp;apos;</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Autodial: Automatic domain alignment layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Maria</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel Rota</forename><surname>Bulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Just dial: Domain alignment layers for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Maria</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel Rota</forename><surname>Bulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Analysis and Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep domain generalization with structured low-rank constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="304" to="313" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Domain generalization via model-agnostic learning of semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Coelho De Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domain generalization with domain-specific aggregation modules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Antonio D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="187" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Domain generalization via multidomain discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoubo</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laiwan</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in artificial intelligence: proceedings of the... conference. Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<publisher>NIH Public Access</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Self-challenging improves cross-domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02454</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Undoing the damage of dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="158" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML deep learning workshop</title>
		<meeting><address><addrLine>Lille</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Episodic training for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Domain generalization via conditional invariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adaptive batch normalization for practical domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodi</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Revisiting batch normalization for practical domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodi</forename><surname>Hou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04779</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep drone racing: From simulation to reality with domain randomization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Loquercio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren?</forename><surname>Ranftl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Alexey Dosovitskiy, Vladlen Koltun, and Davide Scaramuzza</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2507" to="2516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Best sources forward: domain generalization through source-specific nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Robust place categorization with deep domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adagraph: Unifying predictive and continuous domain adaptation through graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6568" to="6577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Boosting domain adaptation by discovering latent domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Domain generalization using a mixture of multiple latent domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Matsuura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5715" to="5725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krikamol</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multi-component image translation for deep domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clinton</forename><surname>Mohammad Mahfujur Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahsa</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sridha</forename><surname>Baktashmotlagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sridharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="579" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Learning to optimize domain specific normalization for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonguk</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yumin</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongwoo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04275</idno>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.10745</idno>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Imagenet pre-trained models with batch normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Rodner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Denzler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.01452</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Mixture regression for covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><forename type="middle">J</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1337" to="1344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Domain randomization for transferring deep neural networks from simulation to the real world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tobin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE/RSJ international conference on intelligent robots and systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5334" to="5344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep visual domain adaptation: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihong</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">312</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="135" to="153" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hod</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
