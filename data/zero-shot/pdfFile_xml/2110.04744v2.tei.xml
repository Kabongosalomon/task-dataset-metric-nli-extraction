<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Published as a conference paper at ICLR 2022 LONG EXPRESSIVE MEMORY FOR SEQUENCE MODELING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Konstantin</forename><surname>Rusch</surname></persName>
							<email>trusch@ethz.ch</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Z?rich</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Mishra</surname></persName>
							<email>smishra@ethz.ch</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Z?rich</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">Benjamin</forename><surname>Erichson</surname></persName>
							<email>erichson@pitt.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
							<email>mmahoney@stat.berkeley.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Pittsburgh</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">ICSI and UC</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Published as a conference paper at ICLR 2022 LONG EXPRESSIVE MEMORY FOR SEQUENCE MODELING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a novel method called Long Expressive Memory (LEM) for learning long-term sequential dependencies. LEM is gradient-based, it can efficiently process sequential tasks with very long-term dependencies, and it is sufficiently expressive to be able to learn complicated input-output maps. To derive LEM, we consider a system of multiscale ordinary differential equations, as well as a suitable time-discretization of this system. For LEM, we derive rigorous bounds to show the mitigation of the exploding and vanishing gradients problem, a wellknown challenge for gradient-based recurrent sequential learning methods. We also prove that LEM can approximate a large class of dynamical systems to high accuracy. Our empirical results, ranging from image and time-series classification through dynamical systems prediction to keyword spotting and language modeling, demonstrate that LEM outperforms state-of-the-art recurrent neural networks, gated recurrent units, and long short-term memory models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Learning tasks with sequential data as inputs (and possibly outputs) arise in a wide variety of contexts, including computer vision, text and speech recognition, natural language processing, and time series analysis in the sciences and engineering. While recurrent gradient-based models have been successfully used in processing sequential data sets, it is well-known that training these models to process (very) long sequential inputs is extremely challenging on account of the so-called exploding and vanishing gradients problem <ref type="bibr">(Pascanu et al., 2013)</ref>. This arises as calculating hidden state gradients entails the computation of an iterative product of gradients over a large number of steps. Consequently, this (long) product can easily grow or decay exponentially in the number of recurrent interactions.</p><p>Mitigation of the exploding and vanishing gradients problem has received considerable attention in the literature. A classical approach, used in Long Short-Term Memory (LSTM) <ref type="bibr" target="#b18">(Hochreiter &amp; Schmidhuber, 1997)</ref> and Gated Recurrent Units (GRUs) <ref type="bibr" target="#b10">(Cho et al., 2014)</ref>, relies on gating mechanisms and leverages the resulting additive structure to ensure that gradients do not vanish. However, gradients might still explode, and learning very long-term dependencies remains a challenge for these architectures <ref type="bibr" target="#b27">(Li et al., 2018)</ref>. An alternative approach imposes constraints on the structure of the hidden weight matrices of the underlying recurrent neural networks (RNNs), for instance by requiring these matrices to be unitary or orthogonal <ref type="bibr" target="#b16">(Henaff et al., 2016;</ref><ref type="bibr" target="#b0">Arjovsky et al., 2016;</ref><ref type="bibr">Wisdom et al., 2016;</ref><ref type="bibr" target="#b21">Kerg et al., 2019)</ref>. However, constraining the structure of these matrices might lead to significantly reduced expressivity, i.e., the ability of the model to learn complicated inputoutput maps. Yet another approach relies on enforcing the hidden weights to lie within pre-specified bounds, leading to control on gradient norms. Examples include <ref type="bibr" target="#b27">Li et al. (2018)</ref>, based on independent neurons in each layer, and <ref type="bibr">Rusch &amp; Mishra (2021a)</ref>, based on a network of coupled oscillators. Imposing such restrictions on weights might be difficult to enforce, and weight clipping could reduce expressivity significantly. This brief survey highlights the challenge of designing recurrent gradient-based methods for sequence modeling which can mitigate the exploding and vanishing gradients problem, while at the same time being sufficiently expressive and possessing the ability to learn complicated input-output maps efficiently. We seek to address this challenge by proposing a novel gradient-based method.</p><p>The starting point for our method is the observation that realistic sequential data sets often contain information arranged according to multiple (time, length, etc., depending on the data and task) scales. Indeed, if there were only one or two scales over which information correlated, then a simple model with a parameter chosen to correspond to that scale (or, e.g., scale difference) should be able to model the data well. Thus, it is reasonable to expect that a multiscale model should be considered to process efficiently such multiscale data. To this end, we propose a novel gradientbased architecture, Long Expressive Memory (LEM), that is based on a suitable time-discretization of a set of multiscale ordinary differential equations <ref type="bibr">(ODEs)</ref>. For this novel gradient-based method (proposed in Section 2):</p><p>? we derive bounds on the hidden state gradients to prove that LEM mitigates the exploding and vanishing gradients problem (Section 4); ? we rigorously prove that LEM can approximate a very large class of (multiscale) dynamical systems to arbitrary accuracy (Section 4); and ? we provide an extensive empirical evaluation of LEM on a wide variey of data sets, including image and sequence classification, dynamical systems prediction, keyword spotting, and language modeling, thereby demonstrating that LEM outperforms or is comparable to state-of-the-art RNNs, GRUs and LSTMs in each task (Section 5).</p><p>We also discuss a small portion of the large body of related work (Section 3), and we provide a brief discussion of our results in a broader context (Section 6). Much of the technical portion of our work is deferred to Supplementary Materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">LONG EXPRESSIVE MEMORY</head><p>We start with the simplest example of a system of two-scale ODEs,</p><formula xml:id="formula_0">dy dt = ? y (? (W y z + V y u + b y ) ? y) , dz dt = ? z (? (W z y + V z u + b z ) ? z) .<label>(1)</label></formula><p>Here, t ? [0, T ] is the continuous time, 0 &lt; ? y ? ? z ? 1 are the two time scales, y(t) ? R dy , z(t) ? R dz are the vectors of slow and fast variables and u = u(t) ? R m is the input signal. For simplicity, we set d y = d z = d. The dynamic interactions between the neurons are modulated by weight matrices W y,z , V y,z , bias vectors b y,z and a nonlinear tanh activation function ?(u) = tanh <ref type="bibr">(u)</ref>.</p><p>Note that refers to the componentwise product of vectors.</p><p>However, two scales (one fast and one slow), may not suffice in representing a large number of scales that could be present in realistic sequential data sets. Hence, we need to generalize (1) to a multiscale version. One such generalization is provided by the following set of ODEs,</p><formula xml:id="formula_1">dy dt =? (W 2 y + V 2 u + b 2 ) (? (W y z + V y u + b y ) ? y) , dz dt =? (W 1 y + V 1 u + b 1 ) (? (W z y + V z u + b z ) ? z) .<label>(2)</label></formula><p>In addition to previously defined quantities, we need additional weight matrices W 1,2 , V 1,2 , bias vectors b y,z and sigmoid activation function?(u) = 0.5(1 + tanh(u/2)). As? is monotone, we can set W 1,2 = V 1,2 ? 0 and (b 1 ) j = b y , (b 2 ) j = b z , for all 1 ? j ? d, wit? ?(b y,z ) = ? y,z to observe that the two-scale system (1) is a special case of (2). One can readily generalize this construction to obtain many different scales in (2). Thus, we can interpret (? z (y, t), ? y (y, t)) = (? (W 1 y + V 1 u + b 1 ) ,? (W 2 y + V 2 u + b 2 )) in (2) as input and state dependent gating functions, which endow ODE (2) with multiple time scales. These scales can be learned adaptively (with respect to states) and dynamically (in time). Moreover, it turns out that the multiscale ODE system (2) is of the same general form (see SM ?C) as the well-known Hodgkin-Huxley equations modeling the dynamics of the action potential for voltage-gated ion-channels in biological neurons <ref type="bibr" target="#b19">(Hodgkin &amp; Huxley, 1952)</ref>.</p><p>Next, we propose a time-discretization of the multiscale ODE system (2), providing a circuit to our sequential model architecture. As is common with numerical discretizations of ODEs, doing so properly is important to preserve desirable properties. To this end, we fix ?t &gt; 0, and we discretize (2) with the following implicit-explicit (IMEX) time-stepping scheme to arrive at LEM, written in compact form as, ?t n = ?t?(W 1 y n?1 + V 1 u n + b 1 ),</p><formula xml:id="formula_2">?t n = ?t?(W 2 y n?1 + V 2 u n + b 2 ), z n = (1 ? ?t n ) z n?1 + ?t n ?(W z y n?1 + V z u n + b z ), y n = (1 ? ?t n ) y n?1 + ?t n ?(W y z n + V y u n + b y ).<label>(3)</label></formula><p>For steps 1 ? n ? N , the hidden states in LEM (3) are y n , z n ? R d , with input state u n ? R m . The weight matrices are W 1,2,z,y ? R d?d and V 1,2,z,y ? R d?m and the bias vectors are b 1,2,z,y ? R d . We also augment LEM (3) with a linear output state ? n ? R o with ? n = W y y n , and W y ? R o?d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>We start by comparing our proposed model, LEM <ref type="formula" target="#formula_2">(3)</ref>, to the widely used LSTM of <ref type="bibr" target="#b18">Hochreiter &amp; Schmidhuber (1997)</ref>. Observe that ?t n , ?t n in (3) are similar in form to the input, forget and output gates in an LSTM (see SM ?D), and that LEM (3) has exactly the same number of parameters (weights and biases) as an LSTM, for the same number of hidden units. Moreover, as detailed in SM ?D, we show that by choosing very specific values of the LSTM gates and the ?t n , ?t n terms in LEM (3), the two models are equivalent. However, this analysis also reveals key differences between LEM (3) and LSTMs, as they are equivalent only under very stringent assumptions. In general, as the different gates in both LSTM and LEM (3) are learned from data, one can expect them to behave differently. Moreover in contrast to LSTM, LEM stems from a discretized ODE system (2), which endows it with (gradient) stable dynamics.</p><p>The use of multiscale neural network architectures in machine learning has a long history. An early example was provided in <ref type="bibr" target="#b17">Hinton &amp; Plaut (1987)</ref>, who proposed a neural network with each connection having a fast changing weight for temporary memory and a slow changing weight for long-term learning. More recently, one can view convolutional neural networks as multiscale architectures for processing multiple spatial scales in data <ref type="bibr" target="#b3">(Bai et al., 2020)</ref>.</p><p>The use of ODE-based learning architectures has also received considerable attention in recent years with examples such as continuous-time neural ODEs <ref type="bibr">Queiruga et al., 2020;</ref> and their recurrent extensions <ref type="bibr">ODE-RNNs (Rubanova et al., 2019)</ref>, as well as RNNs based on discretizations of ODEs <ref type="bibr" target="#b6">(Chang et al., 2018;</ref><ref type="bibr" target="#b9">Chen et al., 2020;</ref><ref type="bibr" target="#b28">Lim et al., 2021;</ref><ref type="bibr">Rusch &amp; Mishra, 2021a;</ref><ref type="bibr" target="#b10">b)</ref>. In addition to the specific details of our archiecture, we differ from other discretized ODE-based RNNs in the explicit use of multiple (learned) scales in LEM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RIGOROUS ANALYSIS OF LEM</head><p>Bounds on hidden states. The structure of LEM (3) allows us to prove (in SM ?E.1) that its hidden states satisfy the following pointwise bound.</p><p>Proposition 4.1. Denote t n = n?t and assume that ?t ? 1. Further assume that the initial hidden states are z 0 = y 0 ? 0. Then, the hidden states z n , y n of LEM (3) are bounded pointwise as,</p><formula xml:id="formula_3">max 1?i?d max{|z i n |, |y i n |} ? min 1, ? ? t n , ?1 ? n, with ? = 1 + ?t ? 2 ? ?t .<label>(4)</label></formula><p>On the exploding and vanishing gradient problem. For any 1 ? n ? N , let X n ? R 2d , denoted the combined hidden state, given by X n = z 1 n , y 1 n , . . . . . . , z i n , y i n , . . . . . . , z d n , y d n . For simplicity of the exposition, we consider a loss function: E n = 1 2 y n ? y n 2 , with y n being the underlying ground truth. The training of our proposed model (3) entails computing gradients of the above loss function with respect to its underlying weights and biases ? ? ? = [W 1,2,y,z , V 1,2,y,z , b 1,2,y,z ], at every step of the gradient descent procedure. Following <ref type="bibr">Pascanu et al. (2013)</ref>, one uses chain rule to show,</p><formula xml:id="formula_4">?E n ?? = 1?k?n ?E (k) n ?? , ?E (k) n ?? = ?E n ?X n ?X n ?X k ? + X k ?? (5)</formula><p>In general, for recurrent models, the partial gradient</p><formula xml:id="formula_5">?E (k)</formula><p>n ?? , which measures the contribution to the hidden state gradient at step n arising from step k of the model, can behave as <ref type="bibr">et al. (2013)</ref>. If ? &gt; 1, then the partial gradient grows exponentially in sequence length, for long-term dependencies k &lt;&lt; n, leading to the exploding gradient problem. On the other hand, if ? &lt; 1, then partial gradients decays exponentially for k &lt;&lt; n, leading to the vanishing gradient problem. Thus, mitigation of the exploding and vanishing gradient problem entails deriving bounds on the gradients. We start with the following upper bound (proved in SM ?E.2), Proposition 4.2. Let z n , y n be the hidden states generated by LEM (3). We assume that ?t &lt;&lt; 1 is chosen to be sufficiently small. Then, the gradient of the loss function E n with respect to any parameter ? ? ? is bounded as</p><formula xml:id="formula_6">?E (k) n ?? ? ? n?k , for some ? &gt; 0 Pascanu</formula><formula xml:id="formula_7">?E n ?? ? (1 +?)t n + (1 +?)?t 2 n ,? = y n ? , ? = max{ W 1 ? , W 2 ? , W z ? , W y ? }, ? = 2 (1 + ?) (1 + 3?)<label>(6)</label></formula><p>If we choose the hyperparameter ?t = O(n ?1 ) (see SM (17) for the order-notation), then one readily observes from (6) that the gradient ? ? E n is uniformly bounded for any sequence length n and the exploding gradient problem is clearly mitigated for LEM (3). Even if one chooses ?t = O(n ?s ), for some 0 ? s ? 1, we show in SM Remark E.1 that the gradient can only grow polynomially (e.g. as O(n) for s = 1/2), still mitigating the exploding gradient problem.</p><p>Following <ref type="bibr">Pascanu et al. (2013)</ref>, one needs a more precise characterization of the partial gradient</p><formula xml:id="formula_8">? ? E (k)</formula><p>n , for long-term dependencies, i.e., k &lt;&lt; n, to show mitigation of the vanishing gradient problem. In SM ?E.3, we state and prove proposition E.2, which provides a precise formula for the asymptotics of the partial gradient. Here, we illustrate this formula in a special case as a corollary, Proposition 4.3. Let y n , z n be the hidden states generated by LEM (3) and the ground truth satisfy y n ? O(1). Then, for any k &lt;&lt; n (long-term dependencies) we have,</p><formula xml:id="formula_9">?E (k) n ?? = O ?t 3 2 .<label>(7)</label></formula><p>Here, constants in O(?t 3 2 ) depend on only on ? (6) and ? = W 2 1 and are independent of n, k.</p><p>This formula <ref type="formula" target="#formula_9">(7)</ref> shows that although the partial gradient can be small, i.e., O(?t 3 2 ), it is in fact independent of k, ensuring that long-term dependencies contribute to gradients at much later steps and mitigating the vanishing gradient problem.</p><p>Universal approximation of general dynamical systems. The above bounds on hidden state gradients show that the proposed model LEM (3) mitigates the exploding and vanishing gradients problem. However, this by itself, does not guarantee that it can learn complicated and realistic input-output maps between sequences. To investigate the expressivity of the proposed LEM, we will show in the following proposition that it can approximate any dynamical system, mapping an input sequence u n to an output sequence o n , of the (very) general form,</p><formula xml:id="formula_10">? n = f ? n?1 , u n , o n = o(? n ), ? 1 ? n ? N,<label>(8)</label></formula><p>with ? n ? R d h , o n ? R do denoting the hidden and output states, respectively. The input signal is u n ? R du and maps f :</p><formula xml:id="formula_11">R d h ? R du ? R d h and o : R d h ? R do are Lipschitz continuous.</formula><p>For simplicity, we set the initial state ? 0 = 0. Proposition 4.4. For all 1 ? n ? N , let ? n , o n be given by the dynamical system (8) with input signal u n . Under the assumption that there exists a R &gt; 0 such that max{ ? n , u n } &lt; R, for all 1 ? n ? N , then for any given &gt; 0 there exists a LEM of the form (3), with hidden states y n , z n ? R dy and output state ? n = W y y n ? R do , for some d y such that the following holds, o n ? ? n ? , ?1 ? n ? N.</p><p>From this proposition, proved in SM ?E.4, we conclude that, in principle, the proposed LEM (3) can approximate a very large class of dynamical systems.</p><p>Universal approximation of multiscale dynamical systems. While expressing a general form of input-output maps between sequences, the dynamical system (8) does not explicitly model dynamics at multiple scales. Instead, here we consider the following two-scale fast-slow dynamical system of the general form,</p><formula xml:id="formula_13">? n = f (? n?1 , ? n?1 , u n ), ? n = ? g(? n , ? n?1 , u n ), o n = o(? n ).<label>(10)</label></formula><p>Here, 0 &lt; ? &lt;&lt; 1 and 1 are the slow and fast time scales, respectively. The underlying maps (f , g) : R d h ?d h ?du ? R d h are Lipschitz continuous. In the following proposition, proved in SM ?E.5, we show that LEM (3) can approximate (10) to desired accuracy.</p><p>Proposition 4.5. For any 0 &lt; ? &lt;&lt; 1, and for all 1 ? n ? N , let ? n , ? n , o n be given by the two-scale dynamical system (10) with input signal u n . Under the assumption that there exists a R &gt; 0 such that max{ ? n , ? n , u n } &lt; R, for all 1 ? n ? N , then for any given &gt; 0, there exists a LEM of the form (3), with hidden states y n , z n ? R dy and output state ? n ? R do with ? n = Wy n such that the following holds,</p><formula xml:id="formula_14">o n ? ? n ? , ?1 ? n ? N.<label>(11)</label></formula><p>Moreover, the weights, biases and size (number of neurons) of the underlying LEM (3) are independent of the time-scale ? .</p><p>This argument can be readily generalized to more than two time scales (see SM Proposition E.4). Hence, we show that, in principle, the proposed model LEM (3) can approximate multiscale dynamical systems, with model size being independent of the underlying timescales. These theoretical results for LEM (3) point to the ability of this architecture to learn complicated multiscale inputoutput maps between sequences, while mitigating the exploding and vanishing gradients problem. Although useful prerequisities, these theoretical properties are certainly not sufficient to demonstrate that LEM (3) is efficient in practice. To do this, we perform several benchmark evaluations, and we report the results below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EMPIRICAL RESULTS</head><p>We present a variety of experiments ranging from long-term dependency tasks to real-world applications as well as tasks which require high expressivity of the model. Details of the training procedure for each experiment can be found in SM ?A. As competing models to LEM, we choose two different types of architectures-LSTMs and GRUs-as they are known to excel at expressive tasks such as language modeling and speech recognition, while not performing well on long-term dependency tasks, possibly due to the exploding and vanishing gradients problem. On the other hand, we choose state-of-the-art RNNs which are tailor-made to learn tasks with long-term dependencies. Our objective is to evaluate the performance of LEM and compare it with competing models. All code to reproduce our results can be found at https://github.com/tk-rusch/LEM.</p><p>Very long adding problem. We start with the well-known adding problem <ref type="bibr" target="#b18">(Hochreiter &amp; Schmidhuber, 1997)</ref>, proposed to test the ability of a model to learn (very) long-term dependencies. The input is a two-dimensional sequence of length N , with the first dimension consisting of random numbers drawn from U([0, 1]) and with two non-zero entries (both set to 1) in the second dimension, chosen at random locations, but one each in both halves of the sequence. The output is the sum of two numbers of the first dimension at positions, corresponding to the two 1 entries in the second dimension. We consider three very challenging cases, namely input sequences with length N = 2000, 5000 and 10000. The results of LEM together with competing models including stateof-the-art RNNs, which are explicitly designed to solve long-term dependencies, are presented in <ref type="figure" target="#fig_0">Fig. 1</ref>. We observe in this figure that while baseline LSTM is not able to beat the baseline meansquare error of 0.167 (the variance of the baseline output 1) in any of the three cases, a proper weight initialization for LSTM, the so-called chrono-initialization of Tallec &amp; Ollivier (2018) leads to much better performance in all cases. For N = 2000, all other architectures (except baseline LSTM) beat the baseline convincingly. However for N = 5000, only LEM, chrono-LSTM and coRNN are able to beat the baseline. In the extreme case of N = 10000, only LEM and chrono-LSTM are able to beat the baseline. Nevertheless, LEM outperforms chrono-LSTM by converging faster (in terms of number of training steps) and attaining a lower test MSE than chrono-LSTM in all three cases. Sequential image recognition. We consider three experiments based on two widely-used image recognition data sets, i.e., <ref type="bibr">MNIST (LeCun et al., 1998)</ref> and <ref type="bibr">CIFAR-10 (Krizhevsky et al., 2009)</ref>, where the goal is to predict the correct label after reading in the whole sequence. The first two tasks are based on MNIST images, which are flattened along the rows to obtain sequences of length N = 784. In sequential MNIST (sMNIST), the sequences are fed to the model one pixel at a time in streamline order, while in permuted sequential MNIST (psMNIST), a fixed random permutation is applied to the sequences, resulting in much longer dependency than for sMNIST. We also consider the more challenging noisy CIFAR-10 (nCIFAR-10) experiment <ref type="bibr" target="#b6">(Chang et al., 2018)</ref>, where CIFAR-10 images are fed to the model row-wise and flattened along RGB channels, resulting in 96-dimensional sequences, each of length 32. Moreover, a random noise padding is applied after the first 32 inputs to produce sequences of length N = 1000. Hence, in addition to classifying the underlying image, a model has to store this result for a long time. In <ref type="table" target="#tab_0">Table 1</ref>, we present the results for LEM on the three tasks together with other SOTA RNNs, which were explicitly designed to solve long-term dependency tasks, as well as LSTM and GRU baselines. We observe that LEM outperforms all other methods on sMNIST and nCIFAR-10. Additionally on psMNIST, LEM performs as well as coRNN, which has been SOTA among single-layer RNNs on this task. EigenWorms: Very long sequences for genomics classification. The goal of this task <ref type="bibr" target="#b1">(Bagnall et al., 2018)</ref> is to classify worms as belonging to either the wild-type or four different mutants, based on 259 very long sequences (length N = 17984) measuring the motion of a worm. In addition to the nominal length, it was empirically shown in Rusch &amp; Mishra (2021b) that the EigenWorms sequences exhibit actual very long-term dependencies (i.e., longer than 10k).  <ref type="formula" target="#formula_0">(2021b)</ref>, we divide the data into a train, validation and test set according to a 70%, 15%, 15% ratio. In <ref type="table" target="#tab_1">Table 2</ref>, we present results for LEM together with other models. As the validation and test sets, each consist of only 39 sequences, we report the mean (and standard deviation of) accuracy over 5 random initializations to rule out lucky outliers. We observe from this table that LEM outperforms all other methods, even the 2-layer UnICORNN architecture, which has been SOTA on this task.</p><p>Healthcare application: Heart-rate prediction. In this experiment, one predicts the heart rate from a time-series of measured PPG data, which is part of the TSR archive (Tan et al., 2020) and has been collected at the Beth Isreal Deaconess medical center. The data set, consisting of 7949 sequences, each of length N = 4000, is divided into a train, validation and test set according to a 70%,15%,15% ratio, <ref type="bibr" target="#b31">(Morrill et al., 2021;</ref><ref type="bibr">Rusch &amp; Mishra, 2021b)</ref>. The results, presented in <ref type="table" target="#tab_2">Table 3</ref>, show that LEM outperforms the other competing models, including having a test L 2 error of 35% less than the SOTA UnICORNN. Multiscale dynamical system prediction. The FitzHugh-Nagumo system <ref type="bibr" target="#b12">(Fitzhugh, 1955</ref>)</p><formula xml:id="formula_15">v = v ? v 3 3 ? w + I ext , w = ? (v + a ? bw),<label>(12)</label></formula><p>is a prototypical model for a two-scale fast-slow nonlinear dynamical system, with fast variable v and slow variable w and ? &lt;&lt; 1 determining the slow-time scale. This relaxation-oscillator is an approximation to the Hodgkin-Huxley model <ref type="bibr" target="#b19">(Hodgkin &amp; Huxley, 1952)</ref> of neuronal actionpotentials under an external signal I ext ? 0. With ? = 0.02, I ext = 0.5, a = 0.7, b = 0.8 and initial data (v 0 , w 0 ) = (c, 0), with c randomly drawn from U([?1, 1]), we numerically approximate <ref type="formula" target="#formula_0">(12)</ref> with the explicit Runge-Kutta method of order 5(4) in the interval [0, 400] and generate 128 training and validation and 1024 test sequences, each of length N = 1000, to complete the data set. The results, presented in <ref type="table" target="#tab_3">Table 4</ref>, show that LEM not only outperforms LSTM by a factor of 6 but also all other methods including coRNN, which is tailormade for oscillatory time-series. This reinforces our theory by demonstrating efficient approximation of multiscale dynamical systems with LEM. Google12 (V2) keyword spotting. The Google Speech Commands data set V2 (Warden, 2018) is a widely used benchmark for keyword spotting, consisting of 35 words, sampled at a rate of 16 kHz from 1 second utterances of 2618 speakers. We focus on the 12-label task (Google12) and follow the pre-defined splitting of the data set into train/validation/test sets and test different sequential models. In order to ensure comparability of different architectures, we do not use performanceenhancing tools such as convolutional filtering or multi-head attention. From <ref type="table" target="#tab_4">Table 5</ref>, we observe that both LSTM and GRU, widely used models in this context, perform very well with a test accuracy of around 95%. Nevertheless, LEM is able to outperform both on this task and provides the best performance.  <ref type="bibr" target="#b29">(Marcus et al., 1993)</ref>, preprocessed by <ref type="bibr" target="#b30">Mikolov et al. (2010)</ref>, has been identified as an excellent task for testing the expressivity of recurrent models <ref type="bibr" target="#b21">(Kerg et al., 2019)</ref>. To this end, in <ref type="table" target="#tab_6">Table 6</ref>, we report the results of different architectures, with a similar number of hidden units, on the PTB char-level task and observe that RNNs, designed explicitly for learning long-term dependencies, perform significantly worse than LSTM and GRU. On the other hand, LEM is able to outperform both LSTM and GRU on this task by some margin (a test bpc of 1.25 in contrast with approximately a bpc of 1.36). In fact, LEM provides the smallest test bpc among all reported single-layer recurrent models on this task, to the best of our knowledge. This superior performance is further illustrated in <ref type="table" target="#tab_7">Table 7</ref>, where the test perplexity for different models on the PTB word-level task is presented. We observe that not only does LEM significantly outperform (by around 40%) LSTM, but it also provides again the best performance among all single layer recurrent models, including the recently proposed TARNN <ref type="bibr" target="#b20">(Kag &amp; Saligrama, 2021</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>The design of a gradient-based model for processing sequential data that can learn tasks with longterm dependencies while retaining the ability to learn complicated sequential input-output maps is  <ref type="bibr" target="#b21">(Kerg et al., 2019)</ref> 1.47 1437 1.3M LSTM <ref type="bibr" target="#b23">(Krueger et al., 2017)</ref> 1.36 1000 5M GRU <ref type="bibr" target="#b2">(Bai et al., 2018)</ref> 1.37 1024 3M LEM 1.25 1024 5M  <ref type="bibr" target="#b20">(Kag &amp; Saligrama, 2021)</ref> 115.9 256 131k LSTM <ref type="bibr" target="#b20">(Kag &amp; Saligrama, 2021)</ref> 116.9 256 524k SkipLSTM <ref type="bibr" target="#b20">(Kag &amp; Saligrama, 2021)</ref> 114.2 256 524k TARNN <ref type="bibr" target="#b20">(Kag &amp; Saligrama, 2021)</ref> 94.6 256 524k LEM 72.8 256 524k</p><p>very challenging. In this paper, we have proposed Long Expressive Memory (LEM), a novel recurrent architecture, with a suitable time-discretization of a specific multiscale system of ODEs <ref type="formula" target="#formula_1">(2)</ref> serving as the circuit to the model. By a combination of theoretical arguments and extensive empirical evaluations on a diverse set of learning tasks, we demonstrate that LEM is able to learn long-term dependencies while retaining sufficient expressivity for efficiently solving realistic learning tasks.</p><p>It is natural to ask why LEM performs so well. A part of the answer lies in the mitigation of the exploding and vanishing gradients problem. Proofs for gradient bounds (6),(7) reveal a key role played by the hyperparameter ?t. We observe from SM <ref type="table" target="#tab_9">Table 8</ref> that small values of ?t might be needed for problems with very long-term dependencies, such as the EigenWorms dataset. On the other hand, no tuning of the hyperparameter ?t is necessary for several tasks such as language modeling, keyword spotting and dynamical systems prediction and a default value of ?t = 1 yielded very good performance. The role and choice of the hyperparameter ?t is investigated extensively in SM ?B.1. However, mitigation of exploding and vanishing gradients problem alone does not explain high expressivity of LEM. In this context, we proved that LEMs can approximate a very large class of multiscale dynamical systems. Moreover, we provide experimental evidence in SM ?B.2 to observe that LEM not only expresses a range of scales, as it is designed to do, but also these scales contribute proportionately to the resulting multiscale dynamics. Furthermore, empirical results presented in SM ?B.2 show that this ability to represent multiple scales correlates with the high accuracy of LEM. We believe that this combination of gradient stable dynamics, specific model structure, and its multiscale resolution can explain the observed performance of LEM.</p><p>We conclude with a comparison of LEM and the widely-used gradient-based LSTM model. In addition to having exactly the same number of parameters for the same number of hidden units, our experiments show that LEMs are better than LSTMs on expressive tasks such as keyword spotting and language modeling, while also providing significantly better performance on long-term dependencies. This robustness of the performance of LEM with respect to sequence length paves the way for its application to learning many different sequential data sets where competing models might not perform satisfactorily. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A TRAINING DETAILS</head><p>All experiments were run on CPU, namely Intel Xeon Gold 5118 and AMD EPYC 7H12, except for Google12, PTB character-level and PTB word-level, which were run on a GeForce RTX 2080 Ti GPU. All weights and biases of LEM (3) are initialized according to U(?1</p><formula xml:id="formula_16">/ ? d, 1/ ? d),</formula><p>where d is the number of hidden units. The hyperparameters are selected based on a random search algorithm, where we present the rounded hyperparameters for the best performing LEM model (based on a validation set) on each task in <ref type="table" target="#tab_9">Table 8</ref>.</p><p>We base the training for the PTB experiments on the following language modelling code: https://github.com/deepmind/lamb, where we fine-tune, based on a random search algorithm, only the learning rate, input-, output-and state-dropout, L 2 -penalty term and the maximum gradient norm.</p><p>We train LEM for 100 epochs on sMNIST, psMNIST and nCIFAR-10, after which we decrease the learning rate by a factor of 10 and proceed training for 20 epochs. Moreover, we train LEM for 50, 60 as well as 400 epochs on EigenWorms, Google12 and FitzHugh-Nagumo. We decrease the learning rate by a factor of 10 after 50 epochs on Google12. On the Healthcare task, we train LEM for 250 epochs, after which we decrease the learning rate by a factor of 10 and proceed training for 250 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B FURTHER EXPERIMENTAL RESULTS</head><p>B.1 ON THE CHOICE OF THE HYPERPARAMETER ?t.</p><p>The hyperparameter ?t in LEM (3) measures the maximum allowed (time) step in the discretization of the multi-scale ODE system (2). In propositions 4.1, 4.2 and 4.3, this hyperparameter ?t plays a key role in the bounds on the hidden states (4) and their gradients (6). In particular, setting ?t = O(N ?1 ) will lead to hidden states and gradients, that are bounded uniformly with respect to the underlying sequence length N . However, these upper bounds on the hidden states and gradients account for worst-case scenarios and can be very pessimistic for the problem at hand.</p><p>Thus, in practice, we determine ?t through a hyperparameter tuning procedure as described in section A. To this end, we perform a random search within ?t &lt; 2 and present the resulting optimal values of ?t for each of the considered data sets in <ref type="table" target="#tab_9">Table 8</ref>. From this table, we observe that for data sets such as PTB, FitzHugh-Nagumo and Google 12 we do not need any tuning of ?t and a  default value of ?t = 1 resulted in very good empiricial performance. On the other data sets such as sMNIST, nCIFAR-10 and the healthcare example, where the sequence length (N = O(10 3 )) is larger, we observe that values of ?t ? 0.1 yielded the best performance. The notable exception to this was for the EigenWorms data set, with a very long sequence length of N = 17984 as well as demonstrated very long range dependencies in the data, see <ref type="bibr">Rusch &amp; Mishra (2021b)</ref>. Here, a value of ?t = 1.6 ? 10 ?3 resulted in the best observed performance. To further investigate the role of the hyperparameter ?t in the EigenWorms experiment, we perform a sensitivity study where the value of ?t is varied and the corresponding accuracy of the trained LEM is observed. The results of this sensitivity study are presented in <ref type="figure" target="#fig_1">Fig. 2,</ref> where we plot the test accuracy (Y-axis) vs. the value of ?t (X-axis). From this figure, we observe that the accuracy is rather poor for ?t ? 1 but improves monotonically as ?t is reduced till a value of approximately 10 ?2 , after which it saturates. Thus, in this case, a value of ?t = O(N ? 1 2 ) (for sequence length N ) suffices to yield the best empirical performance.</p><p>Given this observation, we further test whether ?t = O(N ? 1 2 ) suffices for other problems with long-term dependencies. To this end, we consider the adding problem and vary the input sequence length by an order of magnitude, i.e., from N = 250 to N = 2000. The value of ?t is now fixed at ?t = 1 ? N and the resulting test loss (Y-axis) vs the number of training steps (X-axis) is plotted in <ref type="figure" target="#fig_2">Fig. 3</ref>. We see from this figure that this value of ?t sufficed to yield very small average test errors for this problem for all considered sequence lengths N . Thus, empirically a value of ?t in the range 1 ? N ? ?t ? 1 yields very good performance. Even if we set ?t = O( 1 ? N ), it can happen for very long sequences N &gt;&gt; 1 that the gradient can be quite small from the gradient asymptotic formula (7). This might lead to saturation in training, resulting in long training times. However, we do not observe such long training times for very long sequence lengths in our experiment. To demonstrate this, we again consider <ref type="figure" target="#fig_2">Fig. 3</ref> where the number of training steps (X-axis) is plotted for sequence lengths that vary an order of magnitude. The figure clearly shows that the approximately the same number of training steps are needed to attain a low test error, irrespective of the sequence length. This is further buttressed in <ref type="figure" target="#fig_0">Fig. 1</ref>, where similar number of training steps where needed for obtaining the same very low test error, even for long sequence lengths, with N up to 10000. Moreover, from section A, we see that the number of epochs for different data sets is independent of the sequence length. For instance, only 50 epochs were necessary for EigenWorms with a sequence length of N = 17984 and ?t = 1.6 ? 10 ?3 whereas 400 epochs were required for the FitzHugh-Nagumo system with a ?t = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 MULTISCALE BEHAVOR OF LEM.</head><p>LEM <ref type="formula" target="#formula_2">(3)</ref> is designed to represent multiple scales, with terms ?t n , ?t n being explicitly designed to learn possible multiple scales. In the following, we will investigate if in practice, LEM learns multiple scales and uses them to yield the observed superior empirical performance with respect to competing models.</p><p>To this end, we start by recalling the proposition 4.5 where we showed that in principle, LEM can learn the two underlying timescales of a fast-slow dynamical system (see proposition E.4 for a similar result for the universal approximation of a r-time scale (with r ? 2) dynamical system with LEM). Does this hold in practice ? To further investigate this issue, we consider the FitzHugh-Nagumo dynamical system (12) which serves as a prototype for a two-scale dynamical system. We consider this system (12) with the two time-scales being ? = 0.02 and 1 and train LEM for this system. In <ref type="figure">Fig. 4</ref>, we plot the empirical histogram that bins the ranges of learned scales ?t n , ?t n ? ?t = 2 (for all n and d) and counts the number of occurrences of ?t n , ?t n in each bin. From this figure, we observe that there is a clear concentration of learned scales around the values 1 and ? = 0.02, which exactly correspond to the underlying fast and slow time scales. Thus, for this model problem, LEM is exactly learning what it is designed to do and is able to learn the underlying time scales for this particular problem. 10 ?2 10 ?1 10 0 ?t n , ?t n 10 3 10 4 10 5 10 6 <ref type="figure">Figure 4</ref>: Histogram of (?t n ) i and (?t n ) i for all n = 1, . . . , N and i = 1, . . . , d of LEM (3) after training on the FitzHugh-Nagumo fast-slow system (12) using ?t = 2.</p><p>Nevertheless, one might argue that these learnable mutliple scales ?t n , ?t n are not necessary and a single scale would suffice to provide good empirical performance. We check this possibility on the FitzHugh-Nagumo data set by simply setting ?t n , ?t n ? ?t1 (with 1 being the vector with all entries set to 1), for all n and tuning the hyperparameter ?t. The comparative results are presented in <ref type="table" target="#tab_10">Table 9</ref>. We see from this table by not allowing for learnable ?t n , ?t n and simply setting them to a single scale parameter ?t and tuning this parameter only leads to results that are comparable to the baseline LSTM model. On the other hand, learning ?t n , ?t n resulted in an error that is a factor of 6 less than the baseline LSTM test error. Thus, we demonstrate the importance of the ability of the proposed LEM model to learn multiple scales in this example.  Hence, the multiscale resolution of LEM seems essential for the fast-slow dynamical system. Does this multiscale resolution also appear for other datasets and can it explain aspects of the observed empirical performance ? To this end, we consider the Google12 Keyword spotting data set and start by pointing out that given the spatial (with respect to input dimension d) and temporal (with respect to sequence length N ) heterogeneities, a priori, it is unclear if the underlying data has a multiscale structure. We plot the empirical histograms of ?t n , ?t n in <ref type="figure" target="#fig_3">Fig. 5</ref> to observe that even for this problem, the terms ?t n , ?t n are expressed over a range of scales, amounting to 2 ? 3 orders of magnitude. Thus, a range of scales are present in the trained LEM even for this example, but do they affect the empirical performance of LEM ? We investigate this question by performing an ablation study and reporting the results in <ref type="figure" target="#fig_5">Fig. 6</ref>. In this study, we clip the values of ?t n , ?t n to lie within the range [2 ?i , 1], for i = 0, 1, . . . , 7 and plot the statistics of the observed test accuracy of LEM. We observe from <ref type="figure" target="#fig_5">Fig. 6</ref> that by clipping ?t n , ?t n to lie near the default (single scale) value of 1 results in very poor empirical performance of an accuracy of ? 65%. Then the accuracy jumps to around 90% when an order of magnitude range for ?t n , ?t n is considered, before monotonically and slowly increasing to yield the best empirical performance for the largest range of values of ?t n , ?t n , considered in this study. A closer look at the empirical histograms plotted in <ref type="figure" target="#fig_3">Fig. 5</ref> reveal that the proportion of occurrences of ?t n , ?t n decays as a power law, and not exponentially, with respect to the scale amplitude. This, together with results presented in <ref type="figure" target="#fig_5">Fig. 6</ref> suggest that not only do a range of scales occur in learned ?t n , ?t n , the small scales also contribute proportionately to the dynamics and enable the increase in performance shown in <ref type="figure" target="#fig_5">Fig. 6</ref>.  Finally, in <ref type="figure" target="#fig_6">Fig. 7</ref>, we plot the empirical histograms of ?t n and ?t n for the learned LEM on the sMNIST data set to observe that again a range of scales are observed and the observed occurrences of ?t n and ?t n at each scale decays as a power law with respect to scale amplitude. Hence, we have sufficient empirical evidence to claim that the multi-scale resolution of LEM seems essential to its observed performance. However, further investigation is required to elucidate the precise mechanisms through this multiscale resolution enables superior performance, particularly on problems where the multiscale structure of the underlying data may not be explicit. Specialized weight initialization is a popular tool to increase the performance of RNNs on long-term dependencies tasks. One particular approach is the so-called chrono initialization <ref type="bibr">(Tallec &amp; Ollivier, 2018)</ref> for LSTMs, where all biases are set to zero except for the bias of the forget gate as well as the input gate (b f and b i in the LSTM (15)), which are sampled from</p><formula xml:id="formula_17">b f ? log(U[1, T max ? 1]) b i = ?b f ,</formula><p>where T max denotes the maximal temporal dependency of the underlying sequential data. We can see in <ref type="table" target="#tab_1">Table 2</ref> that the chrono initialization significantly improves the performance of LSTM on the EigenWorms task. Hence, we are interested in extending the chrono initialization to LEMs. One possible manner for doing this is as follows: Initialize all biases of LEM to zero except for b 1 in <ref type="formula" target="#formula_2">(3)</ref>, which is sampled from b 1 ? ? log(U[1, T max ?t ? 1]). We test the chrono initialization for LEM on the EigenWorms dataset, where we train LEM (without tuning ?t, i.e., setting ?t = 1), with and without chrono initialization. We provide the results in <ref type="table" target="#tab_0">Table 10</ref>, where we show again the results of LSTM with and without chrono initialization as well as the LEM result with tuned ?t and without chrono initialization from <ref type="table" target="#tab_1">Table 2</ref> for comparison. We see from <ref type="table" target="#tab_0">Table 10</ref> that when ?t is fixed to 1, the chrono initialization significantly improves the result of LEM. However, if we tune ?t, but do not use the chrono initialization, we significantly improve the performance of LEM again. We further remark that tuning ?t as well as using chrono initialization for LEM does not improve the results obtained with simply tuning ?t in LEM. Thus, we conclude that chrono initialization can successfully be adapted to LEM. However, tuning ?t (which controls the gradients) is still advisable in order to obtain the best possible results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C RELATION BETWEEN LEM AND THE HODGKIN-HUXLEY EQUATIONS</head><p>We observe that the multiscale ODEs <ref type="formula" target="#formula_1">(2)</ref>, on which LEM is based, are a special case of the following ODE system,</p><formula xml:id="formula_18">dz dt = F z (y, t) ? G z (y, t) z, dy dt = F y (z, t) H (y, t) ? G y (y, t) y.<label>(13)</label></formula><p>As remarked in the main text, it turns out the well-known Hodgkin-Huxley equations <ref type="bibr" target="#b19">Hodgkin &amp; Huxley (1952)</ref>, modeling the the dynamics of the action potential of a biological neuron can also be written down in the abstract form <ref type="formula" target="#formula_0">(13)</ref> </p><p>with input current u and constants?,?, c 1,2,3 , whose exact values can be read from <ref type="bibr" target="#b19">(Hodgkin &amp; Huxley, 1952)</ref>.</p><p>Thus, the multiscale ODEs (2) and the Hodgkin-Huxley equations are special case of the same general family (13) of ODEs. Moreover, the gating functions G y,z (y), that model voltage-gated ion channels in the Hodgkin-Huxley equations, are similar in form to ?t n , ?t n in (2).</p><p>It is also worth highlighting the differences between our proposed model LEM (and the underlying ODE system <ref type="formula" target="#formula_1">(2)</ref>) and the Hodgkin-Huxley ODEs modeling the dynamics of the neuronal action potential. Given the complicated form of the nonlinearites F y,z , G y,z , H in the Hodgkin-Huxley equations <ref type="formula" target="#formula_0">(14)</ref>, we cannot use them in designing any learning model. Instead, building on the abstract form of (13), we propose bespoke non-linearities in the ODE (2) to yield a tractable learning model, such as LEM <ref type="formula" target="#formula_2">(3)</ref>. Moreover, it should be emphasized that the Hodgkin-Huxley equations only model the dynamics of a single neuron (with a scalar voltage and 3 ion channels), whereas the hidden state dimension d of (2) can be arbitrary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D RELATION BETWEEN LEM AND LSTM</head><p>The well-known LSTM <ref type="bibr" target="#b18">(Hochreiter &amp; Schmidhuber, 1997</ref>) (in its mainly-used version using a forget gate <ref type="bibr" target="#b14">(Gers et al., 2000)</ref>) is given by,</p><formula xml:id="formula_20">f n =?(W f h n?1 + V f u n + b f ) i n =?(W i h n?1 + V i u n + b i ) o n =?(W o h n?1 + V o u n + b o ) c n = f n c n?1 + i n ?(Wh n?1 + Vu n + b) h n = o n ?(c n ).<label>(15)</label></formula><p>Here, for any 1 ? n ? N , h n ? R d is the hidden state and c n ? R d is the so-called cell state. The vectors i n , f n , o n ? R d are the input, forget and output gates, respectively. u n ? R m is the input signal and the weight matrices and bias vectors are given by W,</p><formula xml:id="formula_21">W f,i,o ? R d?d , V, V f,i,o ? R m?d and b, b f,i,o ? R d , respectively.</formula><p>It is straightforward to relate LSTM (15) and LEM (3) by first setting the cell state c n = z n , for all 1 ? n ? N and the hidden state h n = y n .</p><p>We further need to assume that the input state i n = ?t n and the forget state has to be f n = 1??t n . Finally, the output state of the LSTM (15) has to be o n = ?t n = 1, ?1 ? n ? N.</p><p>Under these assumptions and by setting ?t = 1, we can readily observe that the LEM (3) and LSTM (15) are equivalent.</p><p>A different interpretation of LEM, in relation to LSTM, is as follows; LEM can be thought of a variant of LSTM but with two cell states y n , z n per unit and no output gate. The input gates are ?t n and ?t n and the forget gates are coupled to the input gates. Given that the state z n is fed into the update for the state y n , one can think of one of the cell states sitting above the other, leading to a more sophisticated recursive update for LEM <ref type="formula" target="#formula_2">(3)</ref>, when compared to LSTM (15). Another key difference between LEM and LSTM is the scaling of the learnable gates in LEM by the small hyperparameter ?t. It is natural to examine whether scaling LSTM with such a small hyperparameter ?t will improve its performance on sequential tasks with long-term dependencies.</p><p>To this end, we propose to scale the input and forget gate of an LSTM with a small hyperparameter in two different ways, where we denote the new forget gate asf n and the new input gate as? n . The first version is (?t-LSTM v1)f n = ?tf n ,? n = ?ti n , while the second version is (?t-LSTM v2)</p><formula xml:id="formula_22">f n = (1 ? ?t)f n ,? n = ?ti n .</formula><p>We can see in <ref type="table" target="#tab_0">Table 11</ref> that both ?t-scaled versions of the LSTM lead to some improvements over the baseline LSTM for very long-sequence Eigenworms dataset, while still performing very poorly when compared to LEM. Moreover, we can see that standard sub-sampling routines, such as a truncation of the BPTT algorithm or random sub-sampling, applied to LSTMs lead to better improvements than ?t-scaling the forget and input gate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E SUPPLEMENT TO THE RIGOROUS ANALYSIS OF LEM</head><p>In this section, we will provide detailed proofs of the propositions in Section 4 of the main article. We start with the following simplifying notation for various terms in LEM (3),</p><formula xml:id="formula_23">A n?1 = W 1 y n?1 + V 1 u n + b 1 , B n?1 = W 2 y n?1 + V 2 u n + b 2 , C n?1 = W z y n?1 + V z u n + b z , D n = W y z n + V y u n + b y .</formula><p>Note that for all 1 ? n ? N , A n , B n , C n , D n ? R d . With the above notation, LEM (3) can be written componentwise, for each component 1 ? i ? d as,</p><formula xml:id="formula_24">z i n = z i n?1 + ?t?(A i n?1 )?(C i n?1 ) ? ?t?(A i n?1 )z i n?1 , y i n = y i n?1 + ?t?(B i n?1 )?(D i n ) ? ?t?(B i n?1 )y i n?1 .<label>(16)</label></formula><p>Moreover, we will use the following order-notation,</p><formula xml:id="formula_25">? = O(?), for ?, ? ? R + if there exists constants C, C such that C? ? ? ? C?. M = O(?), for M ? R d1?d2 , ? ? R + if there exists constant C such that M ? C?.<label>(17)</label></formula><p>Note that the techniques of proof in this following three sub-sections burrow heavily from those introduced in Rusch &amp; Mishra (2021a).</p><p>E.1 PROOF OF PROPOSITION 4.1 OF MAIN TEXT.</p><p>First, we prove Proposition 4.1, which yields the bound (4) for the hidden states of LEM.</p><p>Proof. The proof of the bound (4) is split into 2 parts. We start with the first equation in (16) and rewrite it as,</p><formula xml:id="formula_26">z i n = 1 ? ?t?(A i n?1 ) z i n?1 + ?t?(A i n?1 )?(C i n?1 ).</formula><p>Noting that the activation functions are such that 0 ??(x) ? 1, for all x and ?1 ? ?(x) ? 1, for all x and using the fact that ?t ? 1, we have from the above expression that,</p><formula xml:id="formula_27">z i n ? 1 ? ?t?(A i n?1 ) max z i n?1 , 1 + ?t?(A i n?1 ) max z i n?1 , 1 , ? max z i n?1 , 1 .</formula><p>By a symmetric argument, one can readily show that, z i n ? min(?1, z i n?1 ).</p><p>Combining the above inequalities yields,</p><formula xml:id="formula_28">min(?1, z i n?1 ) ? z i n ? max z i n?1 , 1 .<label>(18)</label></formula><p>Iterating (18) over n and using z i 0 = 0 for all 1 ? i ? d leads to,</p><formula xml:id="formula_29">?1 ? z i n ? 1, ?n, ?1 ? i ? d.<label>(19)</label></formula><p>An argument, identical to the derivation of (19), but for the hidden state y yields,</p><formula xml:id="formula_30">?1 ? y i n ? 1, ?n, ?1 ? i ? d.<label>(20)</label></formula><p>Thus, we have shown that the hidden states remain in the interval [?1, 1], irrespective of the sequence length.</p><p>Next, we will use the following elementary identities in the proof,</p><formula xml:id="formula_31">b(a ? b) = a 2 2 ? b 2 2 ? 1 2 (a ? b) 2 ,<label>(21)</label></formula><p>for any a, b ? R, and also,</p><formula xml:id="formula_32">ab ? a 2 2 + b 2 2 , ? &gt; 0.<label>(22)</label></formula><p>We fix 1 ? i ? d and multiply the first equation in (16) with z i n?1 and apply (21) to obtain,</p><formula xml:id="formula_33">(z i n ) 2 2 = (z i n?1 ) 2 2 + ?t?(A i n?1 )?(C i n?1 )z i n?1 ? ?t?(A i n?1 )(z i n?1 ) 2 + (z i n ? z i n?1 ) 2 2 = (z i n?1 ) 2 2 + ?t?(A i n?1 )?(C i n?1 )z i n?1 ? ?t?(A i n?1 )(z i n?1 ) 2 + ?t 2 2 ?(A i n?1 )?(C i n?1 ) ??(A i n?1 )z i n?1 2 , (from (16)) ? (z i n?1 ) 2 2 + ?t?(A i n?1 )|?(C i n?1 )||z i n?1 | ? ?t?(A i n?1 )(z i n?1 ) 2 + ?t 2 2 (?(A i n?1 )?(C i n?1 )) 2 + ?t 2 2? (A i n?1 ) 2 (z i n?1 ) 2 + ?t 2? (A i n?1 ) 2 |?(C i n?1 )||z i n?1 | (as (a ? b) 2 ? a 2 + b 2 + 2|a||b|)</formula><p>We fix = 2??t 1+?t in the elementary identity (22) to yield,</p><formula xml:id="formula_34">|?(C i n?1 )||z i n?1 | ? ?(C i n?1 ) 2 2 + (z i n?1 ) 2 2</formula><p>Applying this to the inequality for (z i n ) 2 leads to,</p><formula xml:id="formula_35">(z i n ) 2 2 ? (z i n?1 ) 2 2 + ?t?(A i n?1 ) + ?t 2? (A i n?1 ) 2 ?(C i n?1 ) 2 2 ? ?t?(A i n?1 ) 1 ? 2 ? ?t?(A i n?1 ) 2 ? ?t?(A i n?1 ) 2 (z i n?1 ) 2 .</formula><p>Using the fact that 0 ??(x) ? 1 for all x ? R, ? 2 ? 1 and that = 2??t 1+?t , we obtain from the last line of the previous equation that,</p><formula xml:id="formula_36">(z i n ) 2 ? (z i n?1 ) 2 + ?t + ?t 2 ? (z i n?1 ) 2 + ?t(1 + ?t) 2 2 ? ?t , ?1 ? n.</formula><p>Iterating the above estimate over n = 1, . . . ,n, for any 1 ?n and settingn = n yields,</p><formula xml:id="formula_37">(z i n ) 2 ? (z i 0 ) 2 + n ?t(1 + ?t) 2 2 ? ?t , ? (z i n ) 2 ? t n (1 + ?t) 2 2 ? ?t as z i 0 = 0, t n = n?t.</formula><p>Taking a square root in the above inequality yields,</p><formula xml:id="formula_38">|z i n | ? ? ? t n , ?n, ?1 ? i ? d.<label>(23)</label></formula><p>with ? defined in the expression (4).</p><p>We can repeat the above argument with the hidden state y to obtain,</p><formula xml:id="formula_39">|y i n | ? ? ? t n , ?n, ?1 ? i ? d.<label>(24)</label></formula><p>Combining <ref type="formula" target="#formula_1">(23)</ref>  Proof. We can apply the chain rule repeatedly (for instance as in <ref type="bibr">Pascanu et al. (2013)</ref>) to obtain,</p><formula xml:id="formula_40">?E n ?? = 1?k?n ?E n ?X n ?X n ?X k ? + X k ?? ?E (k) n ?? .<label>(25)</label></formula><p>Here, the notation ? + X k ?? refers to taking the partial derivative of X k with respect to the parameter ?, while keeping the other arguments constant.</p><p>A straightforward application of the product rule yields,</p><formula xml:id="formula_41">?X n ?X k = k&lt; ?n ?X ?X ?1 .<label>(26)</label></formula><p>For any k &lt; ? n, a tedious yet straightforward computation yields the following representation formula,</p><formula xml:id="formula_42">?X ?X ?1 = I 2d?2d + ?tE , ?1 + ?t 2 F , ?1 .<label>(27)</label></formula><p>Here E , ?1 ? R 2d?2d is a matrix whose entries are given below. For any 1 ? i ? d, we have,</p><formula xml:id="formula_43">E , ?1 2i?1,2j?1 ? 0, j = i E , ?1 2i?1,2i?1 = ??(A i ?1 ), E , ?1 2i?1,2j = (W 1 ) i,j? (A i ?1 ) ?(C i ?1 ) ? z i ?1 + (W z ) i,j? (A i ?1 )? (C i ?1 ), ?1 ? j ? d E , ?1 2i,2j?1 = (W y ) i,j? (B i ?1 )? (D i ), ?1 ? j ? d E , ?1 2i,2j = (W 2 ) i,j? (B i ?1 ) ?(D i ) ? y i ?1 , j = i E , ?1 2i,2i = ??(B i ?1 ) + (W 2 ) i,i? (B i ?1 ) ?(D i ) ? y i ?1 .</formula><p>(28) Similarly, F , ?1 ? R 2d?2d is a matrix whose entries are given below. For any 1 ? i ? d, we have,</p><formula xml:id="formula_44">F , ?1 2i?1,j ? 0, ? 1 ? j ? 2d, F , ?1 2i,2j?1 = ?(W y ) i,j? (A j ?1 )?(B i ?1 )? (D i ), 1 ? j ? d, F , ?1 2i,2j =?(B i ?1 )? (D i ) d ?=1 (W y ) i,? ?(C ? ?1 ) ? z ? ?1 ? (A ? ?1 )(W 1 ) ?,j +?(A ? ?1 )? (C ? ?1 )(W z ) ?,j .</formula><p>(29) Using the fact that, sup x?R max {|?(x)|, |? (x)|, |?(x)|, |? (x)|} ? 1, the pointwise bounds (4), the notation t n = n?t for all n, the definition of ? (6) and the definition of matrix norms, we obtain that,</p><formula xml:id="formula_45">E , ?1 ? ? max 1 + W z ? + (1 + min(1, ? ? t )) W 1 ? , 1 + W y ? + (1 + min(1, ? ? t )) W 2 ? ? 1 + (2 + min(1, ? ? t ))?.</formula><p>(30) By similar calculations, we obtain,</p><formula xml:id="formula_46">F , ?1 ? ? W y ? 1 + (1 + min(1, ? ? t )) W 1 ? + W z ? ? ?(1 + (2 + min(1, ? ? t ))?).<label>(31)</label></formula><p>Applying <ref type="formula" target="#formula_2">(30)</ref> and <ref type="formula" target="#formula_0">(31)</ref>  </p><p>Using the expression (26) with the above inequality yields,</p><formula xml:id="formula_48">?X n ?X k ? ? 1 + ? 2 ?t n?k .<label>(33)</label></formula><p>Next, we choose ?t &lt;&lt; 1 small enough such that the following holds,</p><formula xml:id="formula_49">1 + ? 2 ?t n?k ? 1 + ?(n ? k)?t,<label>(34)</label></formula><p>for any 1 ? k &lt; n.</p><p>Hence applying (34) in <ref type="formula" target="#formula_2">(33)</ref>, we obtain,</p><formula xml:id="formula_50">?X n ?X k ? ? 1 + ?(n ? k)?t.<label>(35)</label></formula><p>For the sake of definiteness, we fix any 1 ? ?, ? ? d and set ? = (W y ) ?,? in the following.</p><p>The following bounds for any other choice of ? ? ? can be derived analogously. Given this, it is straightforward to calculate from the structure of LEM (3) that entries of the vector ? + X k ?(Wy) ?,? are given by,</p><formula xml:id="formula_51">? + X k ?(W y ) ?,? j ? 0, ? j = 2?, ? + X k ?(W y ) ?,? 2? = ?t?(B ? k?1 )? (D ? k )z ? k .<label>(36)</label></formula><p>Hence, by the pointwise bounds (4), we obtain from (36) that</p><formula xml:id="formula_52">? + X k ?(W y ) ?,? ? ? ?t min(1, ? ? t k ).<label>(37)</label></formula><p>Finally, it is straightforward to calculate from the loss function E n = 1 2 y n ? y n 2 that ?E n ?X n = 0, y 1 n ?? 1 , . . . . . . , 0, y d n ?? d .</p><p>Therefore, using the pointwise bounds (4) and the notation? = ? ? , we obtain</p><formula xml:id="formula_54">?E n ?X n ? ?? + min(1, ? ? t n ).<label>(39)</label></formula><p>Applying <ref type="formula" target="#formula_2">(35)</ref>, <ref type="formula" target="#formula_2">(37)</ref> and <ref type="formula" target="#formula_2">(39)</ref> in the definition (25) yields,</p><formula xml:id="formula_55">?E (k) n ?(W y ) ?,? ? ?t min(1, ? ? t k ) ? + min(1, ? ? t n ) (1 + ?(n ? k)?t) .<label>(40)</label></formula><p>Observing that 1 ? k ? n, we see that n ? k ? n and t k ? t n . Therefore, (41) can be estimated for any 1 ? k ? n by,</p><formula xml:id="formula_56">?E (k) n ?(W y ) ?,? ? ?t min(1, ? ? t n ) ? + min(1, ? ? t n ) (1 + ?t n ) , 1 ? k ? n.<label>(41)</label></formula><p>Applying the bound (41) in (25) leads to the following bound on the total gradient,</p><formula xml:id="formula_57">?E n ?(W y ) ?,? ? n k=1 ?E (k) n ?(W y ) ?,? ? t n min(1, ? ? t n ) ? + min(1, ? ? t n ) (1 + ?t n ) ? t n (1 +?)(1 + ?t n ) ? (1 +?)t n + (1 +?)?t 2 n<label>(42)</label></formula><p>which is the desired bound (6) for ? = (W y ) ?,? .</p><p>Moreover, for long-term dependencies i.e., k &lt;&lt; n, we can set t k = k?t &lt; 1, with k independent of sequence length n, in (40) to obtain the following bound on the partial gradient,</p><formula xml:id="formula_58">?E (k) n ?(W y ) ?,? ? ?t 3 2 ? ? k 1 +? (1 + ?t n ) , 1 ? k &lt;&lt; n.<label>(43)</label></formula><p>Remark E.1. The bound (6) on the total gradient depends on t n = n?t, with n being the sequence length and ?t ? 1, a hyperparameter which can either be chosen a priori or determined through a hyperparameter tuning procedure. The proof of the bound (42) relies on ?t being sufficiently small. It would be natural to choose ?t ? n ?s , for some s ? 0. Substituting this expression in (6) leads to a bound of the form,</p><formula xml:id="formula_59">?E n ?? = O n 2(1?s)<label>(44)</label></formula><p>If s = 1, then clearly ?En ?? = O(1) i.e., the total gradient is bounded. Clearly, the exploding gradient problem is mitigated in this case.</p><p>On the other hand, if s takes another value, for instance s = 1 2 which is empirically observed during the hyperparameter training (see Section B.1, then we can readily observe from (44) that ?En ?? = O(n). Thus in this case, the gradient can grow with sequence length n but only linearly and not exponentially. Thus, the exploding gradient problem is also mitigated in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 PROOF OF PROPOSITION 4.3 OF MAIN TEXT.</head><p>To mitigate the vanishing gradient problem, we need to obtain a more precise characterization of the gradient ?E (k) n ?? defined in <ref type="bibr">(25)</ref>. For the sake of definiteness, we fix any 1 ? ?, ? ? d and set ? = (W y ) ?,? in the following. The following formulas for any other choice of ? ? ? can be derived analogously. Moreover, for simplicity of notation, we set the target functionX n ? 0.</p><p>Proposition 4.3 is a straightforward corollary of the following, Proposition E.2. Let y n , z n be the hidden states generated by LEM (3), then we have the following representation formula for the hidden state gradient,</p><formula xml:id="formula_60">?E (k) n ?? = ?t?(B ? k?1 )? (D ? k )z ? k (y ? n ?? ? n ) + ?t 2? (B ? k?1 )? (D ? k )z ? k ? ? d j=1 y j n ?? j n n =k+1? (B j ?1 ) ?(D j ) ? y j ?1 (W 2 ) j,2? ? ? + ?t 2? (B ? k?1 )? (D ? k )z ? k n =k+1? (B ? ?1 ) (y ? n ?? ? n ) + O(?t 3 ).<label>(45)</label></formula><p>Here, the constants in O could depend on ? defined in (6) (main text).</p><p>Proof. The starting point for deriving an asymptotic formula for the hidden state gradient</p><formula xml:id="formula_61">?E (k)</formula><p>n ?? is to observe from the representation formula (27), the bound (31) on matrices F , ?1 and the order notation (17) that,</p><formula xml:id="formula_62">?X ?X ?1 = I 2d?2d + ?tE , ?1 + O(?t 2 ),<label>(46)</label></formula><p>as long as ? is independent of ?t.</p><p>By using induction and the bounds (30),(31), it is straightforward to calculate the following representation formula for the product,</p><formula xml:id="formula_63">?X n ?X k = k&lt; ?n ?X ?X ?1 = I 2d?2d + ?t n =k+1 E , ?1 + O(?t 2 ).<label>(47)</label></formula><p>Recall that we have set ? = (W y ) ?,? . Hence, by the expressions <ref type="formula" target="#formula_2">(38)</ref> and <ref type="formula" target="#formula_2">(36)</ref>, a direct but tedious calculation leads to,</p><formula xml:id="formula_64">?E n ?X n I 2d?2d ? + X k ?? = ?t?(B ? k?1 )? (D ? k )z ? k (y ? n ?? ? n ) ,<label>(48)</label></formula><formula xml:id="formula_65">n =k+1 ?E n ?X n E , ?1 ? + X k ?? = (49) ?t?(B ? k?1 )? (D ? k )z ? k ? ? d j=1 y j n ?? j n n =k+1? (B j ?1 ) ?(D j ) ? y j ?1 (W 2 ) j,2? ? n =k+1? (B ? ?1 ) (y ? n ?? ? n ) ? ? .<label>(50)</label></formula><p>Therefore, by substituting the above expression into the representation formula (47) yields the desired formula (45).</p><p>In order to prove the formula (7) (see Proposition 4.3 of main text), we focus our interest on longterm dependencies i.e., k &lt;&lt; n. Then, a closer perusal of the expression in <ref type="formula" target="#formula_3">(48)</ref>, together with the pointwise bounds (4) which implies that y k?1 ? O( ? ?t), results in the following,</p><formula xml:id="formula_66">?E n ?X n I 2d?2d ? + X k ?? = O ?t 3 2 .<label>(51)</label></formula><p>Similarly, we also obtain,</p><formula xml:id="formula_67">?t n =k+1 ?E n ?X n E , ?1 ? + X k ?? = O ?t 3 2 .<label>(52)</label></formula><p>Combining <ref type="formula" target="#formula_0">(51)</ref> and <ref type="formula" target="#formula_1">(52)</ref> results in the desired asymptotic bound <ref type="formula" target="#formula_9">(7)</ref>.</p><p>Remark E.3. The upper bound on the gradient (6) and the gradient asymptotic formula (7) impact the choice of the timestep hyperparameter ?t. For sequence length n, if we choose ?t ? n ?s , with s ? 0, we see from Remark E.1 that the upper bound on the total gradient scales like O(n 2(1?s) ).</p><p>On the other hand, from <ref type="formula" target="#formula_9">(7)</ref>, the gradient contribution from long-term dependencies will scale like O(n ?3s</p><p>2 ). Hence, a small value of s ? 0, will ensure that the gradient with respect to long-term dependencies will be O(1). However, the total gradient will behave like O(n 2 ) and possibly blow up fast. Similarly, setting s ? 1 leads to a bounded gradient, while the contributions from long-term dependencies decay as fast as n ?3 2 . Hence, one has to find a value of s that balances both these requirements. Equilibrating them leads to s = 4 7 , ensuring that the total gradient grows sub-linearly while long-term dependencies still contribute with a sub-linear decay. This value is very close to the empirically observed value of s = 1 2 which also ensures that the total gradient grows linearly and the contribution of long-term dependencies decays sub-linearly in the sequence length n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.4 PROOF OF PROPOSITION 4.4</head><p>Proof. To prove this proposition, we have to construct hidden states y n , z n , output state ? n , weight matrices W 1,2,y,z , W y , V 1,2,y,z and bias vectors b 1,2,y,z such that LEM (3) with output state ? n = W y y n approximates the dynamical system (8).</p><p>Let R * &gt; R &gt;&gt; 1 and * &lt; , be parameters to be defined later. By the theorem for universal approximation of continuous functions with neural networks with the tanh activation function ? = tanh <ref type="bibr" target="#b4">(Barron, 1993)</ref>, given * , there exist weight matrices W 1 ? R d1?d h , V 1 ? R d1?du , W 2 ? R d h ?d1 and bias vector b 1 ? R d1 such that the tanh neural network defined by,</p><formula xml:id="formula_68">N 1 (h, u) = W 2 ? (W 1 h + V 1 u + b 1 ) ,<label>(53)</label></formula><p>approximates the underlying function f in the following manner,</p><formula xml:id="formula_69">max max( h , u )&lt;R * f (h, u) ? N 1 (h, u) ? * .<label>(54)</label></formula><p>Similarly, one can readily approximate the identity function g(h, u) = h with a tanh neural network of the form,N 2 (h) =W 2 ? W 1 h ,</p><formula xml:id="formula_70">such that max h , u &lt;R * g(h) ? N 2 (h) ? * .<label>(55)</label></formula><p>Next, we define the following dynamical system,</p><formula xml:id="formula_72">z n = W 2 ? (W 1?n?1 + V 1 u n + b 1 ) , y n =W 2 ? W 1zn ,<label>(57)</label></formula><p>with initial statesz 0 =? 0 = 0.</p><p>Using the approximation bound (54), we derive the following bound, <ref type="formula" target="#formula_3">(54)</ref>, <ref type="formula" target="#formula_7">(56)</ref>).</p><formula xml:id="formula_73">? n ?? n = f ? n?1 , u n ?z n +z n ?? n ? f ? n?1 , u n ? W 2 ? (W 1?n?1 + V 1 u n + b 1 ) + g(z n ) ?W 2 ? W 1zn ? f ? n?1 , u n ? f (? n?1 , u n ) + f (? n?1 , u n ) ? W 2 ? (W 1?n?1 + V 1 u n + b 1 ) + g(z n ) ?W 2 ? W 1zn ? Lip(f ) ? n?1 ?? n?1 + 2 * (from</formula><p>Here, Lip(f ) is the Lipschitz constant of the function f on the compact set {(h, u) ? R d h ?du : h , u &lt; R * }. Note that one can readily prove using the fact that? 0 =z 0 = 0, bounds (54), (56) and the assumption ? n , u n &lt; R, that z n , ? n &lt; R * = 2R.</p><p>Iterating the above inequality over n leads to the bound,</p><formula xml:id="formula_74">? n ?? n ? 2 * n?1 ?=0 Lip(f ) ? .<label>(58)</label></formula><p>Hence, using the Lipschitz continuity of the output function o in <ref type="formula" target="#formula_10">(8)</ref>, one obtains,</p><formula xml:id="formula_75">o n ? o(? n ) ? 2 * Lip(o) n?1 ?=0 Lip(f ) ? ,<label>(59)</label></formula><p>with Lip(o) being the Lipschitz constant of the function o on the compact set {h ? R d h : h &lt; R * }.</p><p>Next, we can use the universal approximation theorem for neural networks again to conclude that given a tolerance? , there exist weight matrices W 3 ? R d2?d h , W 4 ? R d h ?d2 and bias vector b 2 ? R d2 such that the tanh neural network defined by,</p><formula xml:id="formula_76">N 3 (h) = W 4 ? (W 3 h + b 2 ) ,<label>(60)</label></formula><p>approximates the underlying output function o in the following manner,</p><formula xml:id="formula_77">max h &lt;R * o(h) ? N 3 (h) ?? .<label>(61)</label></formula><p>Now defining,?</p><formula xml:id="formula_78">n = W 4 ? (W 3?n + b 2 ) ,<label>(62)</label></formula><p>we obtain from <ref type="formula" target="#formula_0">(61)</ref> and (59) that,</p><formula xml:id="formula_79">o n ?? n ?? + 2 * Lip(o) n?1 ?=0 Lip(f ) ? .<label>(63)</label></formula><p>Next, we introduce the notation,</p><formula xml:id="formula_80">z n = ? (W 1?n?1 + V 1 u n + b 1 ) ,? n = ? W 1zn .<label>(64)</label></formula><p>From <ref type="formula" target="#formula_9">(57)</ref>, we see thatz</p><formula xml:id="formula_81">n = W 2zn ,? n =W 2?n<label>(65)</label></formula><p>Thus from <ref type="formula" target="#formula_7">(65)</ref> and <ref type="formula" target="#formula_2">(63)</ref>, we hav?</p><formula xml:id="formula_82">? n = W 4 ? (W 3 W 2?n + b 2 ) , = W 4 ? W 3 W 2 ? W 1 W 2zn + b 2 .<label>(66)</label></formula><p>Define the function R :</p><formula xml:id="formula_83">R d h ? R du ? R do by, R(z) = W 4 ? W 3 W 2 ? W 1 W 2 z + b 2 .<label>(67)</label></formula><p>The function, defined above, is clearly Lipschitz continuous. We can apply the universal approximation theorem for tanh neural networks to find, for any given tolerance? , weight matrices W 5 ? R d3?d4 , W 6 ? R do?d3 , V 2 ? R d3?du and bias vector b 3 ? R d3 such that the following holds,</p><formula xml:id="formula_84">max max( z )&lt;R * R(z) ? W 6 ?(W 5 z + b 3 ) ?? .<label>(68)</label></formula><p>Denote? n = W 6 ?(W 5zn + b 3 ), then from <ref type="formula" target="#formula_7">(68)</ref> and <ref type="formula" target="#formula_7">(66)</ref>, we obtain that ? n ?? n ?? .</p><p>Combining this estimate with (63) yields,</p><formula xml:id="formula_85">o n ?? n ?? +? + 2 * Lip(o) n?1 ?=0 Lip(f ) ? .<label>(69)</label></formula><p>Now, we collect all ingredients to define the LEM that can approximate the dynamical system (8).</p><p>To this end, we define hidden states z n , y n ? R 2d h as</p><formula xml:id="formula_86">z n = [z n ,? n ] , y n = [? n ,? n ] ,</formula><p>withz n ,? n ,? n ,? n ? R d h . These hidden states are evolved by the dynamical system,</p><formula xml:id="formula_87">z ? n = ? W 1W2 0 0 0 y ? n?1 + [V 1 u n , 0] ? + [b 1 , 0] ? , y ? n = ? W 1 W 2 0 W 5 0 z ? n + [0, 0] ? + [0, b 3 ] ?<label>(70)</label></formula><p>and the output state is calculated by,</p><formula xml:id="formula_88">? ? n = [0, W 6 ]y ? n .<label>(71)</label></formula><p>Finally, we can recast the dynamical system (70), (71) as a LEM of the form (3) for the hidden states y n , z n , defined in (70), with the following parameters, Now, define the hidden states? n ,z n ? R dy for all 1 ? n ? N by the LEM (3) with the following parameters,</p><formula xml:id="formula_89">?t = 1, d y = 2d h , W 1 = W 2 = V 1 = V 2 = 0 b 1 = b 2 = b ? , W z = W 1W2 0 0 0 , V z = [V 1 , 0], b z = [b 1 , 0] W y = W 1 W 2 0 W 5 0 , V y = 0, b z = [0, b 3 ]. W y = [0, W 6 ].<label>(72)</label></formula><formula xml:id="formula_90">Here, b ? ? R d h is defined as b ? = [b ? , b ? , . . . , . . . , b ? ], with 1 &lt;&lt; b ? is such that |1 ??(b ? )| ? ?.<label>(73)</label></formula><p>The nature of the sigmoid function guarantees the existence of such a b ? for any ?. As ? decays exponentially fast, we set it to 0 in the following for notational simplicity.</p><p>It is straightforward to verify that the output state of the LEM (3) with parameters given in <ref type="formula" target="#formula_1">(72)</ref> is ? n =? n . Therefore, from (69) and by setting? &lt; 3 ,? &lt; 3 and * &lt; 6Lip(o)</p><formula xml:id="formula_91">N ?1 ?=0 Lip(f ) ? ,</formula><p>we prove the desired bound (9). E.5 PROOF OF PROPOSITION 4.5</p><p>Proof. The proof of this proposition is based heavily on the proof of Proposition 4.4. Hence, we will highlight the main points of difference. and with the same weights and biases, one can approximate the identity function?(h, c, u) = c with the tanh neural network,N g (c) =W 2 ? W 1 c ,</p><formula xml:id="formula_92">(82) such that max h , c , u &lt;R * ?(h, c, u) ? N g (c) ? * .<label>(83)</label></formula><p>Next, we define the following dynamical system,</p><formula xml:id="formula_93">z n = W f 3 ? W f 1? n?1 + W f 2? n?1 + V f 1 u n + b f 1 , z n =W 2 ? W 1?n?1 , y n = (1 ? ? )? n?1 + ? W g 3 ? (W g 1? n + W g 2z n + V g 1 u n + b g 1 ) , y n =W 2 ? W 1?n ,<label>(84)</label></formula><p>with hidden states? n ,z n ,? n ,? n ? R d h and with initial states? 0 =z 0 =? 0 =? 0 = 0.</p><p>We derive the following bounds, <ref type="formula" target="#formula_0">(81)</ref>, <ref type="formula" target="#formula_3">(84))</ref>,</p><formula xml:id="formula_94">? n ?? n = f (? n?1 , ? n?1 , u n ) ? W f 3 ? W f 1? n?1 + W f 2? n?1 + V f 1 u n + b f 1 ? f (? n?1 , ? n?1 , u n ) ? f (? n?1 ,? n?1 , u n ) , + f (? n?1 ,? n?1 , u n ) ? W f 3 ? W f 1? n?1 + W f 2? n?1 + V f 1 u n + b f 1 ? Lip(f ) ? n?1 ?? n?1 + 2 ? n?1 ?? n?1 + ? n?1 ?? n?1 + * (by (79)) ? Lip(f ) ? n?1 ?? n?1 + ? n?1 ?? n?1 + (1 + 2Lip(f )) * (by</formula><formula xml:id="formula_95">and ? n ?? n = (1 ? ? )(? n?1 ?? n?1 ) + ? G(? n , ? n?1 , u n ) ? W g 3 ? (W g 2z n + W g 1? n + V g 1 u n + b g 1 ) ? ? n?1 ?? n?1 + ? G(? n , ? n?1 , u n ) ? G(? n ,z n , u n ) + ? G(? n ,z n , u n ) ? W g</formula><p>3 ? (W g 2z n + W g 1? n + V g 1 u n + b g 1 ) ? ? n?1 ?? n?1 ) + ? Lip(G) ? n ?? n + z n ?? n?1 + ? n?1 ?? n?1 + ? * , ? (1 + ? Lip(G))(1 + Lip(f )) ? n?1 ?? n?1 + ? Lip(G)Lip(f ) ? n?1 ?? n?1 + ? (1 + Lip(G)(2 + 2Lip(f ))) * , where the last inequality follows by using the previous inequality together with (84) and (83).</p><p>As ? &lt; 1, it is easy to see from <ref type="formula" target="#formula_9">(77)</ref> that Lip(G) &lt; Lip(g) + 2 ? . Therefore, the last inequality reduces to, ? n ?? n ? (3 + ? Lip(g))(1 + Lip(f )) ? n?1 ?? n?1 + (2 + ? Lip(g))Lip(f ) ? n?1 ?? n?1 + (? + (2 + ? Lip(g))(2 + 2Lip(f ))) * .</p><p>Adding we obtain, ? n ?? n + ? n ?? n ? C * ? n?1 ?? n?1 + ? n?1 ?? n?1 + D * * ,</p><p>where, C * = max{(3 + Lip(g))Lip(f ), Lip(f )(3 + Lip(g))(1 + Lip(f ))}, D * = 1 + (2 + Lip(g))(2 + 2Lip(f )).</p><p>Iterating over n leads to the bound, ? n ?? n + ? n ?? n ? * D * n?1 ?=0 (C * ) ? .</p><p>Here, Lip(f ), Lip(g) are the Lipschitz constants of the functions f , g on the compact set {(h, c, u) ? R d h ?d h ?du : h , c , u &lt; R * }. Note that one can readily prove using the zero values of initial states, the bounds (81), (83) and the assumption ? n , ? n , u n &lt; R, that ? n , z n , ? n , ? n &lt; R * = 2R.</p><p>Using the definition of the output function (11) and the bound (87) that,</p><formula xml:id="formula_99">o n ? o(? n ) ? W c * D * n?1 ?=0 (C * ) ? .<label>(88)</label></formula><p>Defining the dynamical system,</p><formula xml:id="formula_100">z * n = ? W f 1W 2?n?1 + W f 2 W g 3 y * n?1 + V f 1 u n + b f 1 z n = ? W 1 W g 3 y * n?1 y * n = (1 ? ? )y * n?1 + ? ? W g 1 W f 3 z * n + W g 2W 2zn + V g 1 u n + b g 1 , y n = ? W 1 W f 3 z * n .<label>(89)</label></formula><p>By multiplying suitable matrices to <ref type="formula" target="#formula_3">(84)</ref>, we obtain that, z n = W f 3 z * n ,z n =W 2zn ,? n = W g 3 y * n ,? n =W 2?n .</p><p>(90) Finally, in addition to b ? defined in (58), for any given ? ? (0, 1], we introduce b ? ? R defined b? ?(b ? ) = ?.</p><p>(91) The existence of a unique b ? follows from the fact that the sigmoid function? is monotone. Next, we define the two vectors</p><formula xml:id="formula_101">b ? , b ? ? R 2d h as b i ? = b ? , ? 1 ? i ? 2d h , b i ? = b ? , ? 1 ? i ? d h , b i ? = b ? , ? d h + 1 ? i ? 2d h .<label>(92)</label></formula><p>We are now in a position to define the LEM of form (3), which will approximate the two-scale dynamical system (10). To this end, we define the hidden states z n , y n ? R 2d h such that z n = [z * n ,z n ] and y n = [y * n ,? n ]. The parameters for the corresponding LEM of form (3) given by,</p><formula xml:id="formula_102">?t = 1, d y = 2d h W 1 = W 2 = V 1 = V 2 ? 0, b 1 = b ? , b 2 = b ? , W z = W f 2 W g 3 W f 1W 2 W 1 W g 3 0 , V z = [V f 1 0], b z = [b f 1 , 0], W y = W g 1 W f 3 W g 2W 2 W 1 W f 3 0 , V z = [V g 1 0], b z = [b g 1 , 0],<label>(93)</label></formula><p>and with following parameters defining the output states,</p><formula xml:id="formula_103">W y = [W c W g 3 0] ,<label>(94)</label></formula><p>yields an output state ? n = W y y n .</p><p>It is straightforward to observe that ? n ? o(? n ). Hence, the desired bound (11) follows from (87) by choosing,</p><formula xml:id="formula_104">* = D * N ?1 ?=0 (C * ) ? .</formula><p>The proof of proposition 4.5 can be readily extended to prove the following proposition about a general r-scale dynamical system of the form, ? 1 n = ? 1 f 1 (? 1 n?1 , ? 2 n?1 , . . . , ? r n?1 u n ), ? 2 n = ? 2 f 2 (? 1 n?1 , ? 2 n?1 , . . . , ? r n?1 u n ), ? r n = ? r f r (? 1 n?1 , ? 2 n?1 , . . . , ? r n?1 u n ), o n = o(? 1 n , ? 2 n , . . . , ? r n ).</p><p>Here, ? 1 ? ? 2 . . . . . . ? ? r ? 1, with r &gt; 1, are the r-time scales of the dynamical system (95). We assume that the underlying maps f 1,2,...,r are Lipschitz continuous. We can prove the following proposition, Proposition E.4. For all 1 ? n ? N , let ? 1,2,...,r n , o n be given by the r-scale dynamical system (95) with input signal u n . Under the assumption that there exists a R &gt; 0 such that max{ ? 1 n , |? 2 n , . . . , |? r n , u n } &lt; R, for all 1 ? n ? N , then for any given &gt; 0, there exists a LEM of the form (3), with hidden states y n , z n and output state ? n with ? n = Wy n such that the following holds, o n ? ? n ? , ?1 ? n ? N.</p><p>Moreover, the weights, biases and size (number of neurons) of the underlying LEM (3) are independent of the time-scales ? 1,2,...,r .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F LEMS EMULATE HETEROGENEOUS MULTISCALE METHODS FOR ODES</head><p>Following <ref type="bibr" target="#b24">Kuehn (2015)</ref>, we consider the following prototypical example of a fast-slow system of ordinary differential equations,</p><formula xml:id="formula_107">? (t) = 1 ? (f (?) ? ?) , ? (t) = g(?, ?).<label>(97)</label></formula><p>Here ?, ? ? R m are the fast and slow variables respectively and 0 &lt; ? &lt;&lt; 1 is a small parameter. Note that we have rescaled time and are interested in the dynamics of the slow variable ?(t) in the time interval [0, T ].</p><p>A naive time-stepping numerical scheme for (97) requires a time step size ?t ? O(? ). Thus, the computation will entail time updates N ? O(1/? ). Hence, one needs a multiscale ODE solver to approximate the solutions of the system (97). One such popular ODE solver can be derived by using the Heterogenous multiscale method (HMM); see <ref type="bibr" target="#b24">Kuehn (2015)</ref> and references therein. This in turns, requires using two time stepping schemes, a macro solver for the slow variable, with a time step ?t of the form, ? n = ? n?1 +?tg(? n , ? n?1 ).</p><p>Here, the time step?t &lt; 1 is independent of the small parameter ? .</p><p>Moreover, the fast variable is updated using a micro solver of the form,</p><formula xml:id="formula_109">? (k) n?1 = ? (k?1) n?1 ? ?t(f (? n?1 ) ? ? (k?1) n?1 ), 1 ? k ? K. ? n = ? K n?1 , ? (0) n?1 = ? n?1 .<label>(99)</label></formula><p>Note that the micro time step size ?t and the number of micro time steps K are assumed to independent of the small parameter ? .</p><p>It is shown in <ref type="bibr" target="#b24">Kuehn (2015)</ref> (Chapter 10.8) that for any given small tolerance &gt; 0, one can choose a macro time step?t, a micro time step ?t, the number K of micro time steps, the number N of macro time steps, independent of ? , such that the discrete states ? n approximate the slow-variable ?(t n ) (with t n = n?t) of the fast-slow system (97) to the desired accuracy of .</p><p>Our aim is to show that we can construct a LEM of the form (3) such that the states ? n , ? n , defined in (98), (99) can be approximated to arbitrary accuracy. By combining this with the accuracy of HMM, we will prove that LEMs can approximate the solutions of the fast-slow system (97) to desired accuracy, independent of the small parameter ? in (97).</p><p>Proposition F.1. Let ? n , ? n ? R m , for 1 ? n ? N , be the states defined by the HMM dynamical system (98), (99). For any given &gt; 0, there exists a LEM of the form (3) with hidden states [z n , y n ], where z n , y n ? R dm and output states ? h n , ? c n such that the following holds, max ? n ? ? h n , ? n ? ? c n ? , ?1 ? n ? N.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Results on the very long adding problem for LEM, coRNN, DTRIV? (Casado, 2019), FastGRNN (Kusupati et al., 2018), LSTM and LSTM with chrono initialization (Tallec &amp; Ollivier, 2018) based on three very long sequence lengths N , i.e., N = 2000, N = 5000 and N = 10000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Sensitivity study on hyperparameter ?t in (3) using the EigenWorms experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Average (over ten different initializations each) test mean-square error on the adding problem of LEM for different sequence lengths N , where the hyperparameter ?t of LEM (3) is fixed to ?t = 1/ ? N .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Histogram of (?t n ) i and (?t n ) i for all n = 1, . . . , N and i = 1, . . . , d of LEM (3) after training on the Google12 data set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Lower clipping value for ?t n and ?t n</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Average (and standard deviation of) test accuracies of 5 runs each for LEM on Google12, where ?t n and ?t n in (3) are clipped to the ranges [ 1 2 i , 1] for i = 0, . . . , 7 during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Histogram of (?t n ) i and (?t n ) i for all n = 1, . . . , N and i = 1, . . . , d of LEM (3) after training on the sMNIST data set B.3 ON GRADIENT-STABLE INITIALIZATION.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>F</head><label></label><figDesc>, with d y = 1, d z = 3 and the variables y = y modeling the voltage and z = (z 1 , z 2 , z 3 ) modeling the concentration of Potassium activation, Sodium activation and Sodium inactivation channels.The exact form of the different functions in (13) for the Hodgkin-Huxley equations is given by, F z (y) = (? 1 (y), ? 2 (y), ? 3 (y)) , G z (y) = (? 1 (y) + ? 1 (y), ? 2 (y) + ? 2 (y), ? 3 (y) + ? 3 (y)) y (z, t) = u(t) + z 4 1 + z 3 2 z 3 , H(y) = c 1 (? ? y) + c 2 (? ? y), G y (y) = c 3 ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell>Model</cell><cell></cell><cell>MNIST</cell><cell></cell><cell></cell><cell>CIFAR-10</cell></row><row><cell></cell><cell cols="5">sMNIST psMNIST # units / M nCIFAR-10 # units / M</cell></row><row><cell>GRU</cell><cell>99.1%</cell><cell>94.1%</cell><cell cols="2">256 / 201k 43.8%  *</cell><cell>128 / 88k</cell></row><row><cell>LSTM</cell><cell>98.9%</cell><cell>92.9%</cell><cell cols="2">256 / 267k 11.6%</cell><cell>128 / 116k</cell></row><row><cell>chrono-LSTM</cell><cell>98.9%  *</cell><cell>94.6%  *</cell><cell>128 / 68k</cell><cell>55.9%  *</cell><cell>128 / 116k</cell></row><row><cell cols="2">anti.sym. RNN 98.0%</cell><cell>95.8%</cell><cell>128 / 10k</cell><cell>48.3%</cell><cell>256 / 36k</cell></row><row><cell cols="2">Lipschitz RNN 99.4%</cell><cell>96.3%</cell><cell>128 / 34k</cell><cell>57.4%</cell><cell>128 / 46k</cell></row><row><cell>expRNN</cell><cell>98.4%</cell><cell>96.2%</cell><cell>360 / 69k</cell><cell>52.9%  *</cell><cell>360 / 103k</cell></row><row><cell>coRNN</cell><cell>99.3%</cell><cell>96.6%</cell><cell>128/ 34k</cell><cell>59.0%</cell><cell>128 / 46k</cell></row><row><cell>LEM</cell><cell>99.5%</cell><cell>96.6%</cell><cell>128 / 68k</cell><cell>60.5%</cell><cell>128 / 116k</cell></row></table><note>Test accuracies on sMNIST, psMNIST and nCIFAR-10, where M denotes the total number of parameters of the corresponding model. Results of other models are taken from the respective original paper referenced in the main text, except that the results for LSTM are taken from Helfrich et al. (2018), for GRU from Chang et al. (2017) and the results indicated by* are added by us.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Test accuracies on EigenWorms using 5 re-trainings of each best performing network (based on the validation set), where all other results are taken from Rusch &amp; Mishra (2021b) except that the NRDE result is taken from<ref type="bibr" target="#b31">Morrill et al. (2021)</ref> and the results indicated by * are added by us.</figDesc><table><row><cell>Model</cell><cell>test accuracy</cell><cell cols="2"># units # params</cell></row><row><cell cols="3">NRDE expRNN IndRNN (2 layers) LSTM BiLSTM+1d-conv chrono-LSTM coRNN UnICORNN (2 layers) 90.3% ? 3.0% 83.8% ? 3.0% 40.0% ? 10.1% 49.7% ? 4.8% 38.5% ? 10.1%  *  32 32 64 32 22 40.5% ? 7.3%  *  32 82.6 % ? 6.4%  *  32 86.7% ? 3.0% 32 LEM 92.3% ? 1.8% 32</cell><cell>35k 2.8k 1.6k 5.3k 5.8k 5.3k 2.4k 1.5k 5.3k</cell></row></table><note>Following Morrill et al. (2021) and Rusch &amp; Mishra</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Test L 2 error on heart-rate prediction using PPG data. All results are obtained by running the same code and using the same fine-tuning protocol.</figDesc><table><row><cell>Model</cell><cell cols="3">test L 2 error # units # params</cell></row><row><cell>LSTM</cell><cell>9.93</cell><cell>128</cell><cell>67k</cell></row><row><cell>chrono-LSTM</cell><cell>3.31</cell><cell>128</cell><cell>67k</cell></row><row><cell>expRNN</cell><cell>1.63</cell><cell>256</cell><cell>34k</cell></row><row><cell>IndRNN (3 layers)</cell><cell>1.94</cell><cell>128</cell><cell>34k</cell></row><row><cell>coRNN</cell><cell>1.61</cell><cell>128</cell><cell>34k</cell></row><row><cell cols="2">UnICORNN (3 layers) 1.31</cell><cell>128</cell><cell>34k</cell></row><row><cell>LEM</cell><cell>0.85</cell><cell>128</cell><cell>67k</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Test L 2 error on FitzHugh-Nagumo system prediction. All results are obtained by running the same code and using the same fine-tuning protocol.</figDesc><table><row><cell>Model</cell><cell cols="3">error (?10 ?2 ) # units # params</cell></row><row><cell>LSTM</cell><cell>1.2</cell><cell>16</cell><cell>1k</cell></row><row><cell>expRNN</cell><cell>2.3</cell><cell>50</cell><cell>1k</cell></row><row><cell cols="2">LipschitzRNN 1.8</cell><cell>24</cell><cell>1k</cell></row><row><cell>FastGRNN</cell><cell>2.2</cell><cell>34</cell><cell>1k</cell></row><row><cell>coRNN</cell><cell>0.4</cell><cell>24</cell><cell>1k</cell></row><row><cell>LEM</cell><cell>0.2</cell><cell>16</cell><cell>1k</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table><row><cell>Model</cell><cell cols="3">test accuracy # units # params</cell></row><row><cell>tanh-RNN</cell><cell>73.4%</cell><cell>128</cell><cell>27k</cell></row><row><cell cols="2">anti.sym. RNN 90.2%</cell><cell>128</cell><cell>20k</cell></row><row><cell>LSTM</cell><cell>94.9%</cell><cell>128</cell><cell>107k</cell></row><row><cell>GRU</cell><cell>95.2%</cell><cell>128</cell><cell>80k</cell></row><row><cell>FastGRNN</cell><cell>94.8%</cell><cell>128</cell><cell>27k</cell></row><row><cell>expRNN</cell><cell>92.3%</cell><cell>128</cell><cell>19k</cell></row><row><cell>coRNN</cell><cell>94.7%</cell><cell>128</cell><cell>44k</cell></row><row><cell>LEM</cell><cell>95.7%</cell><cell>128</cell><cell>107k</cell></row></table><note>Test accuracies on Google12. All results are obtained by running the same code and using the same fine-tuning protocol.Language modeling: Penn Tree Bank corpus. Language modeling with the widely used small scale Penn Treebank (PTB) corpus</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>). Moreover, the singlelayer results for LEM are better than reported results for multi-layer LSTM models, such as in Gal &amp; Ghahramani (2016) (2-layer LSTM, 1500 units each: 75.2 test perplexity) or Bai et al. (2018) (3-layer LSTM, 700 units each: 78.93 test perplexity).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Test bits-per-character (bpc) on PTB character-level for single layer LEM and other single layer RNN architectures. Other results are taken from the papers cited accordingly in the table, while the results for coRNN are added by us.</figDesc><table><row><cell>Model</cell><cell cols="3">test bpc # units # params</cell></row><row><cell>anti.sym RNN (Erichson et al., 2021)</cell><cell>1.60</cell><cell>1437</cell><cell>1.3M</cell></row><row><cell cols="2">Lipschitz RNN (Erichson et al., 2021) 1.42</cell><cell>764</cell><cell>1.3M</cell></row><row><cell>expRNN (Kerg et al., 2019)</cell><cell>1.51</cell><cell>1437</cell><cell>1.3M</cell></row><row><cell>coRNN</cell><cell>1.46</cell><cell>1024</cell><cell>2.3M</cell></row><row><cell>nnRNN</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Test perplexity on PTB word-level for single layer LEM and other single layer RNN architectures.</figDesc><table><row><cell>Model</cell><cell cols="3">test perplexity # units # params</cell></row><row><cell cols="2">Lipschitz RNN (Erichson et al., 2021) 115.4</cell><cell>160</cell><cell>76k</cell></row><row><cell>FastRNN</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the difficulty of training recurrent neural networks. In Proceedings of the 30th International Conference on Machine Learning, volume 28 of ICML'13, pp. III-1310-III-1318. JMLR.org, 2013. A. F. Queiruga, N. B. Erichson, D. Taylor, and M. W. Mahoney. Continuous-in-depth neural networks. Technical Report Preprint: arXiv:2008.02389, 2020. Alejandro Queiruga, N Benjamin Erichson, Liam Hodgkinson, and Michael W Mahoney. Compressing deep ode-nets using basis function expansions. arXiv preprint arXiv:2106.10820, 2021. Yulia Rubanova, Ricky TQ Chen, and David Duvenaud. Latent odes for irregularly-sampled time series. In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 5320-5330, 2019. T. Konstantin Rusch and Siddhartha Mishra. Coupled oscillatory recurrent neural network (cornn): An accurate and (gradient) stable architecture for learning long time dependencies. In International Conference on Learning Representations, 2021a. T. Konstantin Rusch and Siddhartha Mishra. Unicornn: A recurrent model for learning very long time dependencies. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 9168-9178. PMLR, 2021b. Corentin Tallec and Yann Ollivier. Can recurrent neural networks warp time? In 6th International Conference on Learning Representations, ICLR, 2018. Chang Wei Tan, Christoph Bergmeir, Francois Petitjean, and Geoffrey I Webb. Monash university, uea, ucr time series regression archive. arXiv preprint arXiv:2006.10996, 2020.</figDesc><table><row><cell>Supplementary Material for:</cell></row><row><cell>Long Expressive Memory for Sequence Modeling</cell></row></table><note>Pete Warden. Speech commands: A dataset for limited-vocabulary speech recognition. arXiv preprint arXiv:1804.03209, 2018. Scott Wisdom, Thomas Powers, John Hershey, Jonathan Le Roux, and Les Atlas. Full-capacity unitary recurrent neural networks. In Advances in Neural Information Processing Systems, pp. 4880-4888, 2016.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Rounded hyperparameters of the best performing LEM architecture for each experiment. If no value is given for ?t, it means that ?t is fixed to 1 and no fine-tuning is performed on this hyperparameter.</figDesc><table><row><cell>experiment</cell><cell cols="2">learning rate batch size</cell><cell>?t</cell></row><row><cell cols="2">Adding (N = 10000) 2.6 ? 10 ?3 sMNIST 1.8 ? 10 ?3 psMNIST 3.5 ? 10 ?3 nCIFAR-10 1.8 ? 10 ?3 EigenWorms 2.3 ? 10 ?3 Healthcare 1.56 ? 10 ?3 FitzHugh-Nagumo 9.04 ? 10 ?3 Google12 8.9 ? 10 ?4 PTB character-level 6.6 ? 10 ?4 PTB word-level 6.8 ? 10 ?4</cell><cell>50 128 128 120 8 32 32 100 128 64</cell><cell>2.42 ? 10 ?2 2.1 ? 10 ?1 1.9 ? 10 0 9.5 ? 10 ?1 1.6 ? 10 ?3 1.9 ? 10 ?1 / / / /</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Test L 2 error on FitzHugh-Nagumo system prediction.</figDesc><table><row><cell>Model</cell><cell cols="3">error (?10 ?2 ) # units # params</cell></row><row><cell>LSTM</cell><cell>1.2</cell><cell>16</cell><cell>1k</cell></row><row><cell cols="2">LEM w/o multi-scale 1.1</cell><cell>16</cell><cell>1k</cell></row><row><cell>LEM</cell><cell>0.2</cell><cell>16</cell><cell>1k</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 :</head><label>10</label><figDesc>Test accuracies on EigenWorms using 5 re-trainings of each best performing network (based on the validation set), where we train LSTM and LEM with and without chrono intialization, as well as LEM without chrono initialization but with tuned ?t.</figDesc><table><row><cell>Model test accuracy</cell><cell cols="4"># units # params chrono tuning ?t</cell></row><row><cell cols="2">LSTM 38.5% ? 10.1% 32 LSTM 82.6 % ? 6.4% 32 LEM 32 57.9% ? 7.7% LEM 32 88.2% ? 6.9% LEM 92.3% ? 1.8% 32</cell><cell>5.3k 5.3k 5.3k 5.3k 5.3k</cell><cell>NO YES NO YES NO</cell><cell>/ / NO NO YES</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>Test accuracies on EigenWorms using 5 re-trainings of each best performing network (based on the validation set) for LSTMs with ?t-scaled input and forget gates, as well as LSTMs with sub-sampling routines, baseline LSTM and LEM.</figDesc><table><row><cell>Model</cell><cell>test accuracy</cell><cell cols="2"># units # params</cell></row><row><cell cols="3">t-BPTT LSTM sub-samp. LSTM 69.2% ? 8.3% 57.9% ? 7.0% LSTM 38.5% ? 10.1% 32 32 32 ?t-LSTM v1 32 53.3% ? 8.2% ?t-LSTM v2 32 56.9% ? 6.7% LEM 92.3% ? 1.8% 32</cell><cell>5.3k 5.3k 5.3k 5.3k 5.3k 5.3k</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>in the representation formula(27)and observing that ?t ? 1 and ? n, we obtain.</figDesc><table><row><cell>?X ?X ?1 ?</cell><cell cols="3">? 1 + 1 + (2 + min(1, ?</cell><cell>?</cell><cell>t ))? ?t + ? 1 + (2 + min(1, ?</cell><cell>?</cell><cell>t ))? ?t 2 ,</cell></row><row><cell></cell><cell>? 1 +</cell><cell>? 2</cell><cell>?t,</cell><cell></cell><cell></cell></row><row><cell>With</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">? = 2 (1 + ?) (1 + 3?)</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS.</head><p>The research of TKR and SM was performed under a project that has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No. 770880). NBE and MWM would like to acknowledge IARPA (contract W911NF20C0035), NSF, and ONR for providing partial support of this work. Our conclusions do not necessarily reflect the position or the policy of our sponsors, and no official endorsement should be inferred.</p><p>The authors thank Dr. Ivo Danihelka (DeepMind) for pointing out that the hidden states for LEM satisfy the maximum principles <ref type="formula">(19)</ref>, (20).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As the steps for approximation of a general Lipschitz continuous output map are identical to the corresponding steps in the proof of proposition 4.4 (see the steps from Eqns. (59) to (69)), we will only consider the following linear output map for convenience herein,</p><p>Let R * &gt; R &gt;&gt; 1 and * &lt; , be parameters to be defined later. By the theorem for universal approximation of continuous functions with neural networks with the tanh activation function ? = tanh, given * , there exist weight matrices</p><p>and bias vector b f 1 ? R d1 such that the tanh neural network defined by,</p><p>approximates the underlying function f in the following manner,</p><p>Next, we define the following map,</p><p>for any ? &gt; 0.</p><p>By the universal approximation theorem, given * , there exist weight matrices W g</p><p>and bias vector b g 1 ? R d2 such that the tanh neural network defined by,</p><p>approximates the function G (77) in the following manner,</p><p>Note that the sizes of the neural network N g can be made independent of the small parameter ? by simply taking the sum of the neural networks approximating the functions g and?(h, c, u) = c with tanh neural networks. As neither of these functions depend on the small parameter ? , the sizes of the corresponding neural networks are independent of the small parameter too.</p><p>Next, as in the proof of proposition 4.4, one can readily approximate the identity function f (h, c, u) = h with a tanh neural network of the form,</p><p>Proof. We start by using iteration on the micro solver (99) from k = 1 to k = K to derive the following,</p><p>As ?t &lt; 1, we have that ?t &lt; 1.</p><p>By the universal approximation theorem for tanh neural networks, for any given tolerance * , there exist weight matrices W f 1 ? R d1?m , W f 2 ? R m?d1 and bias vector b f 1 ? R d1 such that the tanh neural network defined by,</p><p>approximates the underlying function f in the following manner,</p><p>Next, we define the following map,</p><p>By the universal approximation theorem, given * , there exist weight matrices W g 1 , W g 2 ? R d2?m , W g 3 ? R m?d2 and bias vector b g 1 ? R d2 such that the tanh neural network defined by,</p><p>approximates the function G (104) in the following manner,</p><p>Next, as in the proof of propositions 4.4 4.5, one can readily approximate the identity function f (h, c) = h with a tanh neural network of the form,</p><p>such that max</p><p>and with the same weights and biases, one can approximate the identity function?(h, c) = c with the Tanh neural network,N</p><p>Then, we define the following dynamical system,</p><p>with hidden states? n ,z n ,? n ,? n ? R m and with initial states? 0 =z 0 =? 0 =? 0 = 0.</p><p>Completely analogously as in the derivation of (87), we can derive the following bound,</p><p>with constant C * = C * (n, Lip(f ), Lip(g)).</p><p>Published as a conference paper at ICLR 2022 Defining the dynamical system,</p><p>By multiplying suitable matrices to <ref type="formula">(113)</ref>, we obtain that,</p><p>In addition to b ? defined in <ref type="formula">(58)</ref>, for ?t ? (0, 1], we introduce b ? ? R defined b?</p><p>Similarly for?t ? (0, 1], we introduce b ? ? R defined b?</p><p>The existence of unique b ? and b ? follows from the fact that the sigmoid function? is monotone.</p><p>Next, we define the two vectors</p><p>We define the LEM of form (3), which will approximate the HMM (98),(99). To this end, we define the hidden states z n , y n ? R 2m such that z n = [z * n ,z * n ] and y n = [y * n ,? * n ]. The parameters for the corresponding LEM of form (3) given by,</p><p>The output states are defined by,</p><p>It is straightforward to observe that ? h n =? n , ? c n =? n . Hence, the desired bound (100) follows from (112) by choosing, * = C * .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unitary evolution recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amar</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1120" to="1128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The uea multivariate time series classification archive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Bagnall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Dau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Large</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bostrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eamonn</forename><surname>Southam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Keogh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00075</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">An empirical evaluation of generic convolutional and recurrent networks for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01271</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiscale deep equilibrium models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Universal approximation bounds for superpositions of a sigmoidal function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Barron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="930" to="945" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Trivializations for gradient-based optimization on manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lezcano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casado</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9154" to="9164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Antisymmetricrnn: A dynamical system view on recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eldad</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dilated recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Witbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="77" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural ordinary differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">K</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6571" to="6583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Symplectic recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lipschitz recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>N Benjamin Erichson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Azencot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Queiruga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mahoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mathematical models of threshold phenomena in the nerve membrane</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Fitzhugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. Math. Biophysics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="257" to="278" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A theoretically grounded application of dropout in recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1019" to="1027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to forget: Continual prediction with lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Felix A Gers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2451" to="2471" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Orthogonal recurrent neural networks with scaled cayley transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Helfrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devin</forename><surname>Willmott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1969" to="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recurrent orthogonal networks and long-memory tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<editor>Maria Florina Balcan and Kilian Q. Weinberger</editor>
		<meeting>The 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2034" to="2042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Using fast weights to deblur old memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Plaut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth annual conference of the cognitive science society</title>
		<meeting>the ninth annual conference of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A quantitative description of membrane current and its application to conduction and excitation in nerve</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Hodgkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Huxley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Physiology</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="500" to="544" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Time adaptive recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil</forename><surname>Kag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Saligrama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="page" from="15149" to="15158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Non-normal recurrent neural network (nnrnn): learning long time dependencies while improving expressivity with transient dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giancarlo</forename><surname>Kerg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Goyette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><forename type="middle">Puelma</forename><surname>Touzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gauthier</forename><surname>Gidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Vorontsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lajoie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="13591" to="13601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Zoneout: Regularizing rnns by randomly preserving hidden activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tegan</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?nos</forename><surname>Kram?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Pezeshki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><forename type="middle">Rosemary</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Pal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Multiple time scale dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Kuehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">191</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fastgrnn: A fast, accurate, stable and tiny kilobyte sized gated recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Kusupati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kush</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manik</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9017" to="9028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Independently recurrent neural network (indrnn): Building a longer and deeper rnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanqing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbo</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5457" to="5466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soon Hoe Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Benjamin Erichson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Hodgkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mahoney</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.04877</idno>
		<title level="m">Noisy recurrent neural networks</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom??</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafi?t</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luk??</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan?ernock?</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eleventh Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Neural rough differential equations for long time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Morrill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristopher</forename><surname>Salvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Kidger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Foster</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021-07" />
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="18" to="24" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
