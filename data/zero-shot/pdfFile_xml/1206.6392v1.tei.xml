<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Boulanger-Lewandowski</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. IRO</orgName>
								<orgName type="institution">Universit? de Montr?al. Montr?al (QC)</orgName>
								<address>
									<postCode>H3C 3J7</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
							<email>bengioy@iro.umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. IRO</orgName>
								<orgName type="institution">Universit? de Montr?al. Montr?al (QC)</orgName>
								<address>
									<postCode>H3C 3J7</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
							<email>vincentp@iro.umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. IRO</orgName>
								<orgName type="institution">Universit? de Montr?al. Montr?al (QC)</orgName>
								<address>
									<postCode>H3C 3J7</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We investigate the problem of modeling symbolic sequences of polyphonic music in a completely general piano-roll representation. We introduce a probabilistic model based on distribution estimators conditioned on a recurrent neural network that is able to discover temporal dependencies in high-dimensional sequences. Our approach outperforms many traditional models of polyphonic music on a variety of realistic datasets. We show how our musical language model can serve as a symbolic prior to improve the accuracy of polyphonic transcription.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Modeling sequences is an important area of machine learning since many naturally occurring phenomena such as music, speech, or human motion are inherently sequential. Complex sequences are non-local in that the impact of a factor localized in time can be delayed by an arbitrarily long time-lag. For example, musical patterns or themes appearing at the beginning of a piece are often repeated towards the end. Recurrent neural networks (RNN) <ref type="bibr" target="#b16">(Rumelhart et al., 1986)</ref> incorporate an internal memory that can, in principle, summarize the entire sequence history. This property makes them well suited to represent long-term dependencies, but it is nevertheless a challenge to train them efficiently by gradient-based optimization <ref type="bibr" target="#b3">(Bengio et al., 1994)</ref>. It was recently shown that training RNNs via Hessian-free (HF) optimization could help reduce these difficulties <ref type="bibr" target="#b11">(Martens &amp; Sutskever, 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Many sequences of interest are over high-dimensional</head><p>Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). objects, such as images in video, short-term spectra in audio music, tuples of notes in musical scores, or words in text. In these cases, simply predicting the expected value at the next time step given the observed values of the previous time steps is not satisfying. With such high-dimensional objects at each time step, the conditional distribution is very often multi-modal, and we would strongly prefer our models of such sequences to predict the conditional distribution of the next time step given previous time steps. For the case of polyphonic music, it is obvious that the occurrence of a particular note at a particular time modifies considerably the probability with which other notes may occur at the same time. In other words, notes appear together in correlated patterns, or simultaneities, that cannot be conveniently described by a typical RNN architecture designed for the multiclass classification task, for example, because enumerating all configurations of the variable to predict would be very expensive. This difficulty motivates energy-based models which allow us to express the negative log-likelihood of a given configuration by an arbitrary energy function, among which the restricted Boltzmann machine (RBM) <ref type="bibr" target="#b18">(Smolensky, 1986)</ref> has become notorious.</p><p>In this context, we wish to exploit the ability of RBMs to represent a complicated distribution for each time step, with parameters that depend on the previous ones, an idea first put forward with the so-called temporal RBM <ref type="bibr" target="#b21">(Taylor et al., 2007;</ref><ref type="bibr" target="#b19">Sutskever &amp; Hinton, 2007)</ref> which is trained via a heuristic procedure. Combining the desirable characteristics of RNNs and RBMs has proven to be non-trivial. The recurrent temporal RBM (RTRBM) <ref type="bibr" target="#b20">(Sutskever et al., 2008</ref>) is a similar model that allows for exact inference and efficient training by contrastive divergence (CD). Despite its simplicity, this model successfully accounts for several interesting sequences. A similar architecture based on the echo state network was also recently developed <ref type="bibr" target="#b17">(Schrauwen &amp; Buesing, 2009)</ref>. In this work, we demonstrate that the RTRBM outperforms many traditional models of polyphonic music, and we introduce a generalization of the RTRBM, called the RNN-RBM, that allows more freedom to describe the temporal dependencies involved.</p><p>More precisely, we will consider sequences of symbolic music, i.e. represented by the explicit timing, pitch, velocity and instrumental information typically contained in a score or a MIDI file rather than more complex, acoustically rich audio signals. Musical models mostly focus on the basic components of western music, harmony and rhythm, and are trained to predict the pattern of notes (simultaneities) to be played together in the next time interval, given the previous ones. Two elements characterize the qualitative performance of a model: temporal dependencies and chord conditional distributions. While most existing models output only monophonic notes along with predefined chords or other reduced-dimensionality representation (e.g. <ref type="bibr" target="#b13">Mozer, 1994;</ref><ref type="bibr" target="#b5">Eck &amp; Schmidhuber, 2002;</ref><ref type="bibr" target="#b14">Paiement et al., 2009)</ref>, we aim to model unconstrained polyphonic music in the piano-roll representation, i.e. as a binary matrix specifying precisely which notes occur at each time step. Despite ignoring dynamics and other score annotations, this task represents a welldefined framework to improve machine learning algorithms and is directly applicable to polyphonic transcription.</p><p>The objective of polyphonic transcription is to determine the underlying notes of a polyphonic audio signal without access to its score. Human experts approach this difficult problem by giving importance to what they expect to hear rather than exclusively to what is present in the actual signal. Most existing transcription algorithms are frame-based and rely exclusively on the audio signal, even though some approaches employ rudimentary musicological constraints (e.g. <ref type="bibr" target="#b10">Li &amp; Wang, 2007)</ref>. It has long been known that, in the same way that natural language models tremendously improve the performance of speech recognition systems, musical language models can improve purely auditive approaches to music information retrieval <ref type="bibr" target="#b4">(Cemgil, 2004)</ref>. However, combining these two sources of information is not trivial, with the result that temporal smoothing with an HMM is often the only post-processing involved in state-of-the-art transcription <ref type="bibr" target="#b13">(Nam et al., 2011)</ref>. We will show how to enrich an arbitrary transcription algorithm (under basic assumptions) to include the advice of an expert trained on symbolic sequences. Using our hybrid approach, we can improve transcription accuracy <ref type="bibr">(Bay et al., 2009</ref>) much more than the popular HMM approach.</p><p>The remainder of the paper is organized as follows. In Sections 2, 3 and 4 we introduce the RBM, the RTRBM and the RNN-RBM architectures. In Section 5 we validate our model on benchmark datasets. In Section 6 we present our results on musical sequences, and we detail our hybrid transcription approach in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Restricted Boltzmann machines</head><p>An RBM is an energy-based model where the joint probability of a given configuration of the visible vector v (inputs) and the hidden vector h is:</p><formula xml:id="formula_0">P (v, h) = exp(?b T v v ? b T h h ? h T W v)/Z<label>(1)</label></formula><p>where b v , b h and W are the model parameters and Z is the usually intractable partition function. When the vector v is given, the hidden units h i are conditionally independent of one another, and vice versa:</p><formula xml:id="formula_1">P (h i = 1|v) = ?(b h + W v) i (2) P (v j = 1|h) = ?(b v + W T h) j (3) where ?(x) ? (1 + e ?x ) ?1 is the element-wise logistic sigmoid function. The marginalized probability of v is related to the free-energy F (v) by P (v) ? e ?F (v) /Z: F (v) = ?b T v v ? i log(1 + e b h +W v ) i<label>(4)</label></formula><p>Inference in RBMs consists of sampling the h i given v (or the v j given h) according to their conditional Bernoulli distribution (eq. 2). Sampling v from the RBM can be performed efficiently by block Gibbs sampling, i.e. by performing k alternating steps of sampling h|v and v|h. The gradient of the negative loglikelihood of an input vector v (l) involves two opposing terms, called the positive and negative phase:</p><formula xml:id="formula_2">?(? log P (v (l) )) ?? = ?F (v (l) ) ?? ? ?(? log Z) ?? (5) where ? ? {b v , b h , W }.</formula><p>The second term can be estimated by a single sample v (l) * obtained from a k-step Gibbs chain starting at v (l) :</p><formula xml:id="formula_3">?(? log P (v (l) )) ?? ?F (v (l) ) ?? ? ?F (v (l) * ) ?? .<label>(6)</label></formula><p>resulting in the well-known contrastive divergence (CD k ) algorithm <ref type="bibr" target="#b6">(Hinton, 2002)</ref>.</p><p>The neural autoregressive distribution estimator (NADE) <ref type="bibr" target="#b8">(Larochelle &amp; Murray, 2011</ref>) is a tractable model inspired by the RBM and specializing (with tying constraints) an earlier model for the joint distribution of high-dimensional variables <ref type="bibr" target="#b2">(Bengio &amp; Bengio, 2000)</ref>. NADE is similar to a fully visible sigmoid belief network in that the conditional probability distribution of a visible unit v j is expressed as a nonlinear function of v k , ?k &lt; j. In the following discussion, one can substitute RBMs with NADEs by replacing equation (6) with the exact gradient defined in <ref type="bibr" target="#b8">(Larochelle &amp; Murray, 2011)</ref> where the biases are set to</p><formula xml:id="formula_4">b = v (t) b , c = v (t)</formula><p>h . The advantages of a tractable distribution estimator will become obvious when used as part of sequential models.  It is obvious that for the diverse collection, each sample has some room for additional melody notes with probabilities depending on the harmonic context (grey), whereas for JSB chorales, the simultaneities are taken from a more restricted pool and the samples are more clear-cut. This mechanism makes sense musically and the fact that RBMs can adapt to various styles will be useful for the following.</p><formula xml:id="formula_5">G#7 Csus4 G7 G A6 / E C C Dm C / G E G7 G#7 G#dim Am C0 C1 C2 C3 C4 C5 C6 C7 E C# D Am A / C# E / B C Cm</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The RTRBM</head><p>The RTRBM <ref type="bibr" target="#b20">(Sutskever et al., 2008</ref>) is a sequence of conditional RBMs (one at each time step) whose</p><formula xml:id="formula_6">parameters b (t) v , b (t)</formula><p>h , W (t) are time-dependent and depend on the sequence history at time t, denoted A (t) ? {v (? ) ,? (? ) |? &lt; t} where? (t) is the mean-field value of h (t) . Its graphical structure is depicted in <ref type="figure" target="#fig_2">Figure 2</ref>(a). The RTRBM is formally defined by its joint probability distribution:</p><formula xml:id="formula_7">P ({v (t) , h (t) }) = T t=1 P (v (t) , h (t) |A (t) )<label>(7)</label></formula><p>where P (v (t) , h (t) |A (t) ) is the joint probability (eq. 1) of the t th RBM whose parameters are defined below (eq. 8 and 9).</p><p>While all the parameters of the RBMs can depend on the previous time steps, we will consider the case where only the biases depend</p><formula xml:id="formula_8">on? (t?1) : b (t) h = b h + W ? (t?1) (8) b (t) v = b v + W ? (t?1)<label>(9)</label></formula><p>which gives the RTRBM six parameters:</p><formula xml:id="formula_9">W, b v , b h , W , W ,? (0) .</formula><p>The general case is derived in a similar manner.</p><p>While the hidden units h (t) are binary during inference and sampling, it is the mean-field value? (t) that is transmitted to its successors (see eq. 10). This important distinction makes exact inference of the? (t) very easy and improves the efficiency of training <ref type="bibr" target="#b20">(Sutskever et al., 2008)</ref>:</p><formula xml:id="formula_10">h (t) = ?(W v (t) + b (t) h ) = ?(W v (t) + W ? (t?1) + b h )<label>(10</label></formula><p>) is obtained directly from equations <ref type="formula">(2)</ref> and <ref type="formula">(8)</ref>. Note that equation <ref type="formula" target="#formula_0">(10)</ref> is exactly the defining equation of a single-layer RNN with hidden units? <ref type="bibr">(t)</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The RNN-RBM</head><p>The RTRBM can be understood as a sequence of conditional RBMs whose parameters are the output of a deterministic RNN, with the constraint that the hidden units must describe the conditional distributions and convey temporal information. This constraint can be lifted by combining a full RNN with distinct hidden units? <ref type="bibr">(t)</ref> with the RTRBM graphical model as shown in <ref type="figure" target="#fig_2">Figure 2</ref> <ref type="bibr">(b)</ref>. We call this model the RNN-RBM. The joint probability distribution of the RNN-RBM is also given by equation <ref type="formula" target="#formula_7">(7)</ref>, but with? (t) defined arbitrarily, here as per equation <ref type="formula" target="#formula_0">(11)</ref>.</p><p>For simplicity, we consider the RBM parameters to be W, b</p><formula xml:id="formula_11">(t) v , b (t)</formula><p>h (i.e. only the biases are variable) and a single-layer RNN (bottom portion of <ref type="figure" target="#fig_2">Fig. 2</ref> hidden units? <ref type="bibr">(t)</ref> are only connected to their direct predecessor? (t?1) and to v (t) by the relation:</p><formula xml:id="formula_12">(b)) whose v (2) v (T) h (2) h (T) ... ... h (0) h (1) W W' b h (1) bv (1) W" bv (2) v (1) b h (2) b h (T) bv (T) (a) RTRBM v (2) v (T) h (2) h (T) ... ... h (1) W W' b h (1) W" bv (1) bv (2) bv (T) v (1) b h (2) b h (T) h (2) h (T) ... h (0) h (1) W3 W 2 (b) RNN-RBM</formula><formula xml:id="formula_13">h (t) = ?(W 2 v (t) + W 3? (t?1) + b?).<label>(11)</label></formula><p>The RBM portion of the RNN-RBM (upper portion of <ref type="figure" target="#fig_2">Fig. 2(b)</ref>) is otherwise exactly the same as its RTRBM counterpart. This gives the single-layer RNN-RBM nine parameters:</p><formula xml:id="formula_14">W, b v , b h , W , W ,? (0) , W 2 , W 3 , b?.</formula><p>The training algorithm is slightly different than for the RTRBM since the mean-field values of the h (t) are now distinct from? <ref type="bibr">(t)</ref> . An iteration of training is based on the following general scheme:</p><p>1. Propagate the current values of the hidden unit? h (t) in the RNN portion of the graph using (11), 2. Calculate the RBM parameters that depend on th? h (t) (eq. 8 and 9) and generate the negative particles v (t) * using k-step block Gibbs sampling, 3. Use CD k to estimate the log-likelihood gradient (eq. 6) with respect to W , b This procedure can be adapted to any RNN architecture and conditional distribution estimator assuming the RNN provides the estimator's parameters (step 2) and can be trained based on a stochastic gradi-ent signal on those parameters (obtained in step 3). The RNN-NADE, obtained by substituting NADEs for RBMs, allows for exact gradient computation.</p><p>Note that the single-layer RNN-RBM is a generalization of the RTRBM and reduces to this simpler model by setting W 2 = W , W 3 = W and b? = b h in equations <ref type="formula" target="#formula_0">(10)</ref> and <ref type="formula" target="#formula_0">(11)</ref>. The RTRBM was not gaining computationally from sharing these connections, hence untying them does not make it slower. In practice, the ability to distinguish between the number of hidden units h and? allows to scale RBMs to several hundred hidden units while keeping the RNNs to their (typically smaller) optimal size, improving performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Initialization strategies</head><p>Initialization strategies based on unsupervised pretraining of each layer have been shown to be important both for supervised and unsupervised training of deep architectures <ref type="bibr" target="#b1">(Bengio, 2009)</ref>. A recurrent network corresponds to a very deep architecture when unfolded in time, and indeed we find that pretraining can clearly affect the overall performance of both the RTRBM and the RNN-RBM. To ensure the quality of the learned weight matrices, we found that initializing the W , b v and b h parameters from a trained RBM yields less noisy filters. The hidden-to-bias weights W , W can then be initialized to small random values, such that the sequential model will initially behave like independent RBMs, eventually departing from that state.</p><p>In order to capture better temporal dependencies, we initialize the W 2 , W 3 , b?, W , b v ,? (0) parameters of the RNN-RBM from an RNN trained with the crossentropy cost:</p><formula xml:id="formula_15">L({v (t) }) = 1 T T t=1 nv j=1 ?v (t) j log y (t) j ?(1?v (t) j ) log(1?y (t) j ) (12) where y (t) = ?(b (t) v</formula><p>) and equations <ref type="formula" target="#formula_8">(9)</ref> and <ref type="formula" target="#formula_0">(11)</ref> hold. This deterministic objective allows the use of a secondorder optimization method for pretraining of the RNN. Note that the RTRBM could use this strategy to initialize W, W , b v , b h , W ,? (0) , but in practice we have found the initialization from an RBM more important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Details of the BPTT algorithm</head><p>Suppose we want to minimize the negative loglikelihood cost C ? ? log P ({v (t) }). The gradient of C with respect to the parameters of the conditional RBMs can be estimated by CD using equations <ref type="formula" target="#formula_1">(4)</ref> and <ref type="formula" target="#formula_3">(6)</ref>: ?C</p><formula xml:id="formula_16">?b (t) v v (t) * ? v (t)<label>(13)</label></formula><formula xml:id="formula_17">?C ?W T t=1 ?(W v (t) * ?b (t) h )v (t) * T ??(W v (t) ?b (t) h )v (t)T (14) ?C ?b (t) h ?(W v (t) * ? b (t) h ) ? ?(W v (t) ? b (t) h ).<label>(15)</label></formula><p>The gradient then back-propagates through the hidden-to-bias parameters (eq. 8 and 9):</p><formula xml:id="formula_18">?C ?W = T t=1 ?C ?b (t) h? (t?1)T (16) ?C ?W = T t=1 ?C ?b (t) v? (t?1)T (17) ?C ?b h = T t=1 ?C ?b (t) h and ?C ?b v = T t=1 ?C ?b (t) v .<label>(18)</label></formula><p>For the single-layer RNN-RBM, the BPTT recurrence relation follows from <ref type="formula" target="#formula_0">(11)</ref>:</p><formula xml:id="formula_19">?C ?? (t) = W 3 ?C ?? (t+1)? (t+1) (1 ?? (t+1) ) +W ?C ?b (t+1) h + W ?C ?b (t+1) v<label>(19)</label></formula><p>for 0 ? t &lt; T (? (0) being a parameter of the model) and ?C/?? (T ) = 0. Formulas for the remaining RNN-RBM parameters are:</p><formula xml:id="formula_20">?C ?b? = T t=1 ?C ?? (t)? (t) (1 ?? (t) )<label>(20)</label></formula><formula xml:id="formula_21">?C ?W 3 = T t=1 ?C ?? (t)? (t) (1 ?? (t) )? (t?1)T (21) ?C ?W 2 = T t=1 ?C ?? (t)? (t) (1 ?? (t) )v (t)T .<label>(22)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Baseline experiments</head><p>In this section, we compare the performance of the RTRBM with the RNN-RBM on two baseline datasets: bouncing balls videos and motion capture data <ref type="bibr" target="#b20">(Sutskever et al., 2008)</ref>. We use the mean framelevel squared prediction error as a basis of comparison. The prediction of the t th conditional RBM is performed by 50 steps of block Gibbs sampling starting at v (t?1) and hoping to reconstruct v (t) optimally.</p><p>The bouncing ball videos dataset 1 is based on a simulation of balls bouncing in a box <ref type="bibr">(Sutskever &amp; Hinton,</ref><ref type="bibr">1</ref> www.cs.utoronto.ca/~ilya/code/2008/RTRBM.tar 2007). The generated videos are of length T = 128 and of resolution 15 ? 15 pixels in the [0, 1] interval, which makes binary RBMs (eq. 1) well suited for this task. With up to 300 hidden units and an initial learning rate of 0.01, we obtain a squared prediction error of 2.11 for the RTRBM and 0.96 for the RNN-RBM, i.e. less than half the error. The receptive fields (weights) of the first 48 hidden units h (t) (RNN-RBM) are plotted in <ref type="figure" target="#fig_4">Figure 3</ref>. Localized edge detectors are apparent in nearly all the learned filters. The human motion capture dataset 2 is represented by a sequence of joint angles, translations and rotations of the base of the spine in an exponential-map parameterization <ref type="bibr" target="#b7">(Hsu et al., 2005;</ref><ref type="bibr" target="#b21">Taylor et al., 2007)</ref>. Since the data consists of 49 real values per time step, we use the Gaussian RBM variant <ref type="bibr" target="#b22">(Welling et al., 2005)</ref> for this task. We use up to 450 hidden units and an initial learning rate of 0.001. The mean squared prediction test error is 20.1 for the RTRBM and reduced substantially to 16.2 for the RNN-RBM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Modeling sequences of polyphonic music</head><p>In this section, we show results with main application of interest for this paper: probabilistic modeling of sequences of polyphonic music. We report our experiments on four datasets of varying complexity converted to our input format.</p><p>Piano-midi.de is a classical piano MIDI archive that was split according to <ref type="bibr" target="#b15">Poliner &amp; Ellis (2007)</ref>. Nottingham is a collection of 1200 folk tunes 3 with chords instantiated from the ABC format. MuseData is an electronic library of orchestral and piano classical music from CCARH 4 . JSB chorales refers to the entire corpus of 382 fourpart harmonized chorales by J. S. Bach with the split of <ref type="bibr" target="#b0">Allan &amp; Williams (2005)</ref>.</p><p>Each dataset contains at least 7 hours of polyphonic music and the total duration is approximately 67 hours. The polyphony (number of simultaneous notes) varies from 0 to 15 and the average polyphony is 3.9. We use an input of 88 binary visible units that span the whole range of piano from A0 to C8 and temporally aligned on an integer fraction of the beat (quarter note). Consequently, pieces with different time signatures will not have their measures start at the same interval. Although it is not strictly necessary, learning is facilitated if the sequences are transposed in a common tonality (e.g. C major/minor) as preprocessing.</p><p>In addition to the models previously described, we evaluate the following commonly used methods:</p><p>? The simplest baseline model consists in outputting a Gaussian density centered on the previous frame ? = v (t?1) and learned covariance ?. ? N-grams simulate the evolution of note simultaneities as an (N ? 1) th -order Markov chain. We use add-p or Gaussian smoothing and back-off. ? Note N-grams model each note independently by a binary N-gram, possibly with shared parameters (IID). ? An interesting model for chorales harmonisation <ref type="bibr" target="#b0">(Allan &amp; Williams, 2005)</ref> has been adapted to serve as a generative model. It can only be evaluated on the JSB chorales dataset. ? The 'random fields' approach of <ref type="bibr" target="#b9">Lavrenko &amp; Pickens (2003)</ref> is a type of fully visible sigmoid belief network with learned connectivity. ? Other common methods include Gaussian mixture models (GMM), hidden Markov models (HMM) using GMM indices as their state, and multilayer perceptrons (MLP) with the last n time steps as input.</p><p>The log-likelihood (LL) and expected frame-level accuracy (ACC) (Bay et al., 2009) of the symbolic models are presented in <ref type="table" target="#tab_0">Table 1</ref>. We estimate the partition function of each conditional RBM by 100 runs of annealed importance sampling <ref type="bibr" target="#b16">(Salakhutdinov &amp; Murray, 2008)</ref>. We make a few key observations:</p><p>? The complexity of the dataset, such as the simplistic chord accompaniment of Nottingham and the redundant style of four-part chorales by a single composer, in comparison with diverse piano and orchestral music, is clearly reflected in the obtained log-likelihoods and accuracies. ? N-gram models (optimal N * = 2) perform reasonably well for simple datasets but fail in more realistic settings due to the increased data sparsity. In this case, note N-grams (N * <ref type="figure" target="#fig_0">? [8, 14]</ref>) are a better alternative albeit ignoring harmonic dependencies. This inherent trade-off in traditional polyphonic music models can be addressed robustly by the RNN-based models, that perform better on a range of datasets. ? The harmonisation model of <ref type="bibr" target="#b0">Allan &amp; Williams (2005)</ref>, tailored to the specific style of four-part chorales, requires annotated harmonic symbols and yet performs relatively poorly compared to our best performer. Similarly to the GMM + HMM, this model is penalized by the limited history of the HMM and by the difficulty to generalize to new chord voicings in a principled manner. ? In accordance with earlier results <ref type="bibr" target="#b11">(Martens &amp; Sutskever, 2011)</ref>, the use of HF significantly helps the density estimation and prediction performance of RNNs (eq. 12) which would otherwise perform worse than simpler MLPs. This motivates our strategy of pretraining the RNN layer of an RNN-RBM via HF. ? In addition to the distinct recurrent hidden unit? h (t) that convey temporal information more freely, and the fact that suitable learning rates can be specified differently for the RNN and the RBM parts, pretraining the W 2 , W 3 and b? parameters can have the most impact on the RNN-RBM prediction performance. <ref type="figure" target="#fig_6">Figure 4</ref> clearly demonstrates the importance of pretraining and finetuning the RNN and the additional advantage of using HF. ? Although frame-level NADEs are slightly less powerful than RBMs, their desirable properties make the combined RNN-NADE model the most robust distribution estimator. We believe this is due to their tractable distribution, for two reasons. First, CD may not be ideally suited for conditional RBMs with slowly-mixing Gibbs chains <ref type="bibr" target="#b12">(Mnih et al., 2011)</ref>, a non-issue for exact-gradient models. Secondly, the joint sequential model, and not only the RNN portion, can benefit from second-order optimization as can be seen from the last two rows of <ref type="table" target="#tab_0">Table 1</ref>.   We evaluate our models qualitatively by generating sample sequences, provided on the authors' website 5 , and discussed here. While note correlations are obviously neglected in the simpler models (sequence 2), RBM-based models learned basic harmony rules (sequence 3), melody lines (sequences 4, 8) and local temporal coherence (sequence 5). However, long-term structure and musical meter remain elusive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Polyphonic transcription</head><p>Multiple fundamental frequency (f 0 ) estimation, or polyphonic transcription, consists in estimating the audible note pitches in the signal at 10 ms intervals without tracking note contours. We combine our polyphonic sequence models with the acoustic model of <ref type="bibr" target="#b13">Nam et al. (2011)</ref> in order to demonstrate a practical application of the sequence models. Their model was adapted for multiple instruments, and it can be generalized to any method that can score hypothetical combinations of f 0 for a given time frame.</p><p>At each time frame, the Nam et al. (2011) algorithm outputs independent probabilities that each note is present and reports every note with probability p ? 0.5. To incorporate our symbolic model prediction P s (v (t) |A (t) ), we consider the k most promising f 0 candidates (k = 7) from the acoustic model P a (v (t) ) 5 www-etud.iro.umontreal.ca/~boulanni/icml2012 and jointly evaluate all combinations of M candidates ?M ? k by the following cost function:</p><formula xml:id="formula_22">C = ? log P a (v (t) ) ? ? log P s (v (t) |? (t) )<label>(23)</label></formula><p>where? (t) is the approximate sequence history constructed from the f 0 estimated so far in at least half the audio frames corresponding to each past symbolic time step 6 . This corresponds to a product of experts where the hyperparameter ? is the confidence coefficient of our symbolic predictor. If our algorithm is run on audio signals without preprocessing, tempo tracking must be performed first. Since the symbolic models describe only fixed tonality pieces, a first audio-only pass is needed to transpose the estimated f 0 in the correct tonality. Once the optimal f 0 estimates have been determined, HMM smoothing can still filter out spurious results and enhance onset accuracies.</p><p>Digital audio has been generated for the four datasets and we report in <ref type="figure" target="#fig_7">Figure 5</ref> the frame-level transcription accuracy of the Nam et al. (2011) algorithm, either alone, after HMM smoothing, or using our best performing model as a symbolic prior. We observe an improvement in absolute accuracy between 1.3% and 10% over the HMM approach. It can be seen easily that an HMM with emission probabilities P a (v (t) ) is equivalent to equation (23) with a note 2-gram symbolic model, one time step per audio frame and ? = 1. It is therefore unsurprising that the advantage of our search algorithm decreases when the note N-gram already performs well, e.g. for Piano-midi.de <ref type="table" target="#tab_0">(Table 1)</ref>. However, the HMM allows for a global search of the most likely f 0 (the Viterbi path), whereas our algorithm requires a greedy chronological search, a limitation we are currently working to address. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Piano</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We presented an RNN-based model that can learn harmonic and rhythmic probabilistic rules from polyphonic music scores of varying complexity, substantially better than popular methods in music information retrieval. We showed that different strategies related to the description of temporal dependencies can improve prediction accuracy of such models. While longer-term musical structure remains elusive in our unconstrained representation, our model can immediately serve as a symbolic prior for polyphonic transcription, clearly improving the state of the art in this area.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Mean-field samples of an RBM trained on the Piano-midi (top) and JSB chorales (bottom) datasets. Each column is a sample vector of notes, with a chord label where the analysis is unambiguous.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1</head><label>1</label><figDesc>presents mean-field samples P (v j = 1|h * ), where h * ? P (h), drawn from RBMs trained on a diverse collection of classical piano music (top) and on the four-part chorales by J. S. Bach (bottom), along with chord labels where the analysis is unambiguous.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .v</head><label>2</label><figDesc>Comparison of the graphical structures of (a) the RTRBM and (b) the single-layer RNN-RBM. Single arrows represent a deterministic function, double arrows represent the stochastic hidden-visible connections of an RBM. The upper half of the RNN-RBM is the RBM stage while the lower half is a RNN with hidden units? (t) . The RBM biases b are a linear function of? (t?1) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>h</head><label></label><figDesc>backward through time (BPTT)<ref type="bibr" target="#b16">(Rumelhart et al., 1986)</ref> to obtain the estimated gradient with respect to the RNN parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Receptive fields of 48 hidden units of an RNN-RBM trained on the bouncing balls dataset. Each square shows the input weights of a hidden unit as an image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Effect of SGD and HF pretraining on the RNN-RBM symbolic prediction performance. All strategies except the baseline involve pretraining.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Frame-level transcription accuracy of the Nam et al. (2011) model either alone, after HMM smoothing or with our best performing model as a symbolic prior.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Log-likelihood and expected accuracy for various musical models in the symbolic prediction task. The double line separates frame-level models (above) and models with a temporal component (below).</figDesc><table><row><cell>Model</cell><cell cols="2">Piano-midi.de</cell><cell cols="2">Nottingham</cell><cell cols="2">MuseData</cell><cell cols="2">JSB chorales</cell></row><row><cell></cell><cell>LL</cell><cell>ACC %</cell><cell>LL</cell><cell>ACC %</cell><cell>LL</cell><cell>ACC %</cell><cell>LL</cell><cell>ACC %</cell></row><row><cell>Random</cell><cell>-61.00</cell><cell cols="2">3.35 -61.00</cell><cell cols="2">4.53 -61.00</cell><cell cols="2">3.74 -61.00</cell><cell>4.42</cell></row><row><cell>1-Gram (Add-p)</cell><cell>-27.64</cell><cell>4.85</cell><cell>-5.94</cell><cell cols="2">22.76 -19.03</cell><cell cols="2">6.67 -12.22</cell><cell>16.80</cell></row><row><cell>1-Gram (Gaussian)</cell><cell>-10.79</cell><cell>6.04</cell><cell>-5.30</cell><cell cols="2">21.31 -10.15</cell><cell>7.87</cell><cell>-7.56</cell><cell>17.41</cell></row><row><cell>Note 1-Gram</cell><cell>-11.05</cell><cell cols="2">5.80 -10.25</cell><cell cols="2">19.87 -11.51</cell><cell cols="2">7.72 -11.06</cell><cell>15.25</cell></row><row><cell>Note 1-Gram (IID)</cell><cell>-12.90</cell><cell cols="2">2.51 -16.24</cell><cell cols="2">3.56 -14.06</cell><cell cols="2">2.82 -15.93</cell><cell>3.51</cell></row><row><cell>GMM</cell><cell>-15.84</cell><cell>5.08</cell><cell>-7.87</cell><cell cols="2">22.62 -12.20</cell><cell cols="2">7.37 -11.90</cell><cell>15.84</cell></row><row><cell>RBM</cell><cell>-10.17</cell><cell>5.63</cell><cell>-5.25</cell><cell>5.81</cell><cell>-9.56</cell><cell>8.19</cell><cell>-7.43</cell><cell>4.47</cell></row><row><cell>NADE</cell><cell>-10.28</cell><cell>5.82</cell><cell>-5.48</cell><cell cols="2">22.67 -10.06</cell><cell>7.65</cell><cell>-7.19</cell><cell>17.88</cell></row><row><cell>Previous + Gaussian</cell><cell>-12.48</cell><cell>25.50</cell><cell>-8.41</cell><cell cols="2">55.69 -12.90</cell><cell cols="2">25.93 -19.00</cell><cell>18.36</cell></row><row><cell>N-Gram (Add-p)</cell><cell>-46.04</cell><cell>7.42</cell><cell>-6.50</cell><cell cols="2">63.45 -35.22</cell><cell cols="2">10.47 -29.98</cell><cell>24.20</cell></row><row><cell>N-Gram (Gaussian)</cell><cell>-12.22</cell><cell>10.01</cell><cell>-3.16</cell><cell cols="2">65.97 -10.59</cell><cell>16.15</cell><cell>-9.74</cell><cell>28.79</cell></row><row><cell>Note N-Gram</cell><cell>-7.50</cell><cell>26.80</cell><cell>-4.54</cell><cell>62.49</cell><cell>-7.91</cell><cell cols="2">26.35 -10.26</cell><cell>20.34</cell></row><row><cell>GMM + HMM</cell><cell>-15.30</cell><cell>7.91</cell><cell>-6.17</cell><cell cols="2">59.27 -11.17</cell><cell cols="2">13.93 -11.89</cell><cell>19.24</cell></row><row><cell>(Allan &amp; Williams, 2005)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-9.24</cell><cell>16.32</cell></row><row><cell>(Lavrenko &amp; Pickens, 2003)</cell><cell>-9.05</cell><cell>18.37</cell><cell>-5.44</cell><cell>55.34</cell><cell>-9.87</cell><cell>18.39</cell><cell>-8.78</cell><cell>22.93</cell></row><row><cell>MLP</cell><cell>-8.13</cell><cell>20.29</cell><cell>-4.38</cell><cell>63.46</cell><cell>-7.94</cell><cell>25.68</cell><cell>-8.70</cell><cell>30.41</cell></row><row><cell>RNN</cell><cell>-8.37</cell><cell>19.33</cell><cell>-4.46</cell><cell>62.93</cell><cell>-8.13</cell><cell>23.25</cell><cell>-8.71</cell><cell>28.46</cell></row><row><cell>RNN (HF)</cell><cell>-7.66</cell><cell>23.34</cell><cell>-3.89</cell><cell>66.64</cell><cell>-7.19</cell><cell>30.49</cell><cell>-8.58</cell><cell>29.41</cell></row><row><cell>RTRBM</cell><cell>-7.36</cell><cell>22.99</cell><cell>-2.62</cell><cell>75.01</cell><cell>-6.35</cell><cell>30.85</cell><cell>-6.35</cell><cell>30.17</cell></row><row><cell>RNN-RBM</cell><cell>-7.09</cell><cell>28.92</cell><cell>-2.39</cell><cell>75.40</cell><cell>-6.01</cell><cell>34.02</cell><cell>-6.27</cell><cell>33.12</cell></row><row><cell>RNN-NADE</cell><cell>-7.48</cell><cell>20.69</cell><cell>-2.91</cell><cell>64.95</cell><cell>-6.74</cell><cell>24.91</cell><cell>-5.83</cell><cell>32.11</cell></row><row><cell>RNN-NADE (HF)</cell><cell>-7.05</cell><cell>23.42</cell><cell>-2.31</cell><cell>71.50</cell><cell>-5.60</cell><cell>32.60</cell><cell>-5.56</cell><cell>32.50</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">people.csail.mit.edu/ehsu/work/sig05stf 3 ifdo.ca/~seymour/nottingham/nottingham.html 4 www.musedata.org</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">This can create a 'snowball' effect where accurate baseline transcriptions form accurate? (t) estimates, resulting in more relevant symbolic predictions Ps(v (t) |? (t) ), which in turn improve the final transcription.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank NSERC, CIFAR and the Canada Research Chairs for funding, and Compute Canada/Calcul Qu?bec for computing resources.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Evaluation of multiple-F0 estimation and tracking systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 17</title>
		<editor>Bay, M., Ehmann, A.F., and Downie, J.S</editor>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
	<note>ISMIR</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Learning deep architectures for AI. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modeling high-dimensional discrete data with multi-layer neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 12</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="400" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning longterm dependencies with gradient descent is difficult</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Bayesian music transcription</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Cemgil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>Radboud University Nijmegen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Finding temporal structure in music: Blues improvisation with LSTM recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NNSP</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="747" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Style translation for human motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pulli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Popovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1082" to="1089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The neural autoregressive distribution estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR: W&amp;CP</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Polyphonic music modeling with random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pickens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="120" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pitch detection in polyphonic music using instrument tone models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">481</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning recurrent neural networks with Hessian-free optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 28</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Conditional restricted Boltzmann machines for structured output prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI 27</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A classification-based polyphonic piano transcription approach using learned feature representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Slaney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMIR</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="247" to="280" />
		</imprint>
	</monogr>
	<note>Neural network music composition by prediction</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Probabilistic models for melodic prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Paiement</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1266" to="1274" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A discriminative model for polyphonic piano transcription</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Poliner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P W</forename><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASP</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="154" to="164" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning internal representations by error propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Dist. Proc</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1986" />
			<biblScope unit="page" from="318" to="362" />
		</imprint>
	</monogr>
	<note>ICML 25</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A hierarchy of recurrent networks for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schrauwen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Buesing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Information processing in dynamical systems: Foundations of harmony theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smolensky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Dist. Proc</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1986" />
			<biblScope unit="page" from="194" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning multilevel distributed representations for high-dimensional sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="544" to="551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The recurrent temporal restricted Boltzmann machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 20</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Modeling human motion using binary latent variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 19</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">1345</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exponential family harmoniums with an application to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosen-Zvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 17</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1481" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
