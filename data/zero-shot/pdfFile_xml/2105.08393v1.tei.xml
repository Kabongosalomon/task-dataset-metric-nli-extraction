<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Relation Classification with Entity Type Restriction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengfei</forename><surname>Lyu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanhuan</forename><surname>Chen</surname></persName>
							<email>hchen@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Relation Classification with Entity Type Restriction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Relation classification aims to predict a relation between two entities in a sentence. The existing methods regard all relations as the candidate relations for the two entities. These methods neglect the restrictions on candidate relations by entity types, which leads to some inappropriate relations being candidate relations. In this paper, we propose a novel paradigm, RElation Classification with ENtity Type restriction (RECENT), which exploits entity types to restrict candidate relations. Specially, the mutual restrictions of relations and entity types are formalized and introduced into relation classification. Besides, the proposed paradigm, RECENT, is model-agnostic. Based on two representative models GCN and SpanBERT respectively, RECENT GCN and RECENT SpanBERT are trained in RE-CENT 1 . Experimental results on a standard dataset indicate that RECENT improves the performance of GCN and SpanBERT by 6.9 and 4.4 F1 points, respectively. Especially, RECENT SpanBERT achieves a new state-ofthe-art on TACRED.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Relation classification, a supervised version of relation extraction, aims to predict a relation between two entities in a sentence. Relation classification is an important step to construct knowledge bases from a large number of unstructured texts <ref type="bibr" target="#b11">(Trisedya et al., 2019)</ref>, which benefits many natural language processing applications, such as natural language generation <ref type="bibr" target="#b7">(Kang and Hashimoto, 2020)</ref> and question answering <ref type="bibr" target="#b17">(Zhao et al., 2020)</ref>.</p><p>Recently, the majority of methods make use of various neural network architectures to learn a fixed-size representation for a sentence and its * Corresponding author. 1 Our code is available at https://github.com/ /Saintfe/RECENT.  entities with various language features, such as part of speech (POS), entity types, and dependency trees. Dependency trees that are parsed from sentences are exploited by <ref type="bibr">GCN (Kipf and Welling, 2017)</ref> to model sentences <ref type="bibr" target="#b15">(Zhang et al., 2018;</ref><ref type="bibr" target="#b4">Guo et al., 2019)</ref>. As a sequence of words, a sentence is modeled by LSTM <ref type="bibr" target="#b5">(Hochreiter and Schmidhuber, 1997)</ref> and its entity positions are involved with the attention mechanism <ref type="bibr" target="#b16">(Zhang et al., 2017)</ref>. More recently, pretrained language models <ref type="bibr" target="#b3">(Devlin et al., 2019;</ref><ref type="bibr" target="#b1">Baldini Soares et al., 2019;</ref><ref type="bibr" target="#b6">Joshi et al., 2020)</ref> achieve good performance in relation classification since they are pretrained on massive corpora.</p><p>To recap, these methods utilize an encoder architecture <ref type="bibr" target="#b0">(Badrinarayanan et al., 2017)</ref>   treat relations as labels 2 to be classified. However, in this process, these methods inevitably lose the semantics of relations. Take the mutual restrictions between a relation and entity types as an example.</p><p>In <ref type="figure" target="#fig_0">Figure 1</ref>, the relation who-is-born-when restricts its first entity to be a person and the second one to be a time. Conversely, entity types can also restrict candidate relations in relation classification. As illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>, some inappropriate relations can be discarded from candidate relations by entity type restriction. However, the current methods neglect the restriction of entity types on relations so that some inappropriate relations are regarded as candidate relations, which further hurts their performance. To solve the above problem, a novel paradigm, RElation Classification with ENtity Type restriction (RECENT), is proposed to exploit entity types to restrict candidate relations. As the basis of the paradigm, the mutual restrictions of relations and entity types are formalized. With the entity type restriction, some inappropriate relations are discarded from the candidate relations of a specific pair of entity types, as illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>. A specific classifier with a specific set of candidate relations is individually learned for each pair of entity types ( <ref type="figure" target="#fig_2">Figure 3)</ref>. Therefore, the proposed paradigm, RECENT, can eliminate the interference from inappropriate candidate relations.</p><p>The contributions are summarized as follows:</p><p>? The mutual restrictions of relations and entity types are formalized.</p><p>? A novel paradigm, RECENT, is proposed to 2 Specifically, these meaningful relations are treated as meaningless numbers, such as 0, 1, 2. exploit entity types to restrict candidate relations in relation classification.</p><p>? A new state-of-the-art is achieved on TA-CRED.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Paradigm</head><p>Before introducing the proposed paradigm RE-CENT, the mutual restrictions between a relation and a pair of entities are formalized as the basis of RECENT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Relation Function</head><p>When a binary relation is considered as a function, this relation has two entities as its two arguments. Formally, this relation is formalized as r(s, o), where r denotes the relation and s, o denote the first (subject) entity and the second (object) entity, respectively. The range of this relation contains two discrete values {0, 1}:</p><p>r(s, o) = 1 r holds between s and o, 0 otherwise.</p><p>In a broad sense, the domain of this relation can be any pair of entities. However, when a pair of entities with inappropriate types is fed into a specific relation, the relation can directly return 0, no need to consider the compositional semantics of the relation and the pair of entities. For example, a specific relation who-is-born-when expects the first argument to be a person and the second one to be a time. Therefore, (apple, Steven Jobs) is a pair of inappropriate entities for this relation so that who-is-born-when(apple, Steven Jobs) returns 0 without considering the compositional semantics, since apple may refer to either a kind of fruit or a company (not a person) and Steven Jobs may refer to a famous person (not a time).</p><p>Only when a relation receives a pair of appropriate entities whose types match it, the combination of the relation and the entities might make sense (i.e., the function defined in Eq. 1 may return 1). In this case, it is meaningful to further verify the correctness of the compositional semantics. From this perspective, in a narrow sense, the domain (denoted by D r ) of a relation (r) is defined as follows: <ref type="formula">(2)</ref> where ts and to denote the types of the subject entity (s) and the object entity (o), respectively. S(r) and O(r) are the appropriate types of r on the subject entity (s) and the object entity (o), respectively.</p><formula xml:id="formula_1">D r = {(s, o)|ts ? S(r) and to ? O(r)},</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Entity Type Restriction</head><p>In the previous subsection, the narrow domain of a relation restricts entities whose types need to match the relation. Conversely, given a pair of entities whose types are known, the candidate relations of the entities are also restricted, since the match between relations and entity types is mutual.</p><p>Formally, given a pair of entities (s, o) and their types (ts, to), its candidate relations (denoted by R (ts,to) ) are restricted into a limited set:</p><formula xml:id="formula_2">R (ts,to) = {r ? R|(s, o) ? D r } = {r ? R|ts ? S(r) and to ? O(r)},<label>(3)</label></formula><p>where R denotes all possible relations. When the types (ts, to) of a pair of entities (s, o) are explicitly utilized to restrict its candidate relations, the candidate relations reduce from all possible relations R into a rather smaller set R (ts,to) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Relation Classification</head><p>Unlike traditional methods that classify a sentence and its entities on all candidate relations R (the left part of <ref type="figure" target="#fig_2">Figure 3)</ref>, the proposed paradigm, RECENT learns a specific classifier with smaller and more precise candidate relations for each pair of entity types (the right part of <ref type="figure" target="#fig_2">Figure 3</ref>), based on entity type restriction in the previous subsection.</p><p>The procedure of RECENT is summarized in Algorithm 1. In the learning phase, all sentences are first grouped by types of their entities (line 1). For each group (marked as g) with a specific pair of entity types (ts,to), the candidate relations R (ts,to) for the group g are obtained by aggregating the relations in the group g (line 3). Then, a specific classifier (marked by f g ) that maps sentences and their entities in g to R <ref type="bibr">(ts,to)</ref> , is learned for the group g (line 4). In the prediction phase, given a new sample (se, s, o, ts, to), a group (marked as g ) is matched by the entity types (ts, to) (line 6). Then, the classifier f g learned on the group g is utilized to predict a relation according to the input (se, s, o) (line 7).</p><p>From the 4th line of Algorithm 1, the proposed paradigm RECENT is model-agnostic, which means that RECENT is theoretically compatible with many relation classification models.</p><p>Algorithm 1 RECENT Learning Phase: </p><formula xml:id="formula_3">Input: D = {(se i , s i , o i , ts i , to i , r i )|i = 1, 2, ..., N } where the subscript i indicates the ith sample, se is sentence, s is subject entity, o is object entity, ts is type of subject entity,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>The proposed paradigm RECENT is evaluated on TACRED 3 <ref type="bibr" target="#b16">(Zhang et al., 2017)</ref>. TACRED contains 41 semantic relations and a special no relation over 106,264 sentences. The subject entities in TA-CRED are classified into two types: PERSON and ORGANIZATION while the object entities are categorized into 16 fine-grained types, such as LOCA-TION and TIME. Namely, entity types are known. By convention, the micro-averaged F1 score (abbreviated as F1) is reported on TACRED.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Setup</head><p>Since no relation is a candidate relation of each pair of entity types in TACRED, a binary classifier is first learned to distinguish between 41 semantic relations and no relation. In this way, each pair of entity types reduces one candidate relation (i.e. no relation) in RECENT. If the binary classifier predicts no relation for a pair of entities, then the final relation for them is no relation. Otherwise, their specific semantic relation is further predicted in RECENT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Base Models</head><p>The proposed paradigm RECENT is model-agnostic. Two representative models that are GCN <ref type="bibr" target="#b15">(Zhang et al., 2018)</ref> and SpanBERT <ref type="bibr" target="#b6">(Joshi et al., 2020)</ref> are selected as base models (line 4 in Algorithm 1). For a fair comparison with a base model, all classifiers (including the binary classifier) in RECENT are trained by the base model. The corresponding models in the paper are denoted as RECENT GCN and RECENT SpanBERT .</p><p>Hyperparameters For RECENT GCN , the pathcentric pruning K is set to 1 as GCN <ref type="bibr" target="#b15">(Zhang et al., 2018)</ref>. The learning rates for all classifiers in RECENT GCN are set to 0.3. For RECENT SpanBERT , the learning rates for all classifiers are chosen from {5e-6, 1e-5, 2e-5, 3e-5, 5e-5} as SpanBERT.</p><p>Compared Models Extensive models in relation classification are regarded as comparison models. They include PA-LSTM <ref type="bibr" target="#b16">(Zhang et al., 2017)</ref>, C-GCN <ref type="bibr" target="#b15">(Zhang et al., 2018)</ref>, AGGCN <ref type="bibr" target="#b4">(Guo et al., 2019)</ref>, C-AGGCN <ref type="bibr" target="#b4">(Guo et al., 2019)</ref>, MTB (Baldini Soares et al., 2019), KnowBert <ref type="bibr" target="#b10">(Peters et al., 2019)</ref>, SpanBERT-ALT <ref type="bibr" target="#b9">(Lyu et al., 2020)</ref>, KE-PLER <ref type="bibr" target="#b13">(Wang et al., 2020b)</ref>, K-Adapter <ref type="bibr">(Wang et al., 2020a)</ref>, and LUKE <ref type="bibr" target="#b14">(Yamada et al., 2020)</ref>. To save space, please refer to the original papers of these models for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Results</head><p>The experimental results are presented in <ref type="table" target="#tab_4">Table 1</ref>. RECENT GCN achieves a significant performance increase on the F1 score above its base model GCN. The absolute increase reaches 6.9 from 64.0 to 70.9.</p><p>Model P R F1</p><p>PA-LSTM ? <ref type="bibr" target="#b16">(Zhang et al., 2017)</ref> 65.7 64.5 65.1 C-GCN ? <ref type="bibr" target="#b15">(Zhang et al., 2018)</ref> 69.9 63.3 66.4 AGGCN ? <ref type="bibr" target="#b4">(Guo et al., 2019)</ref> 69.9 60.9 65.1 C-AGGCN ? <ref type="bibr" target="#b4">(Guo et al., 2019)</ref> 71  <ref type="bibr" target="#b10">(Peters et al., 2019)</ref> 71.6 71.4 71.5 KEPLER ?* <ref type="bibr" target="#b13">(Wang et al., 2020b)</ref> 71.5 72.5 72.0 K-Adapter ?* <ref type="bibr">(Wang et al., 2020a)</ref> 70.14 74.04 72.04 LUKE ? <ref type="bibr" target="#b14">(Yamada et al., 2020)</ref> 70.  The main contribution for the F1 increase is the improved precision that greatly increases from 69.8 to 88.3. The great increase in precision, which might result from the restriction on candidate relations by entity types in RECENT, indicates the effectiveness of the proposed paradigm RECENT. Besides, RECENT GCN suppresses the compared models that do not include pretrained language models. Similarly, RECENT SpanBERT overtakes its base model SpanBERT by absolute 4.4 points on F1. The great soar (absolute 20.1 points) on precision contributes the superior F1 of RECENT SpanBERT . Unfortunately, the decline in recall limits the further improvement of F1. This might be due to sample imbalance of candidate relations, which will be further studied in future work. On the whole (i.e. F1), RECENT SpanBERT outperforms all the compared models. Especially, RECENT SpanBERT exceeds the state-of-the-art LUKE model 4 by 2.5 F1 points and achieves a new state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Error Analysis of GCN</head><p>This subsection analyzes the influence of a baseline model (i.e. GCN) that neglects the restriction of entity types on relations. We retrain a GCN model and the model achieves 68.4 precision, 60.2 recall, and 64.1 F1 (  results in its reported paper <ref type="bibr" target="#b15">(Zhang et al., 2018)</ref>.</p><p>Observing the prediction results of the model, we find that 1) 1,323 examples are false positives in the test set of TACRED, 2) 144 (about 11%) false positives among them break the entity type restriction. Namely, GCN can make about 89% of false positives meet the entity type restriction, by implicitly using entity types. However, about 11% of false positives still break the restriction. The false positives broken down by relations are counted in Appendix A. In details, false positives broken down by relations are weakly negatively correlated with the amount of training data of relations, where the correlation coefficient is -0.39. This infers that fewer training examples of relations may lead to more false positives of relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In the paper, a novel paradigm, RECENT, is proposed by entity type restriction. RECENT reduces candidate relations for each pair of entity types by the mutual restrictions between relations and entity types. RECENT is model-agnostic. RECENT GCN and RECENT SpanBERT that are based on two representative models GCN and SpanBERT respectively, outperform their counterparts on the standard dataset TACRED, which empirically indicates the effectiveness of the proposed paradigm RE-CENT. Especially, RECENT SpanBERT achieves a new state-of-the-art on TACRED.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A relation restricts entities with appropriate types. In the figure, r is who-is-born-when. Different colored ellipses represent entities with different types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Entity type restriction for relation classification. According to entity type restriction, the number of candidate relations reduces from 5 (left) to 2 (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Relation classification with entity type restriction. The left part does not consider the restriction of entity types on relations and only feeds entity types as features into a general classifier. The right part explicitly utilizes entity types to restrict candidate relations and learns a specific classifier for each pair of entity types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>(marked as f g ) on the group that maps {(se i , s i , o i ) ? g} to R (ts,to) .</figDesc><table><row><cell>3:</cell><cell>aggregate relations in the group as candidate</cell></row><row><cell></cell><cell>relations R (ts,to) defined in Eq. 3.</cell></row><row><cell cols="2">4: learn a classifier : end for</cell></row><row><cell cols="2">Prediction Phase:</cell></row><row><cell></cell><cell>Input: A new sample {se, s, o, ts, to}, each</cell></row><row><cell></cell><cell>specific classifier for each pair of entity types.</cell></row><row><cell></cell><cell>Output: A relation.</cell></row><row><cell cols="2">6: match the sample to a group (marked as g )</cell></row><row><cell></cell><cell>according to the entity types (ts, to).</cell></row><row><cell cols="2">7: Use the classifier (f g ) learned on the group to</cell></row><row><cell></cell><cell>map (se, s, o) to a relation.</cell></row></table><note>to is type of object entity, r is relation. Output: Multiple classifiers.1: Group sentences by entity types.2: for each group g (enity types (ts, to) ) do58: return the relation.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Results on the TACRED dataset. P and R indicate precision and recall, respectively. Bold marks the highest values among models. ? marks results reported in the original papers. * marks results from preprint papers.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>), which are similar to the</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>Results of our trained GCN on the TACRED dataset. P and R indicate precision and recall, respectively. FP indicates the number of false positives and FP(ET) indicates the number of false positives that break the entity type restriction.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://catalog.ldc.upenn.edu/ LDC2018T24</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">LUKE achieves the state-of-the-art (72.7) on the published papers. Cohen et al. (2020) report a new state-of-theart (74.8) in the preprint way. Anyway, RECENTSpanBERT achieves a new state-of-the-art (75.2).</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A The Statistics of False Positives</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SegNet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2016.2644615</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Matching the blanks: Distributional similarity for relation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Livio Baldini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kwiatkowski</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1279</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2895" to="2905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Relation extraction as two-way spanprediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shachar</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Rosenman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goldberg</surname></persName>
		</author>
		<idno>abs/2010.04829</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Attention guided graph convolutional networks for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1024</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="241" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">SpanBERT: Improving pre-training by representing and predicting spans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00300</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="64" to="77" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improved natural language generation via loss truncation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.66</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="718" to="731" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Learning Representations</title>
		<meeting>the 5th International Conference on Learning Representations<address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Auxiliary learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
		<idno type="DOI">10.1109/TETCI.2020.3040444</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computational Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Knowledge enhanced contextual word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidur</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1005</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="43" to="54" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural relation extraction for knowledge base enrichment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Bayu Distiawan Trisedya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhong</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1023</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="229" to="240" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruize</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>2020a. K-Adapter: Infusing knowledge into pre-trained models with adapters. CoRR, abs/2002.01808v5</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">KE-PLER: A unified model for knowledge embedding and pre-trained language representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaocheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<idno>abs/1911.06136v3</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">LUKE: Deep contextualized entity representations with entityaware self-attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikuya</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Shindo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideaki</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.523</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6442" to="6454" />
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Graph convolution over pruned dependency trees improves relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1244</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2205" to="2215" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Positionaware attention and supervised data improve slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1004</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Condition aware and revise transformer for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoming</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanhuan</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3366423.3380301</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference</title>
		<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2377" to="2387" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
