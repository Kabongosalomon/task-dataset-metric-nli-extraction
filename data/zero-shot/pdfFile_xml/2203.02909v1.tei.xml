<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-supervised Image-specific Prototype Exploration for Weakly Supervised Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-03-06">6 Mar 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Sun Yat-Sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxiao</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Sun Yat-Sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhuang</forename><surname>Lai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Sun Yat-Sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Guangdong Province Key Laboratory of Information Security Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Key Laboratory of Machine Intelligence and Advanced Computing</orgName>
								<orgName type="department" key="dep2">Ministry of Education</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Xie</surname></persName>
							<email>xiexiaoh6@mail.sysu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Sun Yat-Sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Guangdong Province Key Laboratory of Information Security Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Key Laboratory of Machine Intelligence and Advanced Computing</orgName>
								<orgName type="department" key="dep2">Ministry of Education</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-supervised Image-specific Prototype Exploration for Weakly Supervised Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-03-06">6 Mar 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Weakly Supervised Semantic Segmentation (WSSS) based on image-level labels has attracted much attention due to low annotation costs. Existing methods often rely on Class Activation Mapping (CAM) that measures the correlation between image pixels and classifier weight. However, the classifier focuses only on the discriminative regions while ignoring other useful information in each image, resulting in incomplete localization maps. To address this issue, we propose a Self-supervised Image-specific Prototype Exploration (SIPE) that consists of an Image-specific Prototype Exploration (IPE) and a General-Specific Consistency (GSC) loss. Specifically, IPE tailors prototypes for every image to capture complete regions, formed our Image-Specific CAM (IS-CAM), which is realized by two sequential steps. In addition, GSC is proposed to construct the consistency of general CAM and our specific IS-CAM, which further optimizes the feature representation and empowers a self-correction ability of prototype exploration. Extensive experiments are conducted on PASCAL VOC 2012 and MS COCO 2014 segmentation benchmark and results show our SIPE achieves new state-of-the-art performance using only image-level labels. The code is available at https://github.com/chenqi1126/SIPE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Semantic segmentation aims to assign a semantic category label to each pixel in an image, which has been widely applied in autonomous driving <ref type="bibr" target="#b13">[14]</ref>, medical imaging <ref type="bibr" target="#b37">[38]</ref> and remote sensing image interpretation <ref type="bibr" target="#b16">[17]</ref>. Benefiting from Convolutional Neural Networks (CNNs), semantic segmentation has achieved remarkable progress in fully supervised manner. However, training a fully supervised segmentation model requires a large number of * Corresponding Author  <ref type="figure">Figure 1</ref>. Main motivation. We visualize the pixel-level feature distribution of four cat images by t-SNE <ref type="bibr" target="#b38">[39]</ref>. The transparency indicates the magnitude of activation. The original CAM activates each pixel using class center (green star). Our method extracts image-specific prototypes (pink star) to generate Image-Specific CAM (IS-CAM) that captures more complete regions. pixel-level annotations, which is notoriously expensive and time-consuming to collect. An alternative approach is to learn from weak labels, e.g., image-level labels <ref type="bibr" target="#b1">[2]</ref>, bounding boxes <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b48">49]</ref>, scribbles <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b45">46]</ref> and points <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref>. Among these works, image-level labels based Weakly Supervised Semantic Segmentation (WSSS) has enjoyed great popularity within the community.</p><p>Most of existing methods leverage Class Activation Mapping (CAM) <ref type="bibr" target="#b52">[53]</ref> technology to provide localization cues of target object. Specifically, these methods train a classifier and regard its learned weights as a general representation of each class, i.e., class center. Then, this class center is used to correlate with image pixels to obtain local-ization maps as shown in <ref type="figure">Fig. 1</ref>. However, CAM tends to focus on a few primary regions (cat's head) while ignoring other useful cues (cat's body). To explain the problem, we visualize pixel-level features of foreground extracted from a trained classification network. Those features are shown with four different colors and their transparency degree indicate the activation of CAM. We find that the class center always gives high activations to the close pixels (correspond to some primary regions) and ignores the distant pixels. The imbalanced activations lead to the incomplete localization map as demonstrated in <ref type="figure">Fig. 1</ref>. In addition, activating features on each image by the centroid of that features (pink star) can be beneficial to explore more complete regions (see Image-Specific CAM (IS-CAM) shown in <ref type="figure">Fig. 1</ref>). Therefore, this paper aims to tailor image-specific prototypes to adaptively describe the image itself.</p><p>To this end, we propose a novel weakly supervised semantic segmentation framework, called Self-supervised Image-specific Prototype Exploration (SIPE). The proposed SIPE consists of an Image-specific Prototype Exploration (IPE) and a General-Specific Consistency (GSC) loss, which is illustrated in <ref type="figure">Fig. 2</ref>. Specifically, IPE is realized as two sequential steps to characterize prototypes, allowing to capture more complete localization maps. In the first step, we utilize inter-pixel semantics to explore spatial structure cues, locating robust seed regions of each class. Given the seed regions, we extract image-specific prototypes and then produce our IS-CAM by prototypical correlation. In addition, GSC is proposed to construct the consistency of general CAM and our specific IS-CAM. This self-supervised signal further optimizes the feature representation and empowers a self-correction ability of prototype exploration. Extensive experiments are conducted on Pascal VOC 2012 <ref type="bibr" target="#b10">[11]</ref> and MS COCO 2014 <ref type="bibr" target="#b29">[30]</ref> and results show that our SIPE achieves new state-of-the-art performance when only image-level labels are available.</p><p>Our main contributions are summarized as:</p><p>? We propose Self-supervised Image-specific Prototype Exploration (SIPE) to learn image-specific knowledge for weakly supervised semantic segmentation.</p><p>? We propose Image Prototype Exploration (IPE) that tailors image-specific prototypes for each image, which is achieved by structure-aware seed locating and background-aware prototype modeling. It enables the model to capture more complete localization maps.</p><p>? We propose a General-Specific Consistency (GSC) loss to effectively regularize the original CAM and IS-CAM, empowering the feature representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Due to the low annotation costs, image-level labels based weakly supervised semantic segmentation has attracted in-creasing attention. Most existing methods adopt Class Activation Mapping (CAM) to generate localization maps and then refine them as pseudo labels to train a fully supervised segmentation model. To achieve a high performance segmentation model, many strategies have been investigated to improve the quality of localization maps. Erasure and accumulation. Erasure methods explore more object regions by intentionally removing the discriminative regions from the images <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43]</ref> or feature maps <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18]</ref>. However, erasing most of the discriminative regions may confuse the classifier and result in false positives. To avoid this problem, some works accumulate multiple activations by applying well-designed sampling on dilated convolution rate <ref type="bibr" target="#b43">[44]</ref>, image scales <ref type="bibr" target="#b49">[50]</ref>, spatial location <ref type="bibr" target="#b23">[24]</ref> and training process <ref type="bibr" target="#b19">[20]</ref>. Cross-image mining. Considering the sharing semantics between images, some works design cross-image relation mining modules, such as cross-image affinity <ref type="bibr" target="#b12">[13]</ref>, max bipartite matching <ref type="bibr" target="#b30">[31]</ref> and co-attention classifier <ref type="bibr" target="#b35">[36]</ref> to excavate semantic context of weak labels. Furthermore, the collaborative information of multi-images is explored to capture the potential knowledge by graph convolution network <ref type="bibr" target="#b27">[28]</ref> and self-attention mechanism <ref type="bibr" target="#b44">[45]</ref>. Background Modeling. Many methods <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48]</ref> obtain precise background by using auxiliary saliency maps, which is laborious. Without auxiliary maps, Fan et al. <ref type="bibr" target="#b11">[12]</ref> propose intra-class discriminator to separate the foreground and the background for each class. However, due to the object and scene diversity of images, it is quite tricky to learn a general intra-class discriminator for each class. Self-supervised Learning. More recent, self-supervised methods mine potential information and build supervisory signals, which has been demonstrated a promising solution to narrow the supervision gap between fully and weakly supervised semantic segmentation. Wang et al. <ref type="bibr" target="#b41">[42]</ref> apply consistency regularization on CAM from various transformed images to accomplish self-supervision learning. Chang et al. <ref type="bibr" target="#b3">[4]</ref> introduce a self-supervised task that discovers sub-categories, which provides additional supervision to enhance feature representations.</p><p>In contrast to existing methods, we fully consider the distinctiveness of images, and introduce image-specific prototypes to discover complete regions and construct a selfsupervised manner to empower feature representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>This section elaborates the proposed SIPE framework for weakly supervised semantic segmentation as shown in <ref type="figure">Fig. 2</ref>. Firstly, we briefly review the preliminary of CAM. Then we describe the pipeline of exploring image-specific prototypes and Image-Specific CAM (IS-CAM). Finally, a self-supervised learning with General-Specific Consistency (GSC) is introduced to empower feature representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IoU Evaluation</head><p>Background  <ref type="figure">Figure 2</ref>. Overview of the proposed SIPE for weakly supervised semantic segmentation. It mainly consists of two proposed methods: an Image-specific Prototype (IPE) Exploration and a General-Specific Consistency (GSC) loss. Specifically, in our IPE, a structure-aware seed locating method is proposed to achieve more robust seed regions and a background-aware prototype modeling is developed to extract hierarchical features. In addition, we add consistent regularization between two types of CAM (i.e., general CAM and our IS-CAM). This self-supervised signal effectively does correction in both CAM and IS-CAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Class Activation Mapping</head><p>Given an input image and a pretrained classification network, the class activation map M f = {M k } K k=1 over K foreground classes can be represented as follows:</p><formula xml:id="formula_0">M k = ReLU (? k T F s ), ?k ? K,<label>(1)</label></formula><p>where F s is the semantic feature from the last layer of the network, ? k denotes the k-th classifier weight, and thus M k is the k-th class-specific activation map. Following previous works, CAM is further normalized to [0, 1] by the maximum value along the spatial axes so that it could be regarded as the probability for each class.</p><p>Considering the importance of background in segmentation task, we follow <ref type="bibr" target="#b41">[42]</ref> to estimate the background activation map M b based on M f . Since CAM tends to cover object regions partially, the estimated background often contains high responses in foreground regions, which will bring considerable noise. To reduce such confusion, we weaken the background probability by introducing an attenuation coefficient ? = 0.5:</p><formula xml:id="formula_1">M b = ?(1 ? max 1?k?K M k ).<label>(2)</label></formula><p>We combine the processed background activation map with the foreground activation map as a whole, i.e. M = M f ? M b , to help model background knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Image-specific Prototype Exploration</head><p>Image-specific prototype is proposed to represent the feature distribution of each class, allowing to capture more complete regions. Different from the prototype representation in few-shot segmentation <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b51">52]</ref>, there is no ground truth pixel-level mask in WSSS. To explore imagespecific prototypes for characterizing a feature distribution, we design an efficient two-step pipeline. The first step provides robust class-wise seed regions and the second step aggregates these seeds on a comprehensive feature space to achieve accurate image-specific representation.</p><p>Structure-aware Seed Locating. A straightforward approach to obtain seeds is empirically selecting thresholds for CAM <ref type="bibr" target="#b18">[19]</ref>, but it is difficult to use a fixed threshold on different images due to the diversity of objects and scenarios. Although CAM pays more attention to discriminative regions, it also produces weak activations on the remaining regions. It means that CAM has the potential to provide the spatial structure of semantic objects. Besides, a pixel's spatial structure can be constituted by clustering high correlation pixels. For an image, we can determine each pixel's category by comparing its spatial structure with CAMs. Based on above analysis, we propose a structureaware seed locating method by exploring inter-pixel semantics to capture the spatial structure and employing CAMs as the templates to match the optimal category. <ref type="figure">Fig. 3</ref> illustrates the proposed method with selected foreground and background examples. Firstly, for an arbitrary pixel i, we take its semantic feature vector f i as the query to compute semantic correlation with all pixels in that feature map. Since pixels with high correlation scores are more likely to belong to the same class, these high correlation pixels can highlight the spatial structure. Therefore, we define the spatial structure of a pixel by inter-pixel semantic correlation: </p><formula xml:id="formula_2">S i (j) = ReLU ( f i ? F s (j) ||f i || ? ||F s (j)|| ),<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic correlation</head><p>Background:0.7 <ref type="figure">Figure 3</ref>. Illustration of structure-aware seed locating of selected foreground (green) and background pixels (red). The structure map are obtained by semantic correlation. Then the class-wise structure similarity can be evaluated by IoU and the maximal one is selected as the final class.</p><p>where ? is dot product and j is spatial index over the feature map as well as the structure map. S i (j) denotes the semantic correlation between pixel i and j, and S i is the structure map of pixel i. We suppress negative correlations by ReLU function to eliminate the influence of irrelevant pixels. Secondly, we evaluate the class-wise IoU between the structure map of pixel i and CAM as the structure similarity:</p><formula xml:id="formula_3">C i k = j M k (j)S i (j) j [M k (j) + S i (j) ? M k (j)S i (j)] .<label>(4)</label></formula><p>Here, C i k denotes the structure similarity for pixel i with respect to k-th class. j is spatial index over the activation map as well as the structure map. From <ref type="figure">Fig. 3</ref>, we can see that the foreground pixel (green star) correlates with the cat's body and achieves the highest IoU with CAM of the cat category. Additionally, the background pixel (red star) is not associated with foreground pixels, so it is more likely to belong to the background class.</p><p>Finally, pixel i is assigned to the category with maximal similarity:</p><formula xml:id="formula_4">R i k = 1, if k = arg max k ? C i k ? , 0, otherwise.<label>(5)</label></formula><p>By repeating this process for all pixels of the image in parallel, the seed regions R of both foreground and background classes are located as shown in <ref type="figure">Fig. 2</ref>.</p><p>Background-aware Prototype Modeling. In this section, we simultaneously model foreground and background prototypes. Considering that background does not have specific semantics, it is difficult to explore representative background prototypes on semantic feature space. Instead, features from shallow layers contain rich low-level visual information (e.g. color, texture), which is more suitable to model background-related information. Therefore, we modify the architecture of the backbone to capture hierarchical features for effective prototype representation. <ref type="figure" target="#fig_1">Fig. 4</ref> illustrates the architecture of modified backbone. Specifically, we add four convolution layers to extract multi-scale outputs. Then the multi-scale outputs are resized to the same size and concatenated to form the hierarchical feature F h . Thus image-specific prototypes P k of foreground and background can be formulated as the centroid of seed regions in hierarchical feature space:</p><formula xml:id="formula_5">P k = i F i h * ?(R i k = 1) i ?(R i k = 1) ,<label>(6)</label></formula><p>where i indexes the spatial locations and ?(?) outputs 1 if the argument is true or 0 otherwise. This process performs class-wise compression on the seed pixels, achieving K foreground prototypes and one background prototype. With these image-specific prototypes, the Image-Specific CAM (IS-CAM) is computed as follows:</p><formula xml:id="formula_6">M k (j) = ReLU ( F h (j) ? P k ||F h (j)|| ? ||P k || ),<label>(7)</label></formula><p>whereM k (j) is the k-th IS-CAM at pixel j. The correlation is bounded in [?1, 1], and followed by ReLU to remove negative correlations. Compared to the original CAM that takes classifier weight as the class center to compute the correlation of each pixel, the proposed IS-CAM utilizes prototypes tailored for every image to achieve more complete object regions. Besides, background prototype modeling provides high-quality background localization cues, which in turn help determine accurate foreground regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Self-supervised Learning with GSC</head><p>To further take advantage of image-specific knowledge, we introduce a self-supervised learning paradigm. The overall training loss consists of multi-label classification loss and the General-Specific Consistency (GSC) loss,</p><formula xml:id="formula_7">L total = L cls + L gsc .<label>(8)</label></formula><p>The classification loss is computed by a multi-label soft margin loss between the image-level category label y and the prediction?, which is obtained by averaging over foreground maps generated by CAM.</p><formula xml:id="formula_8">L cls = 1 K K i=1 y i log ?(? i ) + (1 ? y i ) log(1 ? ?(? i )),<label>(9)</label></formula><p>where ? is the sigmoid activation function.</p><p>The GSC is employed to minimize the difference between original CAM activated by classifier weight and IS-CAM activated by image-specific prototypes. The mathematical definition of this consistency regularization is formulated as the L1 normalization of the two kinds of CAM:</p><formula xml:id="formula_9">L gsc = 1 K + 1 ||M ?M || 1 ,<label>(10)</label></formula><p>where M ,M denotes the original CAM and IS-CAM respectively. The loss is averaged over K foreground classes and one background class. With this consistency, the image-specific knowledge is injected into the feature representation, and the collaborative optimization is accomplished in the training cycles. IS-CAM forces the original CAM to pay attention to the absent object regions, which implicitly narrows the feature distance between the discriminative and missing pixels. Besides, the enhanced semantic and hierarchical features are favorable to capture more comprehensive and accurate image-specific prototypes and improve the quality of localization maps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we first elaborate the experimental settings including dataset, evaluation metric and implementation details. Second, we compare our method with state-ofthe-art approaches on the PASCAL VOC 2012 dataset <ref type="bibr" target="#b10">[11]</ref> and MS COCO 2014 dataset <ref type="bibr" target="#b29">[30]</ref>. Third, we conduct a series of ablation studies to verify the effectiveness of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Settings</head><p>Dataset and Evaluated Metric. We evaluate our proposed method on PASCAL VOC 2012 segmentation benchmark <ref type="bibr" target="#b10">[11]</ref> with 20 foreground classes and one background class. The official dataset split contains 1,464 images for training, 1,449 for validation and 1,456 for testing. Following the common experimental protocol in semantic segmentation, we take additional annotations from SBD <ref type="bibr" target="#b14">[15]</ref> to build an augmented training set with 10,582 images. Another MS COCO 2014 dataset has totally 81 classes and contains 80k train and 40k validation images, which is challenging for weakly supervised semantic segmentation. Note that only image-level classification labels are available during network training for both datasets. Mean intersection over union (mIoU) is used as a metric to evaluate segmentation results. The results for the PASCAL VOC test set are obtained from the official evaluation server. Implementation Details. In our experiments, the Ima-geNet <ref type="bibr" target="#b8">[9]</ref> pretrained ResNet50 <ref type="bibr" target="#b15">[16]</ref> is adopted as backbone with output stride of 16, where fully connected layer is replaced by a classifier with output channels of 20. The augmentation strategy is the same to <ref type="bibr" target="#b24">[25]</ref>, including random flipping, random scaling and crop. The model is trained with a batch size of 16 on 2 Nvidia A100 GPUs. SGD optimizer is adopted to train our model for 5 epochs, with a momentum of 0.9 and a weight decay of 1e-4. The learning rates for the backbone and the newly added layers are set as 0.1 and 1, respectively. We use poly learning scheduler decayed with a power of 0.9 for the learning rate.</p><p>Inference At the inference stage, the network generates foreground and background seeds by hierarchical features and activates to localization maps. Instead of checking various mIoU scores over the training set to obtain pseudo labels as other works <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b41">42]</ref>, we directly compute pseudo labels with the background localization maps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison with State-of-the-arts</head><p>Improvements on localization maps. We first evaluate mIoU on localization maps, where those maps are generated by the proposed IS-CAM. Tab. 1 presents the comparison with other advanced methods on PASCAL VOC 2012 train set. Among these compared methods, ECS <ref type="bibr" target="#b36">[37]</ref> provides the best results with a mIoU of 56.6%. Our proposed SIPE achieves the state-of-the-art performance of 58.6%. Furthermore, we report the performance with denseCRF post-processing. The results show that our SIPE with dense-CRF improves the mIoU to 64.7% and outperforms all other methods, which may be benefited from our high-quality localization maps. We interpret this performance gain comes from the capability of SIPE to generate complete localization maps for foreground and background. As the localization maps can capture satisfying boundaries of semantic objects, the denseCRF is less confusing while refining the CAMs. <ref type="figure" target="#fig_2">Fig. 5</ref> shows the visual comparison of foreground localization maps on PASCAL VOC 2012 train set. It can be observed that our SIPE is effective in capturing the whole semantic regions under various scenes, such as different object scales, crowded objects, and multiple categories. The  obtained high-quality localization maps will further benefit our segmentation results.</p><p>Improvements on segmentation results. To further evaluate the performance of our methods, we train fully supervised models using generated pseudo labels and compare the segmentation results with the state-of-the-arts. Following the common practice <ref type="bibr" target="#b24">[25]</ref>, the pseudo labels are refined by IRN <ref type="bibr" target="#b0">[1]</ref> and used to train DeepLabV2 <ref type="bibr" target="#b6">[7]</ref>. Tab. 2 presents the comparison with state-of-the-art methods on PASCAL VOC 2012 val and test sets. Using only imagelevel labels, our SIPE outperforms previous methods with 68.8% mIoU on val set and 69.7% mIoU on test set. In addition, our method performs favorably against NSROM <ref type="bibr" target="#b47">[48]</ref> and EPS <ref type="bibr" target="#b26">[27]</ref>, which introduce saliency maps as auxiliary   labels for this task. For a fair comparison, we also train the model with ResNet38 following the default setting as <ref type="bibr" target="#b41">[42]</ref>. Our SIPE achieves 69.5% mIoU on test set, exceeding the existing methods that use ResNet38 backbone. The qualitative segmentation results on val set are shown in <ref type="figure" target="#fig_3">Fig. 6</ref>. Based on our SIPE, DeepLabV2 shows more robustness to various challenging scenarios, such as different object scales, multiple objects and multiple categories. In Tab. 3, we also evaluate our method in MS COCO 2014 dataset <ref type="bibr" target="#b29">[30]</ref>. The same training script with the experiment on PASCAL VOC 2012 is employed, but no refinement with IRN due to the large computation cost. Our method achieves 43.6% mIoU with ResNet38 backbone on the validation set, which is 7.2% higher than previous SOTA CSE <ref type="bibr" target="#b22">[23]</ref>. Using ResNet101 backbone, we also outper- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Studies</head><p>Effect of the main contributions. We conduct an ablation study to verify the effect of the proposed two key contributions, i.e., Image-specific Prototype Exploration (IPE) and General-Specific Consistency (GSC). As shown in Tab. 4, with image-specific prototypes, our IS-CAM can improve the original CAM by 2.1% on mIoU score. To enhance the feature representation, GSC is introduced for selfsupervised training. The proposed GSC improves the quality of IS-CAM (5.4%) by a clear margin. By combining these two methods, our full method performs significantly better than the original CAM. <ref type="figure" target="#fig_4">Fig. 7</ref> visualizes CAM and IS-CAM with different settings. From the first two rows, we can observe that image-specific prototypes can activate more useful regions. Additionally, our IS-CAM shows that the proposed method produces more clear background activations than that from CAM. When training our model with GSC, the quality of localization maps is obviously improved, especially for background.  Effect of structure-aware seed locating. To verify the effectiveness of the proposed structure-aware seed locating, we compare the mIoU with other seed generation approaches including applying threshold or argmax operations on CAM. As shown in <ref type="figure" target="#fig_5">Fig. 8</ref>, applying different thresholds on CAM exhibits fluctuations and can only achieve maximal mIoU of 53.3%. In addition, simply applying argmax results in slightly performance gains (+0.4%). These methods are still hard to find compete regions because both of them only depend on the single pixel's probability. In contrast, the proposed structure-aware seed locating largely outperforms the above methods owing to the proposed structure information.</p><p>Effect of prototype modeling. We conduct ablation study of prototype modeling on localization maps. The IoUs of four options concerning feature and Background <ref type="table">Table 5</ref>. Ablation study of combinations of feature selection and Background Prototype Modeling (BPM) via GSC. Each item reports mIoUs for two pseudo labels where the former are generated by searching the best background threshold <ref type="bibr" target="#b41">[42]</ref> and the latter are generated by estimated background map. The best results are shown in bold. Prototype Modeling (BPM) are presented in Tab. 5: (1) Semantic feature without BPM, (2) Semantic feature with BPM, (3) Hierarchical feature without BPM, and (4) Hierarchical feature with BPM. We report threshold-based and estimated-based pseudo labels for each type of option. Our SIPE adopts option (4) where hierarchical feature is learned for image-specific background modeling. It shows that our method achieves the highest performance in both values among all options. From (1) to (2), the mIoU is basically unchanged because the background often does not have specific semantics. From (1) to (3), the mIoU drops over 2% since the low-level information brings confusion to foreground localization. It is worth noting that only when hierarchical feature and background modeling are employed at the same time, the mIoU of the estimated-based pseudo labels exceed that bases on threshold, which strongly proves the effectiveness of estimating background cues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose Self-supervised Image-specific Prototype Exploration (SIPE) for weakly supervised semantic segmentation. In our framework, an Image-specific Prototype Exploration (IPE) is proposed to achieve more favorable localization maps. It is achieved by structure-aware seed locating and background-aware prototype modeling. In addition, a General-Specific Consistency (GSC) loss is developed to efficiently regularize the general CAM and Image-Specific CAM (IS-CAM), empowering the feature representation. Extensive experiments show that our SIPE sets new state-of-the-art performance on two well-known benchmarks using image-level labels.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Illustration of the modified backbone for extracting hierarchical feature representations. The semantic feature is extracted from the last layer and the hierarchical feature is the fusion of four stages of the backbone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>Visual comparison of localization maps generated by different methods on PASCAL VOC 2012 train set. From top to down: original image, Baseline, SCE<ref type="bibr" target="#b3">[4]</ref>, SEAM<ref type="bibr" target="#b41">[42]</ref>, AdvCAM<ref type="bibr" target="#b24">[25]</ref> and our SIPE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Qualitative segmentation results on the validation set of PASCAL VOC 2012 and MS COCO 2014.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Visualization of CAM and IS-CAM with different settings. Our IS-CAM shows more complete regions of person. Moreover, the proposed GSC further refines the background activations. The boundary is well captured as the white box.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Ablation study of structure-aware seed locating. The proposed structural-aware seed locating method is consistently better than CAM with fixed threshold, as well as CAM with adaptive threshold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table Structure</head><label>Structure</label><figDesc></figDesc><table><row><cell cols="2">Person, Table</cell><cell cols="2">Classification Loss</cell><cell></cell><cell></cell><cell></cell><cell>General-Specific Consistency Loss</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>G</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Classifier weight</cell><cell></cell><cell></cell><cell>CAM</cell><cell cols="2">Seed region</cell><cell>Image-specific Prototypes</cell><cell>IS-CAM</cell></row><row><cell></cell><cell>?</cell><cell></cell><cell></cell><cell>Person</cell><cell>Table</cell><cell>Background</cell><cell>Person</cell><cell>foreground</cell><cell>Person</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>C</cell><cell>?</cell><cell></cell><cell>?</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>?</cell><cell>?</cell></row><row><cell></cell><cell cols="2">Feature</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>M</cell><cell>background</cell><cell>C</cell><cell>Table</cell></row><row><cell></cell><cell cols="2">Extraction</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Semantic</cell><cell>C</cell><cell></cell><cell></cell><cell>Background</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell>feature</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">C Correlation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>F</cell><cell>Feature Fusion</cell><cell></cell><cell></cell><cell>Structure map</cell><cell></cell><cell cols="2">similarity</cell><cell>Hierarchical</cell></row><row><cell>M</cell><cell>Mask Average Pool</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>feature</cell></row><row><cell cols="2">G Global Average Pool</cell><cell></cell><cell></cell><cell cols="3">Structure-aware Seed Locating</cell><cell>Background-aware Prototype Modeling</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>mIoU (%) of localization maps on PASCAL VOC 2012 train set. The best results are shown in bold.</figDesc><table><row><cell>Method</cell><cell>Pub.</cell><cell cols="2">Local. Maps +denseCRF</cell></row><row><cell>Baseline</cell><cell>-</cell><cell>50.1</cell><cell>54.3</cell></row><row><cell>SCE [4]</cell><cell>CVPR20</cell><cell>50.9</cell><cell>55.3</cell></row><row><cell>SEAM [42]</cell><cell>CVPR20</cell><cell>55.4</cell><cell>56.8</cell></row><row><cell>EDAM [45]</cell><cell>CVPR21</cell><cell>52.8</cell><cell>58.2</cell></row><row><cell cols="2">AdvCAM [25] CVPR21</cell><cell>55.6</cell><cell>62.1</cell></row><row><cell>ECS [37]</cell><cell>ICCV21</cell><cell>56.6</cell><cell>58.6</cell></row><row><cell>CSE [23]</cell><cell>ICCV21</cell><cell>56.0</cell><cell>62.8</cell></row><row><cell>SIPE (Ours)</cell><cell></cell><cell>58.6</cell><cell>64.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Comparison with other state-of-the-arts on PASCAL VOC 2012 val and test sets. The best results among methods only using image-level labels are shown in bold.</figDesc><table><row><cell>Model</cell><cell>Pub.</cell><cell cols="2">Sup. Backbone Val Test</cell></row><row><cell>DSRG [19]</cell><cell cols="3">CVPR18 I + S ResNet101 61.4 63.2</cell></row><row><cell>SeeNet [18]</cell><cell cols="3">NIPS18 I + S ResNet101 63.1 62.8</cell></row><row><cell cols="4">FickleNet [24] CVPR19 I + S ResNet101 64.9 65.3</cell></row><row><cell>OAA+ [20]</cell><cell cols="3">ICCV19 I + S ResNet101 65.2 66.4</cell></row><row><cell>G-WSSS [28]</cell><cell cols="3">AAAI21 I + S ResNet101 68.2 68.5</cell></row><row><cell>NSROM [48]</cell><cell cols="3">CVPR21 I + S ResNet101 70.4 70.2</cell></row><row><cell>EPS [27]</cell><cell cols="3">CVPR21 I + S ResNet101 71.0 71.8</cell></row><row><cell cols="4">AuxSegNet [47] ICCV21 I + S ResNet38 69.0 68.6</cell></row><row><cell>IRN [1]</cell><cell cols="2">CVPR19 I</cell><cell>ResNet50 63.5 64.8</cell></row><row><cell>ICD [12]</cell><cell cols="3">CVPR20 I ResNet101 64.1 64.3</cell></row><row><cell>SCE [4]</cell><cell cols="3">CVPR20 I ResNet101 66.1 65.9</cell></row><row><cell>SEAM [42]</cell><cell cols="2">CVPR20 I</cell><cell>ResNet38 64.5 65.7</cell></row><row><cell>BES [6]</cell><cell cols="3">ECCV20 I ResNet101 65.7 66.6</cell></row><row><cell>MCIS [36]</cell><cell cols="3">ECCV20 I ResNet101 66.2 66.9</cell></row><row><cell>CONTA [10]</cell><cell>NIPS20</cell><cell cols="2">I ResNet101 66.1 66.7</cell></row><row><cell>LIID [32]</cell><cell cols="3">TPAMI20 I ResNet101 66.5 67.5</cell></row><row><cell>A2GNN [49]</cell><cell cols="3">TPAMI21 I ResNet101 66.8 67.4</cell></row><row><cell cols="4">AdvCAM [25] CVPR21 I ResNet101 68.1 68.0</cell></row><row><cell>CDA [35]</cell><cell>ICCV21</cell><cell>I</cell><cell>ResNet38 66.1 66.8</cell></row><row><cell>ECS [37]</cell><cell>ICCV21</cell><cell>I</cell><cell>ResNet38 66.6 67.6</cell></row><row><cell>CSE [23]</cell><cell>ICCV21</cell><cell>I</cell><cell>ResNet38 68.4 68.2</cell></row><row><cell>CPN [51]</cell><cell>ICCV21</cell><cell>I</cell><cell>ResNet38 67.8 68.5</cell></row><row><cell>SIPE (Ours)</cell><cell></cell><cell>I</cell><cell>ResNet38 68.2 69.5 1</cell></row><row><cell>SIPE (Ours)</cell><cell></cell><cell cols="2">I ResNet101 68.8 69.7 2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Comparison with other state-of-the-arts on MS COCO 2014 val set. The best results are shown in bold.</figDesc><table><row><cell>Model</cell><cell>Pub.</cell><cell cols="2">Sup. Backbone Val</cell></row><row><cell>DSRG [19]</cell><cell cols="2">CVPR18 I + S</cell><cell>VGG16 26.0</cell></row><row><cell>G-WSSS [28]</cell><cell cols="3">AAAI21 I + S ResNet101 28.4</cell></row><row><cell>EPS [27]</cell><cell cols="3">CVPR21 I + S ResNet101 35.7</cell></row><row><cell cols="4">AuxSegNet [47] ICCV21 I + S ResNet38 33.9</cell></row><row><cell>SEC [22]</cell><cell>ECCV16</cell><cell>I</cell><cell>VGG16 22.4</cell></row><row><cell>IRN [1]</cell><cell>CVPR19</cell><cell>I</cell><cell>ResNet50 32.6</cell></row><row><cell>IAL [41]</cell><cell>IJCV20</cell><cell>I</cell><cell>VGG16 27.7</cell></row><row><cell>SEAM [42]</cell><cell>CVPR20</cell><cell>I</cell><cell>ResNet38 31.9</cell></row><row><cell>CONTA [10]</cell><cell>NIPS20</cell><cell>I</cell><cell>ResNet101 33.4</cell></row><row><cell>CSE [23]</cell><cell>ICCV21</cell><cell>I</cell><cell>ResNet38 36.4</cell></row><row><cell>SIPE (Ours)</cell><cell></cell><cell>I</cell><cell>ResNet38 43.6</cell></row><row><cell>SIPE (Ours)</cell><cell></cell><cell>I</cell><cell>ResNet101 40.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Effect of the main contributions. CAM: orginal CAM, IPE: image-specific prototype exploration, GSC: general-specific consistency.</figDesc><table><row><cell>CAM</cell><cell>IPE</cell><cell>GSC</cell><cell>mIoU (%)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>50.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>53.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>58.6</cell></row><row><cell cols="4">forms EPS [27] by 4.9%. These outstanding performances</cell></row><row><cell cols="4">over existing state-of-the-arts on both datasets confirm the</cell></row><row><cell cols="4">effectiveness of our SIPE, which well explores image-</cell></row><row><cell cols="4">specific prototypes via self-supervised learning paradigm.</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://host.robots.ox.ac.uk:8080/anonymous/NGICBM.html 2 http://host.robots.ox.ac.uk:8080/anonymous/UU6VNX.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This project is supported by the Key-Area Research and Development Program of Guangdong Province (2019B010155003), and the National Natural Science Foundation of China (62072482). We would like to thank Pengze Zhang, Huajun Zhou, and Xingxing Weng for insight discussion.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of instance segmentation with inter-pixel relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning pixel-level semantic affinity with image-level supervision for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4981" to="4990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">What&apos;s the point: Semantic segmentation with point supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Bearman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="549" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weaklysupervised semantic segmentation via sub-category exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ting</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robinson</forename><surname>Piramuthu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Seminar learning for click-level weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongjun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinbao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Cai Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiantong</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="6920" to="6929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic segmentation with boundary exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="347" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Attentionbased dropout layer for weakly supervised single object localization and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjung</forename><surname>Shim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Causal intervention for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Hanwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tang</forename><surname>Jinhui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Xiansheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sun</forename><surname>Qianru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning integral objects with intra-class discriminator for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cian: Cross-image affinity net for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="10762" to="10769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep multi-modal object detection and semantic segmentation for autonomous driving: Datasets, methods, and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Haase-Schuetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinz</forename><surname>Hertlein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudius</forename><surname>Glaeser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Timm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Wiesbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Dietmayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semantic contours from inverse detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Arbel?ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="991" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Segmentation for object-based image analysis (obia): A review of algorithms and challenges from remote sensing perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="134" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Self-erasing network for integral object attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Tao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation network with deep seeded region growing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Integral object mining via online attention accumulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Tao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Kai</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Discriminative region suppression for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beomyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangeun</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1754" to="1761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Seed, expand and constrain: Three principles for weakly-supervised image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unlocking the potential of ordinary classifier: Class-specific adversarial erasing framework for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeokjun</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung-Hoon</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonseong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daehee</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuk-Jin</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ficklenet: Weakly and semi-supervised semantic image segmentation using stochastic inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunji</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jangho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Antiadversarially manipulated attributions for weakly and semisupervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunji</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bbam: Bounding box attribution map for weakly supervised semantic and instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihun</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaehun</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2643" to="2652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Railroad is not a train: Saliency as pseudo-pixel supervision for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minhyun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongwuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjung</forename><surname>Shim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Group-wise semantic mining for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scribblesup: Scribble-supervised convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3159" to="3167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Weakly supervised segmentation with maximum bipartite graph matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weide</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tzu-Yi</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Multimedia</title>
		<meeting>the 28th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2085" to="2094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Leveraging instance-, imageand dataset-level information for weakly supervised instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Huan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Song</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Jun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Songyang Zhang, and Xuming He. Part-aware prototype network for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="142" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Scribble-supervised semantic segmentation by uncertainty reduction on neural representation and selfsupervision on neural eigenspace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyi</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhe</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><forename type="middle">G</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="7416" to="7425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Context decoupling augmentation for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Mining cross-image semantics for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Ecs-net: Improving weakly supervised semantic segmentation by using connections between class activation maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Embracing imperfect datasets: A review of deep learning solutions for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Jeyaseelan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">101693</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Panet: Few-shot image semantic segmentation with prototype alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Hao Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtian</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daquan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<idno>Octo- ber 2019. 3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation by iterative affinity learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sifei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1736" to="1749" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Self-supervised equivariant attention mechanism for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yude</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meina</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="12275" to="12284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Object region mining with adversarial erasing: A simple classification to semantic segmentation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1568" to="1576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Revisiting dilated convolution: A simple approach for weakly-and semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7268" to="7277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Embedded discriminative attention mechanism for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junshi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><forename type="middle">Harold</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Scribble-supervised semantic segmentation inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingshan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuge</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="15354" to="15363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Leveraging auxiliary tasks with affinity learning for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farid</forename><surname>Boussaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferdous</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Nonsalient region object mining for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhou</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Sen</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fumin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenmin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Affinity attention graph neural network for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Reliability does matter: An end-to-end weakly supervised semantic segmentation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaizhu</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="12765" to="12772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Complementary patch for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochen</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchao</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Sg-one: Similarity guidance network for one-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on cybernetics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3855" to="3865" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="2921" to="2929" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
