<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Invariant Risk Minimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
						</author>
						<title level="a" type="main">Invariant Risk Minimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine learning suffers from a fundamental problem. While machines are able to learn complex prediction rules by minimizing their training error, data are often marred by selection biases, confounding factors, and other peculiarities <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b22">23]</ref>. As such, machines justifiably inherit these data biases. This limitation plays an essential role in the situations where machine learning fails to fulfill the promises of artificial intelligence. More specifically, minimizing training error leads machines into recklessly absorbing all the correlations found in training data. Understanding which patterns are useful has been previously studied as a correlation-versus-causation dilemma, since spurious correlations stemming from data biases are unrelated to the causal explanation of interest <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b51">52]</ref>. Following this line, we leverage tools from causation to develop the mathematics of spurious and invariant correlations, in order to alleviate the excessive reliance of machine learning systems on data biases, allowing them to generalize to new test distributions.</p><p>As a thought experiment, consider the problem of classifying images of cows and camels <ref type="bibr" target="#b3">[4]</ref>. To address this task, we label images of both types of animals. Due to a selection bias, most pictures of cows are taken in green pastures, while most pictures of camels happen to be in deserts. After training a convolutional neural network on this dataset, we observe that the model fails to classify easy examples of images of cows when they are taken on sandy beaches. Bewildered, we later realize that our neural network successfully minimized its training error using a simple cheat: classify green landscapes as cows, and beige landscapes as camels.</p><p>To solve the problem described above, we need to identify which properties of the training data describe spurious correlations (landscapes and contexts), and which properties represent the phenomenon of interest (animal shapes). Intuitively, a correlation is spurious when we do not expect it to hold in the future in the same manner as it held in the past. In other words, spurious correlations do not appear to be stable properties <ref type="bibr" target="#b53">[54]</ref>. Unfortunately, most datasets are not provided in a form amenable to discover stable properties. Because most machine learning algorithms depend on the assumption that training and testing data are sampled independently from the same distribution <ref type="bibr" target="#b50">[51]</ref>, it is common practice to shuffle at random the training and testing examples. For instance, whereas the original NIST handwritten data was collected from different writers under different conditions <ref type="bibr" target="#b18">[19]</ref>, the popular MNIST training and testing sets <ref type="bibr" target="#b7">[8]</ref> were carefully shuffled to represent similar mixes of writers. Shuffling brings the training and testing distributions closer together, but discards what information is stable across writers. However, shuffling the data is something that we do, not something that Nature does for us. When shuffling, we destroy information about how the data distribution changes when one varies the data sources or collection specifics. Yet, this information is precisely what tells us whether a property of the data is spurious or stable.</p><p>Here we take a step back, and assume that the training data is collected into distinct, separate environments. These could represent different measuring circumstances, locations, times, experimental conditions, external interventions, contexts, and so forth. Then, we promote learning correlations that are stable across training environments, as these should (under conditions that we will study) also hold in novel testing environments.</p><p>Returning to our motivational example, we would like to label pictures of cows and camels under different environments. For instance, the pictures of cows taken in the first environment may be located in green pastures 80% of the time. In the second environment, this proportion could be slightly different, say 90% of the time (since pictures were taken in a different country). These two datasets reveal that "cow" and "green background" are linked by a strong, but varying (spurious) correlation, which should be discarded in order to generalize to new environments. Learning machines which pool the data from the two environments together may still rely on the background bias when addressing the prediction task. But, we believe that all cows exhibit features that allow us to recognize them as so, regardless of their context. This suggests that invariant descriptions of objects relate to the causal explanation of the object itself ("Why is it a cow? ") <ref type="bibr" target="#b31">[32]</ref>. As shown by <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b21">22]</ref>, there exists an intimate link between invariance and causation useful for generalization. However, <ref type="bibr" target="#b39">[40]</ref> assumes a meaningful causal graph relating the observed variables, an awkward assumption when dealing with perceptual inputs such as pixels. Furthermore, <ref type="bibr" target="#b39">[40]</ref> only applies to linear models, and scales exponentially with respect to the number of variables in the learning problem. As such, the seamless integration of causation tools <ref type="bibr" target="#b40">[41]</ref> into machine learning pipelines remains cumbersome, disallowing what we believe to be a powerful synergy. Here, we work to address these concerns.</p><p>Contributions We propose Invariant Risk Minimization (IRM), a novel learning paradigm that estimates nonlinear, invariant, causal predictors from multiple training environments, to enable out-of-distribution (OOD) generalization. To this end, we first analyze in Section 2 how different learning techniques fail to generalize OOD. From this analysis, we derive our IRM principle in Section 3:</p><p>To learn invariances across environments, find a data representation such that the optimal classifier on top of that representation matches for all environments.</p><p>Section 4 examines the fundamental links between causation, invariance, and OOD generalization. Section 5 contains basic numerical simulations to validate our claims empirically. Section 6 concludes with a Socratic dialogue discussing directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The many faces of generalization</head><p>Following <ref type="bibr" target="#b39">[40]</ref>, we consider datasets D e := {(x e i , y e i )} ne i=1 collected under multiple training environments e ? E tr . These environments describe the same pair of random variables measured under different conditions. The dataset D e , from environment e, contains examples identically and independently distributed according to some probability distribution P (X e , Y e ). <ref type="bibr" target="#b0">1</ref> Then, our goal is to use these multiple datasets to learn a predictor Y ? f (X), which performs well across a large set of unseen but related environments E all ? E tr . Namely, we wish to minimize</p><formula xml:id="formula_0">R OOD (f ) = max e?E all R e (f ) where R e (f ) := E X e ,Y e [ (f (X e ), Y e )]</formula><p>is the risk under environment e. Here, the set of all environments E all contains all possible experimental conditions concerning our system of variables, both observable and hypothetical. This is in the spirit of modal realism and possible worlds <ref type="bibr" target="#b28">[29]</ref>, where we could consider, for instance, environments where we switch off the Sun. An example clarifies our intentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 1.</head><p>Consider the structural equation model <ref type="bibr" target="#b54">[55]</ref>:</p><formula xml:id="formula_1">X 1 ? Gaussian(0, ? 2 ), Y ? X 1 + Gaussian(0, ? 2 ), X 2 ? Y + Gaussian(0, 1).</formula><p>As we formalize in Section 4, the set of all environments E all contains all modifications of the structural equations for X 1 and X 2 , and those varying the noise of Y within a finite range [0, ? 2 MAX ]. For instance, e ? E all may replace the equation of X 2 by X e 2 ? 10 6 , or vary ? 2 within this finite range . To ease exposition consider:</p><p>E tr = {replace ? 2 by 10, replace ? 2 by 20}.</p><p>Then, to predict Y from (X 1 , X 2 ) using a least-squares predictor? e = X e 1?1 + X e 2?2 for environment e, we can:</p><p>? regress from X e 1 , to obtain? 1 = 1 and? 2 = 0, ? regress from X e 2 , to obtain? 1 = 0 and? 2 = ?(e) 2 /(?(e) 2 + 1 2 ), ? regress from (X e 1 , X e 2 ), to obtain? 1 = 1/(?(e) 2 +1) and? 2 = ?(e) 2 /(?(e) 2 +1). The regression using X 1 is our first example of an invariant correlation: this is the only regression whose coefficients do not depend on the environment e. Conversely, the second and third regressions exhibit coefficients that vary from environment to environment. These varying (spurious) correlations would not generalize well to novel test environments. Also, not all invariances are interesting: the regression from the empty set of features into Y is invariant, but of weak predictive power.</p><p>The invariant rule? = 1 ? X 1 + 0 ? X 2 is the only predictor with finite R OOD across E all (to see this, let X 2 ? ?). Furthermore, this predictor is the causal explanation about how the target variable takes values across environments. In other words, it provides the correct description about how the target variable reacts in response to interventions on each of the inputs. This is compelling, as invariance is a statistically testable quantity that we can measure to discover causation. We elaborate on the relationship between invariance and causation in Section 4. But first, how can we learn the invariant, causal regression? Let us review four techniques commonly discussed in prior work, as well as their limitations.</p><p>First, we could merge the data from all the training environments and learn a predictor that minimizes the training error across the pooled data, using all features. This is the ubiquitous Empirical Risk Minimization (ERM) principle <ref type="bibr" target="#b49">[50]</ref>. In this example, ERM would grant a large positive coefficient to X 2 if the pooled training environments lead to large ? 2 (e) (as in our example), departing from invariance.</p><p>Second, we could minimize R rob (f ) = max e?Etr R e (f ) ? r e , a robust learning objective where the constants r e serve as environment baselines <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b45">46]</ref>. Setting these baselines to zero leads to minimizing the maximum error across environments. Selecting these baselines adequately prevents noisy environments from dominating optimization. For example, <ref type="bibr" target="#b36">[37]</ref> selects r e = V[Y e ] to maximize the minimal explained variance across environments. While promising, robust learning turns out to be equivalent to minimizing a weighted average of environment training errors: Proposition 2. Given KKT differentiability and qualification conditions, ?? e ? 0 such that the minimizer of R rob is a first-order stationary point of e?Etr ? e R e (f ).</p><p>This proposition shows that robust learning and ERM (a special case of robust learning with ? e = 1 |Etr| ) would never discover the desired invariance, obtaining infinite R OOD . This is because minimizing the risk of any mixture of environments associated to large ? 2 (e) yields a predictor with a large weight on X 2 . Unfortunately, this correlation will vanish for testing environments associated to small ? 2 (e).</p><p>Third, we could adopt a domain adaptation strategy, and estimate a data representation ?(X 1 , X 2 ) that follows the same distribution for all environments <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b32">33]</ref>. This would fail to find the true invariance in Example 1, since the distribution of the true causal feature X 1 (and the one of the target Y ) can change across environments. This illustrates why techniques matching feature distributions sometimes attempt to enforce the wrong type of invariance, as discussed in Appendix C.</p><p>Fourth, we could follow invariant causal prediction techniques <ref type="bibr" target="#b39">[40]</ref>. These search for the subset of variables that, when used to estimate individual regressions for each environment, produce regression residuals with equal distribution across all environments. Matching residual distributions is unsuited for our example, since the noise variance in Y may change across environments.</p><p>In sum, finding invariant predictors even on simple problems such as Example 1 is surprisingly difficult. To address this issue, we propose Invariant Risk Minimization (IRM), a learning paradigm to extract nonlinear invariant predictors across multiple environments, enabling OOD generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Algorithms for invariant risk minimization</head><p>In statistical parlance, our goal is to learn correlations invariant across training environments. For prediction problems, this means finding a data representation such that the optimal classifier, 2 on top of that data representation, is the same for all environments. More formally: Definition 3. We say that a data representation ? : X ? H elicits an invariant predictor w?? across environments E if there is a classifier w : H ? Y simultaneously optimal for all environments, that is, w ? arg minw :</p><formula xml:id="formula_2">H?Y R e (w ? ?) for all e ? E.</formula><p>Why is Definition 3 equivalent to learning features whose correlations with the target variable are stable? For loss functions such as the mean squared error and the cross-entropy, optimal classifiers can be written as conditional expectations. In these cases, a data representation function ? elicits an invariant predictor across environments E if and only if for all h in the intersection of the supports of ?(X e ) we have E[Y e |?(X e ) = h] = E[Y e |?(X e ) = h], for all e, e ? E.</p><p>We believe that this concept of invariance clarifies common induction methods in science. Indeed, some scientific discoveries can be traced to the realization that distinct but potentially related phenomena, once described with the correct variables, appear to obey the same exact physical laws. The precise conservation of these laws suggests that they remain valid on a far broader range of conditions. If both Newton's apple and the planets obey the same equations, chances are that gravitation is a thing.</p><p>To discover these invariances from empirical data, we introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate data representations eliciting invariant predictors w ? ? across multiple environments. To this end, recall that we have two goals in mind for the data representation ?: we want it to be useful to predict well, and elicit an invariant predictor across E tr . Mathematically, we phrase these goals as the constrained optimization problem: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(IRM)</head><p>This is a challenging, bi-leveled optimization problem, since each constraint calls an inner optimization routine. So, we instantiate (IRM) into the practical version:</p><formula xml:id="formula_3">min ?:X ?Y e?Etr R e (?) + ? ? ? w|w=1.0 R e (w ? ?) 2 ,<label>(IRMv1)</label></formula><p>where ? becomes the entire invariant predictor, w = 1.0 is a scalar and fixed "dummy" classifier, the gradient norm penalty is used to measure the optimality of the dummy classifier at each environment e, and ? ? [0, ?) is a regularizer balancing between predictive power (an ERM term), and the invariance of the predictor 1 ? ?(x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">From (IRM) to (IRMv1)</head><p>This section is a voyage circumventing the subtle optimization issues lurking behind the idealistic objective (IRM), to arrive to the efficient proposal (IRMv1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Phrasing the constraints as a penalty</head><p>We translate the hard constraints in (IRM) into the penalized loss</p><formula xml:id="formula_4">L IRM (?, w) = e?Etr R e (w ? ?) + ? ? D(w, ?, e)<label>(1)</label></formula><p>where ? : X ? H, the function D(w, ?, e) measures how close w is to minimizing R e (w ? ?), and ? ? [0, ?) is a hyper-parameter balancing predictive power and invariance. In practice, we would like D(w, ?, e) to be differentiable with respect to ? and w. Next, we consider linear classifiers w to propose one alternative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Choosing a penalty D for linear classifiers w</head><p>Consider learning an invariant predictor w ? ?, where w is a linear-least squares regression, and ? is a nonlinear data representation. In the sequel, all vectors v ? R d are by default in column form, and we denote by v ? R 1?d the row form. By the normal equations, and given a fixed data representation ?, we can write w e ? ? arg minw R e (w ? ?) as:</p><formula xml:id="formula_5">w e ? = E X e ?(X e )?(X e ) ?1 E X e ,Y e [?(X e )Y e ] ,<label>(2)</label></formula><p>where we assumed invertibility. This analytic expression would suggest a simple discrepancy between two linear least-squares classifiers:</p><formula xml:id="formula_6">D dist (w, ?, e) = w ? w e ? 2 .</formula><p>(3) <ref type="figure" target="#fig_1">Figure 1</ref> uses Example 1 to show why D dist is a poor discrepancy. The blue curve shows (3) as we vary the coefficient c for a linear data representation ?(x) = x?Diag([1, c]), and w = (1, 0). The coefficient c controls how much the representation depends on the variable X 2 , responsible for the spurious correlations in Example 1. We observe that (3) is discontinuous at c = 0, the value eliciting the invariant predictor. This happens because when c approaches zero without being exactly zero, the least-squares rule (2) compensates this change by creating vectors w e ? whose second coefficient grows to infinity. This causes a second problem, the penalty approaching zero as c ? ?. The orange curve shows that adding severe regularization to the least-squares regression does not fix these numerical problems.</p><p>To circumvent these issues, we can undo the matrix inversion in (2) to construct:</p><formula xml:id="formula_7">D lin (w, ?, e) = E X e ?(X e )?(X e ) w ? E X e ,Y e [?(X e )Y e ] 2 ,<label>(4)</label></formula><p>which measures how much does the classifier w violate the normal equations. The green curve in <ref type="figure" target="#fig_1">Figure 1</ref> shows D lin as we vary c, when setting w = (1, 0). The The na?ve approach of measuring the distance between optimal classifiers D dist leads to a discontinuous penalty (solid blue unregularized, dashed orange regularized). In contrast, the penalty D lin does not exhibit these problems.</p><p>penalty D lin is smooth (it is a polynomial on both ? and w), and achieves an easy-to-reach minimum at c = 0 -the data representation eliciting the invariant predictor. Furthermore, D lin (w, ?, e) = 0 if and only if w ? arg minw R e (w ? ?). As a word of caution, we note that the penalty D lin is non-convex for general ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Fixing the linear classifier w</head><p>Even when minimizing (1) over (?, w) using D lin , we encounter one issue. When considering a pair (??, 1 ? w), it is possible to let D lin tend to zero without impacting the ERM term, by letting ? tend to zero. This problem arises because (1) is severely over-parametrized. In particular, for any invertible mapping ?, we can re-write our invariant predictor as</p><formula xml:id="formula_8">w ? ? = w ? ? ?1 w ? (? ? ?) ? .</formula><p>This means that we can re-parametrize our invariant predictor as to give w any non-zero valuew of our choosing. Thus, we may restrict our search to the data representations for which all the environment optimal classifiers are equal to the same fixed vectorw. In words, we are relaxing our recipe for invariance into finding a data representation such that the optimal classifier, on top of that data representation, is "w" for all environments. This turns (1) into a relaxed version of IRM, where optimization only happens over ?:</p><formula xml:id="formula_9">L IRM,w=w (?) = e?Etr R e (w ? ?) + ? ? D lin (w, ?, e).<label>(5)</label></formula><p>As ? ? ?, solutions (? * ? ,w) of (5) tend to solutions (? * ,w) of (IRM) for linearw.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Scalar fixed classifiersw are sufficient to monitor invariance</head><p>Perhaps surprisingly, the previous section suggests thatw = (1, 0, . . . , 0) would be a valid choice for our fixed classifier. In this case, only the first component of the data representation would matter! We illustrate this apparent paradox by providing a complete characterization for the case of linear invariant predictors. In the following theorem, matrix ? ? R p?d parametrizes the data representation function, vector w ? R p the simultaneously optimal classifier, and v = ? w the predictor w ? ?.</p><formula xml:id="formula_10">Theorem 4. For all e ? E, let R e : R d ? R be convex differentiable cost functions. A vector v ? R d can be written v = ? w, where ? ? R p?d , and where w ? R p simultaneously minimize R e (w ? ?) for all e ? E, if and only if v ?R e (v) = 0 for all e ? E.</formula><p>Furthermore, the matrices ? for which such a decomposition exists are the matrices whose nullspace Ker(?) is orthogonal to v and contains all the ?R e (v).</p><p>So, any linear invariant predictor can be decomposed as linear data representations of different ranks. In particular, we can restrict our search to matrices ? ? R 1?d and letw ? R 1 be the fixed scalar 1.0. This translates (5) into:</p><formula xml:id="formula_11">L IRM,w=1.0 (? ) = e?Etr R e (? ) + ? ? D lin (1.0, ? , e).<label>(6)</label></formula><p>Section 4 shows that the existence of decompositions with high-rank data representation matrices ? are key to out-of-distribution generalization, regardless of whether we restrict IRM to search for rank-1 ? . Geometrically, each orthogonality condition v ?R e (v) = 0 in Theorem 4 defines a (d?1)-dimensional manifold in R d . Their intersection is itself a manifold of dimension greater than d?m, where m is the number of environments. When using the squared loss, each condition is a quadratic equation whose solutions form an ellipsoid in R d . <ref type="figure" target="#fig_2">Figure 2</ref> shows how their intersection is composed of multiple connected components, one of which contains the trivial solution v = 0. This shows that (6) remains nonconvex, and therefore sensitive to initialization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.5">Extending to general losses and multivariate outputs</head><p>Continuing from <ref type="formula" target="#formula_11">(6)</ref>, we obtain our final algorithm (IRMv1) by realizing that the invariance penalty (4), introduced for the least-squares case, can be written as a general function of the risk, namely D(1.0, ?, e) = ? w|w=1.0 R e (w ? ?) 2 , where ? is again a possibly nonlinear data representation. This expression measures the optimality of the fixed scalar classifier w = 1.0 for any convex loss, such as the cross-entropy. If the target space Y returned by ? has multiple outputs, we multiply all of them by the fixed scalar classifier w = 1.0.</p><formula xml:id="formula_12">? v 1 2 ? v 2 2</formula><p>Solutions intersections of ellipsoids : zero is a solution </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation details</head><p>When estimating the objective (IRMv1) using mini-batches for stochastic gradient descent, one can obtain an unbiased estimate of the squared gradient norm as</p><formula xml:id="formula_13">b k=1 ? w|w=1.0 (w ? ?(X e,i k ), Y e,i k ) ? ? w|w=1.0 (w ? ?(X e,j k ), Y e,j k ) ,</formula><p>where (X e,i , Y e,i ) and (X e,j , Y e,j ) are two random mini-batches of size b from environment e, and is a loss function. We offer a PyTorch example in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">About nonlinear invariances w</head><p>How restrictive is it to assume that the invariant optimal classifier w is linear? One may argue that given a sufficiently flexible data representation ?, it is possible to write any invariant predictor as 1.0 ? ?. However, enforcing a linear invariance may grant non-invariant predictors a penalty D lin equal to zero. For instance, the null data representation ? 0 (X e ) = 0 admits any w as optimal amongst all the linear classifiers for all environments. But, the elicited predictor w ? ? 0 is not invariant in cases where E[Y e ] = 0. Such null predictor would be discarded by the ERM term in the IRM objective. In general, minimizing the ERM term R e (w ? ?) will drive ? so thatw is optimal amongst all predictors, even ifw is linear. We leave for future work several questions related to this issue. Are there noninvariant predictors that would not be discarded by either the ERM or the invariance term in IRM? What are the benefits of enforcing non-linear invariances w belonging to larger hypothesis classes W? How can we construct invariance penalties D for non-linear invariances?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Invariance, causality and generalization</head><p>The newly introduced IRM principle promotes low error and invariance across training environments E tr . When do these conditions imply invariance across all environments E all ? More importantly, when do these conditions lead to low error across E all , and consequently out-of-distribution generalization? And at a more fundamental level, how does statistical invariance and out-of-distribution generalization relate to concepts from the theory of causation?</p><p>So far, we have omitted how different environments should relate to enable out-of-distribution generalization. The answer to this question is rooted in the theory of causation. We begin by assuming that the data from all the environments share the same underlying Structural Equation Model, or SEM <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b38">39]</ref>:</p><formula xml:id="formula_14">Definition 5. A Structural Equation Model (SEM) C := (S, N ) governing the random vector X = (X 1 , . . . , X d )</formula><p>is a set of structural equations:</p><formula xml:id="formula_15">S i : X i ? f i (Pa(X i ), N i ),</formula><p>where Pa(X i ) ? {X 1 , . . . , X d } \ {X i } are called the parents of X i , and the N i are independent noise random variables. We say that "X i causes X j " if X i ? Pa(X j ). We call causal graph of X to the graph obtained by drawing i) one node for each X i , and ii) one edge from X i to X j if X i ? Pa(X j ). We assume acyclic causal graphs.</p><p>By running the structural equations of a SEM C according to the topological ordering of its causal graph, we can draw samples from the observational distribution P (X). In addition, we can manipulate (intervene) an unique SEM in different ways, indexed by e, to obtain different but related SEMs C e . Definition 6. Consider a SEM C = (S, N ). An intervention e on C consists of replacing one or several of its structural equations to obtain an intervened SEM C e = (S e , N e ), with structural equations:</p><formula xml:id="formula_16">S e i : X e i ? f e i (Pa e (X e i ), N e i ),</formula><p>The variable X e is intervened if S i = S e i or N i = N e i . Similarly, by running the structural equations of the intervened SEM C e , we can draw samples from the interventional distribution P (X e ). For instance, we may consider Example 1 and intervene on X 2 , by holding it constant to zero, thus replacing the structural equation of X 2 by X e 2 ? 0. Admitting a slight abuse of notation, each intervention e generates a new environment e with interventional distribution P (X e , Y e ). Valid interventions e, those that do not destroy too much information about the target variable Y , form the set of all environments E all .</p><p>Prior work <ref type="bibr" target="#b39">[40]</ref> considered valid interventions as those that do not change the structural equation of Y , since arbitrary interventions on this equation render prediction impossible. In this work, we also allow changes in the noise variance of Y , since varying noise levels appear in real problems, and these do not affect the optimal prediction rule. We formalize this as follows.</p><p>Definition 7. Consider a SEM C governing the random vector (X 1 , . . . , X d , Y ), and the learning goal of predicting Y from X. Then, the set of all environments E all (C) indexes all the interventional distributions P (X e , Y e ) obtainable by valid interventions e. An intervention e ? E all (C) is valid as long as (i) the causal graph remains acyclic,</p><formula xml:id="formula_17">(ii) E[Y e |Pa(Y )] = E[Y |Pa(Y )], and (iii) V[Y e |Pa(Y )] remains within a finite range.</formula><p>Condition (iii) can be waived if one takes into account environment specific baselines into the definition of R OOD , similar to those appearing in the robust learning objective R rob . We leave additional quantifications of out-of-distribution generalization for future work.</p><p>The previous definitions establish fundamental links between causation and invariance. Moreover, one can show that a predictor v : X ? Y is invariant across E all (C) if and only if it attains optimal R OOD , and if and only if it uses only the direct causal parents of Y to predict, that is, v(</p><formula xml:id="formula_18">x) = E N Y [f Y (Pa(Y ), N Y )].</formula><p>The rest of this section follows on these ideas to showcase how invariance across training environments can enable out-of-distribution generalization across all environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generalization theory for IRM</head><p>The goal of IRM is to build predictors that generalize out-of-distribution, that is, achieving low error across E all . To this end, IRM enforces low error and invariance across E tr . The bridge from low error and invariance across E tr to low error across E all can be traversed in two steps.</p><p>First, one can show that low error across E tr and invariance across E all leads to low error across E all . This is because, once the data representation ? eliciting an invariant predictor w ? ? across E all is estimated, the generalization error of w ? ? respects standard error bounds. Second, we examine the remaining condition towards low error across E all : namely, under which conditions does invariance across training environments E tr imply invariance across all environments E all ?</p><p>For linear IRM, our starting point to answer this question is the theory of Invariant Causal Prediction (ICP) <ref type="bibr" target="#b39">[40,</ref><ref type="bibr">Theorem 2]</ref>. There, the authors prove that ICP recovers the target invariance as long as the data (i) is Gaussian, (ii) satisfies a linear SEM, and (iii) is obtained by certain types of interventions. Theorem 9 shows that IRM learns such invariances even when these three assumptions fail to hold. In particular, we allow for non-Gaussian data, dealing with observations produced as a linear transformation of the variables with stable and spurious correlations, and do not require specific types of interventions or the existence of a causal graph.</p><p>The setting of the theorem is as follows. Y e has an invariant correlation with an unobserved latent variable Z e 1 by a linear relationship Y e = Z e 1 ? ? + e , with e independent of Z e 1 . What we observe is X e , which is a scrambled combination of Z e 1 and another variable Z e 2 that can be arbitrarily correlated with Z e 1 and e . Simply regressing using all of X e will then recklessly exploit Z e 2 (since it gives extra, but spurious, information on e and thus Y e ). A particular instance of this setting is when Z e 1 is the cause of Y e , Z e 2 is an effect, and X e contains both causes and effects. To generalize out of distribution the representation has to discard Z e 2 and keep Z e 1 .</p><p>Before showing Theorem 9, we need to make our assumptions precise. To learn useful invariances, one must require some degree of diversity across training environments. On the one hand, extracting two random subsets of examples from a large dataset does not lead to diverse environments, as both subsets would follow the same distribution. On the other hand, splitting a large dataset by conditioning on arbitrary variables can generate diverse environments, but may introduce spurious correlations and destroy the invariance of interest <ref type="bibr" target="#b39">[40,</ref><ref type="bibr">Section 3.3</ref>]. Therefore, we will require sets of training environments containing sufficient diversity and satisfying an underlying invariance. We formalize the diversity requirement as needing envirnments to lie in linear general position. </p><formula xml:id="formula_19">dim span E X e X e X e x ? E X e , e [X e e ] e?Etr &gt; d ? r.</formula><p>Intuitively, the assumption of linear general position limits the extent to which the training environments are co-linear. Each new environment laying in linear general position will remove one degree of freedom in the space of invariant solutions. Fortunately, Theorem 10 shows that the set of cross-products E X e [X e X e ] not satisfying a linear general position has measure zero. Using the assumption of linear general position, we can show that the invariances that IRM learns across training environments transfer to all environments.</p><p>In words, the next theorem states the following. If one finds a representation ? of rank r eliciting an invariant predictor w ? ? across E tr , and E tr lie in linear general position of degree r, then w ? ? is invariant across E all .</p><p>Theorem 9. Assume that Y e = Z e 1 ? ? + e , Z e 1 ? e , E[ e ] = 0, X e = S(Z e 1 , Z e 2 ).</p><p>Here, ? ? R c , Z e 1 takes values in R c , Z e 2 takes values in R q , and S ? R d?(c+q) . Assume that the Z 1 component of S is invertible: that there existsS ? R c?d such thatS (S(z 1 , z 2 )) = z 1 , for all</p><formula xml:id="formula_20">z 1 ? R c , z 2 ? R q . Let ? ? R d?d have rank r &gt; 0.</formula><p>Then, if at least d ? r + d r training environments E tr ? E all lie in linear general position of degree r, we have that</p><formula xml:id="formula_21">? E X e X e X e ? w = ? E X e ,Y e [X e Y e ]<label>(7)</label></formula><p>holds for all e ? E tr iff ? elicits the invariant predictor ? w for all e ? E all .</p><p>The assumptions about linearity, centered noise, and independence between the noise e and the causal variables Z 1 from Theorem 9 also appear in ICP [40, Assumption 1], implying the invariance E[Y e |Z e 1 = z 1 ] = z 1 ? ?. As in ICP, we allow correlations between e and the non-causal variables Z e 2 , which leads ERM into absorbing spurious correlations (as in our Example 1, where S = I and Z e 2 = X e 2 ). In addition, our result contains several novelties. First, we do not assume that the data is Gaussian, the existence of a causal graph, or that the training environments arise from specific types of interventions. Second, the result extends to "scrambled setups" where S = I. These are situations where the causal relations are not defined on the observable features X, but on a latent variable (Z 1 , Z 2 ) that IRM needs to recover and filter. Third, we show that representations ? with higher rank need fewer training environments to generalize. This is encouraging, as representations with higher rank destroy less information about the learning problem at hand.</p><p>We close this section with two important observations. First, while robust learning generalizes across interpolations of training environments (recall Proposition 2), learning invariances with IRM buys extrapolation powers. We can observe this in Example 1 where, using two training environments, robust learning yields predictors that work well for ? ? <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20]</ref>, while IRM yields predictors that work well for all ?. Finally, IRM is a differentiable function with respect to the covariances of the training environments. Therefore, in cases when the data follows an approximately invariant model, IRM should return an approximately invariant solution, being robust to mild model misspecification. This is in contrast to common causal discovery methods based on thresholding statistical hypothesis tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">On the nonlinear case and the number of environments</head><p>In the same vein as the linear case, we could attempt to provide IRM with guarantees for the nonlinear regime. Namely, we could assume that each constraint ? w|w=1.0 R e (w ? ?) = 0 removes one degree of freedom from the possible set of solutions ?. Then, for a sufficiently large number of diverse training environments, we would elicit the invariant predictor. Unfortunately, we were unable to phrase such a "nonlinear general position" assumption and prove that it holds almost everywhere, as we did in Theorem 10 for the linear case. We leave this effort for future work.</p><p>While general, Theorem 9 is pessimistic, since it requires the number of training environments to scale linearly with the number of parameters in the representation matrix ?. Fortunately, as we will observe in our experiments from Section 5, it is often the case that two environments are sufficient to recover invariances. We believe that these are problems where E[Y e |?(X e )] cannot match for two different environments e = e unless ? extracts the causal invariance. The discussion from Section 3.3 gains relevance here, since enforcing W-invariance for larger families W should allow discarding more non-invariant predictors with fewer training environments. All in all, studying what problems allow the discovery of invariances from few environments is a promising line of work towards a learning theory of invariance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Causation as invariance</head><p>We promote invariance as the main feature of causation. Unsurprisingly, we are not pioneers in doing so. To predict the outcome of an intervention, we rely on (i) the properties of our intervention and (ii) the properties assumed invariant after the intervention. Pearl's do-calculus <ref type="bibr" target="#b38">[39]</ref> on causal graphs is a framework that tells which conditionals remain invariant after an intervention. Rubin's ignorability <ref type="bibr" target="#b43">[44]</ref> plays the same role. What's often described as autonomy of causal mechanisms <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b0">1]</ref> is a specification of invariance under intervention. A large body of philosophical work <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b12">13]</ref> studies the close link between invariance and causation. Some works in machine learning <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b6">7]</ref> pursue similar questions.</p><p>The invariance view of causation transcends some of the difficulties of working with causal graphs. For instance, the ideal gas law P V = nRT or Newton's universal gravitation F = G m1m2 r 2 are difficult to describe using structural equation models (What causes what? ), but are prominent examples of laws that are invariant across experimental conditions. When collecting data about gases or celestial bodies, the universality of these laws will manifest as invariant correlations, which will sponsor valid predictions across environments, as well as the conception of scientific theories.</p><p>Another motivation supporting the invariance view of causation are the problems studied in machine learning. For instance, consider the task of image classification. Here, the observed variables are hundreds of thousands of correlated pixels. What is the causal graph governing them? It is reasonable to assume that causation does not happen between pixels, but between the real-world concepts captured by the camera. In these cases, invariant correlations in images are a proxy into the causation at play in the real world. To find those invariant correlations, we need methods which can disentangle the observed pixels into latent variables closer to the realm of causation, such as IRM. In rare occasions we are truly interested in the entire causal graph governing all the variables in our learning problem. Rather, our focus is often on the causal invariances improving generalization across novel distributions of examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We perform two experiments to assess the generalization abilities of IRM across multiple environments. The source-code is available at https://github.com/facebookresearch/InvariantRiskMinimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Synthetic data</head><p>As a first experiment, we extend our motivating Example 1. First, we increase the dimensionality of each of the two input features in X = (X 1 , X 2 ) to 10 dimensions. Second, as a form of model misspecification, we allow the existence of a 10-dimensional hidden confounder variable H. Third, in some cases the features Z will not be directly observed, but only a scrambled version X = S(Z). <ref type="figure">Figure 3</ref> summarizes the SEM generating the data (X e , Y e ) for all environments e in these experiments. More specifically, for environment e ? R, we consider the following variations:</p><p>? Scrambled (S) observations, where S is an orthogonal matrix, or unscrambled (U) observations, where S = I.</p><p>? Fully-observed (F) graphs, where W h?1 = W h?y = W h?2 = 0, or partially-observed (P) graphs, where (W h?1 , W h?y , W h?2 ) are Gaussian.</p><p>? Homoskedastic (O) Y -noise, where ? 2 y = e 2 and ? 2 2 = 1, or heteroskedastic (E) Y -noise, where ? 2 y = 1 and ? 2 2 = e 2 . <ref type="figure">Figure 3</ref>: In our synthetic experiments, the task is to predict Y e from X e = S(Z e 1 , Z e 2 ).</p><formula xml:id="formula_22">H e Z e 1 Y e Z e 2 H e ? N (0, e 2 ) Z e 1 ? N (0, e 2 ) + W h?1 H e Y e ? Z e 1 ? W 1?y + N (0, ? 2 y ) + W h?y H e Z e 2 ? W y?2 Y e + N (0, ? 2 2 ) + W h?2 H e</formula><p>These variations lead to eight setups referred to by their initials. For instance, the setup "FOS" considers fully-observed (F), homoskedastic Y -noise (O), and scrambled observations (S). For all variants, (W 1?y , W y?2 ) have Gaussian entries. Each experiment draws 1000 samples from the three training environments E tr = {0.2, 2, 5}. IRM follows the variant (IRMv1), and uses the environment e = 5 to cross-validate the invariance regularizer ?. We compare to ERM and ICP <ref type="bibr" target="#b39">[40]</ref>. <ref type="figure" target="#fig_4">Figure 4</ref> summarizes the results of our experiments. We show two metrics for each estimated prediction rule? = X 1 ?? 1?y + X 2 ?? y?2 . To this end, we consider a descrambled version of the estimated coefficients (M 1?y ,M y?2 ) = (? 1?y ,? y?2 ) S . First, the plain barplots shows the average squared error betweenM 1?y and W 1?y . This measures how well does a predictor recover the weights associated to the causal variables. Second, each striped barplot shows the norm of estimated weightsM y?2 associated to the non-causal variable. We would like this norm to be zero, as the desired invariant causal predictor is? e = (W 1?y , 0) S (X e 1 , X e 2 ). In summary, IRM is able to estimate the most accurate causal and non-causal weights across all experimental conditions. In most cases, IRM is orders of magnitude more accurate than ERM (our y-axes are in log-scale). IRM also out-performs ICP, the previous state-of-the-art method, by a large margin. Our experiments also show the conservative behaviour of ICP (preferring to reject most covariates as direct causes), leading to large errors on causal weights and small errors on non-causal weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Colored MNIST</head><p>We validate IRM at learning nonlinear invariant predictors with a synthetic binary classification task derived from MNIST. The goal is to predict a binary label assigned to each image based on the digit. Whereas MNIST images are grayscale, we color each image either red or green in a way that correlates strongly (but spuriously) with the class label. By construction, the label is more strongly correlated with the color than with the digit, so any algorithm purely minimizing training error will tend to exploit the color. Such algorithms will fail at test time because the direction of the correlation is reversed in the test environment. By observing that the strength of the correlation between color and label varies between the two training environments, we can hope to eliminate color as a predictive feature, resulting in better generalization. We define three environments (two training, one test) from MNIST transforming each example as follows: first, assign a preliminary binary label? to the image based on the digit:? = 0 for digits 0-4 and? = 1 for 5-9. Second, obtain the final label y by flipping? with probability 0.25. Third, sample the color id z by flipping y with probability p e , where p e is 0.2 in the first environment, 0.1 in the second, and 0.9 in the test one. Finally, color the image red if z = 1 or green if z = 0.</p><p>We train MLPs on the colored MNIST training environments using different objectives and report results in <ref type="table" target="#tab_0">Table 1</ref>. For each result we report the mean and standard deviation across ten runs. Training with ERM returns a model with high accuracy in the training environments but below-chance accuracy in the test environment, since the ERM model classifies mainly based on color. Training with IRM results in a model that performs worse on the training environments, but relies less on the color and hence generalizes better to the test environments. An oracle that ignores color information by construction outperforms IRM only slightly.</p><p>To better understand the behavior of these models, we take advantage of the fact that h = ?(x) (the logit) is one-dimensional and y is binary, and plot P (y = 1|h, e) as a function of h for each environment and each model in <ref type="figure" target="#fig_5">Figure 5</ref>. We show each algorithm in a separate plot, and each environment in a separate color. The figure shows that, whether considering only the two training environments or all three  environments, the IRM model is closer to achieving invariance than the ERM model. Notably, the IRM model does not achieve perfect invariance, particularly at the tails of the P (h). We suspect this is due to finite sample issues: given the small sample size at the tails, estimating (and hence minimizing) the small differences in P (y|h, e) between training environments can be quite difficult, regardless of the method. We note that conditional domain adaptation techniques which match P (h|y, e) across environments could in principle solve this task equally well to IRM, which matches P (y|h, e). This is because the distribution of the causal features (the digit shapes) and P (y|e) both happen to be identical across environments. However, unlike IRM, conditional domain adaptation will fail if, for example, the distribution of the digits changes across environments. We discuss this further in Appendix C.</p><p>Finally, <ref type="figure" target="#fig_5">Figure 5</ref> shows that P (y = 1|h) cannot always be expressed with a linear classifier w. Enforcing nonlinear invariances (Section 3.3) could prove useful here. phenomena. After all, ERM is an optimal principle to learn predictors from empirical data! Irma: It is, indeed. But even when your hypothesis class allows you to find the empirical risk minimizer efficiently, there are some assumptions at play. First, ERM assumes that training and testing data are identically and independently distributed according to the same distribution. Second, generalization bounds require that the ratio between the capacity of our hypothesis class and the number of training examples n tends to zero, as n ? ?. Third, ERM achieves zero test error only in the realizable case -that is, when there exists a function in our hypothesis class able to achieve zero error. I suspect that violating these assumptions leads ERM into absorbing spurious correlations, and that this is where invariance may prove useful. Eric: Interesting. Should we study the three possibilities in turn? Irma: Sure thing! But first, let's grab another cup of coffee.</p><p>[We also encourage the reader to grab a cup of coffee.] ? Irma: First and foremost, we have the "identically and independently distributed" (iid) assumption. I once heard Professor Ghahramani refer to this assumption as "the big lie in machine learning". This is to say that all training and testing examples are drawn from the same distribution P (X, Y ) = P (Y |X)P (X). Eric: I see. This is obviously not the case when learning from multiple environments, as in IRM. Given this factorization, I guess two things are subject to change: either the marginal distribution P (X) of my inputs, or the conditional distribution P (Y |X) mapping those inputs into my targets. Irma: That's correct. Let's focus first on the case where P (X e ) changes across environments e. Some researchers from the field of domain adaptation call this covariate shift. This situation is challenging when the supports of P (X e ) are disjoint across environments. Actually, without a-priori knowledge, there is no reason to believe that our predictor will generalize outside the union of the supports of the training environments.</p><p>Eric: A daunting challenge, indeed. How could invariance help here? Irma: Two things come to mind. On the one hand, we could try to transform our inputs into some features ?(X e ), as to match the support of all the training environments. Then, we could learn an invariant classifier w(?(X e )) on top of the transformed inputs. [Appendix D studies the shortcomings of this idea.] On the other hand, we could assume that the invariant predictor w has a simple structure, that we can estimate given limited supports. The authors of IRM follow this route, by assuming linear classifiers on top of representations. Eric: I see! Even though the P (X e ) may be disjoint, if there is a simple invariance satisfied for all training environments separately, it may also hold in unobserved regions of the space. I wonder if we could go further by assuming some sort of compositional structure in w, the linear assumption of IRM is just the simplest kind. I say this since compositional assumptions often enable learning in one part of the input space, and evaluating on another. Irma: It sounds reasonable! What about the case where P (Y e |X e ) changes?</p><p>Does this happen in normal supervised learning? I remember attending a lecture by Professor Sch?lkopf <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b24">25]</ref> where he mentioned that P (Y e |X e ) is often invariant across environments when X e is a cause of Y e , and that it often varies when X e is an effect of Y e . For instance, he explains that MNIST classification is anticausal: as in, the observed pixels are an effect of the mental concept that led the writer to draw the digit in the first place. IRM insists on this relation between invariance and causation, what do you think? Eric: I saw that lecture too. Contrary to Professor Sch?lkopf, I believe that most supervised learning problems, such as image classification, are causal.</p><p>In these problems we predict human annotations Y e from pixels X e , hoping that the machine imitates this cognitive process. Furthermore, the annotation process often involves multiple humans in the interest of making P (Y e |X e ) deterministic. If the annotation process is close to deterministic and shared across environments, predicting annotations is a causal problem, with an invariant conditional expectation. Irma: Oh! This means that in supervised learning problems about predicting annotations, P (Y e |X e ) is often stable across environments, so ERM has great chances of succeeding. This is good news: it explains why ERM is so good at supervised learning, and leaves less to worry about. Eric: However, if any of the other problems appear (disjoint P (X e ), not enough data, not enough capacity), ERM could get in trouble, right? Irma: Indeed! Furthermore, in some supervised learning problems, the label is not necessarily created from the input. For instance, the input could be an X-ray image, and the target could be the result of a tumor biopsy on the same patient. Also, there are problems where we predict parts of the input from other parts of the input, like in self-supervised learning <ref type="bibr" target="#b13">[14]</ref>. In some other cases, we don't even have labels! This could include the unsupervised learning of the causal factors of variation behind X e , which involves inverting the causal generative process of the data. In all of these cases, we could be dealing with anticausal problems, where the conditional distribution is subject to change across environments. Then, I expect searching for invariance may help by focusing on invariant predictors that generalize out-of-distribution. Eric: That is an interesting divide between supervised and unsupervised learning! [ <ref type="figure" target="#fig_7">Figure 6</ref> illustrates the main elements of this discussion.]   <ref type="bibr" target="#b55">[56]</ref>. In these cases, such ratio will not tend to zero as n ? ?. So, ERM may be in trouble. Irma: That is correct. Neural networks are often over-parametrized, and over-parametrization carries subtle consequences. For instance, consider that we are using the pseudo-inverse to solve an over-parametrized linear least-squares problem, or using SGD to train an over-parametrized neural network. Amongst all the zero training error solutions, these procedures will prefer the solution with the smallest capacity <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b2">3]</ref>. Unfortunately, spurious correlations and biases are often simpler to detect than the true phenomenon of interest <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref>. Therefore, low capacity solutions prefer exploiting those simple but spurious correlations. For instance, think about relying on large green textures to declare the presence of a cow on an image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nature variables pixels</head><p>Eric: The cows again! Irma: Always. Although I can give you a more concrete example. Consider predicting Y e from X e = (X e 1 , X e 2 ), where:</p><p>Y e ? 10 6 ? X e 1 ? 1 , X e 2 ? 10 6 ? Y e ? 2 ? e, the coefficients satisfy ? 1 = ? 2 = 1, the training environments are e = {1, 10}, and we have n samples for the 2n-dimensional input X. In this over-parametrized problem, the invariant regression from the cause X 1 requires large capacity, while the spurious regression from the effect X 2 requires low capacity. Eric: Oh! Then, the inductive bias of SGD would prefer to exploit the spurious correlation for prediction. In a nutshell, a deficit of training examples forces us into regularization, and regularization comes with the danger of absorbing easy spurious correlations. But, methods based on invariance should realize that, after removing the nuisance variable X 2 , the regression from X 1 is invariant, and thus interesting for out-ofdistribution generalization. This means that invariance could sometimes help fight the issues of small data and over-parametrization. Neat! ? Irma: As a final obstacle to ERM, we have the case where the capacity of our hypothesis class is insufficient to solve the learning problem at hand. Eric: This sounds related to the previous point, in the sense that a model with low capacity will stick to spurious correlations, if these are easier to capture. Irma: That is correct, although I can see an additional problem arising from insufficient capacity. For instance, the only linear invariant prediction rule to estimate the quadratic Y e = (X e ) 2 , where X e ? Gaussian(0, e), is the null predictor Y = 0 ? X. Even though X is the only, causal, and invariance-eliciting covariate! Eric: Got it. Then, we should expect invariance to have a larger chance of success when allowing high capacity. For low-capacity problems, I would rely on cross-validation to lower the importance of the invariance penalty in IRM, and fall back to good old ERM. Irma: ERM is really withstanding the test of time, isn't it? Eric: Definitely. From what we have discussed before, I think ERM is specially useful in the realizable case, when there is a predictor in my hypothesis class achieving zero error. Irma: Why so? Eric: In the realizable case, the optimal invariant predictor has zero error across all environments. Therefore it makes sense, as an empirical principle, to look for zero training error across training environments. This possibly moves towards an optimal prediction rule on the union of the supports of the training environments. This means that achieving invariance across all environments using ERM is possible in the realizable case, although it would require data from lots of environments! Irma: Wait a minute. Are you saying that achieving zero training error makes sense from an invariance perspective? Eric: In the realizable case, I would say so! Turns out all these people training neural networks to zero training error were onto something! ? [ The barista approaches Eric and Irma to let them know that the caf? is closing. ]</p><p>Eric: Thank you for the interesting chat, Irma. Irma: The pleasure is mine! Eric: One of my takeaways is that discarding spurious correlations is something doable even when we have access only to two environments. The remaining, invariant correlations sketch the core pieces of natural phenomena, which in turn form a simpler model. Irma: Simple models for a complex world. Why bother with the details, right? Eric: Hah, right. It seems like regularization is more interesting than we thought. IRM is a learning principle to discover unknown invariances from data. This differs from typical regularization techniques to enforce known invariances, often done by architectural choices (using convolutions to achieve translation invariance) and data augmentation. I wonder what other applications we can find for invariance. Perhaps we could think of reinforcement learning episodes as different environments, so we can learn robust policies that leverage the invariant part of behaviour leading to reward. Irma: That is an interesting one. I was also thinking that invariance has something to say about fairness. For instance, we could consider different groups as environments. Then, learning an invariant predictor means finding a representation such that the best way to treat individuals with similar relevant features is shared across groups. Eric: Interesting! I was also thinking that it may be possible to formalize IRM in terms of invariance and equivariance concepts from group theory. Do you want to take a stab at these things tomorrow at the lab?  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Proof of Theorem 4</head><p>Let ? ? R p?d , w ? R p , and v = ? w. The simultaneous optimization</p><formula xml:id="formula_23">?e w ? arg min w?R p R e (w ? ?)<label>(8)</label></formula><p>is equivalent to</p><formula xml:id="formula_24">?e v ? arg min v?G? R e (v),<label>(9)</label></formula><p>where G ? = {? w : w ? R p } ? R d is the set of vectors v = ? w reachable by picking any w ? R p . It turns out that G ? = Ker(?) ? , that is, the subspace orthogonal to the nullspace of ?. Indeed, for all v = ? w ? G ? and all x ? Ker(?),</p><p>we have x v = x ? w = (?x) w = 0. Therefore G ? ? Ker(?) ? . Since both subspaces have dimension rank(?) = d ? dim(Ker(?)), they must be equal. We now prove the theorem:</p><formula xml:id="formula_25">let v = ? w where ? ? R p?d and w ? R p minimizes all R e (w ? ?). Since v ? G ? , we have v ? Ker(?) ? . Since w minimizes R e (? w), we can also write ? ?w R e (? w) = ? ?R e (? w) = ??R e (v) = 0 .<label>(10)</label></formula><p>Therefore</p><formula xml:id="formula_26">?R e (v) ? Ker(?). Finally v ?R e (v) = w ? ?R e (? w) = 0.</formula><p>Conversely, let v ? R d satisfy v ?R e (v) = 0 for all e ? E. Thanks to these orthogonality conditions, we can construct a subspace that contains all the ?R e (v) and is orthogonal to v. Let ? be any matrix whose nullspace satisfies these conditions. <ref type="formula" target="#formula_4">(10)</ref> is zero.</p><formula xml:id="formula_27">Since v ? Ker(?), that is, v ? Ker(?) ? = G ? , there is a vector w ? R p such that v = ? w. Finally, since ?R e (v) ? Ker(?), the derivative</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Proof of Theorem 9</head><p>Observing that ? E X e ,Y e [X e Y e ] = ? E X e , e [X e ((SX e ) ? + e )], we re-write <ref type="formula" target="#formula_21">(7)</ref> as</p><formula xml:id="formula_28">? ? ? ? ? E X e X e X e (? w ?S ?) ? E X e , e [X e e ] :=qe ? ? ? ? = 0.<label>(11)</label></formula><p>To show that ? leads to the desired invariant predictor ? w =S ?, we assume ? w =S ? and reach a contradiction. First, by Assumption 8, we have dim(span({q e } e?Etr )) &gt; d ? r. Second, by <ref type="bibr" target="#b10">(11)</ref>, each q e ? Ker(?). Therefore, it would follow that dim(Ker(?)) &gt; d ? r, which contradicts the assumption that rank(?) = r.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Proof of Theorem 10</head><p>Let m = |E tr |, and define G : R d \ {0} ? R m?d as (G(x)) e,i = ? e X,X x ? ? e X, i . Let W = G R d \ {0} ? R m?d , which is a linear manifold of dimension at most d, missing a single point (since G is affine, and its input has dimension d).</p><p>For the rest of the proof, let (? e X, ) e?Etr ? R d |Etr| be arbitrary and fixed. We want to show that for generic (? e X,X ) e?Etr , if m &gt; d r + d ? r, the matrices G(x) have rank larger than d ? r. Analogously, if LR(m, d, k) ? R m?d is the set of m ? d matrices with rank k, we want to show that W ? LR(m, d, k) = ? for all k &lt; d ? r.</p><p>We need to prove two statements. First, that for generic(? e X,X ) e?Etr W and LR(m, d, k) intersect transversally as manifolds, or don't intersect at all. This will be a standard argument using Thom's transversality theorem. Second, by dimension counting, that if W and LR(m, d, k) intersect transversally, and k &lt; d ? r, m &gt; d r + d ? r, then the dimension of the intersection is negative, which is a contradiction and thus W and LR(m, d, k) cannot intersect.</p><p>We then claim that W and LR(m, d, k) are transversal for generic (? e X,X ) e?Etr . To do so, define F :</p><formula xml:id="formula_29">(R d \ {0}) ? S d?d + m ? R m?d , F x, ? e X,X e?Etr e l = ? e X,X x ? ? e X, l</formula><p>If we show that ? x,? X,X F : R d ? (S d?d ) m ? R m?d is a surjective linear transformation, then F is transversal to any submanifold of R m?d (and in particular to LR(m, d, k)). By the Thom transversality theorem, this implies that the set of ? e X,X e?Etr such that W is not transversal to LR(m, d, k) has measure zero in S d?d + , proving our first statement.</p><p>Next, we show that ? x,? X,X F is surjective. This follows by by showing that ? ? X,X F : (S d?d ) m ? R m?d is surjective, since adding more columns to this matrix can only increase its rank. We then want to show that the linear map ? ? X,X F : (S d?d ) m ? R m?d is surjective. To this end, we can write: ? ? e i,j F e l = ? e,e (? l,i x j + ? l,j x i ) , and let C ? R m?d . We want to construct a D ? S d?d m such that C e l = i,j,e ? e,e (? l,i x j + ? l,j x i ) D e i,j .</p><p>The right hand side equals</p><formula xml:id="formula_30">i,j,e ? e,e (? l,i x j + ? l,j x i ) D e i,j = j D e l,j x j + i D e i,l x i = (D e x) l + (xD e ) l</formula><p>If D e is symmetric, this equals (2D e x) l . Therefore, we only need to show that for any vector C e ? R d , there is a symmetric matrix D e ? S d?d with C e = D e x. To see this, let O ? R d?d be an orthogonal transformation such that Ox has no zero entries, and name v = Ox, w e = OC e . Furthermore, let E e ? R d?d be the diagonal matrix with entries E e i,i = w e i vi . Then, C e = O T E e Ox. By the spectral theorem, O T E e O is symmetric, showing that ? ? X,X F : (S d?d ) m ? R m?d is surjective, and thus that W and LR(m, d, k) are transversal for almost any ? e X,X e?Etr . By transversality, we know that W cannot intersect LR(m, d, k) if dim(W ) + dim (LR(m, d, k)) ? dim R m?d &lt; 0. By a dimensional argument (see <ref type="bibr" target="#b27">[28]</ref> Therefore, W ? LR(m, d, k) = ? under these conditions, finishing the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Failure cases for Domain Adaptation</head><p>Domain adaptation <ref type="bibr" target="#b4">[5]</ref> considers labeled data from a source environment e s and unlabeled data from a target environment e t with the goal of training a classifier that works well on e t . Many domain adaptation techniques, including the popular Adversarial Domain Adaptation <ref type="bibr" target="#b15">[16,</ref><ref type="bibr">ADA]</ref>, proceed by learning a feature representation ? such that (i) the input marginals P (?(X es )) = P (?(X et )), and (ii) the classifier w on top of ? predicts well the labeled data from e s . Thus, are domain adaptation techniques applicable to finding invariances across multiple environments? One shall proceed cautiously, as there are important caveats. For instance, consider a binary classification problem, where the only difference between environments is that P (Y es = 1) = 1 2 , but P (Y et = 1) = 9 10 . Using these data and the domain adaptation recipe outlined above, we build a classifier w??. Since domain adaptation enforces P (?(X es )) = P (?(X et )), it consequently enforces P (? es ) = P (? et ), wher? Y e = w(?(X e )), for all e ? {e s , e t }. Then, the classification accuracy will be at most 20%. This is worse than random guessing, in a problem where simply training on the source domain leads to a classifier that generalizes to the target domain.</p><p>Following on this example, we could think of applying conditional domain adaptation techniques [30, C-ADA]. These enforce one invariance P (?(X es )|Y es ) = P (?(X et )|Y et ) per value of Y e . Using Bayes rule, it follows that C-ADA enforces a stronger condition than invariant prediction when P (Y es ) = P (Y et ). However, there are general problems where the invariant predictor cannot be identified by C-ADA.</p><p>To see this, consider a discrete input feature X e ? P (X e ), and a binary target Y e = F (X e ) ? Bernoulli(p). This model represents a generic binary classification problem with label noise. Since the distribution P (X e ) is the only moving part across environments, the trivial representation ?(x) = x elicits an invariant prediction rule. Assuming that the discrete variable X e takes n values, we can summarize P (X e ) as the probability n-vector p x,e . Then, ?(X e ) is also discrete, and we can summarize its distribution as the probability vector p ?,e = A ? p x,e , where A ? is a matrix of zeros and ones. By Bayes rule, ? ?,e := P (?(X e )|Y e = 1) = P (Y e = 1|?(X e )) p ?,e P (Y e = 1|?(X e )), p ?,e = (A ? (v p x,e )) (A ? p x,e ) (A ? (v p x,e )) , A ? p x,e , where is the entry-wise multiplication, , is the dot product, and v := P (Y e = 1|X e ) does not depend on e. Unfortunately for C-ADA, it can be shown that the set ? ? := {(p x,e , p x,e ) : ? ?,e = ? ?,e } has measure zero. Since the union of sets with zero measure has zero measure, and there exists only a finite amount of possible A ? , the set ? ? has measure zero for any ?. In conclusion and almost surely, C-ADA disregards any non-zero data representation eliciting an invariant prediction rule, regardless of the fact that the trivial representation ?(x) = x achieves such goal. As a general remark, domain adaptation is often justified using the bound <ref type="bibr" target="#b4">[5]</ref>:</p><p>Error et (w ? ?) ? Error es (w ? ?) + Distance(?(X es ), ?(X et )) + ? .</p><p>Here, ? is the error of the optimal classifier in our hypothesis class, operating on top of ?, summed over the two domains. Crucially, ? is often disregarded as a constant, justifying the DA goals (i, ii) outlined above. But, ? depends on the data representation ?, instantiating a third trade-off that it is often ignored. For a more in depth analysis of this issue, we recommend <ref type="bibr" target="#b23">[24]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Minimal implementation of IRM in PyTorch</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>min ?:X ?H w:H?Y e?Etr R e (w ? ?) subject to w ? arg min w:H?Y R e (w ? ?), for all e ? E tr .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>DFigure 1 :</head><label>1</label><figDesc>dist ((1, 0), ?, e) D dist (heavy regularization) D lin ((1, 0), ?, e) Different measures of invariance lead to different optimization landscapes in our Example 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>The solutions of the invariant linear predictors v = ? w coincide with the intersection of the ellipsoids representing the orthogonality condition v ?R e (v) = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Assumption 8 .</head><label>8</label><figDesc>A set of training environments E tr lie in linear general position of degree r if |E tr | &gt; d ? r + d r for some r ? N, and for all non-zero x ? R d :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FOUFigure 4 :</head><label>4</label><figDesc>Average errors on causal (plain bars) and non-causal (striped bars) weights for our synthetic experiments. The y-axes are in log-scale. See main text for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>IRMFigure 5 :</head><label>5</label><figDesc>Train env. 1 (e=0.2) Train env. 2 (e=0.1) Test env. (e=0.9) P (y = 1|h) as a function of h for different models trained on Colored MNIST: (left) an ERM-trained model, (center) an IRM-trained model, and (right) an ERM-trained model which only sees grayscale images and therefore is perfectly invariant by construction. IRM learns approximate invariance from data alone and generalizes well to the test environment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>All learning problems use empirical observations, here referred to as "pixels". Following a causal and cognitive process, humans produce labels. Therefore, supervised learning problems predicting annotations from observations are causal, and therefore P (label | pixel) is often invariant. Conversely, types of unsupervised and self-supervised learning trying to disentangle the underlying data causal factors of variation (Nature variables) should to some extent reverse the process generating observations (Nature mechanisms). This leads to anticausal learning problems, possibly with varying conditional distributions; an opportunity to leverage invariance. Cat picture by www. flickr. com/ photos/ pustovit .? Eric: Secondly, what about the ratio between the capacity of our classifier and the number of training examples n? Neural networks often have a number of parameters on the same order of magnitude, or even greater, than the number of training examples</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>R</head><label></label><figDesc>e (f ) ? r e , M = max e?Etr R e (f ) ? r e . Then, the pair (f , M ) solves the constrained optimization problem min f,M M s.t. R e (f ) ? r e ? M for all e ? E tr , with Lagrangian L(f, M, ?) = M + e?Etr ? e (R e (f ) ? r e ? M ). If the problem above satisfies the KKT differentiability and qualification conditions, then there exist ? e ? 0 with ? f L(f , M , ?) = 0, such that ? f | f =f e?Etr ? e R e (f ) = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>, example 5.30), it follows that codim(LR(m, d, k)) = dim R m?d ? dim (LR(m, d, k)) = (m ? k)(d ? k). Therefore, if k &lt; d ? r and m &gt; d r + d ? r, it follows that dim(W ) + dim (LR(m, d, k)) ? dim R m?d = dim(W ) ? codim (LR(m, d, k)) ? d ? (m ? k)(d ? k) ? d ? (m ? (d ? r))(d ? (d ? r)) = d ? r(m ? d + r) &lt; d ? r d r + d ? r ? d + r = d ? d = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>import torch from torch . autograd import grad def c om pu t e_ pe na l ty ( losses , dummy_w ): g1 = grad ( losses [0::2]. mean () , dummy_w , create_graph = True )[0] g2 = grad ( losses [1::2]. mean () , dummy_w , create_graph = True )[0] return ( g1 * g2 ). sum () def example_1 ( n =10000 , d =2 , env =1): x = torch . randn (n , d ) * env y = x + torch . randn (n , d ) * env z = y + torch . randn (n , d ) return torch . cat (( x , z ) , 1) , y . sum (1 , keepdim = True ) phi = torch . nn . Parameter ( torch . ones (4 , 1)) dummy_w = torch . nn . Parameter ( torch . Tensor ([1.0])) opt = torch . optim . SGD ([ phi ] , lr =1 e -3) mse = torch . nn . MSELoss ( reduction = " none " ) environments = [ example_1 ( env =0.1) , example_1 ( env =1.0)] for iteration in range (50000): error = 0 penalty = 0 for x_e , y_e in environments : p = torch . randperm ( len ( x_e )) error_e = mse ( x_e [ p ] @ phi * dummy_w , y_e [ p ]) penalty += co mp u te _p en a lt y ( error_e , dummy_w ) error += error_e . mean () opt . zero_grad () (1 e -5 * error + penalty ). backward () opt . step () if iteration % 1000 == 0: print ( phi )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>AlgorithmAcc. train envs. Acc. test env. Accuracy (%) of different algorithms on the Colored MNIST synthetic task. ERM fails in the test environment because it relies on spurious color correlations to classify digits. IRM detects that the color has a spurious correlation with the label and thus uses only the digit to predict, obtaining better generalization to the new unseen test environment.</figDesc><table><row><cell>ERM IRM (ours) Random guessing (hypothetical)</cell><cell>87.4 ? 0.2 70.8 ? 0.9 50</cell><cell>17.1 ? 0.6 66.9 ? 2.5 50</cell></row><row><cell>Optimal invariant model (hypothetical)</cell><cell>75</cell><cell>75</cell></row><row><cell>ERM, grayscale model (oracle)</cell><cell>73.5 ? 0.2</cell><cell>73.0 ? 0.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>6</head><label></label><figDesc>Looking forward: a concluding dialogue [ Eric and Irma are two graduate students studying the Invariant Risk Minimization (IRM) manuscript. Over a cup of coffee at a caf? in Palais-Royal, they discuss the advantages and caveats that invariance brings to Empirical Risk Minimization (ERM). ] Irma: I have observed that predictors trained with ERM sometimes absorb biases and spurious correlations from data. This leads to undesirable behaviours when predicting about examples that do not follow the distribution of the training data. Eric: I have observed that too, and I wonder what are the reasons behind such</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Irma: Surely. See you tomorrow, Eric. Eric: See you tomorrow! [ The students pay their bill, leave the caf?, and stroll down the streets of Paris, quiet and warm during the Summer evening. ] A Additional theorems Theorem 10. Let ? e X,X := E X e [X e X e ] ? S d?d + , with S d?d + the space of symmetric positive semi-definite matrices, and ? e X, := E X e [X e e ] ? R d . Then, for any arbitrary tuple ? e X, e?Etr ? R d |Etr| , the set {(? e X,X ) e?Etr such that E tr does not satisfy general position} has measure zero in (S d?d + ) |Etr| .</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We omit the superscripts " e " when referring to a random variable regardless of the environment.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We will also use the term "classifier" to denote the last layer w for regression problems.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are thankful to Francis Bach, Marco Baroni, Ishmael Belghazi, Diane Bouchacourt, Fran?ois Charton, Yoshua Bengio, Charles Blundell, Joan Bruna, Lars Buesing, Soumith Chintala, Kyunghyun Cho, Jonathan Gordon, Christina Heinze-Deml, Ferenc Husz?r, Alyosha Efros, Luke Metz, Cijo Jose, Anna Klimovskaia, Yann Ollivier, Maxime Oquab, Jonas Peters, Alec Radford, Cinjon Resnick, Uri Shalit, Pablo Sprechmann, S?nar festival, Rachel Ward, and Will Whitney for their help.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">John Aldrich. Autonomy. Oxford Economic Papers</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Andrew</forename><surname>Bagnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">M</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?bor</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Lugosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsigler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Benign Overfitting in Linear Regression. arXiv</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Recognition in terra incognita</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Beery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grant</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Robust optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aharon</forename><surname>Ben-Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkadi</forename><surname>Nemirovski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A metatransfer objective for learning to disentangle causal mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tristan</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasim</forename><surname>Rahaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosemary</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olexa</forename><surname>Bilaniuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Pal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Comparison of classifier methods: a case study in handwritten digit recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harris</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Le Cun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urs</forename><forename type="middle">A</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>S?ckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrice</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Approximating CNNs with bag-of-localfeatures models works surprisingly well on imagenet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Invariant scattering convolution networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephane</forename><surname>Mallat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Intermittent process analysis with scattering moments. The Annals of Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephane</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Bacry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Franois</forename><surname>Muzy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Two theorems on invariance and causality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Cartwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of Science</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Causal invariance as an essential constraint for creating a causal representation of the world. The Oxford handbook of causal reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><forename type="middle">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongjing</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><forename type="middle">Toutanova</forename><surname>Bert</surname></persName>
		</author>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding. NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Statistics of robust optimization: A generalized empirical likelihood approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Glynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Domainadversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>March</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning causal structures using regression invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amiremad</forename><surname>Ghassami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saber</forename><surname>Salehkaleybar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Negar</forename><surname>Kiyavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">NIST Special Database 19: Handprinted forms and characters database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">J</forename><surname>Grother</surname></persName>
		</author>
		<ptr target="https://www.nist.gov/srd/nist-special-database-19" />
	</analytic>
	<monogr>
		<title level="j">NIST CD ROM NIST Special Database</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
	<note>File doc/doc.ps in the</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The probability approach in econometrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trygve</forename><surname>Haavelmo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: Journal of the Econometric Society</title>
		<imprint>
			<date type="published" when="1944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Heinze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Deml</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
		<title level="m">Conditional variance penalties and domain shift robustness. arXiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Invariant causal prediction for nonlinear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Heinze-Deml</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Causal Inference</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Revisiting visual question answering baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Jabri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Support and invertibility in domain-invariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fredrik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ranganath</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AISTATS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Kilbertus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giambattista</forename><surname>Parascandolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<title level="m">Generalization in anti-causal learning. arXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Stable prediction across unknown environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Athey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoxuan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Building machines that learn and think like people. Behavioral and brain sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brenden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tomer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gershman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Introduction to Smooth Manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Counterfactuals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">From dependence to causation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
		<respStmt>
			<orgName>University of Cambridge</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Discovering causal signals in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to pivot with adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Louppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Cranmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="981" to="990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Domain adaptation by using causal inference to predict invariant conditional distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Thijs Van Ommen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Claassen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bongers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joris M</forename><surname>Versteeg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Marcus</surname></persName>
		</author>
		<title level="m">Deep learning: A critical appraisal. arXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Causality from a distributional robustness point of view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Science Workshop (DSW)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Maximin effects in inhomogeneous large-scale data. The Annals of Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>B?hlmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dimensions of scientific law</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">D</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of Science</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Causality: Models, Reasoning, and Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Causal inference using invariant prediction: identification and confidence intervals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>B?hlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JRSS B</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Elements of causal inference: foundations and learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Incompleteness, non locality and realism. a prolegomenon to the philosophy of quantum mechanics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Redhead</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Invariant models for causal transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateo</forename><surname>Rojas-Carulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Estimating causal effects of treatments in randomized and nonrandomized studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of educational Psychology</title>
		<imprint>
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">On causal and anticausal learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Sgouritsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joris</forename><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Certifying some distributional robustness with principled adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aman</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Causal necessity: a pragmatic investigation of the necessity of laws</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Skyrms</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Yale University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A simple method to determine if a music information retrieval system is a &quot;horse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><forename type="middle">L</forename><surname>Sturm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Multimedia</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Unbiased look at dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Principles of risk minimization for learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Do we still need models or just more data and compute?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">The marginal value of adaptive gradient methods in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ashia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nati</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Recht</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Making things happen: A theory of causal explanation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Woodward</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Oxford university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Correlation and causation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewall</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of agricultural research</title>
		<imprint>
			<date type="published" when="1921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
