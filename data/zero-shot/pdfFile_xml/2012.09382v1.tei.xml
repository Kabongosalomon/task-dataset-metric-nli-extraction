<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DecAug: Out-of-Distribution Generalization via Decomposed Feature Representation and Semantic Augmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyue</forename><surname>Bai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanqing</forename><surname>Hong</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwei</forename><surname>Zhou</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyang</forename><surname>Ye</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han-Jia</forename><surname>Ye</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><forename type="middle">Gary</forename><surname>Chan</surname></persName>
							<email>gchan@cse.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
							<email>li.zhenguo@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DecAug: Out-of-Distribution Generalization via Decomposed Feature Representation and Semantic Augmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T02:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>While deep learning demonstrates its strong ability to handle independent and identically distributed (IID) data, it often suffers from out-of-distribution (OoD) generalization, where the test data come from another distribution (w.r.t. the training one). Designing a general OoD generalization framework to a wide range of applications is challenging, mainly due to possible correlation shift and diversity shift in the real world. Most of the previous approaches can only solve one specific distribution shift, such as shift across domains or the extrapolation of correlation. To address that, we propose DecAug, a novel decomposed feature representation and semantic augmentation approach for OoD generalization. DecAug disentangles the category-related and context-related features. Category-related features contain causal information of the target object, while context-related features describe the attributes, styles, backgrounds, or scenes, causing distribution shifts between training and test data. The decomposition is achieved by orthogonalizing the two gradients (w.r.t. intermediate features) of losses for predicting category and context labels. Furthermore, we perform gradientbased augmentation on context-related features to improve the robustness of the learned representations. Experimental results show that DecAug outperforms other state-of-the-art methods on various OoD datasets, which is among the very few methods that can deal with different types of OoD generalization challenges.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Deep learning has demonstrated superior performances on standard benchmark datasets from various fields, such as image classification <ref type="bibr" target="#b18">(Krizhevsky, Sutskever, and Hinton 2012)</ref>, object detection <ref type="bibr" target="#b29">(Redmon et al. 2016)</ref>, natural language processing <ref type="bibr" target="#b7">(Devlin et al. 2019)</ref>, and recommendation systems <ref type="bibr" target="#b6">(Cheng et al. 2016)</ref>, assuming that the training and test data are independent and identically distributed (IID). In practice, <ref type="figure">Figure 1</ref>: Illustration of the two-dimensional out-ofdistribution problem among datasets in different OoD research areas, including Colored MNIST, PACS, and NICO. Extensive experiments showed that many OoD methods can only deal with one dimension of OoD generalization. however, it is common to observe distribution shifts among training and test data, which is known as out-of-distribution (OoD) generalization. How to deal with OoD generalization is still an open problem.</p><p>To improve a DNN's OoD generalization ability, diversified research endeavours are observed recently, which mainly includes domain generalization, invariant risk minimization, and stable learning. Various standard benchmark datasets are adopted to evaluate the proposed OoD generalization algorithms, such as Colored MNIST <ref type="bibr" target="#b2">(Arjovsky et al. 2019)</ref>, PACS <ref type="bibr" target="#b21">(Li et al. 2017a)</ref>, and NICO <ref type="bibr" target="#b14">(He, Shen, and Cui 2020)</ref>. Among these datasets, PACS are widely used in domain generalization <ref type="bibr" target="#b4">(Carlucci et al. 2019;</ref><ref type="bibr" target="#b27">Mancini et al. 2020)</ref> to validate DNN's ability to generalize across different image styles. On the other hand, in recent risk regularization methods, Colored MNIST is often considered <ref type="bibr" target="#b2">(Arjovsky et al. 2019;</ref><ref type="bibr" target="#b1">Ahuja et al. 2020;</ref><ref type="bibr" target="#b19">Krueger et al. 2020)</ref>, where digits' colors are either red or green. Manipulating the correlation between the colors and the labels would result in a distribution shift. In stable learning, another OoD dataset called arXiv:2012.09382v1 <ref type="bibr">[cs.</ref>LG] 17 Dec 2020 NICO was introduced recently <ref type="bibr" target="#b14">(He, Shen, and Cui 2020)</ref>. It contains image style changes, background changes, and correlation extrapolation. Along with this dataset, an OoD learning method, named CNBB, is proposed, based on sample re-weighting inspired by causal inference.</p><p>In this paper, we observe that methods perform well in one OoD dataset, such as PACS, which may show very poor performance on another dataset, such as Colored MNIST, as shown in the our experiments. That may because of the different dimensions of OoD generalization. Here, we identify two types of out-of-distribution factors, including the correlation shift and the diversity shift.</p><p>Correlation shift. One is the correlation shift, which means that labels and the environments are correlated and the relations change across different environments. For example, in <ref type="figure" target="#fig_0">Fig. 2</ref>, we observe the correlation shift between the training set and the test set in Colored MNIST. Specifically, in the training set, number 5 is usually in green while number 4 is usually in red. However, in the test set, number 5 tends to be in red while number 4 tends to be in green. If a model learns color green to predict label 5 when training, it would suffer from the correlation shift when testing.</p><p>Diversity shift. Another out-of-distribution factor is the diversity shift. For example, in PACS, the data come from four different domains: photo, art painting, cartoon and sketch. Data in different domains have significantly different styles. Usually, we leave one domain out as the test set, and the remaining three domains as training set. The model trained on the training set would susceptible to the diversity shift on the test set. See <ref type="figure">Fig. 3</ref> as an illustration.</p><p>Two-dimension OoD. Data in actual scenarios usually involve two different OoD factors simultaneously. For example, in NICO ( <ref type="figure">Fig. 4</ref>), different contexts such as "in cage", "in water", and "on grass" lead to diversity shift, while some contexts are related to specific categories, such as a bird would be "in hand" and a dog may be "at home". We also put datasets from multiple research areas on the same axis ( <ref type="figure">Fig. 1)</ref>, the X-axis denotes the correlation shift which controls the contribution proportions of correlated features, the Y -axis denotes the diversity shift which stands for the change of feature types. Specifically, in the Colored MNIST dataset, the correlation between color and label is high, while in the PACS, the style of images is more diverse. In the NICO, both correlation shift and diversity shift exist.</p><p>In our experiments, we showed that algorithms considered only one-dimension of OoD generalization may fail in the other dimension of OoD. To handle different OoD factors simultaneously, we propose DecAug, a novel decomposed feature representation and semantic augmentation approach for OoD generalization. Specifically, our method first decomposes the high-level representations of input images into category-related and context-related features by orthogonalizing the two gradients of losses for predicting category and context labels respectively. Category-related features are essential for recognizing the category labels of the images, while context-related features are not essential for the recognition but correlated with the category labels. After obtaining the decomposed features, we do gradient-based semantic augmentation on context-related features, representing attributes, styles, backgrounds, or scenes of target objects, to disentangle the spurious correlation between features that are not essential for the recognition and category labels. Our contributions are as follows:</p><p>1. We test OoD methods from diversified research areas and show that very often, they only deal with one special type of OoD generalization challenge.</p><p>2. We propose DecAug to learn disentangled features that capture the information of category and context respectively and perform gradient-based semantic augmentation to enhance the generalization ability of the model. This is the first data augmentation method that attempts to deal with various OoD generalization problems indicating a new promising direction for OoD generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>In  <ref type="bibr" target="#b20">(Kuang et al. 2018)</ref>, which focuses on learning a model that can achieve stable performances across different environments. The methodology of stable learning largely inherited from sampler reweighting in causal inference <ref type="bibr" target="#b20">(Kuang et al. 2018;</ref><ref type="bibr" target="#b14">He, Shen, and Cui 2020)</ref>. For example, in the convnets with batch balancing algorithm (CNBB), instead of viewing all samples in the dataset equally, it first calculates the weights of each sample by a confounder balancing loss which tests whether including or excluding a sample's feature can lead to a significant change in the latent feature representations to reduce the effects of samples that are largely affected by confounders <ref type="bibr" target="#b17">(Imai and Ratkovic 2014;</ref><ref type="bibr" target="#b30">Robins, Rotnitzky, and Zhao 1994)</ref>. While these methods can have theoretical guarantees on simplified models, when confounder results in strong spurious correlations, this method may not be able to work well especially in the deep learning paradigm. Data augmentation. Data augmentation has been widely used in deep learning to improve the generalization ability of deep models <ref type="bibr" target="#b18">(Krizhevsky, Sutskever, and Hinton 2012;</ref><ref type="bibr">Sri-vastava, Greff, and Schmidhuber 2015;</ref><ref type="bibr" target="#b11">Han, Kim, and Kim 2017)</ref>. Elaborately designed augmentation strategies, such as Cutout (DeVries and Taylor 2017), Mixup <ref type="bibr" target="#b38">(Zhang et al. 2017)</ref>, CutMix <ref type="bibr" target="#b37">(Yun et al. 2019)</ref>, and AugMix <ref type="bibr" target="#b15">(Hendrycks et al. 2019)</ref>, have effectively improved the performance of deep models. A more related augmentation method is to interpolate high-level representations. <ref type="bibr" target="#b35">Upchurch et al. (2017)</ref> shows that simple linear interpolation can achieve meaningful semantic transformations. Motivated by this observation, <ref type="bibr" target="#b36">Wang et al. (2019)</ref> proposes to augment deep features with random vectors sampled from class-specific normal distributions. Instead of augmenting the features explicitly, they minimize an upper bound of the expected loss on augmented data. To tackle few-shot learning problem, <ref type="bibr" target="#b12">Hariharan and Girshick (2017)</ref> suggest to train a feature generator that can transfer modes of variation from categories of a large dataset to novel classes with limited samples. To ease the learning from long-tailed data, <ref type="bibr" target="#b23">Liu et al. (2020a)</ref> proposes to transfer the intra-class distribution of head classes to tail classes by augmenting deep features of instances in tail classes. Different from these approaches, our method performs gradientbased augmentation on disentangled context-related features to eliminate distribution shifts for various OoD tasks. Disentangled representation. Disentangling the latent factors from the image variants is a promising way to provide an understanding of the observed data <ref type="bibr" target="#b5">(Chen et al. 2016;</ref><ref type="bibr" target="#b16">Higgins et al. 2017;</ref><ref type="bibr" target="#b26">Ma et al. 2019)</ref>. It aims to learn representations that separate the explanatory factors of variations behind the data. Such representations are more resilient to the complex variants and able to bring enhanced generalization ability <ref type="bibr" target="#b24">(Liu et al. 2018;</ref><ref type="bibr" target="#b28">Peng et al. 2019)</ref>. Disentangled representations are inherently more interpretable. How to obtain disentanglement is still a challenging problem. <ref type="bibr" target="#b32">Shen and Zhou (2020)</ref> identifies latent semantics and examines the representation learned by GANs. It derives a closed-form factorization method to discover latent semantic and prove that all semantic directions found are orthogonal in the latent space. <ref type="bibr" target="#b3">Bahng et al. (2020)</ref> trains a de-biased representation by encouraging it to be different from a set of representations that are biased by design. The method discourages models from taking bias shortcuts, resulting in improved performances on de-biased test data. In this paper, semantic vectors found by DecAug with orthogonal constraints are disentangled from each other in the feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head><p>To deal with the aforementioned two different types of distribution shifts simultaneously, we argue that it is critical to obtain the decomposed features, one is essential for predicting category and the other is not essential but correlated for recognition. In this section, we propose DecAug to learn decomposed high-level representations for the input data. The decomposition is achieved by orthogonalizing the two gradients of losses for predicting category and context labels respectively. To improve the generalization ability, we perform gradient-based semantic augmentation on contextrelated features and concatenate the augmented features to category-related features to make the final prediction. An overview of the proposed method is illustrated in <ref type="figure" target="#fig_2">Fig. 5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Decomposition</head><p>Consider an image recognition task with the training set</p><formula xml:id="formula_0">D = {(x i , y i , c i )} N i=1</formula><p>, where x i is the input image, y i is the corresponding category label, c i is the corresponding context label, and N is the number of training data. As shown in <ref type="figure" target="#fig_2">Fig. 5</ref>, the input data are mapped to the feature space and are decomposed into two branches: category branch and context branch. Given an input image x i with category label y i and context label c i , let z i = g ? (x i ) be the features extracted by a backbone g ? . For the category branch, z i is decomposed into z 1 i = f ? 1 (z i ) by a category feature extractor f ? 1 , followed by a classifier h ? 1 (z 1 i ) to predict the category label. For the context branch, z i is decomposed into z 2 i = f ? 2 (z i ) by a context feature extractor f ? 2 , followed by a classifier h ? 2 (z 2 i ) to predict the context label. We use the standard cross-entropy losses L 1</p><formula xml:id="formula_1">i (?, ? 1 , ? 1 ) = (h ? 1 ? f ? 1 (z i ), y i ) and L 2 i (?, ? 2 , ? 2 ) = (h ? 2 ? f ? 2 (z i ), c i )</formula><p>to optimize these two branches, together with the backbone, respectively.</p><p>It is known that the direction of the non-zero gradient of a function is the direction in which the function increases most quickly, while the direction that is orthogonal to the gradient direction is the direction in which the function increases most slowly. To better decompose the features into categoryrelated and context-related features, we enforce the gradient of the category loss (h ? 1 ? f ? 1 (z i ), y i ) to be orthogonal to the gradient of the context loss (h ? 2 ? f ? 2 (z i ), c i ) with respect to z i , such that the direction that changes the category loss most quickly will not change the context loss from z i and vice versa. Specifically, let G 1</p><formula xml:id="formula_2">i (? 1 , ? 1 ) = ? zi (h ? 1 ? f ? 1 (z i ), y i ) and G 2 i (? 2 , ? 2 ) = ? zi (h ? 2 ? f ? 2 (z i ), c i )</formula><p>be the gradients of the category and context loss with respect to z i respectively. To ensure the orthogonality, we minimize the following loss: </p><formula xml:id="formula_3">L orth i (? 1 , ? 1 , ? 2 , ? 2 ) = ( G 1 i (? 1 , ? 1 ) G 1 i (? 1 , ? 1 ) ? G 2 i (? 2 , ? 2 ) G 2 i (? 2 , ? 2 ) ) 2 . (1) Algorithm</formula><formula xml:id="formula_4">, ? 2 , ? orth . Output: ?, ? 1 , ? 1 , ? 2 , ? 2 , ?. 1: Initialize ?, ? 1 , ? 1 , ? 2 , ? 2 , ?; 2: repeat 3: Sample a mini-batch of training images {(xi, yi, ci)} n i=1</formula><p>with batch size n; 4:</p><p>for each (xi, yi, ci) do 5:</p><p>zi ? g ? (xi); 6:</p><formula xml:id="formula_5">L 1 i (?, ? 1 , ? 1 ) ? (h ? 1 ? f ? 1 (zi), yi); 7: L 2 i (?, ? 2 , ? 2 ) ? (h ? 2 ? f ? 2 (zi), ci); 8:</formula><p>Compute L orth i (? 1 , ? 1 , ? 2 , ? 2 ) according to Eq. (1); 9:</p><p>Randomly sample ?i from [0, 1]; 10:</p><p>Generatez 2 i according to Eq. (2); 11:</p><formula xml:id="formula_6">L concat i (?, ? 1 , ? 2 , ?) ? (h ? ([f ? 1 (zi),z 2 i ]), yi); 12:</formula><p>Compute Li(?, ? 1 , ? 1 , ? 2 , ? 2 , ?) according to Eq. (3); 13: end for 14:</p><p>(</p><formula xml:id="formula_7">?, ? 1 , ? 1 , ? 2 , ? 2 , ?) ? (?, ? 1 , ? 1 , ? 2 , ? 2 , ?) ?? ? ? 1 n n i=1</formula><p>Li(?, ? 1 , ? 1 , ? 2 , ? 2 , ?); 15: until convergence;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic Augmentation</head><p>Considering that context-related features cause correlation or diversity shifts in our setting, we perform augmentation on the context-related features to eliminate such kind of distribution shifts. As in the semantic feature space, we may have multiple alternative directions for OoD. To ensure good performances across different environments, we postulate a worse case for the model to learn for OoD generalization by calculating the adversarially perturbed examples in the feature space. Specifically, let G aug</p><formula xml:id="formula_8">i = ? z 2 i (h ? 2 (z 2 i ), c i )</formula><p>be the gradient of the context loss with respect to z 2 i . We augment the context-related features z 2 i as follows:</p><formula xml:id="formula_9">z 2 i = z 2 i + ?i ? ? G aug i G aug i ,<label>(2)</label></formula><p>where is a hyper-parameter that determines the maximum length of the augmentation vectors and ? i is randomly sampled from [0, 1].</p><p>After augmenting the context-related features, we concatenatez 2 i to the category-related features z 1 i to make the final prediction h ? ([z 1 i ,z 2 i ]), where h ? is a classifier and [z 1 i ,z 2 i ] is the concatenation of two features. We still use the standard cross-entropy loss L concat</p><formula xml:id="formula_10">i (?, ? 1 , ? 2 , ?) = (h ? ([z 1 i ,z 2 i ])</formula><p>, y i ) to optimize the corresponding parameters. Together with the aforementioned losses, the final loss is then defined as</p><formula xml:id="formula_11">Li(?, ? 1 , ? 1 , ? 2 , ? 2 , ?) = L concat i (?, ? 1 , ? 2 , ?) + ? 1 ? L 1 i (?, ? 1 , ? 1 ) + ? 2 ? L 2 i (?, ? 2 , ? 2 ) + ? orth ? L orth i (? 1 , ? 1 , ? 2 , ? 2 ),<label>(3)</label></formula><p>where ? 1 , ? 2 and ? orth are hyper-parameters that balance different losses. We formulate the learning of DecAug as the following optimization problem:</p><formula xml:id="formula_12">min ?,? 1 ,? 1 ,? 2 ,? 2 ,? 1 N N i=1 Li(?, ? 1 , ? 1 , ? 2 , ? 2 , ?).<label>(4)</label></formula><p>The stochastic gradient descent (SGD) algorithm can be applied to optimize the above objective. The detailed procedures are summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In this section, we will conduct numerical experiments to cross benchmark different methods from different perspective of OoD research on different typically challenging and widely used dataset-Colored MNIST, NICO, and PACS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details and Datasets</head><p>We evaluate our method on three challenging OoD datasets with different levels of correlation shift and diversity shift as discussed above: 1) The original digits ranging from 0 to 4 were relabelled as 0 and the digits ranging from 5 to 9 were tagged as 1; 2) The labels of 0 have a probability of 25% to flip to 1, and vice versa; 3) The digits were colored either red or green based on different correlation with the labels to construct different environments (e.g., 80% and 90% for the training environments and 10% for the test environment). In this way, the classifiers will easily over-fit to the spurious feature (e.g., color) in the training environments and ignore the shape feature of the digits. For a fair comparison, we followed the same experimental protocol as in IRM <ref type="bibr" target="#b2">(Arjovsky et al. 2019</ref>) on the Colored MNIST dataset. We equipped the IRMv1 scheme with our DecAug approach using the same settings. The backbone network was a three-layer MLP. The total training epoch was 500 and the batch size was the whole training data. We used the SGD optimizer with an initial learning rate of 0.1. The trained model was tested at the final epoch. The PACS Dataset. This dataset contains 4 domains (Photo, Art Painting, Cartoon, Sketch) with 7 common categories (dog, elephant, giraffe, guitar, horse, house, person). We followed the same leave-one-domain-out validation experimental protocol as in <ref type="bibr" target="#b21">(Li et al. 2017a</ref>). For each time, we select three environments for training and the remaining environment for testing.</p><p>The backbone network we used on PACS dataset was ResNet-18. We followed the same training, validation and test split as in JiGen <ref type="bibr" target="#b4">(Carlucci et al. 2019</ref>). The number of training epochs was 100. The batch size was 64. We used the SGD optimizer with a learning rate of 0.02. The NICO Dataset. This dataset contains 19 classes with 9 or 10 different contexts, i.e., different object poses, positions, backgrounds, and movement patterns, etc. The NICO dataset is one of the newly proposed OoD generalization benchmark in the real scenarios <ref type="bibr" target="#b14">(He, Shen, and Cui 2020)</ref>. The contexts in validation and test set will not appear in training set.</p><p>The backbone network was ResNet-18 without pretraining on the NICO dataset. The number of training epochs was 500 and the batch size was 128. We used the SGD optimizer with a learning rate of 0.05.</p><p>We compare our proposed DecAug with the state-of-thearts, including empirical risk minimization (ERM), invariant risk minimization (IRM, <ref type="bibr" target="#b2">(Arjovsky et al. 2019)</ref>), invariant risk minimization games (IRM-Games, <ref type="bibr" target="#b1">(Ahuja et al. 2020)</ref>), model-agnostic learning of semantic features (MASF, <ref type="bibr" target="#b9">(Dou et al. 2019)</ref>), domain generalization by solving jigsaw puzzles (JiGen, <ref type="bibr" target="#b4">(Carlucci et al. 2019)</ref>) across multiple datasets, debiased training method (ReBias, <ref type="bibr" target="#b3">(Bahng et al. 2020)</ref>), risk extrapolation (Rex, <ref type="bibr" target="#b19">(Krueger et al. 2020)</ref>), and convnets with batch balancing (CNBB, <ref type="bibr" target="#b14">(He, Shen, and Cui 2020)</ref>).</p><p>Our framework was implemented with PyTorch 1.1.0, CUDA v9.0. For the baseline methods, we implement either with Pytorch 1.1.0 or with Tensorflow 1.8 to keep the same setting as their original source code. IRM, JiGen, ReBias, Rex, and CNBB 1 were implemented with Pytorch. IRM-Games and MASF were implemented with Tensorflow. We conducted experiments on NVIDIA Tesla V100. More implementation details can be found in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>In this section, we evaluate and analyze the results of our approach on three datasets: Colored MNIST, PACS and NICO. These datasets represent different aspects of covariant shifts in OoD problems thus provide more thorough studies on OoD generalization compared with previous ones. Illustrative Results on the Colored MNIST Dataset. As shown in <ref type="table" target="#tab_4">Table 2</ref>, DecAug achieves the best generalization performance on Colored MNIST, followed by risk regularization methods, such as Rex and IRM. For typical domain  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Acc test env ERM * 17.10 ? 0.6 IRM <ref type="bibr" target="#b2">(Arjovsky et al. 2019)</ref> 66.90 ? 2.5 Rex <ref type="bibr" target="#b19">(Krueger et al. 2020)</ref> 68.70 ? 0.9 F-IRMGames <ref type="bibr" target="#b1">(Ahuja et al. 2020)</ref> 59.91 ? 2.7 V-IRMGames <ref type="bibr" target="#b1">(Ahuja et al. 2020)</ref> 49.06 ? 3.4 ReBias <ref type="bibr" target="#b3">(Bahng et al. 2020</ref> generalization methods, such as JiGen, and the recently proposed method ReBias, are misled by the spurious correlation existing in the training datasets. Notice that DecAug's performance is very close to ERM trained on grayscale MNIST which provides an upper bound for MLP to generalize on this task. As mentioned in <ref type="bibr" target="#b2">(Arjovsky et al. 2019)</ref>, typical domain generalization methods can only deal with one dimension of OoD problem where image style differs. Our method further improves the performance in Colored MNIST by decomposition and semantic augmentation in the feature space, which disregards spurious features that are correlated but not causal for predicting category. Illustrative Results on the PACS Dataset. In PACS, De-cAug achieves the state-of-the-art (SOTA) performance followed by MASF and Cumix when using ResNet-18 as the backbone network. The details of our results on PACS are shown in <ref type="table" target="#tab_3">Table 1</ref>. The worse performances for risk regularization methods, such as IRM and Rex, are because these methods add strong regularization terms in ERM to eliminate all features that are unstable across different environments. This can work well in the standard and "clean" dataset--MNIST, where shapes of digits are always stable. However, in realistic scenarios, the shapes of target objects   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Studies and Sensitivity Analysis</head><p>For ablation studies and sensitivity analysis, we take the PACS dataset for example. Effectiveness of orthogonal loss. We test the effects of the proposed orthogonal loss. The results are shown in <ref type="table" target="#tab_7">Table 4</ref>. It can be seen that without the orthogonal loss, our method achieves the average accuracy of 80.77% that is higher than most of the methods in <ref type="table" target="#tab_3">Table 1</ref>. This is because the category and context losses also play the role of feature decomposition. The additional orthogonal loss enforces the gradients of the category and context losses to be orthogonal to each other, which helps to further decompose the features. As expected, with the increase of the orthogonal regularization coefficient ? orth , the performance of DecAug can be improved. The experimental results confirm the effectiveness of the proposed orthogonal loss. DecAug variants. We changed current orth regularization to orth constrains between features, refer to <ref type="table" target="#tab_8">Table 5</ref>, which reaches 79.90% on PACS, lower than the original DecAug. We also tried confusion regularization, as discussed in recent literature Open Compound Domain Adaptation <ref type="bibr" target="#b25">(Liu et al. 2020b)</ref>. It seems natural to incorporate confusion regularization into our method for better decomposition. However, after many trials, no improvements were observed. We tried DecAug with DANN adversarial loss "orth" on PACS. As shown in <ref type="table" target="#tab_8">Table 5</ref>, the result is around 81%, lower than the original. This shows both gradient orthogonalization and semantic augmentation are both indispensable parts in the algorithm. We tried "adversarial augmentation" to Jigsaw, the result is much lower than Jigsaw. This shows that the two branch architecture is needed and adversarial augmentation is better performed on the context predicting branch to improve OoD generalization via challenging neural networks to unseen context information. Interpretability analysis. We also use deep neural network interpretability methods in <ref type="bibr" target="#b0">(Adebayo et al. 2018</ref>) to explain the neural network's classification decisions as shown in <ref type="figure" target="#fig_3">Figure 6</ref>. It can be seen that the saliency maps of the category branch focus more on foreground objects, while the saliency maps of the context branch are also sensitive to background contexts that contain domain information. This shows that our method well decomposes the high-level representations into two features that contain category and context information respectively. Later, by performing semantic augmentation on context-related features, our model breaks the inherent relationship between contexts and category labels and generalizes to unseen combinations of foregrounds and backgrounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In this paper, we propose DecAug, a novel decomposed feature representation and semantic augmentation method for various OoD generalization tasks. High-level representations for the input data are decomposed into categoryrelated and context-related features to deal with the diversity shift between training and test data. Gradient-based semantic augmentation is then performed on the context-related features to break the spurious correlation between context features and image categories. To the best of our knowledge, this is the first method that can simultaneously achieve the SOTA performance on various OoD generalization tasks from different research areas, indicating a new research direction for OoD generalization research. For future work, we will construct a large OoD dataset from the industry to further improve the algorithm and put it into real practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Materials</head><p>Ablation Study for Semantic Augmentation</p><p>In DecAug, semantic augmentation is proposed to further alleviate the influence of spurious correlation. We do not use random noise but adversarial augmentation on the context branch to improve the generalization ability of the model.</p><p>In this section, we investigate the effects of semantic augmentation. We follow the same leave-one-domain-out validation protocol and the same training, validation and test split as in <ref type="bibr" target="#b21">Li et al. (2017a)</ref>. The maximum number of training epochs in our experiment is 100. We use the SGD optimizer with a batch size of 64. Recall that is the magnitude of perturbation in augmentation. We test different values of when all the other hyper-parameters remain the same. The results are summarized in <ref type="table" target="#tab_9">Table 6</ref>. The first row lists the performance of the baseline model without augmentation. As can be seen in rows 2 and 4, semantic augmentation significantly improves classification accuracy. DecAug without semantic augmentation achieves 79.64% accuracy, which is lower than DecAug. This is because semantic augmentation uses adversarial perturbation on the semantic space for improving the robustness of DecAug to unseen semantic domains. Moreover, the magnitude of the perturbation has a great influence on the results. Inappropriate magnitudes of perturbation would lead to very poor performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study for Features Concatenation</head><p>In this section, we conduct an ablation study for features concatenation. Following the same leave-one-domain-out validation protocol as in the previous works on PACS, we evaluate the proposed DecAug without the concatenate operation. The balance weight for the category branch and the context branch is one. Note that we also involve the orthogonal constraints in this experiment. As can be seen in <ref type="table" target="#tab_10">Table 7</ref>, the application of features concatenation achieves the best performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gradient Visualization of DecAug in NICO</head><p>We use deep neural network interpretation methods to explain the neural network's classification decisions in NICO, as shown in <ref type="figure">Figure 7</ref>. It can be seen that the saliency maps of the category branch focus more on foreground objects, while the saliency maps of the context branch are also sensitive to background contexts that contain domain information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Details of NICO</head><p>The NICO dataset contains two superclasses: animal and vehicle, which is a newly proposed OoD generalization benchmark in the real world. The original NICO dataset describes different ways to split training, validation and test set. For a fair comparison, we fix the split settings and constrain that the contexts have no intersection among the training, validation and test sets. The details of the split principle used in our experiments are shown in <ref type="table">Table 8 and Table 9</ref>.  <ref type="figure">Figure 7</ref>: The gradient visualization of the decomposed category-related and context-related high-dimensional features in NICO data. The first row is the original input images, the second row is its corresponding back propagation of the category branch and the last row is the back propagation of the context branch.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Typical examples of out-of-distribution correlation shift data from the Colored MNIST dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Typical examples of out-of-distribution diversity shift data from the PACS dataset. (a) Photo. (b) Art Painting. (c) Cartoon. (d) Sketch. (a) In cage (b) In water (c) On grass (d) Others Some examples of the two-dimensional out-ofdistribution data from the NICO dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>An overview of the proposed DecAug. The input features z extracted by the backbone are decomposed into categoryrelated and context-related features with orthogonal regularization. Gradient-based augmentation is then preformed in the feature space to get semantic augmented samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>The gradient visualization of the decomposed category-related and context-related high-dimensional features. The first row is the original input images, the second row is its corresponding back propagation of the category branch and the last row is the back propagation of the context branch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>this section, we review literature related to risk regularization methods, domain generalization, stable learning, data augmentation and disentangled representation.</figDesc><table><row><cell>Risk regularization methods for OoD generalization. The</cell></row><row><cell>invariant risk minimization (IRM, (Arjovsky et al. 2019))</cell></row><row><cell>is motivated by the theory of causality and causal Bayesian</cell></row><row><cell>networks (CBNs), aiming to find an invariant representation</cell></row><row><cell>of data from different training environments. To make the</cell></row><row><cell>model robust to unseen interventions, the invariant risk min-</cell></row><row><cell>imization added invariant risk regularization to monitor the</cell></row><row><cell>optimality of a dummy classifier on different environments.</cell></row><row><cell>IRM-Games (Ahuja et al. 2020) further improves the stabil-</cell></row><row><cell>ity of IRM. Risk extrapolation (Rex, (Krueger et al. 2020))</cell></row><row><cell>adopts a min-max framework to derive a model that can per-</cell></row><row><cell>form well on the worst linear combination of risks from dif-</cell></row><row><cell>ferent environments. These methods typically perform well</cell></row><row><cell>on synthetic datasets, such as Colored MNIST. However, it</cell></row><row><cell>is unknown how they can generalize on more complex prac-</cell></row><row><cell>tical datasets beyond MNIST classification tasks.</cell></row><row><cell>Domain generalization. Fabio et al. proposed a self-</cell></row><row><cell>supervised learning method-Jigsaw that achieves good per-</cell></row><row><cell>formance in typical domain generalization datasets, such as</cell></row><row><cell>PACS (Carlucci et al. 2019). A subnetwork sharing weights</cell></row><row><cell>with the main network is used to solve Jigsaw puzzles.</cell></row><row><cell>This self-supervised learning method helps in improving</cell></row><row><cell>the generalization of model on unseen domains. Qi et al.</cell></row><row><cell>adopted meta learning to learn invariant feature representa-</cell></row><row><cell>tions across domains (Dou et al. 2019). Recently, Mancini et</cell></row><row><cell>al. proposed the curriculum mixup method for domain gen-</cell></row><row><cell>eralization, in which data from multiple domains in the train-</cell></row><row><cell>ing dataset mix together by a curriculum schedule of mixup</cell></row><row><cell>method (Mancini et al. 2020). Domain generalization meth-</cell></row><row><cell>ods have achieved performance gain in generalizing models</cell></row><row><cell>to unseen domains. However, recent OoD research finds that</cell></row><row><cell>domain adaptation methods with similar design principles</cell></row><row><cell>can have problems when training distribution is largely dif-</cell></row><row><cell>ferent from test distribution (Arjovsky et al. 2019).</cell></row><row><cell>Stable learning. Stable learning is a recently proposed new</cell></row><row><cell>concept</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Classification accuracy of our approach trained considering leave-one-domain-out validation compared with the stateof-the-art methods on the PACS benchmark with the ResNet-18 backbone.</figDesc><table><row><cell>Model</cell><cell cols="4">Art Painting Cartoon Sketch Photo Average</cell></row><row><cell>ERM (Carlucci et al. 2019)</cell><cell>77.85</cell><cell>74.86</cell><cell>67.74 95.73</cell><cell>79.05</cell></row><row><cell>IRM (Arjovsky et al. 2019) *</cell><cell>70.31</cell><cell>73.12</cell><cell>75.51 84.73</cell><cell>75.92</cell></row><row><cell>Rex (Krueger et al. 2020) *</cell><cell>76.22</cell><cell>73.76</cell><cell>66.00 95.21</cell><cell>77.80</cell></row><row><cell>JiGen (Carlucci et al. 2019)</cell><cell>79.42</cell><cell>75.25</cell><cell>71.35 96.03</cell><cell>80.51</cell></row><row><cell>DANN (Ganin et al. 2016)</cell><cell>81.30</cell><cell>73.80</cell><cell>74.30 94.00</cell><cell>80.80</cell></row><row><cell>MLDG (Li et al. 2017b)</cell><cell>79.50</cell><cell>77.30</cell><cell>71.50 94.30</cell><cell>80.70</cell></row><row><cell>CrossGrad (Shankar et al. 2018)</cell><cell>78.70</cell><cell>73.30</cell><cell>65.10 94.00</cell><cell>80.70</cell></row><row><cell>MASF (Dou et al. 2019)</cell><cell>80.29</cell><cell>77.17</cell><cell>71.69 94.99</cell><cell>81.03</cell></row><row><cell>Cumix (Mancini et al. 2020)</cell><cell>82.30</cell><cell>76.50</cell><cell>72.60 95.10</cell><cell>81.60</cell></row><row><cell>DecAug</cell><cell>79.00</cell><cell>79.61</cell><cell>75.64 95.33</cell><cell>82.39</cell></row></table><note>* Implemented by ourselves.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: Results of our approach compared with different</cell></row><row><cell>methods on the Colored MNIST dataset(mean ? std devia-</cell></row><row><cell>tion).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Results of our method compared with different models on the NICO dataset.</figDesc><table><row><cell>Model</cell><cell cols="2">Animal Vehicle</cell></row><row><cell>ERM *</cell><cell>75.87</cell><cell>74.52</cell></row><row><cell>IRM (Ahuja et al. 2020) *</cell><cell>59.17</cell><cell>62.00</cell></row><row><cell>Rex (Krueger et al. 2020) *</cell><cell>74.31</cell><cell>66.20</cell></row><row><cell>Cumix (Mancini et al. 2020) *</cell><cell>76.78</cell><cell>74.74</cell></row><row><cell>DANN (Ganin et al. 2016) *</cell><cell>75.59</cell><cell>72.23</cell></row><row><cell>JiGen (Carlucci et al. 2019) *</cell><cell>84.95</cell><cell>79.45</cell></row><row><cell cols="2">CNBB (He, Shen, and Cui 2020) * 78.16</cell><cell>77.39</cell></row><row><cell>DecAug</cell><cell>85.23</cell><cell>80.12</cell></row><row><cell>Implemented by ourselves.</cell><cell></cell><cell></cell></row><row><cell cols="3">can change, meaning that even features for predicting object</cell></row><row><cell cols="3">category can be unstable in different training environments.</cell></row><row><cell cols="3">Illustrative Results on the NICO Dataset. The recently</cell></row><row><cell cols="3">proposed NICO dataset, considers more realistic general-</cell></row><row><cell cols="3">ization scenarios, where objects themselves and the back-</cell></row><row><cell cols="3">grounds i.e.contexts in the dataset, can change vastly. For</cell></row><row><cell cols="3">example, in the training dataset, we have dog pictures on</cell></row><row><cell cols="3">the grass with dog faces posed to the camera, while in the</cell></row><row><cell cols="3">test dataset, there are pictures where dogs are moving on the</cell></row><row><cell cols="3">beachside. In our implementation, CuMix achieved 76.78%</cell></row><row><cell cols="3">(animal) and 74.74% (vehicle) accuracy on NICO, indicat-</cell></row><row><cell cols="3">ing that mixing up (interpolating) data may not able to cor-</cell></row><row><cell cols="3">rect the spurious correlation between irrelevant features such</cell></row><row><cell cols="3">as the background to the predicted category. In addition,</cell></row><row><cell cols="3">DANN achieved 64.77% (animal) and 58.16% (vehicle) ac-</cell></row><row><cell cols="3">curacy, which is similar to IRM. The poor performance of</cell></row><row><cell cols="3">DANN and IRM on NICO may probably due to the diver-</cell></row><row><cell cols="3">sity shift. As Table 3 shows, the proposed DecAug achieved</cell></row><row><cell cols="3">the best generalization performances on two sets, followed</cell></row><row><cell cols="3">by JiGen. This further demonstrates the superiority of the</cell></row><row><cell cols="3">proposed algorithmic framework. Our method has achieved</cell></row><row><cell cols="3">the SOTA performance simultaneously on various OoD gen-</cell></row><row><cell cols="3">eralization tasks, indicating a new promising direction for</cell></row><row><cell>OoD learning algorithm research.</cell><cell></cell><cell></cell></row></table><note>*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Ablation study on PACS with ResNet-18.</figDesc><table><row><cell>PACS</cell><cell cols="4">Art Painting Cartoon Sketch Photo Average</cell></row><row><cell>DecAug without orth loss</cell><cell>78.42</cell><cell>78.32</cell><cell>72.13 94.19</cell><cell>80.77</cell></row><row><cell>DecAug (orth 0.0005)</cell><cell>77.49</cell><cell>77.43</cell><cell>74.32 94.07</cell><cell>80.76</cell></row><row><cell>DecAug (orth 0.001)</cell><cell>78.12</cell><cell>77.34</cell><cell>76.97 94.91</cell><cell>81.83</cell></row><row><cell>DecAug (orth 0.01)</cell><cell>79.00</cell><cell>79.61</cell><cell>75.64 95.33</cell><cell>82.39</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Results of DecAug variants on the PACS dataset.</figDesc><table><row><cell>Model</cell><cell>Average</cell></row><row><cell>DecAug (DANN loss)</cell><cell>81.00</cell></row><row><cell>DecAug (orth between features)</cell><cell>79.90</cell></row><row><cell>DecAug (gradient-based orth)</cell><cell>82.39</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Ablation study for semantic augmentation on PACS with ResNet-18.</figDesc><table><row><cell>PACS</cell><cell cols="4">Art Painting Cartoon Sketch Photo Average</cell></row><row><cell>DecAug without perturbation</cell><cell>75.83</cell><cell>77.37</cell><cell>70.81 94.55</cell><cell>79.64</cell></row><row><cell>DecAug ( = 1)</cell><cell>79.00</cell><cell>79.61</cell><cell>75.64 95.33</cell><cell>82.39</cell></row><row><cell>DecAug ( = 0.01)</cell><cell>75.24</cell><cell>77.65</cell><cell>69.89 94.67</cell><cell>79.36</cell></row><row><cell>DecAug ( = 10)</cell><cell>74.39</cell><cell>77.47</cell><cell>75.24 95.09</cell><cell>80.55</cell></row><row><cell>DecAug ( = 100)</cell><cell>63.13</cell><cell>70.39</cell><cell>64.19 94.55</cell><cell>73.07</cell></row><row><cell>DecAug ( = 1000)</cell><cell>62.89</cell><cell>71.97</cell><cell>71.44 41.13</cell><cell>61.86</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Ablation study for features concatenate on PACS with ResNet-18.</figDesc><table><row><cell>PACS</cell><cell cols="4">Art Painting Cartoon Sketch Photo Average</cell></row><row><cell>DecAug with concat</cell><cell>79.00</cell><cell>79.61</cell><cell>75.64 95.33</cell><cell>82.39</cell></row><row><cell>DecAug without concat</cell><cell>75.83</cell><cell>76.24</cell><cell>75.57 94.79</cell><cell>80.61</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">. Extensive experiments show that our method consistently outperforms previous OoD methods on various types of OoD tasks. For instance, we achieve an average accuracy of 82.39% with ResNet-18<ref type="bibr" target="#b13">(He et al. 2016</ref>) on PACS<ref type="bibr" target="#b21">(Li et al. 2017a)</ref>, which is the state-of-the-art performance.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The code of CNBB is from the authors of the paper.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Nanyang Ye was supported in part by National Key R&amp;D Program of China 2017YFB1003000, in part by National Natural Science Foundation of China under  Grant (No. 61672342, 61671478, 61532012, 61822206,  61832013, 61960206002, 62041205), in part by the Science and Technology Innovation Program of Shanghai (Grant 18XD1401800, 18510761200), in part by Shanghai Key Laboratory of Scalable Computing and Systems.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sanity Checks for Saliency Maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Adebayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Muelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Bengio, S.</editor>
		<editor>Wallach, H.</editor>
		<editor>Larochelle, H.</editor>
		<editor>Grauman, K.</editor>
		<editor>Cesa-Bianchi, N.</editor>
		<editor>and Garnett, R.</editor>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="9505" to="9515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dhurandhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.04692</idno>
		<title level="m">Invariant Risk Minimization Games</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<title level="m">Invariant Risk Minimization</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning De-biased Representations with Biased Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Domain Generalization by Solving Jigsaw Puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>; D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Infogan: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Wide &amp; Deep Learning for Recommender Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harmsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ispir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</title>
		<meeting>the 1st Workshop on Deep Learning for Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<title level="m">Improved Regularization of Convolutional Neural Networks with Cutout</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domain Generalization via Model-Agnostic Learning of Semantic Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Domain-Adversarial Training of Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep Pyramidal Residual Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Low-shot Visual Recognition by Shrinking and Hallucinating Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<title level="m">Towards Non-IID Image Classification: A Dataset and Baselines. Pattern Recognition</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">?-vae: Learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Covariate balancing propensity score</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Imai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ratkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ImageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Out-of-Distribution Generalization via Risk Extrapolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
			<affiliation>
				<orgName type="collaboration">REx</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Caballero</surname></persName>
			<affiliation>
				<orgName type="collaboration">REx</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Jacobsen</surname></persName>
			<affiliation>
				<orgName type="collaboration">REx</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhang</surname></persName>
			<affiliation>
				<orgName type="collaboration">REx</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Binas</surname></persName>
			<affiliation>
				<orgName type="collaboration">REx</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Priol</surname></persName>
			<affiliation>
				<orgName type="collaboration">REx</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
			<affiliation>
				<orgName type="collaboration">REx</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:2003.00688</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stable Prediction across Unknown Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Athey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deeper, Broader and Artier Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Learning to generalize: Meta-learning for Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.03463</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep Representation Learning on Long-tailed Data: A Learnable Embedding Augmentation Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Detach and Adapt: Learning Cross-Domain Disentangled Deep Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Open Compound Domain Adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12406" to="12415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Disentangled Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Towards Recognizing Unseen Categories in Unseen Domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Domain Agnostic Learning with Disentangled Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">You Only Look Once: Unified, Real-Time Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Estimation of Regression Coefficients When Some Regressors Are Not Always Observed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Robins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rotnitzky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">427</biblScope>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.10745</idno>
		<title level="m">Generalizing Across Domains via Cross-Gradient Training</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Closed-Form Factorization of Latent Semantics in GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.06600</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stable Learning via Sample Reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Training Very Deep Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep Feature Interpolation for Image Content Changes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Upchurch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Implicit Semantic Data Augmentation for Deep Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization Strategy to Train Strong Classifiers with Localizable Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond Empirical Risk Minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
