<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An integrated Auto Encoder-Block Switching defense approach to prevent adversarial attacks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Upadhyay</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Yadav</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharanya</surname></persName>
						</author>
						<title level="a" type="main">An integrated Auto Encoder-Block Switching defense approach to prevent adversarial attacks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>According to the recent studies, the vulnerability of state of the art Neural Networks to adversarial input samples has increased drastically. Neural network is an intermediate path or technique by which a computer learns to perform tasks using Machine learning algorithms. Machine Learning and Artificial Intelligence model has become fundamental aspect of life, such as self-driving cars [1], smart home devices, so any vulnerability is a significant concern. The smallest input deviations can fool these extremely literal systems and deceive their users as well as administrator into precarious situations. This article proposes a defense algorithm which utilizes the combination of an auto-encoder [3] and block-switching architecture. Auto-coder is intended to remove any perturbations found in input images whereas block switching method is used to make it more robust against White-box attack. Attack is planned using FGSM [9] model, and the subsequent counter-attack by the proposed architecture will take place thereby demonstrating the feasibility and security delivered by the algorithm. ?</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Machine Learning (ML) has spread its wings in almost all domains from medical to industrial equipment maintenance <ref type="bibr" target="#b0">[1]</ref>. Adversarial examples can be interpreted as optical illusions to ML models in layman terms. These examples are carefully perturbed as inputs to the ML models which subsequently generate erroneous outputs. While such perturbations may seem benign to human perception, it can elicit wrong predictions from the model with full confidence. For example, perpetrators could target self-driving vehicles by causing perturbations using paint or stickers that will cause vehicle to decipher the sign incorrectly. Adversarial examples depict that many modern ML algorithms can be deluded in incredibly simple ways.</p><p>Such failures indicate that even simple ML models can have their behaviour manipulated. Traditional mechanisms for building robust ML models generally do not provide a pragmatic defence against adversarial examples. There are two effective methods that have provided a somewhat effective defence: adversarial training and defensive distillation. This article explores a much more superior defence algorithm against such adversarial examples, thereby eliminating the possibility of white-box attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Definitions</head><p>Adversarial Training: It is a brute force solution which improves the model's robustness by incorporating adversarial examples into the training stage followed by an explicit training of the model against such deceptions. In simple terms, it is the process of creating and incorporating adversarial examples into the training segment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Defensive distillation:</head><p>The ML model is trained to output probabilities instead of making hard decision of classifying input into different classes. It is a defensive strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>White-Box attack:</head><p>It is the type of attack in which attackers have access to the Machine Learning algorithm or model parameters, hyper-parameters, architecture, weights, to name a few.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Black-Box attack:</head><p>In these type of attacks, attackers do not have any kind of information regarding the Machine Learning algorithm/model. The following networks are used in the proposed architecture:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Fast Gradient Sign Method</head><p>Fast Gradient Sign Method (FGSM) <ref type="bibr" target="#b8">[9]</ref> is the powerful attack method. It is used to attack on neural network by the means of gradient. FGSM utilises the back propagated gradients of loss with respect to image input. In other words, instead of dynamically modifying weights based on back propagated gradients, FGSM manipulates input image to maximize the loss with respect to same back propagated gradient. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Where-</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Generative Adversarial Networks</head><p>Generative Adversarial Networks (GAN) <ref type="bibr" target="#b5">[6]</ref> uses unsupervised learning to figure out patterns and irregularities in the input data and also use them to generate new output that has the same patterns and irregularities as the input data. The architecture is shown in <ref type="figure" target="#fig_1">fig 1.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.1">Generator:</head><p>It takes a random set of input values of fixed length, and it tries to generate a sample in the domain same as of input data. Input is drawn randomly from a Gaussian distribution. Once the model is trained, it can be used in future for generating new samples as same as input data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.2">Discriminator:</head><p>It is a classification model which classifies the input data into real and fake classes. Here, real stands for an original data set and fake stands for data generated by generator module. It is only used for training purpose as it assists the generator in generating output samples as similar to input samples. Once training is completed discriminator is discarded.</p><p>These two models work together as discriminator provides feedback on the fake generated inputs and generator then uses these to improve output. These two are run until the discriminator model is in such a state that it can no longer distinguish between fake and real data set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AdvGAN</head><p>AdvGAN (Adversarial GAN) is a modified version of GAN. However, instead of generating samples the same as of input data, it tries to generate samples that can fool state of the art models. The working of Adversarial GAN is similar to GAN but it consists of 3 models:</p><p>Classifier: It checks whether the output generated belong to the desired class (different from its correct class). It ensures that the generated sample gets incorrectly classified. Since discriminator ensures that samples generated by the generator are looking similar to the input data and classifier ensures that it gets wrongly classifies, so a similar-looking output to a human eye easily fools state of the art neural networks. Encoder: This part of the auto-encoder compresses the input data into a latent space. Latent space is a compressed representation of the input data in a reduced dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Auto-Encoder</head><p>Code: This part of auto-encoder is also known as a bottleneck. It represents compressed input in a reduced dimension and passes it to the decoder.</p><p>Decoder: It takes latent space representation (compressed input) as an input and tries to generate the output of the same dimension as of original input. This reconstruction is done depending on the purpose. It can be used to remove noise from an image or can be used for data compression.  o Randomization <ref type="bibr" target="#b7">[8]</ref> acts as a backup for filtration performed by auto-encoder there by increasing the robustness of the proposed model.</p><p>o Grad-CAM <ref type="bibr" target="#b6">[7]</ref> allows the model to predict the highlighted important region based on classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Defence Architecture</head><p>The defence architecture comprises of 3 major components-Auto-encoder <ref type="bibr" target="#b2">[3]</ref>, Block switching <ref type="bibr" target="#b7">[8]</ref> and Grad-CAM <ref type="bibr" target="#b6">[7]</ref>. The purpose of auto-encoder is to perform filtration. Autoencoder is integrated with the Block switching model along with the Grad-CAM. Block switching consists of multiple processes which are selected randomly based on the classification of images. Grad-CAM are the activation maps which uses the gradients to produce highlights on important region in the image. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. IMPLEMENTATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Auto Encoder</head><p>Auto-encoders can be used for filtration purpose by taking adversarial data in the form of inputs and clean data as outputs. It is possible for them to remove adversarial noise from an input image. Thus in the proposed architecture, autoencoders can also be termed as denoisers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Block Switching and Random Weight Switching</head><p>Block-switching <ref type="bibr" target="#b7">[8]</ref> model is trained on two different levels. The first level of training comprises of individual training of sub-models with same architecture. Due to the same architecture of sub-models, every sub-model possess similar characteristics. Block-switching consists of multiple channels. Every sub-model is suitably divided in its lower body and upper body. Lower body contains of all the convolutional layer. Lower parts are again merged to form a single output by including parallel channels of blockswitching while the other parts are discarded. Every submodel has different model parameters due to random initialization and stochasticity in the training process, therefore they tend to have similar characteristics in terms of classification, accuracy and robustness. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Grad-CAM</head><p>The aim of Grad-CAM <ref type="bibr" target="#b6">[7]</ref> is to provide a visual explanation for model decision by using gradients flowing into the final convolution layer. Further it is used to produce a map highlighting the important region in the map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Methodology</head><p>The flowchart <ref type="figure">(Fig 5.)</ref> depicts the entire flow of processes which are deployed in the proposed architecture. The unique combination of Auto-encoder, Block-switching <ref type="bibr" target="#b7">[8]</ref> and grad-CAM <ref type="bibr" target="#b6">[7]</ref> increases the accuracy and robustness of the model.</p><p>The proposed architecture follows several phases namelyimage classification, building of thoroughly supervised dataset of adversarial images, auto-encoder operating as a noise remover along with block-switching containing multiple sub-channels, producing highlighted maps as an output from grad-CAM and ultimately the output of the model is classified image with highlighted important regions on it.</p><p>As an initial step in the architecture, image is taken as input for two purposes specificallyclassification and building of thoroughly supervised dataset of adversarial image. Image classification is performed to ascertain the entire image. The dataset which consists of two differently classified images (original and adversarial) is provided as an input to autoencoder. Auto-encoder removes noise from the input image and yields a denoised image as an output. The output of autoencoder is taken as an input by block-switching model. Block-switching contains different sub-channels which are selected randomly to render the output. Grad-CAM are activation maps which generate highlights on the classified image to uncover important regions in it. The output of block-switching is taken as an input for Grad-CAM. It then processes the image obtained from the image classification model to provide a visual explanation for model decision by using gradients flowing into the final convolution layer. The output of Grad-CAM is the highlighted image with important regions in it. The output of Grad-CAM can be used for anomaly detection. It also tends to notice the attack which encompasses the above deployed tightly coupled architecture of auto-encoder and block-switching model. Ultimately the output of the above explained architecture is the classification result backed by the Grad-CAM. The proposed architecture is tightly coupled and secured in terms of dataflow and levels of classification deployed to prevent the adversarial attacks. The combination of distinct phases of the model is unique and present an overall efficient and architecture. V. RESULTS AND DISCUSSION</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Auto-encoder</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input-Attack image with perturbations</head><p>Output-Image is formed by removing perturbations by auto-encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Grad-CAM</head><p>Further the image classification and grad-CAM output can be used for verification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Overall Accuracy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>The attack by the FGSM <ref type="bibr" target="#b8">[9]</ref> model is effectively countered by the proposed defence architecture with an accuracy of 88.54%. The unique combination of auto-encoder along with randomization in the classification model ensures efficiency, high accuracy and robustness. This work can be extended to capture images form motion videos.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>o</head><label></label><figDesc>adv_x: Adversarial Image o x: Original Image o y: Original input label o ?: Multiplier to ensure the perturbations are small. o ?: Model parameters o J: Loss</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig 1 .</head><label>1</label><figDesc>Architecture of Generative Adversarial Networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>:</head><label></label><figDesc>These are Neural Networks that used Unsupervised Learning to perform data compression, denoising, dimensionality reduction, etc. The layout of auto encoders are given in Fig 2. It consists of 3 parts:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig 2 .</head><label>2</label><figDesc>Auto-Encoder architecture. The input image is encoded to a compressed Representation and then decoded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig 3 .</head><label>3</label><figDesc>Defense architecture using the combination of autoencoder and block-switching method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig 4 .</head><label>4</label><figDesc>Levels of Block-switching model training, and preview of multiple channels and sub-models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig 5 .Fig 6 .</head><label>56</label><figDesc>Combination of auto-encoder, block-switching and grad-CAM Output of respective modules.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>COMPARITIVE STUDY Existing Methods Advantage Disadvantage</head><label></label><figDesc>II. LITERATURE REVIEWThe proposed system majorly focuses on static image input and defence architecture. Following are the characteristics of the proposed model:o Combination of two models to effectively defend both Black box and White Box attack.</figDesc><table><row><cell>III. PROPOSED WORK</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Title</cell><cell></cell><cell></cell><cell>Merit</cell><cell></cell><cell></cell><cell>Demerit</cell></row><row><cell cols="3">One Pixel attack for</cell><cell>Requires</cell><cell cols="3">less</cell><cell>For high definition</cell></row><row><cell>fooling</cell><cell></cell><cell>Deep</cell><cell cols="2">adversarial</cell><cell></cell><cell>image</cell><cell>required</cell></row><row><cell cols="3">Neural Networks</cell><cell cols="2">information</cell><cell></cell><cell>multiple</cell><cell>pixel</cell></row><row><cell>2017 [2]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>perturbations</cell></row><row><cell>PuVAE:</cell><cell></cell><cell>A</cell><cell cols="2">Takes only</cell><cell></cell><cell>Only filter</cell></row><row><cell cols="3">Variational Auto-</cell><cell>0.114</cell><cell></cell><cell></cell><cell>Limited examples</cell></row><row><cell cols="3">encoder to Purify</cell><cell cols="2">second to</cell><cell></cell></row><row><cell cols="2">Adversarial</cell><cell></cell><cell>process</cell><cell></cell><cell></cell></row><row><cell>Examples</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2019 [3]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Defensive Dropout</cell><cell cols="2">Decreased</cell><cell cols="2">the</cell><cell>Unable to defend</cell></row><row><cell>For</cell><cell cols="2">Hardening</cell><cell cols="4">white box attack</cell><cell>all</cell><cell>types</cell><cell>of</cell></row><row><cell>Deep</cell><cell cols="2">Neural</cell><cell cols="4">rate from 100</cell><cell>adversarial attacks</cell></row><row><cell>Networks</cell><cell></cell><cell>under</cell><cell cols="4">percent to 13</cell></row><row><cell cols="2">Adversarial</cell><cell></cell><cell>percent</cell><cell></cell><cell></cell></row><row><cell cols="2">Attacks-2019</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">2.1 Anomaly Detects anomaly</cell><cell></cell><cell></cell><cell>Requires additional</cell></row><row><cell>Detection</cell><cell></cell><cell>and</cell><cell>avoid</cell><cell cols="2">input</cell><cell>Time. It can also be</cell></row><row><cell>Model</cell><cell></cell><cell cols="4">reaching to the actual</cell><cell>termed as bottleneck</cell></row><row><cell></cell><cell></cell><cell>model.</cell><cell></cell><cell></cell><cell></cell><cell>for fast models</cell></row><row><cell>Pruning</cell><cell></cell><cell cols="3">Prevents Noise Based</cell><cell></cell><cell>Not efficient for</cell></row><row><cell>Method</cell><cell></cell><cell cols="2">Perturbations.</cell><cell></cell><cell></cell><cell>Black box attacks</cell></row><row><cell cols="2">Distributed</cell><cell cols="2">Blue Channel</cell><cell></cell><cell></cell><cell>Multiple model</cell></row><row><cell>Colour</cell><cell></cell><cell cols="2">Performs</cell><cell></cell><cell></cell><cell>Occupy large time and</cell></row><row><cell>Channels</cell><cell></cell><cell cols="4">exceptionally well to</cell><cell>space while running.</cell></row><row><cell></cell><cell></cell><cell cols="2">determine</cell><cell cols="2">any</cell><cell>Not good for video</cell></row><row><cell></cell><cell></cell><cell cols="3">adversarial attacks.</cell><cell></cell><cell>input.</cell></row><row><cell cols="2">Adversarial</cell><cell cols="3">Makes model robust</cell><cell></cell><cell>Difficult to train for</cell></row><row><cell>Dataset</cell><cell></cell><cell cols="2">against those</cell><cell></cell><cell></cell><cell>all adversarial</cell></row><row><cell></cell><cell></cell><cell cols="2">Adversarial</cell><cell cols="2">input</cell><cell>attack types as it</cell></row><row><cell></cell><cell></cell><cell cols="2">which is trained.</cell><cell></cell><cell></cell><cell>Largely affects the</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>accuracy.</cell></row><row><cell>Random</cell><cell></cell><cell cols="3">Good for White box</cell><cell></cell><cell>Not efficient for</cell></row><row><cell>Weight</cell><cell></cell><cell>attacks</cell><cell></cell><cell></cell><cell></cell><cell>Black box attacks</cell></row><row><cell>switching</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Prateek Mittal: DARTS: Deceiving Autonomous Cars with Toxic Signs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chawin</forename><surname>Sitawarin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><forename type="middle">Nitin</forename><surname>Bhagoji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arsalan</forename><surname>Mosenia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mung</forename><surname>Chiang</surname></persName>
		</author>
		<idno>abs/1802.06430</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">One Pixel Attack for Fooling Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><forename type="middle">&amp;amp;</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><forename type="middle">&amp;amp;</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kouichi</forename><surname>Sakurai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="828" to="841" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Nam Ik Cho:PuVAE: A Variational Autoencoder to Purify Adversarial Examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uiwon</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyemi</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="126582" to="126593" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Wagner</surname></persName>
		</author>
		<title level="m">Audio Adversarial Examples: Targeted Attacks on Speech-to-Text. IEEE Symposium on Security and Privacy Workshops</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Adversarial Examples: Attacks and Defenses for Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Yuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Generating Adversarial Examples with Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaowei</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramprasaath</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Block Switching: A Stochastic Approach for Deep Learning Security</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Explaining and Harnessing Adversarial Examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An intelligent Context Based Multi-layered Bayesian Inferential predictive analytic framework for classifying machine states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Revathi</forename><surname>Venkataraman</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12652-020-02411-2</idno>
		<ptr target="https://doi.org/10.1007/s12652-020-02411-2" />
	</analytic>
	<monogr>
		<title level="j">Journal of Ambient intelligence and Humanized computing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Attack Selectivity of Adversarial Examples in Remote Sensing Image Scene Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guowei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhe</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="137477" to="137489" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ASNM Datasets: A Collection of Network Attacks for Testing of Adversarial Classifiers and Intrusion Detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Homoliak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamil</forename><surname>Malinka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Han?cek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="112427" to="112453" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial Dual Network Learning With Randomized Image Transform for Restoring Attacked Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihai</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="22617" to="22624" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adversarial Attack: A New Threat to Smart Devices and How to Defend It</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Pai</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanrui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sicheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunpeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Consumer Electron. Mag</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="49" to="55" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adversarial examples for replay attacks against CNN-based face recognition with anti-spoofing capability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benedetta</forename><surname>Tondi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Barni</surname></persName>
		</author>
		<idno>197-198: 102988</idno>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The technology of adversarial attacks in signal recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haojun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Commun</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page">101199</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Defense against adversarial attacks by low-level image transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxia</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1453" to="1466" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahsan</forename><surname>Md</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">A</forename><surname>Ayub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Talbert</surname></persName>
		</author>
		<title level="m">Ambareen Siraj: Model Evasion Attack on Intrusion Detection Systems using Adversarial Machine Learning. CISS 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep Learning Defense Method Against Adversarial Attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SMC</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="3667" to="3672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adversarial machine learning based partial-model attack in IoT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shangqing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yalin</forename><forename type="middle">E</forename><surname>Sagduyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WiseML@WiSec</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adversarial Attacks on Convolutional Neural Networks in Facial Recognition Domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yigit</forename><surname>Alparslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Keim-Shenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shweta</forename><surname>Khade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Greenstadt</surname></persName>
		</author>
		<idno>abs/2001.11137</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Defense of Adversarial Example with Conditional Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangchao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianjin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youwen</forename><surname>Zhang</surname></persName>
		</author>
		<idno>3932584:1-3932584:12</idno>
	</analytic>
	<monogr>
		<title level="j">Secur. Commun. Networks</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adversarial Attack and Defense of Structured Prediction Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjuan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kewei</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2327" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep Learning Defense Method Against Adversarial Attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SMC</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="3667" to="3672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Folz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Palacio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rn</forename><surname>Hees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Andreas Dengel:Adversarial Defense based on Structure-to-Signal Autoencoders</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="3568" to="3577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Encryption Inspired Adversarial Defense for Visual Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maungmaung</forename><surname>Aprilpyone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitoshi</forename><surname>Kiya</surname></persName>
		</author>
		<idno>abs/2005.07998</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">DeepRobust: A PyTorch Library for Adversarial Attacks and Defenses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<idno>abs/2005.06149</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
