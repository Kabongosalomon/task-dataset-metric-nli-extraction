<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Annotating the Tweebank Corpus on Named Entity Recognition and Building NLP Models for Social Media Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MIT Center for Constructive Communication</orgName>
								<address>
									<addrLine>75 Amherst St</addrLine>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Hua</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MIT Center for Constructive Communication</orgName>
								<address>
									<addrLine>75 Amherst St</addrLine>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Beeferman</surname></persName>
							<email>dougb5@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">MIT Center for Constructive Communication</orgName>
								<address>
									<addrLine>75 Amherst St</addrLine>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deb</forename><surname>Roy</surname></persName>
							<email>dkroy@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">MIT Center for Constructive Communication</orgName>
								<address>
									<addrLine>75 Amherst St</addrLine>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Annotating the Tweebank Corpus on Named Entity Recognition and Building NLP Models for Social Media Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>text annotation</term>
					<term>noisy text</term>
					<term>NLP toolkit</term>
					<term>Twitter</term>
					<term>named entity recognition</term>
					<term>tokenization</term>
					<term>lemmatization</term>
					<term>part-of-speech tagging</term>
					<term>dependency parsing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social media data such as Twitter messages ("tweets") pose a particular challenge to NLP systems because of their short, noisy, and colloquial nature. Tasks such as Named Entity Recognition (NER) and syntactic parsing require highly domain-matched training data for good performance. To date, there is no complete training corpus for both NER and syntactic analysis (e.g., part of speech tagging, dependency parsing) of tweets. While there are some publicly available annotated NLP datasets of tweets, they are only designed for individual tasks. In this study, we aim to create Tweebank-NER, an English NER corpus based on Tweebank V2 (TB2), train state-of-the-art (SOTA) Tweet NLP models on TB2, and release an NLP pipeline called Twitter-Stanza. We annotate named entities in TB2 using Amazon Mechanical Turk and measure the quality of our annotations. We train the Stanza pipeline on TB2 and compare with alternative NLP frameworks (e.g., FLAIR, spaCy) and transformer-based models. The Stanza tokenizer and lemmatizer achieve SOTA performance on TB2, while the Stanza NER tagger, part-of-speech (POS) tagger, and dependency parser achieve competitive performance against non-transformer models. The transformer-based models establish a strong baseline in Tweebank-NER and achieve the new SOTA performance in POS tagging and dependency parsing on TB2. We release the dataset and make both the Stanza pipeline and BERTweet-based models available "off-the-shelf" for use in future Tweet NLP research. Our source code, data, and pre-trained models are available at: https://github.com/social-machines/TweebankNLP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Researchers use text data from social media platforms such as Twitter and Reddit for a wide range of studies including opinion mining, socio-cultural analysis, and language variation. Messages posted to such platforms are typically written in a less formal style than what are found in conventional data sources for NLP models, namely news articles, papers, websites, and books. Processing the noisy and informal language of social media is challenging for traditional NLP tools because such messages are usually short in length and irregular in spelling and structure. In response, the NLP community has been constructing language resources and building NLP pipelines for social media data, especially for Twitter. Annotating social media language resources is important to the development of NLP tools. <ref type="bibr" target="#b10">Foster et al. (2011)</ref> is the one of the earliest attempts to annotate tweets in the Penn Treebank (PTB) format. Following a similar PTB-style convention suggested by <ref type="bibr" target="#b29">Schneider et al. (2013)</ref>, <ref type="bibr" target="#b14">Kong et al. (2014)</ref> created Tweebank V1. However, the PTB annotation guidelines leave many annotation decisions unspecified and are therefore unsuitable for informal and usergenerated text. After Universal Dependencies (UD) <ref type="bibr" target="#b19">(Nivre et al., 2016)</ref> was introduced to enable consistent annotation across different languages and gen-The first two authors contribute equally. YH is also affiliated with Harvard Medical School. res, <ref type="bibr" target="#b15">Liu et al. (2018)</ref> introduced a new tweet-based Tweebank V2 in UD, including tokenization, part-ofspeech (POS) tags, and (labeled) Universal Dependencies. Besides syntactic annotation, NLP researchers have also annotated tweets on named entities. <ref type="bibr" target="#b26">Ritter et al. (2011)</ref> first introduced this English Twitter NER task and found that NER systems trained on the news perform poorly on tweets. Since then, the noisy user-generated text (WNUT) workshop has proposed a few benchmark datasets including WNUT15 <ref type="bibr" target="#b35">(Xu et al., 2015)</ref>, WNUT16 <ref type="bibr" target="#b35">(Xu et al., 2015)</ref>, and WNUT17 <ref type="bibr" target="#b7">(Derczynski et al., 2017)</ref> for Twitter lexical normalization and named entity recognition (NER). However, these benchmarks are not based upon TB2, which contains high-quality UD annotations. Annotating named entities in TB2 fills a gap in NLP research, allowing researchers to train multi-task learning models in NER, POS tagging, and dependency parsing, and study the linguistic relationship between syntactic labels and named entities in the Twitter domain.</p><p>Many researchers have invested in building better NLP pipelines for tokenization, POS tagging, parsing, and NER. The earliest work focuses on Twitter POS taggers <ref type="bibr" target="#b11">(Gimpel et al., 2010;</ref><ref type="bibr" target="#b21">Owoputi et al., 2013)</ref> and NER <ref type="bibr" target="#b26">(Ritter et al., 2011)</ref>. Later, <ref type="bibr" target="#b14">Kong et al. (2014)</ref> published TweeboParser on Tweebank V1 to include tokenization, POS tagging, and dependency parsing. <ref type="bibr" target="#b15">Liu et al. (2018)</ref> further improved the whole pipeline based on TB2. The current state-of-the-art (SOTA) pipeline in POS tagging and NER is based on BERT pre-trained on a large number of tweets <ref type="bibr" target="#b18">Nguyen et al. (2020)</ref>. However, these efforts (1) are often no longer maintained <ref type="bibr" target="#b26">(Ritter et al., 2011;</ref><ref type="bibr" target="#b14">Kong et al., 2014)</ref>, (2) do not contain publicly available NLP models (e.g., NER, POS tagger) <ref type="bibr" target="#b18">(Nguyen et al., 2020)</ref>, (3) are written in C/C++ or R with complicated dependencies and installation process (e.g., Twpipe <ref type="bibr" target="#b15">(Liu et al., 2018)</ref> and UD-Pipe <ref type="bibr" target="#b32">(Straka et al., 2016)</ref>), making them difficult to be integrated into Python frameworks and to be used in an "off-the-shelf" fashion. Many modern NLP tools in Python such as spaCy 1 , Stanza <ref type="bibr" target="#b24">(Qi et al., 2020)</ref>, and FLAIR <ref type="bibr" target="#b2">(Akbik et al., 2019)</ref> have been developed for standard NLP benchmarks but have never been adapted to Tweet NLP tasks. In this study, we choose Stanza over other NLP frameworks because (1) the Stanza framework achieves SOTA or competitive performance on many NLP tasks across 66 languages <ref type="bibr" target="#b24">(Qi et al., 2020)</ref>, (2) Stanza supports both CPU and GPU training and inference while transformer-based models (e.g., BERTweet) need GPU, (3) Stanza shows superior performance against spaCy in our experiments despite slower speeds, (4) Stanza is competitive in speed compared with FLAIR of similar accuracy <ref type="bibr" target="#b24">(Qi et al., 2020)</ref>, but the FLAIR dependency parser is still under development. In this paper, we annotate Tweebank V2 on NER to create Tweebank-NER and also build Tweet NLP models based on Stanza and transformer models. We run additional experiments to answer the following questions: (1) How is the quality of the NER annotations? (2) Do NER models trained on existing Twitter NER data perform well on Tweebank-NER? (3) How do Stanza models perform compared with other NLP frameworks on the core Tweet NLP tasks? (4) How do transformer-based models perform compared with traditional models on these tasks? Our contributions are as follows:</p><p>? We annotate Tweebank V2, the main treebank for English Twitter NLP tasks, on NER. This annotation not only provides a new benchmark (Tweebank-NER) for Twitter NER but also makes Tweebank a complete dataset for both syntactic tasks and NER, making it suitable for training multi-task learning models in POS tagging, dependency parsing, and NER.</p><p>? We leverage the Stanza framework to present an accurate and fast Tweet NLP pipeline called Twitter-Stanza. It includes NER, tokenization, lemmatization, POS tagging, and dependency parsing modules, and it supports both CPU and GPU computation.</p><p>? We compare Twitter-Stanza against existing models for each presented NLP task, confirming that Stanza's simple neural architecture 1 https://spacy.io/ is effective and suitable for tweets. Among nontransformer models, the Twitter-Stanza tokenizer and lemmatizer achieve SOTA performance on TB2, and its POS tagger, dependency parser, and NER model obtain competitive performance.</p><p>? We also train transformer-based models to establish a strong baseline on the Tweebank-NER benchmark and SOTA performance in POS tagging and dependency parsing on TB2. We upload the BERTweet-based NER and POS taggers to the Hugging Face Hub: https:// huggingface.co/TweebankNLP</p><p>? We release our data, models, and code. Our Twitter-Stanza pipeline is highly compatible with Stanza's Python interface and is simple to use in an "off-the-shelf" fashion. We hope that our Twitter-Stanza and Hugging Face BERTweet models can serve as a convenient NLP tool and a strong baseline for future research and applications of Tweet analytic tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset and Annotation Scheme</head><p>In this study, we primarily work on the Tweebank V2 dataset and develop its NER annotations through rigorous annotation guidelines. We also evaluate the quality of our annotations, showing that it has a good F1 interannotator agreement score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Datasets and Annotation Statistics</head><p>Tweebank V2 (TB2) <ref type="bibr" target="#b14">(Kong et al., 2014;</ref><ref type="bibr" target="#b15">Liu et al., 2018</ref>)is a collection of 3,550 labeled anonymous English tweets annotated in Universal Dependencies. It is a commonly used corpus for the training and finetuning of NLP systems on social media texts. A summary of TB2 is shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Annotation Guidelines</head><p>We follow the CoNLL 2003 guidelines 2 to annotate named entities. We are aware that some NER annotations (e.g., English OntoNotes) have more than four classes. We adopt the standard four-class CoNLL 2003 NER guidelines for two reasons. One one hand, adopting a more fine-grained annotation scheme is more challenging for human annotators. The 4-class scheme is already quite challenging for humans since the interannotator agreement is low for the MISC class. On the other hand, Tweebank is relatively small, with only 3,550 tweets. An annotation scheme with more classes than that will mean fewer instances per class, and greater difficulty for NER models to learn efficiently. To help annotators understand the guidelines, we provide multiple examples for each rule and ask annotators to read them before the task. Our task focuses on the following four named entities:</p><p>? PER: persons (e.g., Joe Biden, joe biden, Ben, 50 Cent, Jesus) To handle challenges in tweets, we also add requirements consistent with <ref type="bibr" target="#b26">(Ritter et al., 2011)</ref>: (1) ignore numerical entities (MONEY, NUMBER, OR-DINAL, PERCENT), (2) ignore temporal entities (DATE, TIME, DURATION, SET), (3) "At mentions" are not named entities (e.g., allow "Donald Trump" but not @DonaldTrump), (4) #hashtags are not named entities (e.g., allow "BLM" but not "#BLM"), (5) URLs are not named entities (e.g., disallow https://www.google.com/).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Annotation Logistics</head><p>We use the Qualtrics platform to design the sequence labeling task and Amazon Mechanical Turk to recruit annotators. We first launch a pilot study, annotate each of the 100 tweets, and discuss tweets with divergent annotations. Based on the pilot study, we develop a series of annotation rules and precautions. During the recruiting process, each annotator is given an overview of annotation conventions and our guidelines, after which they are asked to complete the qualification test. The qualification test consists of 7 tweets that are selected from the pilot study. An annotator must make fewer than 2 errors and not make any significant error in order to pass the qualification test. We consider a significant error to be one in which any URL, @USER, or hashtag is labeled as a named entity; or one in which the PER-SON, LOCATION, and ORG categories are confused with each other. After all tweets have been annotated by at least 3 annotators, we merge the annotation results and create the Tweebank-NER dataset in the BIO format <ref type="bibr" target="#b25">(Ratinov and Roth, 2009</ref>). In the merging process, if at least two annotators give the annotation result for a tweet, we use that result as the final annotation. Otherwise, we discuss and re-annotate the tweet to reach a consensus. We identify 178 span annotations whose three annotations are different from each other and decide their gold annotations collectively by two authors. We find that one of the three annotators' answers is the same as the final annotation for 155 out of the 178 annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Annotation Quality</head><p>We first evaluate the quality of the annotations using a measure of inter-annotator agreement (IAA). For NER, Cohen's Kappa is not the best measure because it needs the number of negative cases, but NER is a sequence tagging task. Therefore, we follow previous work <ref type="bibr" target="#b13">(Hripcsak and Rothschild, 2005;</ref><ref type="bibr" target="#b12">Grouin et al., 2011;</ref><ref type="bibr" target="#b4">Brandsen et al., 2020)</ref> to use the token-level pairwise F1 score calculated without the O label as a better measure for IAA in NER <ref type="bibr" target="#b6">(Deleger et al., 2012)</ref>. In  In the future, we suggest a few ways to improve the annotation quality. The first way is to increase the number annotators per tweet in both the initial and merge stages. Second, hiring a small number of experienced annotators instead of using crowdsourcing platforms will make the annotations more consistent. Third, adopting a human-in-the-loop approach allows annotators to focus on difficult instances from MISC and ORG, which can reduce the cost and improve the performance of the models at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods for NLP Modeling</head><p>Stanza is a state-of-the-art and efficient framework for many NLP tasks <ref type="bibr" target="#b24">(Qi et al., 2020;</ref><ref type="bibr" target="#b37">Zhang et al., 2021)</ref> and it supports both NER and syntactic tasks. We use Stanza to train NER models as well as syntactic models (tokenization, lemmatization, POS tagging, dependency parsing) on TB2. For more detailed information on Stanza, we refer the readers to the Stanza paper <ref type="bibr" target="#b24">(Qi et al., 2020)</ref> and its current website 3 . We use Twitter GloVe embeddings <ref type="bibr" target="#b22">(Pennington et al., 2014)</ref>  Transformers is a library of pre-trained transformer models for NLP and it provides a TokenClassification module 4 , which is adopted for NER and POS tagging. We denote these models as HuggingFace-BERTweet in our experiments. The spaCy-transformers framework provides the spaCy interface to combine pre-trained representations from transformer-based language models and its own NLP models via Hugging Face's transformers. To train spaCy, we adopt the default NER setting 5 and the default syntactic NLP pipeline 6 . For FLAIR, we train its NER and syntactic modules with the default settings as well. For spaCy-transformers models, we finetune BERTweet-base and XLM-RoBERTa-base language models via spaCy-transformers for NER, POS Tagging, and dependency parsing 7 . We denote them as spaCy-BERTweet and spaCy-XLM-RoBERTa in the paper. BERTweet <ref type="bibr" target="#b18">(Nguyen et al., 2020)</ref> is the first public large-scale language model for English tweets based on RoBERTa and XLM-RoBERTa-base is a multilingual version of RoBERTa-base. All transformer-based models show strong performance in Tweet NER and POS tagging <ref type="bibr" target="#b18">(Nguyen et al., 2020)</ref>. The architecture and training details of the models above can be found at our public repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Named Entity Recognition</head><p>In this paper, we adopt the four-class convention to define NER as a task to locate and classify named entities mentioned in unstructured text into four predefined categories: PER, ORG, LOC, and MISC (Sang  <ref type="bibr" target="#b27">Meulder, 2003)</ref>. We use the Stanza NER architecture for training and evaluation, which is a contextualized string representation-based sequence tagger <ref type="bibr" target="#b1">(Akbik et al., 2018)</ref>. This model contains a forward and a backward character-level LSTM language model to extract token-level representations and a BiLSTM-CRF sequence labeler to predict the named entities. We also train the default NER models for SpaCy, FLAIR, HuggingFace-BERTweet, and spaCy-BERTweet for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Syntactic NLP Tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Tokenization</head><p>Tokenizers predict whether a given character in a sentence is the end of a token. The Stanza tokenizer jointly works on tokenization and sentence segmentation, by modeling them as a tagging problem over character sequences. In accordance with previous work <ref type="bibr" target="#b11">(Gimpel et al., 2010;</ref><ref type="bibr" target="#b15">Liu et al., 2018)</ref>, we focus on the performance in tokenization, as tweets are usually short with a single sentence.</p><p>To compare with spaCy, we train a spaCy tokenizer named char pretokenizer.v1. FLAIR uses spaCy's tokenizer, so we exclude it from comparison. We also include baselines mentioned in previous work <ref type="bibr" target="#b14">(Kong et al., 2014;</ref><ref type="bibr" target="#b15">Liu et al., 2018)</ref>. Twokenizer (O'Connor et al., 2010) is a regex-based tokenizer and does not adapt to the UD tokenization scheme. Stanford CoreNLP , spaCy, and UDPipe v1.2 <ref type="bibr" target="#b31">(Straka and Strakov?, 2017)</ref> are three popular NLP frameworks re-trained on TB2. Twpipe tokenizer <ref type="bibr" target="#b15">(Liu et al., 2018</ref>) is similar to UDPipe, but replaces GRU in UDPipe with an LSTM and uses a larger hidden unit number. We do not compare with transformer-based models because they use subword-level tokenization schemes like WordPiece <ref type="bibr" target="#b34">(Wu et al., 2016)</ref> and BPE <ref type="bibr" target="#b30">(Sennrich et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Lemmatization</head><p>Lemmatization is the process of recovering each word in a sentence to its canonical form. We train the Stanza lemmatizer on TB2, which is implemented as an ensemble model of a dictionary-based lemmatizer and a neural seq2seq lemmatizer. We compare the Stanza lemmatizer against three lemmatizers from spaCy, NLTK, and FLAIR <ref type="table">(Table 7)</ref>. Both NLTK and spaCy lemmatizer are rule-based and use a dictionary to look up the canonical form given a word and it POS tag. The FLAIR lemmatizer is a char-level seq2seq model. We provide gold POS tags for lemmatization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">POS Tagging</head><p>POS tagging assigns each token in a sentence a POS tag. We train the Stanza POS tagger, a bidirectional long short-term memory network as the basic architecture to predict the universal POS (UPOS) tags. We ignore the language-specific POS (XPOS) tags because TB2 only contains UPOS tags.</p><p>We also train the default POS taggers for SpaCy, FLAIR, HuggingFace-BERTweet, spaCy-BERTweet, spaCy-XLM-RoBERTa. We include performance from existing work in Tweet POS tagging: <ref type="formula">(1)</ref>   <ref type="bibr" target="#b18">(Nguyen et al., 2020)</ref>. The first four models were re-trained on the combination of TB2 and UD English-EWT (Ann Bies, Justin Mott, Colin Warner, Seth Kulick, 2012) training sets, whereas the BERTweet-based tagger was fine-tuned solely on TB2.</p><p>HuggingFace-BERTweet has the same architecture implementation as <ref type="bibr" target="#b18">Nguyen et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4.">Dependency Parsing</head><p>Dependency parsing predicts a syntactic structure for a sentence, where every word in the sentence is assigned a syntactic head that points to either another word in the sentence or an artificial root symbol. Stanza's dependency parser combines a Bi-LSTM-based deep biaffine neural parser  and two linguistic features, which can significantly improve parsing accuracy <ref type="bibr" target="#b23">(Qi et al., 2018)</ref>. Gold-standard tokenization and automatic POS tags are used.</p><p>We also re-train spaCy, spaCy-BERTweet, and spaCy-RoBERTa dependency parsers with their default parser architectures <ref type="bibr" target="#b38">8</ref> . We compare our Stanza models with previous work: <ref type="formula">(1)</ref>   <ref type="bibr" target="#b15">(Liu et al., 2018)</ref>, (5) A distilled graph-based parser of the previous ensemble model <ref type="bibr" target="#b15">(Liu et al., 2018)</ref>. These models are all trained on TB2+UD English-EWT. We are aware that Stymne (2020) trained a transition-based uuparser (de Lhoneux et al., 2017) on a combination of TB2, UD English-EWT, and more out-of-domain data (English GUM <ref type="bibr" target="#b36">(Zeldes, 2017)</ref>, LinES <ref type="bibr" target="#b0">(Ahrenberg, 2007)</ref>, ParTUT <ref type="bibr" target="#b28">(Sanguinetti and Bosco, 2015)</ref>) to further boost model performance, but we do not experiment with this data combination to be consistent with <ref type="bibr" target="#b15">Liu et al. (2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation</head><p>We train the NER and syntactic NLP models described above with 1) TB2 training data (the default data setting), 2) TB2 training data + extra Twitter data (the combined data setting). For the combined data setting, we add the training and dev sets from other data sources to TB2's training and dev sets respectively. Specifically, we add WNUT17 9 <ref type="bibr">(Derczynski 8</ref> FLAIR and Hugging Face's transformers do not contain dependency parsing by default. <ref type="bibr">9</ref> We map both "group" and "corporation" to "ORG", and both "creative work" and "product" to "MISC". et al., 2017) for NER. For syntactic NLP tasks, we add UD English-EWT (Ann <ref type="bibr" target="#b39">Bies, Justin Mott, Colin Warner, Seth Kulick, 2012)</ref>. We pick the best models based on the corresponding dev sets and report their performance on their TB2 test sets. For each task, we compare Stanza models with existing studies and alternative NLP frameworks.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Performance in NER</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Main Findings</head><p>The NER experiments presented in <ref type="table" target="#tab_8">Table 3</ref> show that the Stanza NER model (TB2+W17) achieves the best performance among all non-transformer models. At the same time, the Stanza model is up to 75% smaller than the second-best FLAIR model <ref type="bibr" target="#b24">(Qi et al., 2020)</ref>. For transformer-based approaches, spacy-BERTweet and HuggingFace-BERTweet have close performance to each other. The HuggingFace-BERTweet approach trained on TB2+W17 achieves the highest performance (74.35%) on Tweebank-NER, establishing a strong benchmark for future research. We also find that combining the training data from both WNUT17 and TB2 improves the performance of spaCy, FLAIR, Stanza, and BERTweet-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Confusion Matrix Analysis</head><p>In <ref type="figure" target="#fig_1">Figure 1</ref>, we plot a confusion matrix for all four entity types and "O", the label for tokens that do not belong to any of these types. The diagonal and the vertical blue lines are expected because the cells on the diagonal are when the algorithm predicts the correct entity and the vertical line is when the algorithm mistakes an entity for the "O" entity, which is the most common error for NER. We notice that MISC entities are easily mistaken as "O", which corresponds to the annotation statistics in <ref type="table" target="#tab_2">Table 2</ref>, where MISC has the lowest IIA score in pairwise F1. Thus, MISC is the most challenging of the four types for both humans and machines.  <ref type="table">Table 4</ref>: Common mistakes made by the Stanza (W17+TB2) NER model for each error type. "X ? O" means the model predicts X entity to be O by mistake. Green and red texts are gold annotations of the corresponding type in each row. Correct predictions are in bold green and gold annotations missed by the model are in bold red. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">Error Analysis</head><p>We identify the most common error types that Stanza (TB2+W17) 10 makes on the TB2 test in <ref type="figure" target="#fig_1">Figure 1</ref>: predicting PER, LOC, ORG, MISC to be O. We pick some representative examples for each error type, shown in <ref type="table">Table 4</ref>. For the P ER ? O error type, every first letter in a word is capitalized and the model fails to recognize the famous investor "Warren Buffet" in such a context. We find that person entities with abbreviations (e.g., "GD" for "G-dragon"), lower case (e.g., "kush" for "Kush"), or irregular contextual capitalization are challenging to the NER system. For the LOC ? O error type, the structure to encode location is complicated and sometimes interrupted by the parentheses and dashes (e.g., "-day Adventist Church"). In this case, it is caused by the fact that "Seventh-day" is tokenized into three words in TB2. For the ORG/M ISC ? O examples, "Guess Who" is a rock band and "Sounds Live Feels Live" is a concert tour by Australian poprock band 5 Seconds of Summer. These named entities tend to contain common English verbs with their first letters capitalized. It is difficult to annotate them correctly if the model does not have access to world and <ref type="bibr">10</ref> We pick Stanza over BERTweet for error analysis because we only aimed to publish the Stanza pipeline at the beginning. We eventually publish the BERTweet models too. domain knowledge. Our analysis points to the future Twitter NER research to introduce text perturbations into training and to encode commonsense knowledge into NER modeling.   <ref type="table" target="#tab_11">Table 5</ref>, we compare the performance of these models trained on WNUT17 against the ones trained on TB2. We show that the performance of all the models drops significantly if we use the pre-trained model from WNUT17, meaning the Tweebank-NER dataset is still challenging for current NER models and can be used as an additional benchmark to evaluate NER models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Performance in Syntactic NLP Tasks</head><p>Apart from NER, we train and evaluate Stanza models for tokenization, lemmatization, POS tagging, and dependency parsing by leveraging TB2 and UD English-EWT. For each task, we compare our models against previous work on the TB2 test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Tokenization Performance</head><p>In <ref type="table">Table 6</ref>, we observe that the Stanza model trained on TB2 outperforms Twpipe tokenizer, the previous SOTA model, and it achieves slightly higher performance than the spaCy tokenizer. We also find that blending TB2 and UD English-EWT for training brings down the tokenization performance slightly. This is probably because the data source of UD English-EWT, which is collected from weblogs, newsgroups, emails, reviews, and Yahoo! Answers, represents a different dialect from Twitter English.  <ref type="table">Table 6</ref>: Tokenizer comparison on the TB2 test set. "TB2" indicates to use TB2 for training. "TB2+EWT" indicates to combine TB2 and UD English-EWT for training. Note that the first four results are rounded to one decimal place by <ref type="bibr" target="#b15">Liu et al., (2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Lemmatization Performance</head><p>None of the previous Twitter NLP work reports the lemmatization performance on TB2. As shown in <ref type="table">Ta</ref>  <ref type="table">Table 7</ref>: Lemmatization results on the TB2 test set. "TB2" is to use TB2 for training. "TB2+EWT" is to combine TB2 and UD English-EWT for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">POS Tagging Performance</head><p>As shown in <ref type="table" target="#tab_15">Table 8</ref>, HuggingFace-BERTweet (TB2) replicates the SOTA performance from BERTweet <ref type="bibr" target="#b18">(Nguyen et al., 2020)</ref> in terms of accuracy. When trained on the combined data of TB2 and UD English-EWT, HuggingFace-BERTweet achieves the best performance (95.38%) in accuracy out of all the models. Compared to HuggingFace-BERTweet, spaCytransformers models perform worse. The spaCy-XLM-RoBERTa trained on TB2 is 1.3% lower than <ref type="bibr" target="#b18">Nguyen et al. (2020)</ref>. We conjecture that the difference is mainly due to the implementations of the POS tagging layer between spaCy and HuggingFace-BERTweet, which is the same as <ref type="bibr" target="#b18">Nguyen et al. (2020</ref>   <ref type="bibr" target="#b15">Liu et al. (2018)</ref> mentioned, the ensemble model is 20 times larger in size compared to the Stanza parser, although the former performs better. Finally, we confirm that the combination of TB2 and UD English-EWT training sets boost the performance for non-transformer models <ref type="bibr" target="#b15">(Liu et al., 2018)</ref>. The data combination brings down the performance of transformer-based models, which is consistent with our observations in tokenization, POS tagging, and dependency parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we introduce four-class named entities to Tweebank V2, a popular Twitter dataset within the Universal Dependencies framework, creating a new  <ref type="table">Table 9</ref>: Dependency parsing comparison on the TB2 test set. "TB2" indicates to use TB2 for training. "TB2+EWT" indicates to combine TB2 and UD English-EWT for training. Note that the first six results are rounded to one decimal place by <ref type="bibr" target="#b15">Liu et al., (2018)</ref>.</p><p>NER benchmark called Tweebank-NER. We evaluate our annotations and observe good inter-annotator agreement score in pairwise F1 for NER annotation. We train Twitter-specific NLP models (NER, tokenization, lemmatization, POS tagging, dependency parsing) on the dataset with Stanza and compare our models against existing work and NLP frameworks. Our Stanza models show SOTA performance on tokenization and lemmatization and competitive performance in NER, POS tagging, and dependency parsing on TB2. We also train BERT-based methods to establish a strong benchmark on Tweebank-NER and achieve SOTA performance in POS tagging and dependency parsing on TB2. Finally, we publish our dataset and release the Stanza pipeline Twitter-Stanza, which is easy to download and use with Stanza's Python interface. We also release the BERTweet-based NER and POS tagger on Hugging Face Hub. We hope that our research not only contributes annotations to an important dataset but also enables other researchers to use off-the-shelf NLP models for social media analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head><p>We would like to thank Alan Ritter, Yuhui Zhang, Zifan Lin, and anonymous reviewers, who gave precious advice and comments on our paper. We also want to thank John Bauer and Yijia Liu for answering questions related to Stanza and Twpipe. Finally, we would like to thank MIT Center for Constructive Communication for funding our research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Kong et al. (2014)'s graph-based parser with lexical features and word cluster and it uses dual decomposition for decoding, (2) Dozat and Manning (2017)'s neural graph parser with biaffine attention, (3) Ballesteros et al. (2015)'s neural greedy stack LSTM parser, (4) an ensemble model of 20 transition-based parsers</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Confusion matrix generated by the Stanza (TB2+W17) model to show percentages for each combination of predicted and true entity types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table><row><cell>Dataset</cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell></row><row><cell>Tweets</cell><cell>1,639</cell><cell>710</cell><cell>1,201</cell></row><row><cell>Tokens</cell><cell cols="3">24,753 11,742 19,112</cell></row><row><cell>Avg. token per tweet</cell><cell>15.1</cell><cell>16.6</cell><cell>15.9</cell></row><row><cell>Annotated spans</cell><cell>979</cell><cell>425</cell><cell>750</cell></row><row><cell>Annotated tokens</cell><cell>1,484</cell><cell>675</cell><cell>1183</cell></row><row><cell>Avg. token per span</cell><cell>1.5</cell><cell>1.6</cell><cell>1.6</cell></row><row><cell cols="3">Table 1: Annotated corpus statistics.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 ,</head><label>2</label><figDesc>we observe that PER, LOC, and ORG have higher F1 agreement than MISC, showing that MISC is more difficult to annotate than the other classes. We also provide the additional Kappa measure (? =0.347) on annotated tokens to provide some insights, although it significantly underestimates IAA for NER. Finally, we calculate the scores by comparing the crowdsourced annotators against our own internal annotations on 100 sampled examples, obtaining a similar F1 score (0.71).</figDesc><table><row><cell>Label</cell><cell>Quantity</cell><cell>F1</cell></row><row><cell>PER</cell><cell>777</cell><cell>84.6</cell></row><row><cell>LOC</cell><cell>317</cell><cell>74.4</cell></row><row><cell>ORG</cell><cell>541</cell><cell>71.9</cell></row><row><cell>MISC</cell><cell>519</cell><cell>50.9</cell></row><row><cell>Overall</cell><cell>2,154</cell><cell>70.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Number of span annotations per entity type and Inter-annotator agreement scores in pairwise F1.We analyzed the 178 annotations passed to the merge step, finding that the proportion of each label is 8.4% (LOC), 15.2% (PER), 29.2% (ORG), and 47.2% (MISC). These numbers show that MISC is the most challenging class for human annotators and ORG is also relatively difficult compared to LOC and PER. This confirms the IAA measured in pairwise F1 in Table 2 because the MISC has the lowest F1 (50.9%) and ORG has the second lowest F1 (71.9%).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 :</head><label>3</label><figDesc>NER comparison on the TB2 test set in entitylevel F1. "TB2" indicates to use the TB2 train set for training. "TB2+W17" indicates to combine TB2 and WNUT17 train sets for training.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Return Method Billionaire Investor Warren Buffet Wishes He Could Use LOC ? O Getting ready ... @ Pasco Ephesus Seventh -day Adventist Church ORG ? O #bargains #deals 10.27.10 Guess Who " American Woman " Guhhh deeeh you ! MISC ? O RT @USER1508 : Do you ever realize Sounds Live Feels Live Starts this month and just</figDesc><table><row><cell>Error type</cell><cell>weet example</cell></row><row><cell>PER ? O</cell><cell>The 50 %</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: Comparison among NER models trained on</cell></row><row><cell>TB2 vs. WNUT17 on TB2 test in entity-level F1. "Hg-</cell></row><row><cell>Face" stands for "HuggingFace".</cell></row><row><cell>4.1.4. NER Models Trained on WNUT17</cell></row><row><cell>We train spaCy, FLAIR, Stanza, HuggingFace-</cell></row><row><cell>BERTwee, and spaCy-BERTweet NER models on the</cell></row><row><cell>four-class version of WNUT17 and evaluate their per-</cell></row><row><cell>formance on the TB2 test. In</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>ble 7, the Stanza model outperforms the other two rule-based (NLTK and spaCy) and one neural (FLAIR) baseline approaches on TB2. This is not surprising because the Stanza ensemble lemmatizer makes good use of both ruled-based dictionary lookup and seq2seq learning. Similar to what we observe in the tokenization experiments, the combined data setting brings down the performance of FLAIR and Stanza models.</figDesc><table><row><cell>System</cell><cell>F1</cell></row><row><cell>NLTK</cell><cell>88.23</cell></row><row><cell>spaCy</cell><cell>85.28</cell></row><row><cell>Flair (TB2)</cell><cell>96.18</cell></row><row><cell>Flair (TB2+EWT)</cell><cell>84.54</cell></row><row><cell>Stanza (TB2)</cell><cell>98.25</cell></row><row><cell cols="2">Stanza (TB2+EWT) 85.45</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 :</head><label>8</label><figDesc>POS Tagging comparison in accuracy on the TB2 test set. "TB2" is to use TB2 for training. "TB2+EWT" is to combine TB2 and UD English-EWT for training. Please note that the first five results are rounded to one decimal place by<ref type="bibr" target="#b15">Liu et al., (2018)</ref>.</figDesc><table><row><cell>4.2.4. Dependency Parsing Performance</cell></row><row><cell>For dependency parsing experiments, spaCy-XLM-</cell></row><row><cell>RoBERTa (TB2) achieves the SOTA performance (Ta-</cell></row><row><cell>ble 9), surpassing Liu et al. (2018) (Ensemble)</cell></row><row><cell>by 0.42% in UAS 11 . Besides that, the Stanza parser</cell></row><row><cell>achieves the same UAS score and has a close LAS</cell></row><row><cell>score (?0.3%) compared to this best non-transformer</cell></row><row><cell>performance (UAS 82.1% + LAS 77.9%) reported by</cell></row><row><cell>the distilled parser. As</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.clips.uantwerpen.be/ conll2003/ner/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://stanfordnlp.github.io/stanza/ 4 https://github.com/huggingface/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ing Stanford CoreNLP, spaCy, FLAIR, and<ref type="bibr" target="#b16">Ma and Hovy (2016)</ref>. Interestingly, we observe that adding UD English-EWT for training improves the performance of non-transformer models and HuggingFace-BERTweet but slightly brings down the performance of spaCy-transformers models.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">It is difficult to compare their LAS with ours due to the difference in decimal places.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">LinES: An English-Swedish parallel treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ahrenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Nordic Conference of Computational Linguistics (NODAL-IDA 2007)</title>
		<meeting>the 16th Nordic Conference of Computational Linguistics (NODAL-IDA 2007)<address><addrLine>Tartu, Estonia, May; Estonia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="270" to="273" />
		</imprint>
		<respStmt>
			<orgName>University of Tartu</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Contextual string embeddings for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th international conference on computational linguistics</title>
		<meeting>the 27th international conference on computational linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Flair: An easy-to-use framework for state-of-the-art nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="54" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improved transition-based parsing by modeling characters instead of words with lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="349" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Creating a dataset for named entity recognition in the archaeology domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brandsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wansleeben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>B?chet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Declerck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Proceedings LREC 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4573" to="4577" />
		</imprint>
	</monogr>
	<note>The European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">From raw text to universal dependencies-look, no tags!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De Lhoneux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Basirat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kiperwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stymne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="207" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Building gold standard corpora for medical natural language processing tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deleger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lingren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA Annual Symposium Proceedings</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2012</biblScope>
			<biblScope unit="page">144</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<title level="m">Proceedings of the 3rd Workshop on Noisy User-generated Text</title>
		<meeting>the 3rd Workshop on Noisy User-generated Text<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep biaffine attention for neural dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stanford&apos;s graph-based neural dependency parser at the conll 2017 shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="20" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Cetinoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Le Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Genabith</surname></persName>
		</author>
		<title level="m">#hardtoparse: Pos tagging and parsing the twitterverse</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Partof-speech tagging for twitter: Annotation, features, and experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>Carnegie-Mellon Univ Pittsburgh Pa School of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Proposal for an extension of traditional named entitites: from guidelines to evaluation, an overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Galibert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Quintard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th Linguistics Annotation Workshop (The LAW V)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Agreement, the f-measure, and reliability in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hripcsak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Rothschild</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American medical informatics association</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="296" to="298" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A dependency parser for tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1001" to="1012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parsing tweets into universal dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="965" to="975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations</title>
		<meeting>52nd annual meeting of the association for computational linguistics: system demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Bertweet: A pre-trained language model for english tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Universal dependencies v1: A multilingual treebank collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-C</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hajic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1659" to="1666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Tweetmotif: Tweetmotif: Exploratory search and topic summarization for twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahn</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improved part-of-speech tagging for online conversational text with word clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Owoputi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference of the North American chapter of the association for computational linguistics: human language technologies</title>
		<meeting>the 2013 conference of the North American chapter of the association for computational linguistics: human language technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="380" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Universal dependency parsing from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoNLL</title>
		<imprint>
			<date type="published" when="2018" />
			<publisher>UD Shared Task</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Stanza: A python natural language processing toolkit for many human languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Named entity recognition in tweets: An experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 conference on empirical methods in natural language processing</title>
		<meeting>the 2011 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1524" to="1534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Introduction to the conll-2003 shared task: Languageindependent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De Meulder</surname></persName>
		</author>
		<idno>cs/0306050</idno>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Parttut: The turin university parallel treebank. In Harmonization and development of resources and tools for italian natural language processing within the parli project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="51" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A framework for (under) specifying dependency syntax without overloading annotators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saphra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linguistic Annotation Workshop &amp; Interoperability with Discourse</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Tokenizing, pos tagging, lemmatizing and parsing ud 2.0 with udpipe</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Strakov?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="88" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Udpipe: trainable pipeline for processing conll-u files performing tokenization, morphological analysis, pos tagging and parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hajic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Strakov?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4290" to="4297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cross-lingual domain adaptation for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stymne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Workshop on Treebanks and Linguistic Theories</title>
		<meeting>the 19th Workshop on Treebanks and Linguistic Theories</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="62" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
	</analytic>
	<monogr>
		<title level="m">Bridging the gap between human and machine translation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<title level="m">Proceedings of the Workshop on Noisy User-generated Text</title>
		<meeting>the Workshop on Noisy User-generated Text<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">The GUM corpus: Creating multilayer resources in the classroom. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zeldes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="581" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Biomedical and clinical english model packages for the stanza python nlp library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Langlotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1892" to="1899" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Language Resource References</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">English Web Treebank. Philadelphia: Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Mott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Warner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Kulick</surname></persName>
		</author>
		<idno>230-396-178-102- 3</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
