<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Conversational Analysis using Utterance-level Attention-based Bidirectional Recurrent Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandrakant</forename><surname>Bothe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Knowledge Technology</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<addrLine>Vogt-Koelln-Str. 30</addrLine>
									<postCode>22527</postCode>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Magg</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Knowledge Technology</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<addrLine>Vogt-Koelln-Str. 30</addrLine>
									<postCode>22527</postCode>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornelius</forename><surname>Weber</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Knowledge Technology</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<addrLine>Vogt-Koelln-Str. 30</addrLine>
									<postCode>22527</postCode>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Wermter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Knowledge Technology</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<addrLine>Vogt-Koelln-Str. 30</addrLine>
									<postCode>22527</postCode>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Conversational Analysis using Utterance-level Attention-based Bidirectional Recurrent Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms: spoken language understanding</term>
					<term>conversational analysis</term>
					<term>dialogue act classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent approaches for dialogue act recognition have shown that context from preceding utterances is important to classify the subsequent one. It was shown that the performance improves rapidly when the context is taken into account. We propose an utterance-level attention-based bidirectional recurrent neural network (Utt-Att-BiRNN) model to analyze the importance of preceding utterances to classify the current one. In our setup, the BiRNN is given the input set of current and preceding utterances. Our model outperforms previous models that use only preceding utterances as context on the used corpus. Another contribution of our research is a mechanism to discover the amount of information in each utterance to classify the subsequent one and to show that context-based learning not only improves the performance but also achieves higher confidence in the recognition of dialogue acts. We use character-and wordlevel features to represent the utterances. The results are presented for character and word feature representations and as an ensemble model of both representations. We found that when classifying short utterances, the closest preceding utterances contribute to a higher degree.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Conversational discourse analysis is an important task for natural language understanding and for building a spoken dialogue system. A conversation consists of several utterances in a sequence. Discourse analysis of the conversation can be conducted by using speech acts where a speech act defines the performative function of an utterance <ref type="bibr" target="#b0">[1]</ref>. However, speech acts are context-sensitive, where the context provides information for appropriate interpretation of the speech act <ref type="bibr" target="#b1">[2]</ref>. Once the context is taken into account, the question is how many utterances in the context contribute to the current utterance and how do context-utterances affect the interpretation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>?</p><p>We attempt to answer these questions in this research. We propose an utterance-level attention mechanism using a bidirectional recurrent neural network (Utt-Att-BiRNN) for contextbased learning in conversational analysis <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>. The proposed model is intended to not only model context-based learning but also to analyze the amount of contributing information in the utterances for the dialogue act (DA) recognition task. We assess the model performance on the Switchboard Dialogue Act (SwDA) corpus <ref type="bibr" target="#b8">[9]</ref>.</p><p>We previously found a significant improvement of using the context-utterances against the simple utterance-level DA classification. As a result, we now investigate the discourse analysis in a conversation with context-based learning using the Utt-Att-BiRNN model. We show that context-based learning is important for the conversational analysis improving the performance by 5% to 8% accuracy over utterance-level classification.</p><p>We also show that the proposed model not only improves the performance but also provides higher confidence in the predicted classes. We report the amount of information contributed by the context-utterances. We experiment with two models: utterance-level model and Utt-Att-BiRNN model. We discover that there are many instances that were detected wrongly with both models. These instances are also reported in the results and discussion section along with the samples where the simple utterance-level model fails to predict correctly, as opposed to the Utt-Att-BiRNN model, for the SwDA corpus test set. With this investigation, we might be able to find ambiguously or wrongly annotated utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Previous work in the field of conversational discourse analysis has been attempting to model utterance-level classification of the dialogue acts <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref>. However, classifying the DA classes at a single-utterance level might fail when it comes to DA classes where the utterances share similar lexical and syntactic cues (words and phrases) like the backchannel (b), no-answer (nn), yes-answer (ny) and accept/agree (aa) DA classes. <ref type="bibr">Stolcke et al., 2000 [10]</ref> achieve about 71% of accuracy with hidden Markov models on the SwDA test set. Many recent works show that context-based learning, which takes the preceding utterances into account, improves the performance of the proposed models to achieve state-of-the-art results <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>The context-based learning approach was first proposed to model discourse within a conversation using RNNs. The DA of the current utterance was calculated using the preceding utterances as a context, achieving state-of-the-art results of about 74% of accuracy on SwDA <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b19">20]</ref>. Kalchbrenner and Blunsom, 2013 <ref type="bibr" target="#b14">[15]</ref> represent the utterance as a compressed vector of word embeddings using convolutional neural networks (CNN) and use these utterance representations to model discourse within a conversation using RNNs. Lee and Dernoncourt, 2016 <ref type="bibr" target="#b21">[22]</ref> also use recent techniques such as RNNs and CNNs with word-level feature embeddings and achieve about 73% of accuracy. <ref type="bibr">Ortega and Vu, 2017 [20]</ref> also use CNNs and RNNs and achieve about 74% of accuracy.</p><p>In another line of research, the context-based learning approach processes the whole set of utterances in a conversation, where the model can see past and future utterances to calculate the DA of the current utterance <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. Ji et al. 2016 <ref type="bibr" target="#b15">[16]</ref> use discourse annotation for the word-level language modelling on the SwDA corpus and achieve about 77% of accuracy but also highlight a limitation that this approach is not scalable to large data. On the other hand, this work suggests that a domain-independent language model which is trained on big data might be a solution. In some approaches, a hierarchical convolutional and recurrent neural encoder model are used to learn utterance representations by processing a whole conversation <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b18">19]</ref>. The utterance representations are further used to classify DA classes using the conditional random field (CRF) as a linear classifier. However, these models might fail in a dialogue system where one can perceive the past utterances, but cannot see future ones. In a dialogue system for example in human-machine interaction, one can only perceive the preceding utterance as a context but does not know the upcoming utterances. The DA corpus is also annotated by looking at the preceding utterances. Therefore, we use a context-based learning approach where only preceding utterances are considered and regard the 73.9% accuracy <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b19">20]</ref> on the SwDA corpus as a current state-of-the-art result for this particular task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>Discourse analysis is a very important task in the field of natural language processing and hence there are many dialogue act corpora available <ref type="bibr" target="#b24">[24]</ref>. We use the Switchboard Dialogue Act (SwDA 1 ) corpus which is annotated with the Dialogue Act Markup in Several Layers (DAMSL) tag set <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">25]</ref>. SwDA is annotated with 42 DA classes. The corpus consists of 1,115 conversations (196,258 utterances) in the training and 19 conversations (4,186 utterances) in the test set <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Utterance representations</head><p>We represent each utterance with two different speech-language features: characters and words.</p><p>Character representations: The character-level utterance is encoded with a pre-trained character-level language model (LM 2 ) <ref type="bibr" target="#b26">[26]</ref>. This model consists of a single multiplicative longshort-term memory (mLSTM) network <ref type="bibr" target="#b27">[27]</ref> layer with 4,096 hidden units. The mLSTM is composed of an LSTM and a multiplicative RNN and considers each possible input in a recurrent transition function. It is trained as a character language model on ?80 million Amazon product reviews <ref type="bibr" target="#b26">[26]</ref>. We sequentially input the characters of an utterance to the mLSTM and get the hidden vector obtained after the last character and also average the states over all characters in the utterance. We use the average feature vector representations for each utterance in the experiments as it was shown that the average vector over all characters in the utterance works better for dialogue act recognition <ref type="bibr" target="#b22">[23]</ref> and for emotion detection <ref type="bibr" target="#b28">[28]</ref>.</p><p>Word representations: Word-level features are important for analyzing the short sentences in a conversation. We use the word-embeddings distributed as part of ConceptNet 5.5 3 as it is designed to represent the general knowledge involved in understanding language and allows the application to better understand the meanings behind the words people use <ref type="bibr" target="#b29">[29]</ref>. It has a knowledge graph that connects words and phrases of natural language with labelled edges. The embedding dimension is 300 and averaged over all tokens in the utterance. These embeddings provide the out-of-vocabulary instance rate close to 10 percent and mostly for infrequent words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Utterance-level attention-based BiRNN</head><p>First, we present our baseline model as shown in <ref type="figure" target="#fig_0">Figure 1(a)</ref>, it is a simple utterance-level classifier which classifies the utterances with their respective labels (dialogue acts) using a simple feed-forward neural network with backpropagation. The Utt-Att-BiRNN model is shown in <ref type="figure" target="#fig_0">Figure 1(b)</ref>, for which the main components are the bidirectional recurrent neural network (BiRNN) and Attention mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Bidirectional recurrent neural network</head><p>A BiRNN is an extended form of an unidirectional RNN <ref type="bibr" target="#b30">[30]</ref>, introducing one extra hidden layer <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. The hidden to hidden layer connections flow into the opposite temporal direction. The model provides forward and backward states with corresponding directions of the hidden layers, as shown in <ref type="figure" target="#fig_0">Figure 1(b)</ref>, and the final result is calculated as follows:</p><formula xml:id="formula_0">h f t = f W f h h f t?1 + W f u ut + b f h (1) h b t = f W b h h b t?1 + W b u ut + b b h (2) P (yt|{ut, ut?1, ...ut?n}) = g W f y h f t + W b y h b t + by (3)</formula><p>where n is the number of utterances in the context for time instance t. W and h are the corresponding weight matrices and hidden vectors, where the superscripts f and b represent forward and backward hidden layer directions respectively. In our scenario, we want the model to learn the context, thus the input consists of the current utterance and the preceding context. If we use a unidirectional RNN model, there might be a chance that the model becomes more attentive to the current utterance only, as sequential information is compressed to the final state. The bidirectional RNN model, on the other hand, exploits the information in all given input utterances by looking back and forth through them. Therefore, our goal is to treat all utterances equally and learn how much each contribute to the final result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Attention mechanism</head><p>Attention mechanism is loosely based on visual attention found in humans, and broadly used in image recognition and tracking <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b32">32]</ref>. But recently, attention mechanism with RNNs are being used for several natural language processing tasks, such as machine translation and comprehension, speech recognition <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b34">34]</ref>. We propose the attention mechanism to compute the contribution weights of the utterances for predicting the corresponding class. Given the number (n) of preceding utterances in an input sequence u = {ut, ut?1, ...ut?n}, the BiRNN provides the respective hidden vectors h = {ht, ht?1, ...ht?n}. The attention layer computes the weights a = {at, at?1, ...at?n} as the contribution for every corresponding input utterance in u using the respective hidden representations h, as depicted in <ref type="figure" target="#fig_0">Figure 1(b)</ref>. Hence, the final utterance representation u f inal of the utterance sequence in u is formed by a weighted sum of h and a: </p><formula xml:id="formula_1">m = tanh (W h h) (4) y t u t softmax (a) (b) h f t-n h f t-1 h f t u t-n u t-1 u t y t h b t-n h b t-1 h b t + softmax a t-1 a t-</formula><p>where W is a trained parameter while W T being its transpose. We use the sof tmax function to compute the weights which provides n n=0 at?n = 1. It is important for the utterancelevel attention mechanism that we normalize a to interpret the amount of contribution for each utterance in u.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">Training the model</head><p>In the baseline model and the Utt-Att-BiRNN model settings, we use a sof tmax function to predict a discrete set of classes y on top of the learned u f inal representations. We use a set of 5 utterances in u, with the current utterance and 4 utterances in the context. A similar study performed in <ref type="bibr" target="#b22">[23]</ref> shows the effect of the number of utterances in the context. It was shown that three utterances provide sufficient context, however, we use four context-utterances to provide a large enough window for bidirectional exploration by the RNN, hence n = 4.</p><p>In all learning cases, we minimize the categorical crossentropy as we have multiple classes in the DA recognition task. For the baseline model, we use 2 hidden layers with 300 and  <ref type="bibr" target="#b35">[35]</ref> in the BiRNN hidden layer. As a result, we get 128 hidden units as a concatenation of the h f t and h b t hidden units. These are the only parameters determined empirically for the classification tasks but all other parameters were learned during training.</p><p>The Adam optimizer <ref type="bibr" target="#b36">[36]</ref> was used with an initial learning rate 1e-4, which decays during training. Early stopping was used to avoid over-fitting of the network, and 15% of training samples were used for validation. We wait for at least 5 iterations over which the accuracy on the validation set does not improve. Typically, both models, baseline and Utt-Att-BiRNN, took about 20 to 30 interations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and discussion</head><p>The baseline and Utt-Att-BiRNN models are trained and tested using both the utterance representations explained in Section 3.2. We report the accuracies on a test set of the SwDA corpus in <ref type="table" target="#tab_0">Table 1</ref>. Character LM and word-embeddings mean utterance representations perform quite well for this task. Surprisingly, the word-embeddings mean representations of the utterances used from the ConceptNet seem to show good results given the fact of the low dimensionality of the embeddings (300) compared to character LM (4096) size.</p><p>We also experiment with a combined model of these representations in two ways: first by concatenating both representations and use them as an input, and second by averaging the output predictions from both models. Averaging the predictions has shown the best results, and we even found that the average of prediction of models trained with character LM, wordembeddings mean, and concatenated representations give the best of the performance. We can see that context-based learning shows a performance improvement of about 5% on this discourse analysis task.</p><p>We examined the SwDA corpus test set and found that there are many instances that were predicted wrongly with both models. The dominant DA classes in the SwDA corpus are Statement-non-opinion (sd) and Statement-opinion (sv). <ref type="table" target="#tab_1">Table  2</ref> shows the number of samples (Num) and the percentage (pct.) out of 4,186 utterances. The examples of utterances show that it might be difficult for humans to identify the correct DA class. It shows the ambiguity in the two DA classes sd and sv, which accounts about 6% of accuracy reduction for both of the models only with these two classes. We also show the effectiveness of the pragmatic model which predicts the correct class when the  context is important, see <ref type="table" target="#tab_2">Table 3</ref>. For example, if the utterances like "Yes", "Yeah" etc. are followed by Yes-No Question (qy), the probability that the second utterance belongs to Yes-Answer (ny) is higher than being in Backchannel (b) or Abandoned (%). Similar utterances to the ny class are used in the Agree/Accept (aa) class, but they are usually followed by sv, sd, b, or some other classes. In total, we found 330 samples which constitute around 7.88% of the samples that were correctly recognized by the Utt-Att-BiRNN model but not by the utterance-level model. However, we also found that the prediction confidence of the Utt-Att-BiRNN model is higher than the utterance-level classifier. <ref type="figure" target="#fig_1">Figure 2(a)</ref> shows three rows for 30 batches of utterance sets in the DA recognition task: first ground truth, second the predictions of the Utt-Att-BiRNN model, and third the predictions of the utterance-level classifier. The predictions of the Utt-Att-BiRNN model show higher confidence when compared to the predictions of the utterance-level model.</p><p>With the help of Utt-Att-BiRNN model we also computed the amount of contribution of the context utterances. As discussed in Section 3.3.2, the attention weights (at, at?1, ...at?n) can be interpreted as the contribution of the utterances, as the u f inal of the utterance sequence in u is formed by a weighted sum of h and a. <ref type="figure" target="#fig_1">Figure 2(b)</ref> shows the attention weights (a0, a1, ...a4) that represent the contribution of the correspond- . It is clear that the current utterance utt0 contributes more than others, however, the closest preceding utterances seem to contribute substantially. In <ref type="figure" target="#fig_1">Figure 2</ref>(c) and 2(d), we can see the average of the weights for the corresponding utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and future research</head><p>In this article, we have presented the Utt-Att-BiRNN model for conversational analysis. We demonstrated that our model allows not only to model context-based pragmatic learning but also to compute the amount of information used from the context. Our model achieves a state-of-the-art result on the SwDA corpus of about 77% of accuracy, using only preceding utterances in the context. We showed that our model correctly predicted a significant number of the instances on a DA recognition task. We also show that the context-based learning approach shows higher confidence on the classification task compared to simple utterance-level classification. We have investigated different aspects of the conversational analysis and tested on an important task: dialogue act recognition.</p><p>In this research, we only analyzed the utterance representations based on transcripts. However, we plan to use audio features in addition which could provide better representations. Furthermore, it would also help to analyze and mitigate the influence of transcription errors. We investigated the DA annotations by reviewing the predictions of different models, but we could extend it to find out a reliable metric to assess the model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head><p>This project has received funding from the European Union's Horizon 2020 framework programme for research and innovation under the Marie Sklodowska-Curie Grant Agreement No. 642667 (SECURE).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(a) Our baseline model, (b) Utt-Att-BiRNN model. a = sof tmax W T m m (5) u f inal = tanh ha T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Effectiveness of the context. (a) Prediction confidence for a batch of 30 sets of utterances: the first row is the ground truth (GT), the second row the predictions with context (WC), and the third row the predictions with no context (NC). We show only 8 of the 42 classes for simplicity on the y-axis and the set of utterances on the x-axis. (b) The contribution of utterances utt0, utt1, ...utt4 as the attention weights a0, a1, ...a4. (c) The average weight of utterances and (d) in addition averaged over 10 runs to show robustness.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Accuracies (in %) on the SwDA test set, baseline with no context (NC) and Utt-Att-BiRNN model with context (WC) 100 hidden units respectively. For the proposed model, we use 64 hidden units with the dropout regularizer</figDesc><table><row><cell>Models</cell><cell>NC</cell><cell>WC</cell></row><row><cell>Prior related work</cell><cell></cell><cell></cell></row><row><cell>Most common class baseline</cell><cell>31.50</cell><cell></cell></row><row><cell>Stolcke et al., 2000 [10]</cell><cell>71.00</cell><cell></cell></row><row><cell>Kalchbrenner and Blunsom, 2013 [15]</cell><cell></cell><cell>73.90</cell></row><row><cell>Lee and Dernoncourt, 2016 [22]</cell><cell></cell><cell>73.10</cell></row><row><cell>Ortega and Vu, 2017 [20]</cell><cell></cell><cell>73.80</cell></row><row><cell>Our work</cell><cell></cell><cell></cell></row><row><cell>Character LM rep.</cell><cell>71.84</cell><cell>76.47</cell></row><row><cell>Word-embeddings mean rep.</cell><cell>71.73</cell><cell>75.43</cell></row><row><cell>Concatenated rep.</cell><cell>70.83</cell><cell>76.15</cell></row><row><cell>Average char-word-level predictions</cell><cell>71.85</cell><cell>76.84</cell></row><row><cell>Average char-word-level &amp;</cell><cell></cell><cell></cell></row><row><cell>concatenated rep. predictions</cell><cell>71.97</cell><cell>77.42</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>The test samples from the SwDA corpus where both classifiers, simple utterance-level and Utt-Att-BiRNN, failed to correctly predict classes (the majority classes, Statement-nonopinion (sd) and Statement-opinion (sv), are reported here). Where Num is a number of samples, GT stands for ground truth, and pct. for percentage.</figDesc><table><row><cell cols="5">GT NC WC Num pct.</cell><cell>Example of utts</cell></row><row><cell>sv</cell><cell>sd</cell><cell>sd</cell><cell>198</cell><cell cols="2">4.73 Uh, the problem is here</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>But they don't have</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>We're hearing the same</cell></row><row><cell>sd</cell><cell>sv</cell><cell>sv</cell><cell>51</cell><cell cols="2">1.22 They're certainly legal,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Real long legs,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>And time consuming,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>The test samples from the SwDA corpus where the Utt-Att-BiRNN model correctly predict as opposed to the simple utterance-level classifier.</figDesc><table><row><cell cols="5">GT NC WC Num pct.</cell></row><row><cell>ny</cell><cell>b</cell><cell>ny</cell><cell>33</cell><cell>0.79</cell></row><row><cell>aa</cell><cell>b</cell><cell>aa</cell><cell>29</cell><cell>0.69</cell></row><row><cell>aa</cell><cell>sd</cell><cell>aa</cell><cell>12</cell><cell>0.28</cell></row><row><cell>b</cell><cell>aa</cell><cell>b</cell><cell>23</cell><cell>0.55</cell></row><row><cell>b</cell><cell>%</cell><cell>b</cell><cell>16</cell><cell>0.38</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/cgpotts/swda 2 https://github.com/openai/ generating-reviews-discovering-sentiment 3 https://github.com/commonsense/ conceptnet-numberbatch</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">How to Do Things with Words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Austin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Speech acts in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbis?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language &amp; Communication</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="421" to="436" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Expression and Meaning: Studies in the Theory of Speech Acts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Searle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning dialog act processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>L?chel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 16th Conference on Computational Linguistics</title>
		<meeting>of the 16th Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="740" to="745" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hybrid speech recognition with Deep Bidirectional LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Workshop on Automatic Speech Recognition and Understanding</title>
		<meeting>of the IEEE Workshop on Automatic Speech Recognition and Understanding</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="273" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bidirectional Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Learning Representations</title>
		<meeting>of the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Attention-based Bidirectional Long Short-term Memory Networks for Relation Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SWITCH-BOARD: Telephone speech corpus for research and development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Holliman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>of the IEEE International Conference on Acoustics, Speech and Signal essing</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="517" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dialogue Act Modeling for Automatic Tagging and Recognition of Conversational Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Coccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Ess-Dykema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meteer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="339" to="373" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dialogue act classification using a Bayesian approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanchis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vilar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 9th Conference Speech and Computer (SPECOM)</title>
		<meeting>of the 9th Conference Speech and Computer (SPECOM)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="495" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dialogue Act Recognition in Synchronous and Asynchronous Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tavafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference of the Special Interest Group on Discourse and Dialogue. ACL</title>
		<meeting>of the Conference of the Special Interest Group on Discourse and Dialogue. ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="117" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dialogue Act Classification in Domain-Independent Conversations Using a Deep Recurrent Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Khanpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Guntakandla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Computational Linguistics</title>
		<meeting>of the International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2012" to="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Modeling the Intonation of Discourse Segments for Improved Online Dialog Act Tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">K R</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bangalore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>of the IEEE International Conference on Acoustics, Speech and Signal essing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="5033" to="5036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Recurrent Convolutional Neural Networks for Discourse Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop on Continuous Vector Space Models and their Compositionality, ACL</title>
		<meeting>of the Workshop on Continuous Vector Space Models and their Compositionality, ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Latent Variable Recurrent Neural Network for Discourse Relation Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>of the Conference North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="332" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Dialogue Act Sequence Labeling using Hierarchical encoder with CRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04250v2</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Preserving Distributional Information in Dialogue Act Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Zukerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Haffari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP). ACL</title>
		<meeting>of the Conference on Empirical Methods in Natural Language essing (EMNLP). ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2141" to="2146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Using Context Information for Dialog Act Classification in DNN Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Empirical Methods in Natural Language Processing. ACL</title>
		<meeting>of the Conference on Empirical Methods in Natural Language essing. ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2160" to="2168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural-based Context Representation Learning for Dialog Act Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">T</forename><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>of the Conference of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="247" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hierarchical RNN with Static Sentence-Level Attention for Text-Based Speaker Change Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Information</title>
		<meeting>of the ACM Conference on Information</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2203" to="2206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dernoncourt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.03827</idno>
		<title level="m">Sequential Short-Text Classification with Recurrent and Convolutional Neural Networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Context-based Approach for Dialogue Act Recognition using Simple Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Magg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eleventh International Conference on Language Resources and Evaluation</title>
		<meeting>of the Eleventh International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<publisher>LREC</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">European Language Resources Association (ERLA)</title>
		<imprint>
			<biblScope unit="page" from="1952" to="1957" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.05742</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Switchboard Dialog Act Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Biasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Computer Science Inst. Berkeley CA</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
	<note>Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning to Generate Reviews and Discovering Sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01444</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multiplicative LSTM for sequence modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Renals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop track of Proc. of the International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">GradAscent at EmoInt-2017: Character and Word Level Recurrent Neural Network Models for Tweet Emotion Intensity Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lakomkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis at the Conference EMNLP. ACL</title>
		<meeting>of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis at the Conference EMNLP. ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="169" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ConceptNet 5.5: An Open Multilingual Graph of General Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the AAAI Conference on Artificial Intelligence</title>
		<meeting>of the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4444" to="4451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Finding Structure in Time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning to combine foveal glimpses with a third-order Boltzmann machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Advances in Neural Information Processing Systems</title>
		<editor>J. D. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R. S. Zemel, and A. Culotta</editor>
		<meeting>of the Conference on Advances in Neural Information essing Systems</meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1243" to="1251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning Where to Attend with Deep Architectures for Image Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bazzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2151" to="2184" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Grammar as a Foreign Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Advances in Neural Information Processing Systems</title>
		<meeting>of the Conference on Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2773" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Attention-Based Models for Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Serdyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Advances in Neural Information Processing Systems</title>
		<meeting>of the Conference on Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="577" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Improving Neural Networks by Preventing Coadaptation of Feature Detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 3rd International Conference on Learning Representations</title>
		<meeting>of the 3rd International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
