<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">THE COMBINATION OF CONVOLUTION NEURAL NETWORKS AND DEEP NEURAL NETWORKS FOR FAKE NEWS DETECTION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zainab</forename><forename type="middle">A</forename><surname>Jawad</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of computer science</orgName>
								<orgName type="department" key="dep2">College of Mathematical and Computer Science</orgName>
								<orgName type="institution">University of Kufa</orgName>
								<address>
									<postCode>54001</postCode>
									<settlement>Najaf</settlement>
									<country key="IQ">Iraq</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">J</forename><surname>Obaid</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of computer science</orgName>
								<orgName type="department" key="dep2">College of Mathematical and Computer Science</orgName>
								<orgName type="institution">University of Kufa</orgName>
								<address>
									<postCode>54001</postCode>
									<settlement>Najaf</settlement>
									<country key="IQ">Iraq</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">THE COMBINATION OF CONVOLUTION NEURAL NETWORKS AND DEEP NEURAL NETWORKS FOR FAKE NEWS DETECTION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1 2 Z. A. Jawad and A. J. Obaid</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T22:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>FNC-1 Dataset</term>
					<term>Misleading Content</term>
					<term>Natural Language Processing</term>
					<term>TF- IDF</term>
					<term>Soft Cosine Similarity</term>
					<term>Convolutional Neural Networks</term>
					<term>Deep Neural Networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Nowadays, People prefer to follow the latest news on social media, as it is cheap, easily accessible, and quickly disseminated. However, it can spread fake or unreliable, low-quality news that intentionally contains false information. The spread of fake news can have a negative effect on people and society. Given the seriousness of such a problem, researchers did their best to identify patterns and characteristics that fake news may exhibit to design a system that can detect fake news before publishing. In this paper, we have described the Fake News Challenge stage #1 (FNC-1) dataset and given an overview of the competitive attempts to build a fake news detection system using the FNC-1 dataset. The proposed model was evaluated with the FNC-1 dataset. A competitive dataset is considered an open problem and a challenge worldwide. This system's procedure implies processing the text in the headline and body text columns with different natural language processing techniques. After that, the extracted features are reduced using the elbow truncated method, finding the similarity between each pair using the soft cosine similarity method. The new feature is entered into CNN and DNN deep learning approaches. The proposed system detects all the categories with high accuracy except the disagree category. As a result, the system achieves up to 84.6 % accuracy, classifying it as the second ranking based on other competitive studies regarding this dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The detection of fake news has recently stimulated the attention of the general audience and scientists as the spread of misleading information online grows, especially on the internet, such as newsfeeds, news articles, and newspaper articles. For example, according to a recent Jump-shot Tech Blog, on Facebook, 50% of the daily traffic represents fake news sites, while the remaining 20% present normal websites. Identifying fake content in online sources is crucial since 62% of U.S. adults read news on social media <ref type="bibr" target="#b0">[1]</ref>. Until now, computational methods for detecting fake news have depended heavily on humorous news sources like "The Onion" and fact-checking websites like "Factcheck.org" and "Snopes." Moreover, using these publications presents several difficulties and possible consequences. For example, using humorous content as a source for misinformation can introduce underlying contributing effects into the analysis, such as jokes and illogicality. This is certainly relevant for humorous reports from "The Onion," which has previously been used to investigate other sentence characteristics such as jokes <ref type="bibr" target="#b1">[2]</ref> and irony <ref type="bibr" target="#b2">[3]</ref>.</p><p>However, fact-checking websites are typically limited to a single area of interest, like politics. They necessitate human experience, making it challenging to find datasets that offer some level of generalization across several disciplines <ref type="bibr" target="#b3">[4]</ref>.</p><p>Consequently, recent work has explored how machine learning algorithms can extract linguistic features from textual articles. It can determine whether a fake news detection system is effective by evaluating how accurately it detects fake news. A set of datasets has been collected for this purpose, which can use to evaluate fake news detection systems, verify that the headline and body text match, identify mismatched sentences in the body text, and measure the social media spread of fake news <ref type="bibr" target="#b4">[5]</ref>.</p><p>In this work, we explain the main reason for choosing the FNC-1 dataset for evaluating the fake news detection system. Furthermore, this paper explains the main pre-processing methods used. On the other hand, it illustrates how the Elbow Truncated method was used for selecting the most effective feature. In addition, it briefly describes the feature generation step using TF-IDF. Moreover, it presents the cosine similarity method and demonstrates how it measures the similarity between documents. Finally, we illustrate the learning algorithm using CNN and DNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Relate work</head><p>In this section includes a review of initial attempts to use the FNC-1dataset to build a misinformation news detection system. We focus on methods that combine Deep Learning (DL) techniques, Machine Learning (ML), and Natural Language Processing (NLP) techniques.</p><p>By suggesting the UCL Machine Reading (UCLMR) method, Riedel et al. 2017 <ref type="bibr" target="#b5">[6]</ref> conducted an exciting experiment. The suggested method involves combining lexical and similarity information with DL approaches. This system offers simplicity in contrast to the most advanced Neural Network algorithms. Despite the simplicity of the implementation, the authors acquired an 81.72% FNC-1 score. The researchers believed their work would serve as a foundation for competing attempts on the FNC-1 dataset, although the already attained accuracy still needed improvement.</p><p>Another team, Gaurav Bhatt and his team 2017 <ref type="bibr" target="#b6">[7]</ref>, demonstrated a model created using DL methods and statistical, neural, and feature engineering heuristics. The suggested model was straightforward. Furthermore, it fulfils 83.08% of the accuracy, with higher accuracy in all instances expected disagree instances.</p><p>Benjamin Schiller et al. 2018 used a novel method for stance identification in this research <ref type="bibr" target="#b7">[8]</ref> by applying memory networks with Convolutional Neural Networks (CNN), and Long Short-Term Memory (LSTM) approaches. A stance filtering component and the similarity-based matrix were used to enhance the model further. The suggested extension greatly enhances performance benefits and brings competitiveness. Results showed that the strategy effectively recognized prior knowledge; it scored 81.23%. The suggested model only manages one instance at a time and cannot deal with a collection of instances.</p><p>Borges et al. <ref type="bibr" target="#b8">[9]</ref> presented a novel approach that combines Deep Neural Network (DNN) approaches with string external similarity features. The suggested model significantly improves the results of earlier research, which scored 82.23%. However, the authors reported that advanced sentence modelling techniques are required. Furthermore, instead of feed-forward approaches, the Recurrent Neural Network (RNN) method must be used for text encoding.</p><p>In another attempt by Robiert and his co-workers 2021 <ref type="bibr" target="#b9">[10]</ref>, the researcher used RoBERTa as a foundation to improve the classification. In this case, two dense layers are included to reduce dimensions and, finally, the SoftMax classification layer.in addition, they were using soft cosine similarity. However, using summaries provided good results in this preliminary research, but the instances of agree and disagree still needed more improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The proposed system</head><p>The main components of our proposed system are presented in this section. <ref type="figure">Figure  1</ref> illustrates these components which described in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1: The Main Components of The Proposed System.</head><p>We used the FNC-1 dataset in this search. The FNC-1 is a collective effort that includes over 100 volunteers and 71 teams from academia and industry worldwide. This dataset was designed for stance detection with 75,385 labeled headlines and articles. There are four label categories: agree, disagree, discuss, and unrelated. In the dataset, each headline is phrased as a statement. The goal of the FNC-1 is to explore how AI technologies could be employed to tackle fake news problems. They organize an annual competition to encourage the development of new tools that could assist human fact-checkers using ML, AI, and NLP.</p><p>After that, we used data cleaning. Raw data must be transformed into a format that can be understood and used. A real-world dataset is usually incomplete and has inconsistent formatting. It is possible to resolve such issues by preprocessing data and making it more efficient and complete for analysis. A successful data mining or machine learning project depends heavily on this process. As a result, knowledge can be discovered more quickly from datasets, which eventually affects the performance of machine learning models-the main steps of preprocessing, as shown in <ref type="figure" target="#fig_0">Fig. 2</ref>. Among NLP tasks, text generation involves generating text with constraints like starting characters or starting words. In addition, generating text appears indistinguishable from human-written text. In the literature, this task is referred to as "natural language generation." Text Generation is a branch of NLP. It uses mathematical linguistics and AI knowledge to automatically generate natural language texts that can fulfil certain communicative requirements. Which include: Calculate and Encoding by the (Term Frequency-Inverse Document Frequency) TF-IDF: It is a statistical measure that determines how relevant a text is to a document in a list of documents. It is accomplished by multiplying two metrics: the number of times a term makes it appears in a document and the phrase's inverse document frequency across a list of documents. In this step, we perform the TF-IDF for the headline and the body text, which produce two encoding lists: one for the headline and the other for the body text. as shown in <ref type="figure">Fig. 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 3: TF-IDF Vectorization Process</head><p>Feature selection is crucial when building a fake news detection system for removing noisy features and keeping only those relevant to the system. After generating the TF-IDF vectors for both headlines in train stances and body text in train bodies, we use the Elbow truncated method to find the optimal number of features. Furthermore, we have 17000 concepts, while the optimal number of features after using this method is 5000. This step illustrates in <ref type="figure" target="#fig_1">Fig. 4</ref>. After selecting the important feature, we contacted the headline in train stances and text bodies in train bodies in one CSV. This step is shown in <ref type="figure" target="#fig_2">Fig. 5</ref>. Furthermore, it seeks to extract similar patterns from temporal data, such as periodic patterns. Discovering similar patterns is considered among the most crucial data-mining processes and may be used in various fields. Soft Cosine Similarity (SCM) allows us to assess the similarity between two documents in a meaningful way. The sentences have no words in common, but SCM can measure their similarity accurately by modelling synonymy. As part of the method, the documents are also represented as TF-IDF vectors (in other words, their frequency in the documents). It outperforms many state-of-the-art methods when applied to a semantic text similarity task within a community question-answering context. Thus, we use SCM in this study. Finally, learning algorithms define the last level in building a fake news system. This procedure is essential for building a fake news system that can identify misleading news in real time. Different strategies, including ML classification, and DL approaches, are available for this purpose. As our main technique in this study, we used multiple deep learning classification algorithms, which include:</p><p>? Convolutional Neural Networks: This is a part of artificial neural networks commonly used in text mining. Compared to other text classification algorithms, CNNs require relatively little pre-processing. Unlike traditional algorithms, the network learns to optimize the filters (or kernels) through automated learning, whereas in traditional algorithms, these filters are designed by hand. This approach is advantageous because it is independent of prior knowledge and human intervention when obtaining features. ? Deep Neural Networks: In DNNs, data flows from the input layer to the output layer without looping back. A DNN begins by creating a map of virtual neurons and assigning random numerical values to connections between them. A combination of weights and inputs results in output between 0 and 1. An algorithm would adjust the weights if the network failed to recognize a particular pattern accurately. As a result, the algorithm can gradually increase the importance of certain parameters until it finds the correct mathematical manipulation to process the data fully. After finding the SCM between headlines and body text, we add the stance column with four labels (agree, disagree, discuss, and unrelated), which will represent our dependent variable. In addition, we enter these columns into CNN learning models with some properties, as shown in <ref type="table" target="#tab_0">Table 1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN layer Dense Activation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input layer 1024 relu</head><p>Hidden layer 128 relu</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output layer 4 SoftMax</head><p>On the training CSV, with the batch size being 512 and the number of epochs being 80, the best result with a categorial accuracy (average accuracy of stances) of 0.997 and loss function of 0.659 because the first ten epochs were over-fitting. We compute the confusion matrix as shown in <ref type="figure">Fig. 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 6: The Confusion Matrix of CNN Algorithm.</head><p>That is challenging on the competition's CSV, which has real-time news and does not exist in training or testing CSV. After we learn the training CSV, we do the same Learning on the competition CSV. The best result was validation-categorial accuracy (average accuracy of stances) of 0.805 and validation-loss function of 0.938 because the first ten epochs were overfitting. Furthermore, we compute the confusion matrix as shown in <ref type="figure">Fig.7</ref>. Finally, we loaded the weighted CNN to the DNN model to enhance our results, which increased the accuracy to 84.6%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 7: The Confusion Matrix of DNN Algorithm.</head><p>We used this metric for evaluating classification models that specifically measures the similarity between predicted and actual fake news. Furthermore, it is possible to calculate using an equation. The number of documents detected by the system is denoted by True Positive (TP), while the number of correctly predicted fake documents is represented by True Negative <ref type="figure">(TN)</ref>. Furthermore, False Positive (FP) represents the number of real documents classified as fake by the system. Finally, False Negative (FN) refers to the number of fake documents classified as real by the system.</p><p>The F-score is an important metric that reflects the success of detecting fake news rather than real news. Precision represents the percentage of correctly classified observations as a fake document. Sensitivity, in contrast, is defined as the ratio of real news classified to actual real news <ref type="bibr" target="#b10">[11]</ref>:</p><formula xml:id="formula_0">? Precision = | | | |+ | | (1) ? Recall = | | | |+ | |<label>(2)</label></formula><p>? F1-Score = * * + (3)</p><p>? Accuracy = | |+| | | |+ | |+| |+| |</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(4)</head><p>These metrics are widely used in the ML and DL community and allow to evaluate a classifier's performance from various angles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Discussion</head><p>System implementation was performed on a Macintosh platform with a dualcore Intel Core i5 processor and 16 GB of memory, illustrated in <ref type="table" target="#tab_1">Table 2</ref>.</p><p>Both Microsoft Visual Studio 2019 and MATLAB R2020b were used. As shown in <ref type="table" target="#tab_2">Table 3</ref>, pre-processing takes 12 seconds on average, converting the data into a TF-IDF vectorizer takes 16 minutes, and calculating SCM between headlines and body text takes 24 minutes. The test and the training of CNN take 5.55 minutes, respectively. On DNN, the system can be applied in real-time in 2.034 seconds, demonstrating its ability to be applied in real-time.</p><p>The proposed system is evaluated via two classifiers based on the features obtained using Elbow truncated algorithms. CNN and DNN are these classifiers. Based on the CNN classifier, which is most commonly used to analyse or understand natural language processing, the two classifiers perform well in detecting fake news.   <ref type="table" target="#tab_3">Table 4</ref>. Across all stances except disagree, we achieved higher scores and class-wise accuracy, as shown in <ref type="figure">Fig. 8</ref>. It is a problem since the importance of disagree is similar to the importance of agree and discuss. Not only are there a relatively small number of news pairs in the disagree category, but they also contain divergent news articles. Deep models, including top teams, do not perform well when classifying disagree labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 8: The Results of Propose System Based on Evaluation Metrics</head><p>Moreover, we compared the proposed system's performance to previous works based on metrics of accuracy and methods used. Table <ref type="bibr" target="#b4">(5)</ref> shows that our proposed approach outperforms most previous approaches. For example, <ref type="bibr" target="#b5">[6]</ref> used the ULCMR method to achieve 81.72% accuracy, while <ref type="bibr" target="#b6">[7]</ref> used statistical, neural, and feature engineering heuristics to achieve 83.08% accuracy. In another example, the authors in <ref type="bibr" target="#b7">[8]</ref> used Novel memory network enhancements with CNN and LSTM to achieve 81.23% accuracy. Although in <ref type="bibr" target="#b9">[10]</ref>, the researcher achieved 90% accuracy. On the other hand, the proposed system achieved 84.6% accuracy and needs to combine CNN and DNN with SCM.CNN and DNN are used to demonstrate the ability of the system to detect fake news, as shown in <ref type="figure">Fig. 9</ref>.  <ref type="figure">. 9</ref>: Comparison between the proposed approach with previous works Based on State of the Art <ref type="figure" target="#fig_3">Figure 10</ref> illustrates the purpose system with the other previous works in state of the art, which is higher than other proposed models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>Due to social media's increasing popularity, more and more people are consuming news via social media instead of traditional media. In addition, social media has been used to spread fake news, which can negatively impact individual users and society. As part of this research, we reviewed existing literature on the characterization and detection of fake news. Researchers attempted different approaches to build fake news detection systems using machine learning and deep learning approaches using natural language processing. This work focused on the competitive studies that used the FNC-1 dataset. From studying the existing works, it is concluded that the proposed approaches fail to build a system that can detect fake news efficiently. The current work proposed a detection system to detect fake news in the FNC-1 competitive dataset. The proposed system implies cleaning the data, extracting new features using different natural language processing techniques, and reducing the number of features using the elbow truncated method. Furthermore, we found the similarity between each pair of headline and body text, and the resulting feature is entered into CNN and DNN learning approaches. As a result, the system can recognize if the headline agrees with the body text, discuss it, disagree with it, or they are unrelated. The systems give up to 84.6% accuracy, where it detects all these cases with high accuracy except the disagree case, and the main reason for that is that the training pairs of this category are not frequent. As a result, the proposed system can be considered the second-ranking among the competitive studies with the FNC-1 dataset, where it outperforms most of the previous works in terms of accuracy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>The Main Components of The Preprocessing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 :</head><label>4</label><figDesc>Feature Selection Process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 :</head><label>5</label><figDesc>An example of merge process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 10 :</head><label>10</label><figDesc>Comparison between the proposed approach with state the art.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Properties of CNN learning model.</head><label>1</label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 : Summary of the Experiment Results.</head><label>2</label><figDesc></figDesc><table><row><cell>Classifier</cell><cell>Accuracy</cell><cell>Precision</cell><cell>Recall</cell></row><row><cell>Proposed Model</cell><cell>84.6%</cell><cell>84.6%</cell><cell>84.6%</cell></row><row><cell>(CNN, DNN)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 : Summary of the execution time.</head><label>3</label><figDesc>Furthermore, we calculate the results of each stance in the dataset, as shown in</figDesc><table><row><cell>Model</cell><cell>Execution time</cell></row><row><cell>Pre-processing</cell><cell>12 sec</cell></row><row><cell>TF-IDF</cell><cell>16 min</cell></row><row><cell>SCM</cell><cell>24 min</cell></row><row><cell>CNN</cell><cell>5.55 min</cell></row><row><cell>DNN</cell><cell>2 sec</cell></row><row><cell>Totally</cell><cell>45.69 min</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 : Classification Result of Proposed System based on FNC-1 Stances</head><label>4</label><figDesc></figDesc><table><row><cell>Stance</cell><cell>Accuracy</cell><cell>Precision</cell><cell>Recall</cell><cell>F-score</cell></row><row><cell>Unrelated</cell><cell>95.04</cell><cell>98.03</cell><cell>95.81</cell><cell>96.91</cell></row><row><cell>Discuss</cell><cell>87.70</cell><cell>69.25</cell><cell>58.31</cell><cell>63.31</cell></row><row><cell>Agree</cell><cell>88.47</cell><cell>37.02</cell><cell>67.26</cell><cell>47.75</cell></row><row><cell>Disagree</cell><cell>96.00</cell><cell>05.45</cell><cell>14.56</cell><cell>07.93</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 : Comparison Between the Proposed Approach with Previous Works Based on State of the Art</head><label>5</label><figDesc></figDesc><table><row><cell>Reference Number</cell><cell>Year of Study</cell><cell>Technique</cell><cell>Accuracy</cell></row><row><cell>[6]</cell><cell>2017</cell><cell>UCL Machine Reading's (UCLMR) system.</cell><cell>0.8172</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">News use across social media platforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gottfried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shearer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Making computers laugh: Investigations in automatic humor recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Computational irony: A survey and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="467" to="483" />
		</imprint>
	</monogr>
	<note>Artificial intelligence review</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Automatic detection of fake news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>P?rez-Rosas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07104</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A survey of fake news: Fundamental theories, detection methods, and opportunities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zafarani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A simple but tough-to-beat baseline for the Fake News Challenge stance detection task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03264</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On the benefit of combining neural, statistical and external features for fake news identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bhatt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.03935</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Automatic stance detection using end-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohtarami</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07581</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Combining similarity features and deep representation learning for stance detection in the context of checking fake news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Borges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Calado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Data and Information Quality (JDIQ)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploring summarization to enhance headline stance detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sep?lveda-Torres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Applications of Natural Language to Information Systems. 2021</title>
		<imprint>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fake news detection on social media: A data mining perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD explorations newsletter</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="36" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A retrospective analysis of the fake news challenge stance detection task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hanselowski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.05180</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Linked credibility reviews for explainable misinformation detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Denaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Gomez-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Semantic Web Conference. 2020</title>
		<imprint>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
