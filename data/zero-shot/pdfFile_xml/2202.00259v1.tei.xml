<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Detecting Human-Object Interactions with Object-Guided Cross-Modal Calibrated Semantics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangjie</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Control Science and Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mang</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">DAMO Academy</orgName>
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Ni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Control Science and Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Laboratory of Industrial Control Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangpeng</forename><surname>Xu</surname></persName>
							<email>liangpeng.xlp@alibaba-inc.com</email>
							<affiliation key="aff2">
								<orgName type="department">DAMO Academy</orgName>
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Detecting Human-Object Interactions with Object-Guided Cross-Modal Calibrated Semantics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Human-Object Interaction (HOI) detection is an essential task to understand human-centric images from a fine-grained perspective. Although end-to-end HOI detection models thrive, their paradigm of parallel human/object detection and verb class prediction loses two-stage methods' merit: objectguided hierarchy. The object in one HOI triplet gives direct clues to the verb to be predicted. In this paper, we aim to boost end-to-end models with object-guided statistical priors. Specifically, We propose to utilize a Verb Semantic Model (VSM) and use semantic aggregation to profit from this object-guided hierarchy. Similarity KL (SKL) loss is proposed to optimize VSM to align with the HOI dataset's priors. To overcome the static semantic embedding problem, we propose to generate cross-modality-aware visual and semantic features by Cross-Modal Calibration (CMC). The above modules combined composes Object-guided Cross-modal Calibration Network (OCN). Experiments conducted on two popular HOI detection benchmarks demonstrate the significance of incorporating the statistical prior knowledge and produce state-of-the-art performances. More detailed analysis indicates proposed modules serve as a stronger verb predictor and a more superior method of utilizing prior knowledge. The codes are available at https://github.com</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Human Object Interaction (HOI) detection has recently become a thriving research topic as it provides a fine-grained understanding to human-centric images. HOI detection aims to detect triplets formulated as human, verbs, object . Elaborate HOI detection can boost the results of image captioning <ref type="bibr" target="#b54">(Yao et al. 2018)</ref>, image retrieval <ref type="bibr" target="#b20">(Johnson et al. 2015)</ref>, activity recognition <ref type="bibr" target="#b57">(Yuan, Ni, and Wang 2021)</ref>, etc..</p><p>Recently proposed end-to-end methods <ref type="bibr" target="#b28">(Liao et al. 2020;</ref><ref type="bibr" target="#b22">Kim et al. 2021;</ref><ref type="bibr" target="#b42">Tamura, Ohashi, and Yoshinaga 2021)</ref> for HOI detection have achieved notable results without two-stage processing. Unlike two-stage methods that deal with human/object detection and verb prediction sequentially, end-to-end methods run these two processes in parallel. Since two-stage methods identify object class first, it is more effective than end-to-end methods in leveraging the object class information for verb prediction. Objects can reveal direct clues to the interactiveness of HOI triplets ) and furthermore the specific interactions of HOI triplets. Although those unlikely object-verb pairs can be rejected by introducing a post-processing (e.g. applying a binary mask <ref type="bibr" target="#b42">(Tamura, Ohashi, and Yoshinaga 2021)</ref>), a better choice is to inject statistical prior information during training, thus producing better ranking results <ref type="bibr" target="#b8">(Chen et al. 2019)</ref>. In this paper, we take a step further to implant the prior knowledge into an end-to-end model.</p><p>To profit from the object-guided hierarchy, we propose to utilize the semantic space <ref type="bibr" target="#b40">(Rahman et al. 2020;</ref><ref type="bibr" target="#b53">Xu et al. 2019)</ref>. Semantic embeddings are intialized from word embeddings <ref type="bibr" target="#b37">(Pennington, Socher, and Manning 2014;</ref><ref type="bibr" target="#b36">Mikolov et al. 2013)</ref>. Several attempts on utilizing semantic space in HOI constrained in vanilla pretrained embeddings or their independent projections (i.e. MLPs) <ref type="bibr" target="#b60">(Zhong et al. 2020;</ref><ref type="bibr" target="#b10">Gao et al. 2020;</ref><ref type="bibr" target="#b1">Bansal et al. 2020;</ref><ref type="bibr" target="#b38">Peyre et al. 2019</ref>). However, semantic space tends to have a domain discrepancy towards visual space <ref type="bibr" target="#b63">(Zhu et al. 2021</ref>), which can not be overcome by such transformations. Some works <ref type="bibr" target="#b38">Peyre et al. 2019)</ref> incorporate semantic space to push visual space closer to it, which will cause negative effects when visual features are strong and robust. Inspired by <ref type="bibr" target="#b52">(Wu et al. 2018;</ref><ref type="bibr" target="#b55">You et al. 2020)</ref>, we propose a Verb Semantic Model (VSM) that outputs a set of semantic features that fit in with the HOI dataset's verb co-occurrence priors. This procedure is optimized by the proposed Similarity KL (SKL) loss without entry relaxation. Then, we inject object-verb hierarchical priors via semantic aggregation, which generates a set of semantic features corresponding to a set of visual features. By proper utilization of two-modal features, performance can still be boosted under strong vision models.</p><p>As VSM is shared across all images for a given dataset, semantic aggregation gathers static verb semantic embeddings given an object class. This static property is identical to previous methods <ref type="bibr" target="#b33">(Liu, Chen, and Zisserman 2020)</ref> and lacks cross-modality-aware representation. As two modalities provide complementarity, we manage to solve the problem by cross-modal one-to-one calibration: mutually calibrating features from one modality via excitation from the other modality. By this mutual calibration, our model can generate a vision-aware semantic feature set and a semanticaware visual feature set. Specifically, we propose to do Cross-Modal Calibration (CMC), which includes i) calibrating each modality's features by the other modality via Intermodal Calibration (InterC), ii) furthermore utilizing Intramodal Enhanced Calibration (IntraEC) <ref type="bibr" target="#b45">(Vaswani et al. 2017;</ref><ref type="bibr" target="#b31">Lin et al. 2020</ref>) to achieve intra-modal global reasoning.</p><p>In order to apply the proposed VSM and CMC into practice, we select an end-to-end vision model (VM) <ref type="bibr" target="#b64">(Zou et al. 2021;</ref><ref type="bibr" target="#b42">Tamura, Ohashi, and Yoshinaga 2021)</ref> as our VM and compose Object-guided Cross-modal Calibration Network (OCN). To conclude, our contributions are three-fold:</p><p>? We introduce the object-guided statistical priors to facilitate end-to-end HOI detection. We introduce a Verb Semantic Model and use semantic aggregation to profit from this object-guided hierarchy. SKL loss is proposed to optimize VSM to align with the HOI dataset's priors. ? To overcome the problem of static semantic embeddings, we propose to generate cross-modality-aware visual and semantic features by Cross-Modal Calibration, which consists of Inter-modal Calibration and Intra-modal Enhanced Calibration. ? Equipped with proposed modules, our end-to-end HOI detection model OCN achieves state-of-the-art results on two popular benchmarks. More detailed analysis indicates proposed modules serve as a stronger verb predictor and a more superior method of utilizing prior knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Human-Object Interaction Detection Since the proposition of visual semantic role labeling and V-COCO dataset <ref type="bibr" target="#b15">(Gupta and Malik 2015)</ref>, HOI detection has been a research hotspot. The methods to tackle with this problem can be categorized into two-stage methods and one-stage methods. Two-stage methods follow a pipeline of detecting objects first and then use cropped features to infer one HOI triplet's multi-label verb interactions. The inference usually contain multiple streams <ref type="bibr" target="#b5">(Chao et al. 2018)</ref>: an object stream, a human stream and an interaction stream, which is the key stream. InteractNet <ref type="bibr" target="#b14">(Gkioxari et al. 2018</ref>) is propose to predict action-specific density maps. Contextual attention <ref type="bibr" target="#b48">(Wang et al. 2019a</ref>) is proposed to select contextual interaction information. IDN <ref type="bibr" target="#b26">(Li et al. 2020</ref>) is proposed to learn interactions by pair integration and decomposition. Various graph-based models like GPNN <ref type="bibr" target="#b39">(Qi et al. 2018)</ref>, RPNN <ref type="bibr" target="#b62">(Zhou and Chi 2019)</ref>, VSGNet (Ulutan, Iftekhar, and Manjunath 2020), DRG , CHG <ref type="bibr" target="#b47">(Wang, Zheng, and Yingbiao 2020)</ref> are proposed to capture the interaction pattern from different aspects. Other cues like poses <ref type="bibr" target="#b16">(Gupta, Schwing, and Hoiem 2019;</ref>, spatial layouts <ref type="bibr" target="#b11">(Gao, Zou, and Huang 2018)</ref>, action co-occurrence <ref type="bibr" target="#b23">(Kim et al. 2020b</ref>) and language features <ref type="bibr" target="#b33">(Liu, Chen, and Zisserman 2020;</ref><ref type="bibr" target="#b53">Xu et al. 2019;</ref><ref type="bibr" target="#b38">Peyre et al. 2019;</ref><ref type="bibr" target="#b60">Zhong et al. 2020</ref>) are utilized to augment HOI detection.</p><p>One-stage methods can be categorized into three types: i) point-based methods <ref type="bibr" target="#b28">(Liao et al. 2020;</ref><ref type="bibr" target="#b61">Zhong et al. 2021</ref>) which infers heuristically-defined interaction points, ii) anchor-based methods <ref type="bibr" target="#b21">(Kim et al. 2020a</ref>) which detects union boxes, iii) DETR-based <ref type="bibr" target="#b4">(Carion et al. 2020)</ref> methods. Thanks to DETR and its ability to extract contextual cues <ref type="bibr" target="#b45">(Vaswani et al. 2017)</ref>, several customized end-to-end models <ref type="bibr" target="#b22">(Kim et al. 2021;</ref><ref type="bibr" target="#b64">Zou et al. 2021;</ref><ref type="bibr" target="#b7">Chen et al. 2021;</ref><ref type="bibr" target="#b42">Tamura, Ohashi, and Yoshinaga 2021)</ref> originated from DETR have achieved promising results. However, there has not been an end-to-end method to incorporate semantics or explicitly utilize object-guided hierarchical relation priors. Language Semantics for Vision The language semantics has been widely exploited in many vision subareas including zero-shot object detection <ref type="bibr" target="#b2">(Bansal et al. 2018)</ref>, zeroshot recognition <ref type="bibr" target="#b50">(Wang, Ye, and Gupta 2018)</ref>, few-shot object detection <ref type="bibr" target="#b63">(Zhu et al. 2021</ref>) and HOI detection <ref type="bibr" target="#b38">(Peyre et al. 2019;</ref><ref type="bibr" target="#b53">Xu et al. 2019)</ref>. A typical method that the above works adopt is to push vision space closer to semantic space, which fails to provide positive results when the vision model is strong. In this paper, we present a method that utilizes language semantics with dataset-specific prior knowledge, which is better than the supervision from vanilla multi-modal joint embeddings . Cross-Modal Interaction Cross-modal interaction is widely studied in cross-modal retrieval <ref type="bibr" target="#b51">(Wang et al. 2019b;</ref><ref type="bibr" target="#b32">Liu et al. 2019</ref>) and VQA <ref type="bibr" target="#b12">(Gao et al. 2019;</ref><ref type="bibr" target="#b19">Jiang et al. 2020)</ref>. A typical practice of cross-modal interaction is to use the attention mechanism <ref type="bibr" target="#b45">(Vaswani et al. 2017)</ref> to achieve crossmodal global context aggregation. While in our framework, the features in one modality will be dominated by background class <ref type="bibr" target="#b4">(Carion et al. 2020)</ref>, which may degrade the quality of cross-modal context aggregation. Hence, we drop this paradigm. Instead, we introduce Cross-Modal Calibration to better incorporate cross-modal supervision for HOI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head><p>In this section, we detail Object-guided Cross-modal Calibration Network (OCN) by introducing its overall pipeline, details of Verb Semantic Model (VSM) and Cross-Modal Calibration (CMC), and the training and inference strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overall Pipeline</head><p>The overall pipeline of OCN is shown in <ref type="figure" target="#fig_0">Figure 1</ref>, which is mainly composed of three parts: a Vision Model (VM), a Verb Semantic Model (VSM) and CMC that benefits from two-modal features. For VM, we refer to the DETR-based HOI models <ref type="bibr" target="#b64">(Zou et al. 2021;</ref><ref type="bibr" target="#b42">Tamura, Ohashi, and Yoshinaga 2021)</ref> due to their compact structure. Given an input image, VM adopts a backbone (e.g. ResNet-50 <ref type="bibr" target="#b17">(He et al. 2016</ref>)) to extract image features. We add fixed positional encoding <ref type="bibr" target="#b13">(Gehring et al. 2017)</ref> to the reduced features. Then the features are flattened and fed to a Transformer encoder <ref type="bibr" target="#b45">(Vaswani et al. 2017)</ref>. We define a set of learned HOI queries</p><formula xml:id="formula_0">Q = {q i ? R D } Nq i=1 to perform decoding, producing de- coded query featuresQ = {q i ? R D } Nq i=1</formula><p>, where N q , D denote the number of queries and the dimension of queries respectively. Note that one HOI query is responsible for the detection of one HOI triplet human, verbs, object . Thus, the decoded featureq i is then fed to independent Feed-Forward Networks (FFN) to predict a human box, an object box and an object class.</p><p>VSM mainly consists of a verb semantic reasoning module. The inputs of VSM are word embeddings. To partly close the gap between initial word embeddings and the HOI dataset, a newly-proposed SKL loss is used to optimize the embeddings with verb co-occurrence priors. To benefit the verb prediction, we use object-guided verb semantic aggregation to generate a set of semantic embeddingsP . Combined withQ andP , we can perform CMC. After fusing features from two modalities, another FNN is applied to predict verb classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Verb Semantic Model</head><p>VSM aims to create a semantic space that is aligned with the training set. Word embeddings from pretrained models e.g. GloVe <ref type="bibr" target="#b37">(Pennington, Socher, and Manning 2014)</ref> inherently contain co-occurrence priors aligned with certain data e.g. Google News, which may not fit in with our dataset. In VSM, we explicitly inject dataset-specific co-occurrence priors via verb semantic reasoning and SKL Loss.</p><p>To facilitate the semantic space to better close the discrepancy, we adopt a graph formulation for projection. Suppose the initialized word embeddings are P = {p i ? R Dp } Np i=1 , where N p , D p denote the number of verbs in the HOI dataset and the dimension of word embeddings. Note that word embeddings are 2 -normed. We obtainP</p><formula xml:id="formula_1">= {p i ? R D } Np i=1</formula><p>after verb semantic reasoning by</p><formula xml:id="formula_2">r ij = ?(p i ) T ?(p j ) ? D ; r ij = softmax j (r ij )<label>(1)</label></formula><formula xml:id="formula_3">p i = ? Np j=1 r ij W p1 p j + W p2 p i (2)</formula><p>where ? is the non-linear activation function ReLU; ?, ? are both linear projections that embed p i into D-dimension space; r ij denotes pairwise relation; softmax j denotes softmax function conducted along index j; W p1 , W p2 ? R D?Dp are linear projections for value embedding and residual connection.</p><p>Similarity KL To inject priors into the semanticsP , SKL is designed to optimize the adjacency matrix ofP to obey the co-occurrence distribution for a given HOI dataset. Due to the verb imbalanced problem, the naive joint distribution of verb pairs will be dominated by head classes. Inspired by <ref type="bibr" target="#b55">(You et al. 2020)</ref>, we generate a symmetrized conditional distribution. We define the verb from the training set as a</p><formula xml:id="formula_4">set V = {v i } Np i=1 and its conditional probability as C = {c ij = P(v j |v i )|i, j = 1, 2, ...N p ; i = j}. The symmetrized conditional distribution? can be obtained b? c ij = c ij + c ji 2N p<label>(3)</label></formula><p>where? ij denotes the symmetrized probability for c ij . Note that the denominator 2N p is a normalizing factor to make? sum to one. We use 2 -norm to normalizep i . The adjacency matrix A = {a ij |i, j = 1, 2, ...N p ; i = j} of the semantics P can be obtained by</p><formula xml:id="formula_5">a ij = exp(p T ip j /? ) Np k=1 Np l=1,l =k exp(p T kp l /? )<label>(4)</label></formula><p>where ? is a temperature parameter that scales the softmax distribution of inner products of the normalized semantics <ref type="bibr" target="#b52">(Wu et al. 2018</ref>). Our aim is to push close distribution A to distribution?. We utilize the KL-divergence to achieve this purpose, which is formulated as</p><formula xml:id="formula_6">L SKL = E?[log(?) ? log(A)]<label>(5)</label></formula><p>By the utilization of L SKL , the semantics are forced to obey the co-occurrence priors.</p><p>Semantic Aggregation To facilitate the verb prediction, we propose object-guided verb semantic aggregation. The basic intuition is that given an object class for one specific HOI triplet, it indicates what the verb might be or might not be based on the object-verb co-occurrence priors. To realize this, we first collect the conditional priors</p><formula xml:id="formula_7">S = {s ij = P(v j |o i )|i = 1, 2, ..., N o + 1; j = 1, 2, ..., N p } from the training set, where o i ? O = {o i } No+1 i=1</formula><p>, N o denotes the number of object classes and the additional 1 denotes the background class. Note that s ij | i=No+1 is manually set to be a uniform distribution, as the background class </p><formula xml:id="formula_8">i = InterC(p i ,q i ) and? i = IntraEC(y). softmax is used along index j.</formula><p>gives no clue about the verb classes. To overcome the effect caused by false prediction of object classes and to alleviate the long-tailed distribution of verbs, we use Laplacian Smoothing <ref type="bibr" target="#b58">(Zhai and Lafferty 2004)</ref> to smooth the conditional distribution s ij a?</p><formula xml:id="formula_9">s ij = s ij + ?/N p Np k=1 (s ik + ?/N p ) = s ij + ?/N p 1 + ?<label>(6)</label></formula><p>where? ij denotes the smoothed object-verb priors for s ij ; ? is a hyper-parameter for smoothing. Given a decoded HOI query setQ, we predict their object classes by FFN. Combined with object-verb priors, we manage to aggregate a set ofP = {p i ? R D } Nq i=1 , which indicates a verb guess based on the smoothed priors. Note that Q andP are one-to-one match, and the cardinalities ofP andP are different. The verb semantic aggregation process can be formulated as </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-Modal Calibration</head><p>The obtained setQ andP contain visual cues and semantic cues for HOI verbs respectively. To overcome the static semantic embedding problem, we propose to calibrate one modality guided by the other modality. Previous work globally aggregate features from the other modality <ref type="bibr" target="#b12">(Gao et al. 2019</ref>) but both modality in our framework is dominated by background class, which will not result in a fine cross-modal aggregation. Inspired by <ref type="bibr" target="#b18">(Hu, Shen, and Sun 2018;</ref><ref type="bibr" target="#b45">Vaswani et al. 2017)</ref>, we propose to perform cross-modal feature calibration in multiple subspaces, which includes InterC and IntraEC illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>. Below we will exemplify usingp i to calibrateq i , denoted as y i = InterC(p i ,q i ) and performing intra-modal reasoning, denoted as? i = IntraEC(y). The generation of x i = InterC(q i ,p i ) and</p><p>x i = IntraEC(x) is similarly conducted.</p><p>Inter-Modal Calibration To perform InterC, we project p i into a subspace and then excite other modality's featur? q i in the subspace. We formulate it as</p><formula xml:id="formula_10">e i = ?(W t1 ?(W t2pi )) ? W t3qi (8) where W t2 , W t3 ? R D H ?D projectp i andq i into D H - dimension subspaces; W t1 ? R D H ? D H</formula><p>projects the ?activated feature into D H -dimension subspaces; ? is the sigmoid function; ? denotes Hadamard product. We project th? q i in rather low dimension in order to perform multi-head calibration with acceptable computational cost. We can perform the calibration as</p><formula xml:id="formula_11">y i =q i + W t4 ?(LN(W t5 Cat(e (1) i , ..., e (H) i ))) (9)</formula><p>where H denotes the number of independent InterC heads; superscript is added to e i , denoted as different heads; LN denotes LayerNorm <ref type="bibr" target="#b0">(Ba, Kiros, and Hinton 2016)</ref>; Cat denotes concatenation; W t4 , W t5 ? R D?D .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intra-Modal Enhanced Calibration</head><p>Since InterC calibrates the features, it is intuitive to incorporate a global reasoning module IntraEC to restore the global context. In practice, we adopt bilinear pooling <ref type="bibr" target="#b24">(Kim et al. 2016;</ref> to infer intra-modal relation as</p><formula xml:id="formula_12">f ij = w T (W b1 y i ) ? (W b2 y j ) (10) f ij = softmax j (f ij ); g ij = f ij W b3 y j (11) where w ? R D , W b1 , W b2 ? R D?D and W b3 ? R D<label>H</label></formula><p>?D . Also, we extend IntraEC into a multi-head manner for better representation ability:</p><formula xml:id="formula_13">y i = y i + W b4 ?(LN(W b5 Nq j=1 Cat(g (1) ij , ..., g (H) ij ))) (12) where W b4 , W b5 ? R D?D ;</formula><p>H denotes the number of independent IntraEC heads, which is identical to InterC.</p><p>Modality Fusion After CMC is conducted, we obtain two sets of verified features from two modalities. We adopt the fusion strategy <ref type="bibr" target="#b59">(Zhang, Hare, and Pr?gel-Bennett 2018)</ref> to fusex i and? i as</p><formula xml:id="formula_14">z i = ?(W xxi + W y?i ) ? (W xxi ? W y?i ) 2 (13) where W x , W y ? R D?D . The obtained feature set Z = {z i } Nq i=1</formula><p>serves as the feature for predicting verbs by FFN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and Inference Strategy</head><p>Similar to all DETR-based methods, we formulate HOI detection as a set prediction problem <ref type="bibr" target="#b4">(Carion et al. 2020)</ref>. To train the end-to-end model, we need to i) match ground truth (GT) HOI triplets with the predicted HOI triplets, ii) calculate losses for VM and VSM. The matching process is conducted with Hungarian algorithm <ref type="bibr" target="#b25">(Kuhn 1955</ref>). If we denote GT HOI triplet set as G = {g i } Nq i=1 (padded with no HOI triplets in order to match) and the predicted HOI set as  </p><formula xml:id="formula_15">M = {m i } Nq i=1</formula><p>, the bipartite matching can be formulated a?</p><formula xml:id="formula_16">? = arg min ??? Nq Nq i=1 H cost (g i , m ?(i) )<label>(14)</label></formula><p>where ? Nq is the solution space for bipartite matching. The matching cost H cost follows <ref type="bibr" target="#b42">(Tamura, Ohashi, and Yoshinaga 2021)</ref> and is detailed in the Supplementary Material. The loss to train the model can be denoted as</p><formula xml:id="formula_17">L = ? 1 L SKL + ? 2 L box + ? 3 L GIoU + ? 4 L o + ? 5 L v (15)</formula><p>where L box denotes 1 loss for box regression; L GIoU denotes GIoU loss <ref type="bibr" target="#b41">(Rezatofighi et al. 2019)</ref>; L o denotes Cross-Entropy loss for object class; L v denotes loss for verbs. We mainly study Binary Cross-Entropy (BCE) and Focal loss <ref type="bibr" target="#b29">(Lin et al. 2017</ref>) as L v . ? balances these losses by setting different weights. During inference, the object class and the bounding boxes (bbox) of the human and the object for one HOI triplet is simply generated fromq i . The object score is the maximum object confidence score. The verb score is the multiplication of the object score and the verb score predicted by z i . A binary mask is used by default to filter out object-verb pairs that are not in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Datasets and Metrics</head><p>In this paper, we use two widely-adopted datasets dubbed HICO-DET <ref type="bibr" target="#b6">(Chao et al. 2015)</ref> and V-COCO <ref type="bibr" target="#b15">(Gupta and Malik 2015)</ref>. HICO-DET contains 37,536 training images and 9,515 testing images, in which 600 verb, object unique interaction types are defined out of 117 verb classes and 80 object classes. We evaluate on the test set by interaction mAP (%) over three sets: i) Full set (all 600 interactions), ii) Rare set (138 interactions with less than 10 training samples), iii) Non-Rare set (462 interactions with 10 or more training samples). We evaluate our model under Default setting for the 3 sets. One HOI triplet is rightly localized when the predicted bboxes of the human and object have Intersection-over-Union (IoU) greater than 0.5 with GT bboxes.</p><p>V-COCO contains 2,533 training images, 2,867 validating images and 4,946 testing images, in which interactions are defined upon 25 interactions and 80 object classes. We evaluate on the test set by verb mAP (%) under two scenarios following <ref type="bibr" target="#b22">(Kim et al. 2021;</ref><ref type="bibr" target="#b42">Tamura, Ohashi, and Yoshinaga 2021)</ref>: i) In Scenario1, we need to report when there is no object in the GT HOI triplet, denoted as AP #1 role ; ii) In Sce-nario2, we can ignore the prediction of the object bbox when the GT HOI triplet is without object, denoted as AP #2 role .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>For VM, we use Transformer with a 6-layer encoder and a 6-layer decoder following <ref type="bibr" target="#b4">(Carion et al. 2020)</ref>. We use parameters of DETR trained on COCO <ref type="bibr" target="#b30">(Lin et al. 2014</ref>) as VM's initialization. We adopt AdamW <ref type="bibr" target="#b34">(Loshchilov and Hutter 2018)</ref> to optimize OCN for 80 epochs with a weight decay of 10 ?4 . The learning rate (lr) of the backbone is fixed to 10 ?5 . The lr of other parts starts from 10 ?4 and decays to 10 ?5 after the 60th epoch. We use basic data augmentation to train a robust model, including random crop, random horizontal flipping, image scale and color augmentation following <ref type="bibr" target="#b4">(Carion et al. 2020;</ref><ref type="bibr" target="#b28">Liao et al. 2020)</ref>. During evaluation, the most confident K = 100 HOI triplets are selected to compute mAP. By default, we use following parameters if not otherwise stated. We set number of queries N q = 100 and the dimension of queries D = 256. The head number H for InterC and IntraEC is set to 2. The temperature ? of L SKL is set to 0.05. The smoothing parameter ? is set to 0.1. N p is the number of verb classes. The verb loss is Focal loss and the backbone is ResNet-50 by default. We use 300-dimension GloVe word embedding <ref type="bibr" target="#b37">(Pennington, Socher, and Manning 2014)</ref> as P . The hyper-parameters ? 1 , ? 2 , ? 3 , ? 4 , ? 5 in L are set to 1, 2.5, 1, 1, 1 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Analysis</head><p>Ablation Study We conduct model analysis on HICO-DET. Note that because VM's structure does not change, the ability to localize HOI triplets stays nearly unchanged. The boost purely comes from better verb-inferring ability.</p><p>Module and Loss Ablation To demonstrate the efficacy of our proposed module, we first conduct ablation experiments as shown in <ref type="table" target="#tab_1">Table 1a</ref>. By applying our full model, the Rare set can gain 3.36% and the Non-Rare set 1.28%, producing a more balanced result. If removing L SKL , the model trusts the implicit co-occurrence containing in the initialized word embedding, which is not aligned with our dataset, thus causing performance decline. By applying the VSM together with L SKL , the performance can be boosted by basic semantic aggregation, indicating that the objectverb prior based semantic aggregation helps to better rank the verbs. By using InterC, two modal features can cali-    <ref type="bibr" target="#b45">(Vaswani et al. 2017)</ref>. By appending IntraEC to InterC, features in identical modality can restore the global context after calibration, bringing additive performance boost to InterC. Sensitivity Analysis of Head Numbers InterC and In-traEC are designed to be multi-head. We vary the head numbers for both modules, the results of which are shown in <ref type="table" target="#tab_1">Table 1b</ref>. The best choice for the head number is 2.</p><p>Sensitivity Analysis of the Temperature Parameter For the optimization of VSM, we vary the temperature ? in L SKL which is shown in <ref type="table" target="#tab_1">Table 1c</ref>. A low value of ? will sharpen the distribution of? and thus ease the optimization of L SKL . The table indicates the optimal value is 0.05.</p><p>Sensitivity Analysis of the Smoothed Distribution An appropriate probability smoothing hyper-parameter ? in Eq.6 can balance the HOI detection result by smoothed semantic aggregation. We try varying ? and results are in <ref type="table" target="#tab_3">Table  2</ref>. The table indicates that, i) compared to non-smoothed semantic aggregation, properly smoothing the object-verb distribution can slightly boost the performance; ii) the smoothing operation is not sensitive to the choice of ?, with ? ranging from 0.1 to 10 producing similar results. Hence we set ? = 0.1 by default; iii) by setting ? = ?, the model loses the verb prediction orientation, which damages the performance and proves our claim.</p><p>OCN Helps More for Poor Verb Predictor Since our model relies on object-verb and verb-verb priors, it injects verb prediction guessing information given an object. We have reasonable speculation that adding proposed modules on a model with a poor verb predictor will have more significant improvements due to this object-guided structure. We conduct an experiment with a loss that has more trouble in inferring verbs (BCE), shown in <ref type="table" target="#tab_4">Table 3</ref>. BCE suffers from  <ref type="table">Table 4</ref>: Performance analysis on HICO-DET with different methods of utilizing prior knowledge. Mask denotes binary mask used to filter out impossible object-verb pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>BackboneTime#Params Full PPDM <ref type="bibr" target="#b28">(Liao et al. 2020)</ref> HOG104 56ms 194.9M 21.94 HOTR <ref type="bibr" target="#b22">(Kim et al. 2021)</ref> R50 61ms 51.2M 25.10 ASNet  R50 <ref type="formula" target="#formula_6">56ms</ref>   the problem of imbalanced positive-negative samples. OCN with BCE loss improves upon VM by 6.29%, suggesting that OCN greatly ameliorates the imbalance problem. Even with Focal loss, our model can also make its contribution. Moreover, the Rare set benefits more than the Non-Rare set thanks to our object-guided structure.</p><p>Superiority over Multi-Modal Joint Embeddings A common practice of utilizing word embeddings is Multi-Modal Joint Embedding (MMJE) , which maximizes the similarity between positive vision-semantic pairs and keep negative pairs to a predefined margin. We reimplement MMJE by VSM and L sim in  and add MMJE to VM, results of which are shown in <ref type="table" target="#tab_4">Table  3</ref>. Comparing VM and VM+MMJE, MMJE will cause negative effects when VM is already strong because it trusts the underlying verb relations in word embeddings which have a discrepancy towards the HOI dataset. However, our method with priors will constantly bring in positive effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Superiority over Binary Mask</head><p>The binary mask can be treated as a stiff way to utilize relation prior knowledge by applying a hard mask to the predicted object-verb pair. Our method can be considered as a more fine-grained method which considers object-verb priors and verb co-occurrence priors. The results are shown in <ref type="table">Table 4</ref>. In this table, we also provide results with a metric: mean Recall@K (%) <ref type="bibr">(Tang et al. 2020) (mR@K)</ref>, which averages the recall of HOI interactions with top K evaluation. K is set to 100 in this paper. By applying a stiff method utilizing object-verb prior, although mR@100 goes up by 7.27%, the result of the Full set can only be boosted by 0.26%. While OCN w/o binary mask can boost the Full set by 1.93% and the Rare set by 3.72%, with mR@100 merely going up by 6.03%. It indicates that OCN improves the ranking of HOI interactions greatly while the binary mask struggles to do so, demonstrating the significance of mining the object-guided verb prediction structure. If adding binary masks to OCN, the mAP improvement will be very trivial but with an obvious mR@100  boost, which reemphasizes the binary masks' poor ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computational Cost Analysis</head><p>We compare the computational cost with competitive one-stage methods, shown in <ref type="table" target="#tab_7">Table 5</ref>. It can be seen from the table that our method does well in speed-performance trade-off. To be more specific, VM takes 38ms to run that is identical to QPIC. VSM takes 0.6ms to run. InterC and IntraEC take 4.3ms to run. Note that during inference, we can slightly speed it up by inferring VSM once and storingP in the memory for a given dataset. Our model achieves the best performance with acceptable cost adding to VM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Object-Conditioned Verb Distribution Analysis</head><p>To analyze how the object-guided hierarchy helps the verb prediction, we conduct a case study with different methods' verb distribution on the rightly localized HOI triplets whose objects are predicted as toaster, the figure of which is illustrated in <ref type="figure">Figure 3</ref>. Note that VM and OCN have the same vision structure, thus having identical detection abilities. VM predicts the verb more uniformly. OCN, equipped with object-guided priors, predicts the verb distribution aligned more with the distribution of the training set. We also measure the mean Pearson Correlation Coefficient (mPCC) <ref type="bibr" target="#b3">(Benesty et al. 2009</ref>) of the predicted object-conditioned verb distribution to the training object-conditioned verb distribution ('mean' averages different objects). It turns out that OCN has a higher mPCC (0.636) than VM does (0.476), in- dicating the object-guided priors help the verb prediction.</p><p>t-SNE Visualization of the Semantic Space To observe SKL loss's role, we use t-SNE <ref type="bibr" target="#b35">(Maaten and Hinton 2008)</ref> to visualize the input Glove Embedding set P and the optimized setP , illustrated in <ref type="figure">Figure 4</ref>. In <ref type="figure">Figure 4</ref>, we highlight four word pairs with different colors that highly cooccur in HICO-DET. The original GloVe embedding spreads in the space while the optimization of SKL loss pushes semantically similar verbs closer, which decreases the discrepancy between the implicit priors in GloVe and the verb cooccurrence prior in HICO-DET.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparisons with State-of-the-Arts</head><p>We compare our results with previous state-of-the-arts on HICO-DET in <ref type="table" target="#tab_9">Table 6</ref>. The table indicates that i) All previous models trail our model by a considerable margin. None of the one-stage models possesses the object-guided structure, which shows its superiority. ii) Comparing with previous methods that utilize word embeddings, our method greatly surpasses them by a considerable margin and maintains an end-to-end manner. iii) Comparing to other DETRbased models e.g. HOTR, HOITransformer and QPIC, our method is a more balanced detector thanks to the smoothed prior knowledge. We compare our results with previous state-of-the-arts on V-COCO in <ref type="table" target="#tab_9">Table 6</ref>. The table indicates our method's more superior performances compared to methods w/ or w/o word embeddings. Our method surpasses previous best AP #1 role by 2.4% mAP and best AP #2 role by 1.9%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions and Future Work</head><p>In this paper, we propose to facilitate end-to-end HOI detection models with object-guided priors. In practice, we resort to a more aligned semantic space and propose to perform cross-modal calibration. Similar thoughts can also facilitate other visual relation detection problems like scene graph generation and video HOI. However, our method can run into trouble when extending to scenarios like zero-shot HOI detection, which is left for future exploration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The overall pipeline of OCN. Generally, it consists of VM, VSM and CMC. Input word embeddings are shared across different images for a given dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Example visualizations for y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>i</head><label></label><figDesc>denotes the object class of queryq i predicted us-ing FFN.?q(o) i j is the smoothed P(v j |oq(o) i). Eq.7 utilizes the object class as a cue, to aggregate verb semantic embeddings based on the smoothed priors?q(o) i j .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>A case visualization of toaster-conditioned verb distribution with different methods. Better view in color. Visualization of the semantic space on HICO-DET.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Rare 0.025 30.70 25.03 32.39 0.050 30.91 25.56 32.51 0.100 30.54 24.67 32.29 0.200 30.72 25.59 32.25 (c) Effect of varying choices for temperature ? in LSKL.</figDesc><table><row><cell cols="2">LSKL VSM InterC IntraEC Full Rare Non-Rare</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Base VM</cell><cell>29.15 22.20 31.23</cell><cell cols="2">#Heads H Full Rare Non-Rare</cell><cell>?</cell><cell>Full Rare Non-</cell></row><row><cell></cell><cell>30.91 25.56 32.51</cell><cell>1</cell><cell>30.58 25.65 32.05</cell><cell></cell></row><row><cell></cell><cell>30.54 24.33 32.39</cell><cell>2</cell><cell>30.91 25.56 32.51</cell><cell></cell></row><row><cell></cell><cell>29.88 23.50 31.79</cell><cell>4</cell><cell>30.82 24.45 32.73</cell><cell></cell></row><row><cell></cell><cell>30.51 25.15 32.12</cell><cell>8</cell><cell>30.65 24.93 32.36</cell><cell></cell></row><row><cell></cell><cell>30.40 24.71 32.10</cell><cell cols="2">(b) Effect of head numbers for both</cell><cell></cell></row><row><cell cols="2">(a) Ablation study of proposed modules and loss.</cell><cell cols="2">InterC and IntraEC.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Ablation study on HICO-DET.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Effect of varying ? in Eq.6. ? = ? denotes? ij = 1/N p , without any prior knowledge.</figDesc><table><row><cell>Verb Loss</cell><cell>Model</cell><cell>Full</cell><cell>Rare</cell><cell>Non-Rare</cell></row><row><cell></cell><cell>VM</cell><cell>20.13</cell><cell>13.16</cell><cell>22.22</cell></row><row><cell>BCE</cell><cell cols="4">VM + MMJE 20.60+0.47 13.66+0.50 22.67+0.45 OCN 26.42+6.29 20.79+7.63 28.11+5.83</cell></row><row><cell></cell><cell>VM</cell><cell>29.15</cell><cell>22.20</cell><cell>31.23</cell></row><row><cell>Focal</cell><cell cols="4">VM + MMJE 28.83?0.32 22.09?0.11 30.84?0.39 OCN 30.91+1.76 25.56+3.36 32.51+1.28</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: Performance analysis on HICO-DET with different</cell></row><row><cell>verb losses and semantic models.</cell></row><row><cell>brate features based on the other modality, bringing in per-</cell></row><row><cell>formance boost. By using IntraEC, intra-modal features, es-</cell></row><row><cell>pecially semantic aggregated featuresp i , can have better</cell></row><row><cell>global-dependent representations</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>15+0.26 22.20+0.44 31.23+0.21 65.10+7.27 OCN 30.82+1.93 25.48+3.72 32.42+1.40 63.86+6.03 30.91+2.02 25.56+3.80 32.51+1.49 67.64+9.81</figDesc><table><row><cell>Model Mask</cell><cell>Full</cell><cell>Rare</cell><cell cols="2">Non-Rare mR@100</cell></row><row><cell></cell><cell>28.89</cell><cell>21.76</cell><cell>31.02</cell><cell>57.83</cell></row><row><cell>VM</cell><cell>29.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Computational cost analysis on HICO-DET with Tesla V100. HOG and R are short for Hourglass and ResNet.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Comparisons with state-of-the-arts on HICO-DET and V-COCO. Full, Rare and Non-Rare columns are reported on HICO-DET and AP #1 role AP #2 role on V-COCO. * denotes utilization of word embeddings. ? denotes reproduction using COCO pre-trained parameters.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to appreciate Rong Jin for carefully revising the manuscript, Mingqian Tang and Jianwen Jiang for discussing the ideas, and anonymous reviewers for their valuable feedback. This work was supported by National Natural Science Foundation of China Grant No. 62173298.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Detecting human-object interactions via functional generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Rambhatla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="10460" to="10469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Zero-shot object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sikka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Divakaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="384" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Noise reduction in speech processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Benesty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">End-to-End Object Detection with Transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.12872</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning to detect human-object interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="381" to="389" />
		</imprint>
	</monogr>
	<note>ieee winter conference on applications of computer vision (wacv</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hico: A benchmark for recognizing human-object interactions in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1017" to="1025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Reformulating hoi detection as adaptive set prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9004" to="9013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Knowledgeembedded routing network for scene graph generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6163" to="6171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-S</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.01005</idno>
		<title level="m">DIRV: Dense Interaction Region Voting for End-to-End Human-Object Interaction Detection</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Drg: Dual relation graph for human-object interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="696" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">ican: Instance-centric attention network for human-object interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.10437</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamic Fusion With Intra-and Inter-Modality Attention Flow for Visual Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Convolutional sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1243" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Detecting and recognizing human-object interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8359" to="8367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.04474</idno>
		<title level="m">Visual semantic role labeling</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">No-frills humanobject interaction detection: Factorization, layout encodings, and training techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9677" to="9685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Divide and conquer: Question-guided spatio-temporal contextual attention for video question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11101" to="11108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image retrieval using scene graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3668" to="3678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Uniondet: Union-level detector towards real-time human-object interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="498" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">HOTR: End-to-End Human-Object Interaction Detection with Transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="74" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Detecting human-object interactions with action co-occurrence priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="718" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-W</forename><surname>On</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-T</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.04325</idno>
		<title level="m">Hadamard product for low-rank bilinear pooling</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The Hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Naval research logistics quarterly</title>
		<imprint>
			<date type="published" when="1955" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<title level="m">HOI Analysis: Integrating and Decomposing Human-Object Interaction. Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Transferable interactiveness knowledge for human-object interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-S</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3585" to="3594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Ppdm: Parallel point detection and matching for real-time humanobject interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="482" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.12962</idno>
		<title level="m">GPS-Net: Graph Property Sensing Network for Scene Graph Generation</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Improving referring expression grounding with cross-modal attention-guided erasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1950" to="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Amplifying key cues for human-object-interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="248" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Decoupled Weight Decay Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing</title>
		<meeting>the 2014 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Detecting unseen visual relations using analogies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peyre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1981" to="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning Human-Object Interactions by Graph Parsing Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Anyshot object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asian Conference on Computer Vision</title>
		<meeting>the Asian Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Generalized intersection over union: A metric and a loss for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">QPIC: Query-Based Pairwise Human-Object Interaction Detection with Image-Wide Contextual Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ohashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yoshinaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10410" to="10419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Unbiased scene graph generation from biased training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3716" to="3725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Vsgnet: Spatial attention network for detecting human object interactions using graph convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ulutan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iftekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13617" to="13626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Pose-aware multi-level feature network for human object interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9469" to="9478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Contextual heterogeneous graph network for human-object interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yingbiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="248" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep contextual attention for humanobject interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Anwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Laaksonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5694" to="5702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning human-object interaction detection using interaction points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4116" to="4125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Zero-shot recognition via semantic embeddings and knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6857" to="6866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Camp: Cross-modal adaptive message passing for textimage retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5764" to="5773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning to detect human-object interactions with knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Exploring visual relationship for image captioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="684" to="699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Cross-modality attention with semantic graph embedding for multi-label classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="12709" to="12716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning Visual Context for Group Activity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="3261" to="3269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Spatio-Temporal Dynamic Inference Network for Group Activity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7476" to="7485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="179" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Learning to count objects in natural images for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bennett</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05766</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Polysemy deciphering network for human-object interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK, Au</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="69" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Glance and Gaze: Inferring Action-aware Points for One-Stage Human-Object Interaction Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13234" to="13243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Relation Parsing Neural Network for Human-Object Interaction Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Semantic relation reasoning for shot-stable few-shot object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8782" to="8791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">End-to-end human object interaction detection with hoi transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11825" to="11834" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
