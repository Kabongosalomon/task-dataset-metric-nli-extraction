<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilun</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kushal</forename><surname>Lakhotia</surname></persName>
							<email>?lakhotia.kushal@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
							<email>barlaso@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anchit</forename><surname>Gupta</surname></persName>
							<email>anchit@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
							<email>plewis@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Peshterliev</surname></persName>
							<email>stanvp@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
							<email>mehdad@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
							<email>sonalgupta@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meta</forename><surname>Ai</surname></persName>
						</author>
						<title level="a" type="main">Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite their recent popularity and wellknown advantages, dense retrievers still lag behind sparse methods such as BM25 in their ability to reliably match salient phrases and rare entities in the query and to generalize to out-of-domain data. It has been argued that this is an inherent limitation of dense models. We rebut this claim by introducing the Salient Phrase Aware Retriever (SPAR) 1 , a dense retriever with the lexical matching capacity of a sparse model. We show that a dense Lexical Model ? can be trained to imitate a sparse one, and SPAR is built by augmenting a standard dense retriever with ?. Empirically, SPAR shows superior performance on a range of tasks including five question answering datasets, MS MARCO passage retrieval, as well as the EntityQuestions and BEIR benchmarks for out-of-domain evaluation, exceeding the performance of state-of-the-art dense and sparse retrievers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Text retrieval is a crucial component for a wide range of knowledge-intensive NLP systems, such as open-domain question answering (ODQA) models and search engines. Recently, dense retrievers <ref type="bibr" target="#b11">(Karpukhin et al., 2020;</ref><ref type="bibr" target="#b36">Xiong et al., 2021)</ref> have gained popularity and demonstrated strong performance on a number of retrieval tasks. Dense retrievers employ deep neural networks to learn continuous representations for the queries and documents, and perform retrieval in this dense embedding space using nearest neighbor search <ref type="bibr" target="#b9">(Johnson et al., 2019)</ref>. Compared to traditional sparse retrievers that rely on discrete bag-of-words representations, dense retrievers can derive more semantically expressive embeddings, thanks to its end-to-end learnability and powerful pre-trained encoders. This helps dense retrievers to overcome several inherent limitations of sparse systems such as vocabulary mismatch (where different words are used to express the same meaning) and semantic mismatch (where the same word has multiple meanings).</p><p>On the other hand, while existing dense retrievers excel at capturing semantics, they sometimes fail to match the salient phrases in the query. For example, <ref type="bibr" target="#b11">Karpukhin et al. (2020)</ref> show that DPR, unlike a sparse BM25 retriever <ref type="bibr" target="#b31">(Robertson and Walker, 1994)</ref>, is unable to catch the salient phrase "Thoros of Myr" in the query "Who plays Thoros of Myr in Game of Thrones?". Similarly, <ref type="bibr" target="#b36">Xiong et al. (2021)</ref> observe that ANCE fails to recognize "active margin" as a key phrase in the query "What is an active margin" and instead retrieves passages describing the financial term "margin". In addition, dense retrievers struggle to generalize to out-of-domain test data compared to trainingfree sparse retrievers such as BM25. For instance, <ref type="bibr" target="#b32">Sciavolino et al. (2021)</ref> find that DPR performs poorly compared to BM25 on simple entity-centric questions, and <ref type="bibr" target="#b33">Thakur et al. (2021)</ref> introduce a new BEIR benchmark to evaluate the zero-shot generalization of retrieval models showing that BM25 outperforms dense retrievers on most tasks.</p><p>With dense and sparse retrievers each having their own distinctive pros and cons, researchers have long aspired to develop retriever models that combine the strengths of both. This, however, has proven challenging as dense and sparse retrievers are supported by drastically different algorithms and data structures (inverted index <ref type="bibr" target="#b3">(Bia?ecki et al., 2012)</ref> for sparse and approximate nearest neighbor search <ref type="bibr" target="#b9">(Johnson et al., 2019)</ref> for dense). Most existing research towards this goal extends sparse retrievers with improved representations from neural models . These methods, nonetheless, still rely on exact matching on a bag of tokens, which arguably cannot fully leverage the The SPAR model: <ref type="figure">Figure 1</ref>: SPAR augments a dense retriever with a dense Lexical Model ? trained to imitate a sparse teacher retriever. ? is trained using random sentences as queries with positive and negative passages produced by the teacher. ? is then combined with a dense retriever via vector concatenation to form a salient-phrase aware retriever.</p><p>representational power of the pre-trained encoders.</p><p>The opposite route of building better dense retrievers with the strengths of sparse models is much less explored. In fact, there have been theoretical and empirical studies suggesting that such drawbacks of dense retrievers may be a result of inherent limitations <ref type="bibr" target="#b30">Reimers and Gurevych, 2021)</ref>. In this work, we embark on this underexplored research direction by proposing SPAR <ref type="figure">(Figure 1</ref>), a dense retriever with the lexical matching capacity and out-of-domain generalization of a sparse model. In particular, we address an important yet largely unanswered research question: Can we train a dense retriever to imitate a sparse one? Contrary to previous findings, we show that it is indeed possible to mimic a given sparse retriever (e.g., BM25 or UniCOIL ) with a dense Lexical Model ?, and we build the SPAR model by combining ? with a standard dense retriever (e.g., DPR or ANCE). Despite the long-standing dichotomy between sparse and dense retrievers, we arrive at a simple yet elegant solution of SPAR in ?4, by conducting an extensive study to answer two key questions: i) How to train ? to imitate a sparse retriever ( ?4.1) and ii) How to best utilize ? to build a salient-phrase aware dense retriever ( ?4.2).</p><p>We evaluate SPAR on five ODQA datasets ( ?5.1) as well as on the MS MARCO <ref type="bibr" target="#b0">(Bajaj et al., 2018)</ref> passage retrieval benchmark ( ?5.2), and show that it outperforms existing dense and sparse retrievers. We also examine the generalization of SPAR showing strong zero-shot performance across datasets ( ?5.3), including on the BEIR bechmark <ref type="bibr" target="#b33">(Thakur et al., 2021)</ref> and a recently released dataset of entity-centric questions <ref type="bibr" target="#b32">(Sciavolino et al., 2021)</ref>. In addition, we conduct a series of analyses of the Lexical Model ? showcasing its lexical matching capability ( ?6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Sparse retrievers date back for decades and successful implementations such as BM25 <ref type="bibr" target="#b31">(Robertson and Walker, 1994)</ref> remain popular to date for its lexical matching capacity and great generalization. Despite the rapid rise of dense retrievers in recent years, development in sparse retrievers remain active, partly due to the limitations of dense retrievers discussed in ?1. Various methods have been proposed to improve term weight learning <ref type="bibr" target="#b4">(Dai and Callan, 2020;</ref><ref type="bibr" target="#b24">Mallia et al., 2021)</ref>, address vocabulary mismatch <ref type="bibr" target="#b26">(Nogueira and Lin, 2019)</ref> and semantic mismatch <ref type="bibr" target="#b6">(Gao et al., 2021)</ref>, inter alia. While most of these methods have been incompatible with dense retrievers, our SPAR method provides a route for incorporating any such improvement into a dense retriever. Dense retrievers employ pre-trained neural encoders to learn vector representations and perform retrieval by using nearest-neighbor search in this dense embedding space <ref type="bibr" target="#b11">Karpukhin et al., 2020)</ref>. Subsequent works have developed various improvements, including more sophisticated training strategies and using better hard negatives <ref type="bibr" target="#b36">(Xiong et al., 2021;</ref><ref type="bibr" target="#b23">Maillard et al., 2021;</ref><ref type="bibr" target="#b23">Oguz et al., 2021)</ref>. Such improve-ments are also complementary to the SPAR approach, which can potentially leverage these more powerful dense retrievers as shown in ?5.2.</p><p>A few recent studies focus on the limitations of current dense retrievers. <ref type="bibr" target="#b15">Lewis et al. (2021a)</ref> and  study the generalization issue of dense retrievers in various aspects, such as the overlap between training and test data, compositional generalization and the performance on matching novel entities. <ref type="bibr" target="#b33">Thakur et al. (2021)</ref> introduce a new BEIR benchmark to evaluate the zeroshot generalization of retrieval models showing that BM25 outperforms dense retrievers on most tasks. A different line of research explores using multiple dense vectors as representations which achieves higher accuracy but is much slower <ref type="bibr" target="#b12">(Khattab and Zaharia, 2020)</ref>. <ref type="bibr" target="#b19">Lin et al. (2021b)</ref> further propose a knowledge distillation method to train a standard dense retriever with similar performance of the multi-vector ColBERT model. More recently, <ref type="bibr" target="#b32">Sciavolino et al. (2021)</ref> create EntityQuestions, a synthetic dataset of entity-centric questions to highlight the failure of dense retrievers in matching key entities in the query. We evaluate the generalization of SPAR on BEIR and EntityQuestions in ?5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries: Dense Retrieval</head><p>In this work, we adopt DPR <ref type="bibr" target="#b11">(Karpukhin et al., 2020)</ref> as our dense retriever architecture for learning the Lexical Model ?. We give a brief overview of DPR in this section and refer the readers to the original paper for more details.</p><p>DPR is a bi-encoder model with a query encoder and a passage encoder, each a BERT transformer , which encodes the queries and passages into d-dimensional vectors, respectively. Passage vectors are generated offline and stored in an index built for vector similarity search using libraries such as FAISS <ref type="bibr" target="#b9">(Johnson et al., 2019)</ref>. The query embedding is computed at run time, which is used to look up the index for k passages whose vectors are the closest to the query representation using dot-product similarity.</p><p>DPR is trained using a contrastive objective: given a query and a positive (relevant) passage, the model is trained to increase the similarity between the query and the positive passage while decreasing the similarity between the query and negative ones. It is hence important to have hard negatives (irrelevant passages that are likely confused with positive ones) for more effective training 2 .</p><p>We employ the DPR implementation from <ref type="bibr" target="#b23">Oguz et al. (2021)</ref>, which supports efficient multi-node training as well as memory-mapped data loader, both important for the large-scale training of ?. For model training, we also adopt their validation metrics of mean reciprocal rank (MRR) on a surrogate corpus using one positive and one hard negative from each query in the development set. Assuming a set of N dev queries, this creates a mini-index of 2N passages, where the MRR correlates well with full evaluation while being much faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The SPAR Model</head><p>In this section, we present SPAR, our salient phrase aware dense retriever. As illustrated in <ref type="figure">Figure 1</ref>, the basic idea of SPAR is to first train a dense Lexical Model ? such that it produces similar predictions to a sparse teacher retriever. ? is then combined with a regular dense retriever via vector concatenation. Although the high-level idea of SPAR is fairly straightforward, details of the model training process dictate its success in practice, and thus require a careful experimental study. To find the optimal configuration of SPAR, we conduct pilot experiments using the validation set of NaturalQuestions (NQ, <ref type="bibr" target="#b13">Kwiatkowski et al., 2019)</ref> following the open-domain question answering setting . BM25 is adopted as the teacher model for training ?. Below we describe the key results on how to successfully train ? ( ?4.1) and on how to best leverage ? to form SPAR ( ?4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training the Lexical Model ?</head><p>Training ? to imitate the predictions of a sparse retriever is similar to the distillation of the sparse teacher into a bi-encoder model. There are many options to do this, such as imitating the scores of the sparse retriever with the MSE loss or KL divergence, or learning the passage ranking of the teacher while discarding the scores. After unsuccessful initial attempts with these methods, we instead choose an approach inspired by the DPR training for its simplicity and stability in training.</p><p>Recall that to train a DPR model, a passage corpus and a set of training queries are needed, where each query is associated with one or more positive and hard negative passages. To create the training data for ?, we use the sparse teacher retriever to produce the positive and negative passages. In particular, for any given query, we run the teacher model to retrieve the top K passages and use the top n p passages as positives and the bottom n n as negatives. After such training data is generated, ? can be trained using the same contrastive loss as DPR. To find the best strategy for training ?, we experiment with different ways of preparing the queries and different values of K, n p and n n .</p><p>We use a similar process to create the validation data, and adopt the MRR metric ( ?3) for evaluating whether ? behave similarly to the teacher model. In particular, we use the questions from the NQ validation set as the target queries and whether a passage is relevant is again determined by the teacher. For validation, n p is set to 1, which means only the passage ranked the highest by the teacher is considered positive. As a result, a higher MRR on this validation set indicates that the predictions of ? are more similar to the teacher.</p><p>Training queries As the teacher model can be run on arbitrary queries to generate positive and negative passages, we are not restricted to any annotated data but can freely explore what training queries to use for training ?. We experiment with different approaches for constructing such queries, including using either well-formed questions or random sentences in the passage corpus, and also test the effect of using a large number of queries. We consider three query sets: NQ questions, Wiki sentences and PAQ questions. NQ questions consists of 59k questions in the training set of NQ, which have the benefit of being similar to the evaluation queries. Wiki sentences are a large collection of 37 million sentences sampled randomly from the Wikipedia passage corpus. We make sure that at least one sentence is sampled from each passage and more sentences come from the first few passages of each article (following a pseudoexponential distribution) as they tend to contain answers to more questions 3 . Finally, PAQ questions are from the PAQ dataset <ref type="bibr">(Lewis et al., 2021b)</ref>, a collection of 65 million synthetically generated probably asked questions based on Wikipedia. <ref type="table">Table 1</ref> shows how well ? trained with each query set can approximate the teacher BM25 model. We notice that the size of the data certainly plays an important role, as both Wiki ? and PAQ ? outperform NQ ? by a wide margin. Intuitively, largescale training data is helpful for learning lexical <ref type="bibr">3</ref> We did not explore sampling strategies but an early experiment suggests that sampling uniformly may also work.  matching as it gives the neural models more exposure to rare words and phrases. PAQ ? achieves the highest MRR among the three options, for it combines the benefits of NQ and Wiki ?, with large-scale queries that are also similar to the downstream evaluation data. However, such large-scale synthetic queries are very expensive to obtain and not available for all domains, so we focus our attention on the much cheaper Wiki ? option, given that the gap between their performance is small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of positive and negative passages</head><p>We also experimented with the numbers of positive and negative passages per training query. The model performance was not sensitive to the total number of passages retrieved from the teacher model (K) as well as the number of negative passages (n n ). However, the number of positives (n p ) is more important. As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, using more than one positive passage is critical to successful training, as n p = 2 significantly improves the validation metrics over n p = 1. Further increase in n p remains helpful, but with a diminished return. As a result, we use n p = 10 in our final model.  <ref type="table" target="#tab_4">Table 2</ref>, the results are only slightly better than the original DPR on Acc@100. We next test directly combining the vectors of DPR and ?, using either summation (Weighted Sum) or concatenation (Weighted Concat), where the weights are tuned using the validation data. In our experiments, we find that both methods perform well, achieving higher Acc@20 and Acc@100 scores than DPR+BM25. Although concatenation performs better, summation has the benefit of not increasing the dimension of the final vectors. Since both DPR and ? are dense retrievers, this post-hoc combination can be easily done without affecting the retrieval index.</p><p>The good performance of Weighted Concat is encouraging, but also triggers two questions. First, does the good performance come from the longer embedding size? To answer this question, we include the ensemble (weighted concatenation of embeddings) of two independently trained DPR models (2 DPRs) as an additional baseline. Although it has the same dimension and number of parameters as Weighted Concat, its performance is substantially lower. Second, can we train a better concatenation model instead of simply combining the vectors of two separately trained models at test time?</p><p>We experiment with a joint training approach, in which we concatenate the DPR embeddings with that of a trained ? during DPR training. The similarity and loss are computed with the concatenated vector, but we freeze ?, and only train the DPR encoders as well as the scalar weight for vector concatenation. The idea is to make DPR "aware" of the lexical matching scores given by ? during its training in order to learn a SPAR model. This can Acc@k on NQ @20 @100  also be viewed as training DPR to correct the errors made by ?. Somewhat surprisingly, however, this strategy does not work well compared to post-hoc concatenation as shown in <ref type="table" target="#tab_4">Table 2</ref>. We hence adopt the Weighted Concat method in our final model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concatenation Weight Tuning</head><p>When concatenating the vectors from two dense retrievers, they may be on different scales, especially across varied datasets. It is hence helpful to add a weight ? to balance the two models during concatenation. We add the weight to the query embeddings so that the offline passage index is not affected by a change of weight. Specifically, for a query q and a passage p, a dense retriever with query encoder Q and passage encoder P , as well as a ? model with Q ? and P ? , the final query vector in SPAR is Q(q), ?Q ? (q) while the passage vector being P (p), P ? (p) . The final similarity score:</p><formula xml:id="formula_0">sim SPAR (q, p) = Q(q), ?Q ? (q) P (p), P ? (p) = sim(q, p) + ? ? sim ? (q, p) (1)</formula><p>Note that our decision of adding ? to the query vectors can potentially support dynamic or queryspecific weights without the need to change the index, which we leave for future work. Our final SPAR model is a general framework for augmenting any dense retriever with the lexical matching capability from any given sparse retriever. We first train ? using queries from random sentences in the passage collection and labels generated by the teacher model with 10 positive and 5 hard negative passages. We then combine ? and the base dense retriever with weighted vector concatenation using weights tuned on the development set. The passage embeddings can still be generated offline and stored in a single FAISS index and retrieval can be done in the same way as a standard dense retriever.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparing SPAR with Hybrid Retrievers</head><p>While most research efforts focus on improving either the dense or sparse retrievers to overcome their drawbacks, people in practice also build hybrid retrievers that directly combine a dense and a sparse retriever. Unlike SPAR which remains a dense retriever, such hybrid models maintain both a dense and a sparse retriever. When deployed, it separately retrieves from the dense and sparse retriever and then combine the results. This can improve the model accuracy, but inevitably incurs additional engineering costs and may have a higher latency compared to either a dense or sparse retriever. In this section, we briefly highlight some differences between SPAR and the hybrid models.</p><p>Architectural Complexity SPAR consists of two encoders, which increases the complexity of the inference. At retrieval time, however, SPAR does not introduce additional complexity because SPAR inference can be encapsulated in a single forward call, making it a drop-in replacement of any standard dense retriever such as DPR. Passage embeddings can still be pre-computed and stored in a single FAISS index, and only a single lookup in the FAISS index is needed for retrieval. In contrast, hybrid retrievers need to build two separate indices with different libraries (e.g. FAISS for dense and Lucene for sparse). When a query comes in, retrieval needs to be performed on both indices (using different algorithms), and the retrieved passages then need to be aggregated to form the final results. Furthermore, as retrieval techniques for sparse vectors differ from those for dense vectors, it is computationally prohibitive to perform exact hybrid search, and challenging to devise an efficient approximation <ref type="bibr" target="#b35">(Wu et al., 2019)</ref>. On the other hand, Eqn. (1) indicates that SPAR retrieval is an exact hybrid of ? and the base retriever, achievable with a standard FAISS index.</p><p>Index Size and Retrieval Speed SPAR has two variants ( ?4.2), where the weighted concat variant is optimized for accuracy while the weighted sum variant has higher efficiency. With the weighted sum variant, the index size and retrieval speed stays the same as the base dense retriever. With the weighted concat variant, the index size is twice as large. The latency, on the other hand, consists of two parts: encoder inference and index search. A standard DPR model with a HNSW index has an end-to-end latency of 30ms (20ms encoding + 10ms index search) for open-domain question answering, while SPAR with the weighted concat vector combination has 40ms (20ms encoding + 20ms index search).</p><p>In comparison, a standard BM25 in the Anserini toolkit has a 55ms latency <ref type="bibr" target="#b7">(Hofst?tter et al., 2021)</ref>, but the index size is much smaller. A hybrid model, which consists of both a dense and a sparse retriever, has a latency higher than the slower of the two, and an index size that equals to the total size of the dense and sparse index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Open-Domain Question Answering</head><p>Datasets We evaluate on five widely used ODQA datasets : NaturalQuestions (NQ, <ref type="bibr" target="#b13">Kwiatkowski et al., 2019)</ref>, SQuAD v1.1 <ref type="bibr" target="#b29">(Rajpurkar et al., 2016)</ref>, TriviaQA <ref type="bibr" target="#b10">(Joshi et al., 2017)</ref>, We-bQuestions (WebQ, <ref type="bibr" target="#b2">Berant et al., 2013)</ref> and Curat-edTREC (TREC, <ref type="bibr" target="#b1">Baudi? and ?ediv?, 2015)</ref>. We follow the exact setup of DPR <ref type="bibr" target="#b11">(Karpukhin et al., 2020)</ref>, including the train, dev and test splits, and the Wikipedia passage collection, as well as the accuracy@k (Acc@k) metric for evaluation, which is defined as the fraction of queries that has at least one positive passage retrieved in the top k. <ref type="table" target="#tab_6">Table 3</ref> presents the main results on ODQA. For SPAR models, we report two variants both trained with BM25 as teacher, using the Wiki and PAQ training queries respectively ( ?4.1). The MARCO ? is to test the model generalization of SPAR, and will be discussed in ?5.3. SPAR outperforms all state-of-the-art retrievers in the literature, usually by wide margins, demonstrating the effectiveness of our approach.</p><p>Another appealing result comes from SQuAD, a dataset on which all previous dense retrievers fail to even get close to a simple BM25 model. As the SQuAD annotators are given the Wikipedia passage when they write the questions, the lexical overlap between the questions and the passages is hence higher than other datasets. The poor performance of dense retrievers on SQuAD confirms that dense retrieval struggles at lexical matching. On the other hand, SPAR dramatically improves over previous models, achieving an improvement of 13.6 points in Acc@100 over the best existing dense retriever.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NQ</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SQuAD</head><p>TriviaQA WebQ TREC Average Model @20 @100 @20 @100 @20 @100 @20 @100 @20 @100 @20 @100  PAQ ? matches the accuracy of the teacher BM25 model, while Wiki ? performs slightly worse. The performance gap, however, is smaller in the final SPAR model. Both approaches are able to match the performance of the hybrid model, and SPAR-PAQ is only 0.3% better on average than SPAR-Wiki. This enables us to go with the much cheaper Wiki option for training ? without sacrificing much of the end performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">MS Marco Passage Retrieval</head><p>In this section, we report our experiments on the MS MARCO passage retrieval dataset <ref type="bibr" target="#b0">(Bajaj et al., 2018)</ref>, a popular IR benchmark with queries from the Bing search engine and passages from the web. Following standard practice, we evaluate MRR@10, Recall@50 and Recall@1000.</p><p>To highlight the versatility of our approach, we adopt two base dense retrievers in SPAR, ANCE and RocketQA. We further consider two sparse retrievers for training ?, BM25 and UniCOIL , a recent SoTA sparse retriever, to study whether SPAR training can imitate a more advanced teacher model. Similar to the Wiki training queries, we create a MARCO corpus for training ?. As the MS MARCO passage collection has fewer passages than Wikipedia, we use all sentences instead of sampling, resulting in a total of 28 million queries. We also report the performance of the Wiki ? for model generalization (see ?5.3). <ref type="table">Table 4</ref> illustrates the results, where the sections correspond to sparse retrievers, the Lexical Models, state-of-the-art dense retrievers, various hybrid models, and finally SPAR and the model generalization experiments. As demonstrated in <ref type="table">Table 4</ref>, SPAR is able to augment ANCE and Rock-etQA with the lexical matching capacity from either BM25 or UniCOIL, leading to a performance close to the hybrid retriever, and again outperforming all existing dense and sparse retrievers with a MRR@10 of 38.6. The fact that SPAR works with not only DPR and BM25, but other SoTA dense and sparse retrievers makes SPAR a general solution for combining the knowledge of dense and sparse retrievers in a single dense model.</p><p>One intriguing observation is that SPAR works better when retrieving more candidates. SPAR is slightly worse than the hybrid models on MRR@10, but catches up on R@50, and even outperforms the hybrid ones when considering top 1000 candidates. This is also observed on ODQA experiments between R@20 and R@100. Another interesting phenomenon in both experiments is that while ? by itself achieves a slightly lower performance than the teacher sparse retriever, the final SPAR model can reach or beat the hybrid model when combined with the same dense retriever. One possible reason why SPAR outperforms the hybrid  <ref type="bibr" target="#b19">(Lin et al., 2021b)</ref> 35.9 -97.0 (d) RocketQA  37  <ref type="table">Table 4</ref>: SPAR results on MS MARCO passage retrieval. We consider several options for ?, trained with different objectives (BM25 and UniCOIL) and different corpora (MSMARCO and Wikipedia). For ANCE and RocketQA, we use the released checkpoints and our evaluation scripts. We matched public numbers in most cases, but we were unable to reproduce the R@50 and R@1000 reported by RocketQA.</p><p>model may be that SPAR is able to perform an exact "hybrid" of two retrievers since both are dense models (Eqn. 1), while the real hybrid model has to rely on approximation. We leave further investigation in these curious findings to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Out-of-Domain Generalization of SPAR</head><p>We now focus on another important topic regarding the generality of SPAR. We have shown that Wiki ? achieves a similar performance to PAQ ?, making it often unnecessary to rely on sophisticatedly generated queries for training ?. A more exciting finding is that ? also has great zero-shot generalization to other datasets. In the last section of <ref type="table" target="#tab_6">Table 3</ref> and 4, we reported SPAR performance on ODQA using the ? model built for MS MARCO and vice versa. In both directions, ? has a high zero-shot accuracy, and SPAR's performance is close to that using in-domain ?. This suggests that ? shares the advantage of better generalization of a sparse retriever, and it may not be always necessary to retrain ? on new datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Zero-shot performance on BEIR</head><p>We further evaluate zero-shot transfer of SPAR on the BEIR benchmark <ref type="bibr" target="#b33">(Thakur et al., 2021)</ref>, which consists of a diverse set of 18 retrieval tasks across 9 domains 5 . In particular, following the standard setup, all models are trained on MS MARCO and tested on the BEIR benchmarks. Therefore, we adopt the MARCO ? models, and combine them with various dense retrievers trained on MS MARCO to form SPAR models.</p><p>As shown in <ref type="table" target="#tab_11">Table 5</ref>, SPAR achieves a new stateof-the-art overall performance, and performs the best on 11 out of 14 datasets. Regardless of the choice of the base dense retriever, adding either the BM25 or UniCOIL ? can consistently and substantially boost the performance of the dense retriever. With ANCE as the base dense retriever, which performs significantly worse than the simple BM25 on  <ref type="bibr" target="#b8">(Izacard et al., 2021</ref><ref type="bibr">) 59.6 32.8 49.8 63.8 32.9 44.6 23.0 86.5 34.5 41.3 16.5 75.8 23.7 67.7 46.6 GTR-large (Ni et al., 2021</ref> 55.7 32.9 54.7 57.9 42.4 52.5 21.9 89.0 38.   A concurrent work <ref type="bibr" target="#b32">(Sciavolino et al., 2021</ref>) also identifies the lexical matching issue of dense retrievers, focusing specifically on entity-centric queries. They create a synthetic dataset containing simple entity-rich questions, where DPR performs significantly worse than BM25. In <ref type="table" target="#tab_12">Table 6</ref>, we evaluate SPAR on this dataset in a zero-shot setting without any re-training, other than tuning the concatenation weight on the development set. The result further confirms the generalization of SPAR. ? transfers much better to this dataset than DPR, achieving a slightly lower performance than BM25. When ? is combined with DPR, SPAR achieves a higher Acc@20 than the hybrid model, and overall an improvement of 17.4 points over DPR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Implementation Details</head><p>We train ? for 3 days on 64 GPUs with a per-GPU batch size of 32 and a learning rate of 3e?5 (roughly 20 epochs for Wiki ? and MARCO ?, and 10 epochs for PAQ ?). The remaining hyperparameters are the same as in DPR, including the BERT-base encoder and the learning rate scheduler. For Wiki and PAQ ?, we use NQ dev as the validation queries, and MS MARCO dev for MARCO ?. For the dense retrievers used in SPAR, we directly take the publicly released checkpoints without retraining to combine with ?. We use Pyserini <ref type="bibr">(Lin et al., 2021a)</ref> for all sparse models in this work.</p><p>For tuning the concatenation weights ?, we do a grid search on [0.1, 1.0] (step size 0.1) as well as their reciprocals, resulting in a total of 19 candidates ranging from 0.1 to 10. The best ? is selected using the best Acc@100 for ODQA ( ?5.1) and MRR@10 for MS MARCO ( ?5.2) on the development set for each experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Does ? Learn Lexical Matching?</head><p>In this section, we verify whether ? actually learns lexical matching with a series of analyses.   <ref type="bibr" target="#b34">Webber et al., 2010)</ref> between BM25 and various dense retrievers on the dev set. We use the standard p = 0.9 in RBO.</p><p>We first directly compare the predictions of ? against BM25. As shown in <ref type="table" target="#tab_14">Table 7</ref>, the prediction of DPR and BM25 are dramatically different from each other, with a RBO of only 0.1, which is a correlation measure between partially overlapped ranked lists. In contrast, ? achieves a much higher overlap with BM25 of around 0.5 to 0.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Stress test: token-shuffled questions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Original Shuffled ? @20 @100 @20 @100 @20 @100  <ref type="table">Table 8</ref>: Lexical matching stress test on NQ Dev, using token-shuffled questions. ? is order agnostic and maintains its performance on shuffled queries.</p><p>Next, we inspect the lexical matching capacity of ? in an extreme case where the order of tokens in each question is randomly shuffled. <ref type="table">Table 8</ref> indicates that the performance of DPR drops significantly on this token-shuffled dataset, while the bag-of-word BM25 model remains completely unaffected. On the other hand, both Wiki ? and PAQ ? remain highly consistent on this challenge set, showing great robustness in lexical matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Hybrid SPAR + BM25 model</head><p>To confirm that SPAR improves DPR's performance by enhancing its lexical matching capability, we add the real BM25 to SPAR to create a hybrid model. As demonstrated in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we propose SPAR, a salient-phrase aware dense retriever, which can augment any dense retriever with the lexical matching capacity and out-of-domain generalization from a sparse retriever. This is achieved by training a dense Lexical Model ? to imitate the behavior of the teacher sparse retriever, the feasibility of which remained unknown until this work. In the experiments, we show that SPAR outperforms previous state-of-theart dense and sparse retrievers, matching or even beating more complex hybrid systems, on various in-domain and out-of-domain evaluation datasets. Furthermore, SPAR is able to augment any dense retriever such as DPR, ANCE or RocketQA, with knowledge distilled from not only BM25, but more advanced sparse retrievers like UniCOIL, highlighting the generality of our approach.</p><p>For future work we plan to explore if a dense retriever can be trained to learn lexical matching directly without relying on a teacher model. This way, we can avoid imitating the errors of the sparse retriever, and devise new ways of training dense retrievers that can potentially surpass hybrid models. Moreover, there are several intriguing findings in this work that may warrant further study, such as why SPAR's R@k improves relatively to the hybrid model as k increases, and why joint training is less effective than post-hoc vector concatenation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Validation MRR of the Wiki ? using various numbers of positive passages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Table 1: ? trained with various data regimes. The MRR is calculated on questions from NQ dev, using one positive and one hard negative from BM25.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Model</cell><cell>MRR</cell></row><row><cell></cell><cell></cell><cell></cell><cell>NQ ?</cell><cell>76.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Wiki ?</cell><cell>92.4</cell></row><row><cell></cell><cell></cell><cell></cell><cell>PAQ ?</cell><cell>94.7</cell></row><row><cell></cell><cell>90 92</cell><cell>89.9</cell><cell>92.0</cell><cell>92.4</cell><cell>92.5</cell></row><row><cell>Validation MRR</cell><cell>84 86 88</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>82</cell><cell>81.1</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>1 2</cell><cell cols="2">5 Number of positive passages 10</cell><cell>15</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>All models are trained on NQ training set and we report the Acc@20 and Acc@100 metrics on the test set, which evaluates whether any of the top 20/100 retrieved passages contain the answer to the input question. We consider two baseline models, DPR (NQ-single) and the hybrid DPR+BM25 model 4 . Because SPAR is built by augmenting DPR with ?, it should perform better than the DPR alone. Moreover, if our dense lexical model is effective, then the final model should perform at least comparable to DPR+BM25.The first method we test is to initialize DPR with the model weights of ? (Initialization) for DPR training, with the hope that DPR can inherit the lexical matching capacity from ?. However, as shown in</figDesc><table /><note>4.2 Building SPAR with ? With a successfully trained dense lexical model ?, we next experiment with various approaches to build a salient-phrase aware retriever with it.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Comparison of various methods of leveraging the Wiki ? in SPAR: used as initialization for DPR training; combining two trained models with weighted vector sum or concatenation; vector concatenation during DPR training (joint training).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Acc@20 and 100 for Open-Domain Question Answering. Model types are shown in parentheses (d: dense, s: sparse, h: hybrid). The highest performance is in bold, and the highest among dense retrievers is underlined.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>TC NF NQ HQ FQ AA T2 Qu CQ DB SD Fe CF SF Avg. BM25 65.6 32.5 32.9 60.3 23.6 31.5 36.7 78.9 29.9 31.3 15.8 75.3 21.3 66.5 43.0 docT5query 71.3 32.8 39.9 58.0 29.1 34.9 34.7 80.2 32.5 33.1 16.2 71.4 20.1 67.5 44.4 ANCE 65.4 23.7 44.6 45.6 29.5 41.5 24.0 85.2 29.6 28.1 12.2 66.9 19.8 50.7 40.5 ColBERT 67.7 30.5 52.4 59.3 31.7 23.3 20.2 85.4 35.0 39.2 14.5 77.1 18.4 67.1 44.4 Contriever</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 :</head><label>5</label><figDesc>Zero-shot results on BEIR<ref type="bibr" target="#b33">(Thakur et al., 2021)</ref>. All SPAR models, including the concatenation weights, are trained / tuned on MS MARCO. SPAR achieves new state of the art with either ?, highlighting the superior out-ofdomain generalization of SPAR.</figDesc><table><row><cell></cell><cell cols="2">Dataset Legend: TC=TREC-COVID, NF=NFCorpus, NQ=NaturalQuestions,</cell></row><row><cell cols="3">HQ=HotpotQA, FQ=FiQA, AA=ArguAna, T2=Touch?-2020, Qu=Quora, CQ=CQADupStack, DB=DBPedia,</cell></row><row><cell cols="3">SD=SCIDOCS, Fe=FEVER, CF=Climate-FEVER, SF=SciFact.</cell></row><row><cell cols="3">BEIR, SPAR (ANCE + UniCOIL ?) can still out-</cell></row><row><cell cols="3">perform all existing models. When adopting a more</cell></row><row><cell cols="3">advanced base retriever, such as Contriever (Izac-</cell></row><row><cell cols="2">ard et al., 2021), 5.3.2 SPAR on EntityQuestions</cell><cell></cell></row><row><cell>Model</cell><cell></cell><cell>EQ</cell></row><row><cell></cell><cell cols="2">@20 @100</cell></row><row><cell>(d) DPR</cell><cell>56.6</cell><cell>70.1</cell></row><row><cell>(s) BM25</cell><cell>70.8</cell><cell>79.2</cell></row><row><cell>(h) DPR + BM25</cell><cell>73.3</cell><cell>82.3</cell></row><row><cell>(d) Wiki ?</cell><cell>68.4</cell><cell>77.5</cell></row><row><cell>(d) PAQ ?</cell><cell>69.4</cell><cell>78.6</cell></row><row><cell>(d) SPAR</cell><cell>73.6</cell><cell>81.5</cell></row><row><cell>(d) SPAR-PAQ</cell><cell>74.0</cell><cell>82.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 6 :</head><label>6</label><figDesc>Zero-shot performance on the EntityQuestions<ref type="bibr" target="#b32">(Sciavolino et al., 2021)</ref> dataset. We report microaverage instead of macro-average in the original paper.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 7 :</head><label>7</label><figDesc>Rank Biased Overlap (RBO,</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 9</head><label>9</label><figDesc></figDesc><table><row><cell>, adding BM25</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 9 :</head><label>9</label><figDesc>The SPAR+BM25 model yields minimal gains over SPAR, indicating that SPAR does well in lexical matching and performs similarly to a hybrid model. to SPAR only results in minimal gains, which indicates that SPAR renders BM25 almost completely redundant and supports our main claim.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The code and models of SPAR are available at https://github.com/facebookresearch/ dpr-scale/tree/main/spar.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">DPR uses BM25 to generate hard negatives.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We implement DPR+BM25 with Pyserini(Lin et al.,  2021a); see ?4.3 for more discussions on hybrid models.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">4 tasks were omitted in our evaluation for license reasons.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">We used the official checkpoint of GTR-large. While it performs similarly to the published numbers on most datasets, there is a substantial gap on a few datasets, such as FEVER, Climate-FEVER and SciFact, for reasons unknown to us.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Ms marco: A human generated machine reading comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Payal</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Xia Song, Alina Stoica, Saurabh Tiwary, and Tong Wang</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Modeling of the question answering task in the yodaqa system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Baudi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="222" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Grant Ingersoll, and Lucid Imagination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrzej</forename><surname>Bia?ecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Muir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SI-GIR 2012 workshop on open source information retrieval</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
	<note>Apache lucene 4</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Context-Aware Term Weighting For First Stage Passage Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3397271.3401204</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1533" to="1536" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">COIL: Revisit exact lexical match in information retrieval with contextualized inverted list</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.241</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3030" to="3042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficiently teaching an effective dense retriever with balanced topic aware sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Hofst?tter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3462891</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="113" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.09118</idno>
		<title level="m">Towards unsupervised dense information retrieval with contrastive learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Billion-scale similarity search with gpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno type="DOI">10.1109/TBDATA.2019.2921572</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="535" to="547" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1147</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Vancouver</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.550</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6769" to="6781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Colbert: Efficient and effective passage search via contextualized late interaction over bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<idno type="DOI">10.1145/3397271.3401075</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;20</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Natural questions: A benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00276</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="452" to="466" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1612</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6086" to="6096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Question and answer test-train overlap in open-domain question answering datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1000" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>K?ttler</surname></persName>
		</author>
		<title level="m">Aleksandra Piktus, Pontus Stenetorp, and Sebastian Riedel. 2021b. Paq: 65 million probably-asked questions and what you can do with them</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A few brief notes on deepimpact, coil, and a conceptual framework for information retrieval techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3463238</idno>
		<title level="m">Ronak Pradeep, and Rodrigo Nogueira. 2021a. Pyserini: A Python Toolkit for Reproducible Information Retrieval Research with Sparse and Dense Representations</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page" from="2356" to="2362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">In-batch negatives for knowledge distillation with tightly-coupled teachers for dense retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jheng-Hong</forename><surname>Sheng-Chieh Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.repl4nlp-1.17</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Workshop on Representation Learning for NLP</title>
		<meeting>the 6th Workshop on Representation Learning for NLP</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="163" to="173" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Challenges in generalization in open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00369</idno>
		<title level="m">Sparse, Dense, and Attentional Representations for Text Retrieval. Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="329" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A replication study of dense passage retriever</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronak</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.05740</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-task retrieval for knowledge-intensive tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gargi</forename><surname>Ghosh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.89</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1098" to="1111" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning passage impacts for inverted indexes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Mallia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Suel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Tonellotto</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3463030</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1723" to="1727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><forename type="middle">Hern?ndez</forename><surname>?brego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><forename type="middle">B</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.07899</idno>
		<title level="m">Large dual encoders are generalizable retrievers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">From doc2query to docTTTTTquery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kushal</forename><surname>Lakhotia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anchit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>and Yashar Mehdad. 2021. Domain-matched pre-training tasks for dense retrieval</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingqi</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiyang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.466</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="5835" to="5847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1264</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The curse of dense low-dimensional information retrieval for large index sizes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-short.77</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="605" to="611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;94</title>
		<meeting><address><addrLine>London; London</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Simple entity-centric questions challenge dense retrievers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Sciavolino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zexuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Beir: A heterogenous benchmark for zero-shot evaluation of information retrieval models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nandan</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>R?ckl?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08663</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Abhishek Srivastava, and Iryna Gurevych</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A similarity measure for indefinite rankings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
		<idno type="DOI">10.1145/1852102.1852106</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Efficient inner product approximation in hybrid spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Simcha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Dopson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Approximate nearest neighbor negative contrastive learning for dense text retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">2021. xMoCo: Cross momentum contrastive learning for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binxing</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.477</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6120" to="6129" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
