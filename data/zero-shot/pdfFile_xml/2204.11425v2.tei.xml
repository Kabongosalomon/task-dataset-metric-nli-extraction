<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BCI: Breast Cancer Immunohistochemical Image Generation through Pyramid Pix2pix</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengjie</forename><surname>Liu</surname></persName>
							<email>shengjie.liu@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Zhu</surname></persName>
							<email>czhu@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Xu</surname></persName>
							<email>drxufeng@mail.ccmu.edu.cnshizhongyue815</email>
							<affiliation key="aff1">
								<orgName type="institution">Capital Medical University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Jia</surname></persName>
							<email>jiaxinyubupt@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Shi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Capital Medical University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mulan</forename><surname>Jin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Capital Medical University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BCI: Breast Cancer Immunohistochemical Image Generation through Pyramid Pix2pix</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Figure 1. Samples of BCI. Top: HE-stained patches. Bottom: IHC-stained patches. Each column represents a HE-IHC image pair. It contains four expression levels of HER2 (0, 1+, 2+, 3+). *Corresponding authors: Chuang Zhu (czhu@bupt.edu.cn), Feng Xu</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The evaluation of human epidermal growth factor receptor 2 (HER2) expression is essential to formulate a precise treatment for breast cancer. The routine evaluation of HER2 is conducted with immunohistochemical techniques (IHC), which is very expensive. Therefore, for the first time, we propose a breast cancer immunohistochemical (BCI) benchmark attempting to synthesize IHC data directly with the paired hematoxylin and eosin (HE) stained images. The dataset contains 4870 registered image pairs, covering a variety of HER2 expression levels.</p><p>Based on BCI, as a minor contribution, we further build a pyramid pix2pix image generation method, which achieves better HE to IHC translation results than the other current popular algorithms. Extensive experiments demonstrate that BCI poses new challenges to the existing image translation research. Besides, BCI also opens the door for future pathology studies in HER2 expression evaluation based on the synthesized IHC images. BCI dataset can be downloaded from https://bupt-ai-cz.github. io/BCI.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>The evaluation of human epidermal growth factor receptor 2 (HER2) expression is essential to formulate a precise treatment for breast cancer. The routine evaluation of HER2 is conducted with immunohistochemical techniques (IHC), which is very expensive. Therefore, for the first time, we propose a breast cancer immunohistochemical (BCI) benchmark attempting to synthesize IHC data directly with the paired hematoxylin and eosin (HE) stained images. The dataset contains 4870 registered image pairs, covering a variety of HER2 expression levels.</p><p>Based on BCI, as a minor contribution, we further build a pyramid pix2pix image generation method, which achieves better HE to IHC translation results than the other current popular algorithms. Extensive experiments demonstrate that BCI poses new challenges to the existing image translation research. Besides, BCI also opens the door for future pathology studies in HER2 expression evaluation based on the synthesized IHC images. BCI dataset can be downloaded from https://bupt-ai-cz.github. io/BCI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>According to work <ref type="bibr" target="#b34">[35]</ref>, breast cancer is a leading cause of death for women. Accurate diagnosis and therapy are key factors to reduce the mortality rate of breast cancer patient <ref type="bibr" target="#b43">[44]</ref>. The histopathological checking is a gold standard to identify breast cancer. To achieve this, the tumor materials are first made into hematoxylin and eosin (HE) stained slices (a slice is shown in <ref type="figure">Fig. 2(a)</ref>). Then, the diagnosis is performed by pathologists through observing the HE slices under the microscope or analyzing the digitized whole slice images (WSI). For diagnosed breast cancer, it is essential to formulate a precise treatment plan by checking the expression of specific proteins, such as human epidermal growth factor receptor 2 (HER2) <ref type="bibr" target="#b15">[16]</ref>. The breast cancer with overexpression of HER2 is prone to have aggressive clinical behaviour, and thus accurate therapy should be formulated accordingly.</p><p>The routine evaluation of HER2 expression is conducted with immunohistochemical techniques (IHC) <ref type="bibr" target="#b10">[11]</ref>. Specifically, one additional IHC-stained slice (a slice is shown in <ref type="figure">Fig. 2(b)</ref>) is first prepared. Then the pathologists will check the IHC-stained slice to obtain the HER2 expression status: IHC 0, no staining is observed or membrane staining that is incomplete and is faint/barely perceptible and in ? 10% of tumor cells ( <ref type="figure">Fig. 3(a)</ref>); IHC 1+, incomplete  membrane staining that is faint/barely perceptible and in &gt;10% of tumor cells ( <ref type="figure">Fig. 3(b)</ref>); IHC 2+, weak to moderate complete membrane staining observed in &gt;10% of tumor cells ( <ref type="figure">Fig. 3(c)</ref>); IHC 3+, circumferential membrane staining that is complete, intense, and in &gt;10% of tumor cells ( <ref type="figure">Fig. 3(d)</ref>) <ref type="bibr" target="#b38">[39]</ref>. The detection of HER2 expression is critical to the formulation of follow-up treatment plans for breast cancer. However, it is very expensive to conduct HER2 evaluation through the additional preparation of IHC-stained slice. Then the question is can we synthesize the IHC-stained image based on HE-stained WSI? In case of success, we can conduct HER2 expression evaluation directly based on the synthesized IHC-stained slices. This paper presents the above challenge for the first time, and tries to solve it through image-to-image translation technique. Image translation aims to learn the mapping between an input source-domain image and an output target-domain image <ref type="bibr" target="#b6">[7]</ref>. In recent years, some methods and datasets have been proposed to promote the research of image-to-image translation.</p><p>Pix2pix <ref type="bibr" target="#b8">[9]</ref> proposes a universal translation method for paired images. Since then, there have been other supervised image translation algorithms based on pix2pix that can be applied to specific scenes: pix2pixHD <ref type="bibr" target="#b35">[36]</ref> has achieved very good results in high resolution paired image translation; work <ref type="bibr" target="#b27">[28]</ref> proposes an enhanced pix2pix optimized for image dehazing. Besides, there are also many excellent methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref> for unsupervised image translation inspired by these pioneering works <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b44">45]</ref>.</p><p>Dataset is the key factor for image translation, especially for supervised methods. Many fields have proposed datasets pertinently. However, there are only a few works for the medical image translation applications. RegGAN <ref type="bibr" target="#b14">[15]</ref> implements a general image translation method for both paired and unpaired images on BraTS <ref type="bibr" target="#b24">[25]</ref> dataset. In the field of breast cancer, a few of datasets such as BCNB <ref type="bibr" target="#b39">[40]</ref> have been proposed for automatic diagnosing, however, there are no datasets for HE to IHC staining for HER2 detection. This task requires structural level aligned datasets, which poses great challenges due to the difficulty of the acquisition of well paired HE-IHC images. To the best of our knowledge, there are no public image translation datasets exists for HER2 detection in breast cancer tissue.</p><p>To spur research in this area, we introduce BCI, a structural aligned dataset for the translation of HE-stained slices to immunohistochemical results ( <ref type="figure">Fig. 1</ref>). We also propose a method optimized for this task. We benchmark several state-of-the-art (SOTA) algorithms for image translation tasks. In summary, this paper makes the following contributions:</p><p>? We collect and build BCI: a paired HE to HER2 expression image translation dataset. To our knowledge, BCI is the first large-scale publicly available dataset for immunohistochemical image generation.</p><p>? We propose a pyramid pix2pix method to generate immunohistochemical image based on HE. Compared with other pix2pix-like methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b35">36]</ref>, our method can constrain the generated image at multiple scales and achieve better results on our BCI dataset.</p><p>? We conduct extensive experiments on BCI and LLVIP dataset <ref type="bibr" target="#b9">[10]</ref> to explore the gains that different scales bring to the model, which demonstrate the flexibility and versatility of multi-scale constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In this section, we will review some image translation algorithms, as well as some datasets that are often used in image translation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Image Translation</head><p>Image translation algorithm establishes a mapping between two domain images. It is often used in image semantic, image synthesis, and image super-resolution, etc. Image  translation algorithms can be divided into unsupervised image translation and supervised image translation.</p><p>Unsupervised image translation does not require aligned datasets, which makes the application range of this method very wide. Many works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b44">45]</ref> are dedicated to the translation of unpaired images. This type of methods can randomly extract images from two domains during training, which can achieve better image style transfer when it is difficult to obtain paired data. In addition to solving the problem of image translation from one domain to another, there are some methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> that creatively solve the image translation between multiple domains.</p><p>However, unsupervised methods also have a certain limitation: for paired datasets, it may not be possible to establish an accurate mapping between the two domains. To overcome this problem, work <ref type="bibr" target="#b40">[41]</ref> adds additional per-patch labels (e.g. background, necrosis, fibrosis, etc.) to Cycle-GAN during training. For the classification of patches, huge amounts of human work are still required. Therefore, supervised image translation methods still have great application value. Pix2pix <ref type="bibr" target="#b8">[9]</ref> is a pioneering supervised image translation algorithm. It is a general image translation algorithm that can be applied to various image translation tasks. In addition to the adversarial loss between the generator and the discriminator, it also calculates the pixel-level difference between the generated image and the ground truth to continuously improve the generator's effect. Pix2pixHD <ref type="bibr" target="#b35">[36]</ref> optimizes the generator structure on the basis of pix2pix to make the generation of high-resolution images better. EPDN <ref type="bibr" target="#b27">[28]</ref> follows the overall structure of pix2pix, which uses a multi-resolution generator, a multi-scale discriminator, and an enhancer for image dehazing tasks. SRGAN <ref type="bibr" target="#b18">[19]</ref> and ESRGAN <ref type="bibr" target="#b36">[37]</ref> apply the generative adversarial network to image super-resolution tasks, which are essentially a kind of image translation. There are also some supervised methods <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b33">34]</ref> that are widely used in semantic image synthesis. These models take semantic information as input and translate it into real images.</p><p>In the medical field, image translation already has some applications. RegGAN <ref type="bibr" target="#b14">[15]</ref> proposes a general image translation model, which adds a U-net structure registration network after the generator in pix2pix. It calculates the loss between the output image of the registration network and the ground truth, which makes RegGAN achieve good results in both paired and unpaired data. In the field of pathological images, there are some works that <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33]</ref> translate non-standard stained sections into standard stained sections, providing new ideas for the normalization of pathological image staining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Datesets</head><p>The datasets used for image translation tasks are abundant, and these datasets can also be divided into two categories: paired and unpaired. Many paired datasets <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b42">43]</ref> can be used for translation between semantic distribution maps and real images; Cityscapes <ref type="bibr" target="#b5">[6]</ref> and Foggy Cityscapes <ref type="bibr" target="#b31">[32]</ref> can be used for image dehazing research; CelebAMask-HQ <ref type="bibr" target="#b19">[20]</ref> and FFHQ-Aging <ref type="bibr" target="#b25">[26]</ref> are two large-scale face datasets, are used in the research of generating face images from segmentation masks. Part of the images in work <ref type="bibr" target="#b16">[17]</ref> can be used for conversion between day and night. LLVIP <ref type="bibr" target="#b9">[10]</ref> contains registered images in two domains of visible light and infrared light, which can be used for translation between visible light images and infrared light images. BraTS <ref type="bibr" target="#b24">[25]</ref> is a dataset in the medical field, in which T1 weighted images and T2 weighted images can be used for the translation of brain MRI images. Selfie2anime <ref type="bibr" target="#b11">[12]</ref> is an unpaired dataset that provides images in two domains, selfies and cartoon characters, which can be used for the research of transforming real pictures into cartoon styles. There are also some multi-domain datasets such as AFHQ <ref type="bibr" target="#b3">[4]</ref> and RaFD <ref type="bibr" target="#b17">[18]</ref>, these datasets can be used for unsupervised image translation and image synthesis in multiple domains. Note that all paired datasets can be used to train unsupervised image translation models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">BCI Dataset</head><p>The application of deep learning in the medical field has attracted more and more attention. There are already some brain image translation datasets to promote research on brain science, however, there is still no relevant data for pathological image translation. Therefore, we propose the BCI dataset, in order to better promote the research of pathological image translation. We hope that BCI can play a positive role in the diagnosis of breast cancer. At the same time, as a benchmark, our dataset can help analyze the advantages and disadvantages of current image translation algorithms.</p><p>Our overall process of building the dataset is shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. Next, we will introduce more details about this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Collection</head><p>The data scanning equipment is Hamamatsu NanoZommer S60, a pathology section scanner with a scanning speed of 60 seconds per slice. The scanning resolution of the equipment is 0.46 ?m per pixel. We scanned more than 600 pathological slices of breast cancer tissues and sorted out the WSI stained with HE and the corresponding immunohistochemical WSI of 319 breast cancer patients. In the image registration process, we filter out WSI pairs that are unable to complete the alignment. Finally, we got 4870 pairs of HE-IHC patches from 51 different WSI image pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Registration</head><p>For a piece of pathological tissue, the doctor will cut two tissue samples from it for HE staining and HER2 detection. Therefore, there will be differences in the morphology of the two pathological samples. Besides, the tissue samples will be stretched or squeezed to a certain extent during slice preparation, which will increase the difference between the samples. In order to make the images of the two domains aligned, we need to perform registration processing on the images. Projection transformation. First, we use the method of human-computer interaction projection transformation to roughly align the WSI pairs. This method requires manually selecting no less than 4 pairs of corresponding points on the two WSIs ( <ref type="figure" target="#fig_4">Fig. 5)</ref>, then through the method of projection mapping, the irregular quadrilateral determined by the four points on the HE WSI is first mapped to a square, and then the square is mapped to the irregular quadrilateral determined by the four points on the IHC WSI. In this process, the HE image is basically aligned with the contour of the corresponding IHC image by translation and rotation, and the resolution of the two images is kept consistent. At this time, there are still some deviations inside the HE and IHC images, and further registration is required.  <ref type="figure">Figure 6</ref>. The process of elastix registration. The roughly aligned HE and IHC images are divided into blocks, and each block is registered separately with elastix. Finally, the registered blocks are re-spliced <ref type="figure">Figure 7</ref>. By overlapping the registration result with the corresponding IHC image, the difference between projection transformation and elastix registration can be seen: projection transformation can only roughly overlap the two images, but cannot achieve detailed registration; after elastix registration, the overlap in details is realized.  Elastix registration. Second, we use the registration toolbox elastix <ref type="bibr" target="#b13">[14]</ref> to perform fine-grained regional non-rigid registration. This process can align the details of the two domain images as much as possible. <ref type="figure">Fig. 7</ref> shows the detailed alignment of elastix registration based on projection transformation. For each WSI, because its resolution is too high (about 20,000 pixels on a side), the computational power and time consumed by direct registration are huge, in order to improve the efficiency of registration, we divide it into 16 blocks for registration respectively. At the same time, since elastix cannot directly process the RGB image, we split the image and use only a single channel for registration, save the transformation file of the channel, and then apply the transformation file to the other two channels. Finally, we merge the registered images of the three channels and then stitch each registered block into WSI. The registration process of elastix is shown in <ref type="figure">Fig. 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Post-processing</head><p>Our block registration method is efficient, however, during the registration process, the expansion and contraction of the image will leave a gap on the edge of each image block. Therefore, we need to remove the black border be-tween the blocks and fill it with the surrounding content. Finally, the registered WSI image is cut into 1024?1024 size patches. Finally, we will filter out blank and not wellaligned areas.</p><p>Our BCI dataset contains 4870 pairs of pediatric pathological image patches with a resolution of 1024?1024. These patches are from the WSIs of 51 patients. The immunohistochemical results of these 51 patients included four categories: 0, 1+, 2+, and 3+. <ref type="figure" target="#fig_7">Fig. 8</ref> shows the distribution of the 51 WSIs and the number of patches from different IHC results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Proposed Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Architecture</head><p>Our BCI dataset presents a new challenge for image translation. In our dataset, the images of the two domains are paired and registered at the structural level. However, due to the existence of image differences between the two domains, some positions cannot achieve pixel-level alignment, which makes the existing pix2pix series of algorithms difficult to work; at the same time, we need to perform targeted output for each HE stained image, which is not the strength of the unsupervised algorithms. Therefore, we propose a pyramid pix2pix model suitable for structural aligned data. Our overall framework is shown in <ref type="figure">Fig. 9</ref>.</p><p>The L 1 loss in pix2pix algorithm directly calculates the difference between the generated image and the ground truth, which is too restrictive on the generated image. For our BCI dataset, we need to weaken the constraints of L 1 loss, while aligning the generated image and ground truth at other scales. Inspired by scale-space theory <ref type="bibr" target="#b23">[24]</ref>, we will perform the same scale transformation on the generated image and ground truth. The scale transformation consists of two steps: 1) Using a low-pass filter to smooth the image. 2) Downsampling the smooth image. Since the Gaussian kernel is the only linear kernel that realizes the image scale transformation, our low-pass filter uniformly uses the Gaussian kernel with a standard deviation of 1. With the progress of Gaussian filtering, the image becomes more and more blurred, and we reduce the resolution by downsampling to remove redundant pixels. For each resolution level (octave), multiple Gaussian convolutions are performed to achieve scale transformation. Our pix2pix pyramid has several octaves, the first layer of each octave is obtained by downsampling the last image of the previous octave; each octave has 5 layers and performs 4 Gaussian blurrings. For each output of octave, we define it as a scale <ref type="figure">(Fig. 10)</ref>. In our Gaussian Pyramid, we extract the first layer of images in each octave to calculate the loss. The loss for each scale is denoted as S i (i = 1, 2, 3 ? ? ? ): where F i and G represent the Gaussian filtering operation and the generator, respectively. x, y and z represent the input image, the ground truth, and random noise, respectively. Even if we cannot make the generated image highly consistent with the ground truth in the first octave, we can still make the generated image close to the ground truth on a higher-dimensional scale. Our multi-scale loss is recorded as:</p><formula xml:id="formula_0">S i = E x,y,z [?F i (y) ? F i (G(x, z))? 1 ],<label>(1)</label></formula><formula xml:id="formula_1">L multi?scale = i ? i S i ,<label>(2)</label></formula><p>where ? i represents the weight of scale i. Our adversarial loss is still consistent with pix2pix:</p><formula xml:id="formula_2">L cGAN (G, D) =E x,y [logD(x, y)]+ E x,z [log(1 ? D(x, G(x, z)))],<label>(3)</label></formula><p>where generator G tries to minimize this function while discriminator D tries to maximize it. We still keep the L 1 loss in pix2pix in order to maintain the constraints on the original resolution:</p><formula xml:id="formula_3">L 1 = E x,y,z [?y ? G(x, z)? 1 ].<label>(4)</label></formula><p>At this point, our overall objective function is:</p><formula xml:id="formula_4">G * = arg min G max D L cGAN (G, D) + ? 1 L 1 + L multi?scale .<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section, we will use several image translation algorithms to conduct experiments on our BCI dataset. Our experiment was performed on NVIDIA Tesla T4 16GB GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Implementation</head><p>In the pix2pix algorithm, we tried two generator structures, unet256 and resnet-9blocks. Through experiments, we found that resnet-9blocks obviously has a better generation effect. Therefore, in our proposed method, we use the generator structure of resnet-9blocks as the baseline, while the discriminator structure uses the default patchGAN; the Gaussian kernel used is 3?3 with a standard deviation of 1; the input images are not preprocessed; the batch size is set to 2; the optimizer used is Adam; the total number of training epochs is set to 100: the learning rate of first 50 epochs is set to 0.0002 and the learning rate of the remaining 50 epochs gradually drops to 0. In pix2pixHD, both the generator and the discriminator adopt the default settings, and the image preprocessing, the number of training epochs and the optimization strategy are consistent with those of pix2pix. In the cycleGAN algorithm, due to memory limitations, we randomly crop the image to 512?512 resolution before training, and other settings are also consistent with pix2pix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Metrics</head><p>We use Peak Signal to Noise Ratio (PSNR) and Structural Similarity (SSIM) as the evaluation indicators for the quality of the generated image. PSNR is based on the error between the corresponding pixels of two images and is the most widely used objective evaluation index. However, the evaluation result of PSNR may be different from the evaluation result of the Human Visual System (HVS). Therefore, we also use SSIM <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b37">38]</ref>, which comprehensively measures the differences in image brightness, contrast, and structure. This evaluation result is closer to the human visual system. For the unsupervised method, we choose the most representative cycleGAN. It can be seen from the experimental results ( <ref type="figure">Fig. 11</ref> and <ref type="table">Table 1</ref>) that as an unsupervised image translation algorithm, cycleGAN cannot establish an accurate mapping from HE to IHC results. For these registered image pairs, it can only achieve "style" migration, but it is completely impossible to identify the cancer areas. As a representative algorithm of supervised image translation, pix2pix with a resnet generator can basically stain the cancerous area. Its PSNR and SSIM indicators are significantly higher than cycleGAN, but the quality of the generated image is poor, pix2pix with unet generator is even worse. Besides, the staining effect of pix2pix generated images is quite different from the correct results of IHC, especially in the areas where HER2 is highly expressed. Pix2pixHD uses a two-stage generator structure and performs adversarial discriminating on multiple scales. Its high-resolution image generation quality is slightly better than pix2pix on the whole, therefore, it has higher PSNR and SSIM than pix2pix. However, in some areas with low HER2 expression, pix2pixHD may incorrectly generate dark browns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Benchmark Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>The result of our method is better than pix2pix and pix2pixHD in terms of authenticity. In the identification of HER2 expression, our method is better in the case of low expression of HER2 (0/1+), the difference between the generated image and ground truth is slight ( <ref type="figure">Fig. 11(a)(b)</ref>); when the expression level of HER2 is 2+, the image we generate will be lighter than ground truth, but the effect is still better than other methods ( <ref type="figure">Fig. 11(c)</ref>); when HER2 is highly expressed (3+), our method is the same as other methods, unable to identify areas of high expression of HER2 ( <ref type="figure">Fig. 11(d)</ref>), which is also a major issue that needs to be resolved in the future. It is still very challenging to establish an accurate mapping from HE to HER2 expression on our dataset. We still need to explore more effective methods to improve the accuracy of the translation.</p><p>On the LLVIP 1 dataset, our method also achieves the best PSNR and SSIM <ref type="table">(Table 2)</ref>, which proves that our method is not only suitable for the translation of pathological images but also has a certain versatility. Our pyramid pix2pix has the flexibility to change the number of pyramid layers to accommodate different datasets. On our BCI dataset, we tried the gains of different pyramid levels.  <ref type="figure">Figure 11</ref>. Visualization of different methods on different HER2 expressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Multi-scale Analysis</head><p>highest PSNR and SSIM, which demonstrates that it is more reasonable to constrain the generated images and ground truth on the second scale. By optimizing the loss function of scale two (S1), the model effect can be greatly improved. On LLVIP dataset, a four-layer pyramid pix2pix can achieve the approximate effect of a two-layer model ( <ref type="table" target="#tab_1">Table 4</ref>), which shows that the constraint of the high level also improves the generation effect compared to pix2pix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Subjective Validation</head><p>In addition to objective metrics, we also invited two pathologists to diagnose HER2 expression of the generated images. To avoid the influence of subjective factors, we randomly selected 40 real-generated IHC pairs, and shuffled the order of these 80 images. A generated IHC image is considered accurate if the generated image and its corresponding real image are diagnosed at the same level. The accuracy of these 40 generated images is shown in <ref type="table">Table 5</ref>. The results show that there is still a long way to go for current methods before clinical application, which also proves the importance of the BCI dataset in further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we propose BCI, a new dataset in the field of pathology images for the translation of HE stained breast tissue section to its IHC results. This task puts forward pathologist1 pathologist2 Accuracy(%) 37.5 40.0 <ref type="table">Table 5</ref>. Accuracy of generated IHC images.</p><p>new requirements for image translation algorithms, which is to accurately identify the expression area and expression level of HER2 while ensuring the authenticity of the generated image. In addition, we also propose pyramid pix2pix, an image-to-image translation model suitable for registered image pairs. It is still very challenging to establish an accurate mapping from HE to IHC results. There is still a need for more effective methods to improve the accuracy of the translation. In addition, in the future, we will explore the difference in HER2 evaluation between synthetic IHC images and real IHC images. Then we will further study the possibility of formulating accurate clinical treatment plans for breast cancer using synthetic IHC images.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) An example of HE slice. (b) An example of IHC slice.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Visualization of HE-stained and IHC-stained slices. Visualization of four kinds of HER2 expressions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>The establishment of our BCI dataset is generally divided into three steps: 1) breast tissue collection and slice preparation; 2) registration of images in the two domains; 3) post-processing including image refinement and patches cutting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Projection transformation by manually selecting corresponding points. The HE image can be initially aligned with the IHC image after a two-step projection transformation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Image statistics of IHC results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .Figure 10 .</head><label>910</label><figDesc>The framework of the proposed pyramid pix2pix. The image of each scale is obtained from the image of the previous scale after four Gaussian convolutions and one downsampling. Visualization of a sample image at different scales. Gaussian convolution makes the image gradually blurred.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 .</head><label>4</label><figDesc>Multi-scale analysis on LLVIP dataset.</figDesc><table><row><cell>Configuration</cell><cell cols="2">PSNR(dB) SSIM</cell></row><row><cell>pix2pix</cell><cell>19.328</cell><cell>0.440</cell></row><row><cell>pix2pix+S1 (ours)</cell><cell>21.160</cell><cell>0.477</cell></row><row><cell>pix2pix+S1+S2 (ours)</cell><cell>21.033</cell><cell>0.469</cell></row><row><cell>pix2pix+S1+S2+S3 (ours)</cell><cell>21.138</cell><cell>0.472</cell></row><row><cell cols="3">Table 3. Multi-scale analysis on BCI dataset.</cell></row><row><cell>Configuration</cell><cell cols="2">PSNR(dB) SSIM</cell></row><row><cell>pix2pix</cell><cell>12.082</cell><cell>0.207</cell></row><row><cell>pix2pix+S1 (ours)</cell><cell>12.189</cell><cell>0.279</cell></row><row><cell>pix2pix+S1+S2 (ours)</cell><cell>12.173</cell><cell>0.277</cell></row><row><cell>pix2pix+S1+S2+S3 (ours)</cell><cell>12.191</cell><cell>0.278</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>shows that the model with a two-layer pyramid structure (pix2pix+S1) achieves the Visualization of different methods on IHC 0 images. The image we generated is very close to the ground truth. Visualization of different methods on IHC 1+ images. The image we generated is very close to the ground truth. Visualization of different methods on IHC 2+ images. In general, our generated image has a lighter color than ground truth, however, it is still better than other methods. Visualization of different methods on IHC 3+ images. In this case, all methods are difficult to accurately identify the cancer area, which is a huge challenge.</figDesc><table><row><cell>HE (a) HE cycleGAN pix2pix (unet) pix2pix (resnet) pix2pixHD ours Ground truth (b) HE cycleGAN pix2pix (unet) pix2pix (resnet) pix2pixHD ours Ground truth (c) HE (d)</cell><cell>cycleGAN cycleGAN</cell><cell>pix2pix (unet) pix2pix (unet)</cell><cell>pix2pix (resnet) pix2pix (resnet)</cell><cell>pix2pixHD pix2pixHD</cell><cell>ours ours</cell><cell>Ground truth Ground truth</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Visit the link https://bupt-ai-cz.github.io/LLVIP for details of the LLVIP dataset</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was supported in part by the National Natural Science Foundation of China under Grant 62176167, and in part by the BUPT innovation and entrepreneurship support program under Grant 2022-YC-T046.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cocostuff: Thing and stuff classes in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1209" to="1218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyungjoo</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungbin</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunho</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunseok</forename><surname>Min</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.08543</idno>
		<title level="m">Neural stain-style transfer learning using gan for histopathological images</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stargan: Unified generative adversarial networks for multi-domain image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjey</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minje</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8789" to="8797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stargan v2: Diverse image synthesis for multiple domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjey</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjung</forename><surname>Uh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaejun</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Gans n&apos;roses: Stable, controllable, diverse image to image translation (works for videos too!)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><forename type="middle">Jin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Forsyth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.06561</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Multimodal image-to-image translation via a single generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihua</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.01681</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multimodal unsupervised image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Llvip: A visible-infrared paired dataset for low-light vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minzhen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenli</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automated segmentation of cell membranes to evaluate her2 status in whole slide images using a modified deep learning network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salar</forename><surname>Fariba Damband Khameneh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kamasak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in biology and medicine</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="164" to="174" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">U-gat-it: Unsupervised generative attentional networks with adaptive layer-instance normalization for image-toimage translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junho</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonwoo</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwanghee</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.10830</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to discover cross-domain relations with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taeksoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moonsu</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunsoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Elastix: a toolbox for intensity-based medical image registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Staring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keelin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pluim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="196" to="205" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Breaking the dilemma of medical image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingke</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Detian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenjiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanle</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qichao</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.06465</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Detection of her2 from haematoxylin-eosin slides through a cascade of deep learning classifiers via multi-instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ant?nio</forename><surname>David La Barbera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Pol?nia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Roitero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzo</forename><forename type="middle">Della</forename><surname>Conde-Sousa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Imaging</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">82</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Transient attributes for high-level understanding and editing of outdoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Yves</forename><surname>Laffont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhile</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Presentation and validation of the radboud faces database. Cognition and emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Langner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Dotsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gijsbert</forename><surname>Bijlstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Skyler</forename><forename type="middle">T</forename><surname>Wigboldus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hawk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Knippenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Photorealistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Maskgan: Towards diverse and interactive facial image manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Cheng-Han Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingyun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5549" to="5558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Drit++: Diverse image-to-image translation via disentangled representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ding</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maneesh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unsupervised image-to-image translation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Object recognition from local scale-invariant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh IEEE international conference on computer vision</title>
		<meeting>the seventh IEEE international conference on computer vision</meeting>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distinctive image features from scaleinvariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The multimodal brain tumor image segmentation benchmark (brats)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andras</forename><surname>Bjoern H Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Jakab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayashree</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyvan</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Farahani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliya</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicole</forename><surname>Burren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Porz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Slotboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wiest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ohad Fried, Eli Shechtman, and Ira Kemelmacher-Shlizerman. Lifespan age transformation synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Or-El</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumyadip</forename><surname>Sengupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="739" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semantic image synthesis with spatially-adaptive normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Chun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2337" to="2346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Enhanced pix2pix dehazing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyun</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingying</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Spatial pattern templates for recognition of objects with regular structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyle?ek</forename><surname>Radim??ra Radim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GCPR</title>
		<meeting>GCPR<address><addrLine>Saarbrucken, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Stephan R Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="102" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio M</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3234" to="3243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Semantic foggy scene understanding with synthetic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="973" to="992" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Staingan: Stain style transfer for digital histological images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>M Tarek Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shadi</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Albarqouni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ieee 16th international symposium on biomedical imaging</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="953" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">You only need adversarial supervision for semantic image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vadim</forename><surname>Sushko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgar</forename><surname>Sch?nfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Khoreva</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.04781,2020.3</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Global cancer in women: burden and trends</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farhad</forename><surname>Lindsey A Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">L</forename><surname>Islami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><forename type="middle">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmedin</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jemal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Epidemiology and Prevention Biomarkers</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="444" to="457" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">High-resolution image synthesis and semantic manipulation with conditional gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Chun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Esrgan: Enhanced super-resolution generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV) workshops</title>
		<meeting>the European conference on computer vision (ECCV) workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hamid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eero P</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Human epidermal growth factor receptor 2 testing in breast cancer: American society of clinical oncology/college of american pathologists clinical practice guideline focused update. Archives of pathology &amp; laboratory medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Antonio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><forename type="middle">Hale</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimberly</forename><forename type="middle">H</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brittany</forename><forename type="middle">E</forename><surname>Allison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><forename type="middle">B</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mangu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bilous</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wedad</forename><surname>Fitzgibbons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hanna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page" from="1364" to="1382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Predicting axillary lymph node metastasis in early breast cancer using deep learning on primary tumor biopsy slides</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongchuan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mulan</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Oncology</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">4133</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Gan-based virtual re-staining: a promising solution for whole slide image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">Fern?ndez</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B?la</forename><surname>Boz?ky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianni</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04059</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dualgan: Unsupervised dual learning for image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zili</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minglun</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Scene parsing through ade20k dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adela</forename><surname>Barriuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="633" to="641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Breast cancer histopathology image classification through assembling multiple compact cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangzhou</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihui</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC medical informatics and decision making</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
