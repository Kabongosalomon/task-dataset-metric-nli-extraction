<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning with Neighbor Consistency for Noisy Labels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Valmadre</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AIML</orgName>
								<orgName type="institution" key="instit2">University of Adelaide</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning with Neighbor Consistency for Noisy Labels</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advances in deep learning have relied on large, labelled datasets to train high-capacity models. However, collecting large datasets in a time-and cost-efficient manner often results in label noise. We present a method for learning from noisy labels that leverages similarities between training examples in feature space, encouraging the prediction of each example to be similar to its nearest neighbours. Compared to training algorithms that use multiple models or distinct stages, our approach takes the form of a simple, additional regularization term. It can be interpreted as an inductive version of the classical, transductive label propagation algorithm. We thoroughly evaluate our method on datasets evaluating both synthetic (CIFAR-10, CIFAR-100) and realistic (mini-WebVision, WebVision, Clothing1M, mini-ImageNet-Red) noise, and achieve competitive or state-of-the-art accuracies across all of them. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>While deep learning can achieve unprecedented accuracy in image classification tasks, it requires a large, supervised dataset that is often expensive to obtain. Unsupervised and semi-supervised learning seek to alleviate this requirement by incorporating unlabelled examples. However, these approaches cannot take advantage of the various sources of noisy labels in the modern world, such as images with hashtags in social media or images contained in webpages retrieved by a textual query. Training algorithms that are robust to label noise are therefore highly attractive for deep learning.</p><p>The dominant approach to learning with noisy labels in recent work is to use the predictions of the model itself to reject or modify training examples (e.g. <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b46">47]</ref>). This is inherently risky due to the ability of deep networks to fit arbitrary labels <ref type="bibr" target="#b47">[48]</ref> and it is important to take significant measures against overfitting. More-over, this paradigm often leads to complicated training procedures, such as maintaining multiple models or alternating between updating the model and updating the training set.</p><p>This paper proposes Neighbor Consistency Regularization (NCR) for the specific problem of learning with noisy labels, illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. Rather than adopting model predictions as pseudo-labels, NCR introduces an additional consistency loss that encourages each example to have similar predictions to its neighbors. Concretely, the neighbor consistency loss penalizes the divergence of each example's prediction from a weighted combination of its neighbors' predictions, with the weights determined by their similarity in feature space. The motivation of NCR is to enable incorrect labels to be improved or at least attenuated by the labels of their neighbors, relying on the assumption that the noise is sufficiently weak or unstructured so as not to overwhelm the correct labels. Compared to the popular approach of bootstrapping the model predictions <ref type="bibr" target="#b33">[34]</ref>, NCR can be seen as instead bootstrapping the learned feature representation, which may reduce its susceptibility to overfitting and improve its stability at random initialization.</p><p>NCR is inspired by label propagation algorithms for semi-supervised learning <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b49">50]</ref>, which seek to transfer labels from supervised examples to neighboring unsupervised examples according to their similarity in feature space. However, whereas label propagation is typically performed in a batch setting over the entire dataset, our method effectively performs label propagation online within minibatches during stochastic gradient descent. This results in a simple, single-stage training procedure. Moreover, whereas existing methods for label propagation represent transductive learning in that they only produce labels for the specific examples which are provided during training, NCR can be understood as an inductive form of label propagation in that it produces a model which can later be applied to classify unseen examples.</p><p>The key contributions of the paper are as follows.</p><p>? We propose Neighbor Consistency Regularization, a novel loss term for deep learning with noisy labels that encourages examples with similar feature representations to have similar predictions.</p><p>? We verify empirically that NCR achieves better accu-arXiv:2202.02200v2 [cs.CV] 6 Jul 2022 racy than several important baselines at a wide range of noise levels from both synthetic and real distributions, and is complementary to the popular regularization technique of mixup <ref type="bibr" target="#b48">[49]</ref>.</p><p>? We demonstrate that NCR achieves competitive or state-of-the-art accuracies on datasets evaluating both synthetic (CIFAR-10 and CIFAR-100) and realistic (mini-WebVision <ref type="bibr" target="#b22">[23]</ref>, mini-ImageNet-Red <ref type="bibr" target="#b18">[19]</ref>, Clothing1M <ref type="bibr" target="#b43">[44]</ref>) noise scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>This section reviews related work with a focus on image classification using deep learning and draws comparisons to our proposed approach. Note that, while there is a significant body of work examining the problem of noisy labels under the assumption that a small, trusted set of clean examples is available, this paper considers the variant where this is not the case.</p><p>Regularization. Regularization has an integral role under label noise as it limits the ability of a high-capacity model to fit arbitrary labels. Indeed, regularization alone can provide considerable robustness to label noise and many algorithms couple an effective regularization strategy with an explicit noise-handling technique to further robustness. One particularly effective form of regularization is mixup augmentation <ref type="bibr" target="#b48">[49]</ref>, which generates additional examples by linearly interpolating between pairs of examples in both the image and label space. It was originally demonstrated to provide robustness to synthetic label corruption on CIFAR-10.</p><p>Beyond the choice of regularization, there are numerous possible approaches to handle noisy labels. Early investigation into deep learning with label noise concentrated on either estimation of the label transition matrix <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b35">36]</ref> or loss functions that are robust to outliers <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b45">46]</ref>. More recently, numerous methods have been proposed that reweight or re-label the examples that are believed to have incorrect labels. We briefly review this body of work in the following paragraphs. Model predictions for noisy labels. Many methods have used the predictions of the model itself during training to either generate pseudo-labels or to identify incorrect examples (or both). For deep learning, this often leverages the phenomenon that correct labels tend to be approximated earlier than incorrect ones <ref type="bibr" target="#b26">[27]</ref>. Reed et al. <ref type="bibr" target="#b33">[34]</ref> first proposed the bootstrapping loss, in which a fixed linear combination of the annotated label and the current prediction are adopted as the regression target for each example. Our method can be considered a bootstrapping approach which uses the learned similarity rather than the actual predictions. Extensions of <ref type="bibr" target="#b33">[34]</ref> include setting the proportion of annotated and predicted labels adaptively using the model confidence <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b46">47]</ref> and averaging model weights and predictions over time <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b29">30]</ref>. Lukasik et al. <ref type="bibr" target="#b28">[29]</ref> showed that some robustness to noise could be obtained by label smoothing, which instead interpolates between the annotated label and a uniform distribution. To avoid overfitting, several works have proposed to split the training set in half and train two models, with each used to assess the training examples of the other <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>Identifying noisy examples using neighbors. Whereas our method, in effect, uses neighbors to modify the supervision of each example, several approaches have rather used neighbors with the aim of identifying and eliminating noisy examples. Both <ref type="bibr" target="#b41">[42]</ref> and <ref type="bibr" target="#b11">[12]</ref> proposed to identify and reweight examples with incorrect labels using the local density of examples with the same annotation. Wu et al. <ref type="bibr" target="#b42">[43]</ref> constructed a k-NN graph and kept only the examples which constituted the core of the largest connected component per class. Bahri et al. <ref type="bibr" target="#b1">[2]</ref> eliminated examples whose labels did not agree with the prediction of a k-NN classifier. Multi-Objective Interpolation Training (MOIT) <ref type="bibr" target="#b30">[31]</ref> identifies mislabelled examples by comparing the predictions of each example to the average prediction of its neighbors and then replaces the least reliable labels with the model's current predictions. MOIT+ incorporates an additional stage of semi-supervised learning, in which the labels assumed to be noisy, are discarded. Label propagation. Variants of label propagation <ref type="bibr" target="#b49">[50]</ref> have been applied to various computer vision tasks, including retrieval <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18]</ref>, semi-supervised learning <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b19">20]</ref> and fewshot learning <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b34">35]</ref>. For semi-supervised learning in particular, <ref type="bibr" target="#b15">[16]</ref> used it to obtain labels for unsupervised examples based on their neighbors in feature space. While most methods perform label propagation over large graphs containing many examples in a batch fashion, <ref type="bibr" target="#b27">[28]</ref> and <ref type="bibr" target="#b34">[35]</ref> considered label propagation within stochastic gradient descent for episodic few-shot learning <ref type="bibr" target="#b39">[40]</ref>. This is a metalearning approach which seeks a suitable feature representation with which to later perform label propagation during meta-testing. It is not directly applicable for learning with noisy labels and it does not scale to large sets of examples.</p><p>For learning with noisy labels, although neighbors have often been used to identify mislabelled examples (see above), few works have considered the use of neighbors to generate pseudo-labels. Iscen et al. <ref type="bibr" target="#b16">[17]</ref> used graph convolution to propagate labels from a small set of examples with trusted labels to a large set of examples with noisy labels. By comparison, our approach does not require a clean set and is inductive in nature. Perhaps the most similar method to our own is that of <ref type="bibr" target="#b46">[47]</ref>, in which graph filtering is applied once to the global graph of all examples to refine the predictions of an initial model. In contrast, our consistency loss encourages similar examples to have similar labels throughout training and is much simpler to implement. Consistency. The idea of constraining a network to pro- duce consistent outputs as a way to leverage unlabelled data has appeared in several previous works. ICT <ref type="bibr" target="#b38">[39]</ref> and Mixmatch <ref type="bibr" target="#b2">[3]</ref> proposed variants of mixup for semi-supervised learning in which predictions replace the labels for unsupervised examples. Xie et al. <ref type="bibr" target="#b44">[45]</ref> introduced Unsupervised Data Augmentation for semi-supervised image classification, where a model is encouraged to be robust to labelpreserving transformations even when labels are not available by minimizing the divergence between predictions for transformed and non-transformed images. Most relevant to our work, <ref type="bibr" target="#b9">[10]</ref> used prediction consistency with respect to image transformations for the express purpose of learning with noisy labels. While these forms of consistency are effective regularizers, neighbor consistency offers the ability to transfer supervision directly to mislabelled examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries</head><p>We first define our notation and formulate the task of learning with noisy labels. We then describe label propagation, a graph-based semi-supervised learning method designed to work with closed datasets. Problem formulation. We assume a dataset defined by X := {x 1 , . . . , x n }. Each example, e.g. an image, x i , has a corresponding true label? i ? C. In our task, some of the labels, y i , are noisy: y i =? i and do not correctly reflect the visual content of the example x i . During training, we do not know whether y i is noisy (y i =? i ) or clean (y i =? i ). Our goal is to learn a model with the highest accuracy on the true labels,?, although an unknown number of labels in our training set are noisy.</p><p>We learn a convolutional neural network for classification. The network, denoted by f ?,W : X ? R c , takes a dataset example x i as the input and outputs logits for softmax classification. Its two learnable variables ? and W correspond to the feature extractor and classifier, respectively. The feature extractor maps an image</p><formula xml:id="formula_0">x i to a d-dimensional vector v i := g ? (x i ) ? R d . The classifier maps the d- dimensional vector to class scores z i := h W (v i ) ? R c .</formula><p>Typically, the network parameters are learned by minimizing a loss function for supervised classification:</p><formula xml:id="formula_1">L S (X, Y ; ?, W ) := 1 m m i=1 (?(z i ), y i ) ,<label>(1)</label></formula><p>where X and Y correspond to the set of examples in the mini-batch, m = |X| = |Y | denotes the size of the minibatch, ? is the softmax function and (q, p) is the crossentropy loss function for predictions q. When the target distribution p is a single label y ? C, we adopt the shorthand (q, y) = (q, ? y ) for cross-entropy with a one-hot vector ? y .</p><p>Label propagation is a graph-based technique used in semi-supervised learning <ref type="bibr" target="#b49">[50]</ref>. We assume that we are given labeled and unlabeled examples in a dataset, and that the dataset is also defined by a graph which is either given or created from the k-NN of each example <ref type="bibr" target="#b7">[8]</ref>. This method spreads the label information of each node to the other nodes based on the connectivity in the graph. This process is repeated until a global equilibrium state is achieved. Finally, unlabeled examples are assigned to the class from which they have received the most information. Formally, for a graph of dataset X, represented by an affinity matrix W , where W ij = similarity(x i , x j ), Zhou et al. <ref type="bibr" target="#b49">[50]</ref> show that label propagation can be computed by minimizing</p><formula xml:id="formula_2">Q(P ) = 1 2 ? n i=1 P i ? Y i 2 + 1 2 n i,j=1 W ij 1 ? D ii P i ? 1 D jj P j 2 ,<label>(2)</label></formula><p>where D is the degree matrix (a diagonal matrix with entries D ii = j W ij ), P ? R n?c is the matrix of classification predictions, Y ? R n?c is the matrix of one-hot labels for all examples and ? is a regularization parameter. This objective function comprises two terms: a fitting constraint, which encourages the classification of each point to their assigned label, and a smoothing term, which encourages the outputs of nearby points in the graph to be similar. One of the main limitations of label propagation is its transductive property. In transductive learning, the goal is to classify seen unlabeled examples. This is different to inductive learning, which learns a generic classifier to classify any unseen data. To apply label propagation on new test examples, a new graph W needs to be constructed each time a test example is seen. This makes it inefficient in practice.</p><p>Another requirement for label propagation is that the feature space needs to be fixed to compute the affinity matrix W . This requires the feature extractor to be learned beforehand, potentially from the noisy data. Existing work <ref type="bibr" target="#b15">[16]</ref> has tried to overcome this issue by alternating between optimizing the feature space, and performing label propagation. However, this does not directly enforce smoothness, as the optimization of two components are done separately.</p><p>Our goal is to overcome the limitations of label propagation by 1) adapting it to an inductive setting 2) applying the smoothness constraint directly during optimization. In Section 4, we propose a simple and efficient approach which generalizes label propagation by enforcing smoothness in the form of a regularizer. As a result, we avoid constructing an explicit graph to propagate the information, and inference can be performed on any unseen test example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method</head><p>We now present our method Neighbor Consistency Regularization and compare it to classical label propagation. We then highlight its relationship to similar, online techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Neighbor Consistency Regularization</head><p>When learning with noisy labels, the network is prone to overfit, or memorize, the mapping from x i to a noisy label y i for the training data <ref type="bibr" target="#b26">[27]</ref>. This behavior typically results in a non-optimal classification performance in a clean evaluation set, as the network does not generalize well.</p><p>To overcome this issue, we propose Neighbor Consistency Regularization (NCR). Our main assumption is that the over-fitting occurs less dramatically before the classifier h W . This is supported by MOIT <ref type="bibr" target="#b30">[31]</ref>, which shows that feature representations are robust enough to discriminate between noisy and clean examples when training a network. With that assumption, we can design a smoothness constraint similar to label propagation (2) when training the network. The overview of our method is shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>Let us define the similarity between two examples by the cosine similarity of their feature representations, i.e.</p><formula xml:id="formula_3">s i,j = cos(v i , v j ) = v T i v j /( v i v j ).</formula><p>Note that the feature representations contain non-negative values when obtained after a ReLU non-linearity, and therefore the cosine similarity is bounded in the interval [0, 1]. Our goal is to enforce neighbor consistency regularization by leveraging the structure of the feature space produced by g ? to enhance the classifier h W . More specifically, h W (v i ) and h W (v j ) should behave similarly if s i,j is high, regardless of their labels y i and y j . This would prevent the network from overfitting to an incorrect mapping between an example x i and a label y i , if either (or both) y i and y j are noisy.</p><p>To enforce NCR, we design an objective function which minimizes the distance between logits z i and z j , if the corresponding feature representations v i and v j are similar:</p><formula xml:id="formula_4">L NCR (X, Y ; ?, W ) := 1 m m i=1 D KL ?(z i /T ) j?NN k (vi) s i,j k s i,k ? ?(z j /T ) ,<label>(3)</label></formula><p>where D KL is the KL-divergence loss to measure the difference between two distributions, T is the temperature and NN k (v i ) denotes the set of k nearest neighbors of i in the feature space. We set T = 2 throughout our experiments. We normalize the similarity values so that the second term of the KL-divergence loss remains a probability distribution. We set the self-similarity s i,i = 0 so that it does not dominate the normalized similarity. Gradients will be backpropagated to all inputs.</p><p>The objective (3) ensures that the output of x i will be consistent with the output of its neighbors regardless of its potentially noisy label y i . We combine it with the supervised classification loss function (1) to obtain the final objective to minimized during the training:</p><formula xml:id="formula_5">L(X, Y ; ?, W ) := (1 ? ?) ? L S (X, Y ; ?, W ) + ? ? L NCR (X, Y ; ?, W ),<label>(4)</label></formula><p>where the hyper-parameter ? ? [0, 1] controls the impact of the each loss term. Similar to label propagation, the final loss objective (4) has two terms. The first term is the classification loss term L S . This is analogous to the fitting constraint in <ref type="bibr" target="#b1">(2)</ref>. The second term is the NCR loss L NCR , which is also similar to the smoothness constraint in <ref type="bibr" target="#b1">(2)</ref>. We find that it sometimes helps to train the network with ? = 0 for several epochs (denoted by e in our experiments) before enabling the NCR term. However, the main difference between label propagation and our method is that label propagation applies smoothness based on the graph edges W ij computed over the entire dataset. On the other hand, our method is online, and does not require a global graph W . We enforce the NCR through the local neighborhood as the feature space is being learned. As a result, our method does not require a learned feature representation with noisy examples. It enriches the learned feature representation by reducing the negative impact of noisy examples.</p><p>Compared to standard training, NCR incurs an additional computational cost of order O(m 2 (d + c)) where m is the batch size, d is the feature dimension and c is the number of classes. This arises in the computation of the similarity values and weighted predictions in (3). However, this operation is relatively fast to compute for moderate values of m because it is a dense matrix multiplication, for which modern GPUs are optimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Relation to other methods</head><p>Bootstrapping introduces an additional loss that adopts the model's own predictions as labels <ref type="bibr" target="#b33">[34]</ref>. Its motivation is to discourage the model from overfitting to examples which are difficult to fit. The overall loss combines the supervised loss and the bootstrap loss in fixed proportion:</p><formula xml:id="formula_6">L B (X, Y ; ?, W ) := 1 m m i=1 (1 ? ?) ? (?(z i ), y i ) + ? ? (?(z i ), ? B (z i )),<label>(5)</label></formula><p>where ? B is the bootstrap activation function, which may be argmax or softmax (with optional temperature). NCR can be understood as bootstrapping from the neighborhood structure induced by the representation rather than from the model's predictions. This eliminates the dependency on the classifier parameters W , which may be particularly advantageous as it has been shown that linear models can fit random labels given a sufficiently high-dimensional representation <ref type="bibr" target="#b26">[27]</ref>. Label smoothing is a regularization method <ref type="bibr" target="#b36">[37]</ref> that mixes the ground truth labels with a uniform distribution. It has been shown capable of denoising corrupted labels <ref type="bibr" target="#b28">[29]</ref>. Under label smoothing, the supervised classification loss function becomes:</p><formula xml:id="formula_7">L LS (X, Y ; ?, W ) := 1 m m i=1 (1 ? ?) ? (?(z i ), y i ) + ? ? ?(z i ), 1 C 1 .<label>(6)</label></formula><p>Note that the linear combination of losses is equivalent to a linear combination of labels due to the linearity of (q, p) = ?p T log q with respect to p. Our method can be considered a modified version of label smoothing where the uniform distribution is replaced with a distribution defined by the neighboring examples. It would collapse to label smoothing if the neighbors were random or if a high temperature T were used.</p><p>Mixup <ref type="bibr" target="#b48">[49]</ref> bears some resemblance to our method in that it takes a convex combination of labels. However, mixup uses this combination as the regression target for a novel example obtained as the convex combination of the inputs, whereas NCR uses it as the target for an existing example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental setup</head><p>We first perform ablation studies on datasets with synthetic noise, where the noise level can be varied, before considering datasets with organic noise, where the noise level is fixed and unknown. For experiments with synthetic noise, we use the standard variants of CIFAR-10 and -100 <ref type="bibr" target="#b20">[21]</ref> as well as mini-ImageNet with "Blue" and "Red" noise <ref type="bibr" target="#b18">[19]</ref>. The CIFAR and mini-ImageNet-Blue datasets are contaminated with uniform label noise, whereas mini-ImageNet-Red is constructed by replacing some examples in each class with false positives from an image search engine, representing more realistic noise. For experiments with organic noise, we use mini-WebVision <ref type="bibr" target="#b22">[23]</ref>, WebVision <ref type="bibr" target="#b25">[26]</ref> and Clothing1M <ref type="bibr" target="#b43">[44]</ref>. All datasets include a clean validation and/or final evaluation set. Exhaustive implementation details and hyperparameters are also included in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Ablation study</head><p>We first study the effect of the key hyperparameters of NCR at different noise levels using the CIFAR-10 validation set. Specifically, we investigate the impact of ?, which controls the strength of the NCR term in (4), the number of neighbors k and the number of initialization epochs e. We first set the number of neighbors k = m (the batch size) and the number of initialization epochs to zero while varying ?. Subsequently, we select the optimal ? for each noise level and vary k. Finally, we adopt the optimal k and vary e. <ref type="figure" target="#fig_1">Figure 2</ref> shows the validation accuracy for different noise ratios. The performance remains relatively stable over different hyperparameters for 0% and 20% noise ratios. It is optimal to set ? to be high (0.9) for any non-zero noise ratio, indicating that the greater influence of NCR benefits these settings. Similarly, smaller k (e.g. k = 10) leads to higher accuracy when the noise ratio is above 0%. We also observe that e = 0 performs better for higher noise ratios (i.e. 40% and 80%). This shows that the NCR needs to be enabled early in training to prevent the network from memorizing the noisy labels when the noise ratio is high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Baseline comparison</head><p>We now compare NCR against the baselines defined in Section 4.2. The results are reported on the official validation set of mini-ImageNet-{Red, Blue} datasets. We run each experiment five times and report the mean accuracy at the completion of training. We do not report the peak validation accuracy attained during training as the conclusions may be less likely to generalize to an unseen test set. <ref type="table" target="#tab_0">Table 1</ref> shows the final accuracy for each method on the mini-ImageNet-{Red, Blue} datasets across different noise splits. When compared with the standard baseline (eq. (1)), our method significantly improves the performance, up to 4.9% across all noise ratios. Furthermore, we show that our method is compatible with some of the existing baselines. Combining mixup with our method leads to further improvements in some scenarios. We observe that NCR improves the accuracy of the method even at 0% noise. This suggests that it has a general regularization effect. However, the improvement in accuracy is much more pronounced in the training sets which contain label noise. <ref type="figure" target="#fig_2">Figure 3</ref> presents further evidence that NCR inhibits memorization of noisy labels. After the training is complete, we perform one last forward-pass and obtain the confidence p that the model assigns to the annotated label for each training example. The top row shows that the baseline model overfits to the noisy labels, resulting in p = 1 for both clean and noisy images. On the other hand, NCR avoids overfitting and assigns low confidence p = 0 to most of the noisy training labels. Some of the noisy examples are still classified as their assigned label on mini-Imagenet-Red. This is likely due to the dataset containing realistic and correlated noise: the mislabelled class and the true class often have visual patterns in common.</p><p>For the synthetic noise (mini-Imagenet-Blue), NCR separates the clean and noisy examples up to 40% noise ratio. However, the model underfits with 80% noise, resulting in p being close to 0 for both clean and noisy examples. This results in a small improvement for NCR, see mini-ImageNet-Blue with 80% noise in <ref type="table" target="#tab_0">Table 1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Effect on feature embeddings</head><p>Using the datasets with known noise, we can compare the feature similarity of training examples that are correctly or incorrectly labelled as belonging to the same or different classes. In the ideal case, the distributions of within-class and between-class similarities for clean examples would have zero overlap, and would be identical to the true withinclass and between-class similarities for mislabelled examples. <ref type="figure" target="#fig_3">Figure 4</ref> presents the similarity distributions for mini-ImageNet-Blue and -Red. (Note that, for mini-ImageNet-Red, the set of clean examples is known but the true class of the mislabelled examples is not known, so we cannot obtain the true within-class similarity for mislabelled examples.) We compare the distributions for a baseline model and a model trained with NCR. While the distributions for the baseline model overlap, they are not identical, showing that the feature similarities contain some signal for NCR to take advantage of. Training with NCR is shown to achieve greater separation of the classes in feature space, which must be due to the backpropagation of gradients through the feature similarities in (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">State-of-the-art comparison</head><p>In addition to <ref type="table" target="#tab_0">Table 1</ref>, which compares to prior art on mini-ImageNet-Red, we compare NCR against the stateof-the-art on mini-WebVision, WebVision and Clothing1M (which evaluate realistic noise) in <ref type="table" target="#tab_3">Table 2</ref>. Finally, we also compare to prior work on CIFAR-10 and -100 (which represents synthetic noise) in <ref type="table" target="#tab_4">Table 3</ref>.</p><p>In <ref type="table" target="#tab_3">Table 2</ref>, we also present a Data Augmentation (DA) variant of NCR, where we generate a second view of each <ref type="table" target="#tab_0">Table 1</ref>. Baseline and oracle comparison. Classification accuracy is reported on the mini-ImageNet-{Blue, Red} datasets with the ResNet-18 architecture for each individual noise ratio (0%, 20%, 40%, 80%). We present the mean accuracy and standard deviation from five trials. The oracle model is trained on only the known, clean examples in the training set using a cross-entropy loss.  example in the minibatch by applying random color jittering, motivated by <ref type="bibr" target="#b14">[15]</ref>. <ref type="table" target="#tab_3">Table 2</ref> shows that NCR achieves state-of-the-art accuracy on datasets with realistic noise such as mini-WebVision, improving by 1.2% on the best previous result. NCR outperforms other methods on Web-Vision when ResNet50 is used, and is competitive against methods using Inception-ResNetV2, a much stronger architecture. Our method is also competitive on Clothing1M, where it is only 0.2% less than the state-of-the-art.</p><p>Note that NCR does not involve additional steps, such as dividing the dataset into multiple splits, learning multiple models, applying semi-supervised learning, or a secondstage with additional training as done in the other works <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31]</ref> we compare to. While NCR is orthogonal to these strategies, we show that we achieve state of the art re-sults with minimal additional processing (e.g. data augmentation). Furthermore, NCR achieves higher performance compared to GJS <ref type="bibr" target="#b9">[10]</ref> which applies a similar consistency regularization only on different augmentation of each example. This confirms that the neighbor consistency brings further improvements on top of augmentation consistency.</p><p>To show that our method is compatible with the existing approaches, we combine NCR with ELR <ref type="bibr" target="#b26">[27]</ref> for CIFAR-10 and -100 comparisons in <ref type="table" target="#tab_4">Table 3</ref>. We reproduce all the comparisons (by running the public code), except for MOIT <ref type="bibr" target="#b30">[31]</ref> whose results are taken from the paper. Our method consistently improves over ELR, achieving state-of-the-art results in almost all noise ratios in CIFAR. For the noise ratios in which NCR does not obtain the highest result, it is typically the second-highest. Note that we fix the same hyperparam-    eters across all noise ratios, unlike Divide-Mix <ref type="bibr" target="#b22">[23]</ref>, which is a more realistic scenario in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This work introduced Neighborhood Consistency Regularization and demonstrated that it is an effective strategy for deep learning with label noise. While our approach draws inspiration from multi-stage training procedures for semi-supervised learning that employ transductive label propagation, it consists of a comparatively simple training procedure, requiring only that an extra loss be added to the objective which is optimized in stochastic gradient descent. The efficacy of NCR is emphasized by the fact that it achieved state-of-the-art results under both synthetic (CIFAR-10 and -100) and realistic (mini-WebVision) noise scenarios. Limitations and future work. A limitation of NCR is that our proposed loss assumes that it has access to an adequate feature representation of the training data. We overcome this limitation in practice by first training the network for e epochs before applying the NCR loss, but future work is to remove this additional training hyperparameter.</p><p>Promising directions for future research including coupling NCR with a technique to rejecting out-of-distribution examples during training, as employed by other approaches in the literature <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b30">31]</ref>. We also note that NCR could be applied to related problems, such as semi-supervised learning, as a regularization term. Broader Impact. Our proposed method is suited to learning from noisy data, as could be obtained by automatic scraping of the internet (illustrated by our experiments on mini-ImageNet-Red and mini-WebVision). Data collected in this fashion may contain bias <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7]</ref> and a method which is able to more effectively learn from such data may inadvertently cause these biases to be amplified. Furthermore, when using training data automatically scraped from the web, it is possible that the data is being used for a purpose to which the original owner did not consent, potentially infringing on their privacy. A. Training details Implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning with Neighbor Consistency for Noisy Labels</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>We use the ResNet-18 and -50 architectures <ref type="bibr" target="#b13">[14]</ref> in our experiments. We follow the same protocol as ELR <ref type="bibr" target="#b26">[27]</ref>, in CIFAR experiments. For Clothing1M, we follow the work of <ref type="bibr" target="#b22">[23]</ref> and fine-tune a pre-trained ResNet-50 for 80 epochs, where each epoch contains 1000 mini-batches. <ref type="table" target="#tab_5">Table 4</ref> lists the network hyperparameters used to train the network throughout our experiments. We train the network with the typical dotproduct linear classifier h W () in all datasets except for mini-WebVision and WebVision. For the mini-WebVision and WebVision experiments, we follow the work of <ref type="bibr" target="#b30">[31]</ref> and use a cosine classifier for h W (). Cosine classifier is also a linear classifier, however, the features and the classifier weights are 2 -normalized unlike the dot-product classifier.</p><p>We employ random crop augmentation during training in all experiments and resize images to 224 ? 224 pixels. For experiments with CIFAR, we use 32?32 images and reduce the strides. We trained each model on a single Nvidia V100 GPU, and will release all code upon acceptance. NCR hyperparameters. We sweep over the NCR hyperparameters ?, k and e, and choose a set of hyperparameter based on the validation set accuracy on CIFAR-{10, 100} and Clothing1M. This hyperparameter sweep is done for each noise ratio separately. Since mini-ImageNet-{Red, Blue} does not contain a held-out validation set , we create a held-out set from the mini-ImageNet-Red dataset which comprises the (clean) examples from the 0% noise dataset  that do not appear in the datasets with 20%, 40% or 80% noise. The held-out set allows us to choose hyperparameters without overfitting on the final evaluation set. We use the same hyperparameters on mini-ImageNet-Blue as well. <ref type="table" target="#tab_6">Table 5</ref> shows the list of hyperparameters for each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Dataset details</head><p>Mini  <ref type="bibr" target="#b25">[26]</ref>. It contains only the first 50 classes of the Google image subset. This corresponds to 65 944 training images. The validation set contains 2 500 images corresponding to the 50 training classes. Clothing1M <ref type="bibr" target="#b43">[44]</ref> is a large-scale dataset containing 1 million images and 14 categories. Images are collected from the web, and the noisy labels are assigned based on the surrounding text. We do not use the clean training subset with human-verified labels. We follow the existing protocol <ref type="bibr" target="#b23">[24]</ref> and fine-tune a ResNet-50 model which is pre-trained on ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Effect of batch size and number of labels</head><p>We use the WebVision dataset to to analyse the effect of the batch size for large label vocabularies. WebVision is a large-scale dataset containing 2.4M images and 1K classes. We report the accuracy for different batch sizes in <ref type="table" target="#tab_7">Table 6</ref>.</p><p>The accuracy increases with batch size, plateauing after the batch size is more than the number of classes. This shows that NCR requires the batch size to be approximately the number of classes, but that much bigger batch sizes are not required. We use a batch size of 1024 for WebVision. The other training hyperparameters remain the same as mini-Webvision on <ref type="table" target="#tab_5">Table 4</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>To address the problem of noisy labels in the training set, we propose Neighbor Consisteny Regularization. This regularizer encourages examples with similar feature representations to have similar outputs, thus mitigating the impact of training examples with incorrect labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Ablation study. Impact of hyperparameters ?, k and e are evaluated on the CIFAR-10 validation set with ResNet-18.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>StandardFigure 3 .</head><label>3</label><figDesc>Predicted confidence of training examples. Whereas the baseline assigns similar confidence scores to clean and mislabelled examples (usually all high), NCR more often assigns lower confidence to mislabelled examples and higher confidence to correct examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Similarity distributions. We compare the distribution of cosine similarities for training examples in mini-ImageNet that are correctly and incorrectly labelled as the same class or different classes. For mini-ImageNet-Blue, the features learned using NCR achieve significantly better class separation with 40% noise (or less, not pictured). For the more realistic mini-ImageNet-Red, NCR still achieves better separation of the clean examples but fails to separate examples that are incorrectly labelled as the same class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>-ImageNet-Red contains 50 000 training examples and 5 000 validation examples. The noisy images are retrieved by text-to-image and image-to-image search. They come from an open vocabulary outside of the set of classes in the training set. Depending on the noise ratio, a subset of clean images are replaced by the noisy images to construct the training set. Mini-ImageNet-Blue contains 60 000 training examples. The validation set is the same as mini-ImageNet-Red. The noise in mini-ImageNet-Blue is synthetic. The label of each example is independently and uniformly changed according to a probability. The noisy examples come from a fixed vocabulary, i.e. their true label belongs to another class in the training set. WebVision contains 2.4M images and 1000 classes. Images are collected from the web, using the Google and Flickr search engines. The data is imbalanced, meaning each class contains a different number of training examples. Mini-Webvision contains a subset of the original Webvision dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>also includes an oracle that is obtained by ex-cluding the mislabelled examples from the training set, reducing its size by 20%, 40% or 80% accordingly. Under realistic noise (mini-ImageNet-Red), the results show that NCR outperforms the oracle across all noise ratios except for 40% noise. While this may be surprising, it can be explained by the observation that the noisy examples for each class are often visually similar to the clean examples, and thus still contain some useful information. However, the performance of NCR is significantly less than the oracle un-</figDesc><table /><note>der synthetic noise (mini-ImageNet-Blue), where the noisy examples are often entirely dissimilar to the clean examples.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>State-of-the-art comparison with realistic noise.</figDesc><table><row><cell>We</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>State-of-the-art comparison with synthetic noise on CIFAR. A-40% refers to 40% asymmetric noise. All of the other columns refer to symmetric noise.</figDesc><table><row><cell></cell><cell>CIFAR-10</cell><cell></cell><cell>CIFAR-100</cell></row><row><cell></cell><cell cols="2">20% 40% 50% 80% 90% A-40%</cell><cell cols="2">20% 40% 50% 80% 90% A-40%</cell></row><row><cell>Standard</cell><cell cols="2">83.9 68.3 58.5 25.9 17.3 77.3</cell><cell cols="2">61.5 46.2 37.4 10.4 4.1 43.9</cell></row><row><cell cols="2">MOIT+ [31] 94.1 92.0 -75.8 -</cell><cell>93.2</cell><cell>75.9 67.4 -51.4 -</cell><cell>74.0</cell></row><row><cell>D-Mix [23]</cell><cell cols="2">95.1 94.2 93.6 91.4 74.5 91.8</cell><cell cols="2">76.7 74.6 73.1 57.1 29.7 72.1</cell></row><row><cell>ELR+ [27]</cell><cell cols="2">94.9 94.4 93.9 90.9 74.5 88.9</cell><cell cols="2">76.3 74.0 72.0 57.2 30.9 75.8</cell></row><row><cell>Ours+ [27]</cell><cell cols="2">95.2 94.5 94.3 91.6 75.1 90.7</cell><cell cols="2">76.6 74.2 72.5 58.0 30.8 76.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>List of network hyperparameters used in our experiments.</figDesc><table><row><cell></cell><cell cols="4">CIFAR-{10, 100} mini-{Red, Blue} mini-Webvision Clothing1M</cell></row><row><cell>Opt.</cell><cell></cell><cell>SGD</cell><cell></cell><cell></cell></row><row><cell>Momentum</cell><cell></cell><cell>0.9</cell><cell></cell><cell></cell></row><row><cell>Batch</cell><cell>256</cell><cell>128</cell><cell>256</cell><cell>128</cell></row><row><cell>LR</cell><cell>0.1</cell><cell>0.1</cell><cell>0.1</cell><cell>0.002</cell></row><row><cell>LR Sch.</cell><cell cols="3">cosine decay with linear warmup</cell><cell></cell></row><row><cell>Warmup</cell><cell></cell><cell>5</cell><cell></cell><cell></cell></row><row><cell>Epochs</cell><cell>250</cell><cell>130</cell><cell>130</cell><cell>80</cell></row><row><cell>Weight Dec.</cell><cell>5e ? 4</cell><cell>5e ? 4</cell><cell>1e ? 3</cell><cell>1e ? 3</cell></row><row><cell>Arch.</cell><cell>ResNet-18</cell><cell></cell><cell cols="2">ResNet-50</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>List of NCR hyperparameters used in our experiments.</figDesc><table><row><cell cols="2">mini-ImageNet</cell><cell cols="2">CIFAR-10 CIFAR-100</cell><cell cols="2">WebVision Clothing1M</cell></row><row><cell cols="2">0% 20% 40% 80%</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">? 0.9 0.9 0.7 0.9</cell><cell>0.1</cell><cell>0.1</cell><cell>0.5</cell><cell>0.9</cell></row><row><cell>k 50 10 5</cell><cell cols="2">100 10</cell><cell>10</cell><cell>10</cell><cell>1</cell></row><row><cell cols="2">e 50 50 50 50</cell><cell>50</cell><cell>200</cell><cell>0</cell><cell>40</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 .</head><label>6</label><figDesc>Effect of the batch size on our proposed NCR method, on the WebVision dataset containing 1000 classes.</figDesc><table><row><cell cols="2">Batch Size 256</cell><cell cols="2">512 1024 2048</cell></row><row><cell>Accuracy</cell><cell cols="2">73.9 75.0 75.7</cell><cell>75.6</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">* Work done at Google.<ref type="bibr" target="#b0">1</ref> The code is available at https : / / github . com / googleresearch/scenic/tree/main/scenic/projects/ncr</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcguinness</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="312" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep k-NN for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dara</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Gupta</surname></persName>
		</author>
		<idno>PMLR, 2020. 2</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<biblScope unit="page" from="540" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">MixMatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Large image datasets: A pyrrhic win for computer vision?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abeba</forename><surname>Birhane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinay Uday</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Prabhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rodolphe Jenatton, and Jesse Berent. Correlated input-dependent label noise in large-scale image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Collier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basil</forename><surname>Mustafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efi</forename><surname>Kokiopoulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Longremix: Robust learning with high confidence samples in a noisy label environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ragav</forename><surname>Filipe R Cordeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Sachdeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carneiro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.04173</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Does object recognition work for everyone?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Diffusion processes for retrieval revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Donoser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Low-shot learning with large-scale diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Generalized Jensen-Shannon divergence loss for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Englesson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Azizpour</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.04522</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aritra</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cur-riculumNet: Weakly supervised learning from large-scale web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenfan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengke</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinglong</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="135" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Coteaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, NIPS&apos;18</title>
		<meeting><address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="8536" to="8546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Augment your batch: Improving generalization through instance repetition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itay</forename><surname>Ben-Nun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Giladi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hoefler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soudry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Label propagation for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Tolias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="5070" to="5079" />
		</imprint>
	</monogr>
	<note>Yannis Avrithis, and Ondrej Chum</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Graph convolutional networks for learning with few clean and many noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Avrithis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond?ej</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="286" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient diffusion on region manifolds: Recovering small objects with compact cnn representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Tolias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Yannis Avrithis, Teddy Furon, and Ondrej Chum</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Beyond synthetic noise: Deep learning on controlled noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mason</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilong</forename><surname>Yang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">CleanNet: Transfer learning for scalable image classifier training with label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuang-Huei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Di-videMix: Learning with noisy labels as semi-supervised learning. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven C H</forename><surname>Hoi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to learn from noisy labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongkang</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Mopro: Webly supervised learning with momentum prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.07995</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<title level="m">Webvision database: Visual learning and understanding from web data</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Early-learning regularization prevents memorization of noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Niles-Weed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narges</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Fernandez-Granda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minseop</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saehoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunho</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung</forename><forename type="middle">Ju</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Does label smoothing mitigate label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinadh</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">SELF: Learning to filter noisy labels with self-ensembling. ICLR</title>
		<editor>Duc Tam Nguyen, Chaithanya Kumar Mummadi, Thi Phuong Nhung Ngo, Thi Hoai Phuong Nguyen, Laura Beggel, and Thomas Brox</editor>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Multi-objective interpolation training for robustness to label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E O&amp;apos;</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcguinness</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.04462</idno>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Multi-label iterated learning for image classification with label ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai</forename><surname>Rajeswar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pau</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumye</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.12172</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping. ICLR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Embedding propagation: Smoother manifold for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issam</forename><surname>Pau Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Drouin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2080</idno>
		<title level="m">Training convolutional networks with noisy labels</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiki</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiki</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoharu</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5552" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Interpolation consistency training for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="3635" to="3641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Derivative manipulation for general example weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinshao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elyor</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil M</forename><surname>Robertson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11233</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Iterative learning with open-set noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu-Tao</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A topological filter for learning with label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songzhu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">LDMI: A novel information-theoretic loss function for training deep nets robust to label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Webly supervised image classification with self-contained confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingkang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Litong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weirong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huabin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.11894</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03530</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
		<title level="m">mixup: Beyond empirical risk minimization. ICLR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengyong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Thomas Navin Lal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
