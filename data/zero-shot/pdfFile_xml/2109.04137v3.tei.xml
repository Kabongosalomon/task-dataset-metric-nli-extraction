<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fusing Task-oriented and Open-domain Dialogues in Conversational Agents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Young</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Xing</surname></persName>
							<email>xing@nus.edu.sg</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Pandelea</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjie</forename><surname>Ni</surname></persName>
							<email>jinjie001@e.ntu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
							<email>cambria@ntu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fusing Task-oriented and Open-domain Dialogues in Conversational Agents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The goal of building intelligent dialogue systems has largely been separately pursued under two paradigms: task-oriented dialogue (TOD) systems, which perform task-specific functions, and open-domain dialogue (ODD) systems, which focus on non-goal-oriented chitchat. The two dialogue modes can potentially be intertwined together seamlessly in the same conversation, as easily done by a friendly human assistant. Such ability is desirable in conversational agents, as the integration makes them more accessible and useful. Our paper addresses this problem of fusing TODs and ODDs in multi-turn dialogues. Based on the popular TOD dataset Mul-tiWOZ, we build a new dataset FusedChat, by rewriting the existing TOD turns and adding new ODD turns. This procedure constructs conversation sessions containing exchanges from both dialogue modes. It features inter-mode contextual dependency, i.e., the dialogue turns from the two modes depend on each other. Rich dependency patterns such as coreference and ellipsis are included. The new dataset, with 60k new human-written ODD turns and 5k re-written TOD turns, offers a benchmark to test a dialogue model's ability to perform inter-mode conversations. This is a more challenging task since the model has to determine the appropriate dialogue mode and generate the response based on the intermode context. However, such models would better mimic human-level conversation capabilities. We evaluate two baseline models on this task, including the classification-based two-stage models and the two-in-one fused models. We publicly release FusedChat and the baselines to propel future work on inter-mode dialogue systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Recent years have seen a popularity of models on building intelligent systems that converse with humans naturally <ref type="bibr" target="#b13">(Ni et al. 2021)</ref>. Two mainstream models can be categorized as the open-domain dialogue (ODD) models <ref type="bibr" target="#b0">(Adiwardana et al. 2020;</ref><ref type="bibr" target="#b16">Roller et al. 2020;</ref><ref type="bibr" target="#b24">Zhang et al. 2019)</ref> and the task-oriented dialogue (TOD) models <ref type="bibr" target="#b4">(Ham et al. 2020;</ref><ref type="bibr" target="#b1">Budzianowski et al. 2018)</ref>. ODD models, when first adapted with the Seq2Seq modeling paradigm <ref type="bibr" target="#b19">(Sutskever, Vinyals, and Le 2014)</ref>, focused on learning open-domain human conversation based on massive <ref type="bibr">[context, response]</ref> pairs <ref type="bibr" target="#b20">(Vinyals and Le 2015;</ref><ref type="bibr" target="#b9">Li et al. 2016</ref>).</p><p>Copyright ? 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Such models generate the response based on the context and exhibit general chitchat ability. Their primary goal in a conversation is to keep the user engaged and chat over random open-domain topics that he is interested in. The dialogues can be sustained by commonsense without the need for any special databases. TOD models are vastly different. The dialogues exist for the purpose of serving specific functions, such as finding restaurants and booking airlines. They operate on closed domains that are often supported by structured databases and APIs <ref type="bibr" target="#b1">(Budzianowski et al. 2018;</ref><ref type="bibr" target="#b15">Rastogi et al. 2020)</ref>. Commonly three characteristics distinguish them from ODD models: (1) an entity-centered database, (2) explicit dialogue state modeling, and (3) a pre-defined set of dialogue domains and functions (dialogue acts). Humans are able to effortlessly conduct both types of conversations seamlessly together. It is ideal for a dialogue system to be able to do so, because such integration offers a fused system with increased usability. Furthermore, it allows rich interactions between the two dialogue modes, which can not be modeled in either mode independently. Such a dialogue model would better mimic human-level conversation capabilities, e.g., chatting with a friendly assistant ( <ref type="figure">Fig. 1</ref>).</p><p>Despite numerous datasets have been created in recent years for both ODDs and TODs, there is no high-quality human-written dataset on their fusion, especially with intermode contextual dependency. Our work aims to fill this void. We use the popular TOD dataset MultiWOZ <ref type="bibr" target="#b1">(Budzianowski et al. 2018)</ref> as the backbone and let human creators add ODD turns before or after the existing TOD turns. For roughly half the MultiWOZ dialogues, we prepend ODD turns, creating ODD + TOD sessions. For the other half, we append ODD turns, creating TOD + ODD sessions. In both cases, the creator writes an ODD that is contextually related to the existing TOD. We enforce inter-mode dependency in FusedChat. In the prepending case, we make sure the TOD is dependent on the ODD by rewriting the first turn of the TOD, typically with co-reference or ellipsis. In the appending cases, we make sure at least one exchange in the ODD is dependent on concepts or knowledge found in the TOD. In a nutshell, these dependency patterns in our dataset mean that when a dialogue model handles a turn of one dialogue mode, it sometimes has to refer to the contextual information given in the history turns of the other dialogue mode.</p><p>Figure 1: Example of interaction with our dialogue system. The conversation between a user and a digital assistant seamlessly interchanges between TOD and ODD modes with strong inter-mode dependency. The conversation involves querying about a college entrance fee (TOD) and chitchat about personal development and finance (ODD).</p><p>This new dataset offers a unique test-bed for training and evaluating inter-mode dialogue systems that possess both TOD and ODD capabilities. Traditional dialogue evaluation metrics for both dialogue modes can be used together for inter-mode evaluation.</p><p>We develop and evaluate two baseline models for this new setting: (1) The classification-based model. Two response generation models M tod and M odd are independently trained on the turns of the respective modes. They generate the response of their respective mode given a conversational context. A separate mode classification model C is trained and used to determine which mode to invoke given the context. (2) The two-in-one fused dialogue model that is trained on dialogue turns of both modes together. It generates a response given any conversational context, by implicitly predicting the dialogue mode as part of sequence generation.</p><p>In summary, our main contributions are: (1) A new dialogue dataset named FusedChat 1 that fuses TODs and ODDs in multi-turn dialogues. The dialogues feature inter-mode contextual dependency for seamless mode fusion, allowing the dialogue model to better mimic human-level conversation capabilities. FusedChat, with 60k new humanwritten ODD turns and 5k re-written TOD turns, serves as a new benchmark for inter-mode dialogue systems. Traditional metrics used to gauge TOD and ODD systems separately can be combined to evaluate inter-mode dialogue systems.</p><p>(2) two-in-one models and classification-based models are developed and evaluated as inter-mode dialogue models. Our preliminary experiments suggest that the models perform worse than their single-mode counterparts evaluated on single-mode datasets. And the more computationally expensive classification-based model outperforms the cheaper two-in-one fused model. This suggests that effectively fusing different dialogue modes is a challenging task and there is a huge room for improvement upon our baseline 1 https://github.com/tomyoung903/FusedChat fusion models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FusedChat Construction</head><p>To create inter-mode dialogue sessions, our dataset construction process mainly involves having dialogue creators prepend or append self-written ODDs to existing TODs. A dialogue creator plays the part of both the user and the dialogue system by himself. This self-dialogue setting <ref type="bibr" target="#b2">(Byrne et al. 2019)</ref> avoids misunderstandings between two human creators and improve the consistency of the created dialogues.</p><p>For the existing TODs, the MultiWOZ 2.4 dataset <ref type="bibr" target="#b22">(Ye, Manotumruksa, and Yilmaz 2021)</ref> is selected because of its popularity in the literature. MultiWOZ contains TODs in 7 domains, including restaurant, attraction, train, police, hospital, taxi and hotel. The user converses with the dialogue agent for a pre-defined set of functions, such as booking restaurants and locating hospitals. Despite that MultiWOZ was created assuming the user is a tourist <ref type="bibr" target="#b1">(Budzianowski et al. 2018)</ref>, we find that most dialogues themselves do not necessarily reflect a tourist persona and allow flexibly adding open-domain dialogues. In our FusedChat setting, the dialogue creators are free to add any ODD that is contextually consistent with the existing TOD.</p><p>In the following sections, we first discuss the general requirement we set for the added ODDs. We then explain how prepending and appending ODDs are executed and how inter-mode dependency is enforced, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General requirements for the added ODDs</head><p>In this section, we describe the general requirements for the added ODDs for both the prepending and appending cases, as rules for the dialogue creators to follow.</p><p>(1) Every creator writes fictitious ODDs for both the roles of "system" and "user", where the "system" represents an AI conversational agent that is capable of both friendly opendomain conversation (in the added ODDs) and task-oriented dialogues (in the existing MultiWOZ TODs). And "user" represents a human speaker that converses with the AI agent for friendly chitchat and to achieve certain task objectives.</p><p>(2) To ensure the relevance between the existing TOD and the added ODD, we encourage the creators to make the ODD revolve around similar or related topics as in the existing TOD segment, e.g., by talking about the same or related concepts in the TOD. The added ODD turns and the existing TOD turns should connect with each other naturally. There should be strong contextual dependency between the two modes (explained in the next 2 sections).</p><p>(3) The created dialogues should adhere to the general characteristics of ODDs as opposed to TODs. They should be casual chitchat exchanges that do not require the "system" to perform any specific task-oriented functionalities or provide any task-specific information. understanding of their difference, and the ease of fitting those TODs into the context of existing TODs. As an aggressive measure to combat this issue, we deployed a real-time turn-level ODD vs TOD classifier, trained on a combination of three traditional ODD datasets <ref type="bibr" target="#b23">(Zhang et al. 2018;</ref><ref type="bibr" target="#b4">Dinan et al. 2018)</ref> and MultiWOZ. In addition, we outline several pitfalls found in the pilot experiment for the creators to avoid, such as letting the system fabricate information that is beyond commonsense.</p><p>Next, we describe the details on how appending ODDs (TOD + ODD) and prepending ODDs (ODD + TOD) are executed, and how inter-mode dependency is enforced, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appending ODDs</head><p>In the appending scenario, the dialogue creators append an ODD to a provided TOD sampled from the MultiWOZ dataset. The ODD should naturally follow the TOD.</p><p>? We notice that the dialogues from the original Multi-WOZ dataset often end with a "User: Thank you. System: Goodbye." exchange. This exchange effectively ends the conversation. For appending ODDs, we heuristically remove such exchanges from the end of the TOD based on dialogue act annotations (dialogue-act:thank-you and dialogue-act:goodbye).</p><p>Inter-mode Dependency In appending cases, the content of the ODD should be dependent on the preceding TOD. We enforce this by letting the creators write at least one round of exchange whose content reflects concepts or knowledge found the existing TOD segment. <ref type="figure">Fig. 2</ref> shows a TOD + ODD example. The first two rounds of exchange between the user and the system is under the TOD mode. They are about querying and booking an expensive Thai restaurant. The system's replies are supported by dialogue state tracking <ref type="bibr" target="#b1">(Budzianowski et al. 2018</ref>) and an underlying database on available restaurants. In the third round of exchange, the user expresses concern over whether his friends would enjoy the restaurant. Note that this is considered an ODD utterance since it does not invoke any task-oriented function. The system's ODD response is supported by commonsense and empathy. Note how it reflects content from a history TOD turn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prepending ODDs</head><p>In prepending cases, the creator is given a TOD segment from MultiWOZ and asked to prepend an ODD to it. The ODD should naturally lead to the provided TOD. Note that the original TODs in MultiWOZ are selfcontained. For our purpose of modeling inter-mode dependency, we conduct utterance rewriting based on co-reference and ellipsis. In FusedChat, they are the key why the TOD is dependent on the prepended ODD.</p><p>Inter-mode Dependency We want to create ODD + TOD sessions where the TOD is conditioned on the ODD. The key I need to find a restaurant in Cambridge that serves expensive Thai food please.</p><p>Bangkok City is located at 24 Green Street City Centre.</p><p>My friends who are going to dine with me are foodies. I really want them to enjoy the restaurant I pick.</p><p>Don't worry. The cuisine of an expensive restaurant shouldn't be too bad.  <ref type="figure">Figure 2</ref>: An excerpt from a TOD + ODD instance from FusedChat. Note how inter-mode dependency is featured in the last system ODD turn by referring to the concept "expensive restaurant" previously mentioned in the TOD.</p><p>to a successful TOD is dialogue state tracking, where the dialogue system processes the user utterance for [slot type, slot value] pairs (e.g., [Destination: Cambridge]) in order to understand the user's need and respond properly. Our designed method to model inter-mode dependency in our dataset essentially imposes ODD-dependent dialogue state tracking. We randomly select a slot value mentioned in the first user turn in the TOD, e.g., "Cambridge" in <ref type="figure" target="#fig_0">Fig. 3</ref>. We ask the dialogue creators to use the slot value in the prepended ODD, and rewrite the first dialogue user turn accordingly to refer to it implicitly. Rewriting mainly involves co-reference (e.g., "there" in <ref type="figure" target="#fig_0">Fig. 3</ref>), and sometimes ellipsis. Co-reference and ellipsis are important features in multi-turn TODs, attracting researchers to sometimes perform special annotations for them in certain TOD datasets <ref type="bibr" target="#b14">(Quan et al. 2020</ref>). See <ref type="figure" target="#fig_0">Fig. 3</ref> for a detailed example on how inter-mode dependency is featured for ODD + TOD sessions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FusedChat statistics</head><p>A total of 113 undergraduate students from the authors' university were recruited as dialogue creators for Fused-Chat. The difference between FusedChat and MultiWOZ mainly lies in the additional ODD turns, either grounding or grounded by the original TODs. The added ODD turns in FusedChat are a significant extension to the original Multi-WOZ dataset. As shown in (b) New ODD turns are prepended to the original TOD in (a). Note that the TOD user turn is rewritten. The slot value "Cambridge" is mentioned in a prepended ODD turn while co-reference is used in the rewritten user turn. This imposes ODD-dependent dialogue state tracking, forcing the the dialogue system to look for clues in the ODD when it tries to interpret the user's need. added, including 8k+ new tokens not present in the original MultiWOZ dataset, significantly expanding the vocabulary. FusedChat also rewrote the first TOD turns (4670 in total) for the scenario of prepending ODDs. For the scenario appending ODDs, FusedChat discarded 11320 TOD turns containing only "thank-you" and "goodbye" dialogue acts. <ref type="table" target="#tab_3">Table 2</ref> shows the training/validation/testing partition for FusedChat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approaches for inter-mode dialogues</head><p>In this section, we discuss baseline models we developed for inter-mode dialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Definition</head><p>A multi-turn dialogue system generates a response R based on a multi-turn context C. In inter-mode dialogues, C is composed of both TOD and ODD turns. In the FusedChat setting, R can be in either TOD mode or ODD mode, but has to be in only one of the two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>We experiment with two types of models for inter-mode dialogues. <ref type="formula">(1)</ref> The classification-based model that is composed of a mode classification model and two response generation models for TOD and ODD separately and (2) the two-in-one fused model where a single response generation model can perform both TOD and ODD generation, implicitly determining the response mode.</p><p>(1) The classification-based model. Two response generation models M odd and M tod are independently trained to handle each conversation mode. A separate classification model C is trained and used to determine which mode of model to invoke given an inter-mode context. Note that all 3 models above take inter-mode context as input.</p><p>? For M odd , we follow <ref type="bibr" target="#b17">(Shuster et al. 2019</ref>  (2) The two-in-one model. Trained on dialogue turns of both modes, it uses a single model that generates a response given any conversational context by implicitly determining the conversational mode. Similar to <ref type="bibr" target="#b18">(Sun et al. 2020</ref> For all the models above, best checkpoints for testing are selected based on the full validation sets of 1000 instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FusedChat as a new benchmark</head><p>Depending on the context and the dialogue mode, the dialogue turns in our dataset are naturally separated into 4 types in <ref type="figure" target="#fig_1">Fig. 4</ref>: vanilla TODs, vanilla ODDs, ODD-grounded TODs and TOD-grounded ODDs. Vanilla refers to the dialogue turns being grounded on context of its own mode only, resembling traditional datasets. The ODD turns in the "prepending ODDs" scenario and TOD turns in the "appending ODDs" scenario are vanilla.</p><p>In the following sections, we illustrate 4 unique evaluation scenarios on which FusedChat can benchmark the performance of inter-mode dialogue systems, including mode classification, TOD-grounded ODDs, ODD-grounded TODs and full inter-mode dialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mode classification</head><p>The straightforward problem in inter-mode dialogues is to decide which mode the generated response should be. Should the system respond with friendly chitchat (ODD), or should it try to interpret the user's task-oriented goal and respond with certain dialogue acts (TOD)? The accuracy for the mode classification model is shown in <ref type="table">Table 3</ref>. We consider two context options: using only the latest user turn as the context (single-turn) or using the whole history containing multiple turns as the context (multi-turn). Results show that the accuracy is quite high in both cases, with "multiturn" marginally outperforming "single-turn". user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ... user: ... system: ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TOD + ODD instances ODD + TOD instances</head><p>Original  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context option Accuracy</head><p>Single-turn 0.993 Multi-turn 0.995 <ref type="table">Table 3</ref>: Mode classification accuracy for model C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ODD-grounded TODs</head><p>Part of inter-mode dialogues are ODD-grounded TODs, which correspond to the "prepending ODDs" scenario in FusedChat. Like in regular TODs, the system's response is prompted by a task-oriented user request. However, the preceding context contains ODD exchanges, which create unique challenges.    On the one hand, the model needs to recognize useful task-related information from the ODD context for correct dialogue state tracking. On the other hand, the system's response should correctly perform the required task-oriented function according to the latest user request, instead of derailing to chitchat by following the ODD context in the history.</p><p>Evaluation results for this portion of the dialogue turns in FusedChat are shown in <ref type="table" target="#tab_7">Table 4</ref>. We use the traditional TOD evaluation metrics for MultiWOZ, where slot accuracy measures dialogue state tracking, inform rate and success rate measure user goal success and BLEU measures response quality (see more details in <ref type="bibr" target="#b1">(Budzianowski et al. 2018)</ref>).</p><p>In addition, we evaluate the Neural Pipeline approach using the original MultiWOZ dataset (trained and tested on MultiWOZ). Remember that the classification-based model contains M tod , which exactly follows the Neural Pipeline model. This is to evaluate the difficulty of the new ODDgrounded TOD task compared with the vanilla TOD task in MultiWOZ. <ref type="table" target="#tab_7">Table 4</ref> shows that:</p><p>(1) the classification-based model outperforms the twoin-one model marginally.</p><p>(2) The Neural Pipeline model evaluated on the same vanilla TOD dialogues in MultiWOZ significantly outperforms the classification-based model evaluated on ODDgrounded TODs in FusedChat. Such significant difference suggests that ODD-grounded TODs are a more challenging task than vanilla TODs. Presumably, this is because (a) the extra requirement to correctly determine the response mode and (b) the extra need for ODD-dependent dialogue state tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TOD-grounded ODDs</head><p>Another part of inter-mode dialogues are TOD-grounded OODs, which correspond to the "appending ODDs" scenario in FusedChat. The system's ODD response should be conditioned on both the TOD and ODD turns in the context.</p><p>The evaluation on open-domain dialogue generation is notoriously difficult and numerous evaluation methods have been proposed <ref type="bibr" target="#b13">(Ni et al. 2021)</ref>. In our experiment, we follow <ref type="bibr" target="#b0">(Adiwardana et al. 2020</ref>) and use perplexity plus sensibleness and specificity average (SSA) as metrics. SSA represents the average between sensibleness (Does the response make sense given the context?) and specificity (Is the response specific to the context?). Both of them are binary for each response. A response can only be deemed specific if it is deemed sensible. SSA results are computed by averaging 5 expert human evaluators' judgement on 100 randomly sampled dialogue turns from the testset. <ref type="table" target="#tab_8">Table 5</ref> shows the performance of the inter-mode dialogue models on this task.</p><p>The classification-based model outperforms the two-inone model marginally. Results also show that ground-truth responses receive very high SSA scores, significantly exceeding the better dialogue model of the two we developed. This suggests that there is huge room for improvement on this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Full inter-mode dialogues</head><p>We show the results on the full FusedChat testset (containing all 4 types of dialogue turns) in <ref type="table" target="#tab_9">Table 6</ref>. A combination of TOD and ODD metrics discussed above can be used to holistically gauge a dialogue system's capability to perform inter-mode dialogues. The classification-based model marginally outperforms the two-in-one model.</p><p>Note that for the evaluation of ODD-grounded TODs, TOD-grounded ODDs and full inter-mode dialogues, we evaluate the response in a mode-tolerant manner. This means that even when the model generates a response of the wrong mode, we still evaluate that instance normally, instead of directly punishing the metric value to 0. For example, when evaluating BLEU, we still normally calculates the BLEU score against the ground-truth response even if the response generated by the inter-mode dialogue model is an ODD response. Of course, getting the mode wrong typically means bad scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Recently, there have been multiple efforts on developing dialogue systems multi-tasking on various types of dialogues <ref type="bibr" target="#b13">(Ni et al. 2021;</ref><ref type="bibr" target="#b10">Ma et al. 2020)</ref>. Adapter-Bot <ref type="bibr" target="#b11">(Madotto et al. 2020a</ref>) uses a fixed backbone conversational model (DialoGPT) and triggers on-demand dialogue skills (e.g., empathetic responses, weather information, movie recommendation) via different adapters <ref type="bibr" target="#b6">(Houlsby et al. 2019)</ref>. <ref type="bibr" target="#b12">(Madotto et al. 2020b</ref>) learns a dialogue system that independently parameterizes different dialogue skills, and learns to select and combine each of them through Attention over Parameters. <ref type="bibr" target="#b21">Xu et al. (2020)</ref> proposed an end-to-end dialogue model based on a hierarchical encoderdecoder, which employed a discrete latent variable to learn underlying dialogue intentions. They argued that the latent discrete variable interprets the intentions that guide machine responses generation <ref type="bibr" target="#b7">(Howard and Cambria 2013)</ref>. <ref type="bibr" target="#b17">Shuster et al. (2019)</ref> multi-tasked on 12 separate dialogue datasets that focus on different skills and showed that a single unified model can perform decently well on all tasks. However, these models do not model the dependency between different types of dialogues in the multi-turn setting. Thus, they are not guaranteed to converse seamlessly and naturally in multiple dialogue modes simultaneously in a multi-turn conversation session.</p><p>Unlike the models trained on separate dialogue datasets, Smith et al. (2020) tried to fuse multiple skills into one conversation session. They built a new dialogue dataset named Blendedskilltalk containing dialogues where knowledge, emotional and personalizing skills are shown together in the same multi-turn conversation. They show that systems fine-tuned on the new multi-skill dataset have improved ability in handling multiple skills simultaneously in the same multi-turn conversation session. However, they only target open-domain conversations. Our work, on the other hand, targets the fusion of general ODDs and TODs, as we view them as the two most mainstream forms of dialogues for the research community currently. Along the direction of fusing TODs and ODDs, <ref type="bibr" target="#b25">Zhao et al. (2017)</ref> proposed to artificially augment task-oriented dialogues with randomly sampled utterances from a chitchat corpus, mainly to improve the out-of-domain recovery performance for the TOD system. <ref type="bibr" target="#b18">Sun et al. (2020)</ref> proposed to decorate TOD responses with ODD snippets, in order to make the dialogue agent sound more engaging and interactive. Unlike <ref type="bibr" target="#b18">(Sun et al. 2020)</ref>, where ODD snippets act as a supplementary role to TOD responses, our dataset tackles the fusion of TODs and ODDs by treating them as parallel dialogue modes of equal importance, and focuses on modeling inter-mode dependency in the multi-turn setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussions and Future Work</head><p>Our work serves the goal to develop dialogue systems that are capable of performing both TODs and ODDs with intermode dependency. Compared with traditional datasets, the new dataset FusedChat uniquely contains ODD-grounded TODs and TOD-grounded ODDs. It endeavors to fuse the two common forms of human conversations, i.e., casual open-ended conversations supported only by commonsense, and task-oriented conversations supported by specific knowledge bases. We show preliminary experiment results on two baseline models, which suggest huge room for improvement. We release dataset and baselines in order to propel future work on inter-mode dialogue systems.</p><p>We note that the framework set by FusedChat is limited. The dataset does not contain dialogue sessions containing more than one mode switch, which represents a gap with real-world scenarios. We suspect more mode switches could make inter-mode dialogues even more challenging. Our choice of TODs and ODDs does not represent the full scope of possible dialogue settings. We chose the most simple form of ODDs where the response is only determined by the context. Yet in the literature, ODDs have been grounded on various forms of information, such as personas <ref type="bibr" target="#b23">(Zhang et al. 2018)</ref>. We chose the classical setting of TODs as in Multi-WOZ, which is defined by structured entity-centric knowledge bases. However, the concept of TODs has seen expansion, such as with unstructured knowledge access . We expect the fusion of more complex forms of ODDs and TODs to be more challenging, but they would even better represent human-level conversational abilities.</p><p>The construction of FusedChat required a lot of manual creative effort. It is thus very expensive to replicate the same routine for every new inter-mode dialogue scenario. Alternatively, zero-shot or few-shot models that can learn to perform inter-mode dialogues by mostly relying on separate singlemode dialogues are a promising direction. FusedChat can also serve as a test-bed for such paradigms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>An ODD + TOD instance from FusedChat.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>4 types of dialogue turns are present in FusedChat, classified by the dialogue mode and the grounding context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>, 60k+ new ODD turns are I am looking for a train that will be arriving at Cambridge by 16:00 Friday, from King's Lynn.We have a train headed for Cambridge at 15:11.Would you like to book it?</figDesc><table><row><cell>USER</cell></row><row><cell>Destination: Cambridge</cell></row><row><cell>SYSTEM</cell></row><row><cell>(a) An original TOD exchange with the dialogue state [Destination:</cell></row><row><cell>Cambridge].</cell></row><row><cell>I'm</cell></row><row><cell>kind of nervous.</cell></row></table><note>I am meeting my client in Cambridge soon.Wow that is huge! Good luck! I am looking for a train that will be arriving there by 16:00 Friday, from King's Lynn. We have a train headed for Cambridge at 15:11. Would you like to book it?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>FusedChat is composed of ODD + TOD (prepending ODDs) instances and TOD + ODD (appending ODDs) instances.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>), we use an additional &lt;ODD&gt; token during sequence construction to indicate when the response is in the ODD mode. The training sequences are composed of [Context ? (&lt;ODD&gt;, Response)] and [Context ? (Dialogue State, Dialogue Act, Response)]. The model is initialized with GPT2 and finetuned on all dialogue turns in FusedChat.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Evaluation results on ODD-grounded TODs in FusedChat and comparison with MultiWOZ results.</figDesc><table><row><cell>Models</cell><cell cols="4">PPL Sensibleness Specificity SSA</cell></row><row><cell>Two-in-one model</cell><cell>9.15</cell><cell>0.44</cell><cell>0.39</cell><cell>0.42</cell></row><row><cell cols="2">Classification-based model 8.79</cell><cell>0.51</cell><cell>0.45</cell><cell>0.48</cell></row><row><cell>Ground-truth</cell><cell>N/A</cell><cell>0.97</cell><cell>0.91</cell><cell>0.94</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Evaluation results on TOD-grounded ODDs in FusedChat.</figDesc><table><row><cell>Models</cell><cell cols="8">TOD metrics Slot Accuracy Joint SA Inform Success BLEU PPL Sensibleness Specificity SSA ODD metrics</cell></row><row><cell>Two-in-one model</cell><cell>0.972</cell><cell>0.592</cell><cell>70.4</cell><cell>57.0</cell><cell>12.05 10.49</cell><cell>0.52</cell><cell>0.47</cell><cell>0.50</cell></row><row><cell>Classification-based model</cell><cell>0.973</cell><cell>0.600</cell><cell>75.1</cell><cell>60.9</cell><cell>12.17 10.50</cell><cell>0.58</cell><cell>0.51</cell><cell>0.55</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Evaluation results on the full FusedChat testset</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">? Based on the pilot experiment with a sample of creators, we found that the creators had a tendency to write dialogues that are focused on task-specific functionalities, which are technically TODs instead of ODDs as instructed. This is presumably because of a lack of nuanced</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is supported by the Agency for Science, Technology and Research (A*STAR) under its AME Programmatic Funding Scheme (Project #A18A2b0046). We thank Lu Cheng for creating the data collection interface and Low Shi Min and Arya Shashwat for quality control. We thank Peter Young for communication with the creators.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Adiwardana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nemade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.09977</idno>
		<title level="m">Towards a human-like open-domain chatbot</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">MultiWOZ-A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-H</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ramadan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ga?i?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00278</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Krishnamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duckworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cedilnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-Y</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.05358</idno>
		<title level="m">Taskmaster-1: Toward a realistic and diverse dialog dataset</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Endto-End Neural Pipeline for Goal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-E</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.01241</idno>
	</analytic>
	<monogr>
		<title level="m">Wizard of wikipedia: Knowledge-powered conversational agents</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Oriented Dialogue Systems using GPT-2. ACL</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A simple language model for task-oriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hosseini-Asl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00796</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Parameter-efficient transfer learning for NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>De Laroussilhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2790" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Intention awareness: Improving upon situation awareness in human-centric environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human-centric Computing and Information Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Beyond domain apis: Taskoriented conversational modeling with unstructured knowledge access</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hedayatnia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.03533</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Diversity-Promoting Objective Function for Neural Conversation Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A Survey on Empathetic Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="50" to="70" />
		</imprint>
	</monogr>
	<note>Information Fusion</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.12579</idno>
		<title level="m">The Adapter-Bot: All-In-One Controllable Conversational Model</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Attention over Parameters for Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.01871</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pandelea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Adiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.04387</idno>
		<title level="m">Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="930" to="940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Khaitan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8689" to="8696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13637</idno>
		<title level="m">Recipes for building an open-domain chatbot</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The dialogue dodecathlon: Open-domain knowledge and image grounded conversational agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03768</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2021" to="2030" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Can You Put it All Together: Evaluating Conversational Agents&apos; Ability to Blend Skills</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Crook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Silvert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12757</idno>
		<title level="m">Adding Chit-Chats to Enhance Task-Oriented Dialogues</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<idno>abs/1506.05869</idno>
	</analytic>
	<monogr>
		<title level="j">A neural conversational model. CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">End-to-End latent-variable task-oriented dialogue system with exact log-likelihood optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Wide Web</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1989" to="2002" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">MultiWOZ 2.4: A Multi-Domain Task-Oriented Dialogue Dataset with Essential Annotation Corrections to Improve State Tracking Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Manotumruksa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.00773</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Personalizing dialogue agents: I have a dog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07243</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>do you have pets too? arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Dialogpt: Large-scale generative pre-training for conversational response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.00536</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Generative encoder-decoder models for task-oriented spoken dialog systems with chatting capability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.08476</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
