<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Heusel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">LIT AI Lab &amp; Institute of Bioinformatics</orgName>
								<orgName type="institution">Johannes Kepler University Linz</orgName>
								<address>
									<postCode>A-4040</postCode>
									<settlement>Linz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
							<email>ramsauer@bioinf.jku.at</email>
							<affiliation key="aff0">
								<orgName type="department">LIT AI Lab &amp; Institute of Bioinformatics</orgName>
								<orgName type="institution">Johannes Kepler University Linz</orgName>
								<address>
									<postCode>A-4040</postCode>
									<settlement>Linz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
							<email>unterthiner@bioinf.jku.at</email>
							<affiliation key="aff0">
								<orgName type="department">LIT AI Lab &amp; Institute of Bioinformatics</orgName>
								<orgName type="institution">Johannes Kepler University Linz</orgName>
								<address>
									<postCode>A-4040</postCode>
									<settlement>Linz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
							<email>nessler@bioinf.jku.at</email>
							<affiliation key="aff0">
								<orgName type="department">LIT AI Lab &amp; Institute of Bioinformatics</orgName>
								<orgName type="institution">Johannes Kepler University Linz</orgName>
								<address>
									<postCode>A-4040</postCode>
									<settlement>Linz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
							<email>hochreit@bioinf.jku.at</email>
							<affiliation key="aff0">
								<orgName type="department">LIT AI Lab &amp; Institute of Bioinformatics</orgName>
								<orgName type="institution">Johannes Kepler University Linz</orgName>
								<address>
									<postCode>A-4040</postCode>
									<settlement>Linz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the 'Fr?chet Inception Distance" (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.</p><p>Recently actor-critic learning has been analyzed using stochastic approximation. Prasad et al. <ref type="bibr" target="#b54">[50]</ref> showed that a two time-scale update rule ensures that training reaches a stationary local Nash equilibrium if the critic learns faster than the actor. Convergence was proved via an ordinary differential equation (ODE), whose stable limit points coincide with stationary local Nash equilibria. We follow the same approach. We prove that GANs converge to a local Nash equilibrium when trained by a two time-scale update rule (TTUR), i.e., when discriminator and generator have separate learning rates. This also leads to better results in experiments. The main premise is that the discriminator converges to a local minimum when the generator is fixed. If the generator changes slowly enough, then the discriminator still converges, since the generator perturbations are small. Besides ensuring convergence, the performance may also improve since the discriminator must first learn new patterns before they are transferred to the generator. In contrast, a generator which is overly fast, drives the discriminator steadily into new regions without capturing its gathered information. In recent GAN implementations, the discriminator often learned faster than the generator. A new objective slowed down the generator to prevent it from overtraining on the current discriminator <ref type="bibr" target="#b57">[53]</ref>. The Wasserstein GAN algorithm uses more update steps for the discriminator than for the generator <ref type="bibr" target="#b6">[3]</ref>. We compare TTUR and standard GAN training. <ref type="figure">Fig. 1</ref> shows at the left panel a stochastic gradient example on CelebA for original GAN training (orig), which often leads to oscillations, and the TTUR. On the right panel an example of a 4 node network flow problem of Zhang et al.</p><p>[61] is shown. The distance between the actual parameter and its optimum for an one time-scale update rule is shown across iterates. When the upper bounds on the errors are small, the iterates return to a neighborhood of the optimal solution, while for large errors the iterates may diverge (see also Appendix Section A2.3).</p><p>Our novel contributions in this paper are:</p><p>? The two time-scale update rule for GANs,</p><p>? We proof that GANs trained with TTUR converge to a stationary local Nash equilibrium,</p><p>? The description of Adam as heavy ball with friction and the resulting second order differential equation,</p><p>? The convergence of GANs trained with TTUR and Adam to a stationary local Nash equilibrium,</p><p>? We introduce the "Fr?chet Inception Distance" (FID) to evaluate GANs, which is more consistent than the Inception Score.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Generative adversarial networks (GANs) <ref type="bibr" target="#b21">[18]</ref> have achieved outstanding results in generating realistic images <ref type="bibr" target="#b55">[51,</ref><ref type="bibr" target="#b40">36,</ref><ref type="bibr" target="#b31">27,</ref><ref type="bibr" target="#b6">3,</ref><ref type="bibr" target="#b9">6]</ref> and producing text <ref type="bibr" target="#b27">[23]</ref>. GANs can learn complex generative models for which maximum likelihood or a variational approximations are infeasible. Instead of the likelihood, a discriminator network serves as objective for the generative model, that is, the generator. GAN learning is a game between the generator, which constructs synthetic data from random variables, and the discriminator, which separates synthetic data from real world data. The generator's goal is to construct data in such a way that the discriminator cannot tell them apart from real world data. Thus, the discriminator tries to minimize the synthetic-real discrimination error while the generator tries to maximize this error. Since training GANs is a game and its solution is a Nash equilibrium, gradient descent may fail to converge <ref type="bibr" target="#b57">[53,</ref><ref type="bibr" target="#b21">18,</ref><ref type="bibr" target="#b24">20]</ref>. Only local Nash equilibria are found, because gradient descent is a local optimization method. If there exists a local neighborhood around a point in parameter space where neither the generator nor the discriminator can unilaterally decrease their respective losses, then we call this point a local Nash equilibrium.  e convergence to a neighborhood is the best we can hereas by using diminishing step sizes, convergence bability one to the optimal points is made possible.</p><p>bility of The Stochastic Algorithm: The Biased Case: at when the gradient estimation error is biased, we ope to obtain almost sure convergence to the optimal . Instead, we have shown that provided that the biased asymptotically uniformly bounded, the iterates return ntraction region" infinitely often. In this example, we hat ? s (n) = ? (i,j) (n) and are uniformly bounded by a positive value. We also assume that ? s (n) ? N (0, 1) ) (n) ? N (0, 1), for all s and (i, j). lot the iterates (using the relative distance to the points) in <ref type="figure" target="#fig_2">Fig. 4</ref>, which is further "zoomed in" in t can be observed from <ref type="figure" target="#fig_2">Fig. 4</ref> that when the upperon the {? s , ? (i,j) } are small, the iterates return to orhood of the optimal solution. However, when the n errors are large, the recurrent behavior of the may not occur, and the iterates may diverge. This ates the theoretical analysis. We can further observe . 5 that the smaller the upper-bound is, the smaller the tion region" A ? becomes, indicating that the iterates "closer" to the optimal points.  In the previous sections, we have applied the dual decomposition method to Problem <ref type="bibr">(1)</ref> and devised the primal-dual algorithm, which is a single time-scale algorithm. As noted in Section I, there are many other decomposition methods. In particular, the primal decomposition method is a useful machinery for problem with coupled variables <ref type="bibr" target="#b35">[31]</ref>; and when some of the variables are fixed, the rest of the problem may decouple into several subproblems. This naturally yields multiple time-scale algorithms. It is also of great interest to examine the stability of the multiple time-scale algorithms in the presence of noisy feedback, and compare with the single time-scale algorithms, in terms of complexity and robustness.</p><p>To get a more concrete sense of the two time-scale algorithms based on primal decomposition, we consider the following NUM problem:</p><formula xml:id="formula_0">? 2 : maximize {ms ?xs ?Ms , p} s U s (x s ) subject to s:l?L(s) x s ? c l , ?l c l = h l (p), ?l p ? H,<label>(39)</label></formula><p>where the link capacities {c l } are functions of specific MAC parameters p (for instance, p can be transmission probabilities  <ref type="bibr" target="#b65">[61]</ref> which shows the distance of the parameter from the optimum for a one time-scale update of a 4 node network flow problem. When the upper bounds on the errors (?, ?) are small, the iterates oscillate and repeatedly return to a neighborhood of the optimal solution (see also Appendix Section A2.3). However, when the upper bounds on the errors are large, the iterates typically diverge.</p><p>To characterize the convergence properties of training general GANs is still an open challenge <ref type="bibr" target="#b23">[19,</ref><ref type="bibr" target="#b24">20]</ref>. For special GAN variants, convergence can be proved under certain assumptions <ref type="bibr" target="#b43">[39,</ref><ref type="bibr" target="#b26">22,</ref><ref type="bibr" target="#b60">56]</ref>. A prerequisit for many convergence proofs is local stability <ref type="bibr" target="#b39">[35]</ref> which was shown for GANs by Nagarajan and Kolter <ref type="bibr" target="#b50">[46]</ref> for a min-max GAN setting. However, Nagarajan and Kolter require for their proof either rather strong and unrealistic assumptions or a restriction to a linear discriminator. Recent convergence proofs for GANs hold for expectations over training samples or for the number of examples going to infinity <ref type="bibr" target="#b41">[37,</ref><ref type="bibr" target="#b49">45,</ref><ref type="bibr" target="#b44">40,</ref><ref type="bibr" target="#b7">4]</ref>, thus do not consider mini-batch learning which leads to a stochastic gradient <ref type="bibr" target="#b61">[57,</ref><ref type="bibr" target="#b29">25,</ref><ref type="bibr" target="#b46">42,</ref><ref type="bibr" target="#b42">38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Two Time-Scale Update Rule for GANs</head><p>We consider a discriminator D(.; w) with parameter vector w and a generator G(.; ?) with parameter vector ?. Learning is based on a stochastic gradientg(?, w) of the discriminator's loss function L D and a stochastic gradienth(?, w) of the generator's loss function L G . The loss functions L D and L G can be the original as introduced in Goodfellow et al. <ref type="bibr" target="#b21">[18]</ref>, its improved versions <ref type="bibr" target="#b24">[20]</ref>, or recently proposed losses for GANs like the Wasserstein GAN <ref type="bibr" target="#b6">[3]</ref>. Our setting is not restricted to min-max GANs, but is valid for all other, more general GANs for which the discriminator's loss function L D is not necessarily related to the generator's loss function L G . The gradientsg ?, w andh ?, w are stochastic, since they use mini-batches of m real world samples x (i) , 1 i m and m synthetic samples z (i) , 1 i m which are randomly chosen. If the true gradients are g(?, w) = ? w L D and h(?, w) = ? ? L G , then we can defineg(?, w) = g(?, w) + M (w) andh(?, w) = h(?, w) + M (?) with random variables M (w) and M <ref type="bibr">(?)</ref> . Thus, the gradientsg ?, w andh ?, w are stochastic approximations to the true gradients. Consequently, we analyze convergence of GANs by two time-scale stochastic approximations algorithms. For a two time-scale update rule (TTUR), we use the learning rates b(n) and a(n) for the discriminator and the generator update, respectively:</p><formula xml:id="formula_1">w n+1 = w n + b(n) g ? n , w n + M (w) n , ? n+1 = ? n + a(n) h ? n , w n + M (?) n . (1)</formula><p>For more details on the following convergence proof and its assumptions see Appendix Section A2.1. To prove convergence of GANs learned by TTUR, we make the following assumptions (The actual assumption is ended by , the following text are just comments and explanations):</p><p>(A1) The gradients h and g are Lipschitz.</p><p>Consequently, networks with Lipschitz smooth activation functions like ELUs (? = 1) <ref type="bibr" target="#b16">[13]</ref> fulfill the assumption but not ReLU networks.</p><formula xml:id="formula_2">(A2) n a(n) = ?, n a 2 (n) &lt; ?, n b(n) = ?, n b 2 (n) &lt; ?, a(n) = o(b(n)) (A3) The stochastic gradient errors {M (?) n } and {M (w) n } are martingale difference sequences w.r.t. the increasing ?-field F n = ?(? l , w l , M (?) l , M (w) l , l n), n 0 with E M (?) n 2 | F (?) n B 1 and E M (w) n 2 | F (w) n B 2 ,</formula><p>where B 1 and B 2 are positive deterministic constants. The original Assumption (A3) from Borkar 1997 follows from Lemma 2 in <ref type="bibr" target="#b10">[7]</ref> (see also <ref type="bibr" target="#b56">[52]</ref>). The assumption is fulfilled in the Robbins-Monro setting, where mini-batches are randomly sampled and the gradients are bounded.</p><p>(A4) For each ?, the ODE?(t) = g ?, w(t) has a local asymptotically stable attractor ?(?) within a domain of attraction G ? such that ? is Lipschitz. The ODE?(t) = h ?(t), ?(?(t)) has a local asymptotically stable attractor ? * within a domain of attraction. The discriminator must converge to a minimum for fixed generator parameters and the generator, in turn, must converge to a minimum for this fixed discriminator minimum. Borkar 1997 required unique global asymptotically stable equilibria <ref type="bibr">[9]</ref>. The assumption of global attractors was relaxed to local attractors via Assumption (A6) and Theorem 2.7 in Karmakar &amp; Bhatnagar <ref type="bibr" target="#b32">[28]</ref>. See for more details Assumption (A6) in the Appendix Section A2.1.3. Here, the GAN objectives may serve as Lyapunov functions. These assumptions of locally stable ODEs can be ensured by an additional weight decay term in the loss function which increases the eigenvalues of the Hessian. Therefore, problems with a region-wise constant discriminator that has zero second order derivatives are avoided. For further discussion see Appendix Section A2 (C3).</p><p>(A5) sup n ? n &lt; ? and sup n w n &lt; ?. Typically ensured by the objective or a weight decay term.</p><p>The next theorem has been proved in the seminal paper of Borkar 1997 <ref type="bibr">[9]</ref>.</p><p>Theorem 1 <ref type="bibr">(Borkar)</ref>. If the assumptions are satisfied, then the updates Eq. (1) converge to (? * , ?(? * )) a.s.</p><p>The solution (? * , ?(? * )) is a stationary local Nash equilibrium <ref type="bibr" target="#b54">[50]</ref>, since ? * as well as ?(? * ) are local asymptotically stable attractors with g ? * , ?(? * ) = 0 and h ? * , ?(? * ) = 0. An alternative approach to the proof of convergence using the Poisson equation for ensuring a solution to the fast update rule can be found in the Appendix Section A2.1.2. This approach assumes a linear update function in the fast update rule which, however, can be a linear approximation to a nonlinear gradient <ref type="bibr" target="#b34">[30,</ref><ref type="bibr" target="#b36">32]</ref>. For the rate of convergence see Appendix Section A2.2, where Section A2.2.1 focuses on linear and Section A2.2.2 on non-linear updates. For equal time-scales it can only be proven that the updates revisit an environment of the solution infinitely often, which, however, can be very large <ref type="bibr" target="#b65">[61,</ref><ref type="bibr" target="#b17">14]</ref>. For more details on the analysis of equal time-scales see Appendix Section A2.3. The main idea of the proof of Borkar <ref type="bibr">[9]</ref> is to use (T, ?) perturbed ODEs according to <ref type="bibr">Hirsch 1989 [24]</ref> (see also Appendix Section C of Bhatnagar, Prasad, &amp; Prashanth 2013 <ref type="bibr" target="#b11">[8]</ref>). The proof relies on the fact that there eventually is a time point when the perturbation of the slow update rule is small enough (given by ?) to allow the fast update rule to converge. For experiments with TTUR, we aim at finding learning rates such that the slow update is small enough to allow the fast to converge. Typically, the slow update is the generator and the fast update the discriminator. We have to adjust the two learning rates such that the generator does not affect discriminator learning in a undesired way and perturb it too much. However, even a larger learning rate for the generator than for the discriminator may ensure that the discriminator has low perturbations. Learning rates cannot be translated directly into perturbation since the perturbation of the discriminator by the generator is different from the perturbation of the generator by the discriminator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adam Follows an HBF ODE and Ensures TTUR Convergence</head><p>In our experiments, we aim at using Adam stochastic approximation to avoid mode collapsing. GANs suffer from "mode collapsing" where large masses of probability are mapped onto a few modes that cover only small regions. While these regions represent meaningful samples, the variety of the real world data is lost and only few prototype samples are generated. Different methods have been proposed to avoid mode collapsing <ref type="bibr" target="#b14">[11,</ref><ref type="bibr" target="#b47">43]</ref>. We obviate mode collapsing by using Adam stochastic approximation <ref type="bibr" target="#b33">[29]</ref>. Adam can be described as Heavy Ball with Friction (HBF) (see below), since it averages over past gradients. This averaging corresponds to a velocity that makes the generator resistant to getting pushed into small regions. Adam as an HBF method typically overshoots small local minima that correspond to mode collapse and can find flat minima which generalize well <ref type="bibr" target="#b30">[26]</ref>. <ref type="figure" target="#fig_5">Fig. 2</ref> depicts the dynamics of HBF, where the ball settles at a flat minimum. Next, we analyze whether GANs trained with TTUR converge when using Adam. For more details see Appendix Section A3. We recapitulate the Adam update rule at step n, with learning rate a, exponential averaging factors ? 1 for the first and ? 2 for the second moment of the gradient ?f (? n?1 ):</p><formula xml:id="formula_3">g n ?? ?f (? n?1 ) (2) m n ?? (? 1 /(1 ? ? n 1 )) m n?1 + ((1 ? ? 1 )/(1 ? ? n 1 )) g n v n ?? (? 2 /(1 ? ? n 2 )) v n?1 + ((1 ? ? 2 )/(1 ? ? n 2 )) g n g n ? n ?? ? n?1 ? a m n /( ? v n + )</formula><p>, where following operations are meant componentwise: the product , the square root ? ., and the division / in the last line. Instead of learning rate a, we introduce the damping coefficient a(n) with a(n) = an ?? for ? ? (0, 1]. Adam has parameters ? 1 for averaging the gradient and ? 2 parametrized by a positive ? for averaging the squared gradient. These parameters can be considered as defining a memory for Adam. To characterize ? 1 and ? 2 in the following, we define the exponential memory r(n) = r and the polynomial memory r(n) = r/ n l=1 a(l) for some positive constant r. The next theorem describes Adam by a differential equation, which in turn allows to apply the idea of (T, ?) perturbed ODEs to TTUR. Consequently, learning GANs with TTUR and Adam converges.</p><formula xml:id="formula_4">Theorem 2.</formula><p>If Adam is used with ? 1 = 1 ? a(n + 1)r(n), ? 2 = 1 ? ?a(n + 1)r(n) and with ?f as the full gradient of the lower bounded, continuously differentiable objective f , then for stationary second moments of the gradient, Adam follows the differential equation for Heavy Ball with Friction (HBF):? t + a(t)? t + ?f (? t ) = 0 .</p><p>(3)</p><p>Adam converges for gradients ?f that are L-Lipschitz.</p><p>Proof. Gadat et al. derived a discrete and stochastic version of Polyak's Heavy Ball method <ref type="bibr" target="#b53">[49]</ref>, the Heavy Ball with Friction (HBF) <ref type="bibr" target="#b20">[17]</ref>:</p><formula xml:id="formula_5">? n+1 = ? n ? a(n + 1) m n ,<label>(4)</label></formula><p>m n+1 = 1 ? a(n + 1) r(n) m n + a(n + 1) r(n) ?f (? n ) + M n+1 . These update rules are the first moment update rules of Adam <ref type="bibr" target="#b33">[29]</ref>. The HBF can be formulated as the differential equation Eq. (3) <ref type="bibr" target="#b20">[17]</ref>. Gadat et al. showed that the update rules Eq. (4) converge for loss functions f with at most quadratic grow and stated that convergence can be proofed for ?f that are L-Lipschitz <ref type="bibr" target="#b20">[17]</ref>. Convergence has been proved for continuously differentiable f that is quasiconvex (Theorem 3 in Goudou &amp; Munier <ref type="bibr" target="#b25">[21]</ref>). Convergence has been proved for ?f that is L-Lipschitz and bounded from below (Theorem 3.1 in Attouch et al. <ref type="bibr" target="#b8">[5]</ref>). Adam normalizes the average m n by the second moments v n of of the gradient g n : v n = E [g n g n ]. m n is componentwise divided by the square root of the components of v n . We assume that the second moments of g n are stationary, i.e., v = E [g n g n ]. In this case the normalization can be considered as additional noise since the normalization factor randomly deviates from its mean. In the HBF interpretation the normalization by ? v corresponds to introducing gravitation. We obtain</p><formula xml:id="formula_6">v n = 1 ? ? 2 1 ? ? n 2 n l=1 ? n?l 2 g l g l , ?v n = v n ? v = 1 ? ? 2 1 ? ? n 2 n l=1 ? n?l 2 (g l g l ? v) . (5)</formula><p>For a stationary second moment v and ? 2 = 1 ? ?a(n + 1)r(n), we have ?v n ? a(n + 1)r(n). We use a componentwise linear approximation to Adam's second moment normalization ? v can be componentwise incorporated into the gradient g which corresponds to rescaling the parameters without changing the minimum.</p><formula xml:id="formula_7">1/ ? v + ?v n ? 1/ ? v ? (1/(2v ? v)) ?v n + O(? 2 v n ), where all operations are meant componentwise. If we set M (v) n+1 = ?(m n ?v n )/(2v ? va(n + 1)r(n)), then m n / ? v n ? m n / ? v + a(n + 1)r(n)M (v) n+1 and E M (v) n+1 = 0, since E [g l g l ? v] = 0.</formula><p>According to Attouch et al. <ref type="bibr" target="#b8">[5]</ref> the energy, that is, a Lyapunov function, is E(t) = 1/2|?(t)| 2 +f (?(t)) and?(t) = ?a |?(t)| 2 &lt; 0. Since Adam can be expressed as differential equation and has a Lyapunov function, the idea of (T, ?) perturbed ODEs <ref type="bibr">[9,</ref><ref type="bibr" target="#b28">24,</ref><ref type="bibr" target="#b13">10]</ref> carries over to Adam. Therefore the convergence of Adam with TTUR can be proved via two time-scale stochastic approximation analysis like in Borkar <ref type="bibr">[9]</ref> for stationary second moments of the gradient.</p><p>In the Appendix we further discuss the convergence of two time-scale stochastic approximation algorithms with additive noise, linear update functions depending on Markov chains, nonlinear update functions, and updates depending on controlled Markov processes. Futhermore, the Appendix presents work on the rate of convergence for both linear and nonlinear update rules using similar techniques as the local stability analysis of Nagarajan and Kolter <ref type="bibr" target="#b50">[46]</ref>. Finally, we elaborate more on equal time-scale updates, which are investigated for saddle point problems and actor-critic learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>Performance Measure. Before presenting the experiments, we introduce a quality measure for models learned by GANs. The objective of generative learning is that the model produces data which matches the observed data. Therefore, each distance between the probability of observing real world data p w (.) and the probability of generating model data p(.) can serve as performance measure for generative models. However, defining appropriate performance measures for generative models is difficult <ref type="bibr" target="#b59">[55]</ref>. The best known measure is the likelihood, which can be estimated by annealed importance sampling <ref type="bibr" target="#b63">[59]</ref>. However, the likelihood heavily depends on the noise assumptions for the real data and can be dominated by single samples <ref type="bibr" target="#b59">[55]</ref>. Other approaches like density estimates have drawbacks, too <ref type="bibr" target="#b59">[55]</ref>. A well-performing approach to measure the performance of GANs is the "Inception Score" which correlates with human judgment <ref type="bibr" target="#b57">[53]</ref>. Generated samples are fed into an inception model that was trained on ImageNet. Images with meaningful objects are supposed to have low label (output) entropy, that is, they belong to few object classes. On the other hand, the entropy across images should be high, that is, the variance over the images should be large. Drawback of the Inception Score is that the statistics of real world samples are not used and compared to the statistics of synthetic samples. Next, we improve the Inception Score. The equality p(.) = p w (.) holds except for a non-measurable set if and only if p(.)f (x)dx = p w (.)f (x)dx for a basis f (.) spanning the function space in which p(.) and p w (.) live. These equalities of expectations are used to describe distributions by moments or cumulants, where f (x) are polynomials of the data x. We generalize these polynomials by replacing x by the coding layer of an inception model in order to obtain vision-relevant features. For practical reasons we only consider the first two polynomials, that is, the first two moments: mean and covariance. The Gaussian is the maximum entropy distribution for given mean and covariance, therefore we assume the coding units to follow a multidimensional Gaussian. The difference of two Gaussians (synthetic and real-world images) is measured by the Fr?chet distance <ref type="bibr" target="#b19">[16]</ref> also known as Wasserstein-2 distance <ref type="bibr" target="#b62">[58]</ref>. We call the Fr?chet distance d(., .) between the Gaussian with mean (m, C) obtained from p(.) and the Gaussian with mean (m w , C w ) obtained from p w (.) the "Fr?chet Inception Distance" (FID), which is given by <ref type="bibr" target="#b18">[15]</ref>:</p><formula xml:id="formula_8">d 2 ((m, C), (m w , C w )) = m ? m w 2 2 + Tr C + C w ? 2 CC w 1/2 .<label>(6)</label></formula><p>Next we show that the FID is consistent with increasing disturbances and human judgment. <ref type="figure" target="#fig_7">Fig. 3</ref> evaluates the FID for Gaussian noise, Gaussian blur, implanted black rectangles, swirled images, salt and pepper noise, and CelebA dataset contaminated by ImageNet images. The FID captures the disturbance level very well. In the experiments we used the FID to evaluate the performance of GANs. For more details and a comparison between FID and Inception Score see Appendix Section A1, where we show that FID is more consistent with the noise level than the Inception Score.</p><p>Model Selection and Evaluation. We compare the two time-scale update rule (TTUR) for GANs with the original GAN training to see whether TTUR improves the convergence speed and performance of GANs. We have selected Adam stochastic optimization to reduce the risk of mode collapsing. The advantage of Adam has been confirmed by MNIST experiments, where Adam indeed considerably reduced the cases for which we observed mode collapsing. Although TTUR ensures that the discriminator converges during learning, practicable learning rates must be found for each experiment. We face a trade-off since the learning rates should be small enough (e.g. for the generator) to ensure convergence but at the same time should be large enough to allow fast learning. For each of the experiments, the learning rates have been optimized to be large while still ensuring stable training which is indicated by a decreasing FID or Jensen-Shannon-divergence (JSD). We further fixed the time point for stopping training to the update step when the FID or Jensen-Shannon-divergence of the best models was no longer decreasing. For some models, we observed that the FID diverges or starts to increase at a certain time point. An example of this behaviour is shown in <ref type="figure" target="#fig_3">Fig. 5</ref>. The performance of generative models is evaluated via the Fr?chet Inception Distance (FID) introduced above. For the One Billion Word experiment, the normalized JSD served as performance measure. For computing the FID, we propagated all images from the training dataset through the pretrained Inception-v3 model following the computation of the Inception Score <ref type="bibr" target="#b57">[53]</ref>, however, we use the last pooling layer as coding layer. For this coding layer, we calculated the mean m w and the covariance matrix C w . Thus, we approximate the first and second central moment of the function given by the Inception coding layer under the real world distribution. To approximate these moments for the model distribution, we generate 50,000 images, propagate them through the Inception-v3 model, and then compute the mean m and the covariance matrix C. For computational efficiency, we evaluate the FID every 1,000 DCGAN mini-batch updates, every 5,000 WGAN-GP outer iterations for the image experiments, and every 100 outer iterations for the WGAN-GP language model. For the one time-scale updates a WGAN-GP outer iteration for the image model consists of five discriminator mini-batches and ten discriminator mini-batches for the language model, where we follow the original implementation. For TTUR however, the discriminator is updated only once per iteration. We repeat the training for each single time-scale (orig) and TTUR learning rate eight times for the image datasets and ten times for the language benchmark. Additionally to the mean FID training progress we show the minimum and maximum FID over all runs at each evaluation time-step. For more details, implementations and further results see Appendix Section A4 and A6.</p><p>Simple Toy Data. We first want to demonstrate the difference between a single time-scale update rule and TTUR on a simple toy min/max problem where a saddle point should be found. The objective f (x, y) = (1 + x 2 )(100 ? y 2 ) in <ref type="figure" target="#fig_2">Fig. 4</ref> (left) has a saddle point at (x, y) = (0, 0) and fulfills assumption A4. The norm (x, y) measures the distance of the parameter vector (x, y) to the saddle point. We update (x, y) by gradient descent in x and gradient ascent in y using additive Gaussian noise in order to simulate a stochastic update. The updates should converge to the saddle point (x, y) = (0, 0) with objective value f (0, 0) = 100 and the norm 0. In <ref type="figure" target="#fig_2">Fig. 4</ref> (right), the first two rows show one time-scale update rules. The large learning rate in the first row diverges and has large fluctuations. The smaller learning rate in the second row converges but slower than the TTUR in the third row which has slow x-updates. TTUR with slow y-updates in the fourth row also converges but slower.  with the original learning method (orig) and with TTUR. The original training method is faster at the beginning, but TTUR eventually achieves better performance. DCGAN trained TTUR reaches constantly a lower FID than the original method and for CelebA and LSUN Bedrooms all one time-scale runs diverge. For DCGAN the learning rate of the generator is larger then that of the discriminator, which, however, does not contradict the TTUR theory (see the Appendix Section A5).</p><p>In <ref type="table" target="#tab_0">Table 1</ref> we report the best FID with TTUR and one time-scale training for optimized number of updates and learning rates. TTUR constantly outperforms standard training and is more stable.</p><p>WGAN-GP on Image Data. We used the WGAN-GP image model <ref type="bibr" target="#b27">[23]</ref> to test TTUR with the CIFAR-10 and LSUN Bedrooms datasets. In contrast to the original code where the discriminator is trained five times for each generator update, TTUR updates the discriminator only once, therefore we align the training progress with wall-clock time. The learning rate for the original training was optimized to be large but leads to stable learning. TTUR can use a higher learning rate for the discriminator since TTUR stabilizes learning. <ref type="figure">Fig. 6</ref> shows the FID during learning with the original learning method and with TTUR. <ref type="table" target="#tab_0">Table 1</ref> shows the best FID with TTUR and one time-scale training for optimized number of iterations and learning rates. Again TTUR reaches lower FIDs than one time-scale training. WGAN-GP on Language Data. Finally the One Billion Word Benchmark <ref type="bibr" target="#b15">[12]</ref> serves to evaluate TTUR on WGAN-GP. The character-level generative language model is a 1D convolutional neural network (CNN) which maps a latent vector to a sequence of one-hot character vectors of dimension 32 given by the maximum of a softmax output. The discriminator is also a 1D CNN applied to sequences of one-hot vectors of 32 characters. Since the FID criterium only works for images, we measured the performance by the Jensen-Shannon-divergence (JSD) between the model and the real world distribution as has been done previously <ref type="bibr" target="#b27">[23]</ref>. In contrast to the original code where the critic is trained ten times for each generator update, TTUR updates the discriminator only once, therefore we align the training progress with wall-clock time. The learning rate for the original training was optimized to be large but leads to stable learning. TTUR can use a higher learning rate for the discriminator since TTUR stabilizes learning. We report for the 4 and 6-gram word evaluation the normalized mean JSD for ten runs for original training and TTUR training in <ref type="figure">Fig. 7</ref>. In <ref type="table" target="#tab_0">Table 1</ref> we report the best JSD at an optimal time-step where TTUR outperforms the standard training for both measures. The improvement of TTUR on the 6-gram statistics over original training shows that TTUR enables to learn to generate more subtle pseudo-words which better resembles real words. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>For learning GANs, we have introduced the two time-scale update rule (TTUR), which we have proved to converge to a stationary local Nash equilibrium. Then we described Adam stochastic optimization as a heavy ball with friction (HBF) dynamics, which shows that Adam converges and that Adam tends to find flat minima while avoiding small local minima. A second order differential equation describes the learning dynamics of Adam as an HBF system. Via this differential equation, the convergence of GANs trained with TTUR to a stationary local Nash equilibrium can be extended to Adam. Finally, to evaluate GANs, we introduced the 'Fr?chet Inception Distance" (FID) which captures the similarity of generated images to real ones better than the Inception Score. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A1 Fr?chet Inception Distance (FID)</head><p>We improve the Inception score for comparing the results of GANs <ref type="bibr" target="#b57">[53]</ref>. The Inception score has the disadvantage that it does not use the statistics of real world samples and compare it to the statistics of synthetic samples. Let p(.) be the distribution of model samples and p w (.) the distribution of the samples from real world. The equality p(.) = p w (.) holds except for a non-measurable set if and only if p(.)f (x)dx = p w (.)f (x)dx for a basis f (.) spanning the function space in which p(.) and p w (.) live. These equalities of expectations are used to describe distributions by moments or cumulants, where f (x) are polynomials of the data x. We replacing x by the coding layer of an Inception model in order to obtain vision-relevant features and consider polynomials of the coding unit functions. For practical reasons we only consider the first two polynomials, that is, the first two moments: mean and covariance. The Gaussian is the maximum entropy distribution for given mean and covariance, therefore we assume the coding units to follow a multidimensional Gaussian. The difference of two Gaussians is measured by the Fr?chet distance <ref type="bibr" target="#b19">[16]</ref> also known as Wasserstein-2 distance <ref type="bibr" target="#b62">[58]</ref>. The Fr?chet distance d(., .) between the Gaussian with mean and covariance (m, C) obtained from p(.) and the Gaussian (m w , C w ) obtained from p w (.) is called the "Fr?chet Inception Distance" (FID), which is given by <ref type="bibr" target="#b18">[15]</ref>:</p><formula xml:id="formula_9">d 2 ((m, C), (m w , C w )) = m ? m w 2 2 + Tr C + C w ? 2 CC w 1/2 .<label>(7)</label></formula><p>Next we show that the FID is consistent with increasing disturbances and human judgment on the CelebA dataset. We computed the (m w , C w ) on all CelebA images, while for computing (m, C) we used 50,000 randomly selected samples. We considered following disturbances of the image X: Consider the coordinate (x, y) in the noisy (swirled) image for which we want to find the color. Towards this end we need the reverse mapping for the swirl transformation which gives the location which is mapped to (x, y). We first compute polar coordinates relative to a center (x 0 , y 0 ) given by the angle ? = arctan((y ? y 0 )/(x ? x 0 )) and the radius r = (x ? x 0 ) 2 + (y ? y 0 ) 2 . We transform them according to ? = ? + ?e ?5r/(ln 2?) .</p><p>Here ? is a parameter for the amount of swirl and ? indicates the swirl extent in pixels. The original coordinates, where the color for (x, y) can be found, are x org = x 0 + r cos(? ) and y org = y 0 + r sin(? ). We set (x 0 , y 0 ) to the center of the image and ? = 25. The disturbance level is given by the amount of swirl ? ? {0, 1, 2, 4}. The larger ? is, the larger is the disturbance of the image via the amount of swirl. 5. Salt and pepper noise: Some pixels of the image are set to black or white, where black is chosen with 50% probability (same for white). Pixels are randomly chosen for being flipped to white or black, where the ratio of pixel flipped to white or black is given by the noise level ? ? {0, 0.1, 0.2, 0.3}. The larger ? is, the larger is the noise added to the image via flipping pixels to white or black, the larger is the disturbance level. 6. ImageNet contamination: From each of the 1,000 ImageNet classes, 5 images are randomly chosen, which gives 5,000 ImageNet images. The images are ensured to be RGB and to have a minimal size of 256x256. A percentage of ? ? {0, 0.25, 0.5, 0.75} of the CelebA images has been replaced by ImageNet images. ? = 0 means all images are from CelebA, ? = 0.25 means that 75% of the images are from CelebA and 25% from ImageNet etc. The larger ? is, the larger is the disturbance of the CelebA dataset by contaminating it by ImageNet images. The larger the disturbance level is, the more the dataset deviates from the reference real world dataset.</p><p>We compare the Inception Score <ref type="bibr" target="#b57">[53]</ref> with the FID. The Inception Score with m samples and K classes is</p><formula xml:id="formula_10">exp 1 m m i=1 K k=1 p(y k | X i ) log p(y k | X i ) p(y k ) .<label>(8)</label></formula><p>The FID is a distance, while the Inception Score is a score. To compare FID and Inception Score, we transform the Inception Score to a distance, which we call "Inception Distance" (IND). This transformation to a distance is possible since the Inception Score has a maximal value. For zero probability p(y k | X i ) = 0, we set the value p(y k | X i ) log p(y k |Xi) p(y k ) = 0. We can bound the log-term by</p><formula xml:id="formula_11">log p(y k | X i ) p(y k ) log 1 1/m = log m .<label>(9)</label></formula><p>Using this bound, we obtain an upper bound on the Inception Score:</p><formula xml:id="formula_12">exp 1 m m i=1 K k=1 p(y k | X i ) log p(y k | X i ) p(y k )<label>(10)</label></formula><formula xml:id="formula_13">exp log m 1 m m i=1 K k=1 p(y k | X i ) (11) = exp log m 1 m m i=1 1 = m .<label>(12)</label></formula><p>The upper bound is tight and achieved if m K and every sample is from a different class and the sample is classified correctly with probability 1. The IND is computed "IND = m -Inception Score", therefore the IND is zero for a perfect subset of the ImageNet with m &lt; K samples, where each sample stems from a different class. Therefore both distances should increase with increasing disturbance level. In <ref type="figure">Figure A8</ref> we present the evaluation for each kind of disturbance. The larger the disturbance level is, the larger the FID and IND should be. In <ref type="figure">Figure A9</ref>, A10, A11, and A11 we show examples of images generated with DCGAN trained on CelebA with FIDs 500, 300, 133, 100, 45, 13, and FID 3 achieved with WGAN-GP on CelebA.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2 Two Time-Scale Stochastic Approximation Algorithms</head><p>Stochastic approximation algorithms are iterative procedures to find a root or a stationary point (minimum, maximum, saddle point) of a function when only noisy observations of its values or its derivatives are provided. Two time-scale stochastic approximation algorithms are two coupled iterations with different step sizes. For proving convergence of these interwoven iterates it is assumed that one step size is considerably smaller than the other. The slower iterate (the one with smaller step size) is assumed to be slow enough to allow the fast iterate converge while being perturbed by the the slower. The perturbations of the slow should be small enough to ensure convergence of the faster.</p><p>The iterates map at time step n 0 the fast variable w n ? R k and the slow variable ? n ? R m to their new values:</p><formula xml:id="formula_14">? n+1 = ? n + a(n) h ? n , w n , Z (?) n + M (?) n ,<label>(13)</label></formula><formula xml:id="formula_15">w n+1 = w n + b(n) g ? n , w n , Z (w) n + M (w) n .<label>(14)</label></formula><p>The iterates use</p><p>? h(.) ? R m : mapping for the slow iterate Eq. (13),</p><p>? g(.) ? R k : mapping for the fast iterate Eq. <ref type="formula" target="#formula_5">(14)</ref>,</p><p>? a(n): step size for the slow iterate Eq. (13),</p><p>? b(n): step size for the fast iterate Eq. <ref type="formula" target="#formula_5">(14)</ref>,</p><p>? M </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.1 Convergence of Two Time-Scale Stochastic Approximation Algorithms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.1.1 Additive Noise</head><p>The first result is from <ref type="bibr">Borkar 1997 [9]</ref> which was generalized in <ref type="bibr">Konda and Borkar 1999 [31]</ref>. Borkar considered the iterates:</p><formula xml:id="formula_16">? n+1 = ? n + a(n) h ? n , w n + M (?) n ,<label>(15)</label></formula><formula xml:id="formula_17">w n+1 = w n + b(n) g ? n , w n + M (w) n .<label>(16)</label></formula><p>Assumptions. We make the following assumptions: (A2) Assumptions on the learning rates:</p><formula xml:id="formula_18">n a(n) = ? , n a 2 (n) &lt; ? ,<label>(17)</label></formula><formula xml:id="formula_19">n b(n) = ? , n b 2 (n) &lt; ? ,<label>(18)</label></formula><formula xml:id="formula_20">a(n) = o(b(n)) ,<label>(19)</label></formula><p>(A3) Assumptions on the noise: For the increasing ?-field</p><formula xml:id="formula_21">F n = ?(? l , w l , M (?) l , M (w) l</formula><p>, l n), n 0 , the sequences of random variables (M</p><formula xml:id="formula_22">(?) n , F n ) and (M (w) n , F n ) satisfy n a(n) M (?) n &lt; ? a.s. (20) n b(n) M (w) n &lt; ? a.s. .<label>(21)</label></formula><p>(A4) Assumption on the existence of a solution of the fast iterate: For each ? ? R m , the OD?</p><formula xml:id="formula_23">w(t) = g ?, w(t)<label>(22)</label></formula><p>has a unique global asymptotically stable equilibrium ?(?) such that ? : R m ? R k is Lipschitz.</p><p>(A5) Assumption on the existence of a solution of the slow iterate: The OD?</p><formula xml:id="formula_24">?(t) = h ?(t), ?(?(t))<label>(23)</label></formula><p>has a unique global asymptotically stable equilibrium ? * .</p><p>(A6) Assumption of bounded iterates:</p><formula xml:id="formula_25">sup n ? n &lt; ? ,<label>(24)</label></formula><p>sup n w n &lt; ? .</p><p>Convergence Theorem The next theorem is from Borkar 1997 <ref type="bibr">[9]</ref>. Theorem 3 <ref type="bibr">(Borkar)</ref>. If the assumptions are satisfied, then the iterates Eq.   (C3) We address assumption (A4) with weight decay in two ways: (I) Weight decay avoids problems with a discriminator that is region-wise constant and, therefore, does not have a locally stable generator. If the generator is perfect, then the discriminator is 0.5 everywhere. Since the discriminator is locally constant, the generator has gradient zero and cannot improve. Also the discriminator cannot improve, since it has minimal error given the current generator. However, without weight decay the Nash Equilibrium is not stable since the second order derivatives are zero, too. (II) Weight decay avoids that the generator is driven to infinity with unbounded weights. For example a linear discriminator can supply a gradient for the generator outside each bounded region.</p><p>(C4) The main result used in the proof of the theorem relies on work on perturbations of ODEs according to <ref type="bibr">Hirsch 1989 [24]</ref>.</p><p>(C5) <ref type="bibr">Konda and Borkar 1999 [31]</ref> generalized the convergence proof to distributed asynchronous update rules.</p><p>(C6) Tadi? relaxed the assumptions for showing convergence <ref type="bibr" target="#b58">[54]</ref>. In particular the noise assumptions (Assumptions A2 in <ref type="bibr" target="#b58">[54]</ref>) do not have to be martingale difference sequences and are more general than in <ref type="bibr">[9]</ref>. In another result the assumption of bounded iterates is not necessary if other assumptions are ensured <ref type="bibr" target="#b58">[54]</ref>. Finally, Tadi? considers the case of non-additive noise <ref type="bibr" target="#b58">[54]</ref>. Tadi? does not provide proofs for his results. We were not able to find such proofs even in other publications of Tadi?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.1.2 Linear Update, Additive Noise, and Markov Chain</head><p>In contrast to the previous subsection, we assume that an additional Markov chain influences the iterates <ref type="bibr" target="#b34">[30,</ref><ref type="bibr" target="#b36">32]</ref>. The Markov chain allows applications in reinforcement learning, in particular in actor-critic setting where the Markov chain is used to model the environment. The slow iterate is the actor update while the fast iterate is the critic update. For reinforcement learning both the actor and the critic observe the environment which is driven by the actor actions. The environment observations are assumed to be a Markov chain. The Markov chain can include eligibility traces which are modeled as explicit states in order to keep the Markov assumption.</p><p>The Markov chain is the sequence of observations of the environment which progresses via transition probabilities. The transitions are not affected by the critic but by the actor.</p><p>Konda et al. considered the iterates <ref type="bibr" target="#b34">[30,</ref><ref type="bibr" target="#b36">32]</ref>:</p><formula xml:id="formula_27">? n+1 = ? n + a(n) H n ,<label>(26)</label></formula><formula xml:id="formula_28">w n+1 = w n + b(n) g Z (w) n ; ? n + G Z (w) n ; ? n w n + M (w) n w n .<label>(27)</label></formula><p>H n is a random process that drives the changes of ? n . We assume that H n is a slow enough process. We have a linear update rule for the fast iterate using the vector function g(.) ? R k and the matrix function G(.) ? R k?k .</p><p>Assumptions. We make the following assumptions:</p><p>(A1) Assumptions on the Markov process, that is, the transition kernel: The stochastic process Z (w) n takes values in a Polish (complete, separable, metric) space Z with the Borel ?-field</p><formula xml:id="formula_29">F n = ?(? l , w l , Z (w) l</formula><p>, H l , l n), n 0 . For every measurable set A ? Z and the parametrized transition kernel P(.; ? n ) we have:</p><formula xml:id="formula_30">P(Z (w) n+1 ? A | F n ) = P(Z (w) n+1 ? A | Z (w)</formula><p>n ; ? n ) = P(Z (w) n , A; ? n ) . (A2) Assumptions on the learning rates:</p><formula xml:id="formula_31">n b(n) = ? , n b 2 (n) &lt; ? ,<label>(29)</label></formula><formula xml:id="formula_32">n a(n) b(n) d &lt; ? ,<label>(30)</label></formula><p>for some d &gt; 0.</p><p>(A3) Assumptions on the noise: The sequence M (w) n is a k ? k-matrix valued F n -martingale difference with bounded moments:</p><formula xml:id="formula_33">E M (w) n | F n = 0 ,<label>(31)</label></formula><formula xml:id="formula_34">sup n E M (w) n d &lt; ? , ?d &gt; 0 .<label>(32)</label></formula><p>We assume slowly changing ?, therefore the random process H n satisfies </p><formula xml:id="formula_35">sup n E H n d &lt; ? , ?d &gt; 0 .<label>(33)</label></formula><formula xml:id="formula_36">max{ ?(?) } C ,<label>(36)</label></formula><formula xml:id="formula_37">max{ ? (?) } C .<label>(37)</label></formula><p>(b) Boundedness in expectation: All moments are bounded. For any d &gt; 0, there exists</p><formula xml:id="formula_38">C d &gt; 0 such that sup n E ?(Z (w) n ; ?) d C d ,<label>(38)</label></formula><formula xml:id="formula_39">sup n E g(Z (w) n ; ?) d C d ,<label>(39)</label></formula><formula xml:id="formula_40">sup n E ? (Z (w) n ; ?) d C d ,<label>(40)</label></formula><formula xml:id="formula_41">sup n E G(Z (w) n ; ?) d C d .<label>(41)</label></formula><p>(c) Lipschitz continuity of solutions: For some constant C &gt; 0 and for all ?,? ? R m :</p><formula xml:id="formula_42">?(?) ??(?) C ? ?? ,<label>(42)</label></formula><formula xml:id="formula_43">? (?) ??(?) C ? ?? .<label>(43)</label></formula><p>(d) Lipschitz continuity in expectation: There exists a positive measurable function C(.) on Z such that</p><formula xml:id="formula_44">sup n E C(Z (w) n ) d &lt; ? , ?d &gt; 0 .<label>(44)</label></formula><p>Function C(.) gives the Lipschitz constant for every z:</p><formula xml:id="formula_45">(P ?? (.; ?))(z) ? (P??(.;?))(z) C(z) ? ?? ,<label>(45)</label></formula><p>(P ?? (.; ?))(z) ? (P??(.;?))(z)</p><formula xml:id="formula_46">C(z) ? ?? .<label>(46)</label></formula><p>(e) Uniform positive definiteness: There exists some ? &gt; 0 such that for all w ? R k and ? ? R m :</p><formula xml:id="formula_47">w T? (?) w ? w 2 .<label>(47)</label></formula><p>Convergence Theorem. We report Theorem 3.2 (see also </p><formula xml:id="formula_48">lim n?? ? (? n ) w n ??(? n ) = 0 a.s. ,<label>(48)</label></formula><formula xml:id="formula_49">lim n?? w n ?? ?1 (? n )?(? n ) = 0 .<label>(49)</label></formula><p>Comments.</p><p>(C1) The proofs only use the boundedness of the moments of H n <ref type="bibr" target="#b34">[30,</ref><ref type="bibr" target="#b36">32]</ref>, therefore H n may depend on w n . In his PhD thesis <ref type="bibr" target="#b34">[30]</ref>, Vijaymohan Konda used this framework for the actor-critic learning, where H n drives the updates of the actor parameters ? n . However, the actor updates are based on the current parameters w n of the critic.</p><p>(C2) The random process Z (w) n can affect H n as long as boundedness is ensured.</p><formula xml:id="formula_50">(C3) Nonlinear update rule. g Z (w) n ; ? n + G Z (w)</formula><p>n ; ? n w n can be viewed as a linear approximation of a nonlinear update rule. The nonlinear case has been considered in <ref type="bibr" target="#b34">[30]</ref> where additional approximation errors due to linearization were addressed. These errors are treated in the given framework <ref type="bibr" target="#b34">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.1.3 Additive Noise and Controlled Markov Processes</head><p>The most general iterates use nonlinear update functions g and h, have additive noise, and have controlled Markov processes <ref type="bibr" target="#b32">[28]</ref>.</p><formula xml:id="formula_51">? n+1 = ? n + a(n) h ? n , w n , Z (?) n + M (?) n ,<label>(50)</label></formula><formula xml:id="formula_52">w n+1 = w n + b(n) g ? n , w n , Z (w) n + M (w) n .<label>(51)</label></formula><p>Required Definitions. Marchaud Map: A set-valued map h : R l ? {subsets of R k } is called a Marchaud map if it satisfies the following properties:</p><p>(i) For each ? ? R l , h(?) is convex and compact.</p><p>(ii) (point-wise boundedness) For each ? ? R l , sup w?h(?) w &lt; K (1 + ? ) for some K &gt; 0.</p><p>(iii) h is an upper-semicontinuous map. We say that h is upper-semicontinuous, if given sequences {? n } n?1 (in R l ) and {y n } n?1 (in R k ) with ? n ? ?, y n ? y and y n ? h(? n ), n ? 1, y ? h(?). In other words, the graph of h, (x, y) :</p><formula xml:id="formula_53">y ? h(x), x ? R l , is closed in R l ? R k .</formula><p>If the set-valued map H : R m ? {subsets of R m } is Marchaud, then the differential inclusion (DI) given by?</p><formula xml:id="formula_54">(t) ? H(?(t))<label>(52)</label></formula><p>is guaranteed to have at least one solution that is absolutely continuous. If ? is an absolutely continuous map satisfying Eq. (52) then we say that ? ? ?.</p><p>Invariant Set: M ? R m is invariant if for every ? ? M there exists a trajectory, ?, entirely in M with ?(0) = ?. In other words, ? ? ? with ?(t) ? M , for all t ? 0.</p><p>Internally Chain Transitive Set: M ? R m is said to be internally chain transitive if M is compact and for every ?, y ? M , &gt; 0 and T &gt; 0 we have the following: There exist ? 1 , . . . , ? n that are n solutions to the differential inclusion?(t) ? h(?(t)), a sequence ? 1 (= ?), . . . , ? n+1 (= y) ? M and n real numbers t 1 , t 2 , . . . , t n greater than T such that:</p><formula xml:id="formula_55">? i ti (? i ) ? N (? i+1 ) where N (?) is the open -neighborhood of ? and ? i [0,ti] (? i ) ? M for 1 ? i ? n.</formula><p>The sequence (? 1 (= ?), . . . , ? n+1 (= y)) is called an ( , T ) chain in M from ? to y.</p><p>Assumptions. We make the following assumptions <ref type="bibr" target="#b32">[28]</ref>: </p><formula xml:id="formula_56">(</formula><formula xml:id="formula_57">P(Z (?) n+1 ? B (?) |Z (?) l , A (?) l , ? l , w l , l n) = B (?) p (?) (dz|Z (?) n , A (?) n , ? n , w n ), n 0 ,<label>(53)</label></formula><p>for</p><formula xml:id="formula_58">B (?) Borel in S (?) . The {Z (w) n } dynamics is P(Z (w) n+1 ? B (w) |Z (w) l , A (w) l , ? l , w l , l n) = B (w) p (w) (dz|Z (w) n , A (w) n , ? n , w n ), n 0 ,<label>(54)</label></formula><p>for B (w) Borel in S (w) .</p><p>(A2) Assumptions on the update functions: h : R m+k ? S (?) ? R m is jointly continuous as well as Lipschitz in its first two arguments uniformly w.r.t. the third. The latter condition means that</p><formula xml:id="formula_59">?z (?) ? S (?) : h(?, w, z (?) ) ? h(? , w , z (?) ) L (?) ( ? ? ? + w ? w ) .<label>(55)</label></formula><p>Note that the Lipschitz constant L (?) does not depend on z (?) .</p><p>g : R k+m ? S (w) ? R k is jointly continuous as well as Lipschitz in its first two arguments uniformly w.r.t. the third. The latter condition means that</p><formula xml:id="formula_60">?z (w) ? S (w) : g(?, w, z (w) ) ? g(? , w , z (w) ) L (w) ( ? ? ? + w ? w ) .<label>(56)</label></formula><p>Note that the Lipschitz constant L (w) does not depend on z (w) . n } are martingale difference sequence with second moments bounded by K(1 + ? n 2 + w n 2 ). More precisely, {M (?) n } is a martingale difference sequence w.r.t. increasing ?-fields</p><formula xml:id="formula_61">F n = ?(? l , w l , M (?) l , M (w) l , Z (?) l , Z (w) l , l n), n 0 ,<label>(57)</label></formula><formula xml:id="formula_62">satisfying E M (?) n+1 2 | F n K (1 + ? n 2 + w n 2 ) ,<label>(58)</label></formula><p>for n 0 and a given constant K &gt; 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>{M (w)</head><p>n } is a martingale difference sequence w.r.t. increasing ?-fields</p><formula xml:id="formula_63">F n = ?(? l , w l , M (?) l , M (w) l , Z (?) l , Z (w) l , l n), n 0 ,<label>(59)</label></formula><p>satisfying</p><formula xml:id="formula_64">E M (w) n+1 2 | F n K (1 + ? n 2 + w n 2 ) ,<label>(60)</label></formula><p>for n 0 and a given constant K &gt; 0.</p><p>(A4) Assumptions on the learning rates:</p><formula xml:id="formula_65">n a(n) = ? , n a 2 (n) &lt; ? ,<label>(61)</label></formula><formula xml:id="formula_66">n b(n) = ? , n b 2 (n) &lt; ? ,<label>(62)</label></formula><formula xml:id="formula_67">a(n) = o(b(n)) ,<label>(63)</label></formula><p>Furthermore, a(n), b(n), n 0 are non-increasing.</p><p>(A5) Assumptions on the controlled Markov processes, that is, the transition kernels: The stateaction map</p><formula xml:id="formula_68">S (?) ? U (?) ? R m+k (z (?) , a (?) , ?, w) ? p (?) (dy | z (?) , a (?) , ?, w)<label>(64)</label></formula><p>and the state-action map</p><formula xml:id="formula_69">S (w) ? U (w) ? R m+k (z (w) , a (w) , ?, w) ? p (w) (dy | z (w) , a (w) , ?, w)<label>(65)</label></formula><p>are continuous.</p><p>(A6) Assumptions on the existence of a solution:</p><p>We consider occupation measures which give for the controlled Markov process the probability or density to observe a particular state-action pair from S ? U for given ? and a given control policy ?. We denote by D (w) (?, w) the set of all ergodic occupation measures for the prescribed ? and w on state-action space S (w) ? U (?) for the controlled Markov process Z (w) with policy ? (w) . Analogously we denote, by D (?) (?, w) the set of all ergodic occupation measures for the prescribed ? and w on state-action space S (?) ? U (?) for the controlled Markov process Z (?) with policy ? (?) . Defin?</p><formula xml:id="formula_70">g(?, w, ?) = g(?, w, z) ?(dz, U (w) )<label>(66)</label></formula><p>for ? a measure on S (w) ? U (w) and the Marchaud map</p><formula xml:id="formula_71">g(?, w) = {g(?, w, ?) : ? ? D (w) (?, w)} .<label>(67)</label></formula><p>We assume that the set D (w) (?, w) is singleton, that is,?(?, w) contains a single function and we use the same notation for the set and its single element. If the set is not a singleton, the assumption of a solution can be expressed by the differential inclusion?(t) ??(?, w(t)) <ref type="bibr" target="#b32">[28]</ref>.</p><p>?? ? R m , the ODE?</p><formula xml:id="formula_72">(t) =?(?, w(t))<label>(68)</label></formula><p>has an asymptotically stable equilibrium ?(?) with domain of attraction G ? where ? :</p><formula xml:id="formula_73">R m ? R k is a Lipschitz map with constant K. Moreover, the function V : G ? [0, ?) is continuously differentiable where V (?, .) is the Lyapunov function for ?(?) and G = {(?, w) : w ? G ? , ? ? R m }.</formula><p>This extra condition is needed so that the set {(?, ?(?)) : ? ? R m } becomes an asymptotically stable set of the coupled OD? w(t) =?(?(t), w(t)) (69)</p><formula xml:id="formula_74">?(t) = 0 .<label>(70)</label></formula><p>(A7) Assumption of bounded iterates:</p><formula xml:id="formula_75">sup n ? n &lt; ? a.s. ,<label>(71)</label></formula><p>sup n w n &lt; ? a.s.</p><p>Convergence Theorem. The following theorem is from Karmakar &amp; Bhatnagar <ref type="bibr" target="#b32">[28]</ref>: Theorem 5 <ref type="bibr">(Karmakar &amp; Bhatnagar)</ref>. Under above assumptions if for all ? ? R m , with probability 1, {w n } belongs to a compact subset Q ? (depending on the sample point) of G ? "eventually", then</p><formula xml:id="formula_77">(? n , w n ) ? ? ? * ?A0 (? * , ?(? * )) a.s. as n ? ? ,<label>(73)</label></formula><p>where A 0 = ? t 0 {?(s) : s t} which is almost everywhere an internally chain transitive set of the differential inclusion?</p><formula xml:id="formula_78">(t) ??(?(t)),<label>(74)</label></formula><formula xml:id="formula_79">where?(?) = {h(?, ?(?), ?) : ? ? D (w) (?, ?(?))}.</formula><p>Comments.</p><p>(C1) This framework allows to show convergence for gradient descent methods beyond stochastic gradient like for the ADAM procedure where current learning parameters are memorized and updated. The random processes Z (w) and Z (?) may track the current learning status for the fast and slow iterate, respectively.</p><p>(C2) Stochastic regularization like dropout is covered via the random processes A (w) and A (?) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.2 Rate of Convergence of Two Time-Scale Stochastic Approximation Algorithms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.2.1 Linear Update Rules</head><p>First we consider linear iterates according to the PhD thesis of Konda <ref type="bibr" target="#b34">[30]</ref> and Konda &amp; Tsitsiklis <ref type="bibr" target="#b37">[33]</ref>.</p><formula xml:id="formula_80">? n+1 = ? n + a(n) a 1 ? A 11 ? n ? A 12 w n + M (?) n ,<label>(75)</label></formula><formula xml:id="formula_81">w n+1 = w n + b(n) a 2 ? A 21 ? n ? A 22 w n + M (w) n .<label>(76)</label></formula><p>Assumptions. We make the following assumptions:</p><p>(A1) The random variables (M </p><formula xml:id="formula_82">E M (?) n (M (?) n ) T = ? 11 ,<label>(77)</label></formula><formula xml:id="formula_83">E M (?) n (M (w) n ) T = ? 12 = ? T 21 ,<label>(78)</label></formula><formula xml:id="formula_84">E M (w) n (M (w) n ) T = ? 22 .<label>(79)</label></formula><p>(A2) The learning rates are deterministic, positive, nondecreasing and satisfy with 0:</p><formula xml:id="formula_85">n a(n) = ? , lim n?? a(n) = 0 ,<label>(80)</label></formula><formula xml:id="formula_86">n b(n) = ? , lim n?? b(n) = 0 ,<label>(81)</label></formula><formula xml:id="formula_87">a(n) b(n) ? .<label>(82)</label></formula><p>We often consider the case = 0.</p><p>(A3) Convergence of the iterates: We define</p><formula xml:id="formula_88">? := A 11 ? A 12 A ?1 22 A 21 .<label>(83)</label></formula><p>A matrix is Hurwitz if the real part of each eigenvalue is strictly negative. We assume that the matrices ?A 22 and ?? are Hurwitz.</p><p>(A4) Convergence rate remains simple: (a) There exists a constant? 0 such that lim n (a(n + 1) ?1 ? a(n) ?1 ) =? .</p><p>(84)</p><formula xml:id="formula_89">(b) If = 0, then lim n (b(n + 1) ?1 ? b(n) ?1 ) = 0 . (85) (c) The matrix ? ? ?? 2 I (86)</formula><p>is Hurwitz.</p><p>Rate of Convergence Theorem. The next theorem is taken from Konda <ref type="bibr" target="#b34">[30]</ref> and Konda &amp; Tsitsiklis <ref type="bibr" target="#b37">[33]</ref>.</p><p>Let ? * ? R m and w * ? R k be the unique solution to the system of linear equations</p><formula xml:id="formula_90">A 11 ? n + A 12 w n = a 1 ,<label>(87)</label></formula><formula xml:id="formula_91">A 21 ? n + A 22 w n = a 2 .</formula><p>(88) For each n, let?</p><formula xml:id="formula_92">n = ? n ? ? * ,<label>(89)</label></formula><formula xml:id="formula_93">w n = w n ? A ?1 22 (a 2 ? A 21 ? n ) ,<label>(90)</label></formula><formula xml:id="formula_94">? n 11 = ? ?1 n E ? n? T n ,<label>(91)</label></formula><formula xml:id="formula_95">? n 12 = ? n 21 T = ? ?1 n E ? n? T n ,<label>(92)</label></formula><formula xml:id="formula_96">? n 22 = w ?1 n E ? n? T n ,<label>(93)</label></formula><formula xml:id="formula_97">? n = ? n 11 ? n 12 ? n 21 ? n 22 .</formula><p>(94)</p><p>Theorem 6 (Konda &amp; Tsitsiklis). Under above assumptions and when the constant is sufficiently small, the limit matrices </p><p>exist. Furthermore, the matrix</p><formula xml:id="formula_99">? (0) = ? (0) 11 ? (0) 12 ? (0) 21 ? (0) 22<label>(96)</label></formula><p>is the unique solution to the following system of equations</p><formula xml:id="formula_100">? ? (0) 11 + ? (0) 11 ? T ?? ? (0) 11 + A 12 ? (0) 21 + ? (0) 12 A T 12 = ? 11 ,<label>(97)</label></formula><formula xml:id="formula_101">A 12 ? (0) 22 + ? (0) 12 A T 22 = ? 12 ,<label>(98)</label></formula><formula xml:id="formula_102">A 22 ? (0) 22 + ? (0) 22 A T 22 = ? 22 . (99) Finally, lim ?0 ? ( ) 11 = ? (0) 11 , lim ?0 ? ( ) 12 = ? (0) 12 , lim ?0 ? ( ) 22 = ? (0) 22 .<label>(100)</label></formula><p>The next theorems shows that the asymptotic covariance matrix of a(n) ?1/2 ? n is the same as that of a(n) ?1/2? n , where? n evolves according to the single time-scale stochastic iteration: If the assumptions hold with = 0, then a(n) ?1/2? n converges in distribution to N (0, ? (0) 11 ).</p><formula xml:id="formula_103">? n+1 =? n + a(n) a 1 ? A 11?n ? A 12wn + M (?) n ,<label>(101)</label></formula><formula xml:id="formula_104">0 = a 2 ? A 21?n ? A 22wn + M (w) n .<label>(102)</label></formula><p>Comments.</p><p>(C1) In his PhD thesis <ref type="bibr" target="#b34">[30]</ref> Konda extended the analysis to the nonlinear case. Konda makes a linearization of the nonlinear function h and g with</p><formula xml:id="formula_105">A 11 = ? ?h ?? , A 12 = ? ?h ?w , A 21 = ? ?g ?? , A 22 = ? ?g ?w .<label>(104)</label></formula><p>There are additional errors due to linearization which have to be considered. However, only a sketch of a proof is provided but not a complete proof.</p><p>(C2) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.2.2 Nonlinear Update Rules</head><p>The rate of convergence for nonlinear update rules according to Mokkadem &amp; Pelletier is considered <ref type="bibr" target="#b48">[44]</ref>.</p><p>The iterates are</p><formula xml:id="formula_106">? n+1 = ? n + a(n) h ? n , w n + Z (?) n + M (?) n ,<label>(105)</label></formula><formula xml:id="formula_107">w n+1 = w n + b(n) g ? n , w n + Z (w) n + M (w) n .<label>(106)</label></formula><p>with the increasing ?-fields</p><formula xml:id="formula_108">F n = ?(? l , w l , M (?) l , M (w) l , Z (?) l , Z (w) l , l n), n 0 .<label>(107)</label></formula><p>The terms Z (?) n and Z (w) n can be used to address the error through linearization, that is, the difference of the nonlinear functions to their linear approximation.</p><p>Assumptions. We make the following assumptions:</p><p>(A1) Convergence is ensured:</p><formula xml:id="formula_109">lim n?? ? n = ? * a.s. ,<label>(108)</label></formula><formula xml:id="formula_110">lim n?? w n = w * a.s. .<label>(109)</label></formula><p>(A2) Linear approximation and Hurwitz: There exists a neighborhood U of (? * , w * ) such that, for all (?, w) ? U h ?, w g ?, w =</p><formula xml:id="formula_111">A 11 A 12 A 21 A 22 ? ? ? * w ? w * + O ? ? ? * w ? w * 2 .<label>(110)</label></formula><p>We define</p><formula xml:id="formula_112">? := A 11 ? A 12 A ?1 22 A 21 .<label>(111)</label></formula><p>A matrix is Hurwitz if the real part of each eigenvalue is strictly negative. We assume that the matrices A 22 and ? are Hurwitz.</p><p>(A3) Assumptions on the learning rates:</p><formula xml:id="formula_113">a(n) = a 0 n ?? (112) b(n) = b 0 n ?? ,<label>(113)</label></formula><p>where a 0 &gt; 0 and b 0 &gt; 0 and 1/2 &lt; ? &lt; ? 1. If ? = 1, then a 0 &gt; 1/(2e min ) with e min as the absolute value of the largest eigenvalue of ? (the eigenvalue closest to 0).</p><p>(A4) Assumptions on the noise and error: (a) martingale difference sequences:</p><formula xml:id="formula_114">E M (?) n+1 | F n = 0 a.s. ,<label>(114)</label></formula><formula xml:id="formula_115">E M (w) n+1 | F n = 0 a.s. .<label>(115)</label></formula><p>(b) existing second moments:</p><formula xml:id="formula_116">lim n?? E M (?) n+1 M (w) n+1 (M (?) n+1 ) T (M (w) n+1 ) T | F n = ? = ? 11 ? 12 ? 21 ? 22 a.s.<label>(116)</label></formula><p>(c) bounded moments:</p><formula xml:id="formula_117">There exist l &gt; 2/? such that sup n E M (?) n+1 l | F n &lt; ? a.s. ,<label>(117)</label></formula><formula xml:id="formula_118">sup n E M (w) n+1 l | F n &lt; ? a.s.<label>(118)</label></formula><p>(d) bounded error: Rate of Convergence Theorem. We report a theorem and a proposition from Mokkadem &amp; Pelletier <ref type="bibr" target="#b48">[44]</ref>. However, first we have to define the covariance matrices ? ? and ? w which govern the rate of convergence.</p><formula xml:id="formula_119">Z (?) n = r (?) n + O ? ? ? * 2 + w ? w * 2 ,<label>(119)</label></formula><formula xml:id="formula_120">Z (w) n = r (w) n + O ? ? ? * 2 + w ? w * 2 ,<label>(120)</label></formula><p>First we define</p><formula xml:id="formula_121">? ? := lim n?? E M (?) n+1 ? A 12 A ?1 22 M (w) n+1 M (?) n+1 ? A 12 A ?1 22 M (w) n+1 T | F n =<label>(122)</label></formula><formula xml:id="formula_122">? 11 + A 12 A ?1 22 ? 22 (A ?1 22 ) T A T 12 ? ? 12 (A ?1 22 ) T A T 12 ? A 12 A ?1 22 ? 21 .</formula><p>We now define the asymptotic covariance matrices ? ? and ? w :</p><formula xml:id="formula_123">? ? = ? 0 exp ? + 1 a=1 2 a 0 I t ? ? exp ? T + 1 a=1 2 a 0 I t dt ,<label>(123)</label></formula><formula xml:id="formula_124">? w = ? 0 exp (A 22 t) ? 22 exp (A 22 t) dt .<label>(124)</label></formula><p>? ? and ? w are solutions of the Lyapunov equations: </p><formula xml:id="formula_125">? + 1 a=1 2 a 0 I ? ? + ? ? ? T + 1 a=1 2 a 0 I = ? ? ? ,<label>(125)</label></formula><formula xml:id="formula_126">A 22 ? w + ? w A T 22 = ? ? 22 .<label>(126</label></formula><formula xml:id="formula_127">a(n) ?1 (? ? ? * ) b(n) ?1 (w ? w * ) D ? ? N 0 , ? ? 0 0 ? w .<label>(127)</label></formula><p>Theorem 9 (Mokkadem &amp; Pelletier: Strong convergence). Under above assumptions:</p><formula xml:id="formula_128">? ? ? * = O ? ? a(n) log n l=1 a(l) ? ? a.s. ,<label>(128)</label></formula><formula xml:id="formula_129">w ? w * = O ? ? b(n) log n l=1 b(l) ? ? a.s.<label>(129)</label></formula><p>Comments.</p><p>(C1) Besides the learning steps a(n) and b(n), the convergence rate is governed by A 22 for the fast and ? for the slow iterate. ? in turn is affected by interaction effects which are captured by A 21 and A 12 together with the inverse of A 22 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.3 Equal Time-Scale Stochastic Approximation Algorithms</head><p>In this subsection we consider the case when the learning rates have equal time-scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.3.1 Equal Time-Scale for Saddle Point Iterates</head><p>If equal time-scales assumed then the iterates revisit infinite often an environment of the solution <ref type="bibr" target="#b65">[61]</ref>. In Zhang 2007, the functions of the iterates are the derivatives of a Lagrangian with respect to the dual and primal variables <ref type="bibr" target="#b65">[61]</ref>. The iterates are</p><formula xml:id="formula_130">? n+1 = ? n + a(n) h ? n , w n + Z (?) n + M (?) n ,<label>(130)</label></formula><p>w n+1 = w n + a(n) g ? n , w n + Z (w)</p><formula xml:id="formula_131">n + M (w) n .<label>(131)</label></formula><p>with the increasing ?-fields</p><formula xml:id="formula_132">F n = ?(? l , w l , M (?) l , M (w) l , Z (?) l , Z (w) l , l n), n 0 .<label>(132)</label></formula><p>The terms Z Assumptions. We make the following assumptions: </p><formula xml:id="formula_133">E M (?) n+1 2 | F n &lt; ? a.s. ,<label>(134)</label></formula><p>E M Theorem. Define the "contraction region" A ? as follows:</p><formula xml:id="formula_134">A ? = {(?, w) : ? (?) ? h(?, w) or ? (w) ? g(?, w) , 0 ? &lt; 1} .<label>(139)</label></formula><p>Theorem 10 (Zhang). Under above assumptions the iterates return to A ? infinitely often with probability one (a.s.).</p><p>Comments.</p><p>(C1) The proof of the theorem in <ref type="bibr" target="#b65">[61]</ref> does not use the saddle point condition and not the fact that the functions of the iterates are derivatives of the same function.</p><p>(C2) For the unbiased case, Zhang showed in Theorem 3.1 of [61] that the iterates converge. However, he used the saddle point condition of the Lagrangian. He considered iterates with functions that are the derivatives of a Lagrangian with respect to the dual and primal variables <ref type="bibr" target="#b65">[61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.3.2 Equal Time Step for Actor-Critic Method</head><p>If equal time-scales assumed then the iterates revisit infinite often an environment of the solution of DiCastro &amp; Meir <ref type="bibr" target="#b17">[14]</ref>. The iterates of DiCastro &amp; Meir are derived for actor-critic learning.</p><p>To present the actor-critic update iterates, we have to define some functions and terms. ?(u | x, ?) is the policy function parametrized by ? ? R m with observations x ? X and actions u ? U. A Markov chain given by P(y | x, u) gives the next observation y using the observation x and the action u. In each state x the agent receives a reward r(x).</p><p>The average reward per stage is for the recurrent state x * :</p><formula xml:id="formula_135">?(?) = lim T ?? E 1 T T ?1 n=0 r(x n ) | x 0 = x * , ? .<label>(140)</label></formula><p>The estimate of? is denoted by ?.</p><p>The differential value function is</p><formula xml:id="formula_136">h(x, ?) = E T ?1 n=0 (r(x n ) ??(?)) | x 0 = x, ? .<label>(141)</label></formula><p>The temporal difference is</p><formula xml:id="formula_137">d(x, y, ?) = r(x) ??(?) +h(y, ?) ?h(x, ?) .<label>(142)</label></formula><p>The estimate ofd is denoted by d.</p><p>The likelihood ratio derivative ? ? R m is</p><formula xml:id="formula_138">?(x, u, ?) = ? ? ?(u | x, ?) ?(u | x, ?) .<label>(143)</label></formula><p>28</p><p>The value functionh is approximated by</p><formula xml:id="formula_139">h(x, w) = ?(x) T w ,<label>(144)</label></formula><formula xml:id="formula_140">where ?(x) ? R k . We define ? ? R |X |?k ? = ? ? ? ? ? 1 (x 1 ) ? 2 (x 1 ) . . . ? k (x 1 ) ? 1 (x 2 ) ? 2 (x 2 ) . . . ? k (x 2 ) . . . . . . . . . ? 1 (x |X | ) ? 2 (x |X | ) . . . ? k (x |X | ) ? ? ? ?<label>(145)</label></formula><p>and</p><formula xml:id="formula_141">h(w) = ? w .<label>(146)</label></formula><p>For TD(?) we have an eligibility trace:</p><formula xml:id="formula_142">e n = ? e n?1 + ?(x n ) .<label>(147)</label></formula><p>We define the approximation error with optimal parameter w * (?):</p><formula xml:id="formula_143">app (?) = inf w?R k h (?) ? ? w ?(?) = h (?) ? ? w * (?) ?(?) ,<label>(148)</label></formula><p>where ?(?) is an projection operator into the span of ?w. We bound this error by</p><formula xml:id="formula_144">app = sup ??R k app (?) .<label>(149)</label></formula><p>(A5) Assumptions on the approximation space given by ?:</p><p>The columns of the matrix ? are independent, that is, the form a basis of dimension k. The norms of the columns vectors of the matrix ? are bounded above by 1, that is, ? l 2 1 for 1 l k.</p><p>(A6) Assumptions on the learning rate:</p><formula xml:id="formula_145">n a(n) = ? , n a 2 (n) &lt; ? .<label>(158)</label></formula><p>Theorem. The algorithm converged if ? ?? (?) = 0, since the actor reached a stationary point where the updates are zero. We assume that ? ?? (?) hints at how close we are to the convergence point.</p><p>The next theorem from DiCastro &amp; Meir <ref type="bibr" target="#b17">[14]</ref> implies that the trajectory visits a neighborhood of a local maximum infinitely often. Although it may leave the local vicinity of the maximum, it is guaranteed to return to it infinitely often.</p><formula xml:id="formula_146">Theorem 11 (DiCastro &amp; Meir). Define B ?? = B ?td1 ? w + B ?td2 ? ? + B ?td3 app ,<label>(159)</label></formula><p>where B ?td1 , B ?td2 , and B ?td3 are finite constants depending on the Markov decision process and the agent parameters.</p><p>Under above assumptions</p><formula xml:id="formula_147">lim t?? inf ? ?? (? t ) B ?? .<label>(160)</label></formula><p>The trajectory visits a neighborhood of a local maximum infinitely often.</p><p>Comments.</p><p>(C1) The larger the critic learning rates ? w and ? ? are, the smaller is the region around the local maximum.</p><p>(C2) The results are in agreement with those of Zhang 2007 <ref type="bibr" target="#b65">[61]</ref>.</p><p>(C3) Even if the results are derived for a special actor-critic setting, they carry over to a more general setting of the iterates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3 ADAM Optimization as Stochastic Heavy Ball with Friction</head><p>The Nesterov Accelerated Gradient Descent (NAGD) <ref type="bibr" target="#b51">[47]</ref> has raised considerable interest due to its numerical simplicity and its low complexity. Previous to NAGD and its derived methods there was Polyak's Heavy Ball method <ref type="bibr" target="#b53">[49]</ref>. The idea of the Heavy Ball is a ball that evolves over the graph of a function f with damping (due to friction) and acceleration. Therefore, this second-order dynamical system can be described by the ODE for the Heavy Ball with Friction (HBF) <ref type="bibr" target="#b20">[17]</ref>:</p><formula xml:id="formula_148">? t + a(t)? t + ?f (? t ) = 0 ,<label>(161)</label></formula><p>where a(n) is the damping coefficient with a(n) = a n ? for ? ? (0, 1]. This ODE is equivalent to the integro-differential equation?</p><formula xml:id="formula_149">t = ? 1 k(t) t 0 h(s)?f (? s )ds ,<label>(162)</label></formula><p>where k and h are two memory functions related to a(t). For polynomially memoried HBF we have k(t) = t ?+1 and h(t) = (? + 1)t ? for some positive ?, and for exponentially memoried HBF we have k(t) = ? exp(? t) and h(t) = exp(? t). For the sum of the learning rates, we obtain n l=1 a(l) = a ln(n) + ? + 1 2n + O 1 n 2 for ? = 1</p><formula xml:id="formula_150">n 1?? 1?? for ? &lt; 1 ,<label>(163)</label></formula><p>where ? = 0.5772156649 is the Euler-Mascheroni constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gadat et al. derived a discrete and stochastic version of the HBF [17]:</head><p>? n+1 = ? n ? a(n + 1) m n (164) m n+1 = m n + a(n + 1) r(n) ?f (? n ) ? m n + a(n + 1) r(n) M n+1 , where r(n) = r for exponentially memoried HBF for polynomially memoried HBF .</p><p>This recursion can be rewritten as</p><formula xml:id="formula_152">? n+1 = ? n ? a(n + 1) m n (166) m n+1 = 1 ? a(n + 1) r(n) m n + a(n + 1) r(n) ?f (? n ) + M n+1 .<label>(167)</label></formula><p>Therefore</p><formula xml:id="formula_153">E [? n v n ] = E [v n ? v n?1 ] = 1 ? ? 2 1 ? ? n 2 E g 2 ? 1 ? ? 2 1 ? ? n?1 2 n?1 l=1 ? n?l?1 2 E g 2 (172) = 1 ? ? 2 1 ? ? n 2 E g 2 ? E g 2 = 0 .</formula><p>We are interested in the difference of actual stochastic v n to the true stationary v:</p><formula xml:id="formula_154">?v n = v n ? v = 1 ? ? 2 1 ? ? n 2 n l=1 ? n?l 2 g 2 l ? v .<label>(173)</label></formula><p>For a stationary second moment of m n and ? 2 = 1 ? ?a(n + 1)r(n), we have ?v n ? a(n + 1)r(n). We use a linear approximation to ADAM's second moment normalization 1/ ? v can be incorporated into a(n + 1) and r(n).</p><formula xml:id="formula_155">? v + ?v n ? 1/ ? v ? 1/(2v ? v)?v n + O(? 2 v n ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A4 Experiments: Additional Information</head><p>A4.1 WGAN-GP on Image Data.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A4.3 BEGAN</head><p>The Boundary Equilibrium GAN (BEGAN) <ref type="bibr" target="#b9">[6]</ref> maintains an equilibrium between the discriminator and generator loss (cf. Section 3.3 in <ref type="bibr" target="#b9">[6]</ref>)</p><formula xml:id="formula_156">E[L(G(z))] = ?E[L(x)]<label>(174)</label></formula><p>which, in turn, also leads to a fixed relation between the two gradients, therefore, a two time-scale update is not ensured by solely adjusting the learning rates. Indeed, for stable learning rates, we see no differences in the learning progress between orig and TTUR as depicted in <ref type="figure" target="#fig_7">Figure A13</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A5 Discriminator vs. Generator Learning Rate</head><p>The convergence proof for learning GANs with TTUR assumes that the generator learning rate will eventually become small enough to ensure convergence of the discriminator learning. At some time point, the perturbations of the discriminator updates by updates of the generator parameters are sufficient small to assure that the discriminator converges. Crucial for discriminator convergence is the magnitude of the perturbations which the generator induces into the discriminator updates. These perturbations are not only determined by the generator learning rate but also by its loss function, current value of the loss function, optimization method, size of the error signals that reach the generator (vanishing or exploding gradient), complexity of generator's learning task, architecture of the generator, regularization, and others. Consequently, the size of generator learning rate does not solely determine how large the perturbations of the discriminator updates are but serve to modulate them. Thus, the generator learning rate may be much larger than the discriminator learning rate without inducing large perturbation into the discriminator learning.</p><p>Even the learning dynamics of the generator is different from the learning dynamics of the discriminator, though they both have the same learning rate. <ref type="figure" target="#fig_2">Figure A14</ref> shows the loss of the generator and the discriminator for an experiment with DCGAN on CelebA, where the learning rate was 0.0005 for both the discriminator and the generator. However, the discriminator loss is decreasing while the generator loss is increasing. This example shows that the learning rate neither determines the perturbations nor the progress in learning for two coupled update rules. The choice of the learning rate for the generator should be independent from choice for the discriminator. Also the search ranges of discriminator and generator learning rates should be independent from each other, but adjusted to the corresponding architecture, task, etc. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A6 Used Software, Datasets, Pretrained Models, and Implementations</head><p>We used the following datasets to evaluate GANs: The Large-scale CelebFaces Attributes (CelebA) dataset, aligned and cropped <ref type="bibr" target="#b45">[41]</ref>, the training dataset of the bedrooms category of the large scale image database (LSUN) <ref type="bibr" target="#b64">[60]</ref>, the CIFAR-10 training dataset <ref type="bibr" target="#b38">[34]</ref>, the Street View House Numbers training dataset (SVHN) <ref type="bibr" target="#b52">[48]</ref>, and the One Billion Word Benchmark <ref type="bibr" target="#b15">[12]</ref>.</p><p>All experiments rely on the respective reference implementations for the corresponding GAN model. The software framework for our experiments was Tensorflow 1.3 <ref type="bibr">[1,</ref><ref type="bibr" target="#b5">2]</ref> and Python 3.6. We used following software, datasets and pretrained models:</p><p>? BEGAN in Tensorflow, https://github.com/carpedm20/BEGAN-tensorflow, Fixed random seeds removed. Accessed: 2017-05-30</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>31st</head><label></label><figDesc>Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1706.08500v6 [cs.LG] 12 Jan 2018 algorithm under different step sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>onvergence under noisy feedback (the unbiased case).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Convergence under noisy feedback (the biased case).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>)?x*|| ? = ? = [0.05, 0.05, 0.05, 0.05] ? = ? = [0.5, 0.5, 0.5, 0.5] ? = ? = [1, 1, 1, 1] ? = ? = [5, 5, 5, 5] "Zoomed-in" convergence behavior of the iterates in Figure 4. V. STOCHASTIC STABILITY OF TWO TIME-SCALE ALGORITHM UNDER NOISY FEEDBACK</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>10 Figure 1 :</head><label>101</label><figDesc>Left: Original vs. TTUR GAN training on CelebA. Right: Figure from Zhang 2007</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 :</head><label>2</label><figDesc>Heavy Ball with Friction, where the ball with mass overshoots the local minimum ? + and settles at the flat minimum ? * .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>For a stationary second moment v, the random variable {M (v) n } is a martingale difference sequence with a bounded second moment. Therefore {M (v) n+1 } can be subsumed into {M n+1 } in update rules Eq. (4). The factor 1/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>FIDFigure 3 :</head><label>3</label><figDesc>FID is evaluated for upper left: Gaussian noise, upper middle: Gaussian blur, upper right: implanted black rectangles, lower left: swirled images, lower middle: salt and pepper noise, and lower right: CelebA dataset contaminated by ImageNet images. The disturbance level rises from zero and increases to the highest level. The FID captures the disturbance level very well by monotonically increasing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Left: Plot of the objective with a saddle point at (0, 0). Right: Training progress with equal learning rates of 0.01 (first row) and 0.001 (second row)) for x and y, TTUR with a learning rate of 0.0001 for x vs. 0.01 for y (third row) and a larger learning rate of 0.01 for x vs. 0.0001 for y (fourth row). The columns show the function values (left), norms (middle), and (x, y) (right). TTUR (third row) clearly converges faster than with equal time-scale updates and directly moves to the saddle point as shown by the norm and in the (x, y)-plot.DCGAN on Image Data. We test TTUR for the deep convolutional GAN (DCGAN)<ref type="bibr" target="#b55">[51]</ref> at the CelebA, CIFAR-10, SVHN and LSUN Bedrooms dataset.Fig. 5shows the FID during learning Mean FID (solid line) surrounded by a shaded area bounded by the maximum and the minimum over 8 runs for DCGAN on CelebA, CIFAR-10, SVHN, and LSUN Bedrooms. TTUR learning rates are given for the discriminator b and generator a as: "TTUR b a". Top Left: CelebA. Top Right: CIFAR-10, starting at mini-batch update 10k for better visualisation. Bottom Left: SVHN. Bottom Right: LSUN Bedrooms. Training with TTUR (red) is more stable, has much lower variance, and leads to a better FID.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 : 8 200 4 Figure 7 :</head><label>6847</label><figDesc>Mean FID (solid line) surrounded by a shaded area bounded by the maximum and the minimum over 8 runs for WGAN-GP on CelebA, CIFAR-10, SVHN, and LSUN Bedrooms. TTUR learning rates are given for the discriminator b and generator a as: "TTUR b a". Left: CIFAR-10, starting at minute 20. Right: LSUN Bedrooms. Training with TTUR (red) has much lower variance and leads to a better FID. Performance of WGAN-GP models trained with the original (orig) and our TTUR method on the One Billion Word benchmark. The performance is measured by the normalized Jensen-Shannon-divergence based on 4-gram (left) and 6-gram (right) statistics averaged (solid line) and surrounded by a shaded area bounded by the maximum and the minimum over 10 runs, aligned to wall-clock time and starting at minute 150. TTUR learning (red) clearly outperforms the original one time-scale learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>1 . 2 . 3 .</head><label>123</label><figDesc>Gaussian noise: We constructed a matrix N with Gaussian noise scaled to[0, 255]. The noisy image is computed as (1 ? ?)X + ?N for ? ? {0, 0.25, 0.5, 0.75}. The larger ? is, the larger is the noise added to the image, the larger is the disturbance of the image. Gaussian blur: The image is convolved with a Gaussian kernel with standard deviation ? ? {0, 1, 2, 4}. The larger ? is, the larger is the disturbance of the image, that is, the more the image is smoothed. Black rectangles: To an image five black rectangles are are added at randomly chosen locations. The rectangles cover parts of the image. The size of the rectangles is ?imagesize with ? ? {0, 0.25, 0.5, 0.75}. The larger ? is, the larger is the disturbance of the image, that is, the more of the image is covered by black rectangles. 4. Swirl: Parts of the image are transformed as a spiral, that is, as a swirl (whirlpool effect).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure A8 : 13 Figure A9 :</head><label>A813A9</label><figDesc>Left: FID and right: Inception Score are evaluated for first row: Gaussian noise, second row: Gaussian blur, third row: implanted black rectangles, fourth row: swirled images, fifth row. salt and pepper noise, and sixth row: the CelebA dataset contaminated by ImageNet images. Left is the smallest disturbance level of zero, which increases to the highest level at right. The FID captures the disturbance level very well by monotonically increasing whereas the Inception Score fluctuates, stays flat or even, in the worst case, decreases. Samples generated from DCGAN trained on CelebA with different FIDs. Left: FID 500 and Right: FID 300.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure A10 :</head><label>A10</label><figDesc>Samples generated from DCGAN trained on CelebA with different FIDs. Left: FID 133 and Right: FID 100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure A11 :</head><label>A11</label><figDesc>Samples generated from DCGAN trained on CelebA with different FIDs. Left: FID 45 and Right: FID 13.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure A12 :</head><label>A12</label><figDesc>Samples generated from WGAN-GP trained on CelebA with a FID of 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>n</head><label></label><figDesc>: additive random Markov process for the slow iterate Eq. (13), ? M (w) n : additive random Markov process for the fast iterate Eq. (14), ? Z (?) n : random Markov process for the slow iterate Eq. (13), ? Z (w) n : random Markov process for the fast iterate Eq. (14).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>( A1 )</head><label>A1</label><figDesc>Assumptions on the update functions: The functions h : R k+m ? R m and g : R k+m ? R k are Lipschitz.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>( 15 ) 2 ,</head><label>152</label><figDesc>and Eq. (16) converge to (? * , ?(? * )) a.s.Comments(C1) According to Lemma 2 in [7] Assumption (A3) is fulfilled if {M (?) n } is a martingale difference sequence w.r.t F n with E M (?) n } is a martingale difference sequence w.r.t F n with E M (w) n 2 | F (w) n Bwhere B 1 and B 2 are positive deterministic constants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>(</head><label></label><figDesc>C2) Assumption (A3) holds for mini-batch learning which is the most frequent case of stochastic gradient. The batch gradient isG n := ? ? ( 1 N N i=1 f (x i , ?)),1 i N and the minibatch gradient for batch size s is h n := ? ? ( 1 s s i=1 f (x ui , ?)), 1 u i N , where the indexes u i are randomly and uniformly chosen. For the noise M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>h n ? G n we have E[M (?) n ] = E[h n ] ? G n = G n ? G n = 0.Since the indexes are chosen without knowing past events, we have a martingale difference sequence. For bounded gradients we have bounded M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>For generator with mode collapse, (i) the discriminator is 1 in regions without generator examples, (ii) 0 in regions with generator examples only, (iii) is equal to the local ratio of real world examples for regions with generator and real world examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>( 28 )</head><label>28</label><figDesc>We define for every measurable function f P ? f (z) := P(z, dz; ? n ) f (z) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>( A4 )</head><label>A4</label><figDesc>Assumption on the existence of a solution of the fast iterate: We assume the existence of a solution to the Poisson equation for the fast iterate. For each ? ? R m , there exist functionsg(?) ? R k ,?(?) ? R k?k ,?(z; ?) : Z ? R k , and?(z; ?) : Z ? R k?k that satisfy the Poisson equations:? (z; ?) = g(z; ?) ??(?) + (P ?? (.; ?))(z) ,(34)G(z; ?) = G(z; ?) ??(?) + (P ?? (.; ?))(z) .(35)(A5) Assumptions on the update functions and solutions to the Poisson equation: (a) Boundedness of solutions: For some constant C and for all ?:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>A1) Assumptions on the controlled Markov processes: The controlled Markov process {Z (w) n } takes values in a compact metric space S (w) . The controlled Markov process {Z (?) n } takes values in a compact metric space S (?) . Both processes are controlled by the iterate sequences {? n } and {w n }. Furthermore {Z (w) n } is additionally controlled by a random process {A (w) n } taking values in a compact metric space U (w) and {Z (?) n } is additionally controlled by a random process {A (?) n } taking values in a compact metric space U (?) . The {Z (?) n } dynamics is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>( A3 )</head><label>A3</label><figDesc>Assumptions on the additive noise: {M (?) n } and {M (w)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head></head><label></label><figDesc>n = 0, 1, . . ., are independent of w 0 , ? 0 and of each other. The have zero mean: E[M (?) n ] = 0 and E[M (w) n ] = 0. The covariance is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head></head><label></label><figDesc>Assumptions on the learning rate: a(n) &gt; 0 , a(n) ? 0 ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head></head><label></label><figDesc>If we set M (v) n+1 = ?(m n ?v n )/(2v ? va(n + 1)r(n)), then m n / ? v n ? m n / ? v + a(n + 1)r(n)M (v) n+1 and E M (v) n+1 = 0, since E g 2 l ? v = 0.For a stationary second moment of m n , {M (v) n } is a martingale difference sequence with a bounded second moment. Therefore {M (v) n+1 } can be subsumed into {M n+1 } in update rules Eq. (166). The factor 1/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>Figure</head><label></label><figDesc>A13: Mean, maximum and minimum FID over eight runs for BEGAN training on CelebA and LSUN Bedrooms. TTUR learning rates are given as pairs (b, a) of discriminator learning rate b and generator learning rate a: "TTUR b a". Left: CelebA, starting at mini-batch 10k for better visualisation. Right: LSUN Bedrooms. Orig and TTUR behave similar. For BEGAN we cannot ensure TTUR by adjusting learning rates. 33</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Figure A14 :</head><label>A14</label><figDesc>The respective losses of the discriminator and the generator show the different learning dynamics of the two networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The performance of DCGAN and WGAN-GP trained with the original one time-scale update rule and with TTUR on CelebA, CIFAR-10, SVHN, LSUN Bedrooms and the One Billion Word Benchmark. During training we compare the performance with respect to the FID and JSD for optimized number of updates. TTUR exhibits consistently a better FID and a better JSD.</figDesc><table><row><cell cols="2">DCGAN Image dataset method</cell><cell>b, a</cell><cell cols="5">updates FID method b = a updates FID</cell></row><row><cell cols="2">CelebA CIFAR-10 TTUR TTUR SVHN TTUR LSUN TTUR</cell><cell>1e-5, 5e-4 1e-4, 5e-4 1e-5, 1e-4 1e-5, 1e-4</cell><cell>225k 75k 165k 340k</cell><cell>12.5 orig 36.9 orig 12.5 orig 57.5 orig</cell><cell>5e-4 1e-4 5e-5 5e-5</cell><cell>70k 100k 185k 70k</cell><cell>21.4 37.7 21.4 70.4</cell></row><row><cell cols="2">WGAN-GP Image dataset method</cell><cell>b, a</cell><cell cols="5">time(m) FID method b = a time(m) FID</cell></row><row><cell cols="2">CIFAR-10 TTUR LSUN TTUR</cell><cell>3e-4, 1e-4 3e-4, 1e-4</cell><cell>700 1900</cell><cell>24.8 orig 9.5 orig</cell><cell>1e-4 1e-4</cell><cell>800 2010</cell><cell>29.3 20.5</cell></row><row><cell cols="2">WGAN-GP Language n-gram method</cell><cell>b, a</cell><cell cols="5">time(m) JSD method b = a time(m) JSD</cell></row><row><cell>4-gram 6-gram</cell><cell>TTUR TTUR</cell><cell>3e-4, 1e-4 3e-4, 1e-4</cell><cell>1150 1120</cell><cell>0.35 orig 0.74 orig</cell><cell>1e-4 1e-4</cell><cell>1040 1070</cell><cell>0.38 0.77</cell></row><row><cell></cell><cell></cell><cell></cell><cell>9</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>In experiments we have compared GANs trained with TTUR to conventional GAN training with a one time-scale update rule on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark. TTUR outperforms conventional GAN training consistently in all experiments. Contents A1 Fr?chet Inception Distance (FID) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 A2 Two Time-Scale Stochastic Approximation Algorithms . . . . . . . . . . . . . . . . . . 16 A2.1 Convergence of Two Time-Scale Stochastic Approximation Algorithms . . . . . . 16 A2.1.1 Additive Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 A2.1.2 Linear Update, Additive Noise, and Markov Chain . . . . . . . . . . . . . 18 A2.1.3 Additive Noise and Controlled Markov Processes . . . . . . . . . . . . . . 20 A2.2 Rate of Convergence of Two Time-Scale Stochastic Approximation Algorithms . . 23 A2.2.1 Linear Update Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 A2.2.2 Nonlinear Update Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 A2.3 Equal Time-Scale Stochastic Approximation Algorithms . . . . . . . . . . . . . . 27 A2.3.1 Equal Time-Scale for Saddle Point Iterates . . . . . . . . . . . . . . . . . 27 A2.3.2 Equal Time Step for Actor-Critic Method . . . . . . . . . . . . . . . . . . 28 A3 ADAM Optimization as Stochastic Heavy Ball with Friction . . . . . . . . . . . . . . . 30 A4 Experiments: Additional Information . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 A4.1 WGAN-GP on Image Data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 A4.2 WGAN-GP on the One Billion Word Benchmark. . . . . . . . . . . . . . . . . . 33 A4.3 BEGAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 A5 Discriminator vs. Generator Learning Rate . . . . . . . . . . . . . . . . . . . . . . . . 34 A6 Used Software, Datasets, Pretrained Models, and Implementations . . . . . . . . . . . . 34 List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 List of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Theorem 7 in [32]) and Theorem 3.13 from [30]: Theorem 4 (Konda &amp; Tsitsiklis). If the assumptions are satisfied, then for the iterates Eq. (26) and Eq. (27) holds:</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Theorem 4.1 of Konda &amp; Tsitsiklis is important to generalize to the nonlinear case. (C3) The convergence rate is governed by A 22 for the fast and ? for the slow iterate. ? in turn is affected by the interaction effects captured by A 21 and A 12 together with the inverse of A 22 .</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>)</head><label></label><figDesc>Theorem 8 (Mokkadem &amp; Pelletier: Joint weak convergence). Under above assumptions:</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>( A1 )</head><label>A1</label><figDesc>Assumptions on update function: h and g are continuous, differentiable, and bounded. Hurwitz if the real part of each eigenvalue is strictly negative. This assumptions corresponds to the assumption in<ref type="bibr" target="#b65">[61]</ref> that the Lagrangian is concave in w and convex in ?.</figDesc><table><row><cell>Jacobians</cell><cell></cell><cell></cell><cell>The</cell></row><row><cell>?g ?w</cell><cell>and</cell><cell>?h ??</cell><cell>(133)</cell></row><row><cell>are Hurwitz. A matrix is (A2) Assumptions on noise:</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">{M n } and {M (?) F n . Furthermore they are mutually independent. (w) n } are a martingale difference sequences w.r.t. the increasing ?-fields Bounded second moment:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table A2 :</head><label>A2</label><figDesc>The performance of WGAN-GP trained with the original procedure and with TTUR on CIFAR-10 and LSUN Bedrooms. We compare the performance with respect to the FID at the optimal number of iterations during training and wall-clock time in minutes.A4.2 WGAN-GP on the One Billion Word Benchmark.</figDesc><table><row><cell>dataset</cell><cell cols="2">method b, a</cell><cell>iter</cell><cell cols="4">time(m) FID method b = a iter time(m) FID</cell></row><row><cell cols="2">CIFAR-10 TTUR LSUN TTUR</cell><cell cols="2">3e-4, 1e-4 168k 3e-4, 1e-4 80k</cell><cell>700 1900</cell><cell>24.8 orig 9.5 orig</cell><cell>1e-4 53k 1e-4 23k</cell><cell>800 2010</cell><cell>29.3 20.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table A3 :</head><label>A3</label><figDesc>Samples generated by WGAN-GP trained on fhe One Billion Word benchmark with TTUR (left) the original method (right).</figDesc><table><row><cell>Dry Hall Sitning tven the concer</cell><cell>No say that tent Franstal at Bra</cell></row><row><cell>There are court phinchs hasffort</cell><cell>Caulh Paphionars tven got corfle</cell></row><row><cell>He scores a supponied foutver il</cell><cell>Resumaly , braaky facting he at</cell></row><row><cell>Bartfol reportings ane the depor</cell><cell>On toipe also houd , aid of sole</cell></row><row><cell>Seu hid , it 's watter 's remold</cell><cell>When Barrysels commono toprel to</cell></row><row><cell>Later fasted the store the inste</cell><cell>The Moster suprr tent Elay diccu</cell></row><row><cell>Indiwezal deducated belenseous K</cell><cell>The new vebators are demases to</cell></row><row><cell>Starfers on Rbama 's all is lead</cell><cell>Many 's lore wockerssaow 2 2 ) A</cell></row><row><cell>Inverdick oper , caldawho 's non</cell><cell>Andly , has le wordd Uold steali</cell></row><row><cell>She said , five by theically rec</cell><cell>But be the firmoters is no 200 s</cell></row><row><cell>RichI , Learly said remain .''''</cell><cell>Jermueciored a noval wan 't mar</cell></row><row><cell>Reforded live for they were like</cell><cell>Onles that his boud-park , the g</cell></row><row><cell>The plane was git finally fuels</cell><cell>ISLUN , The crather wilh a them</cell></row><row><cell>The skip lifely will neek by the</cell><cell>Fow 22o2 surgeedeto , theirestra</cell></row><row><cell>SEW McHardy Berfect was luadingu</cell><cell>Make Sebages of intarmamates , a</cell></row><row><cell>But I pol rated Franclezt is the</cell><cell>Gullla " has cautaria Thoug ly t</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table A4 :</head><label>A4</label><figDesc>The performance of WGAN-GP trained with the original procedure and with TTUR on the One Billion Word Benchmark. We compare the performance with respect to the JSD at the optimal number of iterations and wall-clock time in minutes during training. WGAN-GP trained with TTUR exhibits consistently a better FID.</figDesc><table><row><cell cols="2">n-gram method b, a</cell><cell>iter</cell><cell cols="5">time(m) JSD method b = a iter time(m) JSD</cell></row><row><cell>4-gram TTUR 6-gram TTUR</cell><cell cols="2">3e-4, 1e-4 98k 3e-4, 1e-4 100k</cell><cell>1150 1120</cell><cell>0.35 orig 0.74 orig</cell><cell>1e-4 33k 1e-4 32k</cell><cell>1040 1070</cell><cell>0.38 0.77</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">| F n &lt; ? a.s. .(135)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>The references are provided after Section A6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>We denoted by?,d, andh the exact functions and used for their approximation ?, d, and h, respectively. We have learning rate adjustments ? ? and ? w for the critic.</p><p>The update rules are: Critic:</p><p>Actor:</p><p>Assumptions. We make the following assumptions:</p><p>(A1) Assumption on rewards:</p><p>The rewards {r(x)} x?X are uniformly bounded by a finite constant B r .</p><p>(A2) Assumption on the Markov chain: Each Markov chain for each ? is aperiodic, recurrent, and irreducible.</p><p>(A3) Assumptions on the policy function:</p><p>The conditional probability function ?(u | x, ?) is twice differentiable. Moreover, there exist positive constants, B ?1 and B ?2 , such that for all x ? X , u ? U, ? ? R m and 1 l 1 , l 2 m we have</p><p>(A4) Assumption on the likelihood ratio derivative:</p><p>For all x ? X , u ? U, and ? ? R m , there exists a positive constant B ? , such that</p><p>where . 2 is the Euclidean L 2 norm.</p><p>The recursion Eq. (166) is the first moment update of ADAM <ref type="bibr" target="#b33">[29]</ref>.</p><p>For the term r(n)a(n) we obtain for the polynomial memory the approximations</p><p>Gadat et al. showed that the recursion Eq. (164) converges for functions with at most quadratic grow <ref type="bibr" target="#b20">[17]</ref>. The authors mention that convergence can be proofed for functions f that are L-smooth, that is, the gradient is L-Lipschitz.</p><p>Kingma et al. <ref type="bibr" target="#b33">[29]</ref> state in Theorem 4.1 convergence of ADAM while assuming that ? 1 , the first moment running average coefficient, decays exponentially. Furthermore they assume that ? 2 1 ? ?2 &lt; 1 and the learning rate ? t decays with ? t = ? ? t . ADAM divides m n of the recursion Eq. (166) by the bias-corrected second raw moment estimate. Since the bias-corrected second raw moment estimate changes slowly, we consider it as an error.</p><p>ADAM assumes the second moment E g 2 to be stationary with its approximation v n : </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Dcgan In Tensorflow</surname></persName>
		</author>
		<ptr target="https://github.com/carpedm20/DCGAN-tensorflow" />
		<title level="m">Fixed random seeds removed</title>
		<imprint>
			<biblScope unit="page" from="2017" to="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>? Improved Training Of Wasserstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gans</surname></persName>
		</author>
		<ptr target="https://github.com/igul222/improved_wgan_training/blob/master/gan_64x64.py" />
		<imprint>
			<biblScope unit="page" from="2017" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<ptr target="https://github.com/igul222/improved_wgan_training/blob/master/gan_language.py" />
		<title level="m">? Improved Training of Wasserstein GANs, language model</title>
		<imprint>
			<biblScope unit="page" from="2017" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<ptr target="http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz" />
		<title level="m">? Inception-v3 pretrained</title>
		<imprint>
			<biblScope unit="page" from="2017" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>J?zefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Man?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Vi?gas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for largescale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gan</forename><surname>Wasserstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generalization and equilibrium in generative adversarial nets (GANs)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning, Proceedings of Machine Learning Research</title>
		<editor>D. Precup and Y. W. Teh</editor>
		<meeting>the 34th International Conference on Machine Learning, Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="224" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The heavy ball with friction method, I. the continuous dynamical system: Global exploration of the local minima of a real-valued function by asymptotic analysis of a dissipative dynamical system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Attouch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Goudou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Redont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Contemporary Mathematics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schumm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10717</idno>
		<title level="m">BEGAN: Boundary equilibrium generative adversarial networks. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gradient convergence in gradient methods with errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="627" to="642" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stochastic Recursive Algorithms for Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhatnagar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Prashanth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Control and Information Sciences</title>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stochastic approximation with two time scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Borkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systems &amp; Control Letters</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="291" to="294" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The O.D.E. method for convergence of stochastic approximation and reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Borkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Meyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="447" to="469" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mode regularized generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.02136</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">One billion word benchmark for measuring progress in statistical language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Robinson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.3005</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast and accurate deep network learning by exponential linear units (ELUs)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-A</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07289</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A convergent online single time scale actor critic algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dicastro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Meir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="367" to="410" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Fr?chet distance between multivariate normal distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Dowson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Landau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="450" to="455" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sur la distance de deux lois de probabilit?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fr?chet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">C. R. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">244</biblScope>
			<biblScope unit="page" from="689" to="692" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gadat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Panloup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saadane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04228</idno>
		<title level="m">Stochastic heavy ball. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On distinguishability criteria for estimating generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6515</idno>
	</analytic>
	<monogr>
		<title level="m">Workshop at the International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.00160</idno>
		<title level="m">NIPS 2016 tutorial: Generative adversarial networks. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The gradient and heavy ball with friction dynamical systems: the quasiconvex case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Goudou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Munier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="173" to="191" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">An online learning approach to generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Grnarova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Y</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03269</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00028</idno>
	</analytic>
	<monogr>
		<title level="m">Improved training of Wasserstein GANs. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Convergent activation dynamics in continuous time networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Hirsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="331" to="349" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08431</idno>
		<title level="m">Boundary-seeking generative adversarial networks. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Flat minima</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07004</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Two time-scale stochastic approximation with controlled Markov noise and off-policy temporal-difference learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Karmakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhatnagar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematics of Operations Research</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<biblScope unit="page">2015</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Actor-Critic Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Konda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Actor-critic-type learning algorithms for Markov decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Konda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Borkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Control Optim</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="94" to="123" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Linear stochastic approximation driven by slowly varying Markov chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Konda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systems &amp; Control Letters</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="102" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Convergence rate of linear two-time-scale stochastic approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Konda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="796" to="819" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Neural Information Processing Systems</title>
		<meeting>the 25th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Stochastic Approximation Algorithms and Recursive Algorithms and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Kushner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Yin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04802</idno>
		<title level="m">Photo-realistic single image super-resolution using a generative adversarial network. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Towards deeper understanding of moment matching network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>P?czos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08584</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.09884</idno>
		<title level="m">Towards understanding the dynamics of generative adversarial networks. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Geometric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.02894</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Approximation and convergence properties of generative adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08991</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The numerics of GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10461</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02163</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Convergence rate and averaging of nonlinear two-time-scale stochastic approximation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mokkadem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pelletier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1671" to="1702" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mroueh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sercu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gan</forename><surname>Fisher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.09675</idno>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04156</idno>
	</analytic>
	<monogr>
		<title level="m">Gradient descent GAN optimization is locally stable. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A method of solving a convex programming problem with convergence rate o(1/k 2 )</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Mathematics Doklady</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="372" to="376" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Some methods of speeding up the convergence of iteration methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Polyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">USSR Computational Mathematics and Mathematical Physics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Two-timescale algorithms for learning Nash equilibria in general-sum stochastic games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Prashanth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhatnagar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems (AAMAS &apos;15)</title>
		<meeting>the 2015 International Conference on Autonomous Agents and Multiagent Systems (AAMAS &apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1371" to="1379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Stochastic recursive inclusion in two timescales with an application to the lagrangian dual problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhatnagar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stochastics</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1173" to="1187" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Improved techniques for training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Almost sure convergence of two time-scale stochastic approximation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">B</forename><surname>Tadi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 American Control Conference</title>
		<meeting>the 2004 American Control Conference</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="3802" to="3807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A note on the evaluation of generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.01844</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tolstikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Simon-Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.02386</idno>
	</analytic>
	<monogr>
		<title level="m">AdaGAN: Boosting generative models</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">MAGAN: margin adaptation for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cully</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Demiris</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03817</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Markov processes over denumerable products of spaces describing large systems of automata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">N</forename><surname>Wasserstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Probl. Inform. Transmission</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="47" to="52" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">On the quantitative analysis of decoderbased generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Grosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04273</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365</idno>
		<title level="m">LSUN: construction of a large-scale image dataset using deep learning with humans in the loop. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">The impact of stochastic noisy feedback on distributed network utility maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2007 -26th IEEE International Conference on Computer Communications</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="222" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">6 4 TTUR and single time-scale update with toy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">. . . . . . . . . . . . . . . . . . . . . . . . . . . . . ; . . . . . . . . . . . . . . . . . . . .</forename><surname>Ball With Friction</surname></persName>
			<affiliation>
				<orgName type="collaboration">. . . . . . . . . . . . . . . . . . . 7</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">5 FID for DCGAN on CelebA, CIFAR-10, SVHN, and LSUN Bedrooms. . . . . . . 8 6 FID for WGAN-GP trained on CIFAR-10 and LSUN Bedrooms</title>
		<imprint/>
	</monogr>
	<note>4 3 FID evaluated for different disturbances</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Performance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wgan-Gp On One Billion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">. . . . . . . . . . . . . . .</forename><surname>Word</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A8</forename><surname>Fid</surname></persName>
			<affiliation>
				<orgName type="collaboration">Inception Score Comparison . . . . . . . . . . . . . . . . . . . . . . . . . 13</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">A9 CelebA Samples with FID 500 and 300</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
				<title level="m">A10 CelebA Samples with FID 133 and 100</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
				<title level="m">A11 CelebA Samples with FID 45 and 13</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">33 A14 Learning dynamics of two networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">. . . . . . . . . .</forename><surname>Bedrooms</surname></persName>
			<affiliation>
				<orgName type="collaboration">. . . . . . . . . . . . . . . . . . . . . . . . . . 34</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dcgan</forename><surname>Results</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">. . . . . . . . . . . . . . . . . . . . . . .</forename><surname>Wgan-Gp</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">32 A3 Samples of the One Billion Word benchmark generated by</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wgan-Gp</forename><surname>Results</surname></persName>
			<affiliation>
				<orgName type="collaboration">A4 Results WGAN-GP on One Billion Word . . . . . . . . . . . . . . . . . . . . . . . 33</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">. . . . . . . . . . . . . . . . . . . . . .</forename><surname>On Image Data</surname></persName>
			<affiliation>
				<orgName type="collaboration">A4 Results WGAN-GP on One Billion Word . . . . . . . . . . . . . . . . . . . . . . . 33</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">. . .</forename><surname>Wgan-Gp</surname></persName>
			<affiliation>
				<orgName type="collaboration">A4 Results WGAN-GP on One Billion Word . . . . . . . . . . . . . . . . . . . . . . . 33</orgName>
			</affiliation>
		</author>
		<imprint>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
