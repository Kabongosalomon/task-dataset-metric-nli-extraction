<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Algorithm and System Co-design for Efficient Subgraph-based Graph Representation Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoteng</forename><surname>Yin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbang</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Wang</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Li</surname></persName>
							<email>panli@purdue.edu?muhan@pku.edu.cn?ywangdr@cs.cornell.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoteng</forename><surname>Yin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbang</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Pan</roleName><forename type="first">Jianguo</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Purdue University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Algorithm and System Co-design for Efficient Subgraph-based Graph Representation Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Subgraph-based graph representation learning (SGRL) has been recently proposed to deal with some fundamental challenges encountered by canonical graph neural networks (GNNs), and has demonstrated advantages in many important data science applications such as link, relation and motif prediction. However, current SGRL approaches suffer from scalability issues since they require extracting subgraphs for each training or test query. Recent solutions that scale up canonical GNNs may not apply to SGRL. Here, we propose a novel framework SUREL for scalable SGRL by co-designing the learning algorithm and its system support. SUREL adopts walkbased decomposition of subgraphs and reuses the walks to form subgraphs, which substantially reduces the redundancy of subgraph extraction and supports parallel computation. Experiments over six homogeneous, heterogeneous and higher-order graphs with millions of nodes and edges demonstrate the effectiveness and scalability of SUREL. In particular, compared to SGRL baselines, SUREL achieves 10? speed-up with comparable or even better prediction performance; while compared to canonical GNNs, SUREL achieves 50% prediction accuracy improvement. PVLDB Reference Format:</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graph-structured data is prevalent to model relations and interactions between elements in real-world applications <ref type="bibr" target="#b19">[20]</ref>. Graph representation learning (GRL) aims to learn representations of graphstructured data and has recently become a hot research topic <ref type="bibr" target="#b11">[12]</ref>. Previous works on GRL focus on either model design or system design while very few works jointly consider them. Works on model design tend to propose more expressive, generalizable and robust GRL models while paying less attention to their deployment <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b36">37]</ref>. This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. Proceedings of the VLDB Endowment, Vol. 15, No. 11 ISSN 2150-8097. doi:XX.XX/XXX.XX Hence, many theoretically powerful models can hardly apply to large real-world graphs. On the other hand, research on system design focuses on system-level techniques for better model development, such as graph partitioning <ref type="bibr" target="#b6">[7]</ref>, sub-sampling <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b48">49]</ref> and pipelining <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b53">54]</ref>. However, they only consider basic GRL models, in particular graph neural network (GNN) models, yet often overlook their modeling limitations to solve practical GRL tasks.</p><p>Canonical GNNs <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19]</ref> share a common framework: each node is associated with a vector representation that gets iteratively updated by aggregating the representations from its neighboring nodes via graph convolution layers. The final prediction is made by combining the representations of nodes of interest. Although recent successes in system research have greatly pumped up the efficiency <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b39">40]</ref>, the GNN framework intrinsically suffers from three modeling limitations. First, information may be over-squashed into a single node representation that results in subpar performance when multiple tasks are associated, e.g. to predict multiple relations or links attached to the same node <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref>. Second, canonical GNNs cannot capture intra-node distance information due to limited expressive power <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b37">38]</ref>, and thus fail to make predictions over a set of nodes (See <ref type="figure">Fig. 1a</ref>), such as substructure counting <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6]</ref> and higher-order pattern prediction <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b52">53]</ref>. Third, the depth of GNNs is entangled with the range of the receptive field. For more non-linearity, using deeper GNNs comes with a larger but possibly unnecessary receptive field, which poses the risk of contaminating the representations with irrelevant information <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>Recently, subgraph-based GRL (SGRL) has emerged as a new trend and has shown superior performance in tasks such as link prediction <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b52">53]</ref>, relation prediction <ref type="bibr" target="#b34">[35]</ref>, higher-order pattern prediction <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b24">25]</ref>, temporal network modeling <ref type="bibr" target="#b41">[42]</ref>, recommender systems <ref type="bibr" target="#b51">[52]</ref>, graph meta-learning <ref type="bibr" target="#b14">[15]</ref>, and subgraph matching <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26]</ref> and prediction <ref type="bibr" target="#b40">[41]</ref>. Different from canonical GNNs, SGRL extracts a subgraph patch for each training and test query and learns the representation of the extracted patch for final prediction (See <ref type="figure">Fig. 1b</ref>). For example, SEAL <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b52">53]</ref> learns the representation of a subgraph around a given node pair to predict the link between them. This framework fundamentally overcomes the above three limitations. First, subgraph extraction allows decoupling the contributions made by a node to different queries, which prevents information over-squashing. Second, subgraph patches can be paired with distance-related features that favor prediction over a set of nodes <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b52">53]</ref>. Third, subgraph extraction disentangles model depth and range of receptive field, which allows learning a rather nonlinear model with only relevant local subgraphs as input.</p><p>Despite their importance, the SGRL framework has not received as much attention as the canonical GNN framework in the system    <ref type="figure">Figure 1</ref>: A Toy Example of SGRL: the task is to predict whether or is more likely to form a link. Ideally, if this comes from a social network, is more likely linked because they share a common neighbor. However, canonical GNNs cannot tell such difference since and share the same subtree structures resulting in the same representation <ref type="bibr" target="#b43">[44]</ref>. SGRL solves this problem by extracting a subgraph patch around each queried node pair. Prediction based on the subgraph representation provides much better performance than canonical GNNs <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b52">53]</ref>.</p><formula xml:id="formula_0">x W M S q G 1 C N g k t s G W 4 E d h O F N A o E d o L J 3 d z v P K H S P J Y P Z p q g H 9 G R 5 C F n 1 F i p m Q 7 K F b f q L k D W i Z e T C u R o D M p f / W H M 0 g i l Y Y J q 3 f P c x P g Z V Y Y z g b N S P 9 W Y</formula><formula xml:id="formula_1">S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x / d x v T 1 B p H s t H M 0 3 Q j + h Q 8 p A z a q z U m P T L F b f q L k D W i Z e T C u S o 9 8 t f v U H M 0 g i l Y Y J q 3 f X c x P g Z V Y Y z g b N S L 9 W Y</formula><p>research community. The underlying challenge comes from the subgraph extraction step in SGRL, which can be rather irregular and time-consuming. Specifically, SGRL requires to materialize a subgraph patch for each query during training and inference. Previous works of SGRL typically extract subgraphs offline for all such queries <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b50">51]</ref>, but it is not scalable for large graphs due to extensive memory need. Meanwhile, the online extraction <ref type="bibr" target="#b47">[48]</ref> is not an option as it requires considerable processing time. The irregularity of subgraphs further makes it difficult to efficiently handle the extraction process in both cases.</p><p>Here, we aim to fill the gap by designing a novel computational framework SUREL, to support SGRL over large graphs. SUREL consists of a new system-friendly learning algorithm for SGRL and a scalable system to support this algorithm. The crucial design of SUREL is to reduce the overhead caused by the online subgraph extraction, which all current SGRL approaches suffer from.</p><p>The key idea behind SUREL is to break (and down-sample) subgraphs into random walks of regular size that can be easily sampled and, more importantly, reused among different queries. To compensate for the missing structural information after subgraph decomposition, we introduce relative position encoding (RPE), an intra-node distance feature that records the position of each node in the sampled subgraph. Specifically, for each node in the network, SUREL collects a certain number of random walk starting from . Each node appearing in these walks uses its landing counts at each step as the RPE vector. Overall, the set of collected walks paired with RPEs can be viewed as a subgraph patch centered at . The complexity of the above process is linear with the number of nodes, and can be done in parallel and offline. For training and inference, given a queried node set , SUREL first groups the sampled walks originated from all nodes in . Then, it implicitly joins the subgraph patches centered at each node in by combining their node-level RPEs into a query-level RPE for each node associated in the grouped walks, which can also be executed in full parallel. Finally, SUREL uses neural networks to learn the representation of the joined set of walks attached with query-level RPEs for final prediction. Since these walks are regular, the training process can be done quickly by GPU. The system architecture of SUREL is illustrated in <ref type="figure" target="#fig_8">Fig. 2</ref>.</p><p>Our contributions can be summarized as follows: (1) A Novel System-Friendly Algorithm. We propose the first scalable algorithm for SGRL tasks by adopting a novel walk-based computation framework. This framework uses regular data structures and allows extreme system acceleration. (2) Dedicated System Support (Open-source). We design SUREL to support the proposed algorithm. It can rapidly sample walks, encode positional features, and join them to represent multiple subgraphs in parallel. SUREL adopts many system optimization techniques including parallelization, memory management, load balancing, etc. (3) High Performance and Efficiency. We evaluate SUREL on link/relation/motif three prediction tasks over 6 real-world graphs of millions of nodes/edges. SUREL significantly outperform the current SGRL approaches, and executes 10? faster in training and testing. Meanwhile, benefiting from the SGRL essence, SUREL outperforms canonical GNNs by a great margin on prediction performance (almost 50% in all tasks).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES AND RELATED WORKS</head><p>In this section, we set up notations, formulate the SGRL problem and review some related works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notations</head><p>Definition 2.1 (Graph-structured data). Let G = (V, E, ) denote an attributed graph, where V = [ ] and E ? V?V are the node set and the edge set respectively. ? R ? denotes the node attributes with -dimension. Further, we use N to represent the set of nodes in the direct neighborhood of node , i.e., N = { : ( , ) ? E}. Definition 2.2 ( -hop Subgraph). Given a graph G and a node set of interest , let G denote the -hop neighboring subgraph w.r.t the set . G is the induced subgraph of G, of which the node set V includes the set and all the nodes in G whose shortest path distance to is less than or equal to . Its edge set is a subset of E, where each edge has both endpoints in its node set V . The nodes in V still carry the original node attributes if G is attributed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Learning Problems and Background</head><p>Now, we formally formulate the GRL and SGRL problems. Definition 2.3 (Graph Representation Learning (GRL)). Given a graph G and a queried set of nodes , graph representation learning aims to learn a mapping from the graph-structured data to some predicting labels as (G, ) ? , where the mapping (G, ) may reflect structures and node attributes of G and their relation to .</p><p>Next, we define SGRL where for a particular query , the predictions are made based on the local subgraph around . Definition 2.4 (Subgraph-based GRL (SGRL)). Given a node set over an ambient graph G and a positive integer , SGRL is to learn the mapping to some labels, which takes the -hop neighboring subgraph of in G as the input (G , ) ? . An SGRL task typically is given some labeled node set queries {( , )} =1 for training and other unlabeled node set queries { } + = +1 for testing. We list a few important examples of SGRL tasks. Link prediction seeks to estimate the likelihood of a link between two endpoints in a given graph. Additionally, it can be generalized to predict the type of links, such as relation prediction for heterogeneous graphs. In this case, the set corresponds to a pair of nodes. The network scientific community has identified the importance of leveraging the local induced subgraphs for link prediction <ref type="bibr" target="#b21">[22]</ref>. For example, the number of common friends (shown as neighbors in a social network) implies how likely two individuals may become friends in the future. Another generalized form of link prediction is higher-order pattern prediction, where the set consists of three or more nodes. The goal is to predict whether the set of nodes in will foster a covered edge (termed hyperedge).</p><p>Graph neural networks (GNNs). Canonical GNNs associate each node with a vector representation h, which is learned and updated by aggregating messages from 's neighbors, as</p><formula xml:id="formula_2">h = UPDATE h ?1 , AGGREGATE {h ?1 | ? N } .</formula><p>Here, UPDATE is implemented by neural networks while AGGRE-GATE is a pooling operation invariant to the order of the neighbors. By unfolding the neighborhood around each node, the computation graph to get each node representation forms a tree structure. According to Def. 2.4, canonical GNNs seem also able to perform SGRL by encoding the local subtree rooted at each node into a node representation (See <ref type="figure">Fig. 1a</ref>). Nevertheless, by this way, each node representation only separately reflects the subgraph around each node but cannot jointly represent the subgraph around multiple nodes, which yields the problem in <ref type="figure">Fig. 1</ref>. However, the SGRL framework considered in this work is able to learn the representation of the joint subgraph around a queried node set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Other Related Works</head><p>Without exception, previous works focus on improving the scalability of canonical GNNs and their system support, but some of their techniques inspire the design of SUREL.</p><p>To overcome the memory bottleneck of GPU when processing large-scaled graphs, sub-sampling the graph structure is a widely adopted strategy. GraphSAGE <ref type="bibr" target="#b12">[13]</ref> and VR-GCN <ref type="bibr" target="#b4">[5]</ref> use uniform sampling schema and variance reduction technique respectively to restrict the size of node neighbors; PIN-SAGE <ref type="bibr" target="#b45">[46]</ref> exploits Personalized PageRank (PPR) scores to sample neighbors. FastGCN <ref type="bibr" target="#b3">[4]</ref> and ASGCN <ref type="bibr" target="#b15">[16]</ref> perform independent layer-wise node sampling to allow neighborhood sharing. Cluster-GCN <ref type="bibr" target="#b6">[7]</ref> and GraphSAINT <ref type="bibr" target="#b48">[49]</ref> study subgraph-based mini-batching approaches to reduce the size of training graphs. Note that the subgraphs in our setting are substantially different from theirs, since our subgraphs work as features for queries while their subgraphs are a compensatory choice to achieve better scalability.</p><p>Many works better the system support for GNNs. DGL <ref type="bibr" target="#b39">[40]</ref> and PyG <ref type="bibr" target="#b8">[9]</ref> are designed for scalable single-machine GNN training. Marius <ref type="bibr" target="#b26">[27]</ref> is proposed to efficiently learn large-scale graph embeddings on a single machine. There are several distributed systems dedicated to GNNs: AliGraph <ref type="bibr" target="#b44">[45]</ref> addresses the storage issue of applying GNNs on massive industrial graphs; AGL [50] employs a subgraph-based system for GRL; ROC <ref type="bibr" target="#b16">[17]</ref> builds a multi-GPU framework for deeper and larger GNN models; Dorylus <ref type="bibr" target="#b35">[36]</ref> designs a CPU-based distributed system for GNN training. G 3 <ref type="bibr" target="#b22">[23]</ref> speedups GNN training via supporting parallel graph-structured operations. Zhou et al. <ref type="bibr" target="#b54">[55]</ref> uses feature dimension pruning to accelerate large-scale GNN inference. However, all these systems only support canonical GNNs so they all suffer from the intrinsic modeling limitations of GNNs.      </p><formula xml:id="formula_3">= " &gt; A A A B 9 H i c b V B N T w I x F H y L X 4 h f q E c v j c S E E 9 k 1 R D 2 S e P G I i Y A J b E i 3 d K G h 2 1 3 b t y R k w + / w 4 k F j v P p j v P l v 7 A I H B S d p M p l 5 L 2 8 6 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y z 1 Y 0 A N l 0 L x F g q U / D H R n E a B 5 J 1 g f J v 7 n Q n X R s T q A a c J 9 y M 6 V C I U j K K V / F 5 E c c S o z D q z f t o v V 9 y a O w d Z J 9 6 S V G C J Z r / 8 1 R v E L I 2 4 Q i a p M V 3 P T d D P q E b B J J + V e q n h C W V j O u R d S x W N u P G z e e g Z u b D K g I S x t k 8 h m a u / N z I a G T O N A j u Z h z S r X i 7 + 5 3 V T D G / 8 T K g k R a 7 Y 4 l C Y S o I x y R s g A 6 E 5 Q z m 1 h D I t b F b C R l R T h</formula><formula xml:id="formula_4">v 5 B + f C o p a N E M W y y S E S q H V C N g k t s G m 4 E t m O F N A w E P g b j 2 8 x / n K D S P J I P Z h q j H 9 K h 5 A P O q L G S 3 w 2 p G T E q 0 v a s l / T K F b f q z k F W i Z e T C u R o 9 M p f 3 X 7 E k h C l Y Y J q 3 f H c 2 P g p V Y Y z g b N S N 9 E Y U z a m Q + x Y K m m I 2 k / n o W f k 3 C p 9 M o i U f d K Q u f p 7 I 6 W h 1 t M w s J N Z S L 3 s Z e J / X i c x g x s / 5 T J O D E q 2 O D R I B D E R y R o g f a 6 Q G T G 1 h D L F b V b C R l R R Z m x P J V u C t / z l V d K 6</formula><formula xml:id="formula_5">I 1 M u Z f X L y R F 0 J w = " &gt; A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C V b B g 5 R d K e p F K H j x 2 I L 9 k O 5 S s m n a h i b Z J c k W y t J f 4 c W D I l 7 9 O d 7 8 N 6 b t H r T 1 w c D j v R l m 5 o U x Z 9 q 4 7 r e T W 1 v f 2 N z K b x d 2 d v f 2 D 4 q H R 0 0 d J Y r Q B o l 4 p N o h 1 p Q z S R u G G U 7 b s a J Y h J y 2 w t H 9 z G + N q d I s k o 9 m E t N A 4 I F k f U a w s d J T / c 5 P k 8 u x P + 0 W S 2 7 Z n Q O t E i 8 j J c h Q 6 x a / / F 5 E E k G l I R x r 3 f H c 2 A Q p V o Y R T q c F P 9 E 0 x m S E B 7 R j q c S C 6 i C d H z x F 5 1 b p o X 6 k b E m D 5 u r v i R Q L r S c i t J 0 C m 6 F e 9 m b i f 1 4 n M f 3 b I G U y T g y V Z L G o n 3 B k I j T 7 H v W Y o s T w i S W Y K G Z v R W S I F S b G Z l S w I X j L L 6 + S 5 l X Z u y 5 X 6 p V S 9 S y L I w 8 n c A o X 4 M E N V O E B a t A A A g K e 4 R X</formula><formula xml:id="formula_6">I 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 q V N y b p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D G / 8 T K g k R a 7 Y Y l G Y S o I x m f 1 N B k J z h n J i C W V a 2 F s J G 1 F N G d p 0 S j Y E b / n l V f J 4 W f W</formula><formula xml:id="formula_7">= " &gt; A A A C H n i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 1 V w U U o i 9 b E s u H F Z w T 6 g C W E y n b Z D J w / m U V p C v s S N v + L G h S K C K / 0 b J 2 0 W t v X A h c M 5 9 3 L v P X 7 M q J C W 9 W M U 1 t Y 3 N r e K 2 6 W d 3 b 3 9 A / P w q C U i x T F p 4 o h F v O M j Q R g N S V N S y U g n 5 g Q F P i N t f 3 S X + e 0 x 4 Y J G 4 a O c x s Q N 0 C C k f Y q R 1 J J n X j k B k k O M W N J J v U R V J i l 0 V M y U g A v G W B s V 6 P Q j j h i D E 8 8 s W 1 V r B r h K 7 J y U Q Y 6 G Z 3 4 5 v Q i r g I Q S M y R E 1 7 Z i 6 S a I S 4 o Z S U u O E i R G e I Q G p K t p i A I i 3 G T 2 X g r P t d K D e r e u U M K Z + n c i Q Y E Q 0 8 D X n d n N Y t n L x P + 8 r p L 9 W z e h Y a w k C f F 8 U V 8 x K C O Y Z Q V 7 l B M s 2 V Q T h D n V t 0 I 8 R B x h q R M t 6 R D s 5 Z d X S e</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>u y a l 9 X a w + 1 c v 0 s j 6 M I T s A p u A A 2 u A F 1 c A 8 a o A k w e A I v 4 A</head><formula xml:id="formula_8">2 8 G 8 / G q / F h f M 5 b C 0 Y + c w w W Y H z / A m Z X o y o = &lt; / l a t e x i t &gt; X u,x ] X v,x , 8x</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE ARCHITECTURE OF SUREL</head><p>In this section, we first give an overview of the SUREL framework as shown in <ref type="figure" target="#fig_8">Fig. 2</ref>. Then, we focus on the design and the implementation of three modules: Walk Sampler &amp; Relative Position Encoder (Preprocessing), Walk-based Subgraph Storage, Query-based Subgraph Joining &amp; Neural Encoding. At last, we elaborate an efficient training pipeline with Subgraph Query Mini-batching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>Existing SGRL frameworks that extract a subgraph per query do not support efficient training and inference. -hop subgraph extraction faces the size "explosion" issue as many nodes have significantly large degrees in real-world networks. Moreover, subgraphs of different sizes cause workload fluctuation, hindering load balancing and memory management.</p><p>Subgraph extraction can be replaced with efficient walk-based sampling, which sidesteps all above issues via regulating the number and the length of sampled walks. The number and the length of these walks are small constants, so the space and time complexity here is only linear w.r.t the number of nodes. Specifically, during preprocessing, SUREL reduces the subgraph around each node in a given graph to a set of random walks originated from it. To compensate for the loss of structural information after breaking subgraphs into walks, an intra-node distance feature termed relative positional encoding (RPE) is proposed, which enables locating each node in the sampled subgraph. The collected set of walks paired with its RPEs is hosted in the walk-based subgraph storage, with a dedicated data structure designed to support rapid and intensive access. The preprocessing flow is presented in the upper part of <ref type="figure" target="#fig_8">Fig. 2</ref>.</p><p>For training and testing, given a query (set of nodes), SUREL employs subgraph joining to implicitly construct a subgraph around the entire query in full parallel. First, all the walks originated from the queried node set are grouped. Then, the precomputed node-level RPEs are joined into query-level RPEs. SUREL further adopts neural networks to encode the grouped walks paired with query-level RPEs, and makes final predictions based on the obtained subgraph representation. A mini-batching strategy is designed to maximize data reuse during training by exploiting the query overlaps.      </p><formula xml:id="formula_9">O I t h V T n P Y S Q X H o c 9 r 1 J z d z v / t A h W R x d K + m C f V C P I p Y w A h W W h q Y 5 a p r W 3 X L 9 q y 8 X w z M i l 2 z F 0 D r x M l J B X K 0 B u Z X f x i T N K S R I h x L 6 T p 2 o r w M C 8 U I p 7 N S P 5 U 0 w W S C R 9 T V N M I h l V 6 2 O H 2 G z r U y R E E s d E U K L d T f G x k O p Z y G v p 4 M s R r L V W 8 u / u e 5 q Q q u v Y x F S a p o R J Y P B S l H K k b z H N C Q C U o U n 2 q C i W D 6 V k T G W G C i d F o l H Y K z + u V 1 0 q n X n M t a 4 6 5 R a V p 5 H E U 4 h T O o g g N X 0 I R b a E E b C D z C M 7 z C m / F k v B j v x s d y t G D k O y f w B 8 b n D 8 K 8 k Q k = &lt; / l a t e x i t &gt; ([0, 2, 0], [0, 2, 0]) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B W h 8 S 8 9 u N k + Y m 1 0 9 D z S Z b 0 K j M x Y = " &gt; A A A B + n i c b V D L S s N A F L 2 p r 1 p f q S 7 d B I t Q I Z S k F H V Z c O O y g n 1 A G s p k O m m H T i Z h Z q K U 2 E 9 x 4 0 I R t 3 6 J O / / G a Z u F t h 6 4 l 8 M 5 9 z J 3 T p A w K p X j f B u F j c 2 t 7 Z 3 i b m l v / + D w y C w f d 2 S c C k z a O G a x 6 A V I E k Y 5 a S u q G O k l g q A o Y K Q b T G 7 m f v e B C E l j f q + m C f E j N O I 0 p B g p L Q 3 M c t W</formula><formula xml:id="formula_10">W I d Y D j / l 2 i 7 U = " &gt; A A A B + n i c b V B N S 8 N A E J 3 U r 1 q / U j 1 6 W S x C h V A S K e q x 4 M V j B d s K b S i b 7 a Z d u t m E 3 Y 1 S Y n + K F w + K e P W X e P P f u G 1 z 0 N Y H w z z e m 2 F n X 5 B w p r T r f l u F t f W N z a 3 i d m l n d 2 / / w C 4 f t l W c S k J b J O a x v A + w o p w J 2 t J M c 3 q f S I q j g N N O M L 6 e + Z 0 H K h W L x Z 2 e J N S P 8 F C w k B G s j d S 3 y 9 W u 6 7 i O 5 z t 5 P + v b F b f m z o F W i Z e T C u R o 9 u 2 v 3 i A m a U S F J h w r 1 f X c R P s Z l p o R T q e l X q p o g s k Y D 2 n X U I E j q v x s f v o U n R p l g M J Y m h I a z d X f G x m O l J p E g Z m M s B 6 p Z W 8 m / u d 1 U x 1 e + R k T S a q p I I u H w p Q j H a N Z D m j A J C W a T w z B R D J z K y I j L D H R J q 2 S C c F b / v I q a Z / X v I t a / b Z e a T h 5 H E U 4 h h O o g g e X 0 I A b a E I L C D z C M 7 z C m / V k v V j v 1 s d i t G D l O 0 f w B 9 b n D 7 + g k Q c = &lt; / l a t e x i t &gt; ([0, 0, 1], [0, 0, 1]) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 H m p Y 6 V A S e N / O d N O c k 3 k 7 y n m L m Q = " &gt; A A A C J n i c b V D L S s N A F J 3 U V 6 2 v q k s 3 g 0 X o o p R E i r o R C m 5 c V r A P a E K Y T K f t 0 M k k z K O 0 h H y N G 3 / F j Y u K i D s / x U n b h W 0 9 M H A 4 5 1 z m 3 h P E j E p l 2 9 9 W b m t 7 Z 3 c v v 1 8 4 O D w 6 P i m e n r V k p A U m T R y x S H Q C J A m j n D Q V V Y x 0 Y k F Q G D D S D k Y P m d 8 e E y F p x J / V N C Z e i A a c 9 i l G y k h + 8 d 4 N k R p i x J J O 6 i e 6 M k m h q 2 O m J V w x x s a o w A l 0 K Y e u i Q U V V B m 7 q V 8 s 2 V V 7 D r h J n C U p g S U a f n H m 9 i K s Q 8 I V Z k j K r m P H y k u Q U B Q z k h Z c L U m M 8 A g N S N d Q j k I i v W R + Z g q v j N K D / U i Y x x W c q 3 8 n E h R K O Q 0 D k 8 x 2 l + t e J v 7 n d b X q 3 3 k J 5 b F W h O P F R 3 3 N o I p g 1 h n s U U G w Y l N D E B b U 7 A r x E A m E l W m 2 Y E p w 1 k / e J K 3 r q n N T r T 3 V S v X y s o 4 8 u A C X o A w c c A v q 4 B E 0 Q B N g 8 A L e w A x 8 W K / W u / V p f S 2 i O W s 5 c w 5 W Y P 3 8 A s o A p d c = &lt; / l a t e x i t &gt; Xu,x ] Xv,x, x 2 {u, b, a, v}</formula><formula xml:id="formula_11">d z E + B l V h j O B 0 2 I v 1 Z h Q N q Z D 7 F o q a Y T a z + a n T s m 5 V Q Y k j J U t a c h c / T 2 R 0 U j r S R T Y z o i a k V 7 2 Z u J / X j c 1 4 Y 2 f c Z m k B i V b L A p T Q U x M Z n + T A V f I j J h Y Q p n i 9 l b C R l R R Z m w 6 R R u C t / z y K m l d V r 2 r a u 2 + V q 5 X 8 j g K c A p n U A E P r q E O d 9 C A J j A Y w j O 8 w p s j n B f n 3 f l Y t K 4 5 + c w J / I H z + Q M 6 1 4 0 J &lt; / l a t e x i t &gt; (1) Random Walks &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S G 6 h u J M Q h K 2 N d y h A S q R 2 T 7 W y g G E = " &gt; A A A B 6 n i c b V D L S g N B E O y N r x h f U Y 9 e B o M Q L 2 F X g 3 o M e P E Y 0 T w g W c L s p D c Z M j u 7 z M w K I e Q T v H h Q x K t f 5 M 2 / c Z L s Q R M L G o q q b r q 7 g k R w b V z 3 2 8 m t r W 9 s b u W 3 C z u 7 e / s H x c O j p o 5 T x b D B Y h G r d k A 1 C i 6 x Y b g R 2 E 4 U 0 i g Q 2 A p G t z O / 9 Y R K 8 1 g + m n G C f k Q H k o e c U W O l h / L l e a 9 Y c i v u H G S V e B k p Q Y Z 6 r / j V 7 c c s j V A a J q j W H c 9 N j D + h y n A m c F r o p h o T y k Z 0 g B 1 L J Y 1 Q + 5 P 5 q V N y Z p U + C W N l S x o y V 3 9 P T G i k 9 T g K b G d E z V A v e z P x P 6 + T m v D G n 3 C Z p A Y l W y w K U 0 F M T G Z / k z 5 X y I w Y W 0 K Z 4 v Z W w o Z U U W Z s O g U b g r f 8 8 i p p X l S 8 q 0 r 1 v l q q l b M 4 8 n A C p 1 A G D 6 6 h B n d Q h w Y w G M A z v M K b I 5 w X</formula><formula xml:id="formula_12">Y d H H M Y j 7 w k S C M R q Q r q W R k k H C C Q p + R v j + 9 z v 3 + P e G C x t G d n C X E D d E 4 o g H F S G r J M 0 + G I Z I T j F g 6 y L x U 1 V X 2 4 D T r V t 1 y P b N q N a w 5 4 C q x C 1 I F B T q e + T U c x V i F J J K Y I S E c 2 0 q k m y I u K W Y k q w y V I A n C U z Q m j q Y R C o l w 0 / k L G T z X y g g G M d c V S T h X f 0 + k K B R i F v q 6 M z 9 Y L H u 5 + J / n K B l c u S m N E i V J h B e L A s W g j G G e B x x R T r B k M 0 0 Q 5 l T f C v E E c Y S l T q 2 i Q 7 C X X 1 4 l v W b D v m i 0 b l v V d q 2 I o w x O w R m o A R t c g j</formula><formula xml:id="formula_13">v m C t s 1 C M Y C X b e B X 0 c = " &gt; A A A C A n i c b V D L S s N A F J 3 U V 6 2 v q C t x M 1 i E L k p J S l G X B T c u K 9 g H p C F M p p N 2 6 G Q S Z i Z C C d G N v + L G h S J u / Q p 3 / o 2 T N g t t P X D h c M 6 9 3 H u P H z M q l W V 9 G 6 W 1 9 Y 3 N r f J 2 Z W d 3 b / / A P D z q y S g R m H R x x C I x 8 J E k j H L S V V Q x M o g F Q</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Preprocessing -Walk Sampling &amp; Encoding</head><p>The bottleneck of current SGRL frameworks is how to cheaply acquire the -hop neighbors for each queried set of nodes. SUREL proposes to decompose the -hop subgraph into a set of -length walks that start from the queried set of nodes. As the walks are regular, their storage and access are extremely efficient. This also resolves the computational problem caused by the long-tailed distribution of node degrees. More importantly, the collected walks grouped by their starting nodes can be shared and reused among different queries. Our design decouples SGRL from redundant subgraph extraction and enables the reusability of preprocessed data. We summarize the preprocessing routines with the support of hashindexed storage in Algorithm 1 and introduce the specifics next. Walk Sampling. During preprocessing, SUREL samples -many -step walks for every node in a given graph. As <ref type="figure">Fig. 3</ref> (upper left) shows, the sampled walks are grouped in a set W , where denotes the starting node of these walks. Walk sampling can be easily divided into parallelizable pieces. The parallelization is implemented based on NumPy and OpenMP framework in C. Moreover, to further accelerate walk sampling, we use compressed sparse row (CSR) to represent the graph. The CSR format consists of two arrays, idxptr of length |V | + 1 used to record the degrees of nodes, and indices of size |E |, each row of which corresponds to the neighbor list per node. CSR allows intensive fast access to the neighbors of a node while keeping the memory cost low, which is vital for walk sampling in large-scale graphs.</p><p>Relative Positional Encoding (RPE). Structural information gets lost after breaking subgraphs into walks. SUREL compensates such loss via RPE to locate the relative position of a node in each sampled subgraph, which characterizes the structural contribution of the node to its corresponding subgraph.</p><p>For each set of walks W , we first establish a set V that contains distinct nodes appearing in W . Define node-level RPE X : V ? Calculate RPE for ? ? V , save the value X , to T , and write its index in T as RPE-ID , back to H ( ); R +1 as follows: for each node ? V , a vector X , ? R +1 is assigned, where X , [ ] is the landing counts of node at position in all walks of W . In SUREL, RPE can be computed on the fly as walks get sampled, thus resulting in nearly zero extra computational cost. The set of walks W paired with the RPE X essentially characterize a sub-sampled subgraph around the node . Next, we present a dedicated data structure to host W and X altogether.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Walk-based Subgraph Storage</head><p>It is easy to manage the collected set of walks due to its regularity. An * -sized chunk is allocated to each set of walks, which assists to speed up data fetching. How to organize node-level RPE presents a real challenge because the cardinality of the set |V | varies from node to node. One na?ve way to avoid such irregularity is to directly scatter these RPEs back to nodes in previously collected walks. But, this gives an * * ( + 1) tensor, resulting in an unrealizable memory need. Moreover, it loses track of node IDs in walks that are needed for joining subgraphs later.</p><p>We use an associative array A to organize all walk-based subgraphs as shown in the upper part of <ref type="figure">Fig. 3</ref>. For each node ? V, its corresponding entry in A is a node-level subgraph formed as a tuple (W , H ). Here, W is a set of walks starting from , and H is a dictionary that maps the unique node set V of W to its corresponding node-level RPE X . The use of dictionary resolves irregularities in V mentioned above, while maintaining the connection between node IDs and their RPEs. In addition, array T is introduced to store RPE values centrally, rather than scattered across dictionaries. As <ref type="figure">Fig. 3 (upper right)</ref> shows, the value of H ( ) is now replaced with the index of the RPE value X , stored in T accordingly, noted as RPE-ID , . This design overall guarantees the access of RPE in (1) time.</p><p>The above A and H are built on top of uthash's macros 1 , with extended support for arbitrary insertions and deletions of key-value pairs. It offers data access and search in (1) time on average, which is about as good as the direct address table but greatly reduces the space wastage. In particular, it has no dependency or need for communication between multiple hash queries, thus can be pleasingly executed in parallel. Both A and H are stored in RAM on the CPU side. As we observed in <ref type="figure">Fig. 3</ref>, there are many repeated RPE values. Once all nodes are sampled, the array T can be pruned to remove duplicates. RPE-IDs will be updated synchronously when T is reindexed. For example, both node and have the RPE value of [0, 0, 1], whose index in T is (1) after pruning. Thus, both H ( ) and H ( ) are assigned to the new RPE-ID as <ref type="bibr" target="#b0">(1)</ref>. The shape of T is regular and its size is usually small after pruning, which can be fully loaded in GPU. In practice, we found that pining RPEs in GPU memory is critical, as it can significantly reduce the communication cost of moving data back and forth between RAM and SDRAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Query-based Subgraph Joining</head><p>The storage designed above records the downsampled subgraph around each node. As SGRL is mostly useful for making predictions over a set of nodes , here we further illustrate how to get the joined subgraph around all the nodes ? .</p><p>The idea is to concatenate all set of walks [..., W , ...] for ? , since each set of walks W can be viewed as a subgraph around . Besides, each node in the walks will be paired with a query-level RPE X , that characterizes the relative position of node in the joint subgraph around the queried set . Specifically, X , is defined by joining all RPEs X , for ? , i.e., X , = ? ? X , (? [..., X , , ...]) ? R ( +1)? | | . There will be some ? such that ? V , for which X , is set to all zeros. Through this procedure, the joined subgraph with query-level RPEs is sent to GPU for representation learning and then model inference.</p><p>The data structure described in Sec. 3.3 enables a highly parallel implementation of subgraph joining along with optimized memory management. On the CPU side, X , is not directly used to assemble walks. Instead, we use a query-level RPE-ID that joins node-level RPE indices in T , i.e. use RPE-ID , = [..., RPE-ID , , ...] ? R | | for ? , which reduces the memory cost from ( + 1) * | | to | |. For instance, in <ref type="figure">Fig. 3 (bottom right)</ref>, X , = ([2, 0, 0], [0, 0, 1]) can be substituted by RPE-ID , = (3, 1), as their RPE values locate at the entry (3) and (1) of T . As follows, SUREL pre-allocates an array with the fixed-size [ * * | |, | |], where * * | | is the size of walks around . Then, SUREL fills the index array with RPE-ID , by multithreads. Note that RPE-ID , can be rapidly retrieved via the dictionary operation H ( ). Lastly, assembling RPE values to walks is performed on GPU via the indexing operation X , = T (RPE-ID , ), where T is pinned in GPU memory earlier. SUREL incorporates a Python/C hybrid API for subgraph joining, building on top of NumPy, PyTorch, OpenMP and uthash.</p><p>Some remarks can be made here. First, the above algorithm contains some redundancy to compute the query-level RPE-ID for the nodes that appear multiple times in the walks. In practice, we find that about half of the nodes appear only once, thus doubling the computation time at most. To avoid such redundancy, one can first compute the set union V = ? ? V , and then compute the querylevel RPE-ID by traversing all nodes in V . However, parallel set union is difficult to implement efficiently. When multithreading is enabled, we observe a significant increase in the efficiency of SUREL, as opposed to the union operation. Also, by dynamically adjusting the number of threads, the workload between CPU and GPU can be well balanced. Second, we have empirically found that using RPE-ID instead of RPE to assemble walks provides an observable performance boost (speed up by 2? or more), otherwise data communication between CPU and GPU would the main bottleneck. Perform subgraph joining for queries in Q; <ref type="bibr" target="#b7">8</ref> Encode the concatenated walks by NN(?) to get the subgraph representation ? for each query; <ref type="bibr" target="#b8">9</ref> Use backpropagation <ref type="bibr" target="#b30">[31]</ref> to optimize model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">end</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Neural Encoding</head><p>After subgraph joining for each query, the obtained subgraph is represented by a concatenated set of walks on which nodes are paired with query-level RPEs (See <ref type="figure">Fig. 3</ref>). Next, we introduce neural networks to encode these walks into a subgraph representation ? . Due to its regularity, any sequential models, e.g., MLP, CNN, RNN, and transformers can be adopted for sampled walks. We test RNN and MLP for neural encoding, both of which achieve similar results. Next, we take the RNN as an example. We encode each walk = ( 0 , 1 , ..., ) ? W as enc( ) = RNN({ X , } =0,1,..., ), where 's denote the node at step in one sampled walk. Here, is to encode the query-level RPE. Node or edge attributes for each step ? can be supported by attaching those attributes after its RPE. To obtain the final subgraph representation of , we aggregate the encoding of all the associated walks through a mean pooling, i.e., ? = mean({enc( )| starts from some ? }). In the end, a two-layer classifier is used to make prediction by taking ? as input. In our experiments, all the tasks can be formulated as binary classification, and thus we adopt Binary Cross Entropy as the loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">The Training and Serving Pipelines</head><p>SUREL organically incorporates the storage designed in Sec. 3.3 and the subgraph-joining operation described in Sec. 3.4 to achieve efficient training and model serving.</p><p>Subgraph queries 's are sets of nodes, which often come from a common ambient on a large graph. There might be many overlaps between different queries and their -hop induced subgraphs. If the queried subgraphs are known in prior, we may put these queries with high node overlap into the same batch to improve data reuse. Here, queries of each given task are assumed to have the same size, e.g. | | = 2 for link prediction. In practice, test queries are usually given online while the training ones can be prepared in advance. Hence, we propose to accelerate the training pipeline by mini-batching the overlapping queries. Practitioners can choose the appropriate pipeline according to the specific situation. Algorithm 2 summarizes the overall training procedure of SUREL. Mini-batching for Training. We first randomly sample a seedset of nodesV from the union of queried node sets ? . Then, we run breadth-first search (BFS) to expand the seed-setV. Neighbor fetching of the BFS here is based on the grouped queries instead of the original graph: a neighbor of node is defined as the node that shares at least one query with it. During BFS, the reached queries will be added to a set Q. The expansion stops once the size of either the seed-setV or the mini-batch Q reaches some pre-defined limits. Since the data structure for each query in SUREL after subgraph joining is regular, it is easy to decide the size limits of seed-set and mini-batch based on resource availability (i.e. GPU memory). In practice, this BFS procedure improves reusability of data within each mini-batch, and may significantly decrease the communication cost between CPU and GPU. If the training set only contains positive queries (often in link/motif prediction tasks), we design an efficient sampling strategy for negative queries by the same principle that randomly pairs them within the same batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head><p>In this section, we aim to evaluate the following points:</p><p>? Regarding prediction performance, can SUREL outperform stateof-the-art SGRL models? Can SUREL significantly outperform canonical GNNs and transductive graph embedding methods due to the claimed benefit of SGRL? ? Regarding runtime, can SUREL significantly outperform state-ofthe-art SGRL models? Can SUREL achieve runtime performance comparable to canonical GNNs? Previous SGRL models are typically much slower than canonical GNNs. ? How about the parameter sensitivity of SUREL? How do the parameters and impact the overall performance? ? How is the parallel design of SUREL performing and scaling?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Setup</head><p>We conduct extensive experiments to evaluate the proposed framework with three kinds of graphs (homogeneous, heterogeneous, and higher-order homogeneous) on three corresponding types of tasks, namely, link prediction, relation prediction and higher-order pattern prediction. Homogeneous graphs are the graphs without node/link types. Heterogeneous graphs include node/link types. Higher-order graphs contain higher-order links that may connect more than 2 nodes. The dataset statistics are summarized in <ref type="table" target="#tab_0">Table  1</ref>, most of which are larger than the datasets used in <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref>, not to mention that our node-set prediction task is much more complex than the node classification task considered in the previous works. Open Graph Benchmark (OGB). We use three link prediction and one relation prediction datasets <ref type="bibr" target="#b13">[14]</ref>: ppa -a protein interaction network, collab -a collaboration network, and citation2 -a citation network; and one heterogeneous network ogb-mag, which contains four types of nodes (paper, author, institution and field) and their relations extracted from MAG <ref type="bibr" target="#b38">[39]</ref>.</p><p>Higher-order Graph Dataset. DBLP-coauthor is a temporal higher-order network that records co-authorship of papers as timestamped higher-order links. tags-math contains sets of tags that are applied to questions on the website math.stackexchange.com as higher-order links. For the two higher-order graphs, SUREL and all the baselines will treat them as standard graphs by projecting higher-order links into cliques. However, the training and test queries are generated based on higher-order links detailed next.</p><p>Settings. For Link Prediction, we follow the data split as OGB requires to isolating the validation and test links (queries) from the graphs. For Relation Prediction, the relations of paper-author (P-A) and paper-citation (P-P) are selected. The dataset is split based on timestamps. 0.5% of existing edges of each target relation type are selected from ogb-mag. For each paper, two authors/citations are picked from its P-A/P-P relations respectively, one for validation and the other for testing. The remaining links are used for training. For Higher-order Pattern Prediction, we focus on predicting whether two nodes will be connected to a third node concurrently via a higher-order link in the future. Specifically, positive queries are node triplets, where two nodes are linked before the timestamp and the third node establishes connection to the pair via a higherorder link after . The split ratio of positive node triplets is 60/20/20 for training/validation/testing. For Relation Prediction and Higherorder Pattern Prediction, each positive query is paired with 1000 randomly sampled negative queries (except tags-math uses 100) in testing. For fair comparison, all baselines are tested with the same set of negative queries sampled individually for each dataset. All experiments are run 10 times independently, and we report the mean performance and standard deviations.</p><p>Baselines. We consider three classes of baselines. Graph Embedding methods for transductive learning: Node2vec <ref type="bibr" target="#b10">[11]</ref> and Deep-Walk <ref type="bibr" target="#b29">[30]</ref>, which learns a single embedding for each node and may suffer from the information over-squashing issue; Canonical GNNs: GCN <ref type="bibr" target="#b18">[19]</ref>, GraphSAGE <ref type="bibr" target="#b12">[13]</ref>, GraphSAINT <ref type="bibr" target="#b48">[49]</ref>, Cluster-GCN <ref type="bibr" target="#b6">[7]</ref>, Relational GCN (R-GCN) <ref type="bibr" target="#b31">[32]</ref>, Relation-aware Heterogeneous Graph Neural Network (R-HGNN) <ref type="bibr" target="#b46">[47]</ref>; SGRL models: SEAL <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b52">53]</ref>, DE-GNN <ref type="bibr" target="#b20">[21]</ref>. SEAL supports both offline and online subgraph extraction per query. However, it takes SEAL 2+ hours and 102GB RAM to offline extract 2% training subgraphs on citation2. Thus, we only keep the online setting for SEAL. DE-GNN only supports offline subgraph extraction. <ref type="table" target="#tab_1">Table 2</ref> compares subgraph sampling for different SGRL methods. We adopt official implementations of above baselines with tuned parameters that match reported results. Metric. The evaluation metrics include Hits@K and Mean Reciprocal Rank (MRR). Hit@K counts the percentage of positive samples ranked at the top-K place against all the negative ones. MRR firstly calculates the inverse of the ranking of the first correct prediction against the given number of paired negative samples, and then an average is taken over the total queries.</p><p>Environment. We use a server with four Intel Xeon Gold 6248R CPUs, 1TB DRAM, and eight NVIDIA RTX 6000 (24GB) GPUs. <ref type="table" target="#tab_4">Table 3</ref> shows results of three prediction tasks. Apparently, for these three link prediction benchmarks, the performance of SGRL models is significantly better than transductive graph embedding models and canonical GNNs, particularly for the challenging tasks over ppa and collab. Within SGRL models, SUREL sets two SOTA results on ppa and citation2, and gets comparable performance on collab against SEAL, which validates the modeling effectiveness of our proposed walk-based framework. For relation prediction and higher-order pattern prediction, we observe a large gap (up to 60%) between canonical GNNs and SUREL-based models, especially in higher-order cases. This again demonstrates the inherent modeling limitation of canonical GNNs to predict over a set of nodes. DE-GNN suffers from serious scalability issues when employing subgraph extraction for higher-order pattern prediction. Our best attempt is to deploy DE-GNN on tags-math by using 10% training samples, while the other three graphs failed. DE-GNN spends more than 300 hours preprocessing just 5% training queries of DBLP-coauthor.   <ref type="table" target="#tab_5">Table 4</ref> reports the runtime, memory consumption comparison on a single machine (using one GPU) between canonical GNNs and SGRL models. SUREL offers a reasonable total runtime on these benchmarks compared with canonical GNNs. Meanwhile, its preprocessing overhead is negligible as showed in <ref type="table" target="#tab_5">Table 4</ref> under the term 'Prep.', and the higher-order case can be efficiently handled as well. SEAL adopts online extraction, and thus the cost is not counted in preprocessing, while its training suffers from the computation bottleneck. DE-GNN uses offline extraction, and it takes 15+ hours and 98GB RAM to process training queries in tags-math, which is obviously incapable of scaling to DBLP-coauthor (so not present in <ref type="table" target="#tab_5">Table 4</ref>). Overall, SUREL substantially accelerates the subgraph extraction and makes it feasible for SGRL on large-scale graphs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Prediction Performance Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Runtime and Memory Complexity Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test MRR</head><p>Step of Walks </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test Hits@50</head><p>Step </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inference Time(s)</head><p>Step </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inference Time (x1000s)</head><p>Step    In terms of memory management, SUREL achieves comparable RAM usage to canonical GNNs, because the number of walks and the steps are small constants in practice. The extra memory cost is linear in |V |, so the total memory cost is still dominated by the original graph. However, SEAL induces much more RAM usage as it extracts subgraphs of long-tail sizes, and its total memory cost is often super-linear in |V |. Both SEAL and SUREL consume much less SDRAM because they do not need GPU to load large adjacency matrices and host node representations.</p><p>We further profile the training and inference performance, and present it in <ref type="figure" target="#fig_16">Fig. 4</ref>. The upper half plots the time-to-accuracy comparison between canonical GNNs and SGRL models. Each dot indicates one training epoch for full-batch GCN, SEAL and SUREL, 10 training epochs for Cluster-GCN and GraphSAINT. As it shows, both SEAL and SUREL use 1-3 epochs to get good enough performance, and each epoch of SUREL takes around 1/10 time of SEAL on citation2. The time per epoch of full-batch GCN is comparable with SUREL, while Cluster-GCN and GraphSAINT are faster. However, these models generally take longer time to converge to even subpar performance. On ppa, the curve of SEAL is pretty oscillating, leading to longer convergence. SUREL uses large and to achieve better and more stable performance on ppa, so the training time per epoch is comparable with SEAL. The training curves of canonical GNN baselines are not plotted for ppa because of their poor performance (See <ref type="table" target="#tab_4">Table 3</ref>).</p><p>The bottom half of <ref type="figure" target="#fig_16">Fig. 4</ref> provides the comparison of end-to-end inference throughput between two classes of models. Canonical GNNs offer rapid inference, since they generate node representations as the intermediate computation results that are shared across all queries. But as aforementioned, sharing node representations may over-squash useful information and degenerate performance as shown in <ref type="table" target="#tab_4">Table 3</ref>. SEAL, as SGRL, achieves good prediction performance but its inference is extremely slow, because of subgraph extraction per query. SUREL fundamentally solves this bottleneck by replacing the extraction with walk-based subgraph joining. It is 4 ? 16? faster than SEAL on inference for link prediction, and achieves even more speedup than DE-GNN in higher-order settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Significant Hyperparameter Analysis</head><p>The number , the step of walks and the hidden dimension effect scalability and accuracy of SUREL. To examine their impact, we evaluate SUREL on citation2, a large sparse graph, and collab, a medium dense graph, for different values of , , and .</p><p>Prediction Performance. <ref type="figure" target="#fig_20">Fig. 5</ref>(a) and 5(d) show the prediction results. As expected, the performance consistently increases if we use a larger number of walks . But for the step , it is not always true that longer steps will guarantee better results, which depends on the specifics of the dataset. For instance, in network citation2, to accurately predict the link between two papers, more steps are needed as it would capture a larger group of papers which share similar semantics. While for collab, the case is different, as deeper walks would include more noise for predicting collaborations between two authors. In general, some small (2 ? 5) and (50 ? 400) ensure adequate performance. By adjusting and , we can achieve the trade-off between accuracy and scalability, none of which is achievable through other SGRL models. Moreover, SUREL is insensitive to the hidden dimension as shown by <ref type="figure" target="#fig_20">Fig. 5(d)</ref>.</p><p>Training and Inference Time Cost. As Figs. 5(b) and 5(c) demonstrated, the time of walk sampling and subgraph joining is nearly linear w.r.t. the total number of walks ( * ) under the same number of threads (16 by default). Here, we do not regulate based on the degree of each node in a query, which may induce certain duplication in sampled walks originated from the nodes with small degrees. Using degree-adaptive is promising to further improve the scalability of SUREL while keeping good prediction performance. We leave such investigation for future study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Performance Scaling</head><p>To investigate the scaling performance of the parallel implementation, we examine the runtime of heavy operations in SUREL by using different numbers of threads. <ref type="figure" target="#fig_22">Fig. 6(a)</ref> shows the throughput of walk sampler and query-level RPE joining on citation2. The runtime is also compared to the estimated runtime by Amdahl's law <ref type="bibr" target="#b9">[10]</ref> shown in <ref type="figure" target="#fig_22">Fig. 6(b)</ref>: walk sampling and RPE joining are in good agreement with the expected speedup, thus implying well parallelized implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We propose a novel computational paradigm, SUREL for subgraphbased representation learning on large-scale graphs. SUREL targets predicting relations over set of nodes. It decouples graph structures into sets of walks to avoid irregularities in subgraphs and enable reuse of intermediate results. It then applies walk-based subgraph joining paired with relative positional encoding for representation learning of queried node sets. Such design allows for full parallelization and significantly improves model scalability. SUREL incorporates the principle of algorithm and system co-design that unlocks the full potential of learning on large-scale data with limited resources. To the best of our knowledge, this is the first work to study subgraph-based representation learning from the perspective of system scalability. Experiments also show that SUREL achieves superior performance in both prediction and scalability on three different SGRL tasks over six large, real-world graph benchmarks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A NOTATIONS</head><p>Frequently used symbols are summarized in <ref type="table" target="#tab_8">Table 5</ref>. <ref type="figure" target="#fig_23">Fig. 7</ref> shows the degree distribution and the node size of subgraph with respect to different numbers of hops in real-world networks collab and citation2. The node size of subgraphs dramatically increases when the number of hop ? 2, because many nodes have significantly large degrees in real-world networks as <ref type="figure" target="#fig_23">Fig. 7</ref> LEFT illustrated. This leads to the size "explosion" issue for current SGRL models. Accordingly, most of SGRL models including SEAL <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b52">53]</ref> and DE-GNN <ref type="bibr" target="#b20">[21]</ref> can only accommodate at most 1-hop neighbors over large networks to avoid the scalability crisis, which in return compromises their performance. SUREL solves this issue by breaking the subgraph into regular walks, which enables it to reach up to -hop neighbors via -step random walks. The long-hop neighbors give extra information, which is beneficial for improving the prediction performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B FURTHER ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C LIMITATIONS OF CANONICAL GNNS AND MORE ILLUSTRATION OF THE ALGORITHMIC INSIGHTS OF SUREL</head><p>Canonical GNNs are known to have several limitations, such as limited expressive power <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b43">44]</ref>, feature oversmoothing <ref type="bibr" target="#b28">[29]</ref>, information over-squashing <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref> and noise contaminating with a large receptive field <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b47">48]</ref>. One of the biggest limitations is that canonical GNNs cannot distinguish the nodes that can be mapped to each other under some graph automorphism. For example, the nodes and in <ref type="figure">Fig. 1</ref> satisfy this property, and canonical GNNs will associate them with the same node representation. Another more practical example from a food web is shown in <ref type="figure">Fig. 8</ref>. In fact, most large networks do not have non-trivial automorphism, and such nodes are not that common. However, the above issue of GNNs actually induces a more severe concern: the node representations learnt by GNNs cannot well capture the intra-node distance information, which is crucial to predict over a set of nodes.</p><p>Another issue of canonical GNNs is to over-squash information into a single node representation. Node representations can be viewed as intermediate computation results that are often used in several downstream tasks. However, a node representation, if it carries the information that is suitable for one task, may carry subpar information for another task.</p><p>The third issue of canonical GNNs is the entanglement of the number of GNN layers and the range of the receptive field. In practice, when more complex and non-linear functions are to be approximated, one may want to add more layers to the neural network. However, GNNs adding more layers will also enlarge the receptive field that may introduce noise.</p><p>The last two issues of GNNs are demonstrated in the left column of <ref type="figure" target="#fig_27">Fig. 9</ref>. SGRL methods can handle these two issues of GNNs in a simple way as illustrated in the right column of <ref type="figure" target="#fig_27">Fig. 9</ref>.</p><p>Furthermore, to handle the challenge encountered in <ref type="figure">Fig. 1a</ref>, <ref type="figure">Fig. 1b</ref> indicates SGRL methods can be adopted, which is to consider ? ? <ref type="figure">Figure 8</ref>: A food web example shows two disconnected components -the boreal forest <ref type="bibr" target="#b33">[34]</ref> and the antarctic fauna <ref type="bibr" target="#b1">[2]</ref>. The query here is which one is more likely the predator of Pelagic Fish, Lynx or Orca? Canonical GNNs cannot solve this query. Srinivasan and Ribeiro <ref type="bibr" target="#b32">[33]</ref> explain this as the failure of GNNs to establish the correlation between the node representations.</p><p>the joint subgraph around the target nodes ({ , } or { , }) as a whole. Subgraph extraction can be mathematically viewed as adding an intra-node distance feature to each node : suppose = { , } is the queried node set; if the distances from to and are both less than or equal to 1, will be selected. Such distance features can also be used as extra node features directly attached to raw node features. Li et al. <ref type="bibr" target="#b20">[21]</ref> have proved the effectiveness of using intra-node distance to better GNN expressive power. SUREL is able to capture such intra-node distance by adopting relative positional encoding (RPE). Lastly, we illustrate how SUREL is related to previous SGRL approaches in <ref type="figure">Fig. 10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D ADDITIONAL EXPERIMENTAL SETTINGS D.1 More Details about the Datasets</head><p>The dataset statistics and experimental setup for evaluation are provided in <ref type="table" target="#tab_9">Table 6</ref>. We choose OGB datasets 2 to evaluate our framework and other baselines, since it comes with large, realworld graphs (million of nodes/edges) for realistic applications (i.e. network of academic, proteins). Moreover, it provides standard, open-sourced evaluation metrics and tools for benchmarking.</p><p>Following the format of OGB, we design four prediction tasks of relations and higher-order patterns, and construct the corresponding datasets on heterogeneous graphs and hypergraphs 3 . The original ogb-mag only contains features for 'paper'-type nodes. We add the node embedding provided by <ref type="bibr" target="#b46">[47]</ref> as raw features for the rest type of nodes in MAG(P-A)/(P-P). For these four tasks, the model is evaluated by one positive query paired with certain number of randomly sampled negative queries, as listed in <ref type="table" target="#tab_10">Table  7</ref> along with other dataset statistics. The customized dataset for relation and higher-order pattern prediction is accessible via Box at https://app.box.com/s/v9nszkai2gig13lm1o6q2ya82ap07gyb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 More Details about the Baselines</head><p>For link prediction and relation prediction, we select baselines from the current OGB leaderboard 4 based on two main factors: scalability and prediction performance. All the public models have code released with a technical report. With additional verification, we Node ! works as the bridge that connects two social communities. The GRL task is to predict whether links between !" and !# exist. Ideally, both links should exist because both !" and !# share a lot of common neighbors. But one single representation of ! can hardly satisfy both as nodes " and # are in different communities and thus may be embedded far away. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Over-squashing Information into a single node representation [Generalization] Subgraph-based GRL</head><p>avoids over-squashing the information and can learn the patterns that are independent of the node identities !" or !# and generalizable across the graphs.</p><p>Entangling the depth of the GNN and the range of the receptive field " , -. / 0 2-hop neighborhood 1-hop neighborhood Two GNN layers on the original graph may include features from nodes 5, 6 that only contaminate the models. While after subgraph extraction, those nodes get removed.</p><formula xml:id="formula_14">1 ! 1 " 1 # 1 $</formula><p>The GRL task is a regression to the sum of crossproduct of neighbors' features: E.g., for node ", the regression target is ' ! = 2(* " * # + * " * $ + * # * $ ) . [Robustness] Subgraph-based GRL disentangles the depth of the model and the range of the receptive field, which assists to denoise the input and improves the model robustness.   as the input feature, and then employs two TAGConv layers of 100 hidden dimensions to generate readout of the queried node sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Architecture and Hyperparameter</head><p>SUREL consists of a 2-layer MLP with ReLU activation for the embedding of node RPEs and a 2-layer RNN to encode joint walks obtained from queried subgraph joining. The hidden dimension of both networks is set to 64. Lastly, the concatenated hidden representations of queried node sets are fed into an 2-layer MLP classifier to make final predictions. For link and relation prediction, we follow the inductive setting that only partial samples will be used for training. Over the training graph, we randomly select 5% links as positive training queries, each paired with -many negative samples ( = 50 by default). We remove these links and use the remaining 95% links to collect random walks and compute node RPEs via Algorithm 1. For higherorder pattern prediction, we use the given graph before timestamp to obtain walks and RPEs, and then optimize model parameters by higher-order triplets provided in the training set.</p><p>The results reported in <ref type="table" target="#tab_4">Table 3</ref> are obtained through the combination of hyperparameters listed in <ref type="table" target="#tab_11">Table 8</ref>. For the profiling of SUREL in <ref type="table" target="#tab_5">Table 4</ref> and <ref type="figure" target="#fig_16">Fig. 4</ref>, we use the following combinations: citation2 ( 2,0,0 , 0,0,1 )</p><p>The walk-based representation of the subgraph around each node. The walk-based representation of the joint subgraph around a queried set of nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collected in preprocessing</head><p>Previous pipelines for subgraph-based representation learning: 1. Extract the subgraph online or offline for each query 2. Add intra-node distance features (Here use shortest path distance as an example)</p><p>Representative models: SEAL (Zhang &amp; Chen, 2018), DE-GNN (Li et al., 2020) a (1,1) a (2,2) <ref type="figure">Figure 10</ref>: How is SUREL related to previous SGRL models? Previous SGRL models, such as SEAL <ref type="bibr" target="#b50">[51]</ref> and DE-GNN <ref type="bibr" target="#b20">[21]</ref>, first extract the neighboring subgraphs according to the queries, and then attach distance features to the nodes. In SUREL, all the subgraphs are represented by sets of walks sampled from the corresponding subgraphs. Given a query, the joint subgraph is represented by the concatenation of sets of walks. The query-level relative positional encoding (RPEs) is obtained by joining node-level RPEs that represent the intra-node distance features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4 Computation Complexity Analysis</head><p>We analyze the computation cost in the proposed framework SUREL and identify three major parts: Random Walks: the space complexity is ( |V |), where |V | denotes the size of node set of the input graph; the time complexity is ( |V |/ ), where is the number of threads. Practically, the number of steps generally lies in the range of 2 ? 5.</p><p>Relative Positional Encoding: the space complexity for RPE is ( 2 |V |) as there are at most ? many distinct nodes in the set of walks originated from a single node. Meanwhile, the space requirement can be further reduced to 1/10 after pruning and remapping RPE via RPE-ID. RPE can be computed along with walk sampling. Thus, the time complexity of RPE computation is still ( |V |/ ) by combining with random walks. Subgraph Joining: for a query , the time complexity is ( ? | |/ ) for joining all associated set of walks in a queried subgraph. is a scalar related to the size of . In practice, | | = 2 for link prediction, | | ? 3 for higher-order pattern prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.5 Implementation Details</head><p>We implemented our framework on top of PyTorch, NumPy, and OpenMP. uhash is adopted to serve light and high efficient indexing for RPEs associated with sampled walks. For better parallelization, the computationally intensive part is written in C language with bindings to support Python APIs, including walk sampler, RPE encoder, and subgraph joining operation. To reduce the overhead of hybrid programming, we use RPE-IDs and native C/Numpy arrays instead of Python objects to exchange results between API calls and underlying C functions. We also provide Python APIs to support customizing above-mentioned parallel operations. The SUREL framework is open-source at https://github.com/Graph-COM/SUREL and free for academic use under the BSD-2-Clause license.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>arXiv:2202.13538v2 [cs.LG] 18 Jul 2022 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E 1 P 9 T o Q m C b H O 5 Q G e G j 3 i B o M q x E 4 = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 1 G P B i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 0 o J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s I b P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 V 1 W v c V m p u X k c R T i B U z g H D 6 6 h B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 4 U O M 7 w = = &lt; / l a t e x i t &gt; w &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q P j f 4 V 3 G p d 4 L m Z d o V i u A 2 v o b x X E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 1 G P B i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 4 U S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k p e N U M W y y W M S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x / d x v T 1 B p H s t H M 0 3 Q j + h Q 8 p A z a q z U m P T L F b f q L k D W i Z e T C u S o 9 8 t f v U H M 0 g i l Y Y J q 3 f X c x P g Z V Y Y z g b N S L 9 W Y U D a m Q + x a K m m E 2 s 8 W h 8 7 I h V U G J I y V L W n I Q v 0 9 k d F I 6 2 k U 2 M 6 I m p F e 9 e b i f 1 4 3 N e G d n 3 G Z p A Y l W y 4 K U 0 F M T O Z f k w F X y I y Y W k K Z 4 v Z W w k Z U U W Z s N i U b g r f 6 8 j p p X V W 9 m 6 r X u K 7 U 3 D y O I p z B O V y C B 7 d Q g w e o Q x M Y I D z D K 7 w 5 T 8 6 L 8 + 5 8 L F s L T j 5 z C n / g f P 4 A 3 7 + M 7 g = = &lt; / l a t e x i t &gt; v &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E 1 P 9 T o Q m C b H O 5 Q G e G j 3 i B o M q x E 4 = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 1 G P B i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 0 o J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s I b P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 V 1 W v c V m p u X k c R T i B U z g H D 6 6 h B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 4 U O M 7 w = = &lt; / l a t e x i t &gt; w &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r a x 8 n P C a L y i v I i e p D A M b Q v J C O P c = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q s e C F 4 8 t 2 A 9 o Q 9 l s J + 3 a z S b s b o Q S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1v b O 8 X d 0 t 7 + w e F R + f i k r e N U M W y x W M S q G 1 C N g k t s G W 4 E d h O F N A o E d o L J 3 d z v P K H S P J Y P Z p q g H 9 G R 5 C F n 1 F i p m Q 7 K F b f q L k D W i Z e T C u R o D M p f / W H M 0 g i l Y Y J q 3 f P c x P g Z V Y Y z g b N S P 9 W Y U D a h I + x Z K m m E 2 s 8 W h 8 7 I h V W G J I y V L W n I Q v 0 9 k d F I 6 2 k U 2 M 6 I m r F e 9 e b i f 1 4 v N e G t n 3 G Z p A Y l W y 4 K U 0 F M T O Z f k y F X y I y Y W k K Z 4 v Z W w s Z U U W Z s N i U b g r f 6 8 j p p X 1 W 9 W t V r X l fq b h 5 H E c 7 g H C 7 B g x u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A 3 j u M 7 Q = = &lt; / l a t e x i t &gt; u &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q P j f 4 V 3 G p d 4 L m Z d o V i u A 2 v o b x X E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 1 G P B i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 4 U S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k p e N U M W y y W M S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x / d x v T 1 B p H s t H M 0 3 Q j + h Q 8 p A z a q z U m P T L F b f q L k D W i Z e T C u S o 9 8 t f v U H M 0 g i l Y Y J q 3 f X c x P g Z V Y Y z g b N S L 9 W Y U D a m Q + x a K m m E 2 s 8 W h 8 7 I h V U G J I y V L W n I Q v 0 9 k d F I 6 2 k U 2 M 6 I m p F e 9 e b i f 1 4 3 N e G d n 3 G Z p A Y l W y 4 K U 0 F M T O Z f k w F X y I y Y W k K Z 4 v Z W w k Z U U W Z s N i U b g r f 6 8 j p p X V W 9 m 6 r X u K 7 U 3 D y O I p z B O V y C B 7 d Q g w e o Q x M Y I D z D K 7 w 5 T 8 6 L 8 + 5 8 L F s L T j 5 z C n / g f P 4 A 3 7 + M 7 g = = &lt; / l a t e x i t &gt; v &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S 8 C R e p j O r K l q e H V h U 7 r G 2 B l B q 2 A = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k q D c L X j y 2 Y G u h D W W z n b R r N 5 u w u x F K 6 C / w 4 k E R r / 4 k b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j t o 5 T x b D F Y h G r T k A 1 C i 6 x Z b g R 2 E k U 0 i g Q + B C M b 2 f + w x M q z W N 5 b y Y J + h E d S h 5 y R o 2 V m j f 9 c s W t u n O Q V e L l p A I 5 G v 3 y V 2 8 Q s z R C a Z i g W n c 9 N z F + R p X h T O C 0 1 E s 1 J p S N 6 R C 7 l k o a o f a z + a F T c m a V A Q l j Z U s a M l d / T 2 Q 0 0 n o S B b Y z o m a k l 7 2 Z + J / X T U 1 4 7 W d c J q l B y R a L w l Q Q E 5 P Z 1 2 T A F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 3 J h u A t v 7 x K 2 h d V 7 7 L q N W u V e i 2 P o w g n c A r n 4 M E V 1 O E O G t A C B g j P 8 A p v z q P z 4 r w 7 H 4 v W g p P P H M M f O J 8 / j Z e M u w = = &lt; / l a t e x i t &gt; ? &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S 8 C R e p j O r K l q e H V h U 7 r G 2 B l B q 2 A = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k q D c L X j y 2 Y G u h D W W z n b R r N 5 u w u x F K 6 C / w 4 k E R r / 4 k b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j t o 5 T x b D F Y h G r T k A 1 C i 6 x Z b g R 2 E k U 0 i g Q + B C M b 2 f + w x M q z W N 5 b y Y J + h E d S h 5 y R o 2 V m j f 9 c s W t u n O Q V e L l p A I 5 G v 3 y V 2 8 Q s z R C a Z i g W n c 9 N z F + R p X h T O C 0 1 E s 1 J p S N 6 R C 7 l k o a o f a z + a F T c m a V A Q l j Z U s a M l d / T 2 Q 0 0 n o S B b Y z o m a k l 7 2 Z + J / X T U 1 4 7 W d c J q l B y R a L w l Q Q E 5 P Z 1 2 T A F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 3 J h u A t v 7 x K 2 h d V 7 7 L q N W u V e i 2 P o w g n c A r n 4 M E V 1 O E O G t A C B g j P 8 A p v z q P z 4 r w 7 H 4 v W g p P P H M M f O J 8 / j Z e M u w = = &lt; / l a t e x i t &gt; ? &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E 1 P 9 T o Q m C b H O 5 Q G e G j 3 i B o M q x E 4 = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 1 G P B i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 0 o J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s I b P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 V 1 W v c V m p u X k c R T i B U z g H D 6 6 h B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 4 U O M 7 w = = &lt; / l a t e x i t &gt; w &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r a x 8 n P C a L y i v I i e p D A M b Q v J C O P c = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q s e C F 4 8 t 2 A 9 o Q 9 l s J + 3 a z S b s b o Q S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k r e N U M W y x W M S q G 1 C N g k t s G W 4 E d h O F N A o E d o L J 3 d z v P K H S P J Y P Z p q g H 9 G R 5 C F n 1 F i p m Q 7 K F b f q L k D W i Z e T C u R o D M p f / W H M 0 g i l Y Y J q 3 f P c x P g Z V Y Y z g b N S P 9 W Y U D a h I + x Z K m m E 2 s 8 W h 8 7 I h V W G J I y V L W n I Q v 0 9 k d F I 6 2 k U 2 M 6 I m r F e 9 e b i f 1 4 v N e G t n 3 G Z p A Y l W y 4 K U 0 F M T O Z f k y F X y I y Y W k K Z 4 v Z W w s Z U U W Z s N i U b g r f 6 8 j p p X 1 W 9 W t V r X l f q b h 5 H E c 7 g H C 7 B g x u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A 3 j u M 7 Q = = &lt; / l a t e x i t &gt; u &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r a x 8 n P C a L y i v I i e p D A M b Q v J C O P c = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q s e C F 4 8 t 2 A 9 o Q 9 l s J + 3 a z S b s b o Q S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k r e N U M W y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>U D a h I + x Z K m m E 2 s 8 W h 8 7 I h V W G J I y V L W n I Q v 0 9 k d F I 6 2 k U 2 M 6 I m r F e 9 e b i f 1 4 v N e G t n 3 G Z p A Y l W y 4 K U 0 F M T O Z f k y F X y I y Y W k K Z 4 v Z W w s Z U U W Z s N i U b g r f 6 8 j p p X 1 W 9 W t V r X l f q b h 5 H E c 7 g H C 7 B g x u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A 3 j u M 7 Q = = &lt; / l a t e x i t &gt; u &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q P j f 4 V 3 G p d 4 L m Z d o V i u A 2 v o b x X E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 1 G P B i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 4 U S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k p e N U M W y y W M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>U D a m Q + x a K m m E 2 s 8 W h 8 7 I h V U G J I y V L W n I Q v 0 9 k d F I 6 2 k U 2 M 6 I m p F e 9 e b i f 1 4 3 N e G d n 3 G Z p A Y l W y 4 K U 0 F M T O Z f k w F X y I y Y W k K Z 4 v Z W w k Z U U W Z s N i U b g r f 6 8 j p p X V W 9 m 6 r X u K 7 U 3 D y O I p z B O V y C B 7 d Q g w e o Q x M Y I D z D K 7 w 5 T 8 6 L 8 + 5 8 L F s L T j 5 z C n / g f P 4 A 3 7 + M 7 g = = &lt; / l a t e x i t &gt; v &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S 8 C R e p j O r K l q e H V h U 7 r G 2 B l B q 2 A = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k q D c L X j y 2 Y G u h D W W z n b R r N 5 u w u x F K 6 C / w 4 k E R r / 4 k b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j t o 5 T x b D F Y h G r T k A 1 C i 6 x Z b g R 2 E k U 0 i g Q + B C M b 2 f + w x M q z W N 5 b y Y J + h E d S h 5 y R o 2 V m j f 9 c s W t u n O Q V e L l p A I 5 G v 3 y V 2 8 Q s z R C a Z i g W n c 9 N z F + R p X h T O C 0 1 E s 1 J p S N 6 R C 7 l k o a o f a z + a F T c m a V A Q l j Z U s a M l d / T 2 Q 0 0 n o S B b Y z o m a k l 7 2 Z + J / X T U 1 4 7 W d c J q l B y R a L w l Q Q E 5 P Z 1 2 T A F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 3 J h u A t v 7 x K 2 h d V 7 7 L q N W u V e i 2 P o w g n c A r n 4 M E V 1 O E O G t A C B g j P 8 A p v z q P z 4 r w 7 H 4 v W g p P P H M M f O J 8 / j Z e M u w = = &lt; / l a t e x i t &gt; ? &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S 8 C R e p j O r K l q e H V h U 7 r G 2 B l B q 2 A = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k q D c L X j y 2 Y G u h D W W z n b R r N 5 u w u x F K 6 C / w 4 k E R r / 4 k b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j t o 5 T xb D F Y h G r T k A 1 C i 6 x Z b g R 2 E k U 0 i g Q + B C M b 2 f + w x M q z W N 5 b y Y J + h E d S h 5 y R o 2 V m j f 9 c s W t u n O Q V e L l p A I 5 G v 3 y V 2 8 Q s z R C a Z i g W n c 9 N z F + R p X h T O C 0 1 E s 1 J p S N 6 R C 7 l k o a o f a z + a F T c m a V A Q l j Z U s a M l d / T 2 Q 0 0 n o S B b Y z o m a k l 7 2 Z + J / X T U 1 4 7 W d c J q l B y R a L w l Q Q E 5 P Z 1 2 T A F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 3 J h u A t v 7 x K 2 h d V 7 7 L q N W u V e i 2 P o w g n c A r n 4 M E V 1 O E O G t A C B g j P 8 A p vz q P z 4 r w 7 H 4 v W g p P P H M M f O J 8 / j Z e M u w = = &lt; / l a t e x i t &gt; ? (b) 1-hop Subgraph Extraction (a) Subtree Rooted at Nodes and &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F r E h / m A i C p h j m N l 2 8 + E K Y 9 y 2 P J A = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k q B e h 4 M V j C 7 Y W 2 l A 2 2 0 m 7 d r M J u x u h h P 4 C L x 4 U 8 e p P 8 u a / c d v m o K 0 P B h 7 v z T A z L 0 g E 1 8 Z 1 v 5 3 C 2 v r G 5 l Z x u 7 S z u 7 d / U D 4 8 a u s 4 V Q x b L B a x 6 g R U o + A S W 4 Y b g Z 1 E I Y 0 C g Q / B + H b m P z y h 0 j y W 9 2 a S o B / R o e Q h Z 9 R Y q X n T L 1 f c q j s H W S V e T i q Q o 9 E v f / U G M U s j l I Y J q n X X c x P j Z 1 Q Z z g R O S 7 1 U Y 0 L Z m A 6 x a 6 m k E W o / m x 8 6 J W d W G Z A w V r a k I X P 1 9 0 R G I 6 0 n U W A 7 I 2 p G e t m b i f 9 5 3 d S E 1 3 7 G Z Z I a l G y x K E w F M T G Z f U 0 G X C E z Y m I J Z Y r b W w k b U U W Z s d m U b A j e 8 s u r p H 1 R 9 S 6 r X r N W q d f y O I p w A q d w D h 5 c Q R 3 u o A E t Y I D w D K / w 5 j w 6 L 8 6 7 8 7 F o L T j 5 z D H 8 g f P 5 A 4 q P j L k = &lt; / l a t e x i t &gt; = &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 Q L C V W 1 3 y o R y 8 U W S 3 / u T q v r V 2 G Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k q M e C F 4 8 t 2 F Z o Q 9 l s J + 3 a z S b s b p Q S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o r e N U M W y x W M T q P q A a B Z f Y M t w I v E 8 U 0 i g Q 2 A n G N z O / 8 4 h K 8 1 j e m U m C f k S H k o e c U W O l 5 l O / X H G r 7 h x k l X g 5 q U C O R r / 8 1 R v E L I 1 Q G i a o 1 l 3 P T Y y f U W U 4 E z g t 9 V K N C W V j O s S u p Z J G q P 1 s f u i U n F l l Q M J Y 2 Z K G z N X f E x m N t J 5 E g e 2 M q B n p Z W 8 m / u d 1 U x N e + x m X S W p Q s s W i M B X E x G T 2 N R l w h c y I i S W U K W 5 v J W x E F W X G Z l O y I X j L L 6 + S 9 k X V u 6 x 6 z V q l X s v j K M I J n M I 5 e H A F d b i F B r S A A c I z v M K b 8 + C 8 O O / O x 6 K 1 4 O Q z x / A H z u c P 4 n e M 8 w = = &lt; / l a t e x i t &gt; w &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m u v w k r m x m p + N s F 4 j 7 y e T 0 6 8 0 f U M = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 1 G P B i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 4 U S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k p e N U M W y y W M S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x / d x v T 1 B p H s t H M 0 3 Q j + h Q 8 p A z a q z U m P T L F b f q L k D W i Z e T C u S o 9 8 t f v U H M 0 g i l Y Y J q 3 f X c x P g Z V Y Y z g b N S L 9 W Y U D a m Q + x a K m m E 2 s 8 W h 8 7 I h V U G J I y V L W n I Q v 0 9 k d F I 6 2 k U 2 M 6 I m p F e 9 e b i f 1 4 3 N e G d n 3 G Z p A Y l W y 4 K U 0 F M T O Z f k w F X y I y Y W k K Z 4 v Z W w k Z U U W Z s N i U b g r f 6 8 j p p X V W 9 m 6 r X u K 7 U r v M 4 i n A G 5 3 A J H t x C D R 6 g D k 1 g g P A M r / D m P D k v z r v z s W w t O P n M K f y B 8 / k D 4 P O M 8 g = = &lt; / l a t e x i t &gt; v &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q P j f 4 V 3 G p d 4 L m Z d o V i u A 2 v o b x X E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 1 G P B i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 4 U S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k p e N U M W y y W M S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x / d x v T 1 B p H s t H M 0 3 Q j + h Q 8 p A z a q z U m P T L F b f q L k D W i Z e T C u S o 9 8 t f v U H M 0 g i l Y Y J q 3 f X c x P g Z V Y Y z g b N S L 9 W Y U D a m Q + x a K m m E 2 s 8 W h 8 7 I h V U G J I y V L W n I Q v 0 9 k d F I 6 2 k U 2 M 6 I m p F e 9 e b i f 1 4 3 N e G d n 3 G Z p A Y l W y 4 K U 0 F M T O Z f k w F X y I y Y W k K Z 4 v Z W w k Z U U W Z s N i U b g r f 6 8 j p p X V W 9 m 6 r X u K 7 U 3 D y O I p z B O V y C B 7 d Q g w e o Q x M Y I D z D K 7 w 5 T 8 6 L 8 + 5 8 L F s L T j 5 z C n / g f P 4 A 3 7 + M 7 g = = &lt; / l a t e x i t &gt; v</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " F 1 0 9 l X z z 9 W t y b I p y U k a + 5 D S 9 8 g 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>r a n k i 3 B W / 3 y O m l f 1 r y r W v 2 + X m l U l 3 U U 4 Q z O o Q o e X E M D 7 q A J L W D w B M / w C m / O x H l x 3 p 2 P x W j B W e 6 c w h 8 4 n z 8 h o Z J E &lt; / l a t e x i t &gt; Wu &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 3 C 3 M I X j 0 G y t K k 8 g E 1 8 Q j O I z f F 1 s = " &gt; A A A B 9 H i c b V B N T w I x F H y L X 4 h f q E c v j W j i i e w a o h 5 J v H j E R J A E N q R b H t D Q 7 a 5 t l 4 R s + B 1 e P G i M V 3 + M N / + N X d i D g p M 0 m c y 8 l z e d I B Z c G 9 f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>r H p X 1 d p 9 r V I / y + s o w g m c w g V 4 c A 1 1 u I M G N I H B E z z D K 7 w 5 E + f F e X c + F q M F J 9 8 5 h j 9 w P n 8 A I f S S Q Q = = &lt; / l a t e x i t &gt; X u &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w z P O z 8 y 9 e R q L k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>e H O W 8 O O / O x 6 I 1 5 2 Q z x / A H z u c P a y m Q F A = = &lt; / l a t e x i t &gt; Q = {u, v} Subgraph Representation &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f j Q X Z N 6 s B c m P u W l t I l p I 8 4 n Z 9 T E = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L F b B U 0 m k q M e C F 4 8 t W l t o Q 9 l s N + 3 S z S b s T o Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j 0 a O J U M 9 5 i s Y x 1 J 6 C G S 6 F 4 C w V K 3 k k 0 p 1 E g e T s Y 3 8 7 8 9 h P X R s T q A S c J 9 y M 6 V C I U j K K V 7 k f 9 Z r 9 c c a v u H G S V e D m p Q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>u q r V m r V I / y + M o w g m c w g V 4 c A 1 1 u I M G t I D B E J 7 h F d 4 c 6 b w 4 7 8 7 H o r X g 5 D P H 8 A f O 5 w 8 d u I 2 b &lt; / l a t e x i t &gt; h Q &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " c 5 9 1 d 5 U C 0 a a 4 s 6 s i d g D C b l I 6 i p s</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 2 :</head><label>2</label><figDesc>The System Architecture of Subgraph-based Graph Representation Learning Framework (SUREL).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>RPEs &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 8 F S T p a x n p / U u Q L P E 1 Q x O H v J C y 0 = " &gt; A A A B + n i c b V D L S s N A F L 2 p r 1 p f q S 7 d D B a h Q i h J K e q y 4 M Z l B f u A N J T J d N I O n T y Y m S g l 9 l P c u F D E r V / i z r 9 x 2 m a h r Q c u 9 3 D O v c y d 4 y e c S W X b 3 0 Z h Y 3 N r e 6 e 4 W 9 r b P z g 8 M s v H H R m n g t A 2 i X k s e j 6 W l L</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>r 2 4 7 t + L a n u + 3 6 F w O z 4 t S c B a x 1 4 u a k A j l a A / O r P 4 x x G h G u M E N S e q 6 T K D 9 D Q l H M y K z U T y V J E J 6 g E f E 0 5 S g i 0 s 8 W p 8 + s c 6 0 M r T A W u r i y F u r v j Q x F U k 6 j Q E 9 G S I 3 l q j c X / / O 8 V I X X f k Z 5 k i r C 8 f K h M G W W i q 1 5 D t a Q C o I V m 2 q C s K D 6 V g u P k U B Y 6 b R K O g R 3 9 c v r p F O v u Z e 1 x l 2 j 0 r T z O I p w C m d Q B R e u o A m 3 0 I I 2 Y H i E Z 3 i F N + P J e D H e j Y / l a M H I d 0 7 g D 4 z P H 8 E 2 k Q g = &lt; / l a t e x i t &gt; ([2, 0, 0], [0, 0, 1]) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " C 4 p z L U n i 1 8 T Q 7 Z 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S W V 3 P T t N 6 h f u s 9 U F y p 8 G e / z L R z I = " &gt; A A A B 9 H i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s x I U Z c F N y 4 r 2 A e 0 Q 8 m k a R u a y Y z J n U I Z + h 1 u X C j i 1 o 9 x 5 9 + Y a W e h r Q c C h 3 P u 5 Z 6 c I J b C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M l G i G W + y S E a 6 E 1 D D p V C 8 i Q I l 7 8 S a 0 z C Q v B 1 M 7 j K / P e X a i E g 9 4 i z m f k h H S g w F o 2 g l v x d S H D M q 0 / a 8 P + 2 X K 2 7 V X Y C s E y 8 n F c j R 6 J e / e o O I J S F X y C Q 1 p u u 5 M f o p 1 S i Y 5 P N S L z E 8 p m x C R 7 x r q a I h N 3 6 6 C D 0 n F 1 Y Z k G G k 7 V N I F u r v j Z S G x s z C w E 5 m I c 2 q l 4 n / e d 0 E h 7 d + K l S c I F d s e W i Y S I I R y R o g A 6 E 5 Q z m z h D I t b F b C x l R T h r a n k i 3 B W / 3 y O m l d V b 3 r a u 2 h V q m 7 e R 1 F O I N z u A Q P b q A O 9 9 C A J j B 4 g m d 4 h T d n 6 r w 4 7 8 7 H c r T g 5 D u n 8 A f O 5 w 8 l j Z J N &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " M h U c i 9 C k s F I P j B f w A 5 m k B X e Y 5 B 0 = " &gt; A A A B 9 H i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s x I U Z c F N y 4 r 2 A e 0 Q 7 m T p m 1 o J j M m m U I Z + h 1 u X C j i 1 o 9 x 5 9 + Y a W e h r Q c C h 3 P u 5 Z 6 c I B Z c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k p a N E U d a k k Y h U J 0 D N B J e s a b g R r B M r h m E g W D u Y 3 G V + e 8 q U 5 p F 8 N L O Y + S G O J B 9 y i s Z K f i 9 E M 6 Y o 0 v a 8 n / T L F b f q L k D W i Z e T C u R o 9 M t f v U F E k 5 B J Q w V q 3 f X c 2 P g p K s O p Y P N S L 9 E s R j r B E e t a K j F k 2 k 8 X o e f k w i o D M o y U f d K Q h f p 7 I 8 V Q 6 1 k Y 2 M k s p F 7 1 M v E / r 5 u Y 4 a 2 f c h k n h k m 6 P D R M B D E R y R o g A 6 4 Y N W J m C V L F b V Z C x 6 i Q G t t T y Z b g r X 5 5 n b S u q t 5 1 t f Z Q q 9 T d v I 4 i n M E 5 X I I H N 1 C H e 2 h A E y g 8 w T O 8 w p s z d V 6 c d + d j O V p w 8 p 1 T + A P n 8 w c k C Z J M &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " S l x t E c J t 0 4 S E I c Q / g j x + P l 6 N f 4 U = " &gt; A A A B 6 n i c b V D L S g N B E O y N r x h f U Y 9 e B o M Q L 2 E 3 B P U Y 8 O I x o n l A s o T Z y W w y Z H Z 2 m e k V Q s g n e P G g i F e / y J t / 4 y T Z g y Y W N B R V 3 X R 3 B Y k U B l 3 3 2 8 l t b G 5 t 7 + R 3 C 3 v 7 B 4 d H x e O T l o l T z X i T x T L W n Y A a L o X i T R Q o e S f R n E a B 5 O 1 g f D v 3 2 0 9 c G x G r R 5 w k 3 I / o U I l Q M I p W e i h X L / v F k l t x F y D r x M t I C T I 0 + s W v 3 i B m a c Q V M k m N 6 X p u g v 6 U a h R M 8 l m h l x q e U D a m Q 9 6 1 V N G I G 3 + 6 O H V G L q w y I G G s b S k k C / X 3 x J R G x k y i w H Z G F E d m 1 Z u L / 3 n d F M M b f y p U k i J X b L k o T C X B m M z / J g O h O U M 5 s Y Q y L e y t h I 2 o p g x t O g U b g r f 6 8 j p p V S v e V a V 2 X y v V y 1 k c e T i D c y i D B 9 d Q h z t o Q B M Y D O E Z X u H N k c 6 L 8 + 5 8 L F t z T j Z z C n / g f P 4 A P F y N C g = = &lt; / l a t e x i t &gt; (2) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j 7 3 p x l x + K r g d 7 R m E a h C Z 5 C Q t x 8 I = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L U S 0 m k q M e C F 4 8 V 7 Q e 0 o W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 2 v r G 5 t b 2 4 W d 4 u 7 e / s F h 6 e i 4 p e N U M W y y W M S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x 7 c x v P 6 H S P J a P Z p K g H 9 G h 5 C F n 1 F j p o e J d 9 E t l t + r O Q V a J l 5 M y 5 G j 0 S 1 + 9 Q c z S C K V h g m r d 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>5 9 3 5 W L T m n G z m G P 7 A + f w B P e G N C w = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " c q + Q u 2 p O L K Q S I h 3 t 7 Y z 8 D 8 S Z s D s = " &gt; A A A C A n i c b V D L S s N A F J 3 U V 6 2 v q C t x M 1 i E L k p J S l G X B T c u K 9 g H p C F M p p N 2 6 O T B P I Q S o h t / x Y 0 L R d z 6 F e 7 8 G y d t F t p 6 4 M L h n H u 5 9 x 4 / Y V R I y / o 2 S m v r G 5 t b 5 e 3 K z u 7 e / o F 5 e N Q T s e K</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>a 4 A R 3 Q B R g 8 g m f w C t 6 M J + P F e D c + F q 0 l o 5 g 5 B n 9 g f P 4 A V N 2 W p w = = &lt; / l a t e x i t &gt; Xu,u [2, 0, 0] &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E r z n 8 p T 8 1 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>1 ) 1 )XFigure 3 :</head><label>113</label><figDesc>a H P S N + f X u d + / 5 4 I S S N + p 2 Y x c U M 0 5 j S g G C k t e e b J M E R q g h F L B 5 m X J n U / e 3 C s e r N u u Z 5 Z t R r W H H C V 2 A W p g g I d z / w a j i K c h I Q r z J C U j m 3 F y k 2 R U B Q z k l W G i S Q x w l M 0 J o 6 m H I V E u u n 8 h Q y e a 2 U E g 0 j o 4 g r O 1 d 8 T K Q q l n I W + 7 s w P l s t e L v 7 n O Y k K r t y U 8 j h R h O P F o i B h U E U w z w O O q C B Y s Z k m C A u q b 4 V 4 g g T C S q d W 0 S H Y y y + v k l 6 z Y V 8 0 W r e t a r t W x F E G p + A M 1 I A N L k E b 3 I A O 6 A I M H s E z e A V v x p P x Y r w b H 4 v W k l H M H I M / M D 5 / A D d i l p Q = &lt; / l a t e x i t &gt; Xu,b [0, 2, 0] &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " p B S k t 1 u b Q l f 2 F a y p X U j W z 0 x D z 6 I = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e s r 6 k r c D B a h i 1 I S K e q y 4 M Z l B f u A N I T J d N I O n T y Y m Q g l V D f + i h s X i r j 1 K 9 z 5 N 0 7 a L L T 1 w I X D O f d y 7 z 1 + w p l U l v V t r K y u r W 9 s l r b K 2 z u 7 e / v m w W F H x q k g t E 1 i H o u e j y X l L K J t x R S n v U R Q H P q c d v 3 x d e 5 3 7 6 m Q L I 7 u 1 C S h b o i H E Q s Y w U p L n n n c D 7 E a E c y z 3 t T L 0 h q e P j h W z a r Z r m d W r L o 1 A 1 o m d k E q U K D l m V / 9 Q U z S k E a K c C y l Y 1 u J c j M s F C O c T s v 9 V N I E k z E e U k f T C I d U u t n s h S k 6 0 8 o A B b H Q F S k 0 U 3 9 P Z D i U c h L 6 u j M / W C 5 6 u f i f 5 6 Q q u H I z F i W p o h G Z L w p S j l S M 8 j z Q g A l K F J 9 o g o l g + l Z E R l h g o n R q Z R 2 C v f j y M u m c 1 + 2 L e u O 2 U W l W i z h K c A K n U A U b L q E J N 9 C C N h B 4 h G d 4 h T f j y X g x 3 o 2 P e e u K U c w c w R 8 Y n z 8 0 T J a S &lt; / l a t e x i t &gt; Xu,a [0, 0, 1] &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " V 5 O G n 6 N 5 Q F 2 d L 2 K H 7 m L v h / j s s Q w = " &gt; A A A C A n i c b V D L S s N A F J 3 U V 6 2 v q C t x M 1 i E L k p J p K j L g h u X F e w D 0 h A m 0 0 k 7 d D I J M 5 N C C d G N v + L G h S J u / Q p 3 / o 2 T N g t t P X D h c M 6 9 3 H u P H z M q l WV 9 G 6 W 1 9 Y 3 N r f J 2 Z W d 3 b / / A P D z q y i g R m H R w x C L R 9 5 E k j H L S U V Q x 0 o 8 F Q a H P S M + f 3 O R + b 0 q E p B G / V 7 O Y u C E a c R p Q j J S W P P N k E C I 1 x o i l / c x L k / o 0 e 3 C s u l W 3 X c + s W g 1 r D r h K 7 I J U Q Y G 2 Z 3 4 N h h F O Q s I V Z k h K x 7 Z i 5 a Z I K I o Z y S q D R J I Y 4 Q k a E U d T j k I i 3 X T + Q g b P t T K E Q S R 0 c Q X n 6 u + J F I V S z k J f d + Y H y 2 U v F / / z n E Q F 1 2 5 K e Z w o w v F i U Z A w q C K Y 5 w G H V B C s 2 E w T h A X V t 0 I 8 R g J h p V O r 6 B D s 5 Z d X S f e i Y V 8 2 m n f N a q t W x F E G p + A M 1 I A N r k A L 3 I I 2 6 A A M H s E z e A V v x p P x Y r w b H 4 v W k l H M H I M / M D 5 / A F T d l q c = &lt; / l a t e x i t &gt; Xu,v [0, 0, 1]&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " V 0 M C i r Y 6 k R c s K z X Z Q O 3 s N T D e 8 p 0 = " &gt; A A A C A n i c b V D L S s N A F J 3 4 r P U V d S V u B o v Q R S l J K e q y 4 M Z l B f u A N I T J d N I O n U z C z K R Q Q n T j r 7 h x o Y h b v 8 K d f + O k z U J b D 1 w 4 n H M v 9 9 7 j x 4 x K Z V n f x t r 6 x u b W d m m n v L u 3 f 3 B o H h 1 3 Z Z Q I T D o 4 Y p H o + 0 g S R j n p K K o Y 6 c e C o N B n p O d P b n K / N y V C 0 o j f q 1 l M 3 B C N O A 0 o R k p L n n k 6 C J E a Y 8 T S f u a l 0 9 o 0 e 3 A a N a t m u Z 5 Z s e r W H H C V 2 A W p g A J t z / w a D C O c h I Q r z J C U j m 3 F y k 2 R U B Q z k p U H i S Q x w h M 0 I o 6 m H I V E u u n 8 h Q x e a G U I g 0 j o 4 g r O 1 d 8 T K Q q l n I W + 7 s w P l s t e L v 7 nO Y k K r t 2 U 8 j h R h O P F o i B h U E U w z w M O q S B Y s Z k m C A u q b 4 V 4 j A T C S q d W 1 i H Y y y + v k m 6 j b l / W m 3 f N S q t a x F E C Z + A c V I E N r k A L 3 I I 2 6 A A M H s E z e A V v x p P x Y r w b H 4 v W N a O Y O Q F / Y H z + A F f 5 l q k = &lt; / l a t e x i t &gt; Xv,v [2, 0, 0]&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g 8 W x j R X B e Q j Y m i 9 2 T 4 + q 6 F 9 l L 1 4 = " &gt; A A A C A n i c b V D L S s N A F J 3 U V 6 2 v q C t x M 1 i E L k p J p K j L g h u X F e w D 0 h A m 0 0 k 7 d D I J M 5 N C C d G N v + L G h S J u / Q p 3 / o 2 T N g t t P X D h c M 6 9 3 H u P H z M q l W V 9 G 6 W 1 9 Y 3 N r f J 2 Z W d 3 b / / A P D z q y i g R m H R w x C L R 9 5 E k j H L S U V Q x 0 o 8 F Q a H P S M + f 3 O R + b 0 q E p B G / V 7 O Y u C E a c R p Q j J S W P P N k E C I 1 x o i l / c x L p 3 W U P T h W 3 a r b r m d W r Y Y 1 B 1 w l d k G q o E D b M 7 8 G w w g n I e E K M y S l Y 1 u x c l M k F M W M Z J V B I k m M 8 A S N i K M p R y G R b j p / I Y P n W h n C I B K 6 u I J z 9 f d E i k I p Z 6 G v O / O D 5 b K X i / 9 5 T q K C a z e l P E 4 U 4 X i x K E g Y V B H M 8 4 B D K g h W b K Y J w o L q W y E e I 4 G w 0 q l V d A j 2 8 s u r p H v R s C 8 b z b t m t V U r 4 i i D U 3 A G a s A G V 6 A F b k E b d A A G j + A Z v I I 3 4 8 l 4 M d 6 N j 0 V r y S h m j s E f G J 8 / N d u W k w = = &lt; / l a t e x i t &gt; Xv,a [0, 0, 1] &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 n / K 7 I o W b R a t n z 5 D 5 G v D m b a E J i M = " &gt; A A A C A n i c b V D L S s N A F J 3 4 r P U V d S V u B o v Q R S l J K e q y 4 M Z l B f u A N I T J d N I O n U z C z K R Q Q n T j r 7 h x o Y h b v 8 K d f + O k z U J b D 1 w 4 n H M v 9 9 7 j x 4 x K Z V n f x t r 6 x u b W d m m n v L u 3 f 3 B o H h 1 3 Z Z Q I T D o 4 Y p H o + 0 g S R j n p K K o Y 6 c e C o N B n p O d P b n K / N y V C 0 o j f q 1 l M 3 B C N O A 0 o R k p L n n k 6 C J E a Y 8 T S f u a l 0 5 q f P T h W r V G z X M + s W H V r D r h K 7 I J U Q I G 2 Z 3 4 N h h F O Q s I V Z k h K x 7 Z i 5 a Z I K I o Z y c q D R J I Y 4 Q k a E U d T j k Ii 3 X T + Q g Y v t D K E Q S R 0 c Q X n 6 u + J F I V S z k J f d + Y H y 2 U v F / / z n E Q F 1 2 5 K e Z w o w v F i U Z A w q C K Y 5 w G H V B C s 2 E w T h A X V t 0 I 8 R g J h p V M r 6 x D s 5 Z d X S b d R t y / r z b t m p V U t 4 i i B M 3 A O q s A G V 6 A F b k E b d A A G j + A Z v I I 3 4 8 l 4 M d 6 N j 0 X r m l H M n I A / M D 5 / A D j x l p U = &lt; / l a t e x i t &gt; Xv,b [0, 2, 0] &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " p S 3 n / g m T O e f w v v j Y e x D u 3 z j W o a E = " &gt; A A A C A n i c b V D L S s N A F J 3 U V 6 2 v q C t x M 1 i E L k p J p K j L g h u X F e w D 0 h A m 0 0 k 7 d D I J M 5 N C C d G N v + L G h S J u / Q p 3 / o 2 T N g t t P X D h c M 6 9 3 H u P H z M q l W V 9 G 6 W 1 9 Y 3 N r f J 2 Z W d 3 b / / A P D z q y i g R m H R w x C L R 9 5 E k j H L S U V Q x 0 o 8 F Q a H P S M + f 3 O R + b 0 q E p B G / V 7 O Y u C E a c R p Q j J S W P P N k E C I 1 x o i l / c x L p / U k e 3 C s u l W 3 X c + s W g 1 r D r h K 7 I J U Q Y G 2 Z 3 4 N h h F O Q s I V Z k h K x 7 Z i 5 a Z I K I o Z y S q D R J I Y 4 Q k a E U d T j k I i 3 X T + Q g b P t T K E Q S R 0 c Q X n 6 u + J F I V S z k J f d + Y H y 2 U v F / / z n E Q F 1 2 5 K e Z w o w v F i U Z A w q C K Y 5 w G H V B C s 2 E w T h A X V t 0 I 8 R g J h p V O r 6 B D s 5 Z d X S f e i Y V 8 2 m n f N a q t W x F E G p + A M 1 I A N r k A L 3 I I 2 6 A A M H s E z e A V v x p P x Y r w b H 4 v W k l H M H I M / M D 5 / A F T f l q c = &lt; / l a t e x i t &gt; Xv,u [0, 0, 1] &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S l x t E c J t 0 4 S E I c Q / g j x + P l 6 N f 4 U = " &gt; A A A B 6 n i c b V D L S g N B E O y N r x h f U Y 9 e B o M Q L 2 E 3 B P U Y 8 O I x o n l A s o T Z y W w y Z H Z 2 m e k V Q s g n e P G g i F e / y J t / 4 y T Z g y Y W N B R V 3 X R 3 B Y k U B l 3 3 2 8 l t b G 5 t 7 + R 3 C 3 v 7 B 4 d H x e O T l o l T z X i T x T L W n Y A a L o X i T R Q o e S f R n E a B 5 O 1 g f D v 3 2 0 9 c G x G r R 5 w k 3 I / o U I l Q M I p W e i h X L / v F k l t x F y D r x M t I C T I 0 + s W v 3 i B m a c Q V M k m N 6 X p u g v 6 U a h R M 8 l m h l x q e U D a m Q 9 6 1 V N G I G 3 + 6 O H V G L q w y I G G s b S k k C / X 3 x J R G x k y i w H Z G F E d m 1 Z u L / 3 n d F M M b f y p U k i J X b L k o T C X B m M z / J g O h O U M 5 s Y Q y L e y t h I 2 o p g x t O g U b g r f 6 8 j p p V S v e V a V 2 X y v V y 1 k c e T i D c y i D B 9 d Q h z t o Q B M Y D O E Z X u H N k c 6 L 8 + 5 8 L F t z T j Z z C n / g f P 4 A P F y N C g = = &lt; / l a t e x i t &gt; (2)&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 Z x w A d Y k n m Q R o u e L 0 F D 3 q N Y / l x Q = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L U S 0 m k q M e C F 4 8 V 7 Q e 0 o W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 2 v r G 5 t b 2 4 W d 4 u 7 e / s F h 6 e i 4 p e N U M W y y W M S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x 7 c x v P 6 H S P J a P Z p K g H 9 G h 5 C F n 1 F j p o e J e 9 E t l t + r O Q V a J l 5 M y 5 G j 0 S 1 + 9 Q c z S C K V h g m r d 9 d z E + B l V h j O B 0 2 I v 1 Z h Q N q Z D 7 F o q a Y T a z + a n T s m 5 V Q Y k j J U t a c h c / T 2 R 0 U j r S R T Y z o i a k V 7 2 Z u J / X j c 1 4 Y 2 f c Z m k B i V b L A p T Q U x M Z n + T A V f I j J h Y Q p n i 9 l b C R l R R Z m w 6 R R u C t / z y K m l d V r 2 r a u 2 + V q 5 X 8 j g K c A p n U A E P r q E O d 9 C A J j A Y w j O 8 w p s j n B f n 3 f l Y t K 4 5 + c w J / I H z + Q M 5 U o 0 I &lt; / l a t e x i t &gt; (0) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j 7 3 p x l x + K r g d 7 R m E a h C Z 5 C Q t x 8 I = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L U S 0 m k q M e C F 4 8 V 7 Q e 0 o W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 2 v r G 5 t b 2 4 W d 4 u 7 e / s F h 6 e i 4 p e N U M W y y W M S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x 7 c x v P 6 H S P J a P Z p K g H 9 G h 5 C F n 1 F j p o e J d 9 E t l t + r O Q V a J l 5 M y 5 G j 0 S 1 + 9 Q c z S C K V h g m r d 9 d z E + B l V h j O B 0 2 I v 1 Z h Q N q Z D 7 F o q a Y T a z + a n T s m 5 V Q Y k j J U t a c h c / T 2 R 0 U j r S R T Y z o i a k V 7 2 Z u J / X j c 1 4 Y 2 f c Z m k B i V b L A p T Q U x M Z n + T A V f I j J h Y Q p n i 9 l b C R l R R Z m w 6 R R u C t / z y K m l d V r 2 r a u 2 + V q 5 X 8 j g K c A p n U A E P r q E O d 9 C A J j A Y w j O 8 w p s j n B f n 3 f l Y t K 4 5 + c w J / I H z + Q M 6 1 4 0 J &lt; / l a t e x i t &gt; (&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S G 6 h u J M Q h K 2 N d y h A S q R 2 T 7 W y g G E = " &gt; A A A B 6 n i c b V D L S g N B E O y N r x h f U Y 9 e B o M Q L 2 F X g 3 o M e P E Y 0 T w g W c L s p D c Z M j u 7 z M w K I e Q T v H h Q x K t f 5 M 2 / c Z L s Q R M L G o q q b r q 7 g k R w b V z 3 2 8 m t r W 9 s b u W 3 C z u 7 e / s H x c O j p o 5 T x b D B Y h G r d k A 1 C i 6 x Y b g R 2 E 4 U 0 i g Q 2 A p G t z O / 9 Y R K 8 1 g + m n G C f k Q H k o e c U W O l h / L l e a 9 Y c i v u H G S V e B k p Q Y Z 6 r / j V 7 c c s j V A a J q j W H c 9 N j D + h y n A m c F r o p h o T y k Z 0 g B 1 L J Y 1 Q + 5 P 5 q V N y Z p U + C W N l S x o y V 3 9 P T G i k 9 T g K b G d E z V A v e z P x P 6 + T m v D G n 3 C Z p A Y l W y w K U 0 F M T G Z / k z 5 X y I w Y W 0 K Z 4 v Z W w o Z U U W Z s O g U b g r f 8 8 i p p X l S 8 q 0 r 1 v l q q l b M 4 8 n A C p 1 A G D 6 6 h B n d Q h w Y w G M A z v M K b I 5 w X 5 9 3 5 W L T m n G z m G P 7 A + f w B P e G N C w = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " j 7 3 p x l x + K r g d 7 R m E a h C Z 5 C Q t x 8 I = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L U S 0 m k q M e C F 4 8 V 7 Q e 0 o W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 2 v r G 5 t b 2 4 W d 4 u 7 e / s F h 6 e i 4 p e N U M W y y W M S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x 7 c x v P 6 H S P J a P Z p K g H 9 G h 5 C F n 1 F j p o e J d 9 E t l t + r O Q V a J l 5 M y 5 G j 0 S 1 + 9 Q c z S C K V h g m r d 9 d z E + B l V h j O B 0 2 I v 1 Z h Q N q Z D 7 F o q a Y T a z + a n T s m 5 V Q Y k j J U t a c h c / T 2 R 0 U j r S R T Y z o i a k V 7 2 Z u J / X j c 1 4 Y 2 f c Z m k B i V b L A p T Q U x M Z n + T A V f I j J h Y Q p n i 9 l b C R l R R Z m w 6 R R u C t / z y K m l d V r 2 r a u 2 + V q 5 X 8 j g K c A p n U A E P r q E O d 9 C A J j A Y w j O 8 w p s j n B f n 3 f l Y t K 4 5 + c w J / I H z + Q M 6 1 4 0 J &lt; / l a t e x i t &gt; (&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K N c 5 a m 8 w B w q t o t b c E / q d 0 Q / 8 s r U = " &gt; A A A B 8 n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i Q i 6 r L g p s s K 9 g F t K J P p p B 0 6 y Y S Z G 6 G E f o Y b F 4 q 4 9 W v c + T d O 2 i y 0 9 c D A 4 Z x 7 m X N P k E h h 0 H W / n d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p G J V q x t t M S a V 7 A T V c i p i 3 U a D k v U R z G g W S d 4 P p f e 5 3 n 7 g 2 Q s W P O E u 4 H 9 F x L E L B K F q p P 4 g o T h i V W X M + r N b c u r s A W S d e Q W p Q o D W s f g 1 G i q U R j 5 F J a k z f c x P 0 M 6 p R M M n n l U F q e E L Z l I 5 5 3 9 K Y R t z 4 2 S L y n F x Y Z U R C p e 2 L k S z U 3 x s Z j Y y Z R Y G d z C O a V S 8 X / / P 6 K Y Z 3 f i b i J E U e s + V H Y S o J K p L f T 0 Z C c 4 Z y Z g l l W t i s h E 2 o p g x t S x V b g r d 6 8 j r p X N W 9 m / r 1 w 3 W t 4 R Z 1 l O E M z u E S P L i F B j S h B W 1 g o O A Z X u H N Q e f F e X c + l q M l p 9 g 5 h T 9 w P n 8 A e H W R V Q = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " 3 l z Q l R D g F 0 K E e s m f y R 0 J 5 p V 4 G / 8 = " &gt; A A A B + n i c b V D L S g M x F M 3 U V 6 2 v q S 7 d B I t Q Y S i Z U t R l w Y 3 L C v Y B 0 6 F k 0 k w b m s k M S U Y p Y z / F j Q t F 3 P o l 7 v w b 0 3 Y W 2 n r g c g / n 3 E t u T p B w p j R C 3 1 Z h Y 3 N r e 6 e 4 W 9 r b P z g 8 s s v H H R W n k t A 2 i X k s e w F W l D N B 2 5 p p T n u J p D g K O O 0 G k 5 u 5 3 3 2 g U r F Y 3 O t p Q v 0 I j w Q L G c H a S A O 7 X P W Q g x z X d 7 y 6 6 c i / G N g V V E M L w H X i 5 q Q C c r Q G 9 l d / G J M 0 o k I T j p X y X J R o P 8 N S M 8 L p r N R P F U 0 w m e A R 9 Q w V O K L K z x a n z + C 5 U Y Y w j K U p o e F C / b 2 R 4 U i p a R S Y y Q j r s V r 1 5 u J / n p f q 8 N r P m E h S T Q V Z P h S m H O o Y z n O A Q y Y p 0 X x q C C a S m V s h G W O J i T Z p l U w I 7 u q X 1 0 m n X n M v a 4 2 7 R q X p 5 H E U w S k 4 A 1 X g g i v Q B L e g B d q A g E f w D F 7 B m / V k v V j v 1 s d y t G D l O y f g D 6 z P H 8 E u k Q g = &lt; / l a t e x i t &gt; ([0, 0, 1], [2, 0, 0]) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F T T s / r X G Z 6 H Y g 4 5 a + 9 B K Q 2 N p E 0 4 = " &gt; A A A B 9 H i c b V B N S w M x F H x b v 2 r 9 q n r 0 E i y C B y m 7 U t R j w Y v H C r Y W 2 q W 8 T d M 2 N J t d k 2 y h L P 0 d X j w o 4 t U f 4 8 1 / Y 7 b d g 7 Y O B I a Z 9 3 i T C W L B t X H d b 6 e w t r 6 x u V X c L u 3 s 7 u 0 f l A + P W j p K F G V N G o l I t Q P U T H D J m o Y b w d q x Y h g G g j 0 G 4 9 v M f 5 w w p X k k H 8 w 0 Z n 6 I Q 8 k H n K K x k t 8 N 0 Y w o i r Q 1 6 y W 9 c s W t u n O Q V e L l p A I 5 G r 3 y V 7 c f 0 S R k 0 l C B W n c 8 N z Z + i s p w K t i s 1 E 0 0 i 5 G O c c g 6 l k o M m f b T e e g Z O b N K n w w i Z Z 8 0 Z K 7 + 3 k g x 1 H o a B n Y y C 6 m X v U z 8 z + s k Z n D j p 1 z G i W G S L g 4 N E k F M R L I G S J 8 r R o 2 Y W o J U c Z u V 0 B E q p M b 2 V L I l e M t f X i W t y 6 p 3 V a 3 d 1 y r 1 i 7 y O I p z A K Z y D B 9 d Q h z t o Q B M o P M E z v M K b M 3 F e n H f n Y z F a c P K d Y / g D 5 / M H I U 6 S R w = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " 9 p O D O E 3 a 9 6 F v 6 l o 4 e W l r o y G m v 9 A = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k q D c L X j y 2 Y G u h D W W z n b R r N 5 u w u x F K 6 C / w 4 k E R r / 4 k b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j t o 5 T x b D F Y h G r T k A 1 C i 6 x Z b g R 2 E k U 0 i g Q + B C M b 2 f + w x M q z W N 5 b y Y J + h E d S h 5 y R o 2 V m j f 9 c s W t u n O Q V e L l p A I 5 G v 3 y V 2 8 Q s z R C a Z i g W n c 9 N z F + R p X h T O C 0 1 E s 1 J p S N 6 R C 7 l k o a o f a z + a F T c m a V A Q l j Z U s a M l d / T 2 Q 0 0 n o S B b Y z o m a k l 7 2 Z + J / X T U 1 4 7 W d c J q l B y R a L w l Q Q E 5 P Z 1 2 T A F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 3 J h u A t v 7 x K 2 h d V 7 7 J a a 9 Y q d T e P o w g n c A r n 4 M E V 1 O E O G t A C B g j P 8 A p v z q P z 4 r w 7 H 4 v W g p P P H M M f O J 8 / j V m M u g = = &lt; / l a t e x i t &gt; ? Query &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " o m B m v c G z 8 L f X q t z Z D D y t 0 b 1 n R X Q = " &gt; A A A B 8 n i c b V B N S w M x E J 3 1 s 9 a v q k c v w S J 4 K G V X i n o R C l 4 8 t m A / Y L e U b J p t Q 7 P J k m Q L Z e n P 8 O J B E a / + G m / + G 9 N 2 D 9 r 6 Y O D x 3 g w z 8 8 K E M 2 1 c 9 9 v Z 2 N z a 3 t k t 7 B X 3 D w 6 P j k s n p 2 0 t U 0 V o i 0 g u V T f E m n I m a M s w w 2 k 3 U R T H I a e d c P w w 9 z s T q j S T 4 s l M E 9 q L 8 V C w i B F s r O Q 3 0 T 0 K s r Q y C W b 9 U t m t u g u g d e L l p A w 5 G v 3 S V z C Q J I 2 p M I R j r X 3 P T U w v w 8 o w w u m s G K S a J p i M 8 Z D 6 l g o c U 9 3 L F i f P 0 K V V B i i S y p Y w a K H + n s h w r P U 0 D m 1 n j M 1 I r 3 p z 8 T / P T 0 1 0 1 8 u Y S F J D B V k u i l K O j E T z / 9 G A K U o M n 1 q C i W L 2 V k R G W G F i b E p F G 4 K 3 + v I 6 a V 9 X v Z t q r V k r 1 y t 5 H A U 4 h w u 4 A g 9 u o Q 6 P 0 I A W E J D w D K / w 5 h j n x X l 3 P p a t G 0 4 + c w Z / 4 H z + A B t p k H A = &lt; / l a t e x i t &gt; Q = {u, v} Prepocessing &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " X 2 l 3 B X c x G u A m / + p n Y W E I G C n q R 0 A = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 k J J I U Y 8 F L x 5 b s B / Q h r L Z T t q 1 m 0 3 Y 3 Q g l 9 B d 4 8 a C I V 3 + S N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K 4 N q 7 7 7 a y t b 2 x u b R d 2 i r t 7 + w e H p a P j l o 5 T x b D J Y h G r T k A 1 C i 6 x a b g R 2 E k U 0 i g Q 2 A 7 G d z O / / Y R K 8 1 g + m E m C f k S H k o e c U W O l R q N f K r s V d w 6 y S r y c l C F H v V / 6 6 g 1 i l k Y o D R N U 6 6 7 n J s b P q D K c C Z w W e 6 n G h L I x H W L X U k k j 1 H 4 2 P 3 R K z q 0 y I G G s b E l D 5 u r v i Y x G W k + i w H Z G 1 I z 0 s j c T / / O 6 q Q l v / Y z L J D U o 2 W J R m A p i Y j L 7 m g y 4 Q m b E x B L K F L e 3 E j a i i j J j s y n a E L z l l 1 d J 6 6 r i X V e q j W q 5 d p n H U Y B T O I M L 8 O A G a n A P d W g C A 4 R n e I U 3 5 9 F 5 c d 6 d j 0 X r m p P P n M A f O J 8 / p 2 2 M y A = = &lt; / l a t e x i t &gt; Q &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " p I G n L O G w D I t X L g Q y r H w h i 5 Z N L 1 I = " &gt; A A A B + n i c b V D L S s N A F L 3 x W e s r 1 a W b Y B F c l J J I U Z c F N y 5 b s A 9 o Q 5 h M J + 3 Q y S T M T N Q S 8 y l u X C j i 1 i 9 x 5 9 8 4 a b P Q 1 g M D h 3 P u 5 Z 4 5 f s y o V L b 9 b a y t b 2 x u b Z d 2 y r t 7 + w e H Z u W o K 6 N E Y N L B E Y t E 3 0 e S M M p J R 1 H F S D 8 W B I U + I z 1 / e p P 7 v X s i J I 3 4 n Z r F x A 3 R m N O A Y q S 0 5 J m V Y Y j U B C O W 9 j M v b d c e M 8 + s 2 n V 7 D m u V O A W p Q o G W Z 3 4 N R x F O Q s I V Z k j K g W P H y k 2 R U B Q z k p W H i S Q x w l M 0 J g N N O Q q J d N N 5 9 M w 6 0 8 r I C i K h H 1 f W X P 2 9 k a J Q y l n o 6 8 k 8 q F z 2 c v E / b 5 C o 4 N p N K Y 8 T R T h e H A o S Z q n I y n u w R l Q Q r N h M E 4 Q F 1 V k t P E E C Y a X b K u s S n O U v r 5 L u R d 2 5 r D f a j W q z V t R R g h M 4 h X N w 4 A q a c A s t 6 A C G B 3 i G V 3 g z n o w X 4 9 3 4 W I y u G c X O M f y B 8 f k D g Z u U G g = = &lt; / l a t e x i t &gt; X Q,x &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 8 N x T M l d 5 t s D p w B I 4 i g 6 q 3 u r o D E = " &gt; A A A C K X i c b Z B L S w M x E M e z 9 V X r a 9 W j l 2 B R 6 s G y K 0 X F U 0 G F e q t i H 9 A t J Z u m b W j 2 Q T I r l q V f x 4 t f x Y u C o l 7 9 I m b b 4 q M 6 E P j P b 2 b I z N 8 N B V d g W W 9 G a m Z 2 b n 4 h v Z h Z W l 5 Z X T P X N 6 o q i C R l F R q I Q N Z d o p j g P q s A B 8 H q o W T E c w W r u f 3 T p F 6 7 Y V L x w L + G Q c i a H u n 6 v M M p A Y 1 a Z t H x C P Q o E X F p 2 I p O 8 F d a 1 S l 2 I P g m 9 Y T k H G C 3 E F + V z / c v z j T Y a 5 l Z K 2 + N A v 8 V 9 k R k 0 S T K L f P J a Q c 0 8 p g P V B C l G r Y V Q j M m E j g V b J h x I s V C Q v u k y x p a + s R j q h m P L h 3 i H U 3 a u B N I / X z A I / p z I i a e U g P P 1 Z 3 J 2 m q 6 l s D / a o 0 I O s f N m P t h B M y n 4 4 8 6 k c D a g M Q 2 3 O a S U R A D L Q i V X O + K a Y 9 I Q k G b m 9 E m 2 N M n / x X V g 7 x 9 m C 9 c F r L F 3 Y k d a b S F t l E O 2 e g I F V E J l V E F U X S H H t A z e j H u j U f j 1 X g f t 6 a M y c w m + h X G x y f t 3 a b s &lt; / l a t e x i t &gt; Hu : Vu ! Xu(RPE-IDu) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n m c M + P U f A W 4 k z B g j L U i i z 0 L e z i Y = " &gt; A A A B 8 n i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g Q s q M F H V Z c O O y Q l 8 w H U o m z b S h m W R I M k I Z + h l u X C j i 1 q 9 x 5 9 + Y a W e h r Q c C h 3 P u J e e e M O F M G 9 f 9 d k o b m 1 v b O + X d y t 7 + w e F R 9 f i k q 2 W q C O 0 Q y a X q h 1 h T z g T t G G Y 4 7 S e K 4 j j k t B d O 7 3 O / 9 0 S V Z l K 0 z S y h Q Y z H g k W M Y G M l f x B j M y G Y Z + 3 5 s F p z 6 + 4 C a J 1 4 B a l B g d a w + j U Y S Z L G V B j C s d a + 5 y Y m y L A y j H A 6 r w x S T R N M p n h M f U s F j q k O s k X k O b q w y g h F U t k n D F q o v z c y H G s 9 i 0 M 7 m U f U q 1 4 u / u f 5 q Y n u g o y J J D V U k O V H U c q R k S i / H 4 2 Y o s T w m S W Y K G a z I j L B C h N j W 6 r Y E r z V k 9 d J 9 7 r u 3 d Q b j 4 1 a 8 6 q o o w x n c A 6 X 4 M E t N O E B W t A B A h K e 4 R X e H O O 8 O O / O x 3 K 0 5 B Q 7 p / A H z u c P i X 2 R X Q = = &lt; / l a t e x i t &gt; T &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m I e e L l P x a + e R g 6 2 Q r 9 e w 9 4 K a W Q E = " &gt; A A A B 8 n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i Q i 6 r L i x m U F + 4 A 2 l M l 0 0 g 6 d T M L M j V B C P 8 O N C 0 X c + j X u / B s n b R b a e m D g c M 6 9 z L k n S K Q w 6 L r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 6 1 T Z x q x l s s l r H u B t R w K R R v o U D J u 4 n m N A o k 7 w S T u 9 z v P H F t R K w e c Z p w P 6 I j J U L B K F q p 1 4 8 o j h m V 2 e 1 s U K 2 5 d X c O s k q 8 g t S g Q H N Q / e o P Y 5 Z G X C G T 1 J i e 5 y b o Z 1 S j Y J L P K v 3 U 8 I S y C R 3 x n q W K R t z 4 2 T z y j J x Z Z U j C W N u n k M z V 3 x s Z j Y y Z R o G d z C O a Z S 8 X / / N 6 K Y Y 3 f i Z U k i J X b P F R m E q C M c n v J 0 O h O U M 5 t Y Q y L W x W w s Z U U 4 a 2 p Y o t w V s + e Z W 0 L + r e V f 3 y 4 b L W c I s 6 y n A C p 3 A O H l x D A + 6 h C S 1 g E M M z v M K b g 8 6 L 8 + 5 8 L E Z L T r F z D H / g f P 4 A b d K R T g = = &lt; / l a t e x i t &gt; A &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j X y N u c u Y O d T h S 3 w D w f Y q y u o W 3 0 E = " &gt; A A A B 8 n i c b V D L S s N A F L 3 x W e u r 6 t L N Y B F c S E m k q M u C G 5 c V 7 A P a U C b T S T t 0 M g k z N 0 I J / Q w 3 L h R x 6 9 e 4 8 2 + c t F l o 6 4 G B w z n 3 M u e e I J H C o O t + O 2 v r G 5 t b 2 6 W d 8 u 7 e / s F h 5 e i 4 b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 O V + 5 4 l r I 2 L 1 i N O E + x E d K R E K R t F K v X 5 E c c y o z L q z Q a X q 1 t w 5 y C r x C l K F A s 1 B 5 a s / j F k a c Y V M U m N 6 n p u g n 1 G N g k k + K / d T w x P K J n T E e 5 Y q G n H j Z / P I M 3 J u l S E J Y 2 2 f Q j J X f 2 9 k N D J m G g V 2 M o 9 o l r 1 c / M / r p R j e + p l Q S Y p c s c V H Y S o J x i S / n w y F 5 g z l 1 B L K t L B Z C R t T T R n a l s q 2 B G / 5 5 F X S v q p 5 1 7 X 6 Q 7 3 a u C z q K M E p n M E F e H A D D b i H J r S A Q Q z P 8 A p v D j o v z r v z s R h d c 4 q d E / g D 5 / M H j 5 G R Y Q = = &lt; / l a t e x i t &gt; An Illustration of Joining RPE into Query-level RPEs with the Support of Walk-based Subgraph Storage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>6</head><label></label><figDesc>Insert { : (W , H )} to A 7 end 8 Prune T and update the value of H by re-indexing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 4 :</head><label>4</label><figDesc>Performance Profiling of Training &amp; Inference (Up: Time-to-accuracy; Down: Inference Throughput).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 5 :</head><label>5</label><figDesc>Hyper-parameter Analysis: the number of walks , the step of walks , and the hidden dimension .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 6 :</head><label>6</label><figDesc>Performance Scaling of SUREL (W alk Sampler and Query-level RPE J oining) vs Different Number of Threads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 7 :</head><label>7</label><figDesc>Characteristics of Real-World Networks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head></head><label></label><figDesc>With sum (mean) neighbor's pooling followed by linear neurons and quadratic neurons ) * = * % , GNN needs two layers:' ! = ) * " + * # + * $ ? [) * " ) + )(* # ) + )(* $ ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 9 :</head><label>9</label><figDesc>LEFT: Two Limitations of Canonical-GNN-based GRL; RIGHT: How to Solve Them by Using Subgraph-based GRL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 :</head><label>1</label><figDesc>Data Preprocessing in SUREL Input: Graph G; number of walks ; step of walks Output: Associative array A, RPE array T 1 Initialize the array A and T , the dictionary H 2 for each node ? G do Run times -step random walks on G as a set of walk W ? Z ? ; Add the key V = set(W ) to H ;</figDesc><table><row><cell>5</cell></row></table><note>34</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Algorithm 2 :</head><label>2</label><figDesc>The Training Pipeline of SUREL Input: A graph G, a set of training queries {( , )}, batch capacity 1 , batch size 2 Output: A Neural Network for Neural Encoding NN(?) 1 Prepare the collection of set of walks W and RPEs X</figDesc><table><row><cell>2 for</cell><cell>= 1, . . . ,</cell><cell>_</cell><cell>do</cell></row><row><cell>3</cell><cell cols="3">Initialize the set Q = ? to track reached queries;</cell></row><row><cell>4</cell><cell cols="3">Randomly choose a seed-set of nodesV from ? ;</cell></row><row><cell>5</cell><cell cols="3">Run breath-first search to expandV and Q until</cell></row><row><cell></cell><cell cols="3">|V | = 1 or |Q| = 2 ;</cell></row><row><cell>6</cell><cell cols="3">Generate negative training queries (if not given) for a</cell></row><row><cell></cell><cell cols="3">mini-batch and put them into Q;</cell></row><row><cell>7</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Summary Statistics for Evaluation Datasets.</figDesc><table><row><cell>Dataset</cell><cell>Type</cell><cell>#Nodes</cell><cell>#Edges</cell></row><row><cell cols="2">citation2 Homo.</cell><cell>2,927,963</cell><cell>30,561,187</cell></row><row><cell>collab</cell><cell>Homo.</cell><cell>235,868</cell><cell>1,285,465</cell></row><row><cell>ppa</cell><cell>Homo.</cell><cell>576,289</cell><cell>30,326,273</cell></row><row><cell>ogb-mag</cell><cell>Hetero.</cell><cell>Paper(P): 736,389 Author(A): 1,134,649</cell><cell>P-A: 7,145,660 P-P: 5,416,271</cell></row><row><cell cols="2">tags-math Higher.</cell><cell>1,629</cell><cell>91,685 (projected) 822,059 (hyperedges)</cell></row><row><cell>DBLP-coauthor</cell><cell>Higher.</cell><cell>1,924,991</cell><cell>7,904,336 (projected) 3,700,067 (hyperedges)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison of SGRL Methods for Subgraph Sampling. Suppose using (|E |) many queries and to denote the average size of sampled subgraphs. The wall-clock time is measured on citation2 test set with = 16 threads.</figDesc><table><row><cell>Methods</cell><cell cols="2">SEAL (1-hop) [51, 53] DE-GNN [21]</cell><cell></cell><cell>SUREL</cell></row><row><cell>Time Complexity</cell><cell>( |E |)</cell><cell>( |E |)</cell><cell>(</cell><cell>? |V |)</cell></row><row><cell>Wall Time</cell><cell>36h</cell><cell>&gt; 1 month</cell><cell></cell><cell>26s</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results for Link Prediction, Relation Prediction, and Higher-order Pattern Prediction. = 1500, and batch size 2 = 32. Hidden dimension and walk parameters , are investigated in Sec. 4.4.</figDesc><table><row><cell>Models</cell><cell></cell><cell cols="2">citation2 MRR (%)</cell><cell cols="2">collab Hits@50 (%) Hits@100 (%) ppa</cell></row><row><cell cols="2">Node2vec</cell><cell cols="2">61.28?0.15</cell><cell></cell><cell>47.54?0.78</cell><cell>18.05?0.52</cell></row><row><cell cols="2">DeepWalk</cell><cell cols="2">84.47?0.04</cell><cell></cell><cell>49.08?0.93</cell><cell>27.80?1.71</cell></row><row><cell>GCN</cell><cell></cell><cell cols="2">84.74?0.21</cell><cell></cell><cell>44.75?1.07</cell><cell>18.67?1.32</cell></row><row><cell>SAGE</cell><cell></cell><cell cols="2">82.60?0.36</cell><cell></cell><cell>54.63?1.12</cell><cell>16.55?2.40</cell></row><row><cell cols="4">Cluster-GCN 80.04?0.25</cell><cell></cell><cell>44.02?1.37</cell><cell>3.56?0.40</cell></row><row><cell cols="4">GraphSAINT 79.85?0.40</cell><cell></cell><cell>53.12?0.52</cell><cell>3.83?1.33</cell></row><row><cell>SEAL</cell><cell></cell><cell cols="4">87.67?0.32 63.64?0.71</cell><cell>48.80?3.16</cell></row><row><cell>SUREL</cell><cell></cell><cell cols="4">89.74?0.18 63.34?0.52</cell><cell>53.23?1.03</cell></row><row><cell>Models</cell><cell cols="2">MAG(P-A) MRR (%)</cell><cell cols="3">MAG(P-P) tags-math DBLP-coauthor MRR (%) MRR (%) MRR (%)</cell></row><row><cell>GCN</cell><cell cols="5">39.43?0.29 57.43?0.30 51.64?0.27</cell><cell>37.95?2.59</cell></row><row><cell>SAGE</cell><cell cols="5">25.35?1.49 60.54?1.60 54.68?2.03</cell><cell>22.91?0.94</cell></row><row><cell>R-GCN</cell><cell cols="4">37.10?1.05 56.82?4.71</cell><cell>-</cell><cell>-</cell></row><row><cell cols="5">R-HGNN 33.41?2.47 45.91?3.28</cell><cell>-</cell><cell>-</cell></row><row><cell>DE-GNN</cell><cell>-</cell><cell></cell><cell>-</cell><cell></cell><cell>36.67?1.59</cell><cell>Timeout</cell></row><row><cell>SUREL</cell><cell cols="5">45.33?2.94 82.47?0.26 71.86?2.15</cell><cell>97.66?2.89</cell></row><row><cell cols="6">SUREL uses an 2-layer MLP for embeddings of RPEs and an 2-layer</cell></row><row><cell cols="6">RNN to encode query-level joined walks. The obtained subgraph</cell></row><row><cell cols="6">embeddings are fed into an MLP classifier for final prediction. De-</cell></row><row><cell cols="6">fault training parameters are: learning rate lr=1e-3 with early</cell></row><row><cell cols="6">stopping of 5-epoch patience, dropout p=0.1, Adam [18] as the</cell></row><row><cell cols="4">optimizer, batch capacity 1</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Breakdown of Runtime, Memory Consumption for Different Models on citation2, collab and DBLP-coauthor.Training time is calculated if no better validation result is observed in 3 consecutive epochs, which assumes the model has converged. Full-batch training models need NVIDIA A100 (48GB) GPUs, results of which are marked with *. Other models take less time on A100 than on RTX 6000.</figDesc><table><row><cell></cell><cell cols="2">Models</cell><cell></cell><cell></cell><cell cols="4">Runtime (s)</cell><cell>Memory (GB)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Prep. Train</cell><cell></cell><cell></cell><cell>Inf.</cell><cell>Total RAM SDRAM</cell></row><row><cell>citataion2</cell><cell cols="3">GCN * Cluster-GCN GraphSAINT SEAL (1-hop) SUREL</cell><cell>17 197 140 46 31</cell><cell cols="5">16,835 2,663 3,845 22,296 130,312 152,654 32 16,884 82 2,942 86 4,071 2,096 7,959 10,086</cell><cell>9.5 18.3 16.9 36.5 15.2</cell><cell>37.55 14.07 14.77 3.35 4.50</cell></row><row><cell></cell><cell cols="2">GCN</cell><cell></cell><cell>6</cell><cell>840</cell><cell></cell><cell></cell><cell>0.1</cell><cell>846</cell><cell>3.2</cell><cell>5.17</cell></row><row><cell>collab</cell><cell cols="3">Cluster-GCN GraphSAINT SEAL (1-hop)</cell><cell>8 &lt;1 10</cell><cell>649 6,746 7,675</cell><cell></cell><cell></cell><cell>0.2 0.2 37</cell><cell>666 6,747 7,722</cell><cell>3.4 3.2 15.4</cell><cell>5.29 6.58 6.97</cell></row><row><cell></cell><cell cols="2">SUREL</cell><cell></cell><cell>&lt;1</cell><cell>1,720</cell><cell></cell><cell></cell><cell>8</cell><cell>1,728</cell><cell>3.6</cell><cell>5.57</cell></row><row><cell>DBLP</cell><cell cols="2">GCN * SAGE * SUREL</cell><cell></cell><cell>--10</cell><cell>153 86 430</cell><cell></cell><cell cols="2">95 77 1,667</cell><cell>248 161 2,107</cell><cell>8.0 7.5 8.6</cell><cell>25.80 24.70 8.61</cell></row><row><cell></cell><cell></cell><cell>0.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>60</cell></row><row><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>55</cell></row><row><cell cols="2">Test MRR</cell><cell>0.6 0.7 0.5</cell><cell></cell><cell></cell><cell cols="2">GCN(full-batch) Cluster-GCN GraphSAINT SEAL</cell><cell>Test Hits@100</cell><cell>40 45 50 35</cell><cell>SEAL</cell></row><row><cell></cell><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell>SUREL</cell><cell></cell><cell></cell><cell>30</cell><cell>SUREL</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>2000</cell><cell>4000</cell><cell>6000</cell><cell>8000</cell><cell></cell><cell>0</cell><cell>500</cell><cell>1000</cell><cell>1500</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Time (s) ? citation2</cell><cell></cell><cell></cell><cell></cell><cell>Time (min) ? ppa</cell></row><row><cell></cell><cell></cell><cell></cell><cell>2733.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>2090.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>1066.6</cell><cell>770.2</cell><cell>1017.0</cell><cell>975.5</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Summary of Frequently Used Notations. .e. join X , for ? as [..., X , , ...]. X</figDesc><table><row><cell cols="2">Symbol Meaning</cell></row><row><cell>Q</cell><cell>a query (set of nodes), i.e. = { , , }</cell></row><row><cell>Q</cell><cell>a collection of queries, i.e. ? Q</cell></row><row><cell>W</cell><cell>the set of walks starting from node</cell></row><row><cell>W</cell><cell>a collection of walks, i.e. ? W</cell></row><row><cell>V</cell><cell>the set of unique nodes appearing in W</cell></row><row><cell>X</cell><cell>the relative positional encoding (RPE) of nodes in</cell></row><row><cell></cell><cell>V regarding their step occurrence in W</cell></row><row><cell>X ,</cell><cell>the RPE vector of node regarding the node (all</cell></row><row><cell></cell><cell>zeros if ? V )</cell></row><row><cell>T</cell><cell>the RPE array with indices as RPE-IDs and entries</cell></row><row><cell></cell><cell>as RPE vectors</cell></row><row><cell>H</cell><cell>the dictionary with nodes in V as keys and RPEs</cell></row><row><cell></cell><cell>X (or RPE-IDs) as values</cell></row><row><cell>A</cell><cell>the associative array with nodes in ? V as key</cell></row><row><cell></cell><cell>and the tuple (W , X ) as entry</cell></row><row><cell>?</cell><cell>the concatenation operation that joins all node-level</cell></row><row><cell></cell><cell>RPEs, i</cell></row></table><note>, the query-level RPE for node , X , = ? ? X ,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Summary Statistics and Experimental Setup for Evaluation Datasets.</figDesc><table><row><cell>Dataset</cell><cell>Type</cell><cell>#Nodes</cell><cell>#Edges</cell><cell cols="4">Avg. Node Deg. Density Split Ratio Split Type</cell><cell>Metric</cell></row><row><cell>citation2</cell><cell>Homo.</cell><cell>2,927,963</cell><cell>30,561,187</cell><cell>20.7</cell><cell>0.00036%</cell><cell>98/1/1</cell><cell>Time</cell><cell>MRR</cell></row><row><cell>collab</cell><cell>Homo.</cell><cell>235,868</cell><cell>1,285,465</cell><cell>8.2</cell><cell>0.0046%</cell><cell>92/4/4</cell><cell>Time</cell><cell>Hits@50</cell></row><row><cell>ppa</cell><cell>Homo.</cell><cell>576,289</cell><cell>30,326,273</cell><cell>73.7</cell><cell>0.018%</cell><cell>70/20/10</cell><cell cols="2">Throughput Hits@100</cell></row><row><cell>ogb-mag</cell><cell>Hetero.</cell><cell>Paper(P): 736,389 Author(A): 1,134,649</cell><cell>P-A: 7,145,660 P-P: 5,416,271</cell><cell>21.7</cell><cell>N/A</cell><cell>99/0.5/0.5</cell><cell>Time</cell><cell>MRR</cell></row><row><cell>tags-math</cell><cell>Higher.</cell><cell>1,629</cell><cell>91,685 (projected) 822,059 (hyperedges)</cell><cell>N/A</cell><cell>N/A</cell><cell>60/20/20</cell><cell>Time</cell><cell>MRR</cell></row><row><cell cols="2">DBLP-coauthor Higher.</cell><cell>1,924,991</cell><cell>7,904,336 (projected) 3,700,067 (hyperedges)</cell><cell>N/A</cell><cell>N/A</cell><cell>60/20/20</cell><cell>Time</cell><cell>MRR</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Dataset Statistics for Relation Prediction and Higher-order Pattern Prediction. Dataset Query Type #Train (Pos.) #Val./Test (Pos.) Pos./Neg.</figDesc><table><row><cell>MAG(P-A)</cell><cell>relation</cell><cell>6,519,308</cell><cell>16,180</cell><cell>1:1000</cell></row><row><cell>MAG(P-P)</cell><cell>relation</cell><cell>5,199,201</cell><cell>22,639</cell><cell>1:1000</cell></row><row><cell>tag-math</cell><cell>higher-order</cell><cell>74,955</cell><cell>24,985</cell><cell>1:100</cell></row><row><cell cols="2">DBLP-coauthor higher-order</cell><cell>79,566</cell><cell>26,522</cell><cell>1:1000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Hyperparameters Used for Benchmark SUREL. 50, = 4, = 20; collab with = 2, = 200, = 20, as relative small values of , , and already guarantee sufficient good performance. The rest hyperparameters remain the same as reported earlier.</figDesc><table><row><cell>Dataset</cell><cell>#Steps</cell><cell>#Walks</cell><cell>#Neg. Samples</cell></row><row><cell>citation2</cell><cell>4</cell><cell>200</cell><cell>50</cell></row><row><cell>collab</cell><cell>2</cell><cell>400</cell><cell>50</cell></row><row><cell>ppa</cell><cell>4</cell><cell>200</cell><cell>50</cell></row><row><cell>MAG (P-A)</cell><cell>3</cell><cell>200</cell><cell>10</cell></row><row><cell>MAG (P-P)</cell><cell>4</cell><cell>100</cell><cell>50</cell></row><row><cell>tags-math</cell><cell>3</cell><cell>100</cell><cell>10</cell></row><row><cell>DBLP-coauthor</cell><cell>3</cell><cell>100</cell><cell>10</cell></row><row><cell>with =</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://troydhanson.github.io/uthash/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://ogb.stanford.edu/docs/dataset_overview/ 3 https://www.cs.cornell.edu/~arb/data/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We greatly thank all the reviewers for valuable feedback and actionable suggestions. H. Yin and P. Li are supported by the 2021 JPMorgan Faculty Award and the National Science Foundation (NSF) award HDR-2117997.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>4 https://ogb.stanford.edu/docs/leader_linkprop/ adopt the published numbers if available on the leaderboard. For the rest, we benchmark the model using their official implementation and tuning parameters as listed below.</p><p>? Graph embedding: graph embedding models for transductive learning such as Node2vec <ref type="bibr" target="#b10">[11]</ref>, DeepWalk 5 <ref type="bibr" target="#b29">[30]</ref>. As implicit matrix factorization, it can be extensively optimized <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b42">43]</ref> for large-scale graph mining tasks. The obtained node representation embeds the global position of target nodes in a given graph, which potentially can be exploited for link prediction. ? GCN family: a graph auto-encoder model that using graph convolution layers to learning node representations, including GCN <ref type="bibr" target="#b18">[19]</ref>, GraphSAGE <ref type="bibr" target="#b12">[13]</ref>, and the derived models, such as Cluster-GCN <ref type="bibr" target="#b6">[7]</ref>, GraphSAINT <ref type="bibr" target="#b48">[49]</ref>. ? R-GCN 6 <ref type="bibr" target="#b31">[32]</ref>: a relational GCN that models heterogeneous graphs with node/link types. ? R-HGNN 7 <ref type="bibr" target="#b46">[47]</ref>: a heterogeneous GNN that focuses on learning relation-aware node representations with attention mechanism. ? SEAL 8 <ref type="bibr" target="#b50">[51]</ref>: apply GCN with double radius labeling tricks to obtain subgraph-level readout for link prediction. SEAL reigns in the top spots of OGB leaderboard on multiple tasks, thanks to the expressiveness inherited from SGRL. The implementation we tested is specially optimized for OGB datasets provided in <ref type="bibr" target="#b52">[53]</ref>. ? DE-GNN 9 <ref type="bibr" target="#b20">[21]</ref>: a provably more powerful SGRL that utilizes distance features (i.e. shortest path distance, landing probability) to assist GNNs in representing any set of nodes. DE-GNN can be applied to tasks such as node classification, link prediction and higher-order cases, with great performance. For graph embedding approaches, we first use these models to generate node embeddings, and then train an MLP as the link predictor with input of the Hadamard product between hidden representations of two nodes. Then, as OGB guideline required, to perform data splitting, tune the MLP over the validation set, and test it through the benchmark evaluator.</p><p>All canonical GNN baselines 10 come with three message passing layers of 256 hidden dimensions, and a tuned dropout ratio in {0, 0.5} for full-batch training. Canonical GNN models combine node embeddings in the queried set as the representations of links/hyperedges, which are later fed into an MLP classifier for final prediction. Besides, they need to use full training data to generate robust node representations. The hypergraph datasets do not come with raw node features. Thus, canonical GNNs here use random features as input for training along with other model parameters. R-GCN and R-HGNN use relational GCNConv layers that support message passing with different relation types between nodes. The relation type of edges is used as the input beside node features.</p><p>SGRL-based models only use partial edges from the training set. Both SEAL and DE-GNN extract 1-hop enclosing subgraphs for training. SEAL applies three GCN layers of 32 hidden dimensions plus a sortpooling and several 1D convolution layers to generate readout of the target subgraphs for prediction. DE-GNN adopts shortest path distance calculated from each extracted subgraph</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the bottleneck of graph neural networks and its practical implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eran</forename><surname>Yahav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Construction of a trophically complex near-shore Antarctic food web model using the Conservative Normal framework with structural coexistence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan M Bengtson</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darryl</forename><forename type="middle">W</forename><surname>Nash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hawker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonny</forename><forename type="middle">S</forename><surname>Norbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><forename type="middle">A</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cropp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Marine Systems</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improving graph neural network expressivity via subgraph isomorphism counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Bouritsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Frasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2020 Workshop on Graph Representation Learning and Beyond</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fastgcn: fast learning with graph convolutional networks via importance sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Stochastic training of graph convolutional networks with variance reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="942" to="950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Can Graph Neural Networks Count Substructures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Villar</forename><surname>Soledad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lin</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="257" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Is a single embedding enough? Learning node representations that capture multiple social contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Epasto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The world wide web conference</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="394" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast Graph Representation Learning with PyTorch Geometric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR 2019 Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Introduction to parallel computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananth</forename><surname>Grama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vipin</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anshul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Pearson Education</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Graph representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Artifical Intelligence and Machine Learning</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="159" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00687</idno>
		<title level="m">Open Graph Benchmark: Datasets for Machine Learning on Graphs</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Graph meta learning via local subgraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kexin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adaptive Sampling Towards Fast Graph Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving the accuracy, scalability, and performance of graph neural networks with roc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sina</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Aiken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning and Systems</title>
		<meeting>Machine Learning and Systems</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="187" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Introduction to statistical relational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nir</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sa?o</forename><surname>D?eroski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Pfeffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Fai</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Neville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The link-prediction problem for social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Liben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Nowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American society for information science and technology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="1019" to="1031" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">G3: when graph neural networks meet parallel graph processing systems on GPUs. Proceedings of the VLDB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Husong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengliang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingsheng</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2813" to="2816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural subgraph isomorphism counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haojie</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1959" to="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Neural Predicting Higher-Order Patterns in Temporal Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2022</title>
		<meeting>the Web Conference 2022</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022" />
			<biblScope unit="page" from="1340" to="1351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyu</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengtao</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arquimedes</forename><surname>Canedo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03092</idno>
		<title level="m">Neural Subgraph Matching</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mohoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Waleffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Xu</surname></persName>
		</author>
		<title level="m">Theodoros Rekatsinas, and Shivaram Venkataraman. 2021. Marius: Learning Massive Graph Embeddings on a Single Machine</title>
		<imprint>
			<biblScope unit="page" from="533" to="549" />
		</imprint>
	</monogr>
	<note>15th USENIX Symposium on Operating Systems Design and Implementation (OSDI 21</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Weisfeiler and leman go neural: Higher-order graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ritzert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Rattan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grohe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4602" to="4609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Graph Neural Networks Exponentially Lose Expressive Power for Node Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenta</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taiji</forename><surname>Suzuki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>David E Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald J</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European semantic web conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the Equivalence between Node Embeddings and Structural Graph Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balasubramaniam</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Population regulation in snowshoe hare and Canadian lynx: asymmetric food web configurations between hare and lynx</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><forename type="middle">Chr</forename><surname>Stenseth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhelm</forename><surname>Falck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ottar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles J</forename><surname>Bj?rnstad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krebs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="5147" to="5152" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Inductive relation prediction by subgraph reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Komal</forename><surname>Teru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9448" to="9457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Dorylus: Affordable, Scalable, and Accurate GNN Training with Distributed CPU Servers and Serverless Threads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Thorpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Eyolfson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanzhou</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinliang</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keval</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Netravali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miryung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqing Harry</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th USENIX Symposium on Operating Systems Design and Implementation</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="495" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Equivariant and Stable Positional Encoding for More Powerful Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haorui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoteng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Microsoft academic graph: When experts are not enough</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chieh-Han</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anshul</forename><surname>Kanakia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantitative Science Studies</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="396" to="413" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep Graph Library: Towards Efficient and Scalable Deep Learning on Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihao</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mufei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR 2019 Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">GLASS: GNN with Labeling Tricks for Subgraph Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Inductive Representation Learning in Temporal Networks via Causal Anonymous Walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Demo of marius: a system for large-scale graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Carlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mohoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Waleffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanan</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="2759" to="2762" />
		</imprint>
	</monogr>
	<note>Theodoros Rekatsinas, and Shivaram Venkataraman</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">How Powerful are Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Aligraph: A comprehensive graph neural network platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3165" to="3166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Heterogeneous graph representation learning with relation awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leilei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanren</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Decoupling the Depth and Scope of Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinglong</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajitesh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malevich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajgopal</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Prasanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Graphsaint: Graph sampling based inductive learning method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajitesh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajgopal</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Prasanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">AGL: a scalable system for industrial-purpose graph machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dalong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibang</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="3125" to="3137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Link prediction based on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Inductive Matrix Completion Based on Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Labeling Trick: A Theory of Using Graph Neural Networks for Multi-Node Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinglong</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">GRAIN: Improving Data Efficiency of GraPh Neural Networks via Diversified inFluence Maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yexin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the VLDB Endowment</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="2473" to="2482" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Accelerating Large Scale Real-Time GNN Inference Using Channel Pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajitesh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajgopal</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Prasanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1597" to="1605" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
