<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SLUE: NEW BENCHMARK TASKS FOR SPOKEN LANGUAGE UNDERSTANDING EVALUATION ON NATURAL SPEECH</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suwon</forename><surname>Shon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ASAPP</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankita</forename><surname>Pasad</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ASAPP</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Brusco</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ASAPP</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ASAPP</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyu</forename><forename type="middle">J</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ASAPP</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SLUE: NEW BENCHMARK TASKS FOR SPOKEN LANGUAGE UNDERSTANDING EVALUATION ON NATURAL SPEECH</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-spoken language understanding</term>
					<term>benchmark</term>
					<term>pre-training</term>
					<term>named entity recognition</term>
					<term>sentiment analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Progress in speech processing has been facilitated by shared datasets and benchmarks. Historically these have focused on automatic speech recognition (ASR), speaker identification, or other lowerlevel tasks. Interest has been growing in higher-level spoken language understanding tasks, including using end-to-end models, but there are fewer annotated datasets for such tasks. At the same time, recent work shows the possibility of pre-training generic representations and then fine-tuning for several tasks using relatively little labeled data. We propose to create a suite of benchmark tasks for Spoken Language Understanding Evaluation (SLUE) consisting of limited-size labeled training sets and corresponding evaluation sets. This resource would allow the research community to track progress, evaluate pre-trained representations for higher-level tasks, and study open questions such as the utility of pipeline versus end-to-end approaches. We present the first phase of the SLUE benchmark suite, consisting of named entity recognition, sentiment analysis, and ASR on the corresponding datasets. We focus on naturally produced (not read or synthesized) speech, and freely available datasets. We provide new transcriptions and annotations on subsets of the VoxCeleb and VoxPopuli datasets, evaluation metrics and results for baseline models, and an open-source toolkit to reproduce the baselines and evaluate new models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Progress on speech processing has benefited from shared data sets and benchmarks. For tasks with plentiful shared resources, such as ASR, we now have high-performing and commercially feasible systems, at least for high-resource languages. On the other hand, "higher-level" spoken language understanding (SLU) tasks have received less attention and resources. There are numerous tasks, at varying linguistic levels, that have been benchmarked extensively for text input by the natural language processing (NLP) communitynamed entity recognition, parsing, sentiment analysis, entailment, summarization, and so on-but they have not been as thoroughly addressed for speech input. Better benchmarks would allow the research community to address open research questions about SLU, such as which tasks can be addressed well by pipeline ASR+NLP approaches and which ones benefit from having direct access to the input speech; and, for the latter kind of tasks, how to best extract the needed speech information.</p><p>One challenge for advancing SLU is that it is costly and timeconsuming to collect large amounts of labeled speech data for all of these tasks. On the other hand, recent developments suggest that it is possible to pre-train general speech representations that can * Work done during an internship at ASAPP then be fine-tuned for a variety of tasks, given only a small amount of labeled data <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>. It is this combination of factors-the need for more benchmark SLU tasks, along with advances in pre-trained representations-that motivate our work. Specifically, the goals of our work are to <ref type="bibr" target="#b0">(1)</ref> track research progress on multiple SLU tasks, <ref type="bibr" target="#b1">(2)</ref> facilitate the development of pre-trained representations by providing fine-tuning and eval sets for a variety of SLU tasks, and <ref type="bibr" target="#b2">(3)</ref> foster the open exchange of research by focusing on freely available datasets that all academic and industrial groups can easily use.</p><p>Several other recent efforts have produced multi-task benchmarks, either combining existing data sets and tasks <ref type="bibr" target="#b2">[3]</ref> or generating read speech data from existing NLP task data <ref type="bibr" target="#b3">[4]</ref>. In this work, we contribute the following: (i) New annotation of publicly available, natural speech data for training and evaluation on new tasks, specifically named entity recognition (NER) and sentiment analysis (SA), as well as new text transcriptions for training and evaluating ASR systems on the same data. (ii) A benchmark suite including a toolkit for baseline models and evaluation, 1 the annotated data, web site, and leaderboard. 2 (iii) A variety of baseline models to measure the state of existing models on these new tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Related work on pre-trained representations. In recent NLP research, self-supervised language models trained on unlabeled text <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref> have come to be used as more or less universal representations for a large range of downstream tasks. Self-supervised speech representations <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> have also become quite successful for a number of tasks, but it is not yet clear how generally applicable any one model is to a variety of downstream tasks. Most pre-trained models are evaluated on a single task such as ASR <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>, speaker recognition <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>, slot filling <ref type="bibr" target="#b17">[18]</ref>, or emotion recognition <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. A few studies have focused on fine-tuning a pre-trained model for multiple downstream tasks, but mostly low-level tasks such as phoneme recognition, speaker identification, keyword spotting, and emotion recognition <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref> (with some exceptions; e.g., Liu et al. <ref type="bibr" target="#b21">[22]</ref> evaluate on sentiment analysis). Benchmark suites and tasks. SUPERB <ref type="bibr" target="#b2">[3]</ref> is a recently created benchmark collection of pre-existing speech processing tasks, designed to compare the applicability of pre-trained models on a variety of tasks, most of which are lower-level speech tasks. It also includes two SLU tasks, intent classification (IC) and slot filling (SF). However, the dataset used for the IC task <ref type="bibr" target="#b23">[24]</ref> is one where many recent models achieve nearly perfect performance, and the dataset for SF <ref type="bibr" target="#b24">[25]</ref> consists of artificial (synthesized) rather than natural speech. ASR-GLUE <ref type="bibr" target="#b3">[4]</ref> is another recently proposed benchmark, which consists of tasks from GLUE <ref type="bibr" target="#b25">[26]</ref>, the popular NLP benchmark, converted to speech by having six speakers dictate the text. Although it includes many more SLU tasks, the limited set of speakers and read speech format makes it less natural. In addition, no in-domain training speech data is available for the ASR-GLUE tasks.</p><p>In addition to these benchmark suites, there are well-known SLU tasks such as ATIS <ref type="bibr" target="#b26">[27]</ref> and the Switchboard NXT tasks <ref type="bibr" target="#b27">[28]</ref>. However, these data sets have licensing constraints, and in the case of ATIS, it is easy to achieve near-perfect performance <ref type="bibr" target="#b28">[29]</ref> since the audio is too clean. For the tasks we consider in this paper-NER and sentiment-other previously released datasets have clear limitations: 1) sentiment analysis datasets are either scripted <ref type="bibr" target="#b29">[30]</ref>, singlespeaker monologues <ref type="bibr" target="#b30">[31]</ref>, or not freely available <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>. 2) the available NER speech datasets <ref type="bibr" target="#b33">[34]</ref> we are aware of are a mix of dictated text and TED talks, with a somewhat biased set of annotations since they are filtered by a text-based NER tagger; and data that is not freely available <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SLUE BENCHMARK 3.1. Tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ASR:</head><p>Although it is not a SLU task, we include ASR because it can help analyze performance on downstream SLU tasks on the same domain, and because pipeline approaches depend on ASR outputs. ASR is evaluated using word error rate (WER). NER: Named entity recognition involves detecting the named entities and their tags (types) in a given sentence. Named entities are phrases, often (but not always) consisting of proper nouns, that refer to distinct entities such as a person, location, organization, numerical value, etc. NER is relevant to downstream tasks like deidentification <ref type="bibr" target="#b34">[35]</ref> and coreference resolution <ref type="bibr" target="#b35">[36]</ref>.</p><p>Similarly to previous work <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b36">37]</ref>, we evaluate performance using micro-averaged F1 scores on two aspects of the output. F1 score is the harmonic mean of precision and recall. The first score, referred to as F1, evaluates an unordered list of named entity phrase and tag pairs predicted for each sentence. The second score, label-F1, considers only the tag predictions. Label-F1 is useful to understand model accuracy despite the possible misspelling and segmentation errors in speech-to-text conversion. SA: Sentiment analysis refers to classifying a given speech segment as having negative, neutral, or positive sentiment. It is a higher-level task since the semantic content is also very important. For example, negative sentiment can be expressed by disparagement, sarcasm, doubt, suspicion, frustration, etc. <ref type="bibr" target="#b37">[38]</ref>. We evaluate SA using macroaveraged (unweighted) recall and F1 scores, similarly to previous work <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Data and annotation</head><p>The data statistics are shown in Tab. 1. The fine-tune and dev sets are intended for training and validation, while the test set is held out for final evaluation. We hired several expert transcribers and annotators from a third-party vendor and an internal annotation team.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">VoxPopuli dataset: NER annotation</head><p>VoxPopuli <ref type="bibr" target="#b39">[40]</ref> is a large multilingual speech corpus consisting of European Parliament event recordings with audio, transcripts and timestamps from the official Parliament website. By the nature of the source, the spoken data includes abundant named entities making it an ideal choice for NER. We use the English subset of the data with transcriptions. We retain the canonical splits provided in the official repository <ref type="bibr" target="#b2">3</ref> for the dev and test sets. For the fine-tune set, we sample about 15 hours from the official train set.</p><p>For annotation, we follow the OntoNotes Release 5.0 <ref type="bibr" target="#b40">[41]</ref> guidelines and entity labels. The label-wise counts in the annotated data are reported in Tab. 2. As the domain of OntoNotes 5 is slightly different from VoxPopuli, for evaluation, we combine similar categories and discard the rare ones, resulting in 7 categories. Raw labels before combining are still included in the dataset. We hired 4 annotators and all annotation was done on text transcripts.</p><p>To estimate human performance, we obtain a second pass of annotations for the test set. The second pass achieved an microaveraged F1 score of 0.79 when evaluated against the first pass. The disagreement between the two passes can either be classified as a mismatch in the detection of the entity phrase (missed/over/partial detection) or a mismatch in the label when they agree on the entity phrase (mislabel). We see that 88% of these disagreements were detection errors and on a closer look at the data, we notice certain recurring systematic differences in the two passes leading to a majority of these errors. We will collect more passes with updated guidelines to account for these objective disagreements, in order to report a more robust human performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">VoxCeleb dataset: Transcription and Sentiment Annotation</head><p>The VoxCeleb <ref type="bibr" target="#b41">[42]</ref> dataset consists of unrestricted single-sided conversation voice snippets for several thousand people extracted from YouTube videos and was originally created for speaker recognition. We provide transcripts and sentiment annotations for the English portion of the official VoxCeleb1 test set (35 out of 40 speakers), and also for a 15-hour subset of the official VoxCeleb1 dev set, which we divide into our fine-tune set (120 speakers) and dev set (20 speakers). We exclude utterances containing slurs, and trim partial words from the ends of audio segments using a forced aligner (as reflected in the timestamps that we provide).</p><p>Sentiment labels were obtained by asking annotators to listen to each individual utterance within each conversation maintaining the order of appearance. This dataset contains utterances only for the interviewee and not the interviewer, so our annotators had to imagine the rest of the conversation. Following <ref type="bibr" target="#b31">[32]</ref>, the annotators labeled an utterance as positive when the speaker showed signs of happiness and positive attitude, such as laughing or smiling or using positive words (encouragement, joy, etc.); as negative when the speaker showed signs of negative emotions such as raising voice in anger, being dismissive, or using negative words (including disparagement, doubt/questioning/suspicion, sarcasm, anger, etc.); and as neutral when there are no emotional or lexical cues to indicate the speaker's sentiment one way or another. If the utterance is too short to determine the sentiment, we marked it as neutral. If the utterance contains a clear mix of positive and negative sentiments, we labeled it as mixed.</p><p>For the test set, each utterance was labeled by 5 passes (from a pool of six annotators) and the segments where at least three annotators agree were retained as ground truth labels. We labeled the remaining utterances as disagreement. The inter-annotator Krippendorff's alpha coefficient for this set is 0.48 (considering the data as ordinal). Also, we compute the pairwise Cohen's kappa score for each combination of annotators, getting a mean of 0.37 (lowest: 0.20, highest: 0.47) -results which are in the range of previous tasks related to natural speech sentiment or emotion <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b31">32]</ref>. For both ASR and Sentiment evaluation on this data, we exclude the samples corresponding to either disagreement or mixed classes.</p><p>The fine-tune and dev sets were annotated in a single pass. We leave the decision of using samples labeled as mixed to the user. For our baseline systems, we discard them. Tab. 3 shows the distribution of labels obtained for each portion of the dataset.   We also run an independent pass of annotation for approximating human performance for this task on the test set. F1 scores are 0.39 for the negative class, 0.82 for the neutral class, and 0.67 for the positive class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">BASELINE MODELS AND RESULTS</head><p>We use SLUE-VoxCeleb for ASR and SA and SLUE-VoxPopuli for ASR and NER. Our baselines use pre-trained speech models from the official Fairseq repository. <ref type="bibr" target="#b3">4</ref> Below we refer to wav2vec 2.0 <ref type="bibr" target="#b10">[11]</ref> as W2V2, and refer to all base and large models with suffix "-B" and "-L" respectively. We also refer to the type and amount of unlabeled pretraining data with a suffix on the model name: Lib-riSpeech (LS), LibriLight (LL), and multilingual VoxPopuli (VP). NLP topline refers to a model that uses human transcription as input, which provides the performance of a pipeline system with a perfect ASR model. Pipeline models generate text from speech using an ASR system, and then apply an NLP model on the decoded text. End-to-end (E2E) models directly map from the input speech to output task labels. We fine-tune all trainable parameters using the respective fine-tune sets described in Sec. 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Automatic speech recognition</head><p>Setup. For ASR baselines, we add a linear layer on top of pretrained W2V2 <ref type="bibr" target="#b10">[11]</ref> and HuBERT <ref type="bibr" target="#b13">[14]</ref> models and fine-tune them on the appropriate SLUE fine-tune set with a character-level CTC objective <ref type="bibr" target="#b42">[43]</ref>. When decoding with a language model (LM), we use beam size 500, LM weight 2 and word insertion penalty -1. We consider both in-domain and out-of-domain LMs. In-domain LMs are   . Given that the in-domain transcription is limited, we observe a larger gain in performance when using LM trained on TED-LIUM 3. We note that these WERs are roughly in line with the WERs of the same models on the LibriSpeech testother set when fine-tuned on 10h of LibriSpeech, making these sets roughly similar in difficulty. We also note that W2V2-B-LS960 outperforms W2V2-B-VP100K, indicating that the model pre-trained on same-language data is a better fit than the model pre-trained on same-domain data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Named entity recognition</head><p>Setup. The NER annotations have the text transcripts along with the (entity phrase, entity tag) pairs. We formulate E2E NER as character level prediction where entity phrases are delimited by tag-specific special characters as in <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b36">37]</ref>. For example, the phrases "irish" and "eu" are tagged as NORP ($) and GPE (%) respectively in ''the $ irish ] system works within a legal and regulatory policy directive framework dictated by the % eu ]". The vocabulary includes 19 special characters, 18 for each of the entity tags (Tab. 2), inserted at the beginning of an entity phrase, and one to denote end of the entity phrase. The NER E2E baseline models using pre-trained W2V2 and HuBERT models are trained similarly to the ASR models (Sec. 4.1). For E2E experiments with LM, we use a 4-gram LM trained on the SLUE-VoxPopuli fine-tune set, and use decoding parameters tuned to optimize the dev performance of the E2E W2V2-B-LS960 model (beam size 500, LM weight 2 and word insertion penalty 1). For pipeline experiments, we use the best ASR models described in Sec. 4.1. The pre-trained DeBERTa-L model is fine-tuned for NER (token classification) using HuggingFace's transformers toolkit <ref type="bibr" target="#b44">[45]</ref> where a linear layer is added on top of the final hidden-state output.</p><p>Results. Baseline experiments are reported in Tab. 5. Note that, since the LM was fine-tuned for a single model, the performance of other models could be sub-optimal; similarly the NLP models were not tuned for the Pipeline experiments. The best models are chosen based on the WER of NER-annotated sentences in the dev set. We make the following observations: ? There is significant room for improvement for both Pipeline and E2E models, even while leveraging state-of-the-art pre-trained models. ? W2V2-B-LS960 and HuBERT-B-LS960 outperform W2V2-B-VP100k suggesting that language mismatch is worse than domain mismatch in a pre-trained model. ? LM decoding provides consistent and significant improvements. . ? Improvements from larger speech models are less evident when using LM decoding; that is, using a small amount (5k utterances) of unlabeled text is as beneficial as leveraging 60 times more unlabeled audio data with the current methods. The last point may suggest that the pre-trained speech models do not learn significant semantic information, so that even a small amount of additional semantic knowledge (in the form of language models here) should help immensely. This point deserves further exploration in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Sentiment analysis</head><p>Setup. For the NLP topline, we use the ground-truth (GT) text of the fine-tune set for fine-tuning the NLP model (DeBERTa-L) and use the GT text of the dev and test sets for evaluation. For pipeline models, we use the GT text of the fine-tune set for fine-tuning the NLP models and the ASR transcriptions of the dev and test sets for evaluation. For the ASR-generated transcription, we use the best ASR models described in Sec. 4.1. For E2E models, we use the speech waveforms of the fine-tune set for fine-tuning the speech models (W2V2 and HuBERT) and the speech waveforms of the dev and test sets for evaluation. For E2E models, on top of the pretrained speech model, we add a self-attention pooling layer and 2 fully connected layers including the output layer. Results. A detailed baseline performance evaluation is shown in Tab. 6. In the pipeline experiments, a larger speech model produces no notable gain in F1 score although it improves the ASR WER by 5% absolute. Similarly, LM decoding in pipeline models doesn't help on the SA task. More interestingly, the pipeline system performs almost as well as the NLP topline system, suggesting that the NLP model can tolerate ASR errors for the SA task. The E2E systems have much worse performance than the pipeline approaches. The performance of E2E system heavily depends on what pre-trained speech model is used while pipeline systems is not sensitive to speech model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">SLUE benchmark results</head><p>A summary of the main SLUE benchmark results thus far is shown in Tab. 7. As an overall rating, we define the SLUE benchmark score as an average of the primary metrics for the three tasks: SLUEscore = 1 3 (100 ? WER ASR-VP +WER ASR-VC 2 ) + F1NER-VP + F1SA-VC . The best pipeline system is still 11% behind the NLP topline in terms of SLUE score. Compared to the best pipeline system, the best E2E system is 7% behind, likely because of the huge NLP model size in the pipeline systems. Adding a language model improves both pipeline and E2E approaches, especially for the NER task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>Motivated by the growing interest in SLU tasks and recent progress on pre-trained representations, we have proposed a new benchmark suite consisting of newly annotated fine-tuning and evaluation sets, and have provided annotations and baselines for new NER, sentiment, and ASR evaluations. We have presented the detailed process to build the benchmark and evaluated numerous baseline systems using current state-of-the-art speech and NLP models. Future work includes adding more SLU tasks and refining test set annotation and human performance measures. Additional potential future work includes more speech-specific evaluation, such as measuring the accuracy of named entity time boundaries in the NER task.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Corpus</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>4 https://github.com/pytorch/fairseq</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Classification of disagreements between the two annotation passes on SLUE-VoxPopuli test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Corpus statistics and task descriptions of SLUE benchmark v0.2. SLUE-VoxPopuli v0.2 NER label statistics.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Fine-tune</cell><cell cols="2">Size -utts (hour) Dev</cell><cell>Test</cell><cell>Tasks</cell><cell>Speech type</cell><cell>Source domain</cell><cell>License</cell></row><row><cell cols="8">SLUE-VoxPopuli 5,000 (14.5) 1,753 (5.0) 1,842 (4.9) ASR, NER Scripted</cell><cell>European parliament</cell><cell>CC0</cell></row><row><cell cols="2">SLUE-VoxCeleb</cell><cell cols="6">5,777 (12.8) 1,454 (3.2) 3,553 (7.8) ASR, SA</cell><cell>Conversational Broadcasting (YouTube) CCBY 4.0</cell></row><row><cell>Combined</cell><cell cols="3">Raw label</cell><cell></cell><cell cols="3"># of NER phrases</cell></row><row><cell>label</cell><cell cols="3">(ontonotes5)</cell><cell></cell><cell cols="3">Fine-tune Dev Test</cell></row><row><cell>PLACE</cell><cell cols="2">GPE, LOC</cell><cell></cell><cell></cell><cell>2012</cell><cell>642</cell><cell>731</cell></row><row><cell></cell><cell cols="4">CARDINAL, MONEY,</cell><cell></cell><cell></cell></row><row><cell>QUANT</cell><cell cols="4">ORDINAL, PERCENT,</cell><cell>923</cell><cell>327</cell><cell>246</cell></row><row><cell></cell><cell cols="2">QUANTITY</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ORG</cell><cell>ORG</cell><cell></cell><cell></cell><cell></cell><cell>864</cell><cell>259</cell><cell>273</cell></row><row><cell>WHEN</cell><cell cols="2">DATE, TIME</cell><cell></cell><cell></cell><cell>762</cell><cell>260</cell><cell>186</cell></row><row><cell>NORP</cell><cell>NORP</cell><cell></cell><cell></cell><cell></cell><cell>647</cell><cell>220</cell><cell>348</cell></row><row><cell>PERSON</cell><cell cols="2">PERSON</cell><cell></cell><cell></cell><cell>272</cell><cell>51</cell><cell>81</cell></row><row><cell>LAW</cell><cell>LAW</cell><cell></cell><cell></cell><cell></cell><cell>250</cell><cell>60</cell><cell>96</cell></row><row><cell cols="3">Sentiment label</cell><cell cols="2">Fine-tune</cell><cell>Sets Dev</cell><cell>Test</cell></row><row><cell></cell><cell cols="2">Negative</cell><cell></cell><cell>227</cell><cell>51</cell><cell>168</cell></row><row><cell></cell><cell>Neutral</cell><cell></cell><cell cols="4">4,223 1,124 2,521</cell></row><row><cell></cell><cell>Positive</cell><cell></cell><cell cols="2">1,279</cell><cell>262</cell><cell>737</cell></row><row><cell></cell><cell>Mixed</cell><cell></cell><cell></cell><cell>48</cell><cell>3</cell><cell>23</cell></row><row><cell cols="3">Disagreement</cell><cell></cell><cell>-</cell><cell>14</cell><cell>104</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell cols="4">5,777 1,454 3,553</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table /><note>SLUE-VoxCeleb v0.2 Sentiment label distribution.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>ASR</figDesc><table><row><cell cols="5">performance (WER, %). Note that W2V2-B-LS960</cell></row><row><cell cols="5">and W2V2-L-LL60K get WER 17.6% and 10.0%, respectively, on</cell></row><row><cell cols="5">LibriSpeech test-other when fine-tuned on LibriSpeech 10h.</cell></row><row><cell>Speech model</cell><cell cols="4">LM Text model F1 (%) label-F1 (%)</cell></row><row><cell>NLP Toplines:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>N/A (GT Text)</cell><cell cols="3">N/A DeBERTa-L 81.4</cell><cell>85.7</cell></row><row><cell>Pipeline approaches:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>W2V2-B-LS960</cell><cell cols="3">-DeBERTa-L 49.5</cell><cell>74.2</cell></row><row><cell>W2V2-L-LL60K</cell><cell cols="3">-DeBERTa-L 59.7</cell><cell>78.8</cell></row><row><cell>W2V2-B-LS960</cell><cell></cell><cell cols="2">DeBERTa-L 69.2</cell><cell>79.8</cell></row><row><cell>W2V2-L-LL60K</cell><cell></cell><cell cols="2">DeBERTa-L 71.8</cell><cell>82.2</cell></row><row><cell>E2E approaches:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>W2V2-B-LS960</cell><cell>-</cell><cell></cell><cell>49.6</cell><cell>64.0</cell></row><row><cell>W2V2-B-VP100K</cell><cell>-</cell><cell></cell><cell>47.9</cell><cell>60.8</cell></row><row><cell>HuBERT-B-LS960</cell><cell>-</cell><cell></cell><cell>49.8</cell><cell>62.9</cell></row><row><cell>W2V2-L-LL60K W2V2-B-LS960</cell><cell>-</cell><cell>N/A</cell><cell>50.5 63.4</cell><cell>64.9 71.7</cell></row><row><cell>W2V2-B-VP100K</cell><cell></cell><cell></cell><cell>61.8</cell><cell>69.8</cell></row><row><cell>HuBERT-B-LS960</cell><cell></cell><cell></cell><cell>61.9</cell><cell>70.3</cell></row><row><cell>W2V2-L-LL60K</cell><cell></cell><cell></cell><cell>64.8</cell><cell>73.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc>Named entity recognition performance on test set. Tab. 4 shows the ASR performance of baseline models. W2V2-L-LL60K performs the best (14.3% and 15.6% on VP and VC respectively) and W2V2-B-LS960 outperforms other base size models. Decoding with LM reduces the WER significantly (14.3% ? 10.4% and 15.6% ? 12.0%)</figDesc><table /><note>trigram models trained on the SLUE fine-tune set. Out-of-domain LMs are trigram models trained on the TED-LIUM 3 [44] LM cor- pus.5 Results.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 .</head><label>6</label><figDesc>Sentiment analysis performance on test set.</figDesc><table><row><cell>Speech model</cell><cell>LM</cell><cell>Text model</cell><cell cols="2">Recall (%) F1 (%)</cell></row><row><cell>NLP Toplines :</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>N/A (GT Text)</cell><cell cols="2">N/A DeBERTa-L</cell><cell>-</cell><cell>66.8</cell></row><row><cell>Pipeline approaches :</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>W2V2-B-LS960</cell><cell>-</cell><cell>DeBERTa-L</cell><cell>-</cell><cell>63.6</cell></row><row><cell>W2V2-L-LL60K</cell><cell>-</cell><cell>DeBERTa-L</cell><cell>-</cell><cell>65.7</cell></row><row><cell>W2V2-B-LS960</cell><cell></cell><cell>DeBERTa-L</cell><cell>-</cell><cell>65.4</cell></row><row><cell>W2V2-L-LL60K</cell><cell></cell><cell>DeBERTa-L</cell><cell>-</cell><cell>65.5</cell></row><row><cell>E2E approaches :</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>W2V2-B-LS960</cell><cell></cell><cell></cell><cell>-</cell><cell>48.6</cell></row><row><cell>W2V2-B-VP100K HuBERT-B-LS960</cell><cell>N/A</cell><cell>N/A</cell><cell>--</cell><cell>38.9 49.4</cell></row><row><cell>W2V2-L-LL60K</cell><cell></cell><cell></cell><cell>-</cell><cell>50.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 9 .Table 10 .</head><label>910</label><figDesc>C. SLUE-VoxCeleb Test set inter-pass analysis in addition to Sec. 3.2.2Fig. 2. Confusion matrix between Majority vote and heldout pass (4th pass) D. Detailed SLUE Benchmark v0.2 result on Dev set Performance of baseline models. *: used LM decoding for ASR and NER tasks.E. Detailed SLUE Benchmark v0.2 result on Test set in addition to Sec. 4.4 Performance of baseline models. *: used LM decoding for ASR and NER tasks.</figDesc><table><row><cell>Speech model</cell><cell cols="2">Model LM</cell><cell>Text</cell><cell>SLUE Score</cell><cell cols="2">ASR WER(%) VP VC</cell><cell cols="2">NER F1 (%) F1(%) SA VP VC</cell></row><row><cell>NLP Topline:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>N/A (GT text)</cell><cell></cell><cell>N/A</cell><cell>BERT-B DeBERTa-B DeBERTa-L</cell><cell>. . .</cell><cell>0.0 0.0 0.0</cell><cell>0.0 0.0 0.0</cell><cell>86.2 86.0 87.5</cell><cell>53.7 57.2 57.8</cell></row><row><cell>Pipeline:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>W2V2-B-LS960</cell><cell></cell><cell>-</cell><cell>BERT-B</cell><cell>62.1</cell><cell cols="2">17.5 17.5</cell><cell>52.0</cell><cell>51.9</cell></row><row><cell>W2V2-B-LS960</cell><cell></cell><cell>-</cell><cell>DeBERTa-B</cell><cell>61.7</cell><cell cols="2">17.5 17.5</cell><cell>49.9</cell><cell>52.6</cell></row><row><cell>W2V2-B-LS960</cell><cell></cell><cell>-</cell><cell>DeBERTa-L</cell><cell>64.4</cell><cell cols="2">17.5 17.5</cell><cell>55.2</cell><cell>55.7</cell></row><row><cell>W2V2-L-LL60K</cell><cell></cell><cell>-</cell><cell>DeBERTa-L</cell><cell>69.8</cell><cell cols="2">11.9 11.3</cell><cell>65.0</cell><cell>56.1</cell></row><row><cell>W2V2-B-LS960</cell><cell></cell><cell></cell><cell>BERT-B</cell><cell>71.6</cell><cell cols="2">12.0 13.3</cell><cell>73.0</cell><cell>54.4</cell></row><row><cell>W2V2-B-LS960</cell><cell></cell><cell></cell><cell>DeBERTa-B</cell><cell>70.2</cell><cell cols="2">12.0 13.3</cell><cell>72.0</cell><cell>51.3</cell></row><row><cell>W2V2-B-LS960</cell><cell></cell><cell></cell><cell>DeBERTa-L</cell><cell>72.0</cell><cell cols="2">12.0 13.3</cell><cell>73.8</cell><cell>54.9</cell></row><row><cell>W2V2-L-LL60K</cell><cell></cell><cell></cell><cell>DeBERTa-L</cell><cell>74.6</cell><cell>9.1</cell><cell>9.1</cell><cell>76.7</cell><cell>56.3</cell></row><row><cell>E2E:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>W2V2-B-LS960</cell><cell></cell><cell>-</cell><cell></cell><cell>60.3</cell><cell cols="2">17.5 17.5</cell><cell>55.0</cell><cell>43.3</cell></row><row><cell cols="2">W2V2-B-VP100K</cell><cell>-</cell><cell></cell><cell>55.0</cell><cell cols="2">21.9 30.5</cell><cell>53.2</cell><cell>38.0</cell></row><row><cell cols="2">HuBERT-B-LS960</cell><cell>-</cell><cell></cell><cell>60.2</cell><cell cols="2">18.6 20.0</cell><cell>54.5</cell><cell>44.0</cell></row><row><cell>W2V2-L-LL60K W2V2-B-LS960</cell><cell></cell><cell>-*</cell><cell>N/A</cell><cell>63.4 66.2</cell><cell cols="2">11.9 11.3 12.0 13.3</cell><cell>56.6 68.1</cell><cell>45.3 43.3</cell></row><row><cell cols="2">W2V2-B-VP100K</cell><cell>*</cell><cell></cell><cell>62.3</cell><cell cols="2">16.8 19.7</cell><cell>67.3</cell><cell>38.0</cell></row><row><cell cols="2">HuBERT-B-LS960</cell><cell>*</cell><cell></cell><cell>65.4</cell><cell cols="2">15.9 15.2</cell><cell>67.8</cell><cell>44.0</cell></row><row><cell>W2V2-L-LL60K</cell><cell></cell><cell>*</cell><cell></cell><cell>68.8</cell><cell>9.1</cell><cell>9.1</cell><cell>70.3</cell><cell>45.3</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/asappresearch/slue-toolkit 2 https://asappresearch.github.io/slue-toolkit/leaderboard.html arXiv:2111.10367v3 [cs.CL] 29 Jul 2022</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/facebookresearch/voxpopuli</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We found this LM to (slightly) outperform bigram and 4-gram models, as well as LMs trained on LibriSpeech.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">APPENDIX</head><p>A. Detailed NER label statistics in addition to Sec. <ref type="bibr" target="#b2">3</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An unsupervised autoregressive model for speech representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">A</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">N</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTER-SPEECH</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Learning problem-agnostic speech representations from multiple selfsupervised tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pascual</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ravanelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Serr?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bonafonte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SUPERB: Speech processing universal performance benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-I</forename><forename type="middle">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lakhotia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-T</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.13048</idno>
		<title level="m">ASR-GLUE: A New Multi-task Benchmark for ASR-Robust Natural Language Understanding</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BERT: Pretraining of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">RoBERTa: A robustly optimized BERT pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">DeBERTa: Decoding-enhanced BERT with Disentangled Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">wav2vec: Unsupervised pre-training for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Improving Transformer-based Speech Recognition Using Unsupervised Pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.09932</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep contextualized acoustic representations for semi-supervised speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salazar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">wav2vec 2.0: A framework for self-supervised learning of speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised Pre-Training of Bidirectional Speech Encoders via Masked Reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-Task Self-Supervised Learning for Robust Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ravanelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pascual</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Swietojanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Trmal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-N</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bolte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><forename type="middle">H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lakhotia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.07447</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.06870</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning speaker representations with mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ravanelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Augmentation adversarial training for self-supervised speaker recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Chung</surname></persName>
		</author>
		<editor>NeurIPS SAS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large-scale unsupervised pre-training for end-to-end spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Contrastive unsupervised learning for speech emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rozgic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Matsoukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Papayiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised learning approach to feature analysis for automatic speech emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Eskimez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heinzelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation Learning with Contrastive Predictive Coding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mockingjay: Unsupervised speech representation learning with deep bidirectional transformer encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Audio Albert: A Lite Bert for Self-Supervised Learning of Audio Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SLT</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Speech model pre-training for end-to-end spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lugosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ravanelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ignoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Tomar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Snips voice platform: an embedded spoken language understanding system for private-by-design voice interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bluche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caulier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doumouro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gisselbrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Caltagirone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lavril</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10190</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The ATIS spoken language systems pilot corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Hemphill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech and Natural Language</title>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The NXT-format Switchboard corpus: a rich resource for investigating the syntax, semantics, pragmatics and prosody of dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Calhoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carletta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Brenier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Beaver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Language resources and evaluation</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semisupervised spoken language understanding via self-supervised speech and language model pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">I</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">IEMOCAP: Interactive emotional dyadic motion capture database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Busso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bulut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Narayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Language resources and evaluation</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multimodal language analysis in the wild: CMU-MOSEI dataset and interpretable dynamic fusion graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanbriesen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A large scale speech sentiment corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martinez-Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abdelwahab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Busso</surname></persName>
		</author>
		<title level="m">The MSP-Conversation corpus.,&quot; in INTERSPEECH</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">End-to-end named entity recognition from English speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Shah</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Audio de-identification: A new entity recognition task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Beryozkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Szpektor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hartman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hassidim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A joint model for entity analysis: Coreference, typing, and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">End-To-End Named Entity and Semantic Concept Extraction from Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghannay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caubriere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Esteve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Camelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Simonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Morin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SLT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A Practical Guide to Sentiment Annotation: Challenges and Solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WASSA</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Speech Sentiment Analysis via Pre-Trained Features from End-to-End ASR Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riviere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Talnikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Haziza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dupoux</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00390</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">OntoNotes: the 90% solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">VoxCeleb: A large-scale speaker identification dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nagraniy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Chungy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">TED-LIUM 3: Twice as Much Data and Corpus Repartition for Experiments on Speaker Adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghannay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tomashenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Est?ve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Others</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
