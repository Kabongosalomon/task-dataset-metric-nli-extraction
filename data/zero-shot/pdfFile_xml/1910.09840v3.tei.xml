<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Best Practice in Explaining Neural Network Decisions with LRP</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-07-13">13 Jul 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Kohlbrenner</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Video Coding and Analytics</orgName>
								<orgName type="institution">Fraunhofer Heinrich Hertz Institute</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Bauer</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Technische Universit?t Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinichi</forename><surname>Nakajima</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Technische Universit?t Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Binder</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">ISTD Pillar</orgName>
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Video Coding and Analytics</orgName>
								<orgName type="institution">Fraunhofer Heinrich Hertz Institute</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Lapuschkin</surname></persName>
							<email>*wojciech.samek|sebastian.lapuschkin@hhi.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Video Coding and Analytics</orgName>
								<orgName type="institution">Fraunhofer Heinrich Hertz Institute</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Best Practice in Explaining Neural Network Decisions with LRP</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-07-13">13 Jul 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-layer-wise relevance propagation</term>
					<term>explainable artificial intelligence</term>
					<term>neural networks</term>
					<term>visual object recognition</term>
					<term>quantitative evaluation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Within the last decade, neural network based predictors have demonstrated impressive -and at times superhuman -capabilities. This performance is often paid for with an intransparent prediction process and thus has sparked numerous contributions in the novel field of explainable artificial intelligence (XAI). In this paper, we focus on a popular and widely used method of XAI, the Layer-wise Relevance Propagation (LRP). Since its initial proposition LRP has evolved as a method, and a best practice for applying the method has tacitly emerged, based however on humanly observed evidence alone. In this paper we investigate -and for the first time quantify -the effect of this current best practice on feedforward neural networks in a visual object detection setting. The results verify that the layerdependent approach to LRP applied in recent literature better represents the model's reasoning, and at the same time increases the object localization and class discriminativity of LRP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In recent years, deep neural networks (DNN) have become the state of the art method in many different fields, but are mainly applied as black-box predictors. Since understanding the decisions of artificial intelligence systems is crucial in numerous scenarios and partially demanded by law 1 , neural network interpretability has been established as an important and active research area. Consequently, many approaches to explaining neural network decisions have been proposed in recent years, e.g. <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b5">[6]</ref>. The Layer-wise Relevance Propagation (LRP) <ref type="bibr" target="#b6">[7]</ref> framework has proven successful at providing a meaningful intuition and measurable quantities describing a network's feature processing and decision making <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref>. LRP attributes relevance scores R i to the model inputs or intermediate neurons i by decomposing a model output of interest. The method follows the principles of relevance conservation and proportional decomposition. Therefore, attribu-This work was partly supported by the German Ministry for Education and Research as BIFOLD (refs. 01IS18025A and 01IS18037A) and TraMeExCo (ref. 01IS18056A). A. Binder is grateful for the support by the Ministry of Education of Singapore (MoE) Tier 2 grant MOE2016-T2-2-154. This publication only reflects the authors views. Funding agencies are not liable for any use that may be made of the information contained herein. <ref type="bibr" target="#b0">1</ref> e.g. via the "right to explanation" proclaimed in the General Data Protection Regulation of the European Union <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> tions computed with LRP maintain a strong connection to the predictor output. While early applications of LRP administer a single decomposition rule uniformly to all layers of a model <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, more recent work describes a trend towards assigning specific decomposition rules purposedly to layers wrt. function and position within the network <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b15">[16]</ref>. This trend has tacitly emerged and formulates a best practice for applying LRP. Under qualitative evaluation, the attribution maps resulting from this current approach seem to be more robust against the well-known effects of shattered gradients <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b16">[17]</ref> and demonstrate an increased discriminativity between different target classes <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref> compared to the uniform application of a single rule.</p><p>However, recent literature applying LRP-rules in a layerdependent manner do not justify the beneficial effects of this novel variant quantitatively, but only based on human observation. In this paper, we design and conduct a series of experiments in order to verify whether a layer-specific application of different decomposition rules actually constitutes an improvement above earlier descriptions and applications of LRP <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b17">[18]</ref>. That is, we measure and compare capabilities of various methods from explainable AI -with a focus on earlier and more recent approaches to LRP -to precisely localize the ground-truth objects in images via attribution of relevance scores. Our experiments are conducted on popular computer vision data sets with ground truth object localizations, the ImageNet <ref type="bibr" target="#b18">[19]</ref> and PascalVOC <ref type="bibr" target="#b19">[20]</ref> datasets, using different neural network models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. FEEDFORWARD NEURAL NETWORKS AND LRP</head><p>Feedforward neural networks constitute a popular architecture type, ranging from simple multi-layer perceptrons and shallower convolutional architectures such as the LeNet-5 <ref type="bibr" target="#b20">[21]</ref> to deeper and more complex Inception <ref type="bibr" target="#b21">[22]</ref> and VGG-like architectures <ref type="bibr" target="#b22">[23]</ref>. These types of neural network commonly use ReLU non-linearities and first pass information through a stack of convolution and pooling layers, followed by several fully connected layers. The good performance of feedforward architectures in numerous problem domains, and the availability as pre-trained models makes them a valuable standard architecture in neural network design. conv <ref type="figure">Fig. 1</ref>. Different attributions for the output classes "Tiger Cat" and "Bernese Mountain Dog" using the VGG-16 model. Network output strengths (logit) of the respective classes is given in parentheses. Network-widely applied rules in (a) -(d) (LRPz, LRP ?? , Guided Backprop and Pattern Attribution respectively), are not, or hardly class discriminative. An application of LRPz to every layer shows the effect of gradient shattering. Variants of LRP CM P implementing a composite strategy of LRP rule application shown in (e) -(g) -here, from left to right, the LRP ? -rule is not applied at all, the three lowest convolution layers, and all convolution and pooling layers -are sensitive to class-specific information and highlight features on different levels of scale and conceptuality (e.g. highlighting the fur pattern activating "Tiger Cat" vs highlighting the general region showing a "Tiger Cat"). Attributions from LRP CM P visualized in red/warm colors identify image regions contributing to the prediction of the target class, while regions marked in blue/cold hues provide contradictory evidence. Further examples can be found in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Layer-wise Relevance Propagation</head><p>Consequently, feedforward networks have been subject to investigations in countless contributions towards neural network interpretability, including applications of LRP <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b17">[18]</ref>, which finds its mathematical foundation in Deep Taylor Decomposition (DTD) <ref type="bibr" target="#b23">[24]</ref>.</p><p>The most basic attribution rule of LRP (to which we will refer to as LRP z ) is defined as</p><formula xml:id="formula_0">R (l) i = j z ij z j R (l+1) j<label>(1)</label></formula><p>and performs a proportional decomposition of a given upper layer relevance value R (l+1) j at some layer (l + 1) and neuron j to obtain lower layer relevance scores R (l) i for neurons i at layer (l), wrt. to the localized preactivations z ij and their respective aggregations z j at the layer output. Here, the localized preactivations z ij describe quantities propagated through the model during prediction time, e.g. z ij = x i w ij and z j = i z ij within a neural network layer with learned weight parameters w ij . Note that Eq. (1) is conservative between layers and in general maintains an equality i R (l) i = f (x) at any layer (l) of the model.</p><p>Further purposed LRP-rules beyond Eq. (1) are introduced in <ref type="bibr" target="#b6">[7]</ref>, which can be understood as advancements thereof:</p><p>So does the LRP ? decomposition rule <ref type="bibr" target="#b6">[7]</ref> add a signed and small constant ? to the denominator in order to prevent divisions by zero and to diminish the effect of recessive (e.g. weak and noisy) mappings z ij to the relevance decomposition.</p><formula xml:id="formula_1">R (l) i = j z ij z j + ? ? sign(z j ) R (l+1) j<label>(2)</label></formula><p>The LRP ?? -rule <ref type="bibr" target="#b6">[7]</ref> performs and then merges separate decompositions for the activatory (z + ij ) and inhibitory (z ? ij ) parts of the forward pass</p><formula xml:id="formula_2">R (l) i = j ? z + ij z + j + ? z ? ij z ? j R (l+1) j<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">z + ij = z ij ; z ij &gt; 0 0 ; else z ? ij = 0 ; else z ij ; z ij &lt; 0<label>(4)</label></formula><p>Here, the non-negative ? parameter permits a weighting of relevance distribution towards activations and inhibitions. The ? parameter is given implicitly s.t. ?+? = 1 in order to uphold conservativity of relevance between layers. The commonly used parameter ? = 1 can be derived from DTD and has been rediscovered in ExcitationBackprop <ref type="bibr" target="#b24">[25]</ref>. Later work <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b25">[26]</ref> introduces LRP ? 2 , a decomposition rule which spreads the relevance of a neuron uniformly across all its inputs. This rule assumes z ij = 1 and z j = i 1 in Eq. (1) only for backpropagating given relevance scores R (l+1) j to lower layers (l), and has seen application in the input layer(s) of neural networks. The LRP ? -rule provides invariance to the decomposition process wrt. to translations in the input domain and effectively propagates relevance scores of higher layer neurons -encoding "explanations" of more abstract concepts -towards the input via the neurons' receptive fields, without further transformation. Note that the LRP ? decomposition rule is thus unsuitable for decomposing fully connected layers.</p><p>Earlier applications of LRP (e.g. <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>) did use one single decomposition rule uniformly over the whole network, which often resulted in suboptimal "explanations" of model behavior <ref type="bibr" target="#b12">[13]</ref>. So are network-wide applications of LRP z (in the following denoted as LRP z , in order to distinguish this specific configuration of LRP from the rule LRP z ) and networkwide applications of LRP ? (denoted as LRP ? ) respectively identical and highly similar to Gradient?Input (G?I) in ReLU-activated DNNs <ref type="bibr" target="#b11">[12]</ref>. LRP z and LRP ? demonstrate -albeit working well for shallower convolutional models <ref type="bibr" target="#b27">[27]</ref>, <ref type="bibr" target="#b28">[28]</ref> such as the LeNet-5 <ref type="bibr" target="#b20">[21]</ref> or simpler fullyconnected networks <ref type="bibr" target="#b29">[29]</ref> -the effect of gradient shattering as overly complex attributions for deeper models <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> (cf. <ref type="figure">Fig. 1(a)</ref>). A Network-wide application of LRP ?? (denoted as LRP ?? ) demonstrates robustness against gradient shattering and produces visually pleasing attribution maps, however is lacking in class-or object discriminativity <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b30">[30]</ref>. By separately considering activatory and inhibitory mappings z ij during the decomposition process, LRP ?? tends to attribute relevance to similar sets of input features activating sequences of neurons throughout the network, regardless of the output class chosen for relevance decomposition (cf. <ref type="figure">Fig. 1(b)</ref>). Further, LRP ?? introduces the constraint of strictly positive layer activations <ref type="bibr" target="#b23">[24]</ref>, which is in general not guaranteed, especially at the (logit) output of a model. A dissatisfaction of this constraint may result in a sign inversion of all backpropagated relevance scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. A Current Best Practice for LRP</head><p>A recent trend among XAI researchers and practitioners employing LRP is the use of a composite strategy of rule applications for decomposing the prediction of a neural network <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b15">[16]</ref>. That is, different parts of the DNN are decomposed using purposed rules, which in combination are robust against gradient shattering while sustaining object discriminativity. Common among these works is the utilization of LRP ? with ? ? 1 (or just LRP z ) to decompose fully connected layers close to the model output, followed by an application of LRP ?? to the underlying convolutional layers (usually with ? ? {1, 2}). Here, the separate decomposition of the positive and negative forward mappings complements the localized feature activation of convolutional filters activated by, and feeding into ReLUs. A final decomposition step within the convolution layers near the input uses the LRP ? -rule. Most commonly this rule (or alternatively the DTD z B -rule defined in context of Deep Taylor Decompositon <ref type="bibr" target="#b23">[24]</ref>) is applied to the input layer only. In summary, we here describe this pattern of rule application as LRP CMP (for CoMPosite). <ref type="figure">Fig. 1</ref> provides a qualitative overview of the effect of LRP CMP in contrast to other parameterizations and methods, which we will further discuss in Sec. IV-B. Note that the option to apply the LRP ? decomposition to the first n layers near the input (instead of only the first one layer) provides control over the local and semantic scale <ref type="bibr" target="#b25">[26]</ref> of the computed attributions (see <ref type="figure">Fig. 1</ref>(e)-(g)). Previous works profit from this option for comparing DNNs of varying depth, and differently configured convolutional stacks <ref type="bibr" target="#b13">[14]</ref>, or by increasing readability of attributions maps aligned to the requirements of human investigators <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METRIC AND ASSUMPTIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motivation</head><p>The declared purpose of LRP is to precisely and quantitatively inform about the (image or intermediate) features which contribute towards or against the decision of a model wrt. to a specific predictor output <ref type="bibr" target="#b6">[7]</ref>. While the recent LRP CMP exhibits improved properties above previous variants of LRP by eyeballing, an objective verification requires quantification. The visual object detection setting, as it is described by the Pascal VOC (PVOC) <ref type="bibr" target="#b19">[20]</ref> or ImageNet <ref type="bibr" target="#b31">[31]</ref> datasets -both of which include object bounding box annotations -delivers an optimal experimental setting for this purpose.</p><p>An assumed ideal model would, in such a setting, exhibit true object understanding by only predicting based on the object itself. A good and representative attribution method should therefore reflect that object understanding of the model closely i.e. by marking (parts of) the shown object as relevant and disregarding visual features not representing the object itself. Similar to <ref type="bibr" target="#b10">[11]</ref>, we therefore rely on a measure based on localization of attribution scores. In the following, we will evaluate LRP CMP against other methods and variants of LRP on ImageNet using a pre-trained VGG-16 network, and on PVOC 2007 using a pre-trained (on PVOC 2012) CaffeNet model <ref type="bibr" target="#b10">[11]</ref>. Both models perform well on their respective task and have been obtained from https://modelzoo.co/ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Verifying Object-centricity During Prediction</head><p>In practice, both datasets can not be assumed to be free from contextual biases (cf. <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b32">[32]</ref>), and in both settings models are trained to categorize images rather than localize objects. Still, we (necessarily) assume that the models we use dominantly base their decision on the target object, as opposed to the image context.</p><p>We verify our hypothesis in <ref type="figure" target="#fig_0">Fig. 2, by</ref> showing for both models and datasets the reaction of the corresponding predictor f to the occlusion of the object area vs. the occlusion of the image background. That is, for each image x of the respective dataset, we leverage the available bounding box annotations and compute partially occluded versions x ? where either the object area or class-specific image background (i.e. the non-object area) are replaced with mean color values per corresponding pixel and dataset. We then measure the ?f (x) = f (x ? ) ? f (x) for the ground truth label(s) of x based on the network's logit outputs, and plot this value as a function of relative bounding box size. <ref type="figure" target="#fig_0">Fig. 2</ref> shows the average values and standard deviation for ?f (x) per bounding box size (discretized into 100 uniform bins) when replacing either the object (area within the bounding box) or the context (rest of the image).</p><p>Occluding the object area consistently leads to a sharper decrease in the output for the specific class. The trend is especially evident for smaller objects. This supports our claim that the networks base their decision mainly on the object itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Attribution Localization as a Quantitative Measure</head><p>This gives us a performance criterion for attribution methods in object detection and classification. In order to track the fraction of the total amount of relevance that is attributed to the object, we use the inside-total relevance ratio ? without, and a weighted variant ? w within consideration of the object size:</p><formula xml:id="formula_4">? = R in R tot ? w = ? ? S tot S in<label>(5)</label></formula><p>While conceptually similar to the inside-outside ratio used in <ref type="bibr" target="#b10">[11]</ref>, ? and ? w avoid numerical issues in edge cases wrt. bounding box size. Here, R in is the sum of positive relevance in the bounding box, R tot the total sum of positive relevance in the image and S in and S tot are the size of the bounding box and the image respectively, in pixels. The subscript w signals the addition of a normalization factor in ? w considering the size of image and object. Correctly locating small objects is more difficult than locating image-sized objects. Since the ratio S tot /S in is always greater than or equal to 1 and increases for smaller objects, ? w puts additional emphasis on measuring the outcome for small bounding box sizes. In both cases, higher values indicate larger fractions of relevance attributed to the object area (and not background), and therefore are the desirable outcome.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Setup</head><p>We perform our experiments on both the ImageNet and the PVOC 2007 datasets, since both collections provide large numbers of ground truth object bounding boxes.</p><p>For PVOC, we compute attribution maps for all samples (approx. 10.000) from PVOC 2007, using a model which has been pre-trained on the multi label setting of PVOC 2012 <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b19">[20]</ref>. The respective model performs with a mean AP of 72.12 on PVOC 2007. Since PVOC describes a multi label setting, multiple classes can be present in the same image. We therefore evaluate ? and ? w once for each unique existing pair of { class ? sample }, yielding approximately 15.000 measurements. Images with a higher number of (smaller) bounding boxes thus effectively have a stronger impact on the results than images with larger (and fewer), image-filling objects, while at the same time describing a more difficult setting. Many of the objects shown in PVOC images are not centered. In order to use all available object information in our evaluation, we rescale the input images to the network's desired input shape, avoiding the (partial) cropping of objects.</p><p>On ImageNet <ref type="bibr" target="#b18">[19]</ref> (2012 version), bounding box information does only exist for the 50.000 validation samples (displaying one class per image) and can be downloaded from the official website 3 . We evaluate a pre-trained VGG-16 model from the keras model zoo, obtained via the iNNvestigate <ref type="bibr" target="#b33">[33]</ref> toolbox. The model performs with a 90.1% top-5 accuracy on the ImageNet test set. For all images the shortest side is rescaled to fit the model input and the longest side is center-cropped to obtain a quadratic input shape. Bounding box information is adjusted correspondingly.</p><p>For computing attribution maps, we make use of existing XAI software packages, depending on the models' formats. That is, for the VGG-16 model we use the Keras <ref type="bibr" target="#b34">[34]</ref> and Tensorflow <ref type="bibr" target="#b35">[35]</ref> based iNNvestigate <ref type="bibr" target="#b33">[33]</ref> toolbox. For the PVOC data and the CaffeNet architecture, we compute attributions using the Caffe <ref type="bibr" target="#b36">[36]</ref> based LRP Toolbox <ref type="bibr" target="#b27">[27]</ref>.</p><p>Both XAI packages support the same functionality regarding LRP, yet differ in the provided selection of other attribution methods. Our study, however, shall be focussed on the beneficial or detrimental effects between the variants of LRP used in literature.</p><p>We compute attribution maps and values for ? and ? w for both models and different variants of LRP: LRP z , LRP ?? (both for ? = 1 and ? = 2), and several parameterizations of LRP CMP . For the latter we distinguish parameter choices for ? in a subscript when discussing quantitative results in Sec. IV-C. Additionally, in case LRP ? is applied to the input layer, we add "+?" to the subscript, e.g. as "LRP CMP :?1+? ".</p><p>We complement the results with Guided Backprop (GB) <ref type="bibr" target="#b2">[3]</ref> and for ImageNet with Pattern Attribution (PA) <ref type="bibr" target="#b3">[4]</ref> only available in iNNvestigate. On both datasets, we evaluate attributions for the ground truth class labels, independent of the network prediction. <ref type="figure">Fig. 1</ref> exemplarily shows attribution maps computed with different methods based on the VGG-16 model, for two object classes present in the ImageNet labels and the input image; "Bernese Mountain Dog" and "Tiger Cat". Attributions in Figs. 1(a)-(d) result from uniform rule application to the whole network. Next to applications of LRP z and LRP ?? with ? = 1, this includes Guided Backprop <ref type="bibr" target="#b2">[3]</ref> and Pattern Attribution <ref type="bibr" target="#b3">[4]</ref>. Neither of these maps demonstrate class-discriminativeness and prominently attribute scores to the same areas, regardless of the target class chosen for attribution. LRP z additionally shows the effects of gradient shattering in a highly complex attribution structure due to its equivalence to G?I. Such attributions would be difficult to use and juxtapose in further algorithmic or manual analyses of model behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Qualitative Observations</head><p>To the right, attribution maps in Figs. 1(e)-(g) correspond to variants of LRP CMP , which apply different decomposition rules depending on layer type and position. In <ref type="figure">Fig. 1(e)</ref>, the LRP ? -rule is not applied at all, while in <ref type="figure">Fig. 1(f)</ref> it is used for the first three convolutional layers, and the whole convolutional stack -including pooling layers -in <ref type="figure">Fig. 1(g)</ref>. Both heatmaps in <ref type="figure">Fig. 1(e</ref>  <ref type="figure">Fig. 1(b)</ref> vs. <ref type="figure">Fig. 1(g)</ref>), while an application in lower layers avoids issues related to gradient shattering, as shown in <ref type="figure">Figs. 1(e</ref>)-(f) compared to <ref type="figure">Fig. 1(a)</ref>.</p><p>Note that the special case shown in <ref type="figure">Fig. 1(g)</ref> is highly similar to an application of the Class Activation Mapping (CAM) <ref type="bibr" target="#b37">[37]</ref> method in the fully connected part of the model, however replaces the upsampling over the model's convolutional stack of the CAM approach with the LRP ? decomposition based approach of the LRP framework, and is thus naturally capable of distributing negative relevance scores.</p><p>Note that the VGG-16 network used here never has been trained in a multi-label setting. Despite only receiving one object category per input sample, it has learned to distinguish between different object types shown in the same image, e.g. that a dog is not a cat. This in turn reflects well in the attribution maps computed after the LRP CMP pattern.</p><p>Further examples akin to <ref type="figure">Fig. 1</ref> are given in the Appendix. <ref type="figure" target="#fig_1">Figs. 3(a) and (b)</ref> show the average in-total ratio ? as a function of bounding box size, discretized over 100 equally spaced intervals, for PVOC 2007 and ImageNet. Averages for ? and ? w over the whole (and partial) datasets can be found in Tab. I. Large values indicate more precise attribution to the relevant object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Quantitative Results</head><p>The inside-total relevance ratio highly depends on the size of the bounding box. In addition to the average ? and ? w as an aggregate over all classes and images, we also report ? ?0.25 and ? ?0.5 , the average values over all objects whose bounding box does not span more than 0.25 and 0.5 times the area of the whole image respectively. The assumed Baseline is the uniform attribution of relevance over the whole image, which is outperformed by all methods. LRP z performs noticeably worse on ImageNet than on PVOC, which we trace back to the significant difference in model depth (13 vs 21 layers) affecting gradient shattering. We omit LRP ? in Tab. I due to the identity in results to LRP z . LRP ?? has the tendency to attribute to all shown objects (via generally neuron-activating features) and suffers from the multiple object classes per image in PVOC, where ImageNet shows only one class. Also, the similarity of attributions between PA and LRP ?? with ? = 1 observed in <ref type="figure">Fig. 1</ref> seem consistent on ImageNet and result in close measurements in Tab. I.</p><p>Tab. I demonstrates that LRP CMP clearly outperforms other methods consistently on large datasets. That is, the increased precision in attribution to relevant objects is especially evident in the presence of smaller bounding boxes in ? w . This can also be seen in ? ?0. <ref type="bibr" target="#b24">25</ref> and ? ?0.5 in Tab. I and the left parts of <ref type="figure" target="#fig_1">Figs. 3(a) and (b)</ref>, where a majority of the image shows contextual information or other classes. Once bounding boxes become (significantly) larger and cover over 50% of the image, all methods converge towards perfect performance, as expected. In both settings, LRP CMP :?2+? yields the best results, while overall the composite strategy is more effectful than a fine tuning of decomposition rule parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Conclusion</head><p>In this study, we discuss a recent development in the application of Layer-wise Relevance Propagation. We summarize this emerging strategy of a composite application of multiple purposed decomposition rules as LRP CMP and juxtapose its effects to previous approaches to LRP and other methods, which uniformly apply a single decomposition rule to all layers of the model. For the first time, our results show that LRP CMP does not only yield measurably more representative attribution maps, but also provides a solution against gradient shattering affecting previous approaches, and improves properties related to object localization and class discrimination via attribution. Moreover, LRP CMP is able to precisely attribute negative relevance scores to class-contradicting features while requiring only one modified backward pass though the model, using established tools from the LRP framework. The discussed beneficial effects are demonstrated qualitatively and verified quantitatively at hand of two large and widely used computer vision datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>In <ref type="figure">Fig. 4</ref> we provide further illustrative examples similar to <ref type="figure">Fig. 1, using</ref>   <ref type="figure">Fig. 4</ref>. Different attributions for the output classes "Bernese Mountain Dog" and "French Bulldog" (A), "Persian Cat" and "Siamese Cat" (B), "Zebra" and "African Elephant" (C) and "Sunglasses" and "Windsor Tie" (D and E), using the pretrained VGG-16 model. For details cf. <ref type="figure">Fig. 1</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Mean prediction changes ?f (x) measured in the logit outputs of the true class as a function of the occluded area, when occluding the pixels within (object) and without (image context) the class-specific bounding boxes on PVOC 2007 (left) and ImageNet (right). Lower values indicate a stronger reaction of the model. Shaded areas show the standard deviation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Average in-total ratio ? as a function of bounding box size. Vertical lines mark thresholds of 25% and 50% covered image area. The baseline can be reached by uniformly attributing to all pixels of the image. Higher values are better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>) and Fig. 1(f) use ? = 1. Here altogether, the visualized attribution maps correspond more to an "intuitive expectation" of how relevance should be attributed compared to Figs. 1(a)-(d), assuming a model predicts based on object understanding. Figs. 1(e)-(g) demonstrate the change in scale and semantic, from attributions to local features to a very coarse localization map, with changing placements of the LRP ? -rule. Further, it becomes clear that with an application of the LRP ?? -rule in upper layers, object localization is lost (see</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I AVERAGE</head><label>I</label><figDesc>CONTEXT ATTRIBUTION METRICS FOR DIFFERENT ANALYZERS AND DATASETS. ROW ORDER IS DETERMINED BY ?w . HIGHER ? * ARE BETTER.</figDesc><table><row><cell cols="2">Data</cell><cell>Analyzer</cell><cell>?w</cell><cell>? ?0.25</cell><cell>? ?0.5</cell><cell>?</cell></row><row><cell></cell><cell></cell><cell>LRP CM P :?2+?</cell><cell>2.716</cell><cell>0.307</cell><cell>0.421</cell><cell>0.532</cell></row><row><cell></cell><cell></cell><cell>LRP CM P :?1</cell><cell>2.664</cell><cell>0.306</cell><cell>0.426</cell><cell>0.539</cell></row><row><cell>PVOC</cell><cell>(CaffeNet)</cell><cell>LRP CM P :?1+? LRP CM P :?2 LRPz GB LRP ?2</cell><cell>2.598 2.475 2.128 1.943 1.843</cell><cell>0.301 0.276 0.236 0.212 0.205</cell><cell>0.421 0.388 0.353 0.335 0.320</cell><cell>0.535 0.504 0.480 0.470 0.452</cell></row><row><cell></cell><cell></cell><cell>LRP ?1</cell><cell>1.486</cell><cell>0.163</cell><cell>0.273</cell><cell>0.403</cell></row><row><cell></cell><cell></cell><cell>Baseline</cell><cell>1.000</cell><cell>0.100</cell><cell>0.186</cell><cell>0.322</cell></row><row><cell></cell><cell></cell><cell>LRP CM P :?2+?</cell><cell>1.902</cell><cell>0.397</cell><cell>0.534</cell><cell>0.714</cell></row><row><cell></cell><cell></cell><cell>LRP CM P :?2</cell><cell>1.797</cell><cell>0.368</cell><cell>0.505</cell><cell>0.693</cell></row><row><cell></cell><cell></cell><cell>LRP CM P :?1</cell><cell>1.7044</cell><cell>0.3467</cell><cell>0.4887</cell><cell>0.6898</cell></row><row><cell>ImageNet</cell><cell>(VGG-16)</cell><cell>LRP CM P :?1+? LRP ?2 GB LRP ?1</cell><cell>1.7043 1.702 1.640 1.609</cell><cell>0.3466 0.332 0.312 0.306</cell><cell>0.4886 0.496 0.485 0.475</cell><cell>0.6898 0.706 0.710 0.699</cell></row><row><cell></cell><cell></cell><cell>PA</cell><cell>1.591</cell><cell>0.303</cell><cell>0.471</cell><cell>0.698</cell></row><row><cell></cell><cell></cell><cell>LRPz</cell><cell>1.347</cell><cell>0.236</cell><cell>0.389</cell><cell>0.632</cell></row><row><cell></cell><cell></cell><cell>Baseline</cell><cell>1.000</cell><cell>0.128</cell><cell>0.260</cell><cell>0.547</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>different input images and object classes.</figDesc><table><row><cell>(A)</cell><cell>Bernese Mountain</cell><cell>Dog (10.42)</cell><cell>conv</cell></row><row><cell></cell><cell>French Bulldog</cell><cell>(2.47)</cell><cell></cell></row><row><cell>(B)</cell><cell></cell><cell></cell><cell>conv</cell></row><row><cell></cell><cell>Persian Cat</cell><cell>(11.12)</cell><cell></cell></row><row><cell></cell><cell>Siamese Cat</cell><cell>(19.28)</cell><cell></cell></row><row><cell>(C)</cell><cell></cell><cell></cell><cell>conv</cell></row><row><cell></cell><cell>Zebra</cell><cell>(16.87)</cell><cell></cell></row><row><cell></cell><cell>African Elephant</cell><cell>(16.28)</cell><cell></cell></row><row><cell>(D)</cell><cell></cell><cell></cell><cell>conv</cell></row><row><cell></cell><cell>Sunglasses</cell><cell>(7.54)</cell><cell></cell></row><row><cell></cell><cell>Windsor Tie</cell><cell>(9.92)</cell><cell></cell></row><row><cell>(E)</cell><cell></cell><cell></cell><cell>conv</cell></row><row><cell></cell><cell>Sunglasses</cell><cell>(8.87)</cell><cell></cell></row><row><cell></cell><cell>Windsor Tie</cell><cell>(10.26)</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">read: ? ="flat", as in the musical ?.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://www.image-net.org/challenges/LSVRC/2012</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Parliament and Council of the European Union</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>General data protection regulation</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">European Union regulations on algorithmic decision-making and a &quot;right to explanation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Flaxman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="50" to="57" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Striving for simplicity: The all convolutional net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Learning Representations (ICLR)</title>
		<meeting>of International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning how to explain neural networks: Patternnet and patternattribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-J</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Sch?tt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>D?hne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Learning Representations (ICLR)</title>
		<meeting>of International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Axiomatic attribution for deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Taly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Machine Learning (ICML)</title>
		<meeting>of International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3319" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Smoothgrad: removing noise by adding noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Smilkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Vi?gas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<idno>abs/1706.03825</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Klauschen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">130140</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Explaining therapy predictions with layer-wise relevance propagation in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wunderle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Fasching</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE International Conference on Healthcare Informatics (ICHI)</title>
		<meeting>of IEEE International Conference on Healthcare Informatics (ICHI)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="152" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Analyzing neuroimaging data through recurrent deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A W</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>R Heekeren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">1321</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unmasking clever hans predictors and assessing what machines really learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>W?ldchen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1096</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Analyzing classifiers: Fisher vectors and deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2912" to="2920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Gradient-based attribution methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ancona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ceolini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>?ztireli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Explainable AI: Interpreting, Explaining and Visualizing Deep Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="169" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Layer-wise relevance propagation: an overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Explainable AI: Interpreting, Explaining and Visualizing Deep Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="193" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Understanding and comparing deep neural networks for age and gender classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE International Conference on Computer Vision Workshops</title>
		<meeting>of IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<publisher>ICCVW</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1629" to="1638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Resolving challenges in deep learning-based analyses of histopathological images using explanation methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>H?gele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seegerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bockmayr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Klauschen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="1908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Batchnorm decomposition for deep neural network interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Y W</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Work-Conference on Artificial Neural Networks (IWANN)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="280" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The shattered gradients problem: If resnets are the answer, then what is the question?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Frean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W D</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcwilliams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Machine Learning</title>
		<meeting>of International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="342" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluating the visualization of what a deep neural network has learned</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Network Learning Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2660" to="2673" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ma</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE</title>
		<meeting>of the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Explaining nonlinear classification decisions with deep taylor decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="211" to="222" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Topdown neural attention by excitation backprop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Bargal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1084" to="1102" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Controlling explanatory heatmap resolution and semantics via decomposition depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE International Conference on Image Processing (ICIP)</title>
		<meeting>of IEEE International Conference on Image essing (ICIP)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="2271" to="2275" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The LRP toolbox for artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="114" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Explaining the unique nature of individual gait patterns with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Horst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">I</forename><surname>Sch?llhorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">2391</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interpretable deep neural networks for single-trial eeg classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience Methods</title>
		<imprint>
			<biblScope unit="volume">274</biblScope>
			<biblScope unit="page" from="141" to="145" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Understanding individual decisions of cnns via contrastive backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Asian Conference on Computer Vision (ACCV)</title>
		<meeting>of Asian Conference on Computer Vision (ACCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="119" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting>of Advances in Neural Information essing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Analyzing imagenet with spectral relevance analysis: Towards imagenet un-hans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Anders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Marin?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="1912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seegerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>H?gele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Sch?tt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>D?hne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-J</forename><surname>Kindermans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="93" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>innvestigate neural networks!</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Keras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<idno>abs/1603.04467</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 22nd ACM international conference on Multimedia</title>
		<meeting>of 22nd ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2921" to="2929" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
