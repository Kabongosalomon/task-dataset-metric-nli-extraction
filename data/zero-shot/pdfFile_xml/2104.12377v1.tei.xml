<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DADgraph: A Discourse-aware Dialogue Graph Neural Network for Multiparty Dialogue Machine Reading Comprehension</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Li</surname></persName>
							<email>jqli@ir.hit.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liu</surname></persName>
							<email>mliu@ir.hit.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihao</forename><surname>Zheng</surname></persName>
							<email>zhzheng@ir.hit.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Zhang</surname></persName>
							<email>hzhang@ir.hit.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
							<email>qinb@ir.hit.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
							<email>tliu@ir.hit.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">National University of Singapore Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DADgraph: A Discourse-aware Dialogue Graph Neural Network for Multiparty Dialogue Machine Reading Comprehension</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Machine reading comprehension</term>
					<term>multiparty dialogue</term>
					<term>discourse structure</term>
					<term>graph neural network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multiparty Dialogue Machine Reading Comprehension (MRC) differs from traditional MRC as models must handle the complex dialogue discourse structure, previously unconsidered in traditional MRC. To fully exploit such discourse structure in multiparty dialogue, we present a discourse-aware dialogue graph neural network, DADgraph, which explicitly constructs the dialogue graph using discourse dependency links and discourse relations. To validate our model, we perform experiments on the Molweni corpus, a large-scale MRC dataset built over multiparty dialogue annotated with discourse structure. Experiments on Molweni show that our discourse-aware model achieves statistically significant improvements compared against strong neural network MRC baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Research into multiparty dialogue has grown rapidly given the growing ubiquity of dialogue agents <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b7">[7]</ref>. The machineaided comprehension of such dialogue, in the form of multiparty dialogue machine reading comprehension (MRC), has subsequently begun to attract research <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[8]</ref>, <ref type="bibr" target="#b9">[9]</ref>.</p><p>Work on general machine reading comprehension is flourishing. Most existing datasets for general machine reading comprehension adopt well-written prose passages and historical questions as inputs <ref type="bibr" target="#b10">[10]</ref>- <ref type="bibr" target="#b14">[14]</ref>. In inputs for such general MRC, a passage is a continuous text where there is a discourse relation between every pair of adjacent sentences. Therefore, we can regard each paragraph in a passage as a linearly structured discourse. In contrast, MRC for multiparty dialogue must consider the more complex, graphical nature of discourse structure: coherence between adjacent utterances is not a given; there may be no discourse relation between adjacent utterances. The discourse structure in such multiparty dialogues can be regarded as a dependency graph, where nodes are utterances.</p><p>Corresponding author. <ref type="figure" target="#fig_1">Figure 1</ref> shows a multiparty dialogue example and its discourse structure from the Molweni dataset ( ? V), where four speakers converse over seven utterances. The annotators of Molweni have contributed three questions ( <ref type="figure" target="#fig_1">Fig. 1, b)</ref>: two answerable ones (Q1 and Q2) and one unanswerable one (Q3). They also have hand-annotated the discourse structure ( <ref type="figure" target="#fig_1">Fig. 1, c)</ref>, where nodes and edges represent utterances and their associated discourse relations, respectively. We observe that adjacent utterance pairs can be incoherent, illustrating the key challenge. It is non-trivial to detect discourse relations, especially between non-adjacent utterances; and crucially, difficult to correctly interpret a multiparty dialogue without a proper understanding of the input's complex structure.</p><p>Hypothesis: Discourse structure informs multiparty dialogue MRC performance in modeling long-term dependencies.</p><p>Discourse structure has been successfully applied to question answering and machine reading comprehension <ref type="bibr" target="#b15">[15]</ref>- <ref type="bibr" target="#b19">[19]</ref>. To the best of our knowledge, there is no prior work introducing discourse structure to multiparty dialogue MRC; i.e., all works on dialogue MRC do not consider the characteristic properties of multiparty dialogue.</p><p>To utilize the discourse structure of multiparty dialogues, we propose DADgraph, a Discourse-Aware Dialogue graph convolutional network consisting of three key components. The first component is sequential context encoding which aims to learn the sequence structure of utterances. The second component is dialogue graph modeling. To effectively model multiparty dialogue discourse structure, we adopt graph neural networks. The third component is the MRC module. After processing the input through two different dialogue encoders, we feed the resultant dialogue representations to the MRC module to find the answer span. In contrast to the basic DialogueGCN <ref type="bibr" target="#b20">[20]</ref> which uses a windowed context, our model Ack.  represents the dialogue graph using discourse dependency links and discourse relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q-Elab</head><p>To the best of our knowledge, the are two dialogue MRC datasets, including the FriendsQA <ref type="bibr" target="#b9">[9]</ref> dataset and the Molweni dataset <ref type="bibr" target="#b21">[21]</ref>. FriendsQA deriving from the Friends TV show, comprises of 1,222 dialogues and 10,610 questions. However, the FriendsQA dataset lacks discourse structure annotation and does not directly serve to validate our hypotheses. As such, Molweni is more suited as it incorporates multiparty dialogue MRC corpus with discourse structure. For this reason, we only adopt the Molweni multiparty dialogue dataset, a large-scale span-based machine reading comprehension dataset. Molweni contains 10,000 dialogues with 88,303 utterances and 30,066 questions, inclusive of both answerable and unanswerable questions. Crucially, the Molweni dataset annotated its discourse relations -all 78,245 present -in all of its dialogues.</p><p>On Molweni, our discourse-aware graph model achieves state-of-the-art results compared with traditional MRC models including BiDAF <ref type="bibr" target="#b22">[22]</ref>, DocQA <ref type="bibr" target="#b23">[23]</ref>, and BERT <ref type="bibr" target="#b24">[24]</ref>. DADgraph also outperforms the DialogueRNN <ref type="bibr" target="#b25">[25]</ref> and Dia-logueGCN <ref type="bibr" target="#b20">[20]</ref> dialogue-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Our work intersects MRC, discourse parsing and dialogue systems. We review these areas with a focus on the choice of MRC dataset, as it is a critical aspect that enables the modeling in DADgraph. a) Machine reading comprehension: MRC asks a system to answer questions with respect to an input passage. There are several types of datasets for machine comprehension, such as multiple-choice datasets <ref type="bibr" target="#b10">[10]</ref>, <ref type="bibr" target="#b12">[12]</ref>, answer sentence selection datasets <ref type="bibr" target="#b26">[26]</ref>, <ref type="bibr" target="#b27">[27]</ref> and extractive datasets <ref type="bibr" target="#b11">[11]</ref>, <ref type="bibr" target="#b28">[28]</ref>- <ref type="bibr" target="#b30">[30]</ref>. b) Discourse parsing for multiparty dialogues: Discourse parsing for multiparty dialogues is a challenging task which aims to obtains the discourse dependency links and discourse relations between utterances. STAC <ref type="bibr" target="#b31">[31]</ref> and Molweni <ref type="bibr" target="#b21">[21]</ref> are existing corpora for the task. The senses of discourse relation are introduced in ? IV. Most existing methods using traditional statistical machine learning models <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b7">[7]</ref>, and more neural-based models for the task are still should be explored <ref type="bibr" target="#b0">[1]</ref>. c) Dialogue systems: Dialogue systems have achieved a great process with introducing deep learning. <ref type="bibr" target="#b32">[32]</ref> [33] and <ref type="bibr" target="#b34">[34]</ref> respectively introduce commonsense knowledge, audio context and transferable latent variables into dialogue systems. <ref type="bibr" target="#b35">[35]</ref> summarizes the literature on empathetic dialogue systems. The usage of discourse structure and topic information for dialogue generation and dialogue summarization would be a meaningful research problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. TASK DEFINITION</head><p>Given a multiparty dialogue d = {u 1 , u 2 , ..., u N } with N utterances and M questions q = {q 1 , q 2 , ..., q M }, the task is to predict answers a = {a 1 , a 2 , ..., a M } for each question. Each utterance u i = {s i , c i } contains two parts: speaker s i and content c i . Besides, all utterances are concatenated to get d cat . There are two types of questions: answerable questions and unanswerable questions. If the question q i is answerable, the answer a i should be a continuous span in d cat including the index of start S and end E of the answer. Otherwise, the answer a i should be N A (unanswerable).</p><formula xml:id="formula_0">a i = (S, E), if q i is answerable N A, if q i is unanswerable IV. METHODOLOGY</formula><p>We now introduce how we combine discourse structure to represent multiparty dialogue with a neural network. The   architecture of our model is shown in <ref type="figure" target="#fig_4">Figure 2</ref>. Our model consists of three parts: sequential context encoding, discourse graph modeling, and MRC module. The sequential context encoding module aims to learn the sequence structure of utterances. The discourse graph modeling module constructs the multiparty discourse graph using discourse dependency links and discourse relations. Finally, the MRC module finds the answer span, where applicable.</p><p>A. Pre-processing: utterance encoding Different from the traditional MRC task, the input of a multiparty dialogue consists of a sequence of utterances originating from different speakers. We first encode the representations of utterances as the input of our model.</p><p>In the related work of DialogueGCN, their model adopts the Convolution Neural Network <ref type="bibr" target="#b36">[36]</ref> to learn the representation of each utterance, using a single convolutional layer followed by max-pooling and a fully connected layer.</p><p>In contrast to DialogueGCN's modeling decision, we adopt the widely-used pretrained model BERT to extract features u i of utterances. <ref type="figure">Fig. 3</ref> shows the BERT input representations. We adopt the [CLS] from well-trained BERT model as the representations of utterances as the inputs of our model. To be clear, the utterance encoder does not participate in the model training; BERT's CLS model is employed to obtain an encoded representation of each utterance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Sequential context encoding</head><p>The sequential context encoder models the dialogue structure according to the timeline of utterances, regarding dialogue as a sequence of utterances. This module learns the sequential structure of utterances in input dialogue and outputs the new representations of utterances. Inspired by DialogueGCN <ref type="bibr" target="#b20">[20]</ref>, after obtaining the context-independent representation u i of each utterance, we model the sequential structure of dialogues  For Wikipedia we extract only the text passages and ignore lists, tables, and headers. It is critical to use a document-level corpus rather than a shuffled sentence-level corpus such as the Billion Word Benchmark (Chelba et al., 2013) in order to extract long contiguous sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Fine-tuning BERT</head><p>Fine-tuning is straightforward since the selfattention mechanism in the Transformer allows BERT to model many downstream taskswhether they involve single text or text pairs-by swapping out the appropriate inputs and outputs. BERT instead uses the self-attention mechanism to unify these two stages, as encoding a concatenated text pair with self-attention effectively includes bidirectional cross attention between two sentences. For each task, we simply plug in the taskspecific inputs and outputs into BERT and finetune all the parameters end-to-end. At the input, sentence A and sentence B from pre-training are analogous to <ref type="bibr" target="#b0">(1)</ref>  Compared to pre-training, fine-tuning is relatively inexpensive. All of the results in the paper can be replicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU, starting from the exact same pre-trained model. <ref type="bibr" target="#b7">7</ref> We describe the task-specific details in the corresponding subsections of Section 4. More details can be found in Appendix A.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we present BERT fine-tuning results on 11 NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">GLUE</head><p>The General Language Understanding Evaluation (GLUE) benchmark (Wang et al., 2018a) is a collection of diverse natural language understanding tasks. Detailed descriptions of GLUE datasets are included in Appendix B.1.</p><p>To fine-tune on GLUE, we represent the input sequence (for single sentence or sentence pairs) as described in Section 3, and use the final hidden vector C ? R H corresponding to the first input token ([CLS]) as the aggregate representation. The only new parameters introduced during fine-tuning are classification layer weights W ? R K?H , where K is the number of labels. We compute a standard classification loss with C and W , i.e., log(softmax(CW T )). <ref type="bibr" target="#b7">7</ref> For example, the BERT SQuAD model can be trained in around 30 minutes on a single Cloud TPU to achieve a Dev F1 score of 91.0%. <ref type="bibr" target="#b8">8</ref> See <ref type="formula" target="#formula_1">(10)</ref> in https://gluebenchmark.com/faq. <ref type="figure">Fig. 3</ref>. BERT input representations <ref type="bibr" target="#b24">[24]</ref>. The input embeddings are the sum of the token embeddings, the segmentation embeddings and the position embeddings.</p><p>by the Bi-directional GRU (Bi-GRU) using Equation <ref type="formula" target="#formula_1">(1)</ref> to learn the context-dependent representation of each utterance.</p><formula xml:id="formula_1">g i = BiGRU (g i(+,?)1 , u i )<label>(1)</label></formula><p>Our choice of a bidirectional GRU model is modular; it can be easily replaced by other sequential modeling encoders, such as other recurrent neural network architectures or a transformer model.</p><p>In a multiparty dialogue, discourse relations can exist between two distant utterances and are substantially affected by long-distance dependencies. Therefore we must augment the discourse relation detection from just adjacent utterances (sequence), and also apply it to non-adjacent utterances (a graph). We construct a dialogue discourse graph in the next module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Discourse graph modeling</head><p>This module is a graph neural network that aims to learn the dialogue discourse graph using Graph Convolutional Network (GCN) <ref type="bibr" target="#b37">[37]</ref>, addressing the modeling of discourse dependency links and discourse relation types in conversation.</p><p>Graph construction: The outputs of sequential context encoder are context-aware utterances representations {g 1 , g 2 , ..., g i , ...g N } that are inputs of dialogue discourse graph modeling module. For graph construction, each utterance u i is regarded as a vertex in the directed graph G = (V, E, R) where V is the vertex set, E is the edge set, R is the relation set. a) Vertices.: In the dialogue discourse graph, each utterance u i is represented as a vertex v i . In <ref type="figure" target="#fig_4">Figure 2</ref>, five vertices represent five utterances from three different speakers, shown in different colors. We assume that all vertices in a dialogue graph are connected (i.e., one large graph component; no isolated nodes). b) Edges.: We adopt discourse dependency links as the directional edges in the dialogue discourse graph. An edge means that there is a discourse dependency relation between the two utterances. For instance, if utterance u j depends on utterance u i , there would be an edge of e ij . As the discourse graph is directional, e ij is not equivalent to e ji . In the majority of cases, an utterance only depends on its previous utterances, so the direction of edges are often directed as a topological sort from earlier utterances to later ones. In training, since all edges are from the ground truth in Molweni, we do not distribute weights for each edge.</p><p>In the DialogueGCN, as there are no discourse information in the dataset, the speaker-level context encoder models an utterance using its previous ten and the following ten utterances to construct a fully connected graph within a window context. Different from DialogueGCN that constructs a fully connected graph within a context utterance window, our model introduces the dialogue's discourse structure: directional discourse links represent the discourse dependency link, which is also associated with a specific relation type. The golden annotation of discourse structure is provided during training and testing.</p><p>As seen in <ref type="figure" target="#fig_4">Fig. 2</ref>, there are only five edges among the five vertices. According to the statistics of the STAC corpus <ref type="bibr" target="#b7">[7]</ref>, each utterance participates in 1.06 discourse relations with other utterances, on average. Therefore, the discourse dependency graph is very sparse; it is mostly a chain. Constructing an appropriate dialogue graph using discourse structure can reduce computing costs, compared to using the sliding window, fully connected graph. The training time and GPU memory use for DialogueGCN are two and four times greater respectively, compared to our model, as empirically measured in our experiments. In <ref type="figure" target="#fig_4">Fig. 2</ref>, we use a solid line to denote the discourse dependency between utterances from different speakers and use a dotted line to represent dependencies between utterances from one speaker. c) Relations.: The relations on the edges are discourse relation types. For example, r ij is the discourse relation type edge e ij which is the discourse dependency link between utterance u j and utterance u i . We adopt the discourse relation hierarchy from STAC <ref type="bibr" target="#b31">[31]</ref>, which includes 16 types of discourse relations: Comment, Clarification question, Elaboration, Acknowledgement, Continuation, Explanation, Conditional, Question-Answer pair (QAP), Alternation, Question-Elab(Q-Elab), Result, Background, Narration, Correction, Parallel and Contrast. In <ref type="figure" target="#fig_4">Fig. 2</ref>, the color of edges represents the discourse relation types. In the example, there 1 ? ? ? ? 1 ? 2 ? 3 ? 4 ? 5 are three different discourse relations: Elaboration, Question-Answer pair, and Acknowledgement.</p><formula xml:id="formula_2">+ 1 ? ? ? ? WS 1 ? ? ? ? 1 ? ? ? WS?weighted sum</formula><p>Graph representation: To construct the graph structure of the dialogue, DADgraph models each utterance according to a given discourse structure. We use g i to initialize v i which is obtained from the sequential context encoder and includes utterance features.</p><p>We introduce H i to compute features of utterance u i by aggregating utterances which have discourse dependency relations.</p><formula xml:id="formula_3">h (1) i = ?( r?R j?N r i ? ij c i,j W (1) r + ? ii W (1) 0 g i ) h (2) i = ?( r?R W (2) h (1) j + W 2 0 h (1) i )<label>(2)</label></formula><p>where h (1) i and h</p><p>(2) i are new feature vectors computed by aggregating other utterances with their discourse dependency links, using the output of sequential encoder g i as inputs.</p><p>After running the discourse graph modeling module, we obtain a new, augmented feature representation of vertex v i (from g i ) h i , which incorporates information about its neighborhood in the directional discourse graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. MRC Module</head><p>In the MRC module, we receive utterance representations h i from the discourse graph modeling module, as well as the embeddings of each word w i in source dialogue, and the representation of question q as inputs. MRC then outputs the answer span (S, E) of question q in the dialogue, when the question is inferred as answerable; N A if inferred as unanswerable. The interactions among words, utterances, and the question are shown in <ref type="figure" target="#fig_8">Fig. 4</ref>.</p><p>MRC combines the utterance representations to word representation via attention to introduce the dialogue discourse graph structure to all words. Based on the discourse-aware word representations, our MRC module predicts whether a word can be the start or end of an answer. We adopt simple interaction between dialogue and the question, so we can analyze the effect of dialogue graph modeling with discourse structure; future work could examine more sophisticated interactions.</p><p>We first compute the interaction between words w j of input dialogue and utterance representation h i obtained from speaker-level context encoder and obtain the attention weighted ? ij . We then compute the weighted sum for aggregating attention scores as the weight of each utterance and obtain new features of each word f i . In this case, f i is regarded as the combination of word feature and discourse structure of utterances.</p><formula xml:id="formula_4">e i,j = h i ? w j ? ij = exp(e ij ) M k=1 exp(e ik ) f i = N j=1 ? ij h i<label>(3)</label></formula><p>To answer the given question q, we perform the dot product between f i and q. The obtained new representation c i thus considers the question information for each word in the dialogue.</p><p>c</p><formula xml:id="formula_5">i = f i ? q (4)</formula><p>Finally, we concatenate the source word embeddings and weighted utterance embedding as final word embeddings. Therefore, for each word of input dialogue d, t i contains two sources of information: word features and question-aware representations with discourse dependencies of utterances.</p><formula xml:id="formula_6">t i = concat(w i , c i )<label>(5)</label></formula><p>To find the answer span in the input dialogue, we introduce a start vector S ? R H and an end vector E ? R H . These respectively represent the start and end of the answer span. We compute the probability of each word i being the answer span and candidate span is computed as follows:</p><formula xml:id="formula_7">s N A = S ? C + E ? C s i,j = max j?i S ? t i + E ? t j<label>(6)</label></formula><p>where C is the vector of representing all words in the dialogue. s N A and s i,j is respectively the probability of the question q being unanswerable and best non-null answer span (i, j). If s i,j &gt; s N A + ? , we predict the question is answerable and the span (i, j) is the answer. Hyperparameter ? thus controls the system's necessary confidence level to declare a specific answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset: Molweni</head><p>With the exception of Molweni, no multiparty dialogue dataset for MRC annotates the discourse structure of dialogues.  Also currently, the state-of-the-art performance of off-the-shelf dialogue discourse parsers is still unsatisfactory. In this paper, we perform experiments on the Molweni dataset. The overview of the Molweni dataset is shown in <ref type="table">Table 1</ref>.</p><p>Considering the properties of multiparty dialogues, the Molweni dataset is presented, a machine reading comprehension (MRC) dataset built over multiparty dialogues. Molweni dataset derives from the large-scale multiparty dialogues dataset the Ubuntu Chat Corpus <ref type="bibr" target="#b38">[38]</ref>, which is a large-scale multiparty dialogues corpus. To learn better graph representations of multiparty dialogues, Molweni adopts the dialogues with 8-15 utterances and 2-9 speakers. To simplify the task, the dataset filters out the dialogues containing long sentences (more than 20 words). Finally, Molweni randomly chooses 10,000 dialogues with 88,303 utterances from those that qualify from the Ubuntu dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Baselines and evaluation</head><p>We use two kinds of models as experiment baselines: classic MRC models for passages, and models that representing multiparty dialogues. a) MRC models for passages understanding: We adopt three well-known MRC models that can answer unanswerable questions as baselines:</p><p>? BiDAF <ref type="bibr" target="#b22">[22]</ref>. The BiDAF model presents the context passage at different levels of granularity and learns the query-aware context representation using a bi-directional attention flow mechanism.</p><p>? DocQA <ref type="bibr" target="#b23">[23]</ref>. This model is a neural paragraph-level QA method, which can scale to document and multidocument inputs. DocQA can ignore no-answer containing paragraphs in documents. The model contains paragraph sampling and attempts to produce a globally correct answer.</p><p>? BERT <ref type="bibr" target="#b24">[24]</ref>. BERT is a bidirectional encoder utilizing transformers <ref type="bibr" target="#b24">[24]</ref>. To learn better representations for text, BERT adopts two objectives: masked language modeling and the next sentence prediction during pretraining. To adapt BERT for our task, we concatenate all utterances from the input dialogue as a passage, where each utterance u i encodes both the speaker identity and their uttered text as {speaker ui : content ui }. b) Neural Models for Dialogue Modeling: We adopt Dia-logueRNN <ref type="bibr" target="#b25">[25]</ref>and DialogueGCN <ref type="bibr" target="#b20">[20]</ref>as our baselines. These two models are originally designed for sentiment classification. To adapt them to our task, we replace DADgraph's internal models with these models, but hold fixed the same final MRC module and BERT-based utterance representations.</p><p>? DialogueRNN. DialogueRNN is a sequential neural network model for representing multiparty dialogues on EM F1 BiDAF <ref type="bibr" target="#b22">[22]</ref> 22.9 39.8 DocQA <ref type="bibr" target="#b23">[23]</ref> 42.5 56.0 BERT <ref type="bibr" target="#b24">[24]</ref> 45.3 58.0 DialogueRNN <ref type="bibr" target="#b25">[25]</ref> 45.4 60.9 DialogueGCN <ref type="bibr" target="#b20">[20]</ref> 45.7 61.0 DADgraph (Our) 46.5 61.5 Human performance 64.3 80. <ref type="table" target="#tab_3">2   TABLE II  RESULTS ON MOLWENI DATASET.</ref> emotion recognition for conversations task with two bidirectional GRUs: a global GRU and a party GRU.</p><formula xml:id="formula_8">? DialogueGCN.</formula><p>Compared to DialogueRNN, DialogueGCN model the context windows of an utterance in the dialogue as a graph and represent the graph using the GCN model. c) Evaluation metric and upper bounds: Our task is closely related to SQuAd 2.0, so we adopt the same evaluation metrics: exact match (EM) and F 1 score to evaluate experiments. EM measures the percentage of predictions that match all words of the ground truth answers exactly. F 1 scores are usually engineered to be more tolerant, measuring the average overlap between a system's prediction and a ground truth answer. We ask two volunteers that have a computer science background and who understand technical dialogues well to answer questions in the test set. Our interannotator study indicates that our volunteers achieved 64.3% in EM and 80.2% in F 1 score on the Molweni dataset. <ref type="table">Table 2</ref> shows the results on Molweni. BiDAF achieves the lowest results in both EM and F 1 measures, and the DocQA model obtains improvements compared to the BiDAF model. As expected, both models do not perform well compared against other models, because two models are designed to model passages understanding which is quite different from multiparty dialogue understanding. BERT is a strong baseline for representing passages, bettering both BiDAF and DocQA. We observe that DialogueRNN and DialogueGCN achieve higher results compared to the BERT model on both EM and F 1 measures. This signifies that such dialogue-based models can learn better representations for dialogues than BERT, and that such represention is important to MRC performance. We also note a genre discrepancy: BERT is pretrained on wellwritten passages, quite different from dialogue text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results</head><p>Our DADgraph, which employs ground truth discourse structure achieves the best results. First, compared to BiDAF, DocQA, and BERT, our dialogue-based model yields improved results that showcase the efficiency of the dialoguebased representation learning model. Second, compared to other dialogue-based models, our model demonstrates that discourse-awareness can create improved representations that better reflect the semantic relations among utterances. As a side effect, DADgraph's model incurs less memory and time costs compared against DialogueGCN, as DialogueGCN adopts a sliding window method and constructs a fully connected graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Ablation Study</head><p>We perform ablation experiments to verify the effect of discourse dependency links and discourse relation types. The results of ablation experiments on the Molweni dataset are shown in <ref type="table">Table 3</ref>. a) Evaluation discourse relation types.: To verify the influence of discourse relation types, we replace discourse relation with relations in vanilla dialogue which depends on two aspects: speaker dependency and temporal dependency. For example, when utterance u i and u j co-occur in a conversation, this ablated model does not consider whether u i is uttered before u j or after (a bag-of-utterance assumption). From <ref type="table">Table 5</ref>, when removing discourse relation types, both EM and F 1 results decrease.</p><p>Our ablation experiments indicate the effect of discourse relations on understanding dialogues. Discourse relations are helpful to understand the dialogue and find the correct span from the dialogue. b) Evaluation on discourse structure.: To verify the help of discourse structure, we adopt a fully connected structure to build an utterance dialogue graph. When using a fully-connected utterance window graph, no corresponding discourse relations to edges are provided in our dataset. Therefore, we only can evaluate the influence of discourse structure including both links and relations. From <ref type="table">Table 5</ref>, when removing both discourse links and relation and adopt a fully connected graph to represent the dialogue, EM and F 1 results all decrease. Ablation experiment results prove the help of discourse structure for modelling dialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Case study</head><p>In this part, we analyze a dialogue from Molweni where DADgraph correctly answers the questions given the discourse structure that DialogueRNN and DialogueGCN baselines yields incorrect answers. <ref type="figure" target="#fig_8">Figure 4</ref> shows an example from the Molweni test dialogues with two answerable questions. In the dialogue, there are three speakers and seven utterances.</p><p>The first question that we examine is "What does bacon5o not want to use?". The answers of DialogueRNN and Dia-logueGCN for Q1 are "a wireless accesspoint" and "it does n't support my internet", respectively. DialogueRNN only models the sequential structure of utterances using the RNN method, which would be limited to long-term dependency problems. Different from DialogueRNN, DialogueGCN can construct a dialogue graph that can be used to model semantic relations between long-distance utterances, but the way of constructing sipher: bacon5o there 's no``fixmbr '' with ubuntu . a fully connected graph does not accurately obtain the structure information in the dialogue and pay huge computing costs.</p><p>The second question (Q2) is "which one is the new acceleration architecture?". In the dialogue, there are two acceleration architectures mentioned: xaa and exa. Considering the occurrence of "acceleration architecture", both DialogueRNN and DialogueGCN output the incorrect answer exa for Q2.</p><p>The third question (Q3) is "What is missing from ubuntu?". The word "ubuntu" in the question is an important clue for finding the answer. The word "ubuntu" appears in both U 1 and U 3 . However, both DialogueRNN and DialogueGCN output the answer internet for question Q3, which is incorrect, originating from U 3 .</p><p>In <ref type="figure">Fig. 5</ref>, our DADgraph correctly answers these three answerable questions. The complex structure of multiparty dialogues makes it difficult to understand them. After introducing discourse structure, our model can learn better representations of each utterance and adopt the structure to find the index of start and end of answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper, we propose a discourse-aware dialogue graph neural network, DADgraph, for multiparty machine reading comprehension tasks. It features a pipeline of three components: sequential context encoding, dialogue discourse graph modeling, and an MRC module. To the best of our knowledge, our model first introduces the discourse structure on multiparty dialogues MRC tasks. To verify the performance of our model, we perform experiments on the Molweni corpus, a large-scale multiparty dialogues dataset for MRC with discourse structure.</p><p>Our experimental results on the Molweni dataset show that discourse structure helps understand the dialogue compared with traditional MRC models on passage and pretrained language models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>(a) Multiparty dialogue from Molweni, with accompanying (b) contributed questions and answers, and (c) discourse structure. Correct answers are marked in red. Q-Elab, QAP, Expl and Ack. respectively represent the Question-Elaboration, Question-Answer Pair, Explanation and Acknowledgements relations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Links between utterances from same speaker. Links between utterances from different speaker. Elaboration relation. Question-answer pair relation. Acknowledgement relation. ?? There are many other discourse relations not in the graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Dialogue graph modeling using discourse structure. The edge between vertices is the discourse dependency link with discourse relation. Different colors of nodes and edges respectively represent different speakers and different discourse relations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 :</head><label>2</label><figDesc>BERT input representation. The input embeddings are the sum of the token embeddings, the segmentation embeddings and the position embeddings. The NSP task is closely related to representationlearning objectives used in Jernite et al. (2017) and Logeswaran and Lee (2018). However, in prior work, only sentence embeddings are transferred to down-stream tasks, where BERT transfers all parameters to initialize end-task model parameters. Pre-training data The pre-training procedure largely follows the existing literature on language model pre-training. For the pre-training corpus we use the BooksCorpus (800M words) (Zhu et al., 2015) and English Wikipedia (2,500M words).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>For applications involving text pairs, a common pattern is to independently encode text pairs before applying bidirectional cross attention, such as Parikh et al. (2016); Seo et al. (2017).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>sentence pairs in paraphrasing, (2) hypothesis-premise pairs in entailment, (3) question-passage pairs in question answering, and (4) a degenerate text-? pair in text classification or sequence tagging. At the output, the token representations are fed into an output layer for tokenlevel tasks, such as sequence tagging or question answering, and the [CLS] representation is fed into an output layer for classification, such as entailment or sentiment analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 4 .</head><label>4</label><figDesc>The interactions in our MRC module. w i are the representations of word i in the dialogue, and q is the question. WS denotes weighted sum.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>1 morfic: 7 Q1:Fig. 5 .</head><label>175</label><figDesc>xaa is old acceleration architecture, exa is the new one, font rendering is so much filepath 2 bacon5o: i dont want ubuntu , it does n't support my internet, thus i can not use it 3 morfic: your internet is different from mine ? damn bush and his internets !4 bacon5o: my internet is differentwhy you ask ? 5 morfic: your possesive``my '' on the internet 6 bacon5o: i use a wireless accesspoint that plugs into my usb which then goes into my motherboard What does bacon5o not want to use? Gold: ubuntu DialogueRNN: a wireless accesspoint DialogueGCN: it does n't support my internet Our model: ubuntu Q2: Which one is new acceleration architecture? Gold: exa DialogueRNN: xaa DialogueGCN: xaa Our model: exa Q3: What is missing from ubuntu? Gold: fixmbr DialogueRNN: internet DialogueGCN: internet Our model: fixmbr An example from our Molweni test set with three speakers: sipher, morfic, and bacon5o. Q1,Q2 and Q3 are three answerable questions in test set. We show ground truth answers and the output answers of DialogueRNN, DialogueGCN, and our model. Correct answers are marked in red; incorrect ones in blue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE I OVERVIEW</head><label>I</label><figDesc>OF MOLWENI FOR MRC.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>TABLE III RESULTS OF ABLATION EXPERIMENTS ON MOLWENI DATASET.</figDesc><table><row><cell>EM 46.5 44.9 -w/o discourse structure 44.7 DADgraph -w/o discourse relations</cell><cell>F1 61.5 60.6 60.5</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank anonymous reviewers for their helpful comments. Thanks to Yibo Sun and Tianwen Jiang for their advice for this paper. The research in this article is supported by the Science and Technology Innovation 2030 -"New Generation Artificial Intelligence" Major Project (2018AA0101901), the National Key Research and Development Project (2018YFB1005103), the National Science Foundation of China (61772156, 61976073), Shenzhen Foundational (JCYJ20200109113441941), Research Funding and the Foundation of Heilongjiang Province (F2018013).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A deep sequential model for discourse parsing on multi-party dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7007" to="7014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Gsn: A graph-structured network for multi-party dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/696</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/696" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5010" to="5016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Keep meeting summaries on topic: Abstractive multi-modal meeting summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Radke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07" />
			<biblScope unit="page" from="2190" to="2196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Abstractive meeting summarization via hierarchical adaptive segmental network learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3455" to="3461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dream: A challenge data set and models for dialogue-based reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="217" to="231" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Integer linear programming for discourse parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Perret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Afantenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Morey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="99" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<ptr target="http://aclweb.org/anthology/N16-1013" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discourse parsing for multi-party chat dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Afantenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Perret</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D15-1109" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="928" to="937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Challenging reading comprehension on daily conversation: Passage completion on multiparty dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jurczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2039" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Friendsqa: Open-domain question answering on tv show transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 20th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="188" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MCTest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D13-1020" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="193" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Race: Large-scale reading comprehension dataset from examinations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Quac: Question answering in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2174" to="2184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">CoQA: A conversational question answering challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="249" to="266" />
			<date type="published" when="2019-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discourse structure for context question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Pragmatics of Question Answering at HLT-NAACL</title>
		<meeting>the Workshop on Pragmatics of Question Answering at HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Discourse processing for context question answering based on linguistic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="511" to="526" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Discourse complements lexical semantics for non-factoid answer reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="977" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Machine comprehension with discourse relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1253" to="1262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning answerentailing structures for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="239" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DialogueGCN: A graph convolutional neural network for emotion recognition in conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chhaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D19-1015" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11" />
			<biblScope unit="page" from="154" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Molweni: A challenge multiparty dialogues-based machine reading comprehension dataset with discourse structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12" />
			<biblScope unit="page" from="2642" to="2652" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01603</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="845" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dialoguernn: An attentive rnn for emotion detection in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6818" to="6825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">What is the jeopardy model? a quasi-synchronous grammar for qa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Wikiqa: A challenge dataset for opendomain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2013" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Newsqa: A machine comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Suleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Representation Learning for NLP</title>
		<meeting>the 2nd Workshop on Representation Learning for NLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Know what you don? t know: Unanswerable questions for squad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Discourse structure and dialogue acts in multiparty dialogue: The stac corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Benamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Afantenos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Diverse and informative dialogue generation with context-specific commonsense knowledge awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="5811" to="5820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Dialogue systems with audio context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pandelea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">388</biblScope>
			<biblScope unit="page" from="102" to="109" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Zero-shot cross-lingual dialogue systems with transferable latent variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">I</forename><surname>Winata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D19-1129" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11" />
			<biblScope unit="page" from="1297" to="1303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A survey on empathetic dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">Z</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="50" to="70" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="285" to="294" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
