<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FOCUSING ON POSSIBLE NAMED ENTITIES IN ACTIVE NAMED ENTITY LABEL ACQUISITION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Osman Berk?apc?</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering and Natural Sciences</orgName>
								<orgName type="institution">Sabanc? University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oznur</forename><surname>Tastan</surname></persName>
							<email>otastan@sabanciuniv.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering and Natural Sciences</orgName>
								<orgName type="institution">Sabanc? University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reyyan</forename><surname>Yeniterzi</surname></persName>
							<email>reyyan.yeniterzi@sabanciuniv.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering and Natural Sciences</orgName>
								<orgName type="institution">Sabanc? University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">FOCUSING ON POSSIBLE NAMED ENTITIES IN ACTIVE NAMED ENTITY LABEL ACQUISITION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>*Co-corresponding authors.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Active learning</term>
					<term>Named entity recognition</term>
					<term>Annotation cost</term>
					<term>Semi-supervised clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Named entity recognition (NER) aims to identify mentions of named entities in an unstructured text and classify them into the predefined named entity classes. Even though deep learning-based pre-trained language models achieve good predictive performances, many domain-specific NER tasks still require a sufficient amount of labeled data. Active learning (AL), a general framework for the label acquisition problem, has been used for the NER tasks to minimize the annotation cost without sacrificing model performance. However, heavily imbalanced class distribution of tokens introduces challenges in designing effective AL querying methods for NER. We propose AL sentence query evaluation functions which pay more attention to possible positive tokens, and evaluate these proposed functions with both sentence-based and token-based cost evaluation strategies. We also propose a better data-driven normalization approach to penalize too long or too short sentences. Our experiments on three datasets from different domains reveal that the proposed approaches reduce the number of annotated tokens while achieving better or comparable prediction performance with conventional methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Name entity recognition (NER) aims to identify mentions of named entities in an unstructured text and classify them into the predefined named entity classes <ref type="bibr">(e.g., person names, organizations, locations)</ref>. NER is one of the fundamental natural language processing (NLP) tasks and is used in other NLP tasks such as entity linking, event extraction, and question answering. Although deep learning-based pre-trained language models <ref type="bibr" target="#b7">[Devlin et al., 2019</ref><ref type="bibr" target="#b46">, Yang et al., 2019</ref><ref type="bibr" target="#b21">, Liu et al., 2019</ref><ref type="bibr" target="#b27">, Raffel et al., 2020</ref> have advanced the state-of-the-art performance in NER <ref type="bibr" target="#b44">[Torfi et al., 2020</ref><ref type="bibr" target="#b26">, Peters et al., 2019</ref>, a sufficient amount of labeled data is still necessary for achieving satisfactory prediction performance in most domains <ref type="bibr" target="#b40">[Tikhomirov et al., 2020</ref><ref type="bibr" target="#b45">, Wang et al., 2020</ref>. Since acquiring labeled data is both time and budget-consuming, efficient label acquisition for NER remains a challenge.</p><p>A general framework for tackling the labeled data acquisition problem is active learning, in which the learner strategically chooses the most valuable instances as opposed to selecting a random sample for labeling <ref type="bibr" target="#b39">[Thompson et al., 1999]</ref>. In the pool-based active learning setup, the active learner selects the most useful examples from an unlabeled pool of samples, queries them to an annotator for labeling; upon receiving the labels for the queried examples, the model is retrained with the augmented labeled set. These query selection, annotation, and retraining steps are iterated multiple times until either the desired performance is achieved or the labeling budget is exhausted <ref type="bibr" target="#b32">[Settles, 2011]</ref>. The goal is to reduce the annotation cost by creating a smaller labeled set while still achieving good predictive performance.</p><p>Active learning (AL) has demonstrated success in various sequence annotation tasks such as part-of-speech tagging <ref type="bibr" target="#b29">[Ringger et al., 2007]</ref>, dependency parsing <ref type="bibr" target="#b18">[Li et al., 2016b]</ref> and semantic parsing <ref type="bibr" target="#b39">[Thompson et al., 1999]</ref>. AL has been used to tackle the label acquisition problem in the NER task as well. <ref type="bibr" target="#b37">Shen et al. [2017]</ref> demonstrated that AL combined with deep learning achieves nearly the same performance on standard datasets with just 25% of the original training data. <ref type="bibr" target="#b5">Chen et al. [2015]</ref> developed and evaluated both existing and new AL methods for a clinical NER task. Their results showed that AL methods, particularly uncertainty-sampling approaches, provide significant savings in the annotation cost.</p><p>In active learning, the most critical step is selecting the useful query examples for manual annotation. This step becomes more challenging for sequence labeling tasks, especially for named entity recognition, for two reasons. The first challenge of applying active learning to NER arises due to imbalanced data distribution. In NER annotation, a token is either labeled with its corresponding named entity class if it is part of a named entity or with the "other" class if it is not part of a named entity. The other class is generally referred as negative annotation or negative token, and all other labels -named entity labels-are referred as positive annotations or positive tokens <ref type="bibr" target="#b22">[Marcheggiani and Arti?res, 2014]</ref>. In NER datasets, negative tokens are usually over-abundant compared to positive tokens.</p><p>The second challenge in applying active learning to NER is related to the varying length of sentences. In NER, tokens are annotated one by one, but the context, hence the corresponding sentence, is still required for accurate token annotation. Therefore, at each active learning iteration, sentences are queried instead of tokens. Active learners that select the informative sentences for querying by directly aggregating over all the tokens are biased towards longer sentences. In order to prevent this bias towards sentences with more terms, the aggregated sentence scores are normalized by the number of tokens in the sentence <ref type="bibr" target="#b9">[Engelson and Dagan, 1996</ref><ref type="bibr" target="#b11">, Haertel et al., 2008</ref>. This commonly used approach solves the problem only partially, since this time, the active learner starts to query "too" short sentences in the early, and intermediate rounds <ref type="bibr" target="#b42">[Tomanek, 2010]</ref>. In this paper, we moderate these two extreme cases and propose a normalization which exploits the corresponding datasets' token count distribution.</p><p>The varying length of sentences also affects the cost evaluation of the active learning framework. Some studies <ref type="bibr" target="#b47">, Yao et al., 2009</ref><ref type="bibr" target="#b13">, Kim et al., 2006</ref><ref type="bibr" target="#b19">, Liu et al., 2020a</ref> treat all sentences equally and compare active learning methods directly with respect to the number of sentences queried. However, this is not realistic since the cost is not fixed across sentences as sentences differ in the number of tokens and the number of named entities they contain <ref type="bibr" target="#b1">[Arora et al., 2009</ref><ref type="bibr" target="#b11">, Haertel et al., 2008</ref>. Therefore, the number of annotated tokens should be incorporated into the active learning cost. In this regard, many studies in the literature <ref type="bibr" target="#b36">[Shen et al., 2004</ref><ref type="bibr" target="#b28">, Reichart et al., 2008</ref><ref type="bibr" target="#b37">, Shen et al., 2017</ref> measure the cost of the annotation by the number of tokens annotated even though they query the sentences. Using only the token count is also an imperfect strategy as the cost of annotating the same number of tokens distributed over multiple sentences is not equivalent to annotating these tokens within a single sentence <ref type="bibr">[Settles et al., 2008, Tomanek and</ref><ref type="bibr" target="#b43">Hahn, 2010]</ref>. This is mainly because there is a cost factor associated with each new sentence that is independent of its content and length. Even though we do not propose a new cost calculation method that encompasses all these different aspects, we consider these two cost evaluation set-ups to analyze the existing and proposed approaches in detail.</p><p>In this study, we propose an extension to the subset of the existing uncertainty sampling methods to handle the challenges associated with the over-abundance of the negative tokens. In our proposed approach, the query evaluation metrics are designed to pay less attention to the tokens that are predicted to have negative annotations. We identify potentially negative tokens through clustering of pre-trained BERT representations after a semi-supervised dimensionality reduction. To the best of our knowledge, the use of the BERT embeddings directly in the active learning querying step for NER has never been attempted before this paper. Last but not least, this paper proposes a better normalization strategy for aggregating token scores to attain a good sentence query metric. For a fair comparison, we evaluate different active learning query methods both under the assumption of fixed annotation cost per sentence and fixed annotation cost per token. Our experiments on three datasets from different domains illustrate that our proposed approach reduces the number of annotated tokens while maintaining the slightly better or same level of prediction performance with the compared methods. We also present an extensive investigation about the effects of different pre-trained language embeddings on the performance of our NER model. The rest of the paper is organized as follows: Section 2 presents the NER data collections used in the experiments together with additional details to motivate the reader for the proposed method, Section 3 summarizes the general active learning setup and the commonly used active learning strategies for the NER task, and Section 4 describes the proposed approach. We describe our experimental setting in Section 5 and detail our results in Section 6. Section 7 concludes with a summary of our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Datasets</head><p>Three commonly used English NER datasets from two different domains are selected.  <ref type="bibr" target="#b8">[Dogan et al., 2014]</ref>: This dataset only contains the Disease tag.</p><p>Some important statistics on these datasets are provided in <ref type="table" target="#tab_0">Table 1</ref>. As it can be seen from the <ref type="table" target="#tab_0">Table 1</ref>, ratio of the positive tokens (annotations) is generally low. CoNLL-03, which has four different named entities, contains the highest percentage with 17%, and this ratio is 8% in NCBI-Disease when there is only one type of named entity. This imbalance causes the problems that are detailed in Section 1. We propose using the predicted annotation type of tokens in the candidate selection setting to address these problems.</p><p>3 Active Learning for NER Let x = x 1 , x 2 , ? ? ? , x n be sequence of tokens in a sentence. Let y = y 1 , y 2 , ? ? ? , y n be the sequence of named entity states, each of which is associated with a named entity type, y ? {y 1 , y 2 , ? ? ? y m }, where m is the number of different named entity classes. In the NER task, our aim is to uncover the hidden sequence of y given the observed sequence of x.</p><p>In the pool-based AL, the pool consists of unlabeled sentences, and at each iteration, the AL strategy aims to identify the most useful examples to be annotated. Since named entities often span multiple tokens and being a named entity or not depends on the context, the fundamental annotation unit in NER is not a token but a sentence. Thus, in the AL framework, the unlabelled pool, U , contains the unlabelled sentences, and the labeled set, L, contains the annotated sentences. At each iteration, a set of sentences is selected as the query set from U , and upon annotation, added to L. Overall the active learning loop proceeds as follows:</p><p>? Initial Model Creation: Initially, some sentences from the set U are selected randomly. These sentences, which are referred to as q 0 , are manually annotated and included to set L. Then, the first NER model is trained with this initial annotated set. ? Iteration: The following steps are repeated until the chosen stop criterion is met.</p><p>-Querying: In the query step at iteration j, examples in the U are ranked based on the querying metric and, the top-ranked |q j | sentences are selected as the query batch. -Annotation: The selected set of sentences, q j , are manually annotated and added to L set.</p><p>-Training: The NER model is retrained on the augmented labeled set L.</p><p>The querying step is the most critical step in AL since the most useful and informative examples for learning are chosen at that step for annotation. One of the most common general frameworks for measuring informativeness is uncertainty sampling <ref type="bibr" target="#b16">[Lewis and Catlett, 1994]</ref>, where the active learner selects the unlabeled example(s) for which the current model is most uncertain about its prediction. In our case, the active learner ranks the sentences based on the uncertainty measure then the top-ranked sentences are queried as a batch for annotation. Since sentences are annotated at NER, an uncertainty score ? is calculated at the sentence level. ?(x * ) &gt; ?(x ) indicates that the current model is more uncertain about x * . Thus it will prefer x * over x when querying.</p><p>Various strategies exist to estimate a token's uncertainty and also different ways are available to calculate the final sentence uncertainty ? <ref type="bibr" target="#b11">, Haertel et al., 2008</ref><ref type="bibr" target="#b42">, Tomanek, 2010</ref>. There are two main ways to assess the informativeness/usefulness of a sentence in AL. One can calculate a score over the entire sentence-based on the conditional probability of the Viterbi sequence given the observation sequence. Alternatively, the score of a sentence can be calculated by aggregating token-level scores, which are calculated at each position i of the observation sequence by the marginal probability of the respective labels. A detailed comparison of several utility functions indicated that one is not necessarily superior to the other. Yet, token aggregated methods perform slightly better and have lower computational complexity since only the best Viterbi sequence needs to be determined <ref type="bibr" target="#b42">[Tomanek, 2010]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Assessing Uncertainty of Tokens</head><p>The uncertainty score of a sentence is calculated by aggregating the tokens' uncertainties <ref type="bibr" target="#b36">[Shen et al., 2004</ref><ref type="bibr" target="#b5">, Chen et al., 2015</ref><ref type="bibr" target="#b19">, Liu et al., 2020a</ref>. Therefore, estimating token uncertainties is critical in assessing the value of a sentence. In this subsection, we will review four different approaches for measuring the uncertainty of a token.</p><p>? Entropy-based: A common way to quantify the class labels' uncertainty is by calculating entropy <ref type="bibr" target="#b35">[Shannon, 2001]</ref> of the class labels. For the NER task, the entropy of the class label for a token, x i , is denoted as H(x i ), is computed over all possible tags as follows:</p><formula xml:id="formula_0">H(x i ) = ? M j=1 P (y i = j|x, ?) log P (y i = j|x, ?)<label>(1)</label></formula><p>where ? represents the model parameters, y i is the predicted label for the token x i , and M is the number of possible class labels for a token. P (y i = j|x, ?) stands for the estimated probability of tag j being the label of token x i .</p><p>? Token probability: The uncertainty associated with the most likely tag assignment of the token is another measure of uncertainty. Let T (x i ) be the token probability, which is computed based on the most probable entity label's estimated probability for x i in x as follows:</p><formula xml:id="formula_1">T (x i ) = 1 ? max 1?j?M P (y i = j|x, ?).<label>(2)</label></formula><p>? Assignment probability: Alternatively, instead of considering each token in isolation, we can consider the most likely label assignment of the sentence, which we will refer to as?, Viterbi sequence, and then use the assigned probability of the token. The uncertainty for a token x i in that sequence assignment is computed based on the probability of the label assignment? i of x i under the most likely tag sequence? <ref type="bibr" target="#b19">[Liu et al., 2020a]</ref>. We call this measure as assignment probability, denoted by A(x i ), is given by the following equation:</p><formula xml:id="formula_2">A(x i ) = 1 ? P (y i =? i |x, ?).<label>(3)</label></formula><p>? Margin-based: Another metric of uncertainty is the margin between the most and the second most probable entity labels of the token x i <ref type="bibr" target="#b31">[Scheffer et al., 2001]</ref>. M (x i ) is defined as follows:</p><formula xml:id="formula_3">M (x i ) = 1 ? ? ? max 1?j?M P (y i = j|x, ?) ? max 1?k?M k =j P (y i = k|x, ?) ? ?<label>(4)</label></formula><p>where j and k are the most likely and the second most likely label assignments for the token y i .</p><p>These four metrics, H(x i ) token entropy, T (x i ) token probability, A(x i ) assignment probability and M (x i ) token margin constitute the four alternative token uncertainty measures we used throughout this paper. We will refer the token uncertainty measure, as ? in the upcoming sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Assessing Uncertainty of Sentences</head><p>Tokens' uncertainty scores are used to evaluate sentence informativeness for querying. Several methods have been proposed in the literature in order to aggregate the token scores into a single sentence score. Three of these, namely Single Most Uncertain (single), Normalized Sum (normalized) and Total Sum (total) will be described before detailing our proposed approach.</p><p>? Single Most Uncertain: One way of deriving the uncertainty score of a sentence x is considering the token x i ? x with maximum uncertainty value ? (x i ) as follows:</p><formula xml:id="formula_4">? s (x) = max 1?i?Nx ? (x i ) (5)</formula><p>where N x is the total number of tokens in the sentence x.</p><p>? Normalized Sum: The previous method focuses on the most uncertain one but ignores the other tokens' usefulness in the sentences. An alternative method is to sum the uncertainty scores of tokens and normalize this sum with the number of tokens in the sentence, N x <ref type="bibr">[Hwa, 2004, Baldridge and</ref><ref type="bibr" target="#b2">Osborne, 2004]</ref>.</p><formula xml:id="formula_5">? n (x) = 1 N x Nx i=1 ? (x i )<label>(6)</label></formula><p>? Total Sum:  argue to use aggregated values directly without normalizing with token count as such sentences tend to contain more information.</p><formula xml:id="formula_6">? t (x) = Nx i=1 ? (x i )<label>(7)</label></formula><p>4 Proposed Active Learning Querying Approach</p><p>In this paper, we propose a new sentence query evaluation function that considers the imbalance between the positive and negative tokens and the length of the query sentences. Our proposed evaluation function requires identifying likely positive tokens at each query step, which we solve through a semi-supervised clustering approach on token embeddings. In the following sections, we will detail this and the proposed normalization approach based on sentence lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Positive Token Biased Querying</head><p>As shown in <ref type="table" target="#tab_0">Table 1</ref>, negative tokens are far more abundant in sentences than positive tokens <ref type="bibr" target="#b41">[Tjong Kim Sang and De Meulder, 2003</ref>]. This imbalance challenges the active learning query evaluation step; when the sentence's overall uncertainty is calculated, negative tokens' uncertainty scores dominate the overall score shadowing the positive tokens. This causes the trained prediction model to miss the opportunity of using sentences with informative, positive tags that are very useful to identify whether a term is named entity or not, and if it is, the correct type of it. We propose to solve this problem by having the query function focus more on the positive tokens. However, the information of which tokens are positive is unknown at the query time thus has to be guessed. For this, we first identify these likely positive tokens using a semi-supervised clustering approach. To achieve this, we exploit pre-trained language model embeddings directly in the querying step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Identifying Possibly Positive Tokens</head><p>Contextual word embeddings provided significant improvements in many NLP tasks mainly because these models are pre-trained over large data collections that enables them to capture the different characteristics of terms depending on the context <ref type="bibr" target="#b20">[Liu et al., 2020b]</ref>. Domain-specific pre-trained models, such as BioBERT, even provide more useful domain enriched representations. In this paper, we use these BERT representations to identify the possibly positive tokens. Since terms that have similar semantic and syntactic roles are expected to have similar embeddings, we resort to clustering in order to identify the possible groups. Based on our observation of the datasets and distribution of tags among these clusters, we assume that the largest cluster will be the negative token cluster. The rationale behind this assumption is that the imbalanced distribution of the data shall reveal itself in the sizes of these clusters; therefore, the largest cluster should be the negative one. Based on this assumption, we consider all the tokens in other clusters' as the positive token set. The final clusters may still contain some outliers. Especially the tokens that are in the largest cluster but away from the corresponding cluster centroid might also be informative and, therefore, desirable to query. Thus, we extend the positive token set with tokens that are at close to the negative token cluster.</p><p>Several adaptations and extensions are needed in order to apply this idea. First of all, contextual embeddings, like BERT or BioBERT, are high dimensional. When the embedding space is high-dimensional, clusters tend to split in a sparse space. When that is the case, one can not confidently assume that the largest cluster will consist of primarily negative tokens because tokens are all grouped into small clusters with similar sizes. In order to prevent this, we propose reducing the original embeddings to a lower-dimensional space and perform clustering in this lower-dimensional space.</p><p>Another possible problem with the existing proposed approach can arise due to both the dimensionality reduction and clustering being unsupervised algorithms. Using unsupervised approaches may result in unexpected clusters due to unrelated characteristics of the tokens. To avoid this, we guide the clusters using task specific labels. Instead of using an unsupervised dimensionality reduction, we use a semi-supervised approach which make use of the subset of available annotations at the query time. Along the active learning iterations, the labeled set grows, which results in better dimensionality reduction over iterations.</p><p>For the the clustering step, we use Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDB-SCAN) algorithm <ref type="bibr" target="#b3">[Campello et al., 2013</ref><ref type="bibr" target="#b4">[Campello et al., , 2015</ref>. It has been shown that Uniform Manifold Approximation and Projection (UMAP) <ref type="bibr" target="#b23">[McInnes et al., 2018]</ref> can be used as an effective pre-processing step to boost the performance of density-based clustering algorithms. We use the semi-supervised extension of UMAP <ref type="bibr" target="#b30">[Sainburg et al., 2021]</ref>. For detecting tokens that are close to the cluster boundaries, we use outliers provided by the GLOSH algorithm <ref type="bibr" target="#b4">[Campello et al., 2015]</ref>. Tokens with the top 1% outlier scores are used.</p><p>To summarize we execute the following steps to obtain a set of likely positive tokens:</p><p>1. We obtain the contextualized word embeddings of the tokens that are in the union of the labeled and unlabeled token set, U ? L, using a pre-trained model. These pre-trained models are domain-specific whenever available.</p><p>2. Embeddings of all the tokens in U ? L are mapped into a two-dimensional space using semi-supervised UMAP. Tokens in L are used for supervision.</p><p>3. HDBSCAN is used to cluster and identify possibly positive tokens. The largest cluster is assumed to be the negative token cluster, and the remaining clusters are merged to form the possibly positive token set P .</p><p>4. We include the topmost %1 outlier tokens based on the outlier scores provided by the GLOSH algorithm. Let T be the most %1 outlier tokens we define the extended positive token set such that P = P ? T .</p><p>Step 1 is performed only once but steps 2 to 4 are executed at each active learning iteration. A token x is estimated to have a positive annotation if and only if x ? P , which is constructed as described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Total Positive Sum Score</head><p>Here we propose to use only the possibly positive ones instead of all tokens. Therefore, the P set which is constructed a part of the corresponding iteration, is used. This approach, which we call as the Total Positive Sum (total-pos), is shown below:</p><formula xml:id="formula_7">? tp (x) = 1?i?Nx xi?P ? (x i ).<label>(8)</label></formula><p>Here, P are the set of tokens that are estimated to be positively annotated at the current iteration. This is very similar to Equation 7, as the only difference is, this one do the calculations over a subset of tokens (possibly positive ones), not all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Density Normalization</head><p>The second extension we propose promotes selection of sentences with typical length in the distribution. When calculating a query metric for a sentence, if no normalization is applied, the aggregated token score favors longer sentences <ref type="bibr">[Tomanek, 2010, Culotta and</ref><ref type="bibr" target="#b6">McCallum, 2005]</ref>. The most common way to prevent this is to normalize the result with the number of tokens in the sentence <ref type="bibr" target="#b12">[Hwa, 2004</ref><ref type="bibr" target="#b2">, Baldridge and Osborne, 2004</ref><ref type="bibr" target="#b37">, Shen et al., 2017</ref>. This on the other hand leads the AL method to choose too short sentences (shown in the Section 6). This is also not desirable as choosing shorter sentences requires more iterations to exceed a predetermined performance level and therefore more manual labeling. Therefore, while querying extremely long sentences should be avoided, querying too short sentences should be avoided as well.</p><p>The second modification we propose deals with this issue. We would like to query sentences that are not too short or too long compared to other sentences in the dataset. For this purpose, we directly use the dataset's distribution of the token count and sample a sentence in proportion to its token count frequency. Let N x be the number of tokens in the sentence. We first estimate the probability density of the token count of sentences in the dataset, let this distribution be p L . The modified evaluation metric ? tp (x) is multiplied with p L (N x ). This way sentences are ranked based on the values of p L (N x )? tp (x). Thus, sentences with more probable token counts are preferred. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Density Normalized Positive Sum Score</head><p>Our second proposed strategy is the uncertainty over the tokens estimated to have positive annotations and favors sentences with an average token count. This strategy, called Density Normalized Positive Sum Score (dnorm-pos), computed as follows:</p><formula xml:id="formula_8">? dp (x) = p L (N x ) 1?i?Nx xi?P ? (x i ).<label>(9)</label></formula><p>4.3 Proposed Active Learning Query Scheme <ref type="figure" target="#fig_0">Figure 1</ref> summarizes the proposed active learning query scheme as a whole. As explained in Section 3, an active learner queries the annotator based on the sentence score ? at each iteration. Both Density Normalized Positive Sum Score and Total Positive Sum Score approaches require constructing the positive token set P . As labeled set L is updated at each iteration, the semi-supervised embeddings are updated with the labeled set P is computed at each iteration as described in Section 4.1.1. Subsequently, Total Positive Sum Score is calculated using desired uncertainty measure ? as shown in Section 4.1.2. Finally, density normalization is applied as explained in Section 4.2.</p><p>5 Experimental Setting</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baseline Methods</head><p>The proposed uncertainty-based querying methods are compared to the following commonly used baselines and strong baselines proposed herein:</p><p>? Random Selection (RS): samples sentences uniformly at random from the unlabelled pool.</p><p>? Longest Sentence Selection (LSS): is a simple baseline that selects the sentence with the highest number of tokens. ? Positive Annotation Selection (PAS): While RS and LSS are standard baselines for AL methods, we propose PAS as a strong baseline for the proposed query function. PAS is similar to the proposed function except it ignores the uncertainty of the tokens. It queries based on the number of likely positive tokens and the number of the tokens in the sentences. We define PAS as follows:</p><formula xml:id="formula_9">PAS(x) = p L (N x ) Nx i=1 1 P (x i )<label>(10)</label></formula><p>where x i is the i th token of sentence x and N x is the number of tokens in the x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Uncertainty-based Querying Methods</head><p>In addition to these simple baselines, 12 querying strategies which are constructed by combining the 4 token uncertainty measures with 3 sentence uncertainty measures are used in the experiments. AP, TE, TP and TM stand respectively for the different values of ? : A, H, T and M . These approaches are listed in the <ref type="table" target="#tab_1">Table 2</ref>. The calculation of two simple baselines (LSS and PAS) and other sentence uncertainty scores are further demonstrated in the example sentence "Angioedema due to ACE inhibitors: common and inadequately diagnosed." <ref type="figure" target="#fig_1">(Figure 2)</ref>. The last two lines in <ref type="figure" target="#fig_1">Figure 2</ref> shows the proposed aggregated uncertainty measures, ? tp for total positive sum score and ? dp for density normalized positive sum score. These proposed sentence scores are computed for different token uncertainty measures that are listed in <ref type="table" target="#tab_2">Table 3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">NER Model</head><p>In evaluating the different active learning strategies, we use Conditional Random Fields (CRF) <ref type="bibr" target="#b14">[Lafferty et al., 2001]</ref> as the NER prediction model. Combining representations from large pre-trained models with structured predictions of CRF <ref type="bibr" target="#b14">[Lafferty et al., 2001]</ref> has been shown to achieve good performance in the NER task when labeled data is not abundant <ref type="bibr" target="#b38">[Souza et al., 2019]</ref>. In this paper, we use a similar approach and use BERT representations as features in the CRF model. (1) </p><formula xml:id="formula_10">[ x 1 ][ x 2 ][ x 3 ][ x 4 ][ x 5 ][ x 6 ][ x 7 ][ x 8 ][ x 9 ] LSS(x) = 9 i=1 1 = 9 PAS(x) = p L (9) 9 i=1 1 P (x i ) = 3 p L (9) ? s (x) = max 1?i?9 ? (x i ) ? n (x) = 1 9 9 i=1 ? (x i ) ? t (x) = 9 i=1 ? (x i ) ? tp (x) = 1?i?9 xi?P ? (x i ) = ? (x 1 ) + ? (x 4 ) + ? (x 5 ) ? dp (x) = p L (9) 1?i?9 xi?P ? (x i ) = p L (9) (? (x 1 ) + ? (x 4 ) + ? (x 5 ))</formula><p>* Assuming positive annotations are estimated correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">BERT Representations</head><p>For CoNLL-03 corpus, word embeddings are extracted from the BERT-base cased model <ref type="bibr" target="#b7">[Devlin et al., 2019]</ref>. Since BC5CDR and NCBI-Disease datasets are more domain-specific, models trained on data of similar domain can be more effective. Therefore, we compare different domain-specific BERT models, namely BioBERT v1.1 cased  and Clinical-BioBERT cased <ref type="bibr" target="#b0">[Alsentzer et al., 2019]</ref> in a passive learning setting. BioBERT cased v1.1 performs better on both NCBI-Disease and BC5CDR. As expected BioBERT v1.1 also achieves significantly higher F 1 -scores (+?4) than using BERT in BC5CDR and NCBI-Disease datasets. Therefore we used BioBERT for both BC5CDR and NCBI-Disease datasets.</p><p>There are alternative ways of extracting word embeddings from a BERT model as features <ref type="bibr" target="#b7">[Devlin et al., 2019]</ref>. We compare three alternatives:</p><p>? LL: Use the last layer directly. The number of hidden units of each layer in BERT is equal to 768. Therefore, the final representation of each token is also a vector of dimension 768. ? SL4: Sum the last 4 layers. Again, each token represented with a vector of dimension 768.</p><p>? CL4: Concatenate the last 4 layers. This one results in a 768?4=3072 dimensional vector for each token.</p><p>Since we observe that the performances of the different strategies depend on the dataset, we report active learning experiment results with best performing strategy on the corresponding test data (see <ref type="table" target="#tab_4">Table 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">CRF Classification</head><p>For token-level classifications we use a Linear-Chain CRF, which is a relatively simple but surprisingly effective tagging model. For an input sentence x = x 1 , x 2 , ? ? ? , x n and corresponding sequence of predictions y = y 1 , y 2 , ? ? ? , y n , the modeled probability distribution p(x|y) has the following form:</p><formula xml:id="formula_11">p(x|y) ? Nx i=1 exp K k=1 ? k f k (y i?1 , y i , x i )<label>(11)</label></formula><p>where K is the total number of features.</p><p>CRF features of a single token consist of the following values for the token itself, the previous token, and the next token: the N-dimensional BERT embedding vector, POS-tag, whenever available 1 , the lower-cased token, the last three and the last two letters of the token, and a boolean value for each of the following checks: title, digit, and lower-case. Thus, each feature dictionary consists of (N +7)?3 = 3N +21 values 2 .</p><p>Training time scales linearly with the average number of features that goes into the token classifier. In our case, the average number of features, N , is the size of the BERT embeddings, and it is the dominating term since it can be either 768 or 3072. To reduce the run time, we project BERT embeddings to a lower-dimensional space using principal component analysis (PCA) <ref type="bibr" target="#b25">[Pearson, 1901]</ref>. We choose the number of principal components such that they collectively explain at least ?80%-?85% of the variance.</p><p>We optimize the feature weights (? k ) using L-BFGS, a limited-memory variation of the popular and robust BFGS algorithm. Due to its linear memory requirement and polynomial complexity, the L-BFGS algorithm is particularly suitable for our case where the model is trained repeatedly with hundreds of features at each AL iteration. CRFsuite <ref type="bibr" target="#b24">[Okazaki, 2007]</ref> implementation is used for the experiments.</p><p>We use the standard split of training/validation/test sets of the datasets with the following percentages; 68%-16%-16% for CoNLL-2003, 33%-33%-33% for BC5CDR, and 75%-12.5%-12.5% for NCBI-Disease. Validation sets are not used for training, they are only used to determine hyper-parameters such as the the number of iterations, training configuration of the CRF model etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">NER Experiments with the Entire Dataset</head><p>As explained above, NER setting consists of several choices like how to use the embeddings or the target dimensions for the dimensionality reduction step. In order to find the right setting for each dataset, different possibilities are explored initially using the entire dataset. In reality, of course, the entire labeled set is not accessible to the active learner. However, since our aim is to investigate the performance of each active learning query evaluation function, making the right decisions in other parts of the system will help us to better evaluate the methods. In addition to the three types of embedding combinations (LL, SL4 and CL4), the following arbitrarily chosen three values 300, 256, and 200 are tried as possible target dimensions for PCA. The results of the experiments are summarized in <ref type="table" target="#tab_4">Table 4</ref>. These experiments guide us to choose the optimum NER setting for each dataset. We perform active learning experiments by using the model achieving the highest F 1 -score on test split for the corresponding dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Active Learning Setup</head><p>For the active learning task, the classical setup described in Section 3 is used. For the initial model set-up, 2 m sentences are selected from the set U randomly, where m is an integer which depends on the input dataset. These sentences (q 0 ) are first included in the set L and the first NER model is trained with this initial annotated set. All the compared methods starts with the same initial label set.</p><p>During the querying step increasing the batch size is a common practice since it becomes harder to observe a performance improvement at later stages . We define the batch size at step j as |q j | = 2 j+m .</p><p>Each experiment is repeated nine times with a randomly selected initial labeled sets. Since, initial NER models may effect the performances of active learning methods, we report the average F 1 -scores over these nine runs. Implementation of active learning framework and methods together with experiment scripts and configuration files are all publicly available 3 . All results can be reproduced with the shared configurations files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>This section will summarize the experimental results of different active learning query strategies on three NER datasets.</p><p>In evaluating the query strategies, we use two different cost measures. As the entire sentence is sent for annotation and all tokens in the sentence are annotated at once, one way of assessing the annotation cost is to directly use the number of sentences queried <ref type="bibr" target="#b47">, Yao et al., 2009</ref><ref type="bibr" target="#b13">, Kim et al., 2006</ref><ref type="bibr" target="#b19">, Liu et al., 2020a</ref>. When a single sentence is queried at each iteration, the number of annotated sentences is equivalent to the number of active learning iterations. Although this sentence-based cost calculation acknowledges the fact that sentences are reviewed at once, it does not take into account that different sentences contain a different number of tokens <ref type="bibr" target="#b1">[Arora et al., 2009</ref><ref type="bibr" target="#b11">, Haertel et al., 2008</ref>. An alternative strategy is to measure the cost of labeling with the number of tokens annotated <ref type="bibr" target="#b36">[Shen et al., 2004</ref><ref type="bibr" target="#b28">, Reichart et al., 2008</ref><ref type="bibr" target="#b37">, Shen et al., 2017</ref>. In this paper, we use both sentence-based and token-based cost evaluation to get a deeper insight into the merits and weaknesses of different active learning query strategies.</p><p>We compare three baseline methods and twenty active learning querying strategies. Among the three standard baseline methods, one of them, the positive annotation selection (PAS) approach, is also proposed herein. Eight of the compared twenty strategies are proposed in this paper; the rest of the twelve are strong baselines that these methods are compared. The F1 scores of all methods compared at the same number of annotated sentences are available in Appendix S1. We summarize these results in <ref type="table" target="#tab_5">Table 5</ref>, by taking the mean of the four token uncertainty measures: assignment probability (AP), token entropy (TE), token probability (TP), and token margin (TM), for each sentence level uncertainty score. d Average F 1 -score of tpTE, tpTP, tpTM and tpAP. e Average F 1 -score of dpTE, dpTP, dpTM and dpAP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Comparison of Different Baselines</head><p>The first three rows in <ref type="table" target="#tab_5">Table 5</ref> list the performances for the three baselines, the middle three rows display active learning query strategies used previously for NER, and the last two rows present the results of the proposed active learning strategies. In this table, for each dataset, results from the last four iterations before convergence are shown, and performances are compared at the same cost, where cost is measured by the number of sentences annotated. The first thing we notice is that in most cases, all query methods outperform baselines. There are few exceptions; for example, normalized method can fall behind baselines in early rounds of AL iterations. This could be because normalized approach chooses shorter sentences that result in a much fewer number of annotated tokens to train with when the same number of sentences are annotated.</p><p>Among the three baselines (RS, LSS, and PAS), there is not a clear winner that outperforms all other baselines consistently. One unexpected behavior we observe is that RS consistently performs better than LSS and PAS in early iterations across all datasets. We expect LSS to be better, especially in early rounds since it selects longer sentences as more tokens will be annotated at early iterations compared to other approaches. However, they do not. The reason could be that in these datasets, long sentences may not contain any positive tokens useful for the classification. To understand the behavior of these baselines more, we examine the results with the second cost measure, the number of annotated tokens. <ref type="figure" target="#fig_2">Figure 3</ref> compares F1 scores of the three baselines at a fixed number of tokens annotated for three datasets. When compared at the same number of tokens annotated, RS is a clear winner compared to PAS and LSS. Both LSS and PAS are likely to choose longer sentences; therefore, more tokens are annotated. Even though PAS contains some slight normalization which seems to help in some cases compared to LSS, it is not as good as the RS when the cost is measured with the annotated number of tokens.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Affect of Focusing on Positive Tokens</head><p>When we compare the other active learning query strategies based on sentence-based cost evaluation, no single strategy outperforms all others across all datasets <ref type="table" target="#tab_5">(Table 5)</ref>. However, among all methods, the proposed total-pos is either the best or the second-best across all datasets and iterations (12 out of 12). Recall that total-pos uses the predicted positive set while total uses all tokens in evaluating a sentence's uncertainty (See Section 4.1.2). These two metrics are not affected by different sentence lengths normalizations. Therefore, they are favored in sentence-based evaluation. While in the sentence-based cost evaluation , total-pos yields similar performances, when token annotated cost is taken into account, clearly the total-pos outperforms total in the ConNLL-03 and BC5CDR datasets as seen in <ref type="figure" target="#fig_6">Figure 4</ref>. In the third dataset (NCBI-Disease), both approaches yield similar learning curves. The NCBI-Disease dataset contains only one type of positive token and among the three datasets, it is the one with the lowest percentage of positive tokens. This class imbalance may have led to difficulty in estimating the positive token clusters accurately. Overall, for the two datasets, the proposed total-pos seems to be a better alternative compared to total providing evidence that focusing on positive tokens' uncertainties is a better strategy than focusing on all tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Comparison of Different Sentence Length Normalization Techniques</head><p>Of the different sentence normalization cases, dnorm-pos consistently performs better than the normalized approach when the number of sentences is the cost metric <ref type="table" target="#tab_5">(Table 5</ref>). Thus normalizing using positive tokens and using the sentence length density distribution is a much better approach than merely normalizing based on the number of tokens. We should also note that normalized consistently yields the lowest scores among all five active learning strategies, indicating that sentence normalization is not a good strategy at all. <ref type="figure" target="#fig_9">Figure 5</ref> also displays the performance of these two strategies with normalization with respect to number of annotated tokens. According to the <ref type="figure" target="#fig_9">Figure 5</ref>, dnorm-pos consistently outperforms normalized in CoNLL-03 dataset and slightly this time in NCBI-Disease dataset. Although normalized is marginally ahead for a few iterations, the two are comparably in BC5CDR dataset. Overall these results indicate that dnorm-pos is better than normalized for both cost measures.   Finally, we compare the two proposed approaches: dnorm-pos and total-pos. When the sentence is the evaluation metric, as seen in <ref type="table" target="#tab_5">Table 5</ref> total-pos either performs similarly or slightly better than dnorm-pos, possibly because it selects longer sentences. However, when we compare them in terms of token-annotated cost, dnorm-pos reaches the same level of F1 scores with few token annotations as seen in <ref type="figure" target="#fig_12">Figure 6</ref>.        <ref type="table">Table 6</ref> lists the approaches that reach a specified F1 score with the least number of annotated tokens for a given uncertainty measure. Since the F1 score depend on the dataset, different F1 score values are picked for each dataset. The methods that use the least number of annotated sentences are shown in bold, and the method that reaches the predefined F1 score level first with the least number of annotated tokens is also shown in italics. According to <ref type="table">Table 6</ref>, the aggregation method (along within the columns of the table) is usually consistent, but the best methods differ for datasets and for different F1 levels (along the rows of table). This clearly indicates that aggregation methods have huge impact on the performances of the AL query methods. Another important observation is the good performance of dnorm-pos across different uncertainty measures and datasets, see entries that start with "dp". The most notable performance improvement achieved by dnorm-pos, is observed in CoNLL-03 dataset, which has the highest positive annotation to negative annotation ratio among all datasets <ref type="table" target="#tab_0">(Table 1)</ref>. At higher F1 levels, dnorm-pos methods outperform all other AL methods and baselines both in sentence and token cost metrics. In BC5CDR, dnorm-pos performs well; in many cases, it is not only cost-efficient in terms of annotated tokens, but it is also cost-efficient when cost metric is number of annotated sentences. Results on the NCBI-Disease dataset is rather mixed, but as seen in <ref type="figure" target="#fig_0">Figure S1</ref>, at higher F1 scores, density-based normalization and positive based scores dominate. <ref type="figure" target="#fig_0">Figure S1</ref> in Appendix presents the performance of all AL approaches and the Random Sampling approach with respect to the number of annotated tokens. <ref type="table">Table 6</ref>: Comparison of aggregation methods for each uncertainty measure. a The method which achieves indicated F 1 -score with least number of tokens is reported. Proposed methods are italicised. In each column, method that requires least number of sentences to achieve indicated F 1 -score is stated in bold. The abbreviations are listed in <ref type="table" target="#tab_2">Table 3</ref> and  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Overall Comparison</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Named Entities Organization Miscellaneous Location Other Person</head><p>The query function relies on identifying the likely positive set before the classification step. We solve this step-through clustering of tokens based on their BERT embeddings (as detailed in Section 4.1.1). Our assumption is that the largest cluster is the negative token set. In this section we inspect how well this step works. <ref type="figure" target="#fig_16">Figure 7</ref> demonstrates an example of CoNLL-03 BERT embeddings reduced to two-dimensions by applying semi-supervised UMAP with only %2 of labeled sentences (randomly selected). It can be seen from <ref type="figure" target="#fig_16">Figure 7a</ref>, negative tokens form a large and dense cluster in the two-dimensional embedding space. We then calculate the precision and recall of the likely positive set. This step achieves .95/.86/.95 precision for negative tokens and .92/.73/.84 recall for the positive tokens for CoNLL-03/BC5CDR/NCBI-Dz. datasets respectively at the first iteration without any labeled set. In contrast to the relatively high precision scores of the negative tokens, precision scores of the positive tokens are .21/.11/.9/, respectively. However, this is not a major problem for our end goal. Because the false-positive other annotated tokens are usually the stray data points and small outlier clusters and misclassification of them does not necessarily lead to missing/ignoring informative tokens. Furthermore, one can also argue that querying negative tokens whose embeddings differ from the rest of the negatives tokens would be informative for the NER model.</p><p>We tune the hyper-parameters of the UMAP and HDBSCAN in the first iteration when there is no labeled set for computational efficiency. The performance of identifying a likely positive set could increase if they are tuned at every step. As an example, for CoNLL-03, we indeed achieved 0.98 recision for negative annotations and 0.97 recall for the positive annotations by using the method described above when only 1% of tokens are annotated, and hyper-parameters are re-tuned. However, since tuning is expensive and the recall of positive tokens is quite high already; we did not do this. With larger resources, the step could be further improved with hyper-tuning at each iteration.</p><p>As mentioned in the Section 4.3 and Section 4.1.1, we use semi-supervised extension of UMAP. The quality of the low dimensional embeddings tends to improve as the number of the labeled data instances increases at each step <ref type="bibr" target="#b30">[Sainburg et al., 2021]</ref>. For example, when %20 of sentences are annotated, we succeed in improving precision scores of negative tokens from .86/.95 to .91/.96, respectively, for BC5CDR and NCBI-Disease. Similarly, recall scores of the positive tokens increased from .73/.84 to .74/.88. Consequentially, initial F 1 -scores .43/.34/.39 reached to .54/.46/.42, respectively for CoNLL-03, BC5CDR and NCBI-Dz. However, we couldn't observe any further performance improvement with more labeled tokens as opposed to our expectations. Therefore, in a setting with limited computational resources, one may prefer to use unsupervised UMAP and could compute low dimensional embeddings only once instead of every iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we focus on active learning for NER. One challenge of applying NER in active learning is the abundance of negative tokens. Uncertainty-based sentence query functions aggregate the scores of the tokens in a sentence, and since the negative tokens' uncertainty scores dominate the overall score, they shadow the informative, positive tokens. In this work, we propose strategies to overcome this by focusing on the possible positive tokens. To identify positive tokens, we use a semi-supervised clustering strategy of tokens' BERT embeddings. We experiment with several strategies where the sentence uncertainty score focuses on positive tokens and show empirically on multiple datasets that this is useful.</p><p>A second challenge of querying sentences with NER is related to the length of the sentences. Longer sentences that contain more tokens can bring more information at once; however, the annotation cost is higher. Normalizing sentences with the tokens they contain, on the other hand, yields to querying too short sentences. We propose to normalize the scores such that sentences with the typical length for the dataset are queried more often. We evaluate the suggested methods based on both sentence and token-based cost analysis. Overall, we believe the work presented here can support active learning efforts in the NER task. <ref type="figure" target="#fig_0">Figure S1</ref>: Average F 1 -scores of different aggregation methods and the baselines with respect to the total number of annotated tokens.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Summary of the proposed active learning framework for the NER task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>An example sentence and corresponding computations of different query evaluation functions * .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Average F 1 -scores of RS, LSS and PAS methods with respect to the total number of annotated tokens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Average F 1 -scores of total and total-pos methods with respect to the total number of annotated tokens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Average F 1 -scores of norm and dnorm-pos methods with respect to the total number of annotated tokens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>FFigure 6 :</head><label>6</label><figDesc>Average F 1 -scores of total-pos and dnorm-pos methods with respect to the total number of annotated tokens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 7 :</head><label>7</label><figDesc>BERT embeddings of CoNLL-03 reduced to two dimension by semi-supervised UMAP, %2 labeled.(a) Entire corpus.(b) Tokens with positive annotations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Details and statistics of the datasets. Average number of tokens per sentence. d Average number of positive tokens per sentence. e Percentage of positive tokens to all tokens.</figDesc><table><row><cell>Dataset</cell><cell>Total # Sentences a</cell><cell>Total # Tokens b</cell><cell>Average # Token c</cell><cell>Average # Pos. Token d</cell><cell>Percentage Pos. Token e</cell></row><row><cell>CoNLL-03</cell><cell>17,291</cell><cell>254,983</cell><cell>14.75</cell><cell>2.45</cell><cell>17%</cell></row><row><cell>BC5CDR</cell><cell>9,357</cell><cell>242,920</cell><cell>25.96</cell><cell>3.03</cell><cell>12%</cell></row><row><cell>NCBI-Dz.</cell><cell>6,372</cell><cell>160,583</cell><cell>25.20</cell><cell>2.08</cell><cell>8%</cell></row><row><cell cols="6">? CoNLL-03 [Tjong Kim Sang and De Meulder, 2003]: This dataset contains four different named entities;</cell></row><row><cell cols="6">namely Person, Organization, Location and Miscellaneous with the following percentages 33%, 28%,</cell></row><row><cell cols="2">24% and 14% respectively.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">? BC5CDR [Li et al., 2016a]: BioCreative V CDR dataset contains equal distribution of Disease and Chemical</cell></row><row><cell>tags.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>? NCBI-Disease</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>a Total number of sentences.b Total number of tokens.c</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Uncertainty-based querying methods and their abbreviations used throughout the text.</figDesc><table><row><cell></cell><cell>Single Most Uncertain</cell><cell>Normalized Sum</cell><cell>Total Sum</cell></row><row><cell></cell><cell>(single)</cell><cell>(normalized)</cell><cell>(total)</cell></row><row><cell>Assignment</cell><cell>sAP</cell><cell>nAP</cell><cell>tAP</cell></row><row><cell>Probability</cell><cell>Single Assignment Probability</cell><cell>Normalized Assignment Probability</cell><cell>Total Assignment Probability</cell></row><row><cell>Token</cell><cell>sTE</cell><cell>tTE</cell><cell>nTE</cell></row><row><cell>Entropy</cell><cell>Single Token Entropy</cell><cell>Normalized Token Entropy</cell><cell>Total Token Entropy</cell></row><row><cell>Token</cell><cell>sTP</cell><cell>nTP</cell><cell>tTP</cell></row><row><cell>Probability</cell><cell>Single Token Probability</cell><cell>Normalized Token Probability</cell><cell>Total Token Probability</cell></row><row><cell>Token</cell><cell>sTM</cell><cell>nTM</cell><cell>tTM</cell></row><row><cell>Margin</cell><cell>Single Token Margin</cell><cell>Normalized Token Margin</cell><cell>Total Token Margin</cell></row><row><cell cols="2">See Section 3.2 and Section 5.2 for definitions.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Proposed aggregated uncertainty measures for each token uncertainty measure.</figDesc><table><row><cell></cell><cell>Total Positive Sum</cell><cell>Density Normalized Positive Sum</cell></row><row><cell></cell><cell>(total-pos)</cell><cell>(dnorm-pos)</cell></row><row><cell>Assignment</cell><cell>tpAP</cell><cell>dpAp</cell></row><row><cell>Probability</cell><cell>Total Positive Assignment Probability</cell><cell>Density Normalized Positive Assignment Probability</cell></row><row><cell>Token</cell><cell>tpTE</cell><cell>dpTE</cell></row><row><cell>Entropy</cell><cell>Total Positive Token Entropy</cell><cell>Density Normalized Positive Token Entropy</cell></row><row><cell>Token</cell><cell>tpTP</cell><cell>dpTP</cell></row><row><cell>Probability</cell><cell>Total Positive Token Probability</cell><cell>Density Normalized Positive Token Probability</cell></row><row><cell>Token</cell><cell>tpTM</cell><cell>dpTM</cell></row><row><cell>Margin</cell><cell>Total Positive Token Margin</cell><cell>Density Normalized Positive Token Margin</cell></row><row><cell cols="3">See Section 4.1.2, Section 4.2.1 and Section 5.2 for definitions.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>x := [[Angioedema] B ] Disease due to [[ACE] B [inhibitors:] I ] Chemical common and inadequately diagnosed.</figDesc><table><row><cell>(2) [Angioedema ][ due ][ to ][ ACE ][ inhibitors: ][ common ][ and ][ inadequately ][ diagnosed ]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison of approaches for extracting BERT embeddings based on passive learning F 1scores. a First header row indicates the dimension of embeddings. Second header row stands for the strategies used to obtain embeddings from BERT. For BC5CDR and NCBI-Disease BioBERT cased v1.1, for CONLL-03 BERT cased base.According toTable 4, models trained with reduced dimensions improve the predictive performance in many cases. Using the original high-dimensional representation obtained by concatenating the last four-layers of BERT (CL4) resulted in 92.7 F 1 -score for CoNLL-2003 dataset, whereas reducing the 3072 dimensional representations to 256 dimensions improved the overall performance by ?0.9 points. Similarly, reducing the 3072 dimensional original representations of CL4 to 200 dimension increases the F 1 -score by 2.3 and 0.3 respectively for NCBI-Disease and BC5CDR datasets. For all three datasets, the CL4 representation consistently outperforms both the SL4 and LL in reduced forms.</figDesc><table><row><cell></cell><cell>3072 768 768</cell><cell>reduced-300</cell><cell>reduced-256</cell><cell>reduced-200</cell></row><row><cell>Dataset</cell><cell cols="4">CL4 b SL4 c LL d CL4 SL4 LL CL4 SL4 LL CL4 SL4 LL</cell></row><row><cell cols="5">CoNLL-03 92.7 92.2 92.7 93.3 71.6 92.7 93.6 65.6 92.9 93.2 60.7 92.7</cell></row><row><cell>BC5CDR</cell><cell cols="4">85.7 85.2 85.3 85.9 85.8 85.1 85.7 85.8 85.0 86.0 85.5 85.1</cell></row><row><cell cols="5">NCBI-Dz. 82.2 80.5 82.6 84.0 82.4 82.2 84.4 84.2 82.4 84.5 83.6 83.5</cell></row></table><note>ab Concatenate last four layer.c Sum last four layer.d Use last layer directly.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>The F 1 -scores of the baseline methods (first three rows) and average F 1 -scores of different sentence score aggregation strategies in the last four iterations before convergence. Percentage of sentences queried is provided for corresponding iterations under the iteration number. Best performing methods are highlighted in red and second-best performing ones in blue. Average F 1 -score of nTE, nTP, nTM and nAP.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">CoNLL-03</cell><cell></cell><cell></cell><cell cols="2">BC5CDR</cell><cell></cell><cell></cell><cell cols="2">NCBI-Dz.</cell><cell></cell></row><row><cell>AL</cell><cell>itr. 8</cell><cell>itr. 9</cell><cell>itr. 10</cell><cell>itr. 11</cell><cell>itr. 6</cell><cell>itr. 7</cell><cell>itr. 8</cell><cell>itr. 9</cell><cell>itr. 6</cell><cell>itr. 7</cell><cell>itr. 8</cell><cell>itr. 9</cell></row><row><cell>Methods</cell><cell>%4</cell><cell>%9</cell><cell>%17.5</cell><cell>%35</cell><cell>%1.5</cell><cell>%3</cell><cell>%6</cell><cell>%11</cell><cell>%5</cell><cell>%10</cell><cell>%19</cell><cell>%39</cell></row><row><cell>RS</cell><cell cols="3">76.5 79.0 81.7</cell><cell>84.7</cell><cell cols="8">66.9 69.9 73.7 79.1 61.1 64.0 69.5 78.2</cell></row><row><cell>LSS</cell><cell cols="3">66.3 70.1 73.6</cell><cell>74.3</cell><cell cols="8">62.6 65.2 73.4 79.8 51.8 61.6 71.3 78.6</cell></row><row><cell>PAS</cell><cell cols="3">65.9 69.5 82.7</cell><cell>87.2</cell><cell cols="8">54.6 59.4 66.2 75.1 57.5 61.7 69.7 78.2</cell></row><row><cell>?(single) a</cell><cell cols="3">77.5 84.9 90.1</cell><cell>92.6</cell><cell cols="8">70.8 72.8 78.2 82.6 60.6 68.4 76.6 81.5</cell></row><row><cell>?(total) b</cell><cell cols="3">78.3 86.5 90.8</cell><cell>92.8</cell><cell cols="8">69.0 75.2 80.3 83.5 60.2 70.9 76.7 81.3</cell></row><row><cell cols="4">?(normalized) c 63.8 75.0 85.4</cell><cell>90.1</cell><cell cols="8">69.2 71.6 76.8 82.0 54.8 60.0 72.5 79.9</cell></row><row><cell cols="4">?(total-pos) d 79.2 86.4 90.5</cell><cell>92.6</cell><cell cols="8">69.7 74.4 79.5 83.0 60.7 69.8 76.8 81.3</cell></row><row><cell cols="4">?(dnorm-pos) e 75.7 84.3 89.8</cell><cell>92.4</cell><cell cols="8">70.8 73.0 77.2 82.0 57.2 66.2 75.3 81.1</cell></row></table><note>a Average F 1 -score of sTE, sTP, sTM and sAP.b Average F 1 -score of tTE, tTP, tTM and tAP.c</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="2">CoNLL-03</cell><cell></cell><cell></cell><cell cols="2">BC5CDR</cell><cell></cell><cell></cell><cell>NCBI-Dz.</cell></row><row><cell>Uncertainty Measure</cell><cell cols="2">60.0 70.0</cell><cell>80.0</cell><cell>90.0</cell><cell>50.0</cell><cell>60.0</cell><cell>70.0</cell><cell>80.0</cell><cell>50.0</cell><cell>60.0 70.0 80.0</cell></row><row><cell>Token prob.</cell><cell>sTP</cell><cell cols="4">sTP dpTP dpTP dpTP</cell><cell>nTP</cell><cell cols="2">dpTP nTP</cell><cell>sTP</cell><cell>sTP</cell><cell>tTP</cell><cell>nTP</cell></row><row><cell cols="11">Token margin sTM sTM dpTM dpTM dpTM nTM nTM nTM sTM tpTM tTM sTM</cell></row><row><cell cols="2">Token entropy sTE</cell><cell>sTE</cell><cell cols="6">dpTE dpTE dpTE dpTE dpTE nTE</cell><cell>nTE</cell><cell>sTE</cell><cell>sTE dpTE</cell></row><row><cell>Assign. prob.</cell><cell>sAP</cell><cell cols="4">sAP dpAP dpAP dpAP</cell><cell>nAP</cell><cell>nAP</cell><cell cols="3">tAP dpAP sAP</cell><cell>tAP dpAP</cell></row></table><note>a Comparison is done by using interpolated values.6.5 Performance of Identifying Positive Token Set in the Query Step</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Only CoNLL-03 contains parts of speech tags. BC5CDR and NCBI-Disease do not involve POS-tags.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">(3N +6)?3 = 3N +18 for the datasets which do not contain POS tags.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/bo1929/anelfop</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S1 Appendix</head> <ref type="table">Table S1</ref><p>: The F 1 -scores of the baseline methods (first three rows) and uncertainty scores together with their corresponding sentence score aggregation strategies average F 1 -scores in the last four iterations before convergence. Percentage of sentences queried labeled set is provided for corresponding iterations under the iteration number. The first part rows list the performances for the three baselines, the middle three parts display active learning query strategies used previously for NER and the last two parts present the results of the proposed active learning strategies. In this table, for each dataset results from the last four iterations before convergence are shown and performances are compared at the same cost, where cost is measured by the number of sentences annotated.</p><p>CoNLL-03 BC5CDR NCBI-Dz. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AL</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Publicly available clinical BERT embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alsentzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Boag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jindi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mcdermott</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-1909</idno>
		<ptr target="https://aclanthology.org/W19-1909" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Clinical Natural Language Processing Workshop</title>
		<meeting>the 2nd Clinical Natural Language Processing Workshop<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="page" from="72" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Estimating annotation cost for active learning in a multi-annotator environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Ros?</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/W09-1903" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing</title>
		<meeting>the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="18" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Active learning and the total cost of annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Osborne</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W04-3202" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Density-based clustering based on hierarchical density estimates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moulavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<idno>978-3-642-37456-2</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining</title>
		<editor>J. Pei, V. S. Tseng, L. Cao, H. Motoda, and G. Xu</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="160" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hierarchical density estimates for data clustering, visualization, and outlier detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moulavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<idno type="DOI">10.1145/2733381</idno>
		<ptr target="https://doi.org/10.1145/2733381" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A study of active learning methods for named entity recognition in clinical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Lasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Denny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbi.2015.09.010</idno>
		<ptr target="https://doi.org/10.1016/j.jbi.2015.09.010" />
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="11" to="18" />
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reducing labeling effort for structured prediction tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th National Conference on Artificial Intelligence</title>
		<meeting>the 20th National Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
	<note>AAAI&apos;05</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://aclanthology.org/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Special report: Ncbi disease corpus: A resource for disease name recognition and concept normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Dogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<idno>1532-0464</idno>
	</analytic>
	<monogr>
		<title level="j">J. of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2014-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Minimizing manual annotation cost in supervised training from corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Engelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<idno type="DOI">10.3115/981863.981905</idno>
		<ptr target="https://doi.org/10.3115/981863.981905" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual Meeting on Association for Computational Linguistics, ACL &apos;96</title>
		<meeting>the 34th Annual Meeting on Association for Computational Linguistics, ACL &apos;96<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="319" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Results of the active learning challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Cawley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lemaire ; I. Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cawley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lemaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Statnikov</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v16/guyon11a.html" />
	</analytic>
	<monogr>
		<title level="m">Active Learning and Experimental Design workshop In conjunction with AISTATS 2010</title>
		<meeting><address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-05-16" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="19" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Assessing the costs of sampling methods in active learning for annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haertel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ringger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Seppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcclanahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers, HLT-Short &apos;08</title>
		<meeting>the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers, HLT-Short &apos;08<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="65" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sample selection for statistical parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hwa</surname></persName>
		</author>
		<idno type="DOI">10.1162/0891201041850894</idno>
		<ptr target="https://doi.org/10.1162/0891201041850894" />
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="276" />
			<date type="published" when="2004-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">MMR-based active machine learning for bio named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N06-2018" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers</title>
		<meeting>the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers<address><addrLine>New York City, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006-06" />
			<biblScope unit="page" from="69" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML &apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML &apos;01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
	<note>ISBN 1558607781</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btz682</idno>
		<ptr target="http://dx.doi.org/10.1093/bioinformatics/btz682" />
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2019-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Heterogenous uncertainty sampling for supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Catlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on International Conference on Machine Learning, ICML&apos;94</title>
		<meeting>the Eleventh International Conference on International Conference on Machine Learning, ICML&apos;94<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
	<note>ISBN 1558603352</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">BioCreative V CDR task corpus: a resource for chemical disease relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sciaky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Mattingly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Wiegers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1093/database/baw068</idno>
		<ptr target="https://doi.org/10.1093/database/baw068.baw068" />
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Active learning for dependency parsing with partial annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1033</idno>
		<ptr target="https://aclanthology.org/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="16" to="1033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Ltp: A new active learning strategy for crf-based named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A survey on contextual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blunsom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roberta</surname></persName>
		</author>
		<title level="m">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An experimental comparison of active learning strategies for partially labeled sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Arti?res</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1097</idno>
		<ptr target="https://www.aclweb.org/anthology/D14-1097" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="898" to="906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Umap: Uniform manifold approximation and projection for dimension reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Melville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Crfsuite: a fast implementation of conditional random fields (crfs)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Okazaki</surname></persName>
		</author>
		<ptr target="http://www.chokkan.org/software/crfsuite/" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">on lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="559" to="572" />
			<date type="published" when="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">To tune or not to tune? adapting pretrained representations to diverse tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-4302</idno>
		<ptr target="https://aclanthology.org/W19-4302" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)</title>
		<meeting>the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08" />
			<biblScope unit="page" from="7" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multi-task active learning for linguistic annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tomanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rappoport</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/P08-1098" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="861" to="869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Active learning for part-of-speech tagging: Accelerating corpus annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ringger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcclanahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haertel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Busby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carmen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Seppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lonsdale</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/W07-1516" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Linguistic Annotation Workshop</title>
		<meeting>the Linguistic Annotation Workshop<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Parametric UMAP Embeddings for Representation and Semi-supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sainburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Gentner</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco_a_01434</idno>
		<idno>0899-7667</idno>
		<ptr target="https://doi.org/10.1162/neco_a_01434" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Active hidden markov models for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Scheffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Decomain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wrobel</surname></persName>
		</author>
		<idno>978-3-540-44816-7</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Intelligent Data Analysis</title>
		<editor>F. Hoffmann, D. J. Hand, N. Adams, D. Fisher, and G. Guimaraes</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">From theories to queries: Active learning in practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles ; I. Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cawley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lemaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Statnikov</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v16/settles11a.html" />
	</analytic>
	<monogr>
		<title level="m">Active Learning and Experimental Design workshop In conjunction with AISTATS 2010</title>
		<meeting><address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-05-16" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An analysis of active learning strategies for sequence labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;08</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;08<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1070" to="1079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Active learning with real annotation costs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Friedland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS 2008 Workshop on Cost-Sensitive Learning</title>
		<meeting>the NIPS 2008 Workshop on Cost-Sensitive Learning</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
		<idno type="DOI">10.1145/584091.584093</idno>
		<ptr target="https://doi.org/10.1145/584091.584093" />
	</analytic>
	<monogr>
		<title level="j">SIGMOBILE Mob. Comput. Commun. Rev</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="55" />
			<date type="published" when="2001-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multi-criteria-based active learning for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.3115/1218955.1219030</idno>
		<ptr target="https://doi.org/10.3115/1218955.1219030" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL &apos;04</title>
		<meeting>the 42nd Annual Meeting on Association for Computational Linguistics, ACL &apos;04<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page">589</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep active learning for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kronrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-2630</idno>
		<ptr target="https://aclanthology.org/W17-2630" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Representation Learning for NLP</title>
		<meeting>the 2nd Workshop on Representation Learning for NLP<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-08" />
			<biblScope unit="page" from="252" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Portuguese named entity recognition using bert-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lotufo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Active learning for natural language parsing and information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Califf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth International Conference on Machine Learning, ICML &apos;99</title>
		<meeting>the Sixteenth International Conference on Machine Learning, ICML &apos;99<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="406" to="414" />
		</imprint>
	</monogr>
	<note>ISBN 1558606122</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Using bert and augmentation in named entity recognition for cybersecurity domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tikhomirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Loukachevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sirotina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dobrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Processing and Information Systems</title>
		<editor>E. M?tais, F. Meziane, H. Horacek, and P. Cimiano</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="16" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Tjong Kim Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F. De</forename><surname>Meulder</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W03-0419" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
		<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Resource-aware annotation through active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tomanek</surname></persName>
		</author>
		<ptr target="http://eldorado.tu-dortmund.de:8080/handle/2003/27172" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>Dortmund University of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Annotation time stamps -temporal metadata from the linguistic annotation process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tomanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hahn ; N. Calzolari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maegaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Odijk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Piperidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tapias</surname></persName>
		</author>
		<idno>2-9517408-6-7</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA)</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Natural language processing advancements by deep learning: A survey. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torfi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Shirvani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Keneshloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tavvaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Extending multilingual BERT to low-resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.240</idno>
		<ptr target="https://aclanthology.org/2020.findings-emnlp.240" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<meeting><address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="2649" to="2656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Crf-based active learning for chinese named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICSMC.2009.5346315</idno>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE International Conference on Systems, Man and Cybernetics</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1557" to="1561" />
		</imprint>
	</monogr>
	<note>of sTE, sTP, sTM and sAP. b Average F 1 -score of tTE, tTP. tTM and tAP</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Average F 1 -score of nTE, nTP, nTM and nAP. d Average F 1 -score of tpTE, tpTP, tpTM and tpAP</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Average F 1 -score of dpTE, dpTP, dpTM and dpAP</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
