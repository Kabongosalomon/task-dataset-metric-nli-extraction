<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph Convolutional Label Noise Cleaner: Train a Plug-and-play Action Classifier for Anomaly Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Xing</forename><surname>Zhong</surname></persName>
							<email>jxzhong@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic and Computer Engineering</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic and Computer Engineering</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Intelligent Video Audio Technology</orgName>
								<address>
									<addrLine>Longgang Shenzhen</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Kong</surname></persName>
							<email>weijie.kong@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic and Computer Engineering</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Liu</surname></persName>
							<email>shanl@tencent.com</email>
							<affiliation key="aff3">
								<orgName type="department">Tencent America</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">H</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic and Computer Engineering</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic and Computer Engineering</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Graph Convolutional Label Noise Cleaner: Train a Plug-and-play Action Classifier for Anomaly Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Video anomaly detection under weak labels is formulated as a typical multiple-instance learning problem in previous works. In this paper, we provide a new perspective, i.e., a supervised learning task under noisy labels. In such a viewpoint, as long as cleaning away label noise, we can directly apply fully supervised action classifiers to weakly supervised anomaly detection, and take maximum advantage of these well-developed classifiers. For this purpose, we devise a graph convolutional network to correct noisy labels. Based upon feature similarity and temporal consistency, our network propagates supervisory signals from high-confidence snippets to low-confidence ones. In this manner, the network is capable of providing cleaned supervision for action classifiers. During the test phase, we only need to obtain snippet-wise predictions from the action classifier without any extra post-processing. Extensive experiments on 3 datasets at different scales with 2 types of action classifiers demonstrate the efficacy of our method. Remarkably, we obtain the frame-level AUC score of 82.12% on UCF-Crime.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Anomaly detection in videos has been long studied for its ubiquitous applications in real-world scenarios, e.g. intelligent surveillance, violence alerting, evidence investigation, etc. Since anomalous events are rarely seen in common environments, anomalies are often defined as behavioral or appearance patterns different from usual patterns in previous work <ref type="bibr">[6,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b12">13]</ref>. Based on this definition, a popular paradigm for anomaly detection is one-class classification <ref type="bibr" target="#b65">[66,</ref><ref type="bibr">11]</ref> (a.k.a. unary classification), i.e., to encode the usual pattern with only normal training samples. Then the distinctive encoded patterns are detected as anomalies. However, it is impossible to collect all normal behaviors in ? <ref type="figure" target="#fig_7">Figure 1</ref>: The concept of alternate optimization mechanism. Noisy labels predicted by the action classifier are utilized to train the label noise cleaner and then they are refined. The cleaned labels are reassigned to optimize the action classifier. The two training processes are executed alternatively. a dataset. Therefore some normal events might deviate from the encoded patterns, and could cause false alarms. In recent years, there has been some research <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b57">58]</ref> on an emerging binary-classification paradigm: the training data contain both anomalous and normal videos.</p><p>Following the binary-classification paradigm, we attempt to address the weakly supervised anomaly detection problem, on which only video-level anomaly labels are available in the training data. In this problem, there are neither trimmed anomalous segments nor temporal annotations for the consideration of the human-labor cost.</p><p>The weakly supervised anomaly detection problem is viewed as a multiple-instance learning (MIL) task in prior works <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b57">58]</ref>. They consider a video (or a set of snippets) as a bag, which consists of the snippets (or frames) deemed as instances, and learn instance-level anomaly labels via bag-level annotations. In this paper, we address the problem from a new perspective, formulating it as a supervised learning task under noise labels. The noise labels refer to wrong annotations of normal snippets within anomalous videos, since a video labeled as "anomaly" may contain quite a few normal clips. In such a viewpoint, we can directly train fully supervised action classifiers once the noisy labels are cleaned.</p><p>There are noticeable advantages of our noise-labeled perspective in both the training and the test phase. Instead of simply extracting offline features for MIL models, our action classifier participates in the whole learning process. During the training process, the only difference between action classifiers and fully supervised updating is the input labels. As a result, we preserve all strengths of theses action classifiers, such as well-designed structures, transferable pre-trained weights, ready-to-use source codes, etc. As for testing, the trained classifier can directly make predictions without any post-processing. It is extremely convenient and highly efficient because the feature extraction and the abnormality decision are seamlessly integrated into a single model.</p><p>Intuitively, a well-trained classifier yields the predictions with less noise, and the cleaned labels in turn help to train a better classifier. To this end, we design an alternate training procedure as <ref type="figure" target="#fig_7">Figure 1</ref> illustrates. It consists of two alternate stages, i.e., cleaning and classification. In the cleaning stage, we train a cleaner to correct the noisy predictions obtained from the classifier, and the cleaner provides refined labels with less noise. In the classification stage, the action classifier is retrained with the cleaned labels and generates more reliable predictions. Such a cyclic operation is executed several times until convergence. The main idea of our cleaner is to eliminate noise of low-confidence predictions via high-confidence ones. We devise a graph convolutional network (GCN) to establish relationships between high-confidence snippets and low-confidence ones. In the graph, snippets are abstracted into vertexes and the anomaly information is propagated through edges. During testing, we no longer require the cleaner and directly obtain snippet-wise anomaly results from the trained classifier. For verification of the general applicability of our model, we carry out extensive experiments with two types of mainstream action classifiers: a 3D-conv network C3D <ref type="bibr" target="#b58">[59]</ref> and a two-stream structure TSN <ref type="bibr" target="#b61">[62]</ref>. In addition, we evaluate the proposed approach on 3 different-scale datasets, i.e., UCF-Crime <ref type="bibr" target="#b57">[58]</ref>, ShanghaiTech <ref type="bibr" target="#b42">[43]</ref> and UCSD-Peds <ref type="bibr" target="#b34">[35]</ref>. The experimental results demonstrate that our model advances the state-of-the-art performance of weakly supervised anomaly detection.</p><p>In a nutshell, the contribution of this paper is three-fold:</p><p>? We formulate the problem of anomaly detection with weak labels as a supervised learning task under noise annotations, and put forward an alternate training framework to optimize the action classifier.</p><p>? We propose a GCN to clean noise labels. To the best of our knowledge, it is the first work to apply a GCN to correct label noise in the area of video analytics.</p><p>? We conduct experiments on 3 different-scale anomaly detection datasets with two types of action classifiers, in which the state-of-the-art performance validates the effectiveness of our approach. The source code is available at https://github.com/jx-zhong-for-academicpurpose/GCN-Anomaly-Detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Anomaly detection. As one of the most challenging problem, anomaly detection in videos has been extensively studied for many years <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr">3,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b34">35]</ref> . Most research addresses the problem under the assumption that anomalies are rare or unseen, and behaviors deviating from normal patterns are supposed to be anomalous. They attempt to encode regular patterns via a variety of statistic models, e.g. the social force model <ref type="bibr" target="#b44">[45]</ref>, the mixture of dynamic models on texture <ref type="bibr" target="#b34">[35]</ref>, Hidden Markov Models on video volumes <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b29">30]</ref>, the Markov Random Field upon spatial-temporal domain <ref type="bibr" target="#b27">[28]</ref>, Gaussian process modeling <ref type="bibr" target="#b48">[49,</ref><ref type="bibr">11]</ref>, and identify anomalies as outliers. Sparse reconstruction <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b66">67]</ref> is also another popular approach for usual pattern modeling. They utilize sparse representation to construct a dictionary for normal behavior, and detect anomalies as the ones with high reconstruction error. Recently, with the great success of deep learning, a few researchers design deep neural networks on abstraction feature learning <ref type="bibr" target="#b18">[19,</ref><ref type="bibr">12,</ref><ref type="bibr" target="#b41">42]</ref> or video prediction learning <ref type="bibr" target="#b39">[40]</ref> for anomaly detection. As opposed to the works that built their detection models on normal behavior only, there is research <ref type="bibr">[2,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b57">58]</ref> employing both usual and unusual data for model building. Among them, MIL is used for motion pattern modeling under weakly supervised setting <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b57">58]</ref>. Sultani et al. <ref type="bibr" target="#b57">[58]</ref> propose an MIL-based classifier to detect anomalies, where a deep anomaly ranking model predicts anomaly scores. Unlike them, we formulate the anomaly detection problem with weak labels as a supervised learning under noise labels, and devise an alternate training procedure to progressively promote the discrimination of action classifiers.</p><p>Action analysis. Action classification is a long standing problem in the field of computer vision, and a large body of research works <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr">10,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b62">63]</ref> have been presented. A majority of modern approaches have introduced deep architecture models <ref type="bibr">[10,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b61">62]</ref>, including the most prevailing two-stream networks <ref type="bibr" target="#b56">[57]</ref>, C3D <ref type="bibr" target="#b58">[59]</ref> and their variants <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr">10]</ref>. Up to now, deep learning based methods have achieved state-of-the-art performance. Besides action classification, some researchers recently have focused on temporal action localization <ref type="bibr" target="#b67">[68,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b15">16]</ref>. The performance metrics of temporal action detection and anomaly detection are quite different: action detection aims to find a temporal interval overlapped with the ground truth as much as possible, whereas anomaly detection aims for a robust frame-level performance under various discrimination thresholds. In this paper, we attempt to leverage the powerful action classifiers to detect anomalies in a simple and feasible way.</p><p>Learning under noisy labels. The research works <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b16">17]</ref> addressing the noise label problem can be generally divided into two categories: noise reduction and loss correction. In the case of noise reduction, they aim to correct noisy labels via formulating the noise model explicitly or implicitly, such as Conditional Random Fields (CRF) <ref type="bibr" target="#b59">[60]</ref>, knowledge graphs <ref type="bibr" target="#b36">[37]</ref>. Approaches in the latter group are developed for directly learning with label noise, utilizing correction methods for loss adjustment. Azadi et al. <ref type="bibr">[4]</ref> actively select training features via imposing a regularization term on loss function. Different from theses general approaches, our GCN is intended for videos and take advantages of the video-based characteristics.</p><p>Graph convolutional neural network. In recent years, a surge of graph convolutional networks <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b17">18]</ref> have been proposed to tackle graph-structured data. An important stream of these works is utilizing spectral graph theory <ref type="bibr">[8,</ref><ref type="bibr" target="#b13">14]</ref>, which decomposes the graph signal on the spectral domain and defines a series of parameterized filters for convolution. A number of researchers propose improvements of spectral convolutions, leading to advanced performances on tasks such as node classification and recommendation system. The goal of our label noise cleaner is classifying nodes (video snippets) in a graph (the whole video) under the supervision of high-confidence annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Statement</head><p>Given a video V = {v i } N i=1 with N snippets, the observable label Y ? {1, 0} indicates whether this video contains anomalous clips or not. Note that no temporal annotation is provided in training data. The goal of anomaly detection is to pinpoint the temporal position of abnormalities once they occurs in test videos.</p><p>Sabato and Tishby <ref type="bibr" target="#b53">[54]</ref> provide a theoretical analysis in which MIL tasks can be viewed as learning under one-sided label noise. In some prior works <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b57">58]</ref>, anomaly detection under the weak supervisory signal is described as a typical MIL problem. Therefore, we naturally cast anomaly detection from MIL formulation to noisy label setting.</p><p>MIL formulation. In this formulation, each clip v i is considered as an instance, of which the anomaly label y i is unavailable. These clips compose the positive/negative bag according to the given video-level anomaly label Y : a positive bag (Y = 1) includes at least one anomalous clip, while a negative bag (Y = 0) is entirely comprised of normal snippets. Consequently, anomaly detection is modeled as key instance detection <ref type="bibr" target="#b38">[39]</ref> under MIL, in search of positive instances v i with y i = 1. This MIL setting allows learning instance-level labels under bag-level supervision, and a set of approaches <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b57">58]</ref> is derived from this.</p><p>Noisy-labeled learning formulation. It is evident that the label Y = 0 is noiseless, since it means all snippets v i in the video V are normal:</p><formula xml:id="formula_0">Y = 0 ? y i = 0, ?v i ? V .<label>(1)</label></formula><p>However, Y = 1 is noisy because in this case the video V is partially made up of anomalous clips:</p><formula xml:id="formula_1">Y = 1 ? y i = 1, ?v i ? V .<label>(2)</label></formula><p>This is referred to as one-sided label noise <ref type="bibr">[7,</ref><ref type="bibr">9,</ref><ref type="bibr" target="#b54">55]</ref>, for the noise only appears along with Y = 1. As long as appropriately handling the label noise w.r.t. Y = 1, we are able to readily apply a variety of well-developed action classifiers to anomaly detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Graph Convolutional Label Noise Cleaner</head><p>Similar to many noisy-labeled learning approaches, our method adopts an EM-like optimization mechanism: alternately training the action classifier and the noise cleaner. At each training step of the noise cleaner, we have obtained rough snippet-wise anomaly probabilities from the action classifier, and the target of our noise cleaner is to correct low-confidence anomaly scores via high-confidence ones.</p><p>Unlike other general noise-labeled learning algorithms, our cleaner is specifically designed for videos. To the best of our knowledge, this is the first work to deploy a GCN in noise-labeled videos. In the graph convolutional network, we leverage two characteristics of a video to correct the label noise, i.e., feature similarity and temporal consistency. Intuitively, feature similarity means the anomaly snippets share some similar characteristics, while temporal consistency means anomaly snippets probably appear in temporal proximity of each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Feature Similarity Graph Module</head><p>As <ref type="figure" target="#fig_8">Figure 2</ref> depicts, features from the action classifier are first compressed with two fully connected layers to mitigate the curse of dimensionality <ref type="bibr">[5]</ref>. We model the feature similarly with an attributed graph <ref type="bibr" target="#b51">[52]</ref> </p><formula xml:id="formula_2">F = (V, E, X) ,</formula><p>where V is the vertex set, E is the edge set, and X is the attribute of vertexes. In particular, V is a video as defined in Section 3, E describes the feature similarity amongst snippets, and X ? R N?d represents the d-dimensional feature of these N snippets. The adjacency matrix A F ? R N ?N of F is defined as:  <ref type="figure" target="#fig_8">Figure 2</ref>: Overview of the training process of label noise cleaner. The action classifier extracts spatio-temporal features from anomalous video snippets and outputs noisy snippet-level labels. Snippet-level features from the classifier are compressed and fed into two graph modules to model the feature similarity and temporal consistency of snippets. In the two graphbased modules, A darker node represents higher anomaly confidence of the snippet. The output of these two models are fused and utilized to predict the snippet-level labels with less noise. The loss is updated to correct the predictive noise via high-confidence snippets.</p><formula xml:id="formula_3">A F (i,j) = exp(X i ? X j ? max(X i ? X)) ,<label>(3)</label></formula><p>where the element A F (i,j) measures the feature similarly between the i th and j th snippets. Since an adjacency matrix should be non-negative, we bound the similarity to the range (0, 1] with a normalized exponential function. Based on the graph F , snippets with similar features are closely connected, and the label assignments are propagated differently in accordance with different adjacency values.</p><p>The nearby vertexes are driven to have the same anomaly label via graph-Laplacian operations. Following Kipf and Welling <ref type="bibr" target="#b28">[29]</ref>, we approximate the graph-Laplacian with a renormalization trick:</p><formula xml:id="formula_4">A F = D F? 1 2 A F D F? 1 2 ,<label>(4)</label></formula><p>where the self-loop adjacency matrix A F = A F + I n , and</p><formula xml:id="formula_5">I n ? R N ?N is the identity matrix; D F (i,i) = j A F (i,j)</formula><p>is the corresponding degree matrix. Finally, the output of a feature similarity graph module layer is computed as:</p><formula xml:id="formula_6">H F = ?( A F XW) ,<label>(5)</label></formula><p>where W is a trainable parametric matrix, and ? is an activation function. Since the whole computational procedure is differentiable, our feature similarity graph module can be trained in an end-to-end fashion. Therefore, neural networks are capable of seamlessly incorporating the single or multiple stacked modules. Although the aforementioned procedure contains some element-wise calculations, we provide a high-efficient vectorized implementation in Appendix.</p><p>Recently, Wang and Gupta <ref type="bibr" target="#b62">[63]</ref> also have established similarity graphs to analyze a video. Nevertheless, both the goal and the method are quite different from ours: they aim to capture long-term dependencies with the similarity relations of correlated objects/regions, whereas we attempt to propagate supervisory signals with the similarity levels of entire snippets/frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Temporal Consistency Graph Module</head><p>As pointed out in <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b63">64]</ref>, temporal consistency is advantageous to many video-based tasks. The temporal consistency graph T is directly built upon the temporal structure of a video. Its adjacency matrix A T ? R N ?N is only dependent on temporal positions of the i th and j th snippets:</p><formula xml:id="formula_7">A T (i,j) = k(i, j) ,<label>(6)</label></formula><p>where k is a non-negative kernel function. Consider that the kernel is supposed to distinguish various temporal distances and closely connect the snippets in vicinity. In practice, we use an exponential kernel (a.k.a. Laplacian kernel) neatly bounded in (0, 1]:</p><formula xml:id="formula_8">k(i, j) = exp(?||i ? j||) .<label>(7)</label></formula><p>Likewise, we obtain the renormalized adjacency matrix A T as Equation 4 for the graph-Laplacian approximation, and the forward result of this module is computed as:</p><formula xml:id="formula_9">H T = ?( A T XW) ,<label>(8)</label></formula><p>where W is a trainable parametric matrix, ? is an activation function, and X is the input feature matrix. The stacked temporal consistency graph layers also can be conveniently included into neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Loss Function</head><p>Finally, the outputs of the above two modules are fused with an average pooling layer, and activated by a Sigmoid function to make the probabilistic prediction p i of each vertex in the graph, corresponding to the anomaly probability of our noise cleaner w.r.t. the i th snippet. The loss function L is based upon two types of supervision:</p><formula xml:id="formula_10">L = L D + L I ,<label>(9)</label></formula><p>where L D and L I are computed under the direct and the indirect supervision respectively. Given the rough snippetwise anomaly probabilities Y = { y i } N i=1 from the action classifier. The loss term under direct supervision is defined as a cross-entropy error over the high-confidence snippets:</p><formula xml:id="formula_11">L D = ? 1 |H| i?H [ y i ln p i + (1 ? y i ) ln (1 ? p i )] ,<label>(10)</label></formula><p>where H is the set of high-confidence snippets. We oversample each video frame with the "10-crop" augment, 1 and calculate mean anomaly probabilities y i as well as predictive variances of the action classifier. As pointed out by Kendall and Gal <ref type="bibr" target="#b26">[27]</ref>, variance measures the uncertainty of predictions. In other words, the smaller variance indicates the higher confidence. This criterion of confidence is conceptually simple yet practically effective. The indirectly supervised term is a temporal-ensembling strategy <ref type="bibr" target="#b31">[32]</ref> to further harness a small number of labeled data, because high-confidence predictions are only from a portion of the entire video. Its main idea is to smooth the network predictions of all snippets at different training steps:</p><formula xml:id="formula_12">L I = 1 N N i=1 |p i ? p i | ,<label>(11)</label></formula><p>where p i is the discount-weighted average predictions of our noise cleaner over various training epochs. There is a major difference between the original "cool start" initialization and our implementation as explained in Appendix, since we have already obtained a set of rough predictions from the action classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Alternate Optimization</head><p>The training process of our noise cleaner is merely one part of the alternate optimization. The other part, i.e., the training process of our classifier, is exactly the same as common fully supervised updating, except that the labels are snippet-wise predictions from our trained cleaner. After repeating such an alternate optimization several times, final anomaly detection results are directly predicted by the last trained classifier. Obviously, almost no change in the action classifier is required during the training or the test phase. As a result, we can conveniently train the fully supervised action classifier under weak labels, and directly deploy it for anomaly detection without all the bells and whistles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets and Evaluation Metric</head><p>We conduct the experiments upon three datasets of various scales, i.e., UCF-Crime <ref type="bibr" target="#b57">[58]</ref>, ShanghaiTech <ref type="bibr" target="#b42">[43]</ref> and UCSD-Peds <ref type="bibr" target="#b34">[35]</ref>.</p><p>UCF-Crime is a large-scale dataset of real-world surveillance videos. It has 13 types of anomalies with 1,900 long untrimmed videos, which consist of 1,610 training videos and 290 test videos.</p><p>ShanghaiTech is a medium-scale dataset of 437 videos, including 130 abnormal events on 13 scenes. In the standard protocol <ref type="bibr" target="#b42">[43]</ref>, all training videos are normal, and this setting is inappropriate for the binary-classification task. Hence, we reorganize the dataset by randomly selecting anomaly testing videos into training data and vice versa. Meanwhile, both training videos and testing ones cover all of the 13 scenes. This new split of the dataset will be available for follow-up comparisons. More details are given in Appendix.</p><p>UCSD-Peds is a small-scale dataset made up of two subsets: Peds1 has 70 videos, and Peds2 has 28 videos. Since the former is more frequently used for pixel-wise anomaly detection <ref type="bibr" target="#b65">[66]</ref>, we only conduct experiments on the latter as in <ref type="bibr" target="#b42">[43]</ref>. Similarly, the default training set does not contain anomaly videos. Following He et al. <ref type="bibr" target="#b19">[20]</ref>, 6 anomaly videos and 4 normal ones on UCSD-Peds2 are randomly included into training data, and the remaining videos constitute the test set. We also repeat this process 10 times and report the average performance.</p><p>Evaluation Metric. Following previous works <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b57">58]</ref>, we plot the frame-level receiver operating characteristics (ROC) curve and compute an area under the curve (AUC) as the evaluation metric. In the task of temporal anomaly detection, a larger frame-level AUC implies the higher diagnostic ability, as well as the robuster performance at various discrimination thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Implementation Details</head><p>Action classifiers. For verification of the general applicability of our model, we utilize two mainstream structures of action classifiers in the experiments. C3D [59] is a 3D-convolutional network. The model is pre-trained on the Sports-1M <ref type="bibr" target="#b25">[26]</ref> dataset. In the training process, we input features from its fc7 layer into our label noise cleaner. Temporal Segment Network (TSN) <ref type="bibr" target="#b61">[62]</ref> is a two-stream architecture. We choose BN-Inception <ref type="bibr" target="#b22">[23]</ref> pre-trained on  Kinetics-400 <ref type="bibr">[10]</ref> as the backbone, and extract features from its global pool layer to train our noise cleaner. The action classifiers are both implemented upon the Caffe <ref type="bibr" target="#b24">[25]</ref> platform with the same settings of video sampling and data augment as <ref type="bibr" target="#b61">[62]</ref>. In all the experiments, we keep the default settings if not specified particularly.</p><p>Label noise cleaner. After we add the author list and the acknowledgement section into our camera-ready version, this part has to be moved to Appendix because of limited space. Please refer to our Github page and Appendix. Step-1</p><p>Step-2</p><p>Step-3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3:</head><p>Step-wise performance on UCF-Crime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experiments on UCF-Crime</head><p>Under the video-level supervision, we train C3D with 18,000 iterations. As for TSN, the initial iteration number of both streams is 20,000. At each re-training step, we stop the updating procedure at 4,000 iterations.</p><p>Step-wise results. As <ref type="figure">Figure 3</ref> depicts, we report the AUC performance at each step to evaluate the efficacy of our alternate training mechanism. Even if only given videolevel labels, C3D and the RGB branch of TSN can achieve a descent performance at the Step-1. It is a wise choice for us to involve action classifiers in the training process. However, the optical flow stream of TSN is far from satisfaction, which reflects the necessity of our noise cleaner. At the following steps, the proposed approach significantly improves the detection performance of all the action classifiers. Faced with the most noise in initial predictions, the AUC performance of our optical flow branch is still boosted from 70.87% to 78.08% with a relative gain of 10.2%.</p><p>Indirect supervision. We conduct ablation studies upon the optical flow modality of TSN. First, we exclude the indirectly supervised term from the loss to verify its effectiveness. As on the 2 nd row of <ref type="table" target="#tab_0">Table 1</ref>, the performance slightly declines from 74.60% to 73.79%, but the gain on the result of Step-1 remains considerable. In the following ablations, we remove the indirect supervised term to eliminate interference.</p><p>Temporal consistency. We would like to explore two questions: Is temporal information helpful? Can our graph convolution utilize this information? By excluding the other interference factors, there is only the temporal consistency module. To remove the graph of temporal information, we fill the A T in Equation 6 with 0.5 (the mid-value of its bounds) and reproduce the alternate training procedure. As shown on the 3 rd row of <ref type="table" target="#tab_0">Table 1</ref>, the performance without temporal graph is worse than that of Step-1, in which case the GCN only memorizes the pattern of high-confidence predictions but ignores other snippets. As for the ablation on graph convolution, we observe that the independent temporal consistency module boosts the AUC to 72.93% as on the 4 th row of <ref type="table" target="#tab_0">Table 1</ref>, which demonstrates that our graph convolution really capitalizes on the temporal information.</p><p>Feature similarity. Likewise, we only reserve the feature similarity module to investigate the efficacy of similarity graphs and our convolutional operation. We first damage the feature similarity graph by setting all elements of the adjacency matrix as the mid-value. As on the 5 th row of <ref type="table" target="#tab_0">Table 1</ref>, the AUC value falls to 67.23% without the graph. After recovering the original feature similarity graph, the single feature similarity module can increase the AUC value from 70.87% to 72.44% as shown on the 6 th row of <ref type="table" target="#tab_0">Table 1</ref>. This illustrates that both similarity graphs and the convolution are beneficial to clean the noisy labels.</p><p>Quantitative comparison. We compare our methods with state-of-the-art models upon 3 indicators, i.e., ROC  Step-wise AUC (%) on ShanghaiTech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Action Classifier C3D TSN RGB TSN Optical Flow</head><p>Step curves, AUC and false alarm rates. As <ref type="figure" target="#fig_2">Figure 4</ref> shows, our curves of all the action classifiers almost completely enclose the others, which means they are consistently superior to their competitors at various thresholds. The smoothness of the three curves shows the high stability of our proposed approach. As shown in <ref type="table" target="#tab_1">Table 2</ref>, we boost the AUC value up to 82.12% at most. As for false alarm rates at 0.5 detection score, the C3D is slightly inferior to Sultani et al., whereas the other two classifiers are fairly satisfactory as shown in <ref type="table" target="#tab_1">Table 2</ref>. Notably, the RGB branch of TSN reduces the false alarm rate to 0.1%, nearly 1/20 of the best-so-far result.</p><p>Qualitative analysis on the test set. To observe the influence of our model, we visualize the before-and-after change in predictions of action classifiers. As presented in <ref type="figure" target="#fig_3">Figure 5</ref>, our denoising process substantially alleviates the predictive noise of action classifiers within both normal and anomaly snippets. Intriguingly, the classifier fails to detect the anomaly event in the "Arrest007" video from beginning to end as <ref type="figure" target="#fig_3">Figure 5c</ref> depicts. After watching all videos of the "Arrest" class, we finally discover the possible cause: the similar scene in this testing video does not exist in training data. In this video, a man is arrested at the laundromat for vandalism of washing machines as shown in <ref type="figure" target="#fig_3">Figure 5d</ref>, while "Arrest" events occur on the highway or at the checkout counter in training data. It implies that to detect anomalous events in generic scenes is still a big challenge for the limited generalization ability of current models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Experiments on ShanghaiTech</head><p>Step-wise results. As illustrated in <ref type="table" target="#tab_2">Table 3</ref>, the performance is improved after the alternate training w.r.t. all the action classifiers. The results of optical flow branch of TSN <ref type="table" target="#tab_9">Table 4</ref>: Quantitative comparison on UCSD-Peds2. Following the reviewer comment, we make more comparisons as shown in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>AUC (%) Adam <ref type="bibr" target="#b0">[1]</ref> 63.0 MDT <ref type="bibr" target="#b43">[44]</ref> 85.0 SRC <ref type="bibr" target="#b12">[13]</ref> 86.1 AMDN <ref type="bibr" target="#b65">[66]</ref> 90.8 AL <ref type="bibr" target="#b19">[20]</ref> 90. Step-3 reflects that excessive iterations may deteriorates on the detection performance. Nevertheless, our method performs robustly as the AUC value only drops slightly.</p><p>Qualitative Analysis. Different from UCF-Crime, the training data in the new split of ShanghaiTech have temporal ground truths. Based on this, the working principle of our GCN can be intuitively understood. The anomaly event in <ref type="figure" target="#fig_4">Figure 6</ref> is that a student jumps over the rail as shown in <ref type="figure" target="#fig_5">Figure 7</ref>. The temporal consistency module (at the upper right) is inclined to smooth the original highconfidence predictions (orange points at the upper left). Therefore, it correctly annotates the 150 th ? 200 th frames with dense high-confidence predictions, but neglects the remaining ground truth for insufficient high-confidence inputs. The feature similarity module (at the lower right) tends to propagate information through a similar degree. It labels a long interval of snippets including the student's previous run-up and subsequent slow-down actions, possibly because they have the similar representation of "a fast movement in the same direction" on the optical flow. The entire GCN (at the lower left) combining these two modules can make more precise labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Experiments on UCSD-Peds</head><p>In UCSD-Peds, some of the ground truths are only 4 frames, but the predictive unit of C3D reaches a length of 16 frames. Thus we conduct the experiments with TSN. To match the input dimension with the RGB branch, the original gray-scale frames are duplicated into the 3 primarycolor channels.</p><p>Step-wise results. After repeating experiments 10 times, we obtain the box plots in <ref type="figure" target="#fig_6">Figure 8</ref>. The average results at the first step are good enough, so we start with feeding top 90% high-confidence predictions into the GCN. We observe that the proposed method not only increases the detection performance, but also stabilize the predictions of the 10time repeated experiments.</p><p>Quantitative comparison. We report the "mean value   ? standard deviation" of the AUC, and make comparisons with other methods under the same splitting protocol as in <ref type="bibr" target="#b19">[20]</ref>. Our approach outperform others with both the input modalities as shown in <ref type="table" target="#tab_9">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we address weakly supervised anomaly detection from a new perspective, by casting it as a supervised learning task under noise labels. In contrast to MIL formulation in previous works, such a perspective possesses distinct merits in two aspects: a) it directly inherits all the strengths of well-developed action classifiers; b) anomaly detection is accomplished by an integral end-to-end model with great convenience. Furthermore, we utilize a GCN to clean labels for training an action classifier. During the alternate optimization process, the GCN reduces noise via propagating anomaly information from high-confidence predictions to low-confidence ones. We validate the proposed detection model on 3 different-scale datasets with 2 types of action classification networks, where the superior performance proves its effectiveness and versatility. Our approach of directly utilizing action classifiers for anomaly detection has great computational efficiency. As shown in <ref type="table" target="#tab_0">Table 1</ref>, we report the frame per second (FPS) performance of the two types of action classifiers. Although the time-consuming pre-processes (e.g., 10-crop oversampling) are taken into consideration, the three action classifiers still have the real-time or even the super real-time performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Implementation of Label Noise Cleaner</head><p>At the first cleaning step, we select the 30% and 60% highest-confidence snippets as H for two-stream and C3D networks respectively if not specified, and increase the cardinality of H by 30% at each step. To learn an unbiased model, we also include normal videos in training data. To generate the label assignments of action classifiers, we concentrate the output probability into a single anomaly category with a min-max normalization. The output dimensions of the first two fully connected layers are 512 and 128 respectively, at the 60% dropout <ref type="bibr">[10]</ref> rate. Both the graph modules have two convolutional layers: a 32unit hidden layer activated by ReLu and the last 1-unit output layer. Due to the limited memory of GPUs, we at most sample 1,600 high-confidence snippets with not more than 8 neighbours respectively in a video. We implement our noise cleaner upon Pytorch <ref type="bibr">[8]</ref> with the following hyper-parameters: base learning rate = 0.0001, momentum = 0.9 and weight decay = 0.0005. In preliminary experiments, we observe that three iterations are sufficient in most cases. Therefore we repeat the alternate optimization until the 3 rd step and compare the last (not always the best) results with other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">More Comparisons on UCSD-Peds</head><p>Several unary-classification works in 2018 also conduct experiments on UCSD-Peds. As shown in <ref type="table" target="#tab_2">Table 3</ref> and the main body of our paper, their default implementations are not directly comparable with ours because of different data splits. For some open-source works, we hereby reproduce experiments on the data split in <ref type="bibr" target="#b0">[1]</ref> as ours, while the results in their original papers are also provided within square parentheses "[]" for reference as reported in <ref type="table" target="#tab_1">Table 2</ref>. Since UCF-Crime is released at Github on June 10 th 2018 lately, except the official reference <ref type="bibr">[11]</ref> and its comparisons, neither public reporting of results nor source codes can be found, and we hope that our work can fill in the blanks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Vectorized Feature Similarity Module</head><p>Following the main body of our paper, we denote the feature similarity graph as F = (V, E, X) , where V is the vertex set, E is the edge set, and X is the attribute of vertexes. In particular, V is a video, E describes the feature similarity amongst snippets, and X ? R N?d represents the d-dimensional feature of these N snippets. The adjacency matrix A ? R N ?N of F is defined as:   <ref type="table" target="#tab_2">Table 3</ref>: Difference in splitting UCSD-Peds. The random selection is repeated 10 times in <ref type="bibr" target="#b0">[1]</ref>.</p><formula xml:id="formula_13">A (i,j) = exp(X i ? X j ? max(X i ? X)) ,<label>(1)</label></formula><p>where the element A (i,j) measures the feature similarly between the i th and j th snippets. Here is an equivalent vectorization of Equation 1:</p><formula xml:id="formula_14">A = exp(XX T ? torch.max(XX T , dim = 1)) ,<label>(2)</label></formula><p>where the torch.max function takes the maximum value over dimension 1.</p><p>The nearby vertexes are driven to have the same anomaly label via the graph-Laplacian operation approximated with a renormalization trick <ref type="bibr">[3]</ref>:</p><formula xml:id="formula_15">A = D ? 1 2 A D ? 1 2 ,<label>(3)</label></formula><p>where the self-loop adjacency matrix A = A + I n , and I n ? R N ?N is the identity matrix; D is the corresponding degree matrix:</p><formula xml:id="formula_16">D (i,i) = j A (i,j) .<label>(4)</label></formula><p>The vectorization of Equation 4 is implemented with the vectorized summation and the broadcasting diagonal functions of Pytorch:</p><formula xml:id="formula_17">D = torch.diag(torch.sum( A, dim = 1)) .<label>(5)</label></formula><p>Finally, the output H of a feature similarity graph module layer is computed as:</p><formula xml:id="formula_18">H = ?( AXW) ,<label>(6)</label></formula><p>where W is a trainable parametric matrix, and ? is an activation function.</p><p>Since the whole computational procedure is differentiable, our feature similarity graph module can be trained in an end-to-end fashion. Therefore, neural networks are capable of seamlessly incorporating the single or multiple stacked modules. The temporal similarity module can be also rewritten as its corresponding vectorized implementation in a similar manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Details of Indirectly Supervised Loss Term</head><p>Our indirectly supervised term of the loss function can be viewed as a temporal ensembling strategy <ref type="bibr">[4]</ref>. The pseudo code is shown in Algorithm 1. In practice, we set ? as 0.5 in all of the experiments. Since we have already obtained a set of rough predictions from the action classifier, the "cool start" initialization and the bias correction of the original temporal ensembling method <ref type="bibr">[4]</ref> are not required as illustrated on the 1 st and the 8 th statements.  In total, there are 437 videos on ShanghaiTech. As shown in <ref type="table" target="#tab_9">Table 4</ref>, we split the data into two subsets: the training set is made up of 238 videos, and the testing set contains 199 videos. In each scene, the numbers of normal and anomaly videos w.r.t. the two subsets are depicted in <ref type="figure" target="#fig_7">Figure 1 and Figure 2</ref>, respectively. The new data split is available at https://github.com/jx-zhong-foracademic-purpose/GCN-Anomaly-Detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Reorganization of ShanghaiTech</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Discuss the Formulation</head><p>Following the reviewer's suggestion, we discuss our noisy-labeled problem formulation and the EM-like optimization mechanism under this formulation in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Concept: MIL vs Noisy-labeled Learning</head><p>Conceptually, the two formulations mainly differ in their emphases. Given a positive bag Y = 1, the MIL usually focuses on positive instances y i = 1, whereas the noisylabeled training pays attention to noisy labels y i = 0 and the remaining ones are y i = 1. The two conceptions are complementary and have transformational relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Practice: EM-like MIL vs Ours</head><p>Practically, in terms of selection criteria on "seed examples", the EM-like MIL focuses on the most-likely positive instances, while our noisy-labeled optimization prefers the most-likely reliable predictions. Take the three MIL models the reviewer mentioned for examples. If the 10crop prediction of a snippet within an anomalous video is {0.2, 0.2, ..., 0.2}, He et al. <ref type="bibr" target="#b0">[1]</ref> will not update their "anchor dictionary" with it for its low anomaly score (mean value=0.2), Hou et al. <ref type="bibr">[2]</ref> will exclude it because it is "non-discriminative" (without "the same label" as the corresponding video), Zhang et al. <ref type="bibr">[12]</ref> will neglect it since their E-step is to seek the most "responsible" instance to the bag annotation, but we will select it to supervise our GCN because it is highly certain and noiseless (predictive vari-ance=0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Terminology: EM-like vs EM-based</head><p>As pointed out in the main body of this paper, our updating method is "EM-like" instead of "EM-based". The resemblance between our optimization mechanism and the EM-based approach is that they both alternately repeat update-and-fix processes. However, our method is not "EM-based" since we do not explicitly estimate mathematical expectation in the training process.</p><p>Algorithm 1 Indirectly Supervised Loss Term. Note that the practical computational processes are incrementally implemented, while in this pseudo code all of them are calculated from the 1 st epoch for clarity. Input:</p><formula xml:id="formula_19">V = {v i } N i=1 : a video with N snippets Y = { y i } N i=1</formula><p>: the rough snippet-wise anomaly probabilities from the last action classifier p ? (v i ): the GCN predictions of video clips v i with trainable parameters ? ?(v i ): the stochastic augmentation (such as dropout and random cropping) function of input snippets v i ?: a hyper-parametric discount factor within the range of (0, 1) Output:</p><p>L j I : the indirectly supervised loss at the j th epoch <ref type="bibr">1:</ref> Initialize the smooth target p i?1,2,..,N = y i?1,2,..,N 2: repeat 3:</p><p>Initialize the epoch counter j = 0 4:</p><p>for each video V in the training set do 5:</p><p>Obtain the GCN predictions of augmented snippets: p i = p ? (?(v i ))</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Compute the loss under indirect supervision:</p><formula xml:id="formula_20">L j I = 1 N N i=1 |p i ? p i | 7:</formula><p>Optimize the parameters ? of the GCN <ref type="bibr">8:</ref> Update the smooth target: p i?1,2,..,N = ?p i?1,2,..,N + (1 ? ?)p i?1,2,..,N</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>Update the epoch counter: j = j + 1 10: until j == current epoch number  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>ROC curves on UCF-Crime.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Visualization of testing results on UCF-Crime. The blue curves are predictions of the action classifier trained under video-level labels, and the orange curves are the results under cleaned supervision. The "GT" bars in green are ground truths. Best viewed in Adobe Reader where (d) should play as a video.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Visualization of GCN outputs on ShanghaiTech w.r.t. the video "05 0021". The rough prediction at the upper left is from the optic flow branch, while the other three are snippet-wise labels cleaned by the GCN modules.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Partial video of "05 0021" on ShanghaiTech. Best viewed in Adobe Reader where (a)-(c) should play as videos.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Box-whisker plots of step-wise performance on UCSD-Peds2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 1 :</head><label>1</label><figDesc>Training set on the reorganization of ShanghaiTech.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 2 :</head><label>2</label><figDesc>Testing set on the reorganization of ShanghaiTech.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Ablation Studies on UCF-Crime.</figDesc><table><row><cell>Training Stage Step-2 Step-2 Step-2 Step-2 Step-2 Step-2</cell><cell>Indirect Supervision ?</cell><cell cols="4">Temporal Consistency Conv. Graph Conv. Graph Feature Similarity ? ? ? ? ? ? ? ? ? ? ? ? ? ?</cell><cell>AUC (%) 74.60 73.79 67.57 72.93 67.23 72.44</cell></row><row><cell>Step-1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>70.87</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Quantitative comparison on UCF-Crime. ? and ? indicate the loss without and with constraints respectively.</figDesc><table><row><cell>Method</cell><cell cols="2">AUC (%) False Alarm (%)</cell></row><row><cell>SVM Baseline</cell><cell>50.0</cell><cell>-</cell></row><row><cell>Hasan et al. [19]</cell><cell>50.6</cell><cell>27.2</cell></row><row><cell>Lu et al. [41]</cell><cell>65.51</cell><cell>3.1</cell></row><row><cell>Sultani et al.  ? [58]</cell><cell>74.44</cell><cell>-</cell></row><row><cell>Sultani et al.  ? [58]</cell><cell>75.41</cell><cell>1.9</cell></row><row><cell>Ours C3D</cell><cell>81.08</cell><cell>2.8</cell></row><row><cell>TSN RGB</cell><cell>82.12</cell><cell>0.1</cell></row><row><cell>TSN OpticalF low</cell><cell>78.08</cell><cell>1.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 :</head><label>2</label><figDesc>Comparison on UCSD-Peds in 2018. The results of their original papers under data split [5] are reported within "[]".</figDesc><table><row><cell>Splitting Approach</cell><cell cols="2">Train Normal Abnormal</cell><cell>Test</cell></row><row><cell>Following [5] Following [1]</cell><cell>16 4</cell><cell>0 6</cell><cell>12 18</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>The number of videos on our reorganized Shang-haiTech.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">"10-crop" means cropping images into the center, four corners, and their mirrored counterparts.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We are grateful to the three anonymous reviewers for their valuable comments and suggestions. In addition, we would like to thank Jerry for English language editing.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust real-time unusual event detection using multiple fixed location monitors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shimshoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reinitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="555" to="560" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Tracking and identification of suspicious and abnormal behaviors using supervised machine learning technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Adhiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kolhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Patil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Advances in Computing, Communication and Control</title>
		<meeting>the International Conference on Advances in Computing, Communication and Control</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="96" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Video parsing for abnormality detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Anti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011-11" />
			<biblScope unit="page" from="2415" to="2422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Auxiliary image regularization for deep cnns with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Azadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Dynamic Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Bellman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1957" />
			<publisher>Princeton University Press</publisher>
			<pubPlace>Princeton, NJ, USA</pubPlace>
		</imprint>
	</monogr>
	<note>1 edition</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Abnormal events detection based on spatio-temporal cooccurences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Benezeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jodoin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosenberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2548" to="2465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A note on learning from multiple-instance examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avrim</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kalai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1998-01" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="23" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spectral networks and locally connected networks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multiple instance learning: A survey of problem characteristics and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc-Andr</forename><surname>Carbonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronika</forename><surname>Cheplygina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghyslain</forename><surname>Gagnon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="329" to="353" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Quo vadis, action recognition? a new model and the kinetics dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4724" to="4733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Video anomaly detection and localization using hierarchical feature representation and gaussian process regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yie-Tarng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Hsien</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Abnormal event detection in videos using spatiotemporal autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">H</forename><surname>Tay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Neural Networks</title>
		<imprint>
			<date type="published" when="2017-06" />
			<biblScope unit="page" from="189" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sparse reconstruction cost for abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3449" to="3456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convolutional two-stream network fusion for video action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1933" to="1941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cascaded boundary regression for temporal action detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Training deep neuralnetworks using a noise adaptation layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ben-Reuven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning temporal regularity in video sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Roy-Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="733" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An anomalyintroduced learning method for abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="29573" to="29588" />
			<date type="published" when="2018-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A markov clustering topic model for mining behaviour in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009-09" />
			<biblScope unit="page" from="1165" to="1172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Abnormal event detection via multi-instance dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hujun</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Data Engineering and Automated Learning -IDEAL 2012</title>
		<editor>Hujun Yin, Jos? A. F. Costa, and Guilherme Barreto</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="76" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Slow and steady feature analysis: higher order temporal coherence in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinesh</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3852" to="3861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia, MM &apos;14</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Large-scale video classification with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanketh</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1725" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">What uncertainties do we need in bayesian deep learning for computer vision? In</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5574" to="5584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Observe locally, infer globally: A space-time mrf for detecting abnormal activities with incremental updates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="2921" to="2928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Anomaly detection in extremely crowded scenes using spatio-temporal motion pattern models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kratz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nishino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1446" to="1453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A revisit of sparse coding based anomaly detection in stacked rnn framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Design of robust neural network classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nonboe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hintz-Madsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multi-scale analysis of contextual information within spatio-temporal video volumes for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="2363" to="2367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Anomaly detection and localization in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="18" to="32" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning from noisy labels with distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Single shot temporal action detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Shou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="988" to="996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Key instance detection in multi-instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="253" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Future frame prediction for anomaly detection a new baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Abnormal event detection at 150 fps in matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013-12" />
			<biblScope unit="page" from="2720" to="2727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Remembering history with convolutional lstm for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expo</title>
		<imprint>
			<biblScope unit="page" from="439" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A revisit of sparse coding based anomaly detection in stacked rnn framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Viral Bhalodia, and Nuno Vasconcelos. Anomaly detection in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1975" to="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Abnormal crowd behavior detection using social force model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mehran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="935" to="942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep learning from temporal coherence in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="737" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Angry crowds: Detecting violent events in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vittorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016-10" />
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Anomaly detection in video surveillance via gaussian process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">O</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">1555011</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Asymmetric transitivity preserving graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Attributed graph models: Modeling network structure with correlated attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">J</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Iii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">La</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Fond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gallagher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM WWW</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="831" to="842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning spatiotemporal representation with pseudo-3d residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5534" to="5542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multi-instance learning with any hypothesis class</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivan</forename><surname>Sabato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2999" to="3039" />
			<date type="published" when="2012-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Classification with asymmetric label noise: Consistency and maximal denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Handy</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual Conference on Learning Theory</title>
		<meeting>the 26th Annual Conference on Learning Theory<address><addrLine>Princeton, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="12" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Autoloc: Weakly-supervised temporal action localization in untrimmed videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuyuki</forename><surname>Miyazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Fu</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Two-stream convolutional networks for action recognition in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="568" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Real-world anomaly detection in surveillance videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waqas</forename><surname>Sultani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning spatiotemporal features with 3d convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Du</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4489" to="4497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Toward robustness against label noise in training deep discriminative neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Action recognition with improved trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3551" to="3558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Temporal segment networks for action recognition in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Videos as space-time region graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Slow feature analysis: Unsupervised learning of invariances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurenz</forename><surname>Wiskott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrence</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="715" to="770" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Chaotic invariants of lagrangian particle trajectories for anomaly detection in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010-06" />
			<biblScope unit="page" from="2054" to="2060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Detecting anomalous events in videos by learning deep representations of appearance and motion. Computer Vision and Image Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page" from="117" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Online detection of unusual events in videos via dynamic sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="3313" to="3320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Temporal action detection with structured segment networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">References [1] Chengkun He, Jie Shao, and Jiayu Sun. An anomalyintroduced learning method for abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Xing</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>Step-by-step erasion, one-by-one collection: A weakly supervised temporal action detector</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Patch-based convolutional neural network for whole slide tissue image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Kurc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Saltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="2424" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matias</forename><surname>Samuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aila</forename><surname>Oskari</surname></persName>
		</author>
		<idno>App. 15/721</idno>
		<imprint>
			<date type="published" when="2018-12" />
			<biblScope unit="volume">433</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">US Patent</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Anomaly detection and localization in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="32" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Future frame prediction for anomaly detection a new baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Classifier two-sample test for video anomaly detections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusha</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barnab?s</forename><surname>P?czos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Plug-and-play cnn for crowd motion analysis: An application in abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sangineto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In WACV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Real-world anomaly detection in surveillance videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waqas</forename><surname>Sultani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Em-dd: An improved multiple-instance learning technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sally</forename><forename type="middle">A</forename><surname>Goldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1073" to="1080" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
