<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EFFICIENT-VDVAE: LESS IS MORE</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louay</forename><surname>Hazami</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayhane</forename><surname>Mama</surname></persName>
							<email>rayhane@squareup.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ragavan</forename><surname>Thurairatnam</surname></persName>
							<email>ragavan@squareup.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Cash App Labs</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Cash App Labs</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Cash App Labs</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">EFFICIENT-VDVAE: LESS IS MORE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Unsupervised representation learning</term>
					<term>Hierarchical VAE</term>
					<term>Very deep VAE</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hierarchical VAEs have emerged in recent years as a reliable option for maximum likelihood estimation. However, instability issues and demanding computational requirements have hindered research progress in the area. We present simple modifications to the Very Deep VAE to make it converge up to 2.6? faster, save up to 20? in memory load and improve stability during training. Despite these changes, our models achieve comparable or better negative log-likelihood performance than current state-of-the-art models on all 7 commonly used image datasets we evaluated on. We also make an argument against using 5-bit benchmarks as a way to measure hierarchical VAE's performance due to undesirable biases caused by the 5-bit quantization. Additionally, we empirically demonstrate that roughly 3% of the hierarchical VAE's latent space dimensions is sufficient to encode most of the image information, without loss of performance, opening up the doors to efficiently leverage the hierarchical VAEs' latent space in downstream tasks. We release our source code and models at https://github.com/Rayhane-mamah/Efficient-VDVAE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Maximum likelihood models have garnered a lot of attention from researchers in the last few years. Deep autoregressive models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref> have long achieved the best log likelihoods across different modalities. Variational Autoencoder <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> (VAE) is a different type of maximum likelihood models that are usually associated with representation learning <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> and are known to generate subjectively more diverse images <ref type="bibr" target="#b8">[9]</ref> compared to other generative approaches like diffusion models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref> and GANs <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref>. Very Deep VAE (VDVAE) <ref type="bibr" target="#b15">[16]</ref>, a newly proposed hierarchical VAE (HVAE), shows great promise in competing with deep autoregressive models in Maximum Likelihood Estimation (MLE). However, this method has proven to be computationally costly and to be generally unstable during training. In this paper, we aim to tackle these two issues and to share some of our insights that we have gathered throughout our experiments with VDVAE.</p><p>We start this work with a background on VAEs and HVAEs in section 2 and list similar works to VDVAE in section 3. Both these sections can be skipped by practitioners who are familiar with HVAEs.</p><p>In section 4, we introduce Efficient-VDVAE, which encompasses our contributions and tackles both the instability and compute cost problems associated with VDVAE.</p><p>We kick off the section 5 by empirically showing the impact of our approach. We then provide evaluations of our model trained on 7 commonly used benchmarks and show that our models are either on par with VDVAE or better in terms of Negative Log Likelihood (NLL) on all datasets. We also share some generated samples from the prior distribution of our model.</p><p>We then interpret the Efficient-VDVAE from an informational theory perspective in section 6, and we show the dilemma between that interpretation and the current dominant HVAE implementations, demonstrating along the way that commonly used 5-bit benchmarks are not suitable benchmarks for HVAEs. * Equal contribution.</p><p>? To whom correspondence should be addressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2203.13751v2 [cs.LG] 28 Apr 2022</head><p>Efficient-VDVAE: Less is more Finally, in section 7, we examine the size of the "effective latent space" of the Efficient-VDVAE and illustrate that one can prune 97% of the latent space without harming reconstruction quality, opening up the doors for a more effective usage of the HVAE's latent space in downstream tasks.</p><p>For practitioners interested in using VDVAE based models, we provide tips and insights gained from this work in the supplemental material C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Variational AutoEncoders</head><p>The goal of VAEs is to learn a generative model parametrized with ? of a joint distribution p ? (x, z) that is usually factorized as:</p><formula xml:id="formula_0">p ? (x, z) = p ? (x|z)p ? (z)<label>(1)</label></formula><p>where p ? (z) is a prior distribution over latent variables z and p ? (x|z) is the likelihood function (usually called stochastic decoder) that generates a data sample x from its latent variables z. VAEs are trained with the Evidence Lower Bound (ELBO):</p><formula xml:id="formula_1">log p ? (x) ? E q ? (z|x) [log p ? (x|z)] ? D KL [q ? (z|x)||p ? (z))]<label>(2)</label></formula><p>Where D KL is the Kullback-Leibler divergence and q ? (z|x) is the approximate posterior parametrized with ?. Usually in typical VAEs, q ? (z|x) and p ? (z) are modeled with Gaussian distributions. For a derivation of the ELBO and a more in depth introduction to VAEs, see <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Hierarchical Variational AutoEncoders</head><p>While fully factorized Gaussian q ? (z|x) and p ? (z) VAEs are theoretically capable of modeling any complex data distribution p(x), in practice they are usually unable to learn such a solution due to computational constraints and a difficult optimization landscape <ref type="bibr" target="#b17">[18]</ref>. To help alleviate this problem, deep HVAEs <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref> have been proposed in recent years as a way to increase the expressiveness of both the approximate posterior and the prior distributions, such as:</p><formula xml:id="formula_2">p ? (z) = p ? (z 1 ) L i=2 p ? (z i |z &lt;i ) q ? (z|x) = q ? (z 1 |x) L i=2 q ? (z i |x, z &lt;i ) (3) p ? (x|z) = p ? (x|z L )p ? (z) = p ? (x|z L )p ? (z 1 ) L i=2 p ? (z i |z &lt;i )<label>(4)</label></formula><p>where L is the total number of latent hierarchical variables z = {z 1 , z 2 , ..., z L }. This formulation is known as the top-down inference (or bidirectional inference) HVAE introduced in <ref type="bibr" target="#b20">[21]</ref>. <ref type="figure" target="#fig_6">Figure 4</ref> gives a general overview of this process.</p><p>By substituting the hierarchical stochastic encoder, stochastic decoder and prior expressions in equation <ref type="formula" target="#formula_1">(2)</ref>, we obtain the Hierarchical ELBO that HVAEs are trained to maximize:</p><formula xml:id="formula_3">log p ? (x) ? E q ? (z|x) [log p ? (x|z)] ? D KL [q ? (z 1 |x)||p ? (z 1 ))] ? L i=2 E q ? (z&lt;i|x) D KL [q ? (z i |x, z &lt;i )||p ? (z i |z &lt;i )] (5)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>While HVAEs have been used on multiple occasions in literature <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>, they became especially prominent in recent works when these models became deep enough to compete with state-of-the-art autoregressive models.</p><p>The most widely used base very deep HVAE models are NVAE <ref type="bibr" target="#b22">[23]</ref> and VDVAE <ref type="bibr" target="#b15">[16]</ref>. During training, the former relies on heavy regularization in the hopes of stabilizing the unbounded KL terms of (5) and the latter -while achieving better NLL than NVAE-is less stable due to lack of regularization; both these models being more computationally expensive the deeper the model gets.</p><p>This work is based on VDVAE in the aim of reducing its computational requirements and adding more training stability. For completeness, we provide details of the architecture we use in all of our experiments in <ref type="figure">figure 5</ref>. It is advisable to refer to the source code for more details.</p><p>4 Revisiting VDVAE</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Compute reduction</head><p>Architecture design VDVAE's work <ref type="bibr" target="#b15">[16]</ref> empirically demonstrates that networks in general benefit from more layers at higher resolutions (measured in NLL), suggesting that it is important to have latent variables that learn local image details at high resolution layers. Our investigation shows that the benefit of adding layers to the high resolution layers is only noticeable when comparing NLL metrics and doesn't perceptively affect the model's reconstructed or generated images. The addition of high resolution layers also drastically increases the memory requirements of the networks. Moreover, the NLL gains from adding high resolutions layers follows the rule of diminishing returns. We show that it is possible to design memory efficient VDVAEs that don't affect NLL results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimization</head><p>We study the effect of changing the optimization scheme in order to converge faster (fewer updates and faster clock time). We also train all our models with reduced batch sizes in order to save computational costs. These changes introduce more training instabilities. Therefore, we developed new methods to stabilize the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Stabilization</head><p>Gradient smoothing One common problem with training deep Gaussian HVAEs is the very large gradients resulting from the unbounded KL term <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23]</ref>, more specifically the gradients resulting from the inverse of the posterior standard deviation 1/? posterior . While NVAE attempts to solve this by using residual normal distributions and clipping the range of the log(?) predicted by the model, VDVAE counters this by clipping/skipping sharp gradients. In practice, we find that these solutions can hinder the model's learning depending on the dataset and depending on the model's other hyper-parameters. We propose instead to smooth the gradients of the inverse std by computing the Gaussian stds of both posteriors and priors with ? = Softplus(y, ?) = 1 ? log(1 + exp(?y)), with y the activation of a linear layer and ? being a smoothing multiplier smaller than 1. Like VDVAE, we use the discretized mixture of logistics (MoL) as the output layer of the generative model. To mitigate its sharp gradients, we similarly use gradient smoothing.</p><p>Optimizer Since the norm of gradients of the MoL layer can be much larger than 1, especially when using small batch sizes, optimizing this model with the Adam optimizer <ref type="bibr" target="#b23">[24]</ref> can prove to be challenging since its second momentum v t = ? 2 v t?1 + (1 ? ? 2 )g 2 t grows large. As such, we propose to use its infinite norm alternative, Adamax, which does not suffer from the same problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Model design, NLL and memory</head><p>We first tested to what extent increasing the depth of the model in the higher resolution layers is useful for the NLL metric, and how much memory can be saved by reducing this depth without hurting the model performance. In table 1a, we train multiple networks while fixing the number of low resolution layers and we experiment with only changing the number of medium and high resolution layers. We conclude that, after a certain depth, increasing the number of layers in high resolution latent spaces stops improving MLE performance. Distributing the number of layers across the lower resolution layers, not only saves memory, but also preserves performance.   We trained networks with the same model architecture with varying the batch size for 500k steps and tested the effect of gradient smoothing at ? = log(2). The gradient smoothing does not affect NLL and results in greater stability when the batch size is reduced, as measured by the number of skipped updates at a gradient update threshold of 800 (for a negative ELBO measured in nats/dim). These results are computed on the CIFAR-10 dataset, but other datasets exhibit similar behaviors. (b) Number of skipped updates in 80k steps on high resolution datasets for a threshold of 1200 (loss computed in nats/dim), ? = 0.4 and a batch size of 8 . Gradient smoothing allows us to train models with small batch sizes.</p><p>We then tested the impact of using the same big number of filters across all layers of the model against adopting an incremental strategy of the width, as can be seen in table 1b. We show that high resolution latent spaces benefit less from width than the lower resolution latent spaces. We take advantage of this finding to considerably reduce the GPU memory load while remaining comparable to the baseline. In all of our experiments, we set a maximum GPU memory load of 320GB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Gradient smoothing and stability</head><p>Reducing the computation requirements by reducing the batch size as described in section 4.1 introduces training instabilities. We show in table 2 that gradient smoothing substantially improves stability when using small batch sizes and that it is mandatory for high resolution datasets. For completeness, we show the effect of gradient smoothing as a function of model depth in Appendix B.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Quantitative model results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Computation load comparison</head><p>We start by examining the training memory load gain between our Efficient-VDVAE and the original VDVAE. All VDVAE parameters are reported in the original VDVAE work 3 , and we train our models with only applying the architecture and optimization modifications described in section 4 and tested in experiments 5.1, 5.2.</p><p>In    An asterisk (*) denotes scores with data augmentation. Since most models overfit on CIFAR-10, data augmentation greatly improves performance. Our computational efficiency allows us to set HVAE baselines on high resolution datasets. Efficient-VDVAE outperforms current state-of-the-art models on most datasets.</p><formula xml:id="formula_4">- - 0.72 - - - - - Flow++[33] - 3.08 3.86 3.69 - - - - - - - GLOW[34] - 3.35 4.09 3.81 - 1.03 - - - - - DenseFlow[35] - 2.98 3.63 3.35 1.99 - - - - - - ?-VAE[36] - 2.83 3.77 - - - - - - - - SPN[37] - - 3.85 3.52 - 0.61 - - - - - MaCow[38] - 3.16 - 3.69 - 0.67 - - - - - PixelVAE++[3] 78.00 2.90 - - - - - - - - - Locally Masked PixelCNN[39] 77.58 2.89 - - - 0.74 - - - - - Image Transformer[40] - 2.89 3.77 - - - - - - - - Sparse Transformer[41] - 2.80 - 3.44 - - - - - - - Aug. Sparse Transformer[4] - 2.53* - - - - - - - - - UDM[42] - 3.04 - - 1.93 - - - - - - VDM[43] - ? 2.49* ? 3.72* ? 3.40* - - - - - - - NVAE[23] ? 78.01 ? 2.91 ? 3.92 - ? 2.03 ? 0.70 - ? 0.69 - - - VDVAE[16] - ? 2.87 ? 3.80 ? 3.52 - - - ? 0.61 - - ? 2.42 CR-NVAE[44] ? 76.93* ? 2.51* - - ? 1.86* - - - - - - Efficient-VDVAE - ? 2.87 ? 3.58 ? 3.30 ? 1.83 ? 0.57 - ? 0.60 - - - Efficient-VDVAE (</formula><p>to converge in 2? less updates and to train in 2.6? less clock time on Imagenet 32 ? 32. In this scenario, computational gains can worsen the NLL metric by up to 0.02% which is usually qualitatively indistinguishable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">NLL results</head><p>In table 4, we report the NLL scores compared to other notable MLE models. We report these results on more datasets than in the original VDVAE for completeness: We add NLL results on MNIST <ref type="bibr" target="#b27">[28]</ref>, CelebA 64 ? 64 <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>, CelebAHQ 256?256 and CelebAHQ 1024?1024 <ref type="bibr" target="#b30">[31]</ref>. Most of these additions are commonly used except CelebAHQ 1024?1024 which we added to act as a baseline for high resolution images for future work. We also provide the 8-bit scores on FFHQ 256 ? 256 and CelebAHQ 256 ? 256 which are usually trained in 5-bits (see section 6 for an in-depth explanation).</p><p>Despite being more efficient than VDVAE, Efficient-VDVAE consistently achieves either similar or better NLL scores on all baselines. It also achieves state-of-the-art performance on all datasets but CIFAR-10, although it remains comparable to non-augmented models. See codebase for a rundown of all hyper-parameters used for each dataset.    We observe that the unbounded model has a lower reconstruction loss. We also observe that the KL divergence converges to a lower value which then allows the Negative ELBO to reach a better final value. This however does not reflect the overall closeness of the reconstructed images to the target images as demonstrated by the Structural Similarity Index Measure (SSIM) <ref type="bibr" target="#b45">[46]</ref> values. 6 Information theoretic interpretation and output layer dilemma</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Qualitative model results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Lossless compression</head><p>From an information theory perspective, the reconstruction loss is interpreted as the term that copies information from the pixel space to the latent space, and the KL divergence is interpreted as the regularization term that compresses that information <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b44">45]</ref>. Thus, during training, we expect the reconstruction loss to decrease and the KL divergence to increase as more information gets stored in the latent space. When the reconstruction loss reaches a minimum at which it can no longer decrease, we expect the KL divergence term to decrease as information in the latent space gets compressed.</p><p>While empirically desirable, VAEs (and HVAEs) rarely achieve perfect reconstructions. This is in part due to a pre-existing limit on the sharpness of the output layer; the MoL layer in the case of VDVAE. While this has been originally implemented to preserve training stability <ref type="bibr" target="#b1">[2]</ref>, in our experiments it proved to be unnecessary after the gradient smoothing addition. We study the effect of removing such a bound in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Impact on 5-bit quantization</head><p>The removal of the bound on the MoL layer allows us to adhere more accurately to the principles of lossless compression, and more importantly, avoid training our networks in an over-regularized regime <ref type="bibr" target="#b17">[18]</ref>. In table 4, we test the effect of this removal on FFHQ 256 ? 256 and CelebAHQ 256 ? 256 which have been consistently quantized to 5-bits in prior work <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b33">34]</ref>. We achieve much better NLL than state-of-the-art models on these 5-bit benchmarks. We report in figure 2 the evolution of the validation metrics of a bounded and an unbounded model on FFHQ 256 ? 256 during training.</p><p>Qualitatively, the model appears to compress the latent space information attributed to the banding effect <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50]</ref> which is heavily present in the 5-bit target images. <ref type="figure">Figure 3</ref> illustrates the appearance of banding effects in the 5-bit targets, and their effect on the unbounded models' reconstructions. We show differences between unconditional generated samples in 8-bits and 5-bits in figure 1.   Although prior work <ref type="bibr" target="#b33">[34]</ref> has introduced the use of the 5-bit benchmarks as a means to reduce the datasets' complexity by removing the high frequency color depth information, current state-of-the-art models are more capable of modeling the high frequency noise. Since VAEs are trained to mimic the training data distribution, and, any bias introduced in the data preparation makes them generate samples with a similar bias, they are expected to mimic the banding effect which is undesirable from a generative modeling perspective. Additionally, as HVAEs get more expressive, NLL differences on 5-bit datasets start to only contrast how well the models are compressing the banding effects, rather than giving a global sense of how well the HVAEs are learning the data distribution. Thus, we advocate that all future work should be evaluated on the 8-bit images. As a step in this direction, we provide in Lastly, we observe in table 4, that the removal of the output bound does not affect the NLL results of the 8-bit benchmarks. We hypothesize that this is because our current models are not expressive enough to produce the same KL compression effect on full color depth images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Effective latent space</head><p>In their dense form, z can occupy a lot of memory, especially with very deep HVAEs, which is not suitable for downstream tasks. Fortunately, in practice, VAEs (and HVAEs) train in a polarized regime and learn a latent space where the majority of the latent dimensions are "turned off" for all samples <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref>.</p><p>We experiment with "pruning" the posteriors that are "turned-off" by replacing them with the prior and observe its effect on the test scores. By definition of the polarized regime <ref type="bibr" target="#b50">[51]</ref>, dimensions are turned-off when their average KL divergence (independent from the latent resolution) is lower than a certain threshold. We report, in table 5, the effect of moving the cutoff threshold on CelebAHQ 256 ? 256 (these results hold for other datasets as well).</p><p>We discover that roughly 3% of the latent dimensions encode most of the information required to reconstruct the inputs as shown by an almost equal reconstruction loss. The remaining 97% posterior dimensions can be collapsed on the prior without any qualitative effects as seen in <ref type="figure" target="#fig_9">figure 6</ref>. Therefore, we theorize that using the "active dimensions" of the latent space alone could be sufficient for downstream tasks, while also being memory efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Limitations and broader impact</head><p>This paper's contributions are based on the fundamental need for a cheaper and stabler version of the Deep HVAE. The contributions of this paper have been tested on commonly used datasets for a full comparison with current state-of-the-art.</p><p>This work makes it more accessible to build applications in representation learning, content generation and semisupervised learning. However, these applications are known to have potential negative societal impacts, as the model's representation could be biased and can harm the livelihood of minorities and marginalized groups. Making these models more accessible can also simplify harmful content generation. More work needs to be done on these models to eliminate such deficiencies.</p><p>Despite our work, HVAEs still require a relatively large amount of compute, especially on high resolution datasets, which can still make them inaccessible for individuals and small groups. From a stability point of view, very deep HVAEs that use unimodal latent distributions with infinite support remain, to some extent, unstable by design. Using different latent distributions <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56]</ref> may prove fruitful for completely stabilizing HVAEs. However, using different latent distributions while achieving the same NLL performance of the Gaussian distribution is still an open area of research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>In this paper, we show that VDVAE's stability and computational efficiency could be improved while retaining or boosting the MLE performance as measured in NLL. We then argue against benchmarking on 5-bit quantized datasets, and we reason that future work should be evaluated on full color depth datasets. We also empirically show that only a minor percentage of HVAE's sparse latent dimensions is responsible for encoding most of the information. In the spirit of making these models accessible, we have publicly released our source code. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional architecture details</head><p>A.1 General model architecture</p><p>We start by providing a more detailed information about the bidirectional HVAE architecture and how it works. The VDVAE architecture is a special type of bidirectional HVAE, where the top-down block uses different bottleneck residual blocks <ref type="bibr" target="#b56">[57]</ref> to compute the prior and posterior distributions. In <ref type="figure">figure 5c</ref>, we show the color-coded top-down block from VDVAE.</p><p>In Efficient-VDVAE, we make three slight modifications to the VDVAE architecture:</p><p>? Bottom-up block: We added a skip connection before propagating the output towards the top-down block. This enables us to project the activations ? to any arbitrary width when passing it to the posterior computation branch (in the top-down block), even if the filters number of the rest of the model is changing ( <ref type="figure">figure 5b</ref>). ? Pool layer: VDVAE uses a non-trainable average pooling to downsample activations. We replace that with a 1 ? 1 convolution to have the freedom to change the number of filters.</p><p>? Unpool layer: We add a 1 ? 1 convolution prior to the nearest neighbor upsampling to also have the freedom to change the filter size inside the top-down model ( <ref type="figure">figure 5a</ref>).</p><p>Although the VDVAE work raises the concern that using trainable convolutions in the "pool layer" and "unpool layer" can cause the low resolutions latent groups to not encode any information, we did not observe this behavior in our experiments. Nonetheless, should that happen on other datasets in the future, we provide the KL warm-up schedule described in NVAE <ref type="bibr" target="#b22">[23]</ref> as a solution in the source code. <ref type="figure">Figure 5</ref>: Architecture of the Efficient-VDVAE. Both the pooling and unpooling are different from the traditional VDVAE architecture for the sake of generalization of non-constant filter width in the model. The "Pool" layer is a convolution followed by a Leaky ReLU activation. Dashed blocks are optional and not always present (more details in the source code).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Detailed layer distributions parameters</head><p>In order to explain a part of the memory and NLL differences in table 3, we provide a more detailed overview of the distribution of the stochastic layers across different latent resolutions in table 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Gradient smoothing and divergence</head><p>All the models in this work, including the CelebAHQ 1024 ? 1024 and FFHQ 1024 ? 1024 models, were trained with a maximal memory constraint of 320GB. As such, the maximum batch size that we were able to use on high resolution datasets is 8, which amplified the instabilities of not using gradient smoothing. As seen in table 2b, high resolution models cannot be trained without gradient smoothing as they very quickly diverge, despite our attempts of reducing the learning rate to account for the small batch size.   <ref type="table">Table 7</ref>: Effect of gradient smoothing with respect to model depth on 8-bit FFHQ 256 ? 256 after 800k updates with ? = log(2). The gradient smoothing doesn't affect NLL, but greatly reduces the number of skips as the model gets deeper (All models were run with a batch size of 8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Gradient smoothing and model depth</head><p>For completeness, we train networks while fixing all hyper-parameters and only changing the depth of the model. We then re-train the networks while removing the gradient smoothing and measure both NLL and the number of skipped updates. We show our results in table 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Additional tips and insights for practitioners</head><p>In this section, we provide some notable tips and insights from our experience working with Efficient-VDVAE in the hope of saving valuable time for practitioners who want to use similar architectures. When training under the Efficient-VDVAE setup, we observe that scaling the z projections is much more important than scaling the last convolution of each residual block. Not doing the former results in models diverging at the first training step, while not doing the latter can still result in models that train until convergence.   In our source code, we view these two designs as opposite extreme ends of the same general spectrum. In fact, we implement our models so that Efficient-VDVAE can be designed to be symmetrical, asymmetrical and any combination of the two (symmetrical in parts).</p><p>Empirically, for two models with the same number of layers, we didn't notice any advantage to either design on NLL, convergence or stability. However, we experimented with reducing the bottom-up model's size in an attempt to reduce computational requirements without hurting the model's performance. We report our findings in table 8. We noticed that it is in fact possible to reduce the bottom-up model's complexity up to a certain limit before starting to lose performance, as measured in NLL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 A note on the resolution of the latent space</head><p>We want to allocate this section to talk about the effect of building latent spaces in the same resolution of the input image.</p><p>While it is common practice in autoencoders to have a latent space smaller than the image so that the network compresses the pixel information and avoid learning an identity function, VAEs practically never learn an optimal latent space to model a distribution p(x), even if they have the capacity to do so <ref type="bibr" target="#b17">[18]</ref>.</p><p>The implementation of latent spaces in the same resolution as the image can boost the NLL of the HVAE as shown in <ref type="table" target="#tab_14">table 9</ref>. Qualitatively, however, these layers barely have a visible effect as they mostly operate on the noise of the pixels. Thus, if the goal is generative modeling, then the high resolution layers can be dropped for a memory load gain without major side effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 A note on the overfitting of HVAEs</head><p>Like any other maximum likelihood model, HVAEs will overfit when they can. HVAE's overfitting usually manifests as a large discrepancy between the aggregate posterior of the training data and the aggregate posterior of the validation data. This discrepancy can be measured by a difference between D KL (q ? (z|x)||p ? (z)) in training and validation.</p><p>CIFAR-10 is a good example of when HVAEs (and maximum likelihood models in general) overfit, which is the main reason why models that rely on augmentations score better on that benchmark. CR-NVAE <ref type="bibr" target="#b43">[44]</ref> is a good example of an attempt to reduce the HVAE's overfitting on CIFAR-10 by applying a consistency regularization on the latent space. While CR-NVAE was built on top of NVAE in their work, there should be no problem with applying the same consistency regularization to any other HVAE. That is however outside the scope of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Keep a situational mindset</head><p>Despite the theory and the rules of thumb, it is always healthy to keep a situational mindset. At the end of the day, "For most data sets only a few of the hyper-parameters really matter, but [...] different hyper-parameters are important on different data sets" <ref type="bibr" target="#b57">[58]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional samples D.1 Pruned posteriors reconstructions</head><p>We show in <ref type="figure" target="#fig_9">figure 6</ref> reconstructions from Efficient-VDVAE before and after pruning 97% of its posteriors. Qualitative observations agree with the reconstruction loss, and no noticeable differences appear on the images. We hypothesize from these observations that the 3% of posteriors used in these reconstructions encode most of the latent information and they can be sufficient, and memory efficient, to use in downstream tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Generated samples from the prior</head><p>Due to lack of space in the paper, we share additional samples generated from the prior distribution here.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(a) Imagenet 32 ?</head><label>32</label><figDesc>32 (t = 0.85). (b) Imagenet 64 ? 64 (t = 0.9).(c) CelebA 64 ? 64 (t = 0.8).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( d )</head><label>d</label><figDesc>CelebAHQ 256 ? 256 5-bits (t = 0.85). (e) FFHQ 256 ? 256 5-bits (t = 0.8).(f) CelebAHQ 256 ? 256 8-bits (t = 0.85).(g) FFHQ 256 ? 256 8-bits (t = 0.8).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Samples generated from the prior of Efficient-VDVAE with temperature (t) (best viewed zoomed in). Compared to 5-bit images, the full depth color images don't have banding effects. They also introduce small details missing in 5-bit images (moles, freckles, light reflections, etc.). More samples are available in appendix D.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Impact of the bound on metrics: We compare the metrics of the bounded model and the unbounded model both trained on FFHQ 256 ? 256.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1</head><label>1</label><figDesc>illustrates generated samples from the prior using the equation 4. We show a comparable subjective image quality and diversity to that of VDVAE. Although our models achieve a substantial improvement on the FFHQ 1024 ? 1024 NLL compared to the VDVAE baseline, they are still not expressive enough to generate good high quality high resolution images. We show unconditional samples with different temperatures on FFHQ 1024 ? 1024 and CelebAHQ 1024 ? 1024 in D.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 : 5 -</head><label>35</label><figDesc>bit quantization and banding effects on FFHQ 256?256 (best viewed zoomed in). From left to right: 5-bit targets, unbounded reconstruction, bounded reconstruction and finally the 8-bit targets. All on FFHQ 256 ?256. % of used posteriors</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>(a) Inference model q ? (z|x) (b) Generative model p ? (x, z) Bidirectional inference HVAE. The blue blocks are shared between the inference model and generative model. The inference model's (encoder) outputs are in the bidirectional case computed by both a pass through the bottom-up then the top-down blocks. Dashed lines represent optional connections between the bottom-up and top-down blocks (more details in C.2 and the source code).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4</head><label>4</label><figDesc>depicts the general form of a bidirectional inference HVAE, color-coded with: red for the inference model and blue for the generative model. Shared parameters between the inference and generative model are also coded in blue. The bottom-up blocks in the HVAE extract latent activations ? that are used later on by the top-down block to create the posterior distribution q ? (z L |x, z &lt;L ). Both the prior and posterior distributions are created within the top-down block and are used in the KL divergence term of the ELBO. During training, we sample z i from the posterior q ? (z i |x, z &lt;i ) which depends on the activations ? computed by the bottom-up blocks. During unconditional generation from the prior, the bottom-up blocks are unavailable, we thus sample z i from the prior p ? (z i |z &lt;i ) instead.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>C. 1</head><label>1</label><figDesc>Taming the exponentially growing variance of deep models in their work[16], VDVAE's author demonstrates how scaling the last convolution of each bottleneck residual block by 1/ ? L, L being the total number of latent hierarchical variables, helps stabilize the model's training. In their open sourced codebase, they additionally scale the weights of the projection of sample z (figure 5c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Image reconstructions with 100% of the posteriors (left) and 3% of the posteriors with the highest average KL divergence (right). Reconstruction differences are indistinguishable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>More unconditional samples on Imagenet 32 ? 32 (t = 0.85).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>More unconditional samples on Imagenet 64 ? 64 (t = 0.9).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 9 :</head><label>9</label><figDesc>Unconditional samples on MNIST (t = 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 10 :</head><label>10</label><figDesc>More unconditional samples on CelebA 64 ? 64 (t = 0.8).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 15 :Figure 16 :</head><label>1516</label><figDesc>More unconditional samples on CelebAHQ 1024 ? 1024. From top row to bottom row, temperatures are {0.4, 0.6, 0.8, 1.} More unconditional samples on FFHQ 1024 ? 1024. From top row to bottom row, temperatures are {0.3, 0.5, 0.7, 0.9}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>NLL and memory load with different configurations of stochastic layers on ImageNet 32 ? 32 (similar trends appear on the other benchmarks). (a): Networks with fixed low resolution, but with different number of middle and high resolution layers. The addition of extra layers in high resolution is a diminishing returns endeavor. (b): Networks with 84 stochastic layers, but with varying layer widths. Reducing the width of the model can save memory while getting comparable NLL results.</figDesc><table><row><cell>Batch size</cell><cell cols="2">Without gradient smoothing NLL (bits/dim) Skipped updates</cell><cell cols="2">With gradient smoothing NLL (bits/dim) Skipped updates</cell><cell>Dataset</cell><cell>Without gradient smoothing</cell><cell>With gradient smoothing</cell></row><row><cell>4 8 32</cell><cell>3.25 3.11 2.97</cell><cell>78 8 3</cell><cell>3.22 3.11 2.97</cell><cell>5 4 0</cell><cell>FFHQ 1024 ? 1024 CelebAHQ 1024 ? 1024</cell><cell>diverged diverged</cell><cell>6 23</cell></row><row><cell></cell><cell cols="3">(a) Gradient smoothing and batch size.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>(b) High resolution datasets.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Effects of gradient smoothing. (a)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>table 3</head><label>3</label><figDesc></figDesc><table><row><cell>Dataset</cell><cell></cell><cell>CIFAR-10</cell><cell></cell><cell cols="3">Imagenet 32 ? 32</cell><cell cols="3">Imagenet 64 ? 64</cell><cell cols="3">FFHQ 256 ? 256 (5-bits)</cell></row><row><cell>Model</cell><cell>C1</cell><cell>C2</cell><cell>VDVAE</cell><cell>C1</cell><cell>C2</cell><cell>VDVAE</cell><cell>C1</cell><cell>C2</cell><cell>VDVAE</cell><cell>C1</cell><cell>C2</cell><cell>VDVAE</cell></row><row><cell>Layers</cell><cell>47</cell><cell>47</cell><cell>43</cell><cell>73</cell><cell>73</cell><cell>78</cell><cell>84</cell><cell>84</cell><cell>75</cell><cell>66</cell><cell>66</cell><cell>66</cell></row><row><cell>width</cell><cell>incr.</cell><cell>384</cell><cell>384</cell><cell>incr.</cell><cell>512</cell><cell>512</cell><cell>incr.</cell><cell>512</cell><cell>512</cell><cell>incr.</cell><cell>512</cell><cell>512</cell></row><row><cell>Batch size</cell><cell>16</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>64</cell><cell>256</cell><cell>32</cell><cell>32</cell><cell>128</cell><cell>16</cell><cell>16</cell><cell>32</cell></row><row><cell>Learning rate</cell><cell>0.001</cell><cell>0.001</cell><cell>0.0001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.0001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.0001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.0001</cell></row><row><cell>Optimizer</cell><cell cols="2">Adamax Adamax</cell><cell>Adam</cell><cell cols="2">Adamax Adamax</cell><cell>Adam</cell><cell cols="2">Adamax Adamax</cell><cell>Adam</cell><cell cols="2">Adamax Adamax</cell><cell>Adam</cell></row><row><cell>Parameters</cell><cell>18M</cell><cell>57M</cell><cell>39M</cell><cell>52M</cell><cell>145M</cell><cell>119M</cell><cell>57M</cell><cell>168M</cell><cell>125M</cell><cell>67M</cell><cell>198M</cell><cell>115M</cell></row><row><cell>Time (h)</cell><cell>99</cell><cell>108</cell><cell>144</cell><cell>161</cell><cell>177</cell><cell>420</cell><cell>184</cell><cell>202</cell><cell>420</cell><cell>226</cell><cell>245</cell><cell>420</cell></row><row><cell>Training iter.</cell><cell>800k</cell><cell>800k</cell><cell>1.1M</cell><cell>800k</cell><cell>800k</cell><cell>1.7M</cell><cell>800k</cell><cell>800k</cell><cell>1.6M</cell><cell>850k</cell><cell>850k</cell><cell>1.7M</cell></row><row><cell>Memory (GB)</cell><cell>8</cell><cell>17</cell><cell>32</cell><cell>26</cell><cell>76</cell><cell>512</cell><cell>29</cell><cell>116</cell><cell>512</cell><cell>101</cell><cell>304</cell><cell>512</cell></row><row><cell>NLL (bits/dim)</cell><cell>? 2.91</cell><cell>? 2.87</cell><cell>? 2.87</cell><cell>? 3.60</cell><cell>? 3.58</cell><cell>? 3.80</cell><cell>? 3.33</cell><cell>? 3.30</cell><cell>? 3.52</cell><cell>? 0.61</cell><cell>? 0.60</cell><cell>? 0.61</cell></row></table><note>, we report the results on CIFAR-10 [25], ImageNet 32 ? 32, ImageNet 64 ? 64 [26] and FFHQ 256 ? 256 [27] datasets. In the worst case, Efficient-VDVAE has a 1.68? lower training memory load, converges in 1.38? less updates and trains 1.45? faster in clock time, while being consistently similar or better than the original VDVAE in terms of NLL. More compact Efficient-VDVAE configurations can also be trained to consume 20? less memory load,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Computational load comparison. We train 2 configurations of Efficient-VDVAE, derived from the VDVAE baseline by only modifying the hyper-parameters described in section 4. We report the convergence speed as measured in number of iterations and clock time (in hours). We also report the total training memory load of each model and their NLL at convergence time. The configuration C1 is only different from C2 in the use of incremental filter width (experiment of table 1b). A south-east arrow ( ) denotes the use of cosine decay. More detailed model hyper-parameters are available in table 6 and the source code.</figDesc><table><row><cell>Model</cell><cell>MNIST</cell><cell>CIFAR-10</cell><cell>Imagenet 32 ? 32</cell><cell>Imagenet 64 ? 64</cell><cell>CelebA 64 ? 64</cell><cell cols="2">CelebAHQ 256 ? 256</cell><cell cols="2">FFHQ 256 ? 256</cell><cell>CelebAHQ 1024 ? 1024</cell><cell>FFHQ 1024 ? 1024</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5-bits</cell><cell>8-bits</cell><cell>5-bits</cell><cell>8-bits</cell></row><row><cell>ANF[32]</cell><cell>-</cell><cell>3.05</cell><cell>3.92</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Comparison against state-of-the-art likelihood-based generative models. Unless otherwise specified, all datasets have 8-bit images. All benchmarks are in bits/dim except for MNIST benchmarks which are reported in nats.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Evolution of the encoded dataset (z) size and test costs (bits/dim) with the pruning of the latent posteriors on 8-bit FFHQ 256 ? 256 (uncompressed pixels size is ? 50GB). We observe that by only using 3% of the latent space, the encoded dataset size can be 33? smaller with a comparable negative ELBO results.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>table 4</head><label>4</label><figDesc></figDesc><table /><note>NLL scores for the 8-bit version of the FFHQ 256 ? 256 and CelebAHQ 256 ? 256 datasets.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>, 4 2 , 8 2 , 16 2 , 32 2 384, 384, 192, 96, 48 3, 4, 7, 11, 22 C2 1 2 , 4 2 , 8 2 , 16 2 , 32 2 384 3, 4, 7, 11, 22 VDVAE 1 2 , 4 2 , 8 2 , 16 2 , 32 2 , 4 2 , 8 2 , 16 2 , 32 2 , 64 2 , 128 2 , 256 , 4 2 , 8 2 , 16 2 , 32 2 , 64 2 , 128 2 , 256 VDVAE 1 2 , 4 2 , 8 2 , 16 2 , 32 2 , 64 2 , 128 2 , 256</figDesc><table><row><cell>Dataset</cell><cell>Model</cell><cell>Latent resolutions</cell><cell>Width</cell><cell>Layers per resolution</cell></row><row><cell>CIFAR-10</cell><cell>C1</cell><cell cols="2">1 2 384</cell><cell>1, 3, 6, 11, 22</cell></row><row><cell>Imagenet</cell><cell>C1</cell><cell>1 2 , 4 2 , 8 2 , 16 2 , 32 2</cell><cell>512, 512, 256, 128, 64</cell><cell>6, 7, 19, 25, 16</cell></row><row><cell>32 ? 32</cell><cell>C2</cell><cell>1 2 , 4 2 , 8 2 , 16 2 , 32 2</cell><cell>512</cell><cell>6, 7, 19, 25, 16</cell></row><row><cell></cell><cell>VDVAE</cell><cell>1 2 , 4 2 , 8 2 , 16 2 , 32 2</cell><cell>512</cell><cell>2, 5, 10, 20, 41</cell></row><row><cell>Imagenet</cell><cell>C1</cell><cell>1 2 , 4 2 , 8 2 , 16 2 , 32 2 , 64 2</cell><cell>512, 512, 256, 256, 64, 64</cell><cell>6, 7, 19, 25, 16, 11</cell></row><row><cell>64 ? 64</cell><cell>C2</cell><cell>1 2 , 4 2 , 8 2 , 16 2 , 32 2 , 64 2</cell><cell>512</cell><cell>6, 7, 19, 25, 16, 11</cell></row><row><cell></cell><cell>VDVAE</cell><cell>1 2 , 4 2 , 8 2 , 16 2 , 32 2 , 64 2</cell><cell>512</cell><cell>2, 4, 8, 16, 32, 13</cell></row><row><cell>FFHQ</cell><cell>C1</cell><cell cols="3">1 2 2 512, 512, 512, 256, 256, 128, 128, 128 2, 4, 5, 10, 22, 14, 8, 1</cell></row><row><cell>256 ? 256</cell><cell>C2</cell><cell>1 2 2</cell><cell>512</cell><cell>2, 4, 5, 10, 22, 14, 8, 1</cell></row><row><cell></cell><cell></cell><cell>2</cell><cell>512</cell><cell>2, 4, 5, 10, 22, 14, 8, 1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Layers distribution by resolution. A single integer in the width column means that width was kept constant for the entire model (outside of the bottleneck residual blocks).</figDesc><table><row><cell>Model depth</cell><cell cols="2">Without gradient smoothing</cell><cell cols="2">With gradient smoothing</cell></row><row><cell></cell><cell cols="2">NLL (bits/dim) Skipped updates</cell><cell cols="2">NLL (bits/dim) Skipped updates</cell></row><row><cell>30</cell><cell>2.28</cell><cell>2</cell><cell>2.27</cell><cell>0</cell></row><row><cell>49</cell><cell>2.20</cell><cell>9</cell><cell>2.21</cell><cell>1</cell></row><row><cell>66</cell><cell>2.18</cell><cell>14</cell><cell>2.18</cell><cell>0</cell></row><row><cell>69</cell><cell>2.18</cell><cell>24</cell><cell>2.17</cell><cell>0</cell></row><row><cell>75</cell><cell>2.17</cell><cell>37</cell><cell>2.17</cell><cell>2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>Effect of reducing the bottom-up model's depth on CIFAR-10.</figDesc><table><row><cell></cell><cell cols="3">Distribution of Layers</cell><cell></cell><cell>Memory</cell><cell>NLL</cell></row><row><cell cols="5">32 ? 32 16 ? 16 8 ? 8 4 ? 4 1 ? 1</cell><cell>(GB)</cell><cell>(bits/dim)</cell></row><row><cell>0</cell><cell>11</cell><cell>7</cell><cell>4</cell><cell>3</cell><cell>9</cell><cell>2.96</cell></row><row><cell>11</cell><cell>11</cell><cell>7</cell><cell>4</cell><cell>3</cell><cell>13</cell><cell>2.91</cell></row><row><cell>22</cell><cell>11</cell><cell>7</cell><cell>4</cell><cell>3</cell><cell>17</cell><cell>2.87</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 9 :</head><label>9</label><figDesc>Effect of using high resolution layers on CIFAR-10. These results hold for all other datasets we tried except for MNIST because it has a binary distribution that we model using the Bernoulli distribution.C.2 Asymmetrical model design Traditionally, HVAEs were built to have symmetrical bottom-up and top-down models, where each top-down block i receives a different activation ? i from a bottom-up block L ? i. VDVAE breaks this symmetry by allowing K consecutive top-down blocks {i, i + 1, ..., i + K} to use the same activation ? i . More specifically, ? i is only extracted from the bottom-up model once per latent resolution, and is used for all top-down blocks of that resolution.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">On occasions, the official released codebase parameters differs from what's reported in the paper. In that case we rely on the codebase version.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Alex Krizhevsky for his mentorship and insightful discussions. The authors also thank Joe Palermo, Marc Tyndel, Hashiam Kadhim and Stephen Piron for their feedback and support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Conditional image generation with pixelcnn decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik P</forename><surname>Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.05517</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Andriyash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Vinci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Buffoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad H</forename><surname>Amin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.09948</idno>
		<title level="m">Pixelvae++: Improved pixelvae with discrete prior</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Distribution augmentation for generative modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<editor>Hal Daum? III and Aarti Singh</editor>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Unsupervised feature learning and deep learning: A review and new perspectives. CoRR, abs/1206</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">5538</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Deep generative modelling: A comparative review of vaes, gans, normalizing flows, energy-based and autoregressive models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Bond-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">G</forename><surname>Willcocks</surname></persName>
		</author>
		<idno>abs/2103.04922</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niru</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improved denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Quinn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nichol</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8162" to="8171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno>abs/1611.07004</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno>abs/1703.10593</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Very deep {vae}s generalize autoregressive models and can outperform them on images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">An introduction to variational autoencoders. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A tutorial on vaes: From bayes&apos; rule to lossless compression. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hierarchical variational models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="324" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improved variational inference with inverse autoregressive flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ladder variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Casper Kaae S?nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maal?e</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>S?ren Kaae S?nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning hierarchical priors in vaes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexej</forename><surname>Klushyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nutan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Kurle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smagt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nvae: A deep hierarchical variational autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Cifar-10 (canadian institute for advanced research)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Flickr faces hq (ffhq) 70k from stylegan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">MNIST handwritten digit database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3730" to="3738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Autoencoding beyond pixels using a learned similarity metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Boesen Lindbo Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?ren</forename><forename type="middle">Kaae</forename><surname>S?nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Winther</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<editor>Maria Florina Balcan and Kilian Q. Weinberger</editor>
		<meeting>The 33rd International Conference on Machine Learning<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="20" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<idno>abs/1710.10196</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.07101</idno>
		<title level="m">Augmented normalizing flows: Bridging the gap between generative flows and latent variable models</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Flow++: Improving flow-based generative models with variational dequantization and architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2722" to="2730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Glow: Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Densely connected normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Grci?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Grubi?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sini?a</forename><surname>?egvi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Preventing posterior collapse with delta-vaes. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A?ron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinyals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Generating high fidelity images with subscale pixel networks and multidimensional upscaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01608</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Macow: Masked convolutional generative flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Locally masked convolution for autoregressive models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1358" to="1367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Image transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4055" to="4064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Generating long sequences with sparse transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.10509</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Score matching model for unbounded data score</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongjun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungjae</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyungwoo</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanmo</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Il-Chul</forename><surname>Moon</surname></persName>
		</author>
		<idno>abs/2106.05527</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.00630</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">Variational diffusion models. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Consistency regularization for variational auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarth</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adji</forename><surname>Bousso Dieng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02731</idno>
		<title level="m">Ilya Sutskever, and Pieter Abbeel. Variational lossy autoencoder</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhou Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">How to train your neural ode: the world of jacobian and kinetic regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Finlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levon</forename><surname>Nurbekyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">M</forename><surname>Oberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3154" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Score-based generative modeling in latent space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Kreis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Adaptive debanding filter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengzhong</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessie</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balu</forename><surname>Adsumilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1715" to="1719" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Capturing banding in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jatin</forename><surname>Sapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Kapoor</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">08</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Variational autoencoders pursue pca directions (by accident)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Rolinek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominik</forename><surname>Zietlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Martius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12406" to="12415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unsupervised model selection for variational disentangled representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunny</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Saraiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Watters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Lerchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The continuous categorical: a novel simplex-valued exponential family</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliott</forename><surname>Gordon-Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Loaiza-Ganem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">P</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3637" to="3647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Neural discrete representation learning. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">NWT: towards natural audio-to-video generation with representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayhane</forename><surname>Mama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">S</forename><surname>Tyndel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hashiam</forename><surname>Kadhim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cole</forename><surname>Clifford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ragavan</forename><surname>Thurairatnam</surname></persName>
		</author>
		<idno>abs/2106.04283</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Abdelrahman Mohamed, and Michael Auli. wav2vec 2.0: A framework for self-supervised learning of speech representations. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
