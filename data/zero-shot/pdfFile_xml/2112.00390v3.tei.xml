<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SegDiff: Image Segmentation with Diffusion Probabilistic Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Amit</surname></persName>
							<email>tomeramit1@mail.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="institution">Tel-Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Shaharbany</surname></persName>
							<email>shaharabany@mail.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="institution">Tel-Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliya</forename><surname>Nachmani</surname></persName>
							<email>eliyan@mail.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="institution">Tel-Aviv University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
							<email>wolf@mail.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="institution">Tel-Aviv University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SegDiff: Image Segmentation with Diffusion Probabilistic Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Diffusion Probabilistic Methods are employed for stateof-the-art image generation. In this work, we present a method for extending such models for performing image segmentation. The method learns end-to-end, without relying on a pre-trained backbone. The information in the input image and in the current estimation of the segmentation map is merged by summing the output of two encoders. Additional encoding layers and a decoder are then used to iteratively refine the segmentation map, using a diffusion model. Since the diffusion model is probabilistic, it is applied multiple times, and the results are merged into a final segmentation map. The new method produces state-ofthe-art results on the Cityscapes validation set, the Vaihingen building segmentation benchmark, and the MoNuSeg dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Diffusion methods, which iteratively improve a given image, obtain image quality that is on par with or better than other types of generative models, including other forms of log-likelihood models and adversarial models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19]</ref>. Such methods have been shown to excel in many generation tasks, both conditional and unconditional.</p><p>The vast majority of diffusion models are applied in domains in which there is no absolute ground truth result and the output is evaluated either through a user study or using several quality and diversity scores. As far as we know, with the exception of super resolution <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b40">41]</ref>, diffusion models have not been applied to problems in which the ground truth result is unique.</p><p>In this work, we tackle the problem of image segmentation. This problem is a cornerstone of both classical computer vision and the deep learning methods of the last decade. The leading methods in the field employ encoder-decoder networks of varied architectures <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b52">53]</ref>. While adversarial methods have been attempted <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b50">51]</ref>, they do not constitute the current state of the art.</p><p>Therefore, it is uncertain whether diffusion models, which have been used primarily for GAN-like generation tasks, would be competitive in this domain. In this work, we propose applying a diffusion model to learn the image segmentation map. Unlike other recent improvements in the field of image segmentation <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b43">44]</ref>, we train our method end-to-end, without relying on a pre-trained backbone network.</p><p>The diffusion model employs a denoising network conditioned on the input image only through a sum in which this information is aggregated with information arising from the current estimate x t . Specifically, the input image I and the current estimate x t of the binary segmentation map are passed through two different encoders, and the sum of these multi-channel tensors is passed through a U-Net <ref type="bibr" target="#b37">[38]</ref> to provide the next estimate x t?1 .</p><p>Since the generation process is stochastic in its nature, one may obtain multiple solutions. As we show, merging these solutions, by simply averaging multiple runs, leads to an improvement in overall accuracy.</p><p>The novel method presented produces state-of-the-art results on multiple benchmarks: Cityscapes <ref type="bibr" target="#b8">[9]</ref>, building segmentation <ref type="bibr" target="#b38">[39]</ref>, and nuclei segmentation <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>Our main contributions are:</p><p>? We are the first to apply diffusion models to the image segmentation problem.</p><p>? We propose a new way to condition the model on the input image.</p><p>? We introduce the concept of multiple generations, in order to improve performance and calibration of the diffusion model.</p><p>? We obtained state-of-the-art results on multiple benchmarks. The margin is especially large for small data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Image segmentation is a problem of assigning each pixel a label that identifies whether it belongs to a specific class or not. This problem is widely investigated using different architectures. These include fully convolutional networks <ref type="bibr" target="#b30">[31]</ref>, encoder-decoder architectures with skip-connections, such as U-Net <ref type="bibr" target="#b37">[38]</ref>, transformer-based architectures, such as the segformer <ref type="bibr" target="#b49">[50]</ref>, and even architectures that combine hypernetworks, such as <ref type="bibr" target="#b35">[36]</ref>. Diffusion Probabilistic Models (DPM) <ref type="bibr" target="#b42">[43]</ref> are a class of generative models based on a Markov chain, which can transform a simple distribution (e.g. Gaussian) to data that is sampled in a complex distribution. Diffusion models are capable of generating high-quality images that can compete with and even outperform the latest GAN methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b42">43]</ref>. A variational framework for the likelihood estimation of diffusion models was introduced by Huang et al. <ref type="bibr" target="#b20">[21]</ref>. Subsequently, Kingma et al. <ref type="bibr" target="#b22">[23]</ref> proposed a Variational Diffusion Model that produces state-ofthe-art results in likelihood estimation for image density. Diffusion models were also applied to language modeling <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b19">20]</ref>, where a novel diffusion model for categorical data was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conditional Diffusion Probabilistic Models</head><p>In our work, we use diffusion models to solve the image segmentation problem as conditional generation, given the image. Conditional generation with diffusion models includes methods for class-conditioned generation, which is obtained by adding a class embedding to the timestamp embedding <ref type="bibr" target="#b34">[35]</ref>. In <ref type="bibr" target="#b7">[8]</ref> a method for guiding the generative process in DDPM is present. This method allows the generation of images based on a given reference image without any additional learning.</p><p>In the domain of super resolution, the lower-resolution image is upsampled and then concatenated, channelwise, to the generated image at each iteration <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b40">41]</ref>. A similar approach passes the low-resolution images through a convolutional block <ref type="bibr" target="#b26">[27]</ref> prior to the concatenation. Concurrently with our work, diffusion models were applied to image-to-image translation tasks <ref type="bibr" target="#b39">[40]</ref>. These tasks include uncropping, inpainting, and colorization. The results obtained outperform strong GAN baselines.</p><p>Conditional diffusion models have also been used for voice generation. The mel-spectrogram is processed with a convolutional network, and is used as an additional input to the DPM denoising network <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b29">30]</ref>. Furthermore, in <ref type="bibr" target="#b36">[37]</ref> a text-to-speech diffusion model is introduced, which uses text as a condition to the diffusion model.</p><p>In our work, we take a different approach to conditioning, adding (not concatenating) the input image, after it passes through an convolutional encoder, to the current estimation of the segmentation image. In other words, we learn the DPM of a residual model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Background</head><p>We briefly introduce the formulation of diffusion models mentioned in <ref type="bibr" target="#b17">[18]</ref>. Diffusion models are generative models parametrized by a Markov chain and composed of forward and backward processes. The forward process q is described by the formulation:</p><formula xml:id="formula_0">q(x 1:T |x 0 ) = T t=1 q(x t |x t?1 ),<label>(1)</label></formula><p>where T is the number of steps in the diffusion model, x 1 , ..., x T are latent variables, and x 0 is a sample from the data. At each iteration of the forward process, Gaussian noise is added according to</p><formula xml:id="formula_1">q(x t |x t?1 ) = N (x t ; 1 ? ? t x t?1 , ? t I n?n ),<label>(2)</label></formula><p>where ? t is a constant that defines the schedule of added noise, and I n?n is the identity matrix of size n. As described in <ref type="bibr" target="#b17">[18]</ref>,</p><formula xml:id="formula_2">? t = 1 ? ? t ,? t = t s=0 ? s .<label>(3)</label></formula><p>The forward process supports sampling at an arbitrary timestamp t, with the formula</p><formula xml:id="formula_3">q(x t |x 0 ) = N (x t ; ?? t x 0 , (1 ?? t )I n?n ),<label>(4)</label></formula><p>which can be reparametrized to:</p><formula xml:id="formula_4">x t = ?? t x 0 + (1 ?? t ) , ? N (0, I n?n ). (5)</formula><p>The reverse process is parametrized by ? and defined by</p><formula xml:id="formula_5">p ? (x 0:T ?1 |x T ) = T t=1 p ? (x t?1 |x t ).<label>(6)</label></formula><p>Starting from p ? (x T ) = N (x T ; 0, I n?n ), the reverse process transforms the latent variable distribution p ? (x T ) to the data distribution p ? (x 0 ). The reverse process steps are performed by taking small Gaussian steps described by</p><formula xml:id="formula_6">p ? (x t?1 |x t ) = N (x t?1 ; ? ? (x t , t), ? ? (x t , t)).<label>(7)</label></formula><p>Calculating q(x t?1 |x t , x 0 ) using Bayes' theorem, one obtains: <ref type="figure">Figure 1</ref>. Our proposed diffusion method for image segmentation encodes the input signal, xt, with F . The extracted features are summed with the feature map of the conditioned image I generated by network G. Networks E and D are a U-net encoder and decoder <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b37">38]</ref>, respectively, that refine the estimated segmentation map, obtaining xt?1.</p><formula xml:id="formula_7">q(x t?1 |x t , x 0 ) = N (x t?1 ;?(x t , x 0 ),? t I n?n ),<label>(8)</label></formula><p>wher?</p><formula xml:id="formula_8">? t (x t , x 0 ) = ?? t?1 ? t 1 ?? t x 0 + ? ? t (1 ?? t?1 ) 1 ?? t x t ,<label>(9)</label></formula><formula xml:id="formula_9">? = 1 ?? t?1 1 ?? t ? t .<label>(10)</label></formula><p>The neural network ? ? predicts the noise , which is parametrized using Eq. 5, 9 to obtain:</p><formula xml:id="formula_10">? ? (x t , t) = 1 ? ? t (x t ? ? t ? 1 ?? t ? (x t , t)).<label>(11)</label></formula><p>Following <ref type="bibr" target="#b17">[18]</ref> we set</p><formula xml:id="formula_11">? ? (x t , t) = ? 2 t I n?n ,<label>(12)</label></formula><p>where</p><formula xml:id="formula_12">? 2 t =? t .<label>(13)</label></formula><p>The forward process variance parameter is chosen to be a linearly increasing constant from ? 1 = 10 ?4 to ? T = 2 * 10 ?2 , formally:</p><formula xml:id="formula_13">? t = 10 ?4 (T ? t) + 2 * 10 ?2 (t ? 1) T ? 1 .<label>(14)</label></formula><p>Finally, we will minimize the term</p><formula xml:id="formula_14">E x0, ,t [|| ? ? ( ?? t x 0 + ? 1 ?? t , t)|| 2 ],<label>(15)</label></formula><p>where ? N (0, I n?n ).</p><p>For inference, we can reparametrize the reverse process, Eq. 7, with Eq. 11, obtaining</p><formula xml:id="formula_15">x t?1 = 1 ? ? t (x t ? 1 ? ? t ? 1 ?? t ? (x t , t)) + ? ? z.<label>(16)</label></formula><formula xml:id="formula_16">Algorithm 1 Inference Algorithm Input total diffusion steps T, image I x T ? N (0, I n?n ) for t = T, T ? 1, ..., 1 do z ? N (0, I n?n ) ? t = 10 ?4 (T ?t)+2 * 10 ?2 (t?1) T ?1 ? t = 1 ? ? t ? t = t s=0 ? s ? t = 1??t?1 1??t ? t x t?1 = ? t ? 1 2 (x t ? 1??t ? 1??t ? (x t , I, t)) + 1 [t&gt;1]? 1 2 t z return x 0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Training Algorithm</head><p>Input total diffusion steps T, images and segmentation</p><formula xml:id="formula_17">masks dataset D = {(I k , M k )} K k = 1 repeat Sample (I i , M i ) ? D, ? N (0, I n?n ) Sample t ? Uniform({1,...,T}) ? t = 10 ?4 (T ?t)+2 * 10 ?2 (t?1) T ?1 ? t = 1 ? ? t ? t = t s=0 ? s Take gradient step on ? ? || ? ? (x t , I i , t)||, x t = ?? t M i + ? 1 ?? t until convergence</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method</head><p>Our method modifies the diffusion model by conditioning the step estimation function ? on an input tensor that combines information derived from both the current estimate x t and the input image I.</p><p>In diffusion models, ? is typically a U-Net <ref type="bibr" target="#b37">[38]</ref>. In our work, ? can be expressed in the following form:</p><formula xml:id="formula_18">? (x t , I, t) = D(E(F (x t ) + G(I), t), t) .<label>(17)</label></formula><p>In this architecture, the U-Net's decoder D is conventional and its encoder is broken down into three networks: E, F , and G. The last encodes the input image, while F encodes the segmentation map of the current step x t . The two processed inputs have the same spatial dimensionality and number of channels. Based on the success of residual connections <ref type="bibr" target="#b16">[17]</ref>, we sum these signals F (x t ) + G(I). This sum then passes to the rest of the U-Net encoder E. The current step index t is passed to two different networks D and E. In each of these, it is embedded using a shared learned look-up table.</p><p>The output of ? from Eq. 17, which is conditioned on I, is plugged into Eq. 16, replacing the unconditioned ? network. This resulting inference time procedure is illustrated in <ref type="figure">Fig. 1</ref> and detailed in Alg. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Employing multiple generations</head><p>Since calculating x t?1 during inference includes the addition of ? ? (x t , t)z, where z is from a standard distribution, there is significant variability between different runs of the inference method on the same inputs, see <ref type="figure" target="#fig_0">Fig. 2</ref></p><formula xml:id="formula_19">(b).</formula><p>In order to exploit this phenomenon, we run the inference algorithm multiple times, then average the results.</p><p>This way, we stabilize the results of segmentation and improve performance, as demonstrated in <ref type="figure" target="#fig_0">Fig. 2</ref>(c). We use thirty generated instances in all experiments, except for the experiments in the ablation study, which quantifies the gain of this averaging procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Training</head><p>The training procedure is depicted in Alg. 2. The total number of diffusion steps T is set by the user. For each iteration, a random sample is obtained (I i , M i ) (an image and the associated ground truth binary segmentation map). The iteration number 1 ? t ? T is sampled from a uniform distribution, and epsilon from a standard distribution.</p><p>We then sample x t according to Eq. 5, compute F (x t ) + G(I i ), and apply networks E and D to obtain ? (x t , I i , t).</p><p>The loss being minimized is a modified version of Eq 15, namely:</p><formula xml:id="formula_20">E x0, ,xe,t [|| ? ? ( ?? t x 0 + ? 1 ?? t , I i , t)|| 2 ]. (18)</formula><p>At training time, the ground truth segmentation of the input image I i is known, and the loss is computed by setting</p><formula xml:id="formula_21">x 0 = M i .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Architecture</head><p>The input image encoder G is built from Residual in Residual Dense Blocks <ref type="bibr" target="#b46">[47]</ref> (RRDBs), which combine multi-level residual connections without batch normalization layers. G has an input 2D-convolutional layer, an RRDB with a residual connection around it, followed by another 2D-convolutional layer, leaky RELU activation and a final 2D-convolutional output layer. F is a 2Dconvolutional layer with a single-channel input and an output of C channels.</p><p>The encoder-decoder part of ? , i.e., D and E, is based on U-Net, similarly to <ref type="bibr" target="#b34">[35]</ref>. Each level is composed of residual blocks, and at resolution 16x16 and 8x8 each residual block is followed by an attention layer. The bottleneck contains two residual blocks with an attention layer in between. Each attention layer contains multiple attention heads.</p><p>The residual block is composed of two convolutional blocks, where each convolutional block contains groupnorm, Silu activation, and a 2D-convolutional layer. The residual block receives the time embedding through a linear layer, Silu activation, and another linear layer. The result is then added to the output of the first 2D-convolutional block. Additionally, the residual block has a residual connection that passes all its content.</p><p>On the encoder side (network E), there is a downsample block after the residual blocks of the same depth, which is a 2D-convolutional layer with a stride of two. On the decoder side (network D), there is an upsample block after the residual blocks of the same depth, which is composed of the nearest interpolation that doubles the spatial size, followed by a 2D-convolutional layer. Each layer in the encoder has a skip connection to the decoder side.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We present segmentation results for three datasets, as well as an ablation study. Datasets The Cityscapes dataset <ref type="bibr" target="#b8">[9]</ref> is an instance segmentation dataset containing 5,000 annotated images divided into 2,975 images for training, 500 for validation, and 1,525 for testing.</p><p>The experimental setting used is sometimes referred to as interactive segmentation and is motivated by the need to accelerate object annotation <ref type="bibr" target="#b0">[1]</ref>. Under this setting, there are eight object categories, and the goal is to recover the objects' per-pixel masks, given a cropped patch that contains the bounding box around each object.</p><p>Our per-object training and validation sets are created by taking crops from images in the original Cityscapes sets using the locations of the ground truth classes (we do not have access to the ground truth labels of the original Cityscapes test set). We compared our method for the Cityscapes dataset with PSPDeepLab <ref type="bibr" target="#b4">[5]</ref>, Polygon-RNN++ <ref type="bibr" target="#b0">[1]</ref>, Curve-GCN <ref type="bibr" target="#b28">[29]</ref> Deep active contours <ref type="bibr" target="#b13">[14]</ref>, Segformer-B5 <ref type="bibr" target="#b49">[50]</ref> and Stdc1 <ref type="bibr" target="#b10">[11]</ref>. For most baselines, we report the results obtained from previous publications. For Segformer and Stdc, we train from scratch.</p><p>We did not perform a comparison with PolyTrans-form <ref type="bibr" target="#b27">[28]</ref>, since it uses a different protocol. Specifically, this method, which improves upon Mask R-CNN <ref type="bibr" target="#b15">[16]</ref>, utilizes the entire image (and not just the segmentation patch) as part of its inputs, and does not work on standard patches in a way that would enable a direct comparison. The Vaihingen dataset <ref type="bibr" target="#b38">[39]</ref> contains 168 aerial images of Vaihingen, in Germany, divided into 100 images for train-ing and 68 for the test. The task is to segment the central building in each image. For this dataset, the leading baselines are DSAC <ref type="bibr" target="#b33">[34]</ref>, DarNet <ref type="bibr" target="#b6">[7]</ref>, TDAC <ref type="bibr" target="#b14">[15]</ref>, Deep active contours <ref type="bibr" target="#b13">[14]</ref>, FCN-UNET <ref type="bibr" target="#b37">[38]</ref>, FCN-ResNet-34, FCN-HarDNet-85 <ref type="bibr" target="#b3">[4]</ref>, Segformer-B5 <ref type="bibr" target="#b49">[50]</ref> and Stdc1 <ref type="bibr" target="#b10">[11]</ref>.</p><p>The MoNuSeg dataset <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> contains a training set with 30 microscopic images from seven organs, with annotations of 21,623 individual nuclei. The test dataset contains 14 similar images. We resized the images to a resolution of 512 ? 512, following <ref type="bibr" target="#b44">[45]</ref>. The relevant baseline methods are FCN <ref type="bibr" target="#b2">[3]</ref>, UNET <ref type="bibr" target="#b37">[38]</ref>, UNET++ <ref type="bibr" target="#b52">[53]</ref>, Res-Unet <ref type="bibr" target="#b47">[48]</ref>, Axial attention (A.A) Unet <ref type="bibr" target="#b45">[46]</ref> and Medical transformer <ref type="bibr" target="#b44">[45]</ref>. Evaluation The Cityscapes dataset is evaluated using the common metrics of mean Intersection-over-Union (mIoU) per class.</p><formula xml:id="formula_22">mIoU (y i ,? i ) = N i=1 T P (y i ,? i ) T P (y i ,? i ) + F N (y i ,? i ) + F P (y i ,? i )<label>(19)</label></formula><p>Where N is the number of classes in the dataset, TP is the true positive between the ground truth y and output mask?, FN is a false negative, and FP is a false positive.</p><p>The Vaihingen dataset is evaluated using several metrics: mIoU, F1-score, Weighted Coverage (WCov), and Boundary F-score (BoundF), as described in <ref type="bibr" target="#b6">[7]</ref>. Briefly, the prediction is correct if it is within a certain distance threshold from the ground truth. The benchmarks use five thresholds, from 1px to 5px, for evaluating performance.</p><p>Following previous work, evaluation on the MoNuSeg dataset is performed using mIoU and the F1-score. Training details The number of diffusion steps in previous works was 1000 <ref type="bibr" target="#b17">[18]</ref> and even 4000 <ref type="bibr" target="#b34">[35]</ref>. The literature suggests that more is better <ref type="bibr" target="#b41">[42]</ref>. In our main experiments, we employ 100 diffusion steps to reduce inference time. An additional set of experiments investigated the influence of the number of diffusion steps on the performance and runtime of the method.</p><p>The AdamW <ref type="bibr" target="#b31">[32]</ref> optimizer is used in all our experiments. Based on the intuition that the more RRDB blocks, the better the results, we used as many blocks as we could fit on the GPU without overly reducing batch size. The Unet used for datasets with a resolution of 256 ? 256 has one additional layer with respect to the dataset with half that resolution, in order to account for the spatial dimensions.</p><p>On the Cityscapes dataset, the input resolution of our model is 128 ? 128. The test metrics are computed on the original resolution; therefore, we resized the prediction to the original image size.</p><p>Training took place with a batch size of 30 images. The network had 15 RRDB blocks and a depth of six. The number of channels was set to [C, C, 2C, 2C, 4C, 4C] with C = 128. We followed the same augmentation scheme as in <ref type="bibr" target="#b13">[14]</ref>, including random scaling in the range of [0.75, 1.25], with up to 22 degrees rotation in each direction, and a horizontal flip with a probability of 0.5.</p><p>For the Vaihingen dataset, the size of the input image and the test image resolution was 256 ? 256. The experiments were performed with a batch size of eight images, six RRDB blocks, and a depth of seven. The number of channels was set to [C, C, C, 2C, 2C, 4C, 4C] with C = 128.</p><p>The same augmentations are used as in <ref type="bibr" target="#b6">[7]</ref>: random scaling by a factor sampled uniformly in the range [0.75, 1.5], a rotation sampled uniformly between zero and 360 degrees, independent horizontal and vertical flips, applied with a probability of 0.5, and a random color jitter, with a maximum value of 0.6 brightness, 0.5 contrast, 0.4 saturation, and 0.025 hue.</p><p>For MoNuSeg, the input image resolution was 256?256, but the test resolution was 512 ? 512. To address this, we applied a sliding window of 256 ? 256 with a stride of 256, i.e., we tested each quadrant of the image separately.</p><p>The experiments were carried out with a batch size of eight images, with 12 RRDB blocks. The network depth was seven, and the number of channels in each depth was [C, C, C, 2C, 2C, 4C, 4C], with C = 128. We used the same augmentation scheme as in <ref type="bibr" target="#b44">[45]</ref> with random cropping of 256 ? 256 to adjust for GPU memory.</p><p>It is worth noting that all baseline methods except Segformer and Stdf rely on pre-trained weights obtained on the ImageNet, PASCAL or COCO datasets. Our networks are initialized with random weights. Results Following previous work, Cityscapes is evaluated in one of two settings. Tight: in this setting, the samples (image and associated segmentation map) are extracted by a tight crop around the object mask. Expansion: samples are extracted by a crop around the object mask, which is 15% larger than the tight crop. The inputs of the model are crops 10% -20% larger than the tight one. This setting is slightly more challenging, since there is less information on the location of the target object.</p><p>The results for the Cityscapes dataset are reported in Tab. 1. As can be seen, our method outperforms all baseline methods, across all categories and in both settings.</p><p>The gap is apparent even for the most recent baseline methods and, as can be seen in <ref type="figure" target="#fig_1">Fig. 3</ref>, the gap in performance is especially sizable for datasets with less training images.</p><p>The results for the Vaihingen dataset are presented in Tab. 2. As can be seen, our method outperforms the results reported in previous work for all four scores.</p><p>The results for the MoNuSeg dataset are presented in Tab. 3. In both segmentation metrics, our method outperforms all previous works, including very recent variants of U-Net and transformers that were developed specifically for this segmentation task. 28.84 28.71 U-Net <ref type="bibr" target="#b37">[38]</ref> 79.43 65.99 U-Net++ <ref type="bibr" target="#b52">[53]</ref> 79.49 66.04 Res-UNet <ref type="bibr" target="#b47">[48]</ref> 79.49 66.07 A.A U-Net <ref type="bibr" target="#b45">[46]</ref> 76.83 62. <ref type="bibr" target="#b48">49</ref> MedT <ref type="bibr" target="#b44">[45]</ref> 79.55 66.17 Ours 81.59 69.00 <ref type="table">Table 3</ref>. Segmentation results for the MoNuSeg dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>The performance of the mIoU segmentation metric as a function of the number of iterations is presented for the three datasets in <ref type="figure">Fig. 4</ref>. It is interesting to note that the number of diffusion steps required to achieve the maximal score differs across the datasets.</p><p>All Cityscapes classes present similar behavior (with different levels of performance), saturating around the 60th iteration. The Vaihingen score takes longer to reach its maximal value. While one may attribute this to the larger input image size observed by the network, MoNuSeg, which has the same input image size as Vaihingen, reaches satura-  tion earlier, similarly to the Cityscapes classes. An alternative hypothesis can relate the number of required iterations to the ratio of pixels within the segmentation mask, which is higher for Cityscapes and MoNuSeg than for Vaihingen. This requires further validation. We next study the effect of the number of generated in-  stances on performance. The results can be seen in <ref type="figure">Fig. 5</ref>.</p><p>In general, increasing the number of generated instances tends to increase the mIoU score. However, the number of runs required to reach optimal performance varies between classes. For example, for the "Bus" and "Train" classes of Cityscapes, the best score is achieved when using 10 and 3 generated instances, respectively. MoNuSeg, requires considerably more runs <ref type="bibr" target="#b24">(25)</ref> for maximal performance. On the other hand, when the number of generated instances is increased, inference time also increases linearly, resulting in a slower method compared to architectures such as Segformer and Stdc.</p><p>Another aspect of achieving improvement by employing multiple generations is calibration. The calibration score is measured as the difference between the prediction probability and the true probability of the event. For example, a perfectly calibrated model is defined by P(? = Y |P = p) = p, which means that the prediction probability equals the true probability of the event. We estimate the calibration score by splitting the [0, 1] range into ten uniform bins, then average the squared difference between each bin's mean prediction probability and the percentage of positive samples.</p><p>The results of examining the calibration scores are pre-  <ref type="figure">Fig. 6</ref>. For most datasets, increasing the number of generated instances improves the calibration score, especially when the increase is from a single instance. In addition, for the larger classes in Cityscapes -Rider and Bicycle -and for the MoNuSeg and Vaihingen datasets, the improvement continues to increase even more compared to the other datasets. The "Train" class in Cityscapes is an exception; here, the single-instance calibration score is better than other experiments with a larger number of generated instances. This phenomenon may be a result of the highly varied size and the small number of test images.</p><p>Ablation Study We evaluate various alternatives to our method. The first variant concatenates [F (x t ), G(I)] at the channel dimension. The second variant employs FC-HarDNet-70 V2 <ref type="bibr" target="#b3">[4]</ref> instead of RRDBs. The third variant, following <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b40">41]</ref>, concatenates I channelwise to x t , with- out using an encoder. The last alternative method is to propagate F (x t ) through the U-Net module and add it to G(I) after the first, third, and fifth downsample blocks (variants four-six), instead of performing F (x t ) + G(I). In this variant, G(I) is downsampled to match the required number of channels by propagating it through a 2D-convolutional layer with a stride of two.</p><p>These variant experiments were tested by averaging nine generated instances on the Vaihingen dataset and on Cityscapes "Bus" (the performance reported for our method is therefore slightly different from those reported in Tab. 2).</p><p>The summation we introduce as a conditioning approach outperforms concatenation (variant one) on Vaihingen by a large margin, while on Cityscapes "Bus", the difference is small. The RRDB blocks are preferable to the FC-HarDNet architecture in both datasets (variant two). Removing the encoder affects the metrics significantly (variant three), slightly more so on Vaihingen. The change in the signal's integration position of variant four leads to a negligible difference on Vaihingen and even outperforms our full method on Cityscapes "Bus". Variants five and six lead to a decrease in performance as the distance from the first layer increases. <ref type="figure">Fig. 7</ref> depicts sample results for the various variants (one-four) of the Vaihingen dataset.</p><p>Parameter sensitivity For testing the stability of our proposed method, we experimented with the two hyperparam-eters that can affect performance the most: the number of diffusion steps, and the number of RRDB blocks. To study the effect of these parameters, we varied the number of diffusion steps in the range of <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr">75,</ref><ref type="bibr">100,</ref><ref type="bibr">150,</ref><ref type="bibr">200]</ref>, and the number of RRDB blocks in the range of <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10]</ref> for Vaihingen and <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25]</ref> for Cityscapes "Bus". We started from a baseline configuration (which was 100 diffusion steps, 3 RRDB blocks for Vaihingen, and 10 RRDB blocks for Cityscapes "Bus") and experimented with different values around these. The effect of the number of RRDB blocks In this part we set the number of diffusion steps to 100. As can be seen in <ref type="figure">Fig. 8</ref>, with our configuration, the optimal number of RRDB blocks is 3 for Vaihingen, and 10 for Cityscapes "Bus". However, evidently, the number of blocks has a limited impact in the case of both Cityscapes and Vaihingen. The gap between the best and worst performance points is less than 1 mIoU for Vaihingen and less than 2 mIoU for Cityscapes "Bus". Therefore, we conclude that this hyperparameter has a small effect on performance. Varying the number of diffusion steps T In this part, we set the number of RRDB blocks of Vaihingen to 3 and Cityscapes "Bus" to 10. We explore the possible accuracy/runtime tradeoff with regards to the number T of diffusion steps. Results are shown in <ref type="figure">Fig. 9</ref>.</p><p>When the number of diffusion steps is increased -as we can see in <ref type="figure">Fig. 9</ref>(a) -the graph fluctuation for Vaihingen is less than 1 mIoU, and for Cityscapes "Bus" it is less than 2 mIoU.</p><p>Surprisingly, when the number of diffusion steps is reduced, even to just 25, which is a very low number compared to the literature <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b34">35]</ref>, the segmentation results remain stable in both datasets, with a degradation of only up to 2 mIou for Vaihingen, and 1 mIou for Cityscapes "Bus". This reduction can speed up performance by a factor of four and provide a reasonable accuracy to runtime tradeoff.</p><p>The results for the generation time of one sample in seconds are presented in <ref type="figure">Fig. 9(b)</ref>. As can be observed, both graphs are linear, with a different slope. The main reason for this is the difference in image size (which is 256 ? 256 for Vaihingen and 128 ? 128 for Cityscapes "Bus"). Another, minor reason is the difference in the number of RRDB blocks in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>A wealth of methods have been applied to image segmentation, including active contour and their deep variants, encoder-decoder architectures, and U-Nets, which -together with more recent, transformer-based methods -represent a leading approach. In this work, we propose utilizing the state-of-the-art image generation technique of diffusion models. Our diffusion model employs a U-Net architecture, which is used to incrementally improve the obtained generation, similarly to other recent diffusion models.</p><p>In order to condition the input image, we generate another encoding path, which is similar to U-Net's encoderdecoder use in conventional image segmentation methods. The two encoder pathways are merged by summing the activations early in the U-Net's encoder.</p><p>Using our approach, we obtain state-of-the-art segmentation results on a diverse set of benchmarks, including street view images, aerial images, and microscopy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgments</head><p>This project has received funding from the European Research Council (ERC) under the European Unions Horizon 2020 research and innovation programme (grant ERC CoG 725974).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Obtaining multiple segmentation results for Cityscapes, Vaihingen, and MoNuSeg. (a) input image, (b) a subset of the obtained results for multiple runs on the same input, visualized by the jet color scale between 0 in blue and 1 in red, (c) average result, and (d) ground truth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>mIoU relative to SegDiff being 100% for each Cityscape class, sorted by the number of training images per class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .Figure 5 .</head><label>45</label><figDesc>mIoU (mean and variance) across the test images as a function of the number of diffusion steps. (a) Results for the Cityscapes classes, with 128 ? 128 image resolution. (b) Results for the Vaihingen and MoNuSeg datasets, with 256 ? 256 image resolution. mIoU per number of generated inferences. (a) Results for the Cityscapes classes, with 128 ? 128 image resolution. (b) Results for the Vaihingen and MoNuSeg datasets, with 256 ? 256 image resolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .Figure 7 .</head><label>67</label><figDesc>Mean calibration score (lower is better) per number of generated inferences. The error bars depict the standard error. (a) Results for the Cityscapes classes, with an image resolution of 128 ? 128. (b) Results for the Vaihingen and MoNuSeg datasets, with the 256 ? 256 image resolution. Results of the ablation study. (a) the input image, (b-e) results for variants one-four of our method, respectively, (f) the result of our method, and (g) ground truth. Panels (b-f) employ the jet color scale between 0 in blue and 1 in red sented in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .Figure 9 .</head><label>89</label><figDesc>mIoU per number of RRDB blocks. (a) Results on Vaihingen, (b) Results on Cityscapes "Bus". Generation time in seconds and mIou per number of diffusion steps for Vaihingen and Cityscapes "Bus". (a) mIoU per diffusion step, (b) Time per diffusion step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Cityscapes segmentation results for two protocols: the top part refers to segmentation results with 15% expansion around the bounding box; the bottom part refers to segmentation results with a tight bounding box. Segmentation results for the Vaihingen dataset.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bicycle</cell><cell>Bus</cell><cell>Person Train Truck M.cycle</cell><cell>Car</cell><cell>Rider Mean</cell></row><row><cell>expansion</cell><cell cols="3">Polygon-RNN++ [1] PSP-DeepLab [5] Polygon-GCN [29] Spline-GCN [29] SegDiff (ours)</cell><cell>63.06 67.18 66.55 67.36 69.80</cell><cell cols="2">81.38 72.41 64.28 78.90 83.81 72.62 68.76 80.48 85.01 72.94 60.99 79.78 85.43 73.72 64.40 80.22 85.97 76.09 75.95 80.68</cell><cell>62.01 65.94 63.87 64.86 67.06</cell><cell>79.08 69.95 71.38 80.45 70.00 73.66 81.09 71.00 72.66 81.88 71.73 73.70 83.40 72.57 76.44</cell></row><row><cell></cell><cell cols="2">Deep contour [14]</cell><cell></cell><cell>68.08</cell><cell cols="2">83.02 75.04 74.53 79.55</cell><cell>66.53</cell><cell>81.92 72.03 75.09</cell></row><row><cell></cell><cell cols="2">Segformer-B5 [50]</cell><cell></cell><cell>68.02</cell><cell cols="2">78.78 73.53 68.46 74.54</cell><cell>64.06</cell><cell>83.20 69.12 72.46</cell></row><row><cell></cell><cell cols="2">Stdc1 [11]</cell><cell></cell><cell>67.86</cell><cell cols="2">80.67 74.20 69.73 77.02</cell><cell>64.52</cell><cell>83.53 69.58 73.39</cell></row><row><cell></cell><cell cols="2">Stdc2 [11]</cell><cell></cell><cell>68.67</cell><cell cols="2">81.29 74.41 71.36 75.71</cell><cell>63.69</cell><cell>83.51 69.90 73.57</cell></row><row><cell></cell><cell cols="2">SegDiff (ours)</cell><cell></cell><cell>69.62</cell><cell cols="2">84.64 75.18 74.89 80.34</cell><cell>67.75</cell><cell>83.63 73.49 76.19</cell></row><row><cell>Method</cell><cell cols="6">F1-Score mIoU WCov FBound</cell></row><row><cell cols="2">FCN-UNet [38]</cell><cell>87.40</cell><cell cols="3">78.60 81.80</cell><cell>40.20</cell></row><row><cell cols="2">FCN-ResNet34</cell><cell>91.76</cell><cell cols="3">87.20 88.55</cell><cell>75.12</cell></row><row><cell cols="3">FCN-HarDNet [4] 93.97</cell><cell cols="3">88.95 93.60</cell><cell>80.20</cell></row><row><cell>DSAC [34]</cell><cell></cell><cell>-</cell><cell cols="3">71.10 70.70</cell><cell>36.40</cell></row><row><cell>DarNet [7]</cell><cell></cell><cell>93.66</cell><cell cols="3">88.20 88.10</cell><cell>75.90</cell></row><row><cell cols="3">Deep contour [14] 94.80</cell><cell cols="3">90.33 93.72</cell><cell>78.72</cell></row><row><cell>TDAC [15]</cell><cell></cell><cell>94.26</cell><cell cols="3">89.16 90.54</cell><cell>78.12</cell></row><row><cell cols="3">Segformer-B5 [50] 93.94</cell><cell cols="3">88.57 91.91</cell><cell>77.95</cell></row><row><cell>Stdc1 [11]</cell><cell></cell><cell>94.04</cell><cell cols="3">88.75 92.78</cell><cell>78.86</cell></row><row><cell>Stdc2 [11]</cell><cell></cell><cell>93.97</cell><cell cols="3">88.62 92.59</cell><cell>77.3</cell></row><row><cell cols="2">SegDiff (ours)</cell><cell>95.14</cell><cell cols="3">91.12 93.83</cell><cell>85.09</cell></row><row><cell></cell><cell>Method</cell><cell></cell><cell cols="2">Dice mIoU</cell><cell></cell></row><row><cell></cell><cell>FCN [3]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 .</head><label>4</label><figDesc>Ablation study for different conditioning methods.</figDesc><table><row><cell></cell><cell>Method</cell><cell>F1-Score</cell><cell>IoU</cell><cell cols="2">WCov FBound</cell></row><row><cell></cell><cell>Variant one</cell><cell>91.60</cell><cell cols="2">85.45 88.67</cell><cell>71.70</cell></row><row><cell>Vaihingen</cell><cell>Variant two Variant three Variant four Variant five Variant six</cell><cell>90.92 93.77 94.77 93.16 91.97</cell><cell cols="2">84.00 89.67 88.67 91.69 90.27 93.82 87.76 91.08 85.57 89.83</cell><cell>70.00 80.15 82.64 79.89 71.04</cell></row><row><cell></cell><cell>Full method</cell><cell>94.95</cell><cell cols="2">90.64 94.00</cell><cell>84.37</cell></row><row><cell>Cityscapes "Bus"</cell><cell>Variant one Variant two Variant three Variant four Variant five Variant six Full method</cell><cell>90.52 85.21 90.35 91.30 89.57 82.97 90.72</cell><cell cols="2">84.15 90.37 75.92 81.15 83.76 88.56 85.17 90.34 82.73 88.87 72.66 80.85 84.35 89.96</cell><cell>62.66 38.81 58.80 63.85 58.40 34.38 63.87</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Efficient interactive annotation of segmentation datasets with polygon-rnn++</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Acuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amlan</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Daniel Tarlow, and Rianne van den Berg. Structured denoising diffusion models in discrete state-spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="17981" to="17993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hardnet: A low memory traffic network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao-Yang</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Shan</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Hsiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youn-Long</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Wavegrad: Estimating gradients for waveform generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanxin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.00713</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Darnet: Deep active ray network for building segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominic</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Ilvr: Conditioning method for denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jooyoung</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghyun</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjune</forename><surname>Gwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.02938</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Diffusion models beat gans on image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Nichol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rethinking bisenet for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyuan</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenqi</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junshi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junfeng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Adversarial examples for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaithanya</forename><surname>Mummadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Hendrik</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.01101</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scene segmentation with dual relation-aware attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2547" to="2560" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shir</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Shaharabany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00367</idno>
		<title level="m">End to end trainable active contours via differentiable rendering</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">End-to-end trainable deep active contour models for automated image segmentation: Delineating buildings in aerial imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Hatamizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debleena</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demetri</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Piotr Doll?r, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cascaded diffusion models for high fidelity image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salimans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">47</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didrik</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priyank</forename><surname>Jaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Forr?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<title level="m">Argmax flows and multinomial diffusion: Towards non-autoregressive language models. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">2102</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A variational perspective on diffusion-based generative models and score matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><forename type="middle">Hyun</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ccnet: Criss-cross attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="603" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.00630</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">Variational diffusion models. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Diffwave: A versatile diffusion model for audio synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaji</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kexin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09761</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A multiorgan nucleus segmentation challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neeraj</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruchika</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanning</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><forename type="middle">Fahri</forename><surname>Onder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efstratios</forename><surname>Tsougenis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A dataset and a technique for generalized nuclear segmentation for computational pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neeraj</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruchika</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanuj</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surabhi</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Vahadane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Sethi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Srdiff: Single image super-resolution with diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huajun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueting</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Polytransform: Deep polygon transformer for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namdar</forename><surname>Homayounfar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chiu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9131" to="9140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fast interactive object annotation with curve-gcn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amlan</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Diffsinger: Singing voice synthesis via shallow diffusion mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinglin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.02446</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Decoupled weight decay regularization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Semantic segmentation using adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pauline</forename><surname>Luc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camille</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.08408</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning deep structured active contours end-to-end</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devis</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Kellenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improved denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Quinn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nichol</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Hyperseg: Patchwise hypernetwork for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Nirkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Hassner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="4061" to="4070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Grad-tts: A diffusion probabilistic model for text-to-speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vadim</forename><surname>Popov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vovk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Gogoryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tasnima</forename><surname>Sadekova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Kudinov</surname></persName>
		</author>
		<idno>PMLR, 2021. 2</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="8599" to="8608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unet: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Isprs semantic labeling contest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><surname>Rottensteiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunho</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Gerke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">D</forename><surname>Wegner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS: Leopoldsh?he</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiwen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Norouzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.05826</idno>
		<title level="m">Palette: Image-to-image diffusion models</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Image super-resolution via iterative refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Norouzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.07636</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Noise estimation for generative diffusion models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>San-Roman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliya</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.02600</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niru</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Segmenter: Transformer for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Strudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7262" to="7272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Medical transformer: Gated axialattention for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeya Maria Jose</forename><surname>Valanarasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Poojan</forename><surname>Oza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilker</forename><surname>Hacihaliloglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Axial-deeplab: Standalone axial-attention for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Esrgan: Enhanced super-resolution generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV) workshops</title>
		<meeting>the European conference on computer vision (ECCV) workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Weighted res-unet for high-quality retina vessel segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozi</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 9th international conference on information technology in medicine and education (ITME)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Adversarial examples for semantic segmentation and object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhishuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1369" to="1378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Segformer: Simple and efficient design for semantic segmentation with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Segan: adversarial network with multi-scale l1 loss for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodney</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolei</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="383" to="392" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07122</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Unet++: A nested u-net architecture for medical image segmentation. In Deep learning in medical image analysis and multimodal learning for clinical decision support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md</forename><surname>Mahfuzur Rahman Siddiquee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianming</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="3" to="11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
