<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Tiny Episodic Memories in Continual Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslan</forename><surname>Chaudhry</surname></persName>
							<email>arslan.chaudhry@eng.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><forename type="middle">Rohrbach</forename><surname>Facebook</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">King Abdullah University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Research</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">King Abdullah University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">King Abdullah University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thalaiyasingam</forename><surname>Ajanthan</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Australian National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puneet</forename><forename type="middle">K</forename><surname>Dokania</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">&amp;apos; Aurelio</forename><surname>Ranzato</surname></persName>
							<affiliation key="aff5">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">On Tiny Episodic Memories in Continual Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In continual learning (CL), an agent learns from a stream of tasks leveraging prior experience to transfer knowledge to future tasks. It is an ideal framework to decrease the amount of supervision in the existing learning algorithms. But for a successful knowledge transfer, the learner needs to remember how to perform previous tasks. One way to endow the learner the ability to perform tasks seen in the past is to store a small memory, dubbed episodic memory, that stores few examples from previous tasks and then to replay these examples when training for future tasks. In this work, we empirically analyze the effectiveness of a very small episodic memory in a CL setup where each training example is only seen once. Surprisingly, across four rather different supervised learning benchmarks adapted to CL, a very simple baseline, that jointly trains on both examples from the current task as well as examples stored in the episodic memory, significantly outperforms specifically designed CL approaches with and without episodic memory. Interestingly, we find that repetitive training on even tiny memories of past tasks does not harm generalization, on the contrary, it improves it, with gains between 7% and 17% when the memory is populated with a single example per class. 1 1 Code: https://github.com/facebookresearch/agem Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The objective of continual learning (CL) is to rapidly learn new skills from a sequence of tasks leveraging the knowledge accumulated in the past. Catastrophic forgetting <ref type="bibr" target="#b14">[McCloskey and Cohen, 1989]</ref>, i.e. the inability of a model to recall how to perform tasks seen in the past, makes such efficient adaptation extremely difficult.</p><p>This decades old problem of CL <ref type="bibr" target="#b20">[Ring, 1997;</ref><ref type="bibr" target="#b23">Thrun, 1998</ref>] is now seeing a surge of interest in the research community with several methods proposed to tackle catastrophic forgetting <ref type="bibr" target="#b18">[Rebuffi et al., 2017;</ref><ref type="bibr" target="#b7">Kirkpatrick et al., 2016;</ref><ref type="bibr" target="#b27">Zenke et al., 2017;</ref><ref type="bibr">Lee et al., 2017a;</ref><ref type="bibr" target="#b0">Aljundi et al., 2018;</ref><ref type="bibr" target="#b13">Lopez-Paz and Ranzato, 2017;</ref><ref type="bibr">Lee et al., 2017b;</ref><ref type="bibr" target="#b2">Chaudhry et al., 2019]</ref>. In this work, we quantitatively study some of these methods (that assume a fixed network architecture) on four benchmark datasets under the following assumptions: i) each task is fully supervised, ii) each example from a task can only be seen once using the learning protocol proposed by <ref type="bibr" target="#b2">Chaudhry et al. [2019]</ref> (see ?3), and iii) the model has access to a small memory storing examples of past tasks. Restricting the size of such episodic memory is important because it makes the continual learning problem more realistic and distinct from multi-task learning where complete datasets of all the tasks are available at each step.</p><p>We empirically observe that a very simple baseline, dubbed Experience Replay (ER) 2 , that jointly trains on both the examples from the current task and examples stored in the very small episodic memory not only gives superior performance over the existing state-of-the-art approaches specifically designed for CL (with and without episodic memory), but it also is computationally very efficient. We verify this finding on four rather different supervised learning benchmarks adapted for CL; Permuted MNIST, Split CIFAR, Split miniImageNet and Split CUB. Importantly, repetitive training on the same examples of a tiny episodic memory does not harm generalization on past tasks. In ?5.5, we analyze this phenomenon and provide insights as to why directly training on the episodic memory does not have a detrimental effect in terms of generalization. Briefly, we observe that the training on the datasets of subsequent tasks acts like a data-dependent regularizer on past tasks allowing the repetitive training on tiny memory to generalize beyond the episodic memory. We further observe that methods, that do not train directly on the memory, such as GEM <ref type="bibr" target="#b13">[Lopez-Paz and Ranzato, 2017]</ref> and A-GEM <ref type="bibr" target="#b2">[Chaudhry et al., 2019]</ref>, underfit the training data and end up not fully utilizing the beneficial effects of this implicit and data depdendent regularization.</p><p>Overall, ER with tiny episodic memories offers very strong performance at a very small additional computational cost over the fine-tuning baseline. We believe that this approach will serve as a stronger baseline for the development of future CL approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Regularization-based CL approaches These works attempt to reduce forgetting by regularizing the objective such that it either penalizes the feature drift on already learned tasks <ref type="bibr" target="#b12">[Li and Hoiem, 2016;</ref><ref type="bibr" target="#b18">Rebuffi et al., 2017]</ref> or discourages change in parameters that were important to solve past tasks <ref type="bibr" target="#b7">[Kirkpatrick et al., 2016;</ref><ref type="bibr" target="#b27">Zenke et al., 2017;</ref><ref type="bibr" target="#b1">Chaudhry et al., 2018;</ref><ref type="bibr" target="#b0">Aljundi et al., 2018]</ref>. The former approach relies on the storage of network activations and subsequent deployment of knowledge distillation <ref type="bibr" target="#b5">[Hinton et al., 2014]</ref>, whereas the latter approach stores a measure of parameter importance whose best case memory complexity is the same as the total number of network parameters.</p><p>Memory-Based CL approaches These approaches <ref type="bibr" target="#b13">[Lopez-Paz and Ranzato, 2017;</ref><ref type="bibr" target="#b19">Riemer et al., 2019;</ref><ref type="bibr" target="#b2">Chaudhry et al., 2019]</ref> use episodic memory that stores a subset of data from past tasks to tackle forgetting. One approach to leverage such episodic memory is to use it to constrain the optimization such that the loss on past tasks can never increase <ref type="bibr" target="#b13">[Lopez-Paz and Ranzato, 2017]</ref>.</p><p>Experience Replay (ER) The use of ER is well established in reinforcement learning (RL) tasks <ref type="bibr" target="#b15">[Mnih et al., 2013</ref><ref type="bibr" target="#b16">[Mnih et al., , 2015</ref><ref type="bibr" target="#b3">Foerster et al., 2017;</ref><ref type="bibr" target="#b21">Rolnick et al., 2018]</ref>. <ref type="bibr" target="#b6">Isele and Cosgun [2018]</ref>, for instance, explore different ways to populate a relatively large episodic memory for a continual RL setting where the learner does multiple passes over the data. In this work instead, we study supervised learning tasks with a single pass through data and a very small episodic memory. More recently, <ref type="bibr" target="#b4">[Hayes et al., 2018;</ref><ref type="bibr" target="#b19">Riemer et al., 2019]</ref> used ER for supervised CL learning tasks. Hayes et al. <ref type="bibr">[2018]</ref>, independently, study different replay strategies in ER and show improvements over the finetune baseline. Our contribution is to show the improvements brought by ER, perhaps surprisingly, over the specifically designed CL approaches. We differ from <ref type="bibr" target="#b19">[Riemer et al., 2019]</ref> in considering episodic memories of much smaller sizes. Finally, and most importantly, we extend these previous studies by analyzing why repetitive training on tiny memories does not lead to overfitting ( ?5.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Learning Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Protocol for Single-Pass Through the Data</head><p>We use the learning protocol proposed by <ref type="bibr" target="#b2">Chaudhry et al. [2019]</ref>. There are two streams of tasks, described by the following ordered sequences of datasets, one stream for Cross-Validation D CV = {D ?T CV , ? ? ? , D ?1 } consisting of T CV tasks, and one for EValuation</p><formula xml:id="formula_0">D EV = {D 1 , ? ? ? , D T } consisting of T tasks, where D k = {(x k i , t k i , y k i ) n k i=1</formula><p>} is the dataset of the k-th task. The sequence D CV contains only a handful of tasks and it is only used for cross-validation purposes. Tasks from this sequence can be replayed as many times as needed and have various degree of similarity to tasks in the training and evaluation dataset, D EV . The latter stream, D EV , instead can be played only once; the learner will observe examples in sequence and will be tested throughout the learning experience. The final performance will be reported on the held-out test set drawn from D EV . The k-th task in any of these streams consists of</p><formula xml:id="formula_1">D k = {(x k i , t k i , y k i ) n k i=1 },</formula><p>where each triplet constitutes an example defined by an input (x k ? X ), a task descriptor (t k ? T ) which is an integer id in this work, and a target vector (y k ? y k ), where y k is the set of labels specific to task k and y k ? Y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Metrics</head><p>We measure performance on D EV using two metrics, as standard practice in the literature <ref type="bibr" target="#b13">[Lopez-Paz and Ranzato, 2017;</ref><ref type="bibr" target="#b1">Chaudhry et al., 2018]</ref>:</p><p>Average Accuracy (A ? [0, 1]) Let a i,j be the performance of the model on the held-out test set of task 'j' after the model is trained on task 'i'. The average accuracy at task T is then defined as:</p><formula xml:id="formula_2">AT = 1 T T j=1 aT,j<label>(1)</label></formula><p>Forgetting (F ? [?1, 1]) Let f i j be the forgetting on task 'j' after the model is trained on task 'i' which is computed as:</p><formula xml:id="formula_3">f i j = max l?{1,??? ,i?1} a l,j ? ai,j<label>(2)</label></formula><p>The average forgetting measure at task T is then defined as:</p><formula xml:id="formula_4">FT = 1 T ? 1 T ?1 j=1 f T j (3)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experience Replay</head><p>Recent works <ref type="bibr" target="#b13">[Lopez-Paz and Ranzato, 2017;</ref><ref type="bibr" target="#b2">Chaudhry et al., 2019]</ref> have shown that methods relying on episodic memory have superior performance than regularization based approaches (e.g., <ref type="bibr" target="#b7">[Kirkpatrick et al., 2016;</ref><ref type="bibr" target="#b27">Zenke et al., 2017]</ref>) when using a "single-pass through the data" protocol ( ?3.1). While GEM <ref type="bibr" target="#b13">[Lopez-Paz and Ranzato, 2017]</ref> and its more efficient version A-GEM <ref type="bibr" target="#b2">[Chaudhry et al., 2019]</ref> used the episodic memory as a mean to project gradients, here we drastically simplify the optimization problem and, similar to <ref type="bibr" target="#b19">Riemer et al. [2019]</ref> and <ref type="bibr" target="#b4">Hayes et al. [2018]</ref>, directly train on the the examples stored in a very small memory, resulting in better performance and more efficient learning.</p><p>The overall training procedure is given in Alg. 1. Compared to the simplest baseline model that merely fine-tunes the parameters on the new task starting from the previous task parameter vector, ER makes two modifications. First, it has an episodic memory which is updated at every time step, line 8. Second, it doubles the size of the minibatch used to compute the gradient descent parameter update by stacking the actual minibatch of examples from the current task with a minibatch of examples taken at random from the memory, line 7. As we shall see in our empirical validation, these two simple modifications yield much better generalization and substantially limit forgetting, while incurring in a negligible additional computational cost on modern GPU devices. Next, we explain the difference between the direct (ER) and indirect (A-GEM) training on episodic memory from the optimization perspective.</p><p>A-GEM vs ER: Let us assume that B n is a mini-batch of size K from the current task t and B M is the same size mini-batch from a very small episodic memory M. Furthermore, following the notation from <ref type="bibr" target="#b2">Chaudhry et al. [2019]</ref>, let g be the gradient computed with mini-batch B n and g ref be the gradient computed with B M . In A-GEM, if g T g ref ? 0, then the current task gradient g is directly used for optimization whereas if g T g ref &lt; 0, g is projected such that g T g ref = 0. Refer to Eq. 11</p><p>Algorithm 1 Experience Replay for Continual Learning. for t ? {1, ? ? ? , T } do 5: in <ref type="bibr" target="#b2">Chaudhry et al. [2019]</ref> for the exact form of projection. In ER instead, since both mini-batches are used in the optimization step, the average of g and g ref is used. It may seem a bit counter-intuitive that, even though ER repetitively trains on M, it is still able to generalize to previous tasks beyond the episodic memory. We investigate this question in ?5.5.</p><formula xml:id="formula_5">for B n K ? D t do</formula><p>Since we study the usage of tiny episodic memories, the sample that the learner selects to populate the memory becomes crucial, see line 8 of the algorithm. For this, we describe various strategies to write into the memory. All these strategies assume access to a continuous stream of data and a small episodic memory, which rules out approaches relying on the temporary storage of all the examples seen so far. This restriction is consistent with our definition of CL: a learning experience through a stream of data under the constraint of a fixed and small sized memory and limited compute budget.</p><p>Reservoir Sampling: Similarly to <ref type="bibr" target="#b19">Riemer et al. [2019]</ref>, Reservoir sampling <ref type="bibr" target="#b25">[Vitter, 1985]</ref> takes as input a stream of data of unknown length and returns a random subset of items from that stream. If 'n' is the number of points observed so far and 'mem_sz' is the size of the reservoir (sampling buffer), this selection strategy samples each data point with a probability mem_sz n . The routine to update the memory is given in Appendix Alg. 2.</p><p>Ring Buffer: Similarly to <ref type="bibr" target="#b13">Lopez-Paz and Ranzato [2017]</ref>, for each task, the ring buffer strategy allocates as many equally sized FIFO buffers as there are classes. If C is the total number of classes across all tasks, and mem_sz is the total size of episodic memory, each stack has a buffer of size mem_sz C . As shown in Appendix Alg. 3, the memory stores the last few observations from each class. Unlike reservoir sampling, samples from older tasks do not change throughout training, leading to potentially stronger overfitting. Also, at early stages of training the memory is not fully utilized since each stack has a constant size throughout training. However, this simple sampling strategy guarantees equal representation of all classes in the memory, which is particularly important when the memory is tiny. k-Means: For each class, we use online k-Means to estimate the k centroids in feature space, using the representation before the last classification layer. We then store in the memory the input examples whose feature representation is the closest to such centroids, see Appendix Alg. 4. This memory writing strategy has similar benefits and drawbacks of ring buffer, except that it has potentially better coverage of the feature space in L2 sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean of Features (MoF):</head><p>Similarly to <ref type="bibr" target="#b18">Rebuffi et al. [2017]</ref>, for each class we compute a running estimate of the average feature vector just before the classification layer and store examples whose feature representation is closest to the average feature vector (see details in Appendix Alg. 5). This writing strategy has the same balancing guarantees of ring buffer and k-means, but it populates the memory differently. Instead of populating the memory at random or using k-Means, it puts examples that are closest to the mode in feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we review the benchmark datasets used in our evaluation, as well as the architectures and the baselines we compared against. We then report the results we obtained using episodic memory and experience replay (ER). Finally, we conclude with a brief analysis investigating generalization when using ER on tiny memories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We consider four commonly used benchmarks in CL literature. Permuted MNIST <ref type="bibr" target="#b7">[Kirkpatrick et al., 2016]</ref> is a variant of MNIST <ref type="bibr" target="#b9">[LeCun, 1998]</ref> dataset of handwritten digits where each task has a certain random permutation of the input pixels which is applied to all the images of that task. Our Permuted MNIST benchmark consists of a total of 23 tasks.</p><p>Split CIFAR <ref type="bibr" target="#b27">[Zenke et al., 2017]</ref> consists of splitting the original CIFAR-100 dataset <ref type="bibr" target="#b8">[Krizhevsky and Hinton, 2009]</ref> into 20 disjoint subsets, each of which is considered as a separate task. Each task has 5 classes that are randomly sampled without replacement from the total of 100 classes.</p><p>Similarly to Split CIFAR, Split miniImageNet is constructed by splitting miniImageNet <ref type="bibr" target="#b24">[Vinyals et al., 2016]</ref>, a subset of ImageNet with a total of 100 classes and 600 images per class, to 20 disjoint subsets.</p><p>Finally, Split CUB <ref type="bibr" target="#b2">[Chaudhry et al., 2019]</ref> is an incremental version of the fine-grained image classification dataset CUB <ref type="bibr" target="#b26">[Wah et al., 2011]</ref> of 200 bird categories split into 20 disjoint subsets of classes.</p><p>In all cases, D CV consists of 3 tasks while D EV contains the remaining tasks. As described in ? 3.2, we report metrics on D EV after doing a single training pass over each task in the sequence. The hyper-parameters selected via cross-validation on D CV are reported in Appenddix Tab. 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Architectures</head><p>For MNIST, we use a fully-connected network with two hidden layers of 256 ReLU units each. For CIFAR and miniImageNet, a reduced ResNet18, similar to <ref type="bibr" target="#b13">Lopez-Paz and Ranzato [2017]</ref>, is used and a standard ResNet18 with ImageNet pretraining is used for CUB. The input integer task id is used to select a task specific classifier head, and the network is trained via cross-entropy loss.</p><p>For a given dataset stream, all baselines use the same architecture, and all baselines are optimized via stochastic gradient descent with a mini-batch size equal to 10. The size of the mini-batch sampled from the episodic memory is also set to 10 irrespective of the size of the episodic buffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baselines</head><p>We compare against the following baselines:</p><p>? FINETUNE, a model trained continually without any regularization and episodic memory, with parameters of a new task initialized from the parameters of the previous task. ? EWC <ref type="bibr" target="#b7">[Kirkpatrick et al., 2016]</ref>, a regularization-based approach that avoids catastrophic forgetting by limiting the learning of parameters critical to the performance of past tasks, as measured by the Fisher information matrix (FIM). In particular, we compute the FIM as a moving average similar to EWC++ in <ref type="bibr" target="#b1">Chaudhry et al. [2018]</ref> and online EWC in . ? A-GEM <ref type="bibr" target="#b2">[Chaudhry et al., 2019]</ref>, a model that uses episodic memory as an optimization constraint to avoid catastrophic forgetting. Since GEM <ref type="bibr" target="#b13">[Lopez-Paz and Ranzato, 2017</ref>] and A-GEM have similar performance, we only consider the latter in our experiments due to its computational efficiency. ? MER <ref type="bibr" target="#b19">[Riemer et al., 2019]</ref>, a model that also leverages an episodic memory and uses a loss that approximates the dot products of the gradients of current and previous tasks to avoid forgetting. To make the experimental setting more comparable (in terms of SGD updates) to the other methods, we set the number of inner gradient steps to 1 for each outer Reptile <ref type="bibr" target="#b17">[Nichol and Schulman, 2018]</ref> meta-update with the mini-batch size of 10.  In the first experiment, we measured average accuracy at the end of the learning experience on D EV as a function of the size of the memory (detailed numerical results are provided in Appendix Tabs 3,4,5,6). From the results in <ref type="figure" target="#fig_2">Fig. 1</ref>, we can make several observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>First, methods using ER greatly outperform not only the baseline approaches that do not have episodic memory (FINETUNE and EWC) but also state-of-the-art approaches relying on episodic memory of the same size (A-GEM and MER). Moreover, the ER variants outperform even when the episodic memory is very small. For instance, on CIFAR the gain over A-GEM brought by ER is 1.7% when the memory only stores 1 example per class, and more than 5% when the memory stores 13 examples per class. This finding might seem quite surprising as repetitive training on a very small episodic memory may potentially lead to overfitting on the examples stored in the memory. We will investigate this finding in more depth in ?5.5. In the same setting, the gain compared to methods that do not use memory (FINETUNE and EWC) is 15% and about 28% when using a single example per class and 13 examples per class, respectively.</p><p>Second and not surprisingly, average accuracy increases with the memory size, and does not saturate at 13 examples per class which is our self-imposed limit.</p><p>Third, experience replay based on reservoir sampling works the best across the board except when the memory size is very small (less than 3 examples per class). Empirically we observed that as more and more tasks arrive and the size of the memory per class shrinks, reservoir sampling often ends up evicting some of the earlier classes from the memory, thereby inducing higher forgetting.</p><p>Fourth, when the memory is tiny, sampling methods that by construction guarantee a balanced number of samples per class, work the best (even better than reservoir sampling). All methods that have this property, ring buffer, k-Means and Mean of Features, have a rather similar performance which is substantially better than the reservoir sampling. For instance, on CIFAR, with one example per class in the memory, ER with reservoir sampling is 3.5% worse than ER K-Means, but ER K-Means, ER Ring Buffer and ER MoF are all within 0.5% from each other (see Appendix Tab. 4 for numerical values). These findings are further confirmed by looking at the evolution of the average accuracy (Appendix <ref type="figure">Fig. 5 left)</ref> as new tasks arrive when the memory can store at most one example per class.</p><p>The better performance of strategies like ring buffer for tiny episodic memories, and reservoir sampling for bigger episodic memories, suggests a hybrid approach, whereby the writing strategy relies on reservoir sampling till some classes have too few samples stored in the memory. At that point, the writing strategy switches to the ring buffer scheme which guarantees a minimum number of examples for each class. For instance, in the experiment of <ref type="figure" target="#fig_3">Fig. 2</ref> the memory budget consists of only 85 memory slots, an average of 1 sample per class by the end of the learning experience (as there are  <ref type="figure" target="#fig_2">1 slot per class)</ref>. The vertical bar marks where the hybrid approach switches from reservoir to ring buffer strategy. The hybrid approach works better than both reservoir (once more tasks arrive) and ring buffer (initially, when the memory is otherwise not well utilized). The orange curve is a variant of ring buffer that utilizes the full memory at all times, by reducing the ring buffer size of observed classes as new classes arrive. Overall, the proposed hybrid approach works at least as good as the other approaches throughout the whole learning experience. (Averaged over 3 runs).   17 tasks and 5 classes per task). The learner switches from reservoir sampling to ring buffer once it observes that any of the classes seen in the past has only one sample left in the memory. When the switch happens (marked by a red vertical line in the <ref type="figure">figure)</ref>, the learner only keeps randomly picked min(n, |M| K ) examples per class in the memory, where n is the number of examples of class c in the memory and K are the total number of classes observed so far. The overwriting happens opportunistically, removing examples from over-represented classes as new classes are observed. <ref type="figure" target="#fig_3">Fig. 2</ref> shows that when the number of tasks is small, the hybrid version enjoys the high accuracy of reservoir sampling. As more tasks arrive and the memory per task shrinks, the hybrid scheme achieves superior performance than reservoir (and at least similar to ring buffer).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Finally, experience replay methods are not only outperforming all other approaches in terms of accuracy (and lower forgetting as reported in Tab. 1), but also in terms of compute time. Tab. 2 reports training time on both Split CIFAR and Split CUB, using ring buffer as a use case since all other ER methods have the same computational complexity. We observe that ER adds only a slight overhead compared to the finetuning baseline, but it is much cheaper than stronger baseline methods like A-GEM and MER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Analysis</head><p>The strong performance of experience replay methods which directly learn using the examples stored in the small episodic memory may be surprising. In fact, <ref type="bibr" target="#b13">Lopez-Paz and Ranzato [2017]</ref> discounted this repetitive training on the memory option by saying: "Obviously, minimizing the loss at the current example together with [the loss on the episodic memory] results in overfitting to the examples stored in [the memory]". How can the repeated training over the same very small handful of examples possibly generalize?</p><p>To investigate this matter we conducted an additional experiment. For simplicity, we consider only two tasks, T 1 and T 2 , and study the generalization performance on T 1 as we train on T 2 . We denote by D 2 the training set of T 2 and by M 1 the memory storing examples from T 1 's training set. Our hypothesis is that although direct training on the examples in M 1 (in addition to those coming from D 2 ) does indeed lead to strong memorization of M 1 (as measured by nearly zero cross-entropy loss on M 1 ), such training is still overall beneficial in terms of generalization on the original task T 1  because the joint learning with the examples of the current task T 2 acts as a strong, albeit implicit and data-dependent, regularizer for T 1 .</p><p>To validate this hypothesis, we consider the MNIST Rotations dataset <ref type="bibr" target="#b13">[Lopez-Paz and Ranzato, 2017]</ref>, where each task has digits rotated by a certain degree, a setting that enables fine control over the relatedness between the tasks. The architecture is the same as for Permuted MNIST, with only 10 memory slots, one for each class of T 1 . First, we verified that the loss on M 1 quickly drops to nearly 0 as the model is trained using both M 1 and D 2 . As expected, the model achieves a perfect performance on the examples in the memory, which is not true for methods like A-GEM which make less direct use of the memory (see Appendix Tab. 7). We then verified that only training on M 1 without D 2 , yields strong overfitting to the examples in the memory and poor generalization performance, with a mere average accuracy of 40% on T 1 from the initial 85% which was obtained just after training on T 1 . If we only train on D 2 without using M 1 (same as FINETUNE baseline), we also observed overfitting to D 2 as long as T 2 and T 1 are sufficiently unrelated, <ref type="figure" target="#fig_4">Fig. 3(b) and 3(c)</ref>.</p><p>When the two tasks are closely related instead (difference of rotation angles less than 20 degrees), we observe that even without the memory, generalization on T 1 improves as we train on T 2 because of positive transfer from the related task, see red curve in <ref type="figure" target="#fig_4">Fig. 3(a)</ref>. However, when we train on both D 2 and M 1 , generalization on T 1 is better than FINETUNE baseline, i.e., training with D 2 only, regardless of the degree of relatedness between the two tasks, as shown by the green curves in <ref type="figure" target="#fig_4">Fig. 3</ref>.</p><p>These findings suggest that while the model essentially memorizes the examples in the memory, this does not necessarily have a detrimental effect in terms of generalization as long as such learning is performed in conjunction with the examples of T 2 . Moreover, there are two major axes controlling this regularizer: the number of examples in T 2 and the relatedness between the tasks. The former sets the strength of the regularizer. The latter, as measured by the accuracy on T 1 when training only on D 2 , controls its effectiveness. When T 1 and T 2 are closely related, <ref type="figure" target="#fig_4">Fig. 3(a)</ref>, training on D 2 prevents overfitting to M 1 by providing a data-dependent regularization that, even by itself, produces positive transfer. When T 1 and T 2 are somewhat related, <ref type="figure" target="#fig_4">Fig. 3(b)</ref>, training on D 2 still improves generalization on T 1 albeit to a much lesser extent. However, when the tasks are almost adversarial to each other as an upside down 2 may look like a 5, the resulting regularization becomes even harmful, <ref type="figure" target="#fig_4">Fig. 3(c)</ref>. In this case, accuracy drops from 40% (training only on M 1 ) to 30% (training on both M 1 and D 2 ).</p><p>One remaining question related to generalization is how ER relates to A-GEM <ref type="bibr" target="#b2">[Chaudhry et al., 2019]</ref> and whether A-GEM overfits even less? The answer is positive. As shown in Appendix Tab. 7, A-GEM's accuracy on the memory examples does not reach 100% even after having processed 1000 samples. Interestingly, accuracy on the training set is lower than ER suggesting that the more constrained weight updates of A-GEM make it actually underfit. This underfitting prevents A-GEM from reaping the full regularization benefits brought by training on the data of subsequent tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In this work we studied ER methods for supervised CL tasks. Our empirical analysis on several benchmark streams of data shows that ER methods even with a tiny episodic memory offer a very large performance boost at a very marginal increase of computational cost compared to the finetuning baseline. We also studied various ways to populate the memory and proposed a hybrid approach that strikes a good trade-off between randomizing the examples in the memory while keeping enough representatives for each class.</p><p>Our study also sheds light into a very interesting phenomenon: memorization (zero cross-entropy loss) of tiny memories is useful for generalization because training on subsequent tasks acts like a data dependent regularizer. Overall, we hope the CL community will adopt experience replay methods as a baseline, given their strong empirical performance, efficiency and simplicity of implementation.</p><p>There are several avenues of future work. For instance, we would like to investigate what are the optimal inputs that best mitigate expected forgetting and optimal strategies to remove samples from the memory when it is entirely filled up.</p><p>Algorithm <ref type="formula">5</ref>  for (x, y) in B do 6: return M</p><formula xml:id="formula_6">f [t][y] ? ? * f [t][y] + (1 ? ?) * ? ? (x) 7: d = ||? ? (x) ? f [t][</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Detailed Results</head><p>Here we describe the detailed results used to generate the <ref type="figure" target="#fig_2">Fig. 1</ref> in the main paper. In addition we also report the forgetting metric (3). Note that the MULTI-TASK baseline does not follow the definition of continual learning as it keeps the dataset of all the tasks around at every step.       In Tab. 7, we provide train, memory and test set performance on both the ER-RINGBUFFER and A-GEM with two different configurations of tasks; similar tasks (10?rotation), dissimilar tasks (90?rotation). It can be seen from the table, and as argued in the ?5.5 of the main paper that ER-RINGBUFFER always achieves the perfect performance on the memory. To achieve the same effect with A-GEM one has to train for more iterations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Further Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Hyper-parameter Selection</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Sample without replacement a mini-batch of size K from task t (B n ? B M , ?, lr) Single gradient step to update the parameters by stacking current minibatch</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Average accuracy as a function of episodic memory size. The box shows the gain in average accuracy of ER-RINGBUFFER over FINETUNE and EWC baselines when only 1 sample per class is used. The performance is averaged over 5 runs. Uncertainty estimates are provided in Appendix Tabs 3,4,5,6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Evolution of average accuracy (A k ) as new tasks are learned in Split CIFAR. The memory has only 85 slots (in average</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Analysis on MNIST Rotation: Test accuracy on Task 1 as a function of the training iterations over Task 2. The blue curves are the accuracy when the model is trained using only M1. The red curves are the accuracy when the model is trained using only D2, the training set of Task 2. The green curves are the accuracy when in addition to D2, the model uses the memory from Task 1, M1 (experience replay). (Averaged over 3 runs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :Figure 5 :Figure 6 :Figure 7 :</head><label>4567</label><figDesc>MNIST: Evolution of average accuracy (A k ) as new tasks are learned when '1' and '15' samples per class are used. CIFAR: Evolution of average accuracy (A k ) as new tasks are learned when using '1' and '13' samples per class. The performance is averaged over 5 runs. Uncertainty estimates are provided in Tabs 3, 4, 5, 6. miniImageNet: Evolution of average accuracy (A k ) as new tasks are learned when '1' and '13' samples per class are used. CUB: Evolution of average accuracy (A k ) as new tasks are learned when '1' and '10' samples per class are used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>FINETUNE</head><label></label><figDesc>1), ? (10) lr (0.03), ? (10) lr (0.03), ? (10) lr (0.03), ? (10) A-GEM lr (0.1) lr (0.03) lr (0.03) lr (0.03) MER lr (0.03), ? (0.1), s (10) lr (0.03), ? (0.1), s (5) lr (0.1), ? (0.1), s (5) lr (0.03), ? (0.1), s (5) ER-RESERVOIR lr (0.1) lr (0.1) lr (0.03) lr (0.1) ER-[OTHERS] lr (0.1) lr (0.03) lr (0.03) lr (0.03)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Forgetting when using a tiny episodic memory of single example per class.</figDesc><table><row><cell>Methods</cell><cell cols="2">Training Time [s]</cell></row><row><cell></cell><cell cols="2">CIFAR CUB</cell></row><row><cell>FINETUNE</cell><cell>87</cell><cell>194</cell></row><row><cell>EWC</cell><cell>159</cell><cell>235</cell></row><row><cell>A-GEM</cell><cell>230</cell><cell>510</cell></row><row><cell>MER</cell><cell>755</cell><cell>277</cell></row><row><cell cols="2">ER-RINGBUFFER (ours) 116</cell><cell>255</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Learning Time on D EV [s]</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Mean of Features. Store examples that are closest to the running average feature vector. 1: procedure UPDATEMEMORY(mem_sz, t, n, B)</figDesc><table><row><cell>2:</cell><cell># Assume heaps M[t][y] of fixed size are already initialized</cell></row><row><cell>3:</cell><cell># Assume average features f [t][y] are already initialized</cell></row><row><cell>4:</cell><cell># Assume moving average decay hyper-parameter (?) is given</cell></row><row><cell>5:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Permuted MNIST: Performance (average accuracy (left column) and forgetting (right column)) for different number of samples per class. The average accuracy numbers from the this table are used to generateFig. 1 in ?5.4 of the main paper.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Split CIFAR: Performance (average accuracy (left column) and forgetting (right column)) for different number of samples per class. The average accuracy numbers from the this table are used to generateFig. 1 in ?5.4 of the main paper.</figDesc><table><row><cell>Methods</cell><cell></cell><cell></cell><cell cols="3">Episodic Memory (Samples Per Class)</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Average Accuracy [AT (%)]</cell><cell></cell><cell></cell><cell cols="2">Forgetting [FT ]</cell></row><row><cell></cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>13</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>13</cell></row><row><cell>A-GEM</cell><cell cols="4">54.9 (? 2.92) 56.9 (? 3.45) 59.9 (? 2.64) 63.1 (? 1.24)</cell><cell cols="4">0.14 (? 0.03) 0.13 (? 0.03) 0.10 (? 0.02) 0.07 (? 0.01)</cell></row><row><cell>MER</cell><cell cols="4">49.7 (? 2.97) 57.7 (? 2.59) 60.6 (? 2.09) 62.6 (? 1.48)</cell><cell cols="4">0.19 (? 0.03) 0.11 (? 0.01) 0.09 (? 0.02) 0.07 (? 0.01)</cell></row><row><cell>ER-RINGBUFFER</cell><cell cols="4">56.2 (? 1.93) 60.9 (? 1.44) 62.6 (? 1.77) 64.3 (? 1.84)</cell><cell cols="4">0.13 (? 0.01) 0.09 (? 0.01) 0.08 (? 0.02) 0.06 (? 0.01)</cell></row><row><cell>ER-MOF</cell><cell cols="8">56.6 (? 2.09) 59.9 (? 1.25) 61.1 (? 1.62) 62.7 (? 0.63) 0.12 (? 0.01 ) 0.10 (? 0.01) 0.08 (? 0.01) 0.07 (? 0.01)</cell></row><row><cell>ER-K-MEANS</cell><cell cols="4">56.6 (? 1.40) 60.1 (? 1.41) 62.2 (? 1.20) 65.2 (? 1.81)</cell><cell cols="4">0.13 (? 0.01) 0.09 (? 0.01) 0.07 (? 0.01) 0.04 (? 0.01)</cell></row><row><cell>ER-RESERVOIR</cell><cell cols="4">53.1 (? 2.66) 59.7 (? 3.87) 65.5 (? 1.99) 68.5 (? 0.65)</cell><cell cols="4">0.19 (? 0.02) 0.12 (? 0.03) 0.09 (? 0.02) 0.05 (? 0.01)</cell></row><row><cell>FINETUNE</cell><cell>40.6 (? 3.83)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.27 (? 0.04)</cell><cell>-</cell><cell>-</cell></row><row><cell>EWC</cell><cell>41.2 (? 2.67)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.27 (? 0.02)</cell><cell>-</cell><cell>-</cell></row><row><cell>MULTI-TASK</cell><cell></cell><cell>68.3</cell><cell></cell><cell></cell><cell></cell><cell>-</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>miniImageNet: Performance (average accuracy (left column) and forgetting (right column)) for different number of samples per class. The average accuracy numbers from the this table are used to generateFig. 1 in ?5.4 of the main paper.</figDesc><table><row><cell>Methods</cell><cell></cell><cell></cell><cell cols="3">Episodic Memory (Samples Per Class)</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Average Accuracy [AT (%)]</cell><cell></cell><cell></cell><cell cols="2">Forgetting [FT ]</cell></row><row><cell></cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>13</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>13</cell></row><row><cell>A-GEM</cell><cell cols="3">48.2 (? 2.49) 51.6 (? 2.69) 54.3 (? 1.56)</cell><cell>54 (? 3.63)</cell><cell cols="4">0.13 (? 0.02) 0.10 (? 0.02) 0.08 (? 0.01) 0.09 (? 0.03)</cell></row><row><cell>MER</cell><cell cols="8">45.5 (? 1.49) 49.4 (? 3.43) 54.8 (? 1.79) 55.1 (? 2.91) 0.15 (? 0.01) 0.12 (? 0.02) 0.07 (? 0.01) 0.07 (? 0.01)</cell></row><row><cell>ER-RINGBUFFER</cell><cell cols="8">49.0 (? 2.61) 53.5 (? 1.42) 54.2 (? 3.23) 55.9 (? 4.05) 0.12 (? 0.02) 0.07 (? 0.02) 0.08 (? 0.02) 0.06 (? 0.03)</cell></row><row><cell>ER-MOF</cell><cell cols="8">48.5 (? 1.72) 53.3 (? 2.80) 53.3 (? 3.11) 56.5 (? 1.92) 0.12 (? 0.01) 0.08 (? 0.01) 0.08 (? 0.02) 0.05 (? 0.02)</cell></row><row><cell>ER-K-MEANS</cell><cell cols="8">48.5 (? 0.35) 52.3 (? 3.12) 56.6 (? 2.48) 55.1 (? 1.86) 0.12 (? 0.02) 0.09 (? 0.02) 0.06 (? 0.01) 0.06 (? 0.01)</cell></row><row><cell>ER-RESERVOIR</cell><cell cols="8">44.4 (? 3.22) 50.7 (? 3.36) 56.2 (? 4.12) 61.3 (? 6.72) 0.17 (? 0.02) 0.12 (? 0.03) 0.07 (? 0.04) 0.04 (? 0.06)</cell></row><row><cell>FINETUNE</cell><cell>34.7 (? 2.69)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.26 (? 0.03)</cell><cell>-</cell><cell>-</cell></row><row><cell>EWC</cell><cell>37.7 (? 3.29)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.21 (? 0.03)</cell><cell>-</cell><cell>-</cell></row><row><cell>MULTI-TASK</cell><cell></cell><cell>62.4</cell><cell></cell><cell></cell><cell></cell><cell>-</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>CUB: Performance (average accuracy (left column) and forgetting (right column)) for different number of samples per class. The average accuracy numbers from the this table are used to generate Fig. 1 in ?5.4 of the main paper.</figDesc><table><row><cell cols="2">Methods</cell><cell></cell><cell></cell><cell></cell><cell cols="3">Episodic Memory (Samples Per Class)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Average Accuracy [AT (%)]</cell><cell></cell><cell></cell><cell>Forgetting [FT ]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>10</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>10</cell></row><row><cell cols="2">A-GEM</cell><cell></cell><cell cols="6">62.1 (? 1.28) 62.1 (? 1.87) 63.4 (? 2.33) 62.5 (? 2.34) 0.09 (? 0.01) 0.08 (? 0.02) 0.07 (? 0.01) 0.08 (? 0.02)</cell></row><row><cell cols="2">MER</cell><cell></cell><cell cols="6">55.4 (? 1.03) 65.3 (? 1.68) 68.1 (? 1.61) 71.1 (? 0.93) 0.10 (? 0.01) 0.04 (? 0.01) 0.03 (? 0.01) 0.03 (? 0.01)</cell></row><row><cell cols="3">ER-RINGBUFFER</cell><cell cols="6">65.0 (? 0.96) 71.4 (? 1.53) 73.6 (? 1.57) 75.5 (? 1.84) 0.03 (? 0.01) 0.01 (? 0.01) 0.01 (? 0.01) 0.02 (? 0.01)</cell></row><row><cell cols="3">ER-K-MEANS</cell><cell cols="6">67.9 (? 0.87) 71.6 (? 1.56) 73.9 (? 2.01) 76.1 (? 1.74) 0.02 (? 0.01) 0.02 (? 0.01) 0.02 (? 0.01) 0.01 (? 0.01)</cell></row><row><cell cols="3">ER-RESERVOIR</cell><cell cols="6">61.7 (? 0.62) 71.4 (? 2.57) 75.5 (? 1.92) 76.5 (? 1.56) 0.09 (? 0.01) 0.04 (? 0.01) 0.02 (? 0.01) 0.03 (? 0.02)</cell></row><row><cell cols="3">FINETUNE</cell><cell>55.7 (? 2.22)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.13 (? 0.03)</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">EWC</cell><cell></cell><cell>55.0 (? 2.34)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.14 (? 0.02)</cell><cell>-</cell><cell>-</cell></row><row><cell cols="3">MULTI-TASK</cell><cell></cell><cell>65.6</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>Avg Accuracy</cell><cell>0.6 0.7 0.8</cell><cell cols="4">Tasks 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>MNIST Rotation Performance of task 1 after training on task 2.</figDesc><table><row><cell>Task 2 Samples</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rotation Angle</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">10?90?E</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">R-RINGBUFFER</cell><cell></cell><cell>A-GEM</cell><cell></cell><cell cols="3">ER-RINGBUFFER</cell><cell></cell><cell>A-GEM</cell><cell></cell></row><row><cell></cell><cell cols="12">Train Mem Test Train Mem Test Train Mem Test Train Mem Test</cell></row><row><cell>1000</cell><cell>85.6</cell><cell>1</cell><cell>86.2</cell><cell>81.5</cell><cell>86.6</cell><cell>82.5</cell><cell>68.7</cell><cell>1</cell><cell>69.4</cell><cell>51.7</cell><cell>73.3</cell><cell>52.1</cell></row><row><cell>20000</cell><cell>91.4</cell><cell>1</cell><cell>91.6</cell><cell>91.4</cell><cell>1</cell><cell>91.5</cell><cell>32.7</cell><cell>1</cell><cell>33.4</cell><cell>31.6</cell><cell>1</cell><cell>33.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Hyper-parameters selection on the four benchmark datasets. 'lr' is the learning rate, '?' is the synaptic strength for EWC, '?' is the with in batch meta-learning rate for MER, 's' is current example learning rate multiplier for MER.</figDesc><table><row><cell>Methods</cell><cell>MNIST</cell><cell>CIFAR</cell><cell>CUB</cell><cell>miniImageNet</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">For consistency to prior work in the literature, we will refer to this approach which trains on the episodic memory as ER, although its usage for supervised learning tasks is far less established.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>In ?A, we provide algorithms for different memory update strategies described in ?4 of the main paper. The detailed results of the experiments which were used to generate <ref type="figure">Fig. 1</ref> and Tab. 1 in the main paper are provided in ?B. The analysis conducted in ?5.5 of the main paper is further described in ?C. Finally, in ?D, we list the hyper-parameters used for each of the baselines across all the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Memory Update Algorithms</head><p>Here we provide the algorithms to write into memory as discussed in ?4 of the main paper.</p><p>Algorithm 2 Reservoir sampling update. mem_sz is the number of examples the memory can store, t is the task id, n is the number of examples observed so far in the data stream, and B is the input mini-batch.  return M</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Memory aware synapses: Learning what (not) to forget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahaf</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Babiloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Riemannian walk for incremental learning: Understanding forgetting and intransigence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslan</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Puneet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thalaiyasingam</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient lifelong learning with a-gem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslan</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stabilising experience replay for deep multi-agent reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nantas</forename><surname>Nardelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Triantafyllos</forename><surname>Afouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimon</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Whiteson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1146" to="1155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Memory efficient experience replay for streaming learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tyler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><forename type="middle">D</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05922</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Selective experience replay for lifelong learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akansel</forename><surname>Cosgun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.10269</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><forename type="middle">C</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kieran</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>PNAS</publisher>
		</imprint>
		<respStmt>
			<orgName>Proceedings of the National Academy of Sciences of the United States of America</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="https://www.cs.toronto.edu/kriz/cifar.html" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeongtae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehong</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungju</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunho</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.01547</idno>
		<title level="m">Lifelong learning with dynamically expandable networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting by incremental moment matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang-Woo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Hwa</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byoung-Tak</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Hoiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="614" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gradient episodic memory for continuum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Catastrophic interference in connectionist networks: The sequential learning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of learning and motivation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="109" to="165" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Playing atari with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5602</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">K</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page">529</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<title level="m">Reptile: a scalable metalearning algorithm</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">iCaRL: Incremental classifier and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S-V</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to learn without forgetting by maximizing transfer and minimizing interference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Riemer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Cases</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ajemian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Rish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhai</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Child: A first step towards continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="77" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Experience replay for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<idno>abs/1811.11682</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Progress and compress: A scalable framework for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jelena</forename><surname>Luketina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference in Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Lifelong learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning to learn</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="181" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Random sampling with a reservoir</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software (TOMS)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="57" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The caltech-ucsd birds-200-2011 dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Continual learning through synaptic intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zenke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
