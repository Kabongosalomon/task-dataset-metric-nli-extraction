<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Boosting for Domain Adaptation: Towards Robust Predictions in Scene Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="20151">AUGUST 2015 1</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Journal Of L A T E X Class</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Files</surname></persName>
						</author>
						<title level="a" type="main">Adaptive Boosting for Domain Adaptation: Towards Robust Predictions in Scene Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">14</biblScope>
							<biblScope unit="issue">8</biblScope>
							<date type="published" when="20151">AUGUST 2015 1</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Index Terms-Domain Adaptation, Scene Segmentation</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Domain adaptation is to transfer the shared knowledge learned from the source domain to a new environment, i.e., target domain. One common practice is to train the model on both labeled source-domain data and unlabeled target-domain data. Yet the learned models are usually biased due to the strong supervision of the source domain. Most researchers adopt the early-stopping strategy to prevent over-fitting, but when to stop training remains a challenging problem since the lack of the target-domain validation set. In this paper, we propose one efficient bootstrapping method, called Adaboost Student, explicitly learning complementary models during training and liberating users from empirical early stopping. Adaboost Student combines deep model learning with the conventional training strategy, i.e., adaptive boosting, and enables interactions between learned models and the data sampler. We adopt one adaptive data sampler to progressively facilitate learning on hard samples and aggregate "weak" models to prevent overfitting. Extensive experiments show that (1) Without the need to worry about the stopping time, AdaBoost Student provides one robust solution by efficient complementary model learning during training. (2) AdaBoost Student is orthogonal to most domain adaptation methods, which can be combined with existing approaches to further improve the state-of-the-art performance. We have achieved competitive results on three widely-used scene segmentation domain adaptation benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I N recent years, deep learning approaches have achieved significant improvement in many computer vision fields, including semantic segmentation <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. However, improving the scalability of deeply-learned models remains a challenging task. For instance, the segmentation models learned on the data collected on sunny days usually perform terribly in different environments, such as rainy days and foggy days <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. One straightforward idea is to collect more training data for the target environment and re-train one domain-specific model for inference. However, it is usually unaffordable to annotate large-scale datasets for every target scenario, especially for the tasks demanding pixel-wise annotations, e.g., scene segmentation. Therefore, researchers resort to domain adaptation techniques <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> to "borrow" the common knowledge from homogeneous datasets, e.g., labeled source-domain data. The source-domain data can be the synthetic data generated by game engines, such as GTA5 <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, or the large-scale Zhedong Zheng is with the School of Computing, National University of Singapore, Singapore 118404. E-mail: zdzheng@nus.edu.sg Yi Yang is with the College of Computer Science and Technology, Zhejiang University, China 310027. E-mail: yangyics@zju.edu.cn. He is in part supported by the Fundamental Research Funds for the Central Universities (No. 226-2022-00087).</p><p>Yi Yang is the corresponding author. <ref type="figure">Fig. 1</ref>. The sensitivity analysis of the model on the GTA5 <ref type="bibr" target="#b6">[7]</ref> ? Cityscapes <ref type="bibr" target="#b7">[8]</ref> benchmark in the first 50000 iterations on the target-domain test set. We re-implement the widely-used method AdaptSegNet <ref type="bibr" target="#b14">[15]</ref>, and observe the prediction fluctuation at different training iterations. The proposed Adaboost Student makes the model free from the early-stopping trick and can efficiently converge to one competitive performance on the target domain. For instance, the empirical early-stopping time is usually set at the 25,000-th iteration <ref type="bibr" target="#b18">[19]</ref>, which is sub-optimal.</p><p>data collected in other real-world scenarios <ref type="bibr" target="#b7">[8]</ref>. In this way, we can largely save the annotation cost as well as the training time to achieve competitive results in the target domain. The common practice is to train the segmentation model on both labeled source-domain data and unlabeled target-domain data. Most existing works focus on domain alignment, minimizing the gap between the source domain and the target domain <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>. Several early attempts leverage generative models to transfer the image style at the pixel level <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, while other works concentrate on narrowing the semantic gap in the feature space <ref type="bibr" target="#b13">[14]</ref>. For instance, Tsai et al. <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> and Luo et al. <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> harness the adversarial loss to encourage the segmentation model to learn domain-invariant features. However, one inherent problem exists in the scene segmentation domain adaptation. Due to the strong supervision on the source-domain label, we observe that the model is still prone to over-fitting the source domain, leading to the unstable prediction on the target domain (see <ref type="figure">Figure 1</ref>). Although several researchers adopt the early-stopping strategy to prevent over-fitting <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, when to stop the training remains challenging. The unstable prediction not only compromises the method re-implementation, but also harms users to select the final model in the real-world application.</p><p>In an attempt to overcome the above-mentioned challenge, this paper adopts the spirit of one conventional training strategy, i.e., adaptive boosting <ref type="bibr" target="#b19">[20]</ref>, with the deeply-learned model to facilitate learning complementary models and progressively improve the model scalability. In particular, we gradually provide more sampling probability to the "hard" samples that achieve high prediction variance in the current model. In this way, we can efficiently obtain several complementary models during one-time training rather than training arXiv:2103.15685v3 [cs.CV] <ref type="bibr" target="#b21">22</ref> Sep 2022 multiple independent models as the conventional adaptive boosting <ref type="bibr" target="#b19">[20]</ref>. Aggregating such model snapshots provide more robust predictions on unlabeled target domain data and, more importantly, prevents the model from over-fitting. As a result, we observe a consistent improvement over other domain adaptation approaches on three prevailing benchmarks. To summarize, our contributions are:</p><p>? an efficient bootstrapping method for scene segmentation domain adaptation, AdaBoost Student, which enables interactions between learned models and the data sampler, and aggregates the "weak" model snapshots to prevent over-fitting. AdaBoost Student makes users free from the empirical early stopping trick; and ? an adaptive data sampler to progressively increase the sampling probability of hard samples with ambiguous predictions, facilitating the complementary model learning. The criterion of hard sample selection is based on prediction variance in unlabeled target-domain data; and ? a demonstration that the proposed approach has a consistent improvement over existing methods on two syntheticto-real benchmarks and one cross-city benchmark. The rest of this paper is organized as follows. Section II discusses relevant works, including semantic segmentation adaptation, bootstrapping learning, and hard example mining. Section III elaborates on the proposed AdaBoost Student approach followed by experiment results in Section IV. We add further ablation studies and discussion in Section V. Finally, Section VI concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Semantic Segmentation Adaptation</head><p>There are two big families of segmentation adaptation. One line of works <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b9">[10]</ref> concentrates on the domain alignment. Some pioneering works <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> leverage the CycleGAN <ref type="bibr" target="#b23">[24]</ref> to transfer the image style to the target domain, minimizing the biases from the source domain. Taking one step further, Wu et al. <ref type="bibr" target="#b2">[3]</ref> and Yue et al. <ref type="bibr" target="#b24">[25]</ref> transfer the input images into different styles, such as rainy and foggy, to learn domain-invariant features. In contrast, several works do not change the image style at the pixel level but leverage the adversarial loss to disentangle the shared knowledge and minimize the negative impact of the domain-specific information. For instance, Tsai et al. <ref type="bibr" target="#b14">[15]</ref> and Luo et al. <ref type="bibr" target="#b17">[18]</ref> demand the generator to fool the discriminator by discriminating the feature between the source domain and target domain. Sankaranarayanan et al. <ref type="bibr" target="#b25">[26]</ref> leverage the image reconstruction as the self-supervision task to align the two domains, i.e., the real-world environment and synthetic data, yielding a scalable learned model, but it also costs more computation resources for recovering the large-size input image. Another line of works <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> focuses on mining the domain-specific knowledge in the target domain. The main idea is to minimize the prediction entropy in the target domain <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>. Zou et al. <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref> propose to leverage the pseudo labels with high confidence, and discuss different regularization terms. Taking one step further, Feng et al. <ref type="bibr" target="#b34">[35]</ref> and Lin et al. <ref type="bibr" target="#b35">[36]</ref> leverage the group information to acquire pseudo labels with high precision.</p><p>Zheng et al. <ref type="bibr" target="#b18">[19]</ref> apply one two-step training strategy, which first conducts the domain alignment to generate better pseudo labels according to multi-level features <ref type="bibr" target="#b36">[37]</ref>, and then applies the pseudo label learning. Furthermore, Zheng et al. <ref type="bibr" target="#b37">[38]</ref> rectify the pseudo label learning by explicitly combining the prediction uncertainty into the cross-entropy loss. In this paper, we notice that existing works, to some extent, still suffer from over-fitting and early-stopping tricks, leading to large prediction variance and re-implementation difficulties. We propose an efficient bootstrapping method, which is orthogonal to most existing approaches on minimizing the domain gap. In fact, the proposed method can be fused with existing methods to further improve the model scalability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Bootstrapping Learning</head><p>Bootstrapping learning denotes the capability of the model to progressively improve the performance by teaching itself <ref type="bibr" target="#b38">[39]</ref>. The teacher-student training policy <ref type="bibr" target="#b39">[40]</ref> is first proposed for model distillation, which intends to distill the knowledge from large-scale models to mobile models. It demands the parameter-efficient student model to predict consistent prediction scores with the large teacher model. However, teacher-student policy needs one pre-trained sophisticated network as the teacher model in advance, which is not always available. To address this limitation, Zhang et al. <ref type="bibr" target="#b40">[41]</ref> introduce deep mutual learning to simultaneously train two models of different structures from scratch and learn from each other. Different from preserving two models during training, Laine et al. <ref type="bibr" target="#b41">[42]</ref> propose ? model to enable the model learning from the model itself, which demands consistent prediction on the original input and the augmented input. Furthermore, Laine et al. also explore the temporal ensembling, which leverages the prediction history to stabilize the training. To address the out-of-the-date prediction in history, Tarvainen et al. <ref type="bibr" target="#b42">[43]</ref> and Choi et al. <ref type="bibr" target="#b43">[44]</ref> propose to maintain one mean model by moving average weight <ref type="bibr" target="#b44">[45]</ref>, which does not need to train one new model again. Similarly, Chen et al. <ref type="bibr" target="#b45">[46]</ref> and Zheng et al. <ref type="bibr" target="#b18">[19]</ref> introduce the memory mechanism to help the feature update, facilitating consistency learning. We are mainly different from existing bootstrapping learning approaches in two aspects: 1) We do not introduce more prerequisites, e.g., extra memory modules or an independent teacher model. Instead, we gradually aggregate the complementary model during training. The model can converge efficiently, and achieve competitive performance in the target domain quickly; 2) We explicitly consider the model weakness and adopt one adaptive data sampler, which focuses on the "hard" samples and facilitates learning complementary models in a coherent manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Hard Example Mining</head><p>The neural networks usually underestimate the minority, i.e., hard examples, during the mini-batch optimization <ref type="bibr" target="#b46">[47]</ref>, leading to over-fitting most "easy" samples. Therefore, several <ref type="figure">Fig. 2</ref>. Illustration of the basic model structure (Gray Parts). We follow most existing works <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b37">[38]</ref> to deploy the modified Deeplab-v2 <ref type="bibr" target="#b1">[2]</ref> with ResNet-101 <ref type="bibr" target="#b50">[51]</ref> as backbone. The auxiliary classifier is added to help the optimization, preventing gradient vanishment, especially for the lower layers <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b0">[1]</ref>. In this work, we focus on the outer loop (Green Parts). We leverage the discrepancy of the segmentation outputs from the primary classifier Cp and Ca to acquire the prediction variance V kl . The variance is then utilized to update the data sampler. More details can be found in Section III-A. researchers resort to example mining strategies to add more emphasis on the example with large losses. Most existing works focus on the object detection task. For instance, Shrivastava et al. <ref type="bibr" target="#b47">[48]</ref> let the network forward twice, called OHEM, to mine hard samples. OHEM searches hard examples from a large pool of 4000 regions in the first round, and then optimize the network by the selected samples, which are the top 128 high-loss regions. To evade the two-stage forward process, Lin et al. <ref type="bibr" target="#b46">[47]</ref> propose to directly enlarge the punishment on the hard example by a modified cross entropy loss, which also yields performance improvement. In contrast, many metric learning methods <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref> do not directly modify the loss, but select the input triplets with the largest loss, such as the farthest positives and the closet negatives to help the model learn the distance (relation) in the semantic space. In this work, we do not have the target-domain label, and could not foreknow the wrong samples. Therefore, we resort to the prediction variance as the hardness indicator. In fact, the proposed method is orthogonal to existing work, including focal loss and OHEM (using cross entropy as the hardness indicator). There are three main differences between our work and OHEM: (1) OHEM needs to feed forward the network twice in every iteration, while the proposed method conducts the inference once. We only update the data sampler after every epoch, which is relatively efficient. (2) OHEM is based on cross-entropy loss with ground-truth labels. In our work, we do not have the target-domain ground-truth labels. Therefore, we resort to the prediction variance, and as shown in <ref type="table" target="#tab_1">Table II</ref>, the prediction variance surpasses the prediction entropy. <ref type="bibr" target="#b2">(3)</ref> We further leverage the diversity between different epochs to conduct student aggregation. In the experiment, we also add ablation studies on the compatibility with existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD</head><p>Formulation. Given the labeled source-domain dataset X m = {x i m } M i=1 and the unlabeled target-domain dataset X n = {x j n } N j=1 , scene segmentation domain adaptation is to learn the projection function F , which maps the input data X to the segmentation map Y . M and N denote the number of the source-domain images and the target-domain images, respectively. Following the common practice in <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="figure">Fig. 3</ref>. The brief pipeline of the proposed method. There are two main components, i.e., Adaptive Sampler and Student Aggregation. We modify the training data distribution to learn complementary "weak" models, preventing the model from over-fitting. Different from existing methods, the pipeline enables interactions between learned models and the data sampler. The proposed method is orthogonal to most existing scene segmentation domain adaptation approaches (in the rounded rectangle). <ref type="bibr" target="#b18">[19]</ref>, we adopt the modified DeepLabv2 <ref type="bibr" target="#b1">[2]</ref> as the baseline model, which contains two classifiers, i.e., the primary classifier C p and the auxiliary classifier C a . The auxiliary classifier design is to help optimization and prevent the gradient from vanishing <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b0">[1]</ref>. In this work, we also involve the auxiliary prediction into the calculation of the prediction variance V kl . To simplify, we denote the two segmentation functions F p and F a , where F p (x) is the output of the primary classifier, and F a (x) is the output of the auxiliary classifier (see <ref type="figure">Figure 2</ref>). Overview. In this work, we do not pursue a sophisticated segmentation structure or optimization losses. We focus on the learning strategy. As shown in <ref type="figure">Figure 3</ref>, we provide one brief pipeline to illustrate the proposed approach, AdaBoost Student. AdaBoost Student contains two primary components, i.e., Adaptive Sampler and Student Aggregation. Adaptive Sampler modifies the input training data distribution, and provides more emphasis on uncertain samples. On the other hand, Student Aggregation is to accumulate the learned "weak" student models and output the prediction uncertainty to update data distribution. It is worth noting that there is one interaction loop from Adaptive Sampler to Student Aggregation, and back to Adaptive Sampler. We adopt one training policy similar to Generative Adversarial Network (GAN) <ref type="bibr" target="#b52">[53]</ref>. During training, Student Aggregation updates model parameters when the input data distribution is fixed, and vice versa. We fix the aggregated student model parameter to update the data distribution of Adaptive Sampler. We will illustrate the two components extensively in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Adaptive Sampler</head><p>Most bootstrapping works <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b41">[42]</ref> focus on mining the knowledge from the fixed data distribution but ignore the attention to the "hard" samples. The straightforward solution underpinning the conventional method, i.e., Adaptive boosting <ref type="bibr" target="#b19">[20]</ref>, is to improve the sampling rate of the wrongclassified samples. In a similar spirit, we adopt one adaptive sampler to progressively update the input data distribution D t according to the epoch t. The initial data distribution D 1 (j) = 1/N , and every sample has equal sampling probability. To learn the complementary models for the target domain, we improve the sampling rate of the "hard" target-domain samples with ambiguous predictions during training. It is worth noting that, due to the missing label in the target-domain, we can not deploy the prediction error to find the "hard" samples. Instead, we deploy the prediction variance as the "hard" indicator. Specifically, we formulate the prediction variance as the KLdivergence between the prediction of the primary classifier and the auxiliary classifier. The prediction variance of one single target-domain image can be calculated as:</p><formula xml:id="formula_0">V kl (x j n |?) = E[F p (x j n |?) log( F p (x j n |?) F a (x j n |?) )].<label>(1)</label></formula><p>If two classifiers predict the same class prediction, the value V kl is low. Otherwise, the prediction variance is high, which indicates the model is not confident on such training data. In practice, since the output prediction is the pixel-wise segmentation map, we adopt the mean value of the whole prediction map as the indicator for the input image. To make V kl as one distribution for the whole dataset, we apply the softmax function to normalize the prediction variance and make the sum of the V kl equal to 1. The next data sampling distribution is averaged with the last data distribution and the normalized prediction variance as:</p><formula xml:id="formula_1">D t+1 (j) = 1 2 (D t (j) + V kl (x j n |?)). (2) Since N j=1 D t (j) = 1 and N j=1 V kl = 1, we ensure the update distribution N j=1 D t+1 = 1, and D t+1 (j) is positive.</formula><p>As a result, the samples obtaining high prediction variance have more chances to be sampled in the next epoch. Discussion. 1. Why is there a discrepancy between the primary classifier and the auxiliary classifier? It is mostly due to the different receptive fields of the two classifiers. Specifically, the input feature of the primary classifier is "res5c", while the auxiliary classifier learns from the "res4b22" of the ResNet-101 backbone <ref type="bibr" target="#b50">[51]</ref>. We leverage the prediction variance to represent the model uncertainty on the input data as <ref type="bibr" target="#b37">[38]</ref>. Besides, we insert the dropout function before classifiers, which also enlarges the prediction discrepancy and helps to obtain the accurate uncertainty <ref type="bibr" target="#b53">[54]</ref>. 2. What are the advantages of the proposed adaptive sampler? There are two main points. First, we do not need the target-domain label to estimate the prediction error, which is different from the conventional AdaBoost algorithm in supervised learning. Instead, we leverage the prediction uncertainty to find the "hard" samples, which are more feasible for the domain adaptation problem. Second, existing methods usually ignore the importance of the input data distribution. The "easy" targetdomain data, which has high prediction confidence, generally does not provide more domain-specific information about the target domain. The adaptive sampler explicitly introduces the prediction variance into the data distribution update (see Eq. 2). We put more and more emphasis on the data with high uncertainty, facilitating the complementary model learning. The dynamic input distribution via the adaptive sampler encourages the knowledge transfer to the target domain efficiently. 3. Other sampling criterion. Except for the prediction variance, prediction entropy is another alternative choice. In the ablation study, we also provide the empirical result based on the sampling criterion of the prediction entropy, which can be formulated as:</p><formula xml:id="formula_2">V en (x j n |?) = E[?F p (x j n |?) log(F p (x j n |?))].</formula><p>A high value indicates that the prediction is close to the uniform distribution, and the model is not confident with the predicted classes given the input data. The samples obtaining high prediction entropy have more chances to be sampled in the next epoch. However, we observe one similar phenomenon with <ref type="bibr" target="#b37">[38]</ref> that the prediction entropy is sensitive to the object edges in segmentation maps rather than the "hard" samples with ambiguous predictions, which need to be "seen" again. Therefore, the sampling criterion based on prediction entropy generally performs worse than the prediction variance in Eq. 1, which is verified in <ref type="table" target="#tab_1">Table II</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Student Aggregation</head><p>In the conventional strategy, i.e., Adaptive Boosting, multiple binary classifiers are sequentially learned with more attentions to the hard samples. Instead of training multiple deeply-learned models sequentially, we leverage the adaptive data sampler to enable learning complementary models in onetime training, which largely saves the training cost. Next, we combine the vote of "weak" model snapshots as one final model. We regard snapshots as student models but do not introduce extra teachers. For the deeply-learned models, it is not efficient to preserve all the model snapshots in the memory, and fuse the prediction of every model, which demands the multiple-time inference. We follow Mean Teacher <ref type="bibr" target="#b42">[43]</ref> to apply the weight average moving to keep one weight-averaged model of previous epochs:</p><formula xml:id="formula_3">? t = ? t ? ? t ,<label>(3)</label></formula><p>where the model weight ? t assigns different emphasis to "weak" models, and ? t denotes the parameters of the student model at the t-th epoch. ? t denotes the parameters of the aggregated model. Since we can not foreknow the segmentation error on the target domain, we simply adopt average weights, which can be online updated as: for iteration = 1 to T2 do 5:</p><formula xml:id="formula_4">? t = t ? 1 t ? t?1 + 1 t ? t ,<label>(4)</label></formula><p>To be simplify, here we only show the basic cross-entropy segmentation loss on the source domain data:</p><formula xml:id="formula_5">Lce = E[?p i m log F (x i m |?)].<label>(5) 6:</label></formula><p>We denotes other regularization losses on the target domain as R(x j n , ?). Update the model weight:</p><formula xml:id="formula_6">L total = Lce + R(x j n , ?).<label>(6)</label></formula><p>7:</p><p>end for 8: ?t = ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>The mean model parameter is updated:</p><formula xml:id="formula_7">?t = t ? 1 t ?t?1 + 1 t ?t.<label>(7)</label></formula><p>10:</p><p>Update the adaptive data distribution Dt+1:</p><formula xml:id="formula_8">Dt+1(j) = 1 2 (Dt(j) + V kl (x j n |?t)),<label>(8)</label></formula><p>where V kl is the prediction variance defined in Eq. 1, and we apply the current mean model ?t to estimate the variance. 11: end for 12: return ?t. one mean student model, which can be preserved in CPU memory. Second, the model update is efficient and effective, which does not require gradient calculation. We only need to update the weights of every layer to the mean value of existing snapshots. Meanwhile, student aggregation provides one final model with good generalizability, preventing overfitting as the traditional AdaBoost algorithm. More quantitative results are discussed in Experiment. 3. Correlation with Ad-aBoost. The main spirit of the proposed method is following Adaboost <ref type="bibr" target="#b19">[20]</ref> to treat "hard" samples differently according to learned model snapshots. However, for domain adaptation, we can not foreknow the error e m on the unlabeled target-domain data. Therefore, we adopt the trade-off. 1) In this work, we update the distribution based on the prediction variance instead of the error; 2) The binary classifier aggregation in Adaboost can be formulated as:</p><formula xml:id="formula_9">G(x) = sign( M m=1 ? m G m (x)),</formula><p>where G m () is one of weak classifiers and ? m is the adaptive weights based on the error e m . ? m = 1 2 log( 1?em em ). Since the error e m in target domain is unavailable, we deploy the temporal ensemble via weight averaging as a trade-off, which equals to set ? m = 1 M . In ablation studies, we also try different updating strategies, such as momentum, which is inferior to the proposed method. It verifies that the weight averaging trade-off is sub-optimal yet effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Optimization</head><p>We combine the two components, i.e., adaptive sampler and student aggregation, in a coherent manner, and explicitly en-able interactions between learned models and the data sampler. As shown in Algorithm 1, the adaptive sampler depends on the mean student model ? t to update the data distribution (see Eq. 8). Meanwhile, the adaptive sampler controls the input training data, which, in turn, affects the ? t and ? t (see Eq. 7). Since we do not pursue new segmentation losses or regularization objectives, here we just mention the basic source-domain segmentation loss as:</p><formula xml:id="formula_10">L ce = E[?p i m log F (x i m |?)].<label>(9)</label></formula><p>where p i m is the ground-truth probability vector of the label y i m . The value p i m (c) equals to 1 if c == y i m otherwise 0. Besides, there are multiple feasible regularization terms, including adversarial losses proposed in <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref> and consistency loss <ref type="bibr" target="#b18">[19]</ref>. Without loss of generality, here we denote the regularization terms on the target domain as R(x j n , ?). Therefore, the optimization objective in every iteration can be formulated as:</p><formula xml:id="formula_11">L total = L ce + R(x j n , ?).<label>(10)</label></formula><p>It is worth noting that different baseline methods have different regularization terms. We follow the regularization term in the corresponding baseline method for a fair comparison. In this paper, we compare three baseline methods, i.e., AdaptSeg-Net <ref type="bibr" target="#b14">[15]</ref>, MRNet <ref type="bibr" target="#b18">[19]</ref> and Uncertainty <ref type="bibr" target="#b37">[38]</ref>. AdaptSegNet mainly adopts the adversarial loss for regularization, while MRNet adds a consistency-based memory regularization. The Uncertainty follows MRNet, so Uncertainty has the same regularization term as MRNet. For a fair comparison, we follow the corresponding regularization term in different baseline methods. After every T 2 iterations, we update the adaptive sampler and the mean student model, as discussed in Section III-A and Section III-B. The training is stopped after T 1 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENT</head><p>A. Implementation Details Network Architecture. We adopt the Deeplab-v2 <ref type="bibr" target="#b1">[2]</ref> as the baseline model, which deploys the ResNet-101 <ref type="bibr" target="#b50">[51]</ref> as the backbone. Following most existing works <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b37">[38]</ref>, we insert one auxiliary classifier with the same structure as the primary classifier. The classifier consists of one Atrous Spatial Pyramid Pooling (ASPP) module <ref type="bibr" target="#b1">[2]</ref> and one fully-connected layer. The auxiliary classifier is added at the res4b22 layer. We also insert the dropout layer of 0.2 drop rate before the fully-connected layer. Training Details. Following existing works <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>, the input image is resized to 1280 ? 640, and we randomly crop 1024 ? 512 for training. Random horizontal flipping is also applied. We deploy the SGD optimizer with a mini-batch of 2. The initial learning rate is set as 0.0002. Following <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref>, we deploy the ploy learning rate policy by multiplying the scale factor (1 ? current iter total iter ) 0.9 . The total iteration is set as 50k (T 1 = 10, T 2 = 5000). When inference, we follow <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b37">[38]</ref> to combine the prediction of the two classifiers as the final prediction. Our implementation is based on Pytorch <ref type="bibr" target="#b57">[58]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Datasets and Evaluation Metric</head><p>Datasets. In this work, we conduct experiments on three scene segmentation domain adaptation benchmarks. To simplify the illustration, we denote the source dataset A and the target dataset B as A ? B. Two widely-used benchmarks are to leverage the synthetic data to learn the shared knowledge, and adapt the knowledge to the real-world scenario. The settings are GTA5 <ref type="bibr" target="#b6">[7]</ref> ? Cityscapes <ref type="bibr" target="#b7">[8]</ref> and SYNTHIA <ref type="bibr" target="#b58">[59]</ref> ? Cityscapes <ref type="bibr" target="#b7">[8]</ref>. In particular, the GTA5 dataset is collected from one video game, which contains 24,966 labeled images for training. The SYNTHIA dataset is generated from a virtual city engine with pixel-level annotations as well, including 9,400 training images. The target dataset, i.e., Cityscapes, collects the real-world street-view images from 50 different cities, yielding 2, 975 unlabeled training images and 500 images for testing. We also adopt one cross-city benchmark, i.e., Cityscapes [8] ? Oxford RobotCar <ref type="bibr" target="#b59">[60]</ref>. In this setting, we use the annotation of 2, 975 training images of the Cityscapes dataset. In contrast with the Synthetic-to-real setting, the Oxford RobotCar dataset is also collected from the realistic street-view camera. The challenge is in the noisy variants, such as weather and illumination conditions. The Oxford RobotCar dataset is collected on rainy days and cloudy days, while the Cityscapes dataset mostly contains images on sunny days. More details are shown in <ref type="table" target="#tab_1">Table I</ref>. Evaluation Metric. We follow previous works to report the IoU accuracy of each category, and mean IoU (mIoU) for all the classes. For SYNTHIA ? Cityscapes, some previous works report the mean IoU over 13 classes, while others report both 13 classes and 16 classes. We report both results, and denote the results of 13 classes and 16 classes as mIoU * and mIoU, respectively. For GTA5 ? Cityscapes and Cityscapes ? Oxford RobotCar, we report the 19-category and 9-category accuracy, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation Studies</head><p>Effect of the Adaptive Sampler. First, we study the adaptive sampler. Since we intend to learn the complementary model snapshots, as shown in <ref type="table" target="#tab_1">Table II</ref>, the single "weak" model does not achieve significant improvement, even with the performance drop. The observation is aligned with the conventional AdaBoost algorithm <ref type="bibr" target="#b19">[20]</ref>, since the current snapshot takes more attention to "hard" samples. Here we give one toy example on a binary classification to illustrate the phenomenon 1 . It is because every weak classifier considers more hard negatives in the last round and may overfit the negative data. Despite  the probability of overfitting the negatives, such snapshots are complementary to the snapshot trained in the early stage and help the ensembled model keep performance improvement. Therefore, compared with the baseline method, i.e., MRNet <ref type="bibr" target="#b18">[19]</ref>, which achieves 45.5% mIoU accuracy, MRNet using adaptive sampler decreases to 45.2%. It is because the hard negatives do not lead to one single optimal student model but the complementary model of the last model snapshot. If we further apply the student aggregation, MRNet + Ours has achieved significant improvement from 45.2% mIoU accuracy to 49.0% mIoU accuracy, which also surpasses MRNet (45.5% mIoU) by a relatively large margin. By default, we apply the sampler based on the prediction variance, and we observe that the alternative sampler based on the prediction entropy leads to one inferior performance of 48.1% mIoU. It is mainly due to the prediction entropy taking more attention to the object edges as shown in <ref type="bibr" target="#b37">[38]</ref>, which can not nominate "hard" samples with ambiguous predictions accurately. Furthermore, we compare other sampling strategies, i.e., sampling with replacement (PutBack) and random sampling (Random), to verify the effectiveness of the proposed Adaptive Sampler. PutBack sampler is different from the original MRNet, which directly adopts the sampling without replacement (Uniform). As shown in <ref type="table" target="#tab_1">Table II</ref> The proposed Adaptive Sampler (ours) surpasses the PutBack Sampler, since we explicitly add more emphasis on the hard samples. Similarly, we could observe that (1) Random sampling (44.6%) is inferior to Uniform sampling (45.5%). It is because the random sampler, like PutBack sampler, usually does not "see" all data in every epoch. <ref type="bibr" target="#b1">(2)</ref> Random sampling leads to diverse snapshots, but it also suffers from a larger performance fluctuation. We observe that some snapshots in <ref type="figure">Fig. 4</ref>. Convergence of the proposed method. We provide the sensitivity analysis of MRNet+Ours on two benchmarks, i.e., GTA5?Cityscapes (GTA5) and SYNTHIA?Cityscapes (SYNTHIA). The results suggest that the AdaBoost Student model (AdaBoost) quickly converges, while the performance of the student model (Student) is still fluctuating. our implementation arrive at around 41-42% mIoU, which results in performance convergence. For instance, the snapshot at the 25000th iteration performs 44.6% mIoU, but the model at the 45000th iteration only arrives at 41.8% mIoU. Therefore, Random sampling + student aggregation (averaged model) only converges to 48.4% mIoU, which is also inferior to our method. Due to the random sampling is not stable, we run the experiment twice. Despite the performance fluctuation of the single snapshot, the re-run performance with random sampling also converges to 48.3% mIoU (around 48.4% mIoU). Finally, we could see that no matter uniform, putback, or random sampling method, the aggregated models all converge to around 48.4% compared to the 49.0% of our method. Therefore, it verifies our motivation that the sampling on hard negative samples is non-trivial. Effect of the Student Aggregation. We also investigate the student aggregation in Adaboost Student (see <ref type="table" target="#tab_1">Table II</ref>). There are two main observations. (1) The student aggregation alone can yield performance improvement. It is due to the model discrepancy during training. Especially for the scene segmentation, the extremely small training batch sizes and data shuffle lead to different training orders in every epoch. Therefore, the baseline method, i.e., MRNet, with student aggregation alone, has arrived at 48.4% mIoU accuracy from 45.5% mIoU.</p><p>(2) Since the input data distribution is fixed in the baseline method, the model snapshots are still homogeneous due to the training data. In contrast, the proposed method explicitly demands learning complementary models by the dynamic input data via the adaptive sampler. The full method with the adaptive sampler, therefore, yields better results at 49.0%, surpassing the student aggregation alone (48.4%). The results also suggest the effectiveness of the adaptive sampler. Compatibility of the Proposed Method. We argue that the proposed method is orthogonal to most existing methods, and can be fused with existing frameworks to obtain better performance. Therefore, we re-implement three existing approaches, including AdaptSegNet <ref type="bibr" target="#b14">[15]</ref>, MRNet <ref type="bibr" target="#b18">[19]</ref> and Uncertainty <ref type="bibr" target="#b37">[38]</ref>. As shown in <ref type="table" target="#tab_1">Table III</ref>, we observe one consistent performance improvement on GTA5?Cityscapes for all three methods. For the widely-adopted method, i.e., AdaptSegNet <ref type="bibr" target="#b14">[15]</ref>, AdaptSegNet + Ours has arrived at 47.3% mIoU, which surpasses the original AdaptSegNet (42.4%) by <ref type="bibr">Fig. 5</ref>. Qualitative results of semantic segmentation adaptation on GTA5 ? Cityscapes and SYNTHIA ? Cityscapes. We show the original targetdomain image, the ground-truth segmentation, and the output of methods, i.e., MRNet <ref type="bibr" target="#b18">[19]</ref>, and MRNet [19] + Ours. Our results are in the right column. (Best viewed in color). We deploy the white dash boxes to highlight the different predictions. The proposed method is more robust to the minority categories, such as lights, poles, and traffic signs.</p><p>+4.9%. Furthermore, we observe one similar performance improvement on recent methods. MRNet <ref type="bibr" target="#b18">[19]</ref> + Ours has boosted from 45.5% mIoU accuracy to 49.0%, while Uncertainty <ref type="bibr" target="#b37">[38]</ref> + Ours obtains +0.6% from 50.3% to 50.9% mIoU accuracy. As shown in <ref type="table" target="#tab_1">Table IV and Table V</ref>, we observe one similar result on both SYNTHIA?Cityscapes and Cityscapes?Oxford RobotCar benchmarks. For the SYNTHIA?Cityscapes benchmark, AdaptSegNet <ref type="bibr" target="#b14">[15]</ref>, MRNet <ref type="bibr" target="#b18">[19]</ref> and Uncertainty <ref type="bibr" target="#b37">[38]</ref> have achieved +1.2%, +2.7% and +2.6% mIoU*, respectively. On the other hand, AdaptSegNet <ref type="bibr" target="#b14">[15]</ref>, MRNet <ref type="bibr" target="#b18">[19]</ref> and Uncertainty <ref type="bibr" target="#b37">[38]</ref> have achieved +1.8%, +1.2% and +0.8% mIoU on the Cityscapes?Oxford RobotCar benchmark, respectively. In a summary, the extensive experiment with three methods on three benchmarks verifies that the proposed approach, Adaptive Student, can be fused with existing frameworks to improve the model generalizability in the target domain.</p><p>Limitation. We observe that the proposed method shows less improvement on the pseudo label learning based method, i.e., Uncertainty <ref type="bibr" target="#b37">[38]</ref> than the domain alignment based method, i.e., AdaptSegNet <ref type="bibr" target="#b14">[15]</ref> and MRNet <ref type="bibr" target="#b18">[19]</ref>. The main reason is the strong supervised learning of the generated pseudo labels on the target domain, which limits the model discrepancy and compromises learning complementary "weak" models in the proposed AdaBoost Student.</p><p>Convergence of the Proposed Method. One advantage of the proposed method is the quick convergence to one robust model after limited iterations, since the complementary models are aggregated during training. Here we provide the sensitivity analysis of convergence time on both GTA5 ? Cityscapes and SYNTHIA ? Cityscapes. We adopt MRNet as the baseline model. As shown in <ref type="figure">Figure 4</ref>, we observe that the proposed method can efficiently converge at around 30, 000 iterations, while the student models are still jittering during training.   </p><formula xml:id="formula_12">- - - - - - - - - - - - - - - - - - - 29.2 FCAN [67] - - - - - - - - - - - - - - - - - - -</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparisons with State-of-the-art Methods</head><p>Synthetic-to-real. We mainly compare other recent methods on two synthetic-to-real benchmarks, which leverage the synthetic data to learn the shared knowledge. We compare recent methods with reported results and several methods re-implemented by us. For a fair comparison, we compare models with a similar structure, which is based on the Deeplab-v2 <ref type="bibr" target="#b1">[2]</ref>, and the backbone is ResNet-101 <ref type="bibr" target="#b50">[51]</ref>. The competitive methods can be generally classified into two categories according to the usage of the pseudo label. One line of works focuses on the domain alignment, including AdaptSegNet <ref type="bibr" target="#b14">[15]</ref>, SIBAN <ref type="bibr" target="#b16">[17]</ref>, CLAN <ref type="bibr" target="#b17">[18]</ref>, APODA <ref type="bibr" target="#b63">[64]</ref>, PatchAlign <ref type="bibr" target="#b15">[16]</ref>, DT <ref type="bibr" target="#b64">[65]</ref> and MRNet <ref type="bibr" target="#b18">[19]</ref>. Another line of works focuses on mining the target-domain knowledge via noisy labels and deploys the pseudo label learning, such as CBST <ref type="bibr" target="#b26">[27]</ref>, MRKLD <ref type="bibr" target="#b27">[28]</ref> and Uncertainty <ref type="bibr" target="#b37">[38]</ref>, which generally achieves higher performance. As shown in <ref type="table" target="#tab_1">Table III and Table IV</ref>, the proposed method yields consistent improvement in both kinds of works. The competitive performance has been achieved by combining AdaBoost Student with the Uncertainty <ref type="bibr" target="#b37">[38]</ref>. Specifically, we have achieved 50.9% and 50.4% mIoU on GTA5?Cityscapes and SYNTHIA?Cityscapes, respectively. Furthermore, the pre-class IoU results also suggest that the proposed method has achieved relatively good results on several classes of smallscale objectives, including Pole, Wall, and Fence. Cross-city. We also evaluate the proposed method on one new cross-city benchmarks, i.e., Cityscapes ? Oxford RobotCar (see <ref type="table">Table V</ref>). Both Cityscapes and Oxford RobotCar are collected from the realistic scenarios but in different cities and weather. The proposed method also has achieved the competitive result of 75.2% mIoU accuracy and showed a consistent performance improvement with other existing methods.</p><p>Qualitative Results. Furthermore, we provide the segmentation results in <ref type="figure">Figure 5</ref>, which also verifies the effectiveness of the proposed method. Comparing to the segmentation predictions of vanilla MRNet <ref type="bibr" target="#b18">[19]</ref>, MRNet + Ours generally rectifies the object details, and achieves more robust outputs on the target domain. We apply the white dash boxes to highlight the different predictions. In particular, the proposed method is more robust to the minority categories, such as lights, poles, and traffic signs.</p><p>V. FURTHER ANALYSIS AND DISCUSSIONS Network Structure. We also verify the proposed method on a relatively vanilla network, i.e., VGG16 <ref type="bibr" target="#b68">[69]</ref>. Following previous works, we do not introduce BN (Batch Normalization) layers in the backbone network. We re-implement MRNet <ref type="bibr" target="#b18">[19]</ref>, which has achieved 25.5% mIoU on GTA5 ? Cityscapes. As shown in <ref type="table" target="#tab_1">Table VI</ref>, we can observe two main points. First, the proposed method is complementary to the existing works, e.g., MRNet <ref type="bibr" target="#b18">[19]</ref>, and MRNet [19] + Ours achieves +14.0% mIoU improvements. Second, we also achieve one competitive result 39.5% mIoU with other existing methods based on VGG16. Aggregation with Momentum. Due to the prediction fluctuation on the target domain, we can not foreknow which snapshot is reliable. We also run MRNet+Ours with momentum strategy <ref type="bibr" target="#b71">[72]</ref> on GTA5 ? Cityscapes. Two momentum values 0.9 and 0.5 are explored to keep old weights. The aggregated model only achieves 46.4% and 45.3%, respectively, which is inferior to the weight averaging. It verifies that the weight averaging trade-off is sub-optimal yet effective. In this paper, we leverage the weight averaging strategy, but it is still open to other aggregation alternatives. Focal Loss. The focal loss is designed for supervised learning, which is modified from the cross-entropy loss <ref type="bibr" target="#b46">[47]</ref>. For domain adaptation, we do not have ground-truth target-domain labels. Therefore, we apply the focal loss on the source-domain data to train the model. We re-implement the focal loss, and apply the default gamma=2 as the original paper suggested. However, the result of Ours+Focal Loss (47.87% mIoU) is not better than Ours. We think that the focal loss makes the model focus on the "hard" samples in the source domain rather than target domain, which compromises the final performance.</p><p>In the future, we will further study to fuse the focal loss in other formats on the target domain. vs. Mean Teacher (MT). Similarly, the existing method, i.e., Mean Teacher (MT) <ref type="bibr" target="#b42">[43]</ref> also preserves one weight-average model during the training process. We apply the same strategy, including iteration numbers, to update the teacher model and re-implement Mean Teacher. The main difference between the proposed method and Mean Teacher (MT) is twofold: First, we adopt the adaptive sampler, which enables interactions between learned models and the data sampler. In this way, the proposed method leads to more complementary snapshots during training for the student aggregation. Second, Mean Teacher needs the teacher prediction in every iteration. It demands extra model inference to calculate the kl-divergence loss (costs extra time and memory) and forces the student model and the weight-average teacher model to predict the same distribution given the input, which also limits learning complementary student models. In contrast, the proposed method does not introduce such an objective and performs more efficiently and effectively with the spirit of AdaBoost <ref type="bibr" target="#b19">[20]</ref>. As a result, the proposed method outperforms MT (Student) 46.6% and MT (Teacher) 47.5% mIoU (see <ref type="table" target="#tab_1">Table VII</ref>).</p><p>Multi-Source Domains. We add a new setting on GTA5 + SYNTHIA?Cityscapes with two source domains to evaluate the proposed method. With multi-source domain data, the model can be trained more robust to the unlabelled target environment as well as more diverse between single snapshots. As shown in <ref type="table" target="#tab_1">Table VIII</ref>, we could observe three points: (1) With more source-domain data, the model arrives at a better  <ref type="bibr" target="#b72">[73]</ref> 2.86 VAT <ref type="bibr" target="#b73">[74]</ref> 10.55 CT-GAN <ref type="bibr" target="#b74">[75]</ref> 9.98 ? 0.21 Mean Teacher <ref type="bibr" target="#b42">[43]</ref> 6.28 ? 0.15 Mean Teacher [43] * 6.14 ? 0.24 Ours 6.05 ? 0.12 basic result of 47.6% compared to 45.5% (only GTA5).</p><p>(2) The model with the adaptive sampler (48.4%) is still competitive with the single snapshot on baseline (47.6%). (3) With better single snapshots, our method achieves the best performance of 50.8% mIoU. Semi-supervised Learning. We follow MeanTeacher <ref type="bibr" target="#b42">[43]</ref> and modify the official code on Cifar-10 as our baseline 2 . The MeanTeacher backbone also has two classifiers, one for classification and the other for regressing the teacher prediction. Therefore, the proposed method can directly leverage the difference between two classifiers as the prediction variance to update the data sampler. As shown in <ref type="table" target="#tab_1">Table IX</ref>, the proposed method further improves the semi-supervised learning result (10 runs with 4000 labeled data) from 6.28% ? 0.15 top-1 error (reported in MeanTeacher) to 6.05% ? 0.12 top-1 error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>We identify one practical challenge in deciding the earlystopping time of the scene segmentation domain adaptation task. To address this limitation, we propose an efficient bootstrapping solution, AdaBoost Student, to learn the scalable model by aggregating "weak" models. The main idea underpinning AdaBoost Student is to leverage the model discrepancy during training. Specifically, AdaBoost Student adopts one adaptive data sampler and explicitly facilitates learning complementary models in a coherent manner. Thus, AdaBoost Student can efficiently converge to one robust final model and prevent over-fitting. As a result, we have achieved consistent improvements and competitive results on three benchmarks, including two synthetic-to-real benchmarks and one cross-city benchmark. In the future, we will continue to investigate the usage of Adaboost Student and apply it to other fields, such as medical images, to obtain the model with good generalizability.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>where t ? {2, ...T 1 } and ? 1 = ? 1 . We do not need to update the mean student model very often. In our practice, we update the mean model every T 2 = 5000 iterations. T 1 is the total training epoch number, while T 2 is the iteration number of each epoch. We find that the weight averaging still can achieve a competitive result. Discussion. 1. How about computation costs? Time Cost. As shown in Eq. 4, only 2 DNN weights need to be considered during every update, and the weight averaging costs about one forward inference time, which can be neglected<ref type="bibr" target="#b54">[55]</ref>. Memory Cost. The main memory cost is to preserve one mean student model. We note that the mean student model can be moved to CPU memory during idle time. We do not Training Procedure of the Proposed MethodRequire: The source domain dataset Xm = {X i m } M i=1 ; The source domain label Ym = {y i m } M i=1 ; The unlabeled target domain dataset Xn = {x j n } N j=1 ; Require: The source-domain parameter ?s; The epoch number T1;The iteration number T2 in each epoch. 1: Initialize ? = ?s; 2: Initialize target domain data distribution D1(j) = 1/N ;3:  for epoch t = 1 to T1 do</figDesc><table><row><cell>4:</cell></row></table><note>update the mean student model very often. When updating, we just move it back to GPU memory. Since we do not need to calculate the gradient but the mean of model parameters, the update process also costs limited memory. 2. What are the advantages of Student Aggregation? The advantages are mostly in two aspects: First, instead of training S (S &gt; 5) classifiers in the conventional AdaBoost, we only need to keep Algorithm 1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I LIST</head><label>I</label><figDesc>OF CATEGORIES AND NUMBER OF IMAGES OF FOUR DATASETS, i.e.,</figDesc><table><row><cell cols="5">GTA5 [7], SYNTHIA [59], CITYSCAPES [8] AND OXFORD</cell></row><row><cell></cell><cell></cell><cell cols="2">ROBOTCAR [60].</cell><cell></cell></row><row><cell>Datasets</cell><cell cols="4">GTA5 SYNTHIA Cityscapes Oxford RobotCar</cell></row><row><cell cols="2">#Train Images 24,966</cell><cell>9,400</cell><cell>2,975</cell><cell>894</cell></row><row><cell>#Test Images</cell><cell>-</cell><cell>-</cell><cell>500</cell><cell>271</cell></row><row><cell>#Category</cell><cell>19</cell><cell>16</cell><cell>19</cell><cell>9</cell></row><row><cell>Synthetic</cell><cell></cell><cell></cell><cell>?</cell><cell>?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II ABLATION</head><label>II</label><figDesc>STUDY OF THE TWO COMPONENTS IN ADABOOST STUDENT ON GTA5?CITYSCAPES. WE ADOPT MRNET [19] AS BASELINE, AND STUDY THE IMPACT OF THE ADAPTIVE SAMPLER AND THE STUDENT AGGREGATION ALONE. THE RESULTS SUGGEST THAT THE ADAPTIVE SAMPLER DOES NOT IMPROVE THE SINGLE MODEL PERFORMANCE BUT HELPS COMPLEMENTARY MODEL LEARNING, FACILITATING THEFINAL "WEAK" STUDENT MODEL AGGREGATION. OURS (ENTROPY) DENOTES THAT WE APPLY THE PREDICTION ENTROPY TO UPDATE THE ADAPTIVE SAMPLER, WHILE OURS (VARIANCE) IS THE DEFAULT SETTING IF NOT SPECIFIED. PUTBACK SAMPLER DENOTES RANDOM SAMPLING WITH REPLACEMENT.</figDesc><table><row><cell>Method</cell><cell>PutBack Adaptive</cell><cell>Student</cell><cell>mIoU</cell></row><row><cell></cell><cell cols="2">Sampler Sampler Aggregation</cell><cell></cell></row><row><cell>MRNet [19] w Uniform</cell><cell></cell><cell></cell><cell>45.5</cell></row><row><cell>w PutBack</cell><cell></cell><cell></cell><cell>43.6</cell></row><row><cell>w Random</cell><cell></cell><cell></cell><cell>44.6</cell></row><row><cell>w Adaptive Sampler</cell><cell></cell><cell></cell><cell>45.2</cell></row><row><cell>w Uniform + Student Aggregation</cell><cell></cell><cell></cell><cell>48.4</cell></row><row><cell>w PutBack + Student Aggregation</cell><cell></cell><cell></cell><cell>48.3</cell></row><row><cell>w Random + Student Aggregation</cell><cell></cell><cell></cell><cell>48.4</cell></row><row><cell>MRNet [19] + Ours (entropy)</cell><cell></cell><cell></cell><cell>48.1</cell></row><row><cell>MRNet [19] + Ours (variance)</cell><cell></cell><cell></cell><cell>49.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>, (1) PutBack Sampler does not lead to a better single snapshot. It is because the learned model does not "see" all data in every iteration, which compromises the training process. (2) PutBack Sampler also ensures diverse snapshots. Therefore, PutBack Sampler + Student Aggregation arrives 48.3% mIoU accuracy, which is close to the baseline + Student Aggregation of 48.4%. (3)</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III QUANTITATIVE</head><label>III</label><figDesc>RESULTS ON GTA5 ? CITYSCAPES. WE PRESENT PRE-CLASS IOU AND MIOU. THE BEST ACCURACY IN EVERY COLUMN IS IN BOLD.</figDesc><table><row><cell>Method</cell><cell cols="4">Road SW Build Wall Fence Pole</cell><cell>TL</cell><cell>TS</cell><cell cols="3">Veg. Terrain Sky</cell><cell>PR</cell><cell cols="3">Rider Car Truck Bus Train Motor Bike mIoU</cell></row><row><cell>Source</cell><cell>75.8 16.8 77.2</cell><cell>12.5</cell><cell>21.0</cell><cell cols="4">25.5 30.1 20.1 81.3</cell><cell>24.6</cell><cell cols="3">70.3 53.8 26.4 49.9</cell><cell>17.2</cell><cell>25.9</cell><cell>6.5</cell><cell>25.3</cell><cell>36.0</cell><cell>36.6</cell></row><row><cell>AdaptSegNet [15]</cell><cell>86.5 36.0 79.9</cell><cell>23.4</cell><cell>23.3</cell><cell cols="4">23.9 35.2 14.8 83.4</cell><cell>33.3</cell><cell cols="3">75.6 58.5 27.6 73.7</cell><cell>32.5</cell><cell>35.4</cell><cell>3.9</cell><cell>30.1</cell><cell>28.1</cell><cell>42.4</cell></row><row><cell cols="2">AdaptSegNet [15] + Ours 89.5 34.1 83.7</cell><cell>31.5</cell><cell>25.0</cell><cell cols="4">36.0 40.6 34.6 85.6</cell><cell>44.6</cell><cell cols="3">77.8 61.4 30.4 85.6</cell><cell>35.9</cell><cell>47.1</cell><cell>1.8</cell><cell>19.4</cell><cell>34.1</cell><cell>47.3</cell></row><row><cell>SIBAN [17]</cell><cell>88.5 35.4 79.5</cell><cell>26.3</cell><cell>24.3</cell><cell cols="4">28.5 32.5 18.3 81.2</cell><cell>40.0</cell><cell cols="3">76.5 58.1 25.8 82.6</cell><cell>30.3</cell><cell>34.4</cell><cell>3.4</cell><cell>21.6</cell><cell>21.5</cell><cell>42.6</cell></row><row><cell>CLAN [18]</cell><cell>87.0 27.1 79.6</cell><cell>27.3</cell><cell>23.3</cell><cell cols="4">28.3 35.5 24.2 83.6</cell><cell>27.4</cell><cell cols="3">74.2 58.6 28.0 76.2</cell><cell>33.1</cell><cell>36.7</cell><cell>6.7</cell><cell>31.9</cell><cell>31.4</cell><cell>43.2</cell></row><row><cell>SP-Adv [61]</cell><cell>86.2 38.4 80.8</cell><cell>25.5</cell><cell>20.5</cell><cell cols="4">32.8 33.4 28.2 85.5</cell><cell>36.1</cell><cell cols="3">80.2 60.3 28.6 78.7</cell><cell>27.3</cell><cell>36.1</cell><cell>4.6</cell><cell>31.6</cell><cell>28.4</cell><cell>44.3</cell></row><row><cell>MaxSquare [62]</cell><cell>88.1 27.7 80.8</cell><cell>28.7</cell><cell>19.8</cell><cell cols="4">24.9 34.0 17.8 83.6</cell><cell>34.7</cell><cell cols="3">76.0 58.6 28.6 84.1</cell><cell>37.8</cell><cell>43.1</cell><cell>7.2</cell><cell>32.3</cell><cell>34.2</cell><cell>44.3</cell></row><row><cell>ASA [63]</cell><cell>89.2 27.8 81.3</cell><cell>25.3</cell><cell>22.7</cell><cell cols="4">28.7 36.5 19.6 83.8</cell><cell>31.4</cell><cell cols="3">77.1 59.2 29.8 84.3</cell><cell>33.2</cell><cell>45.6 16.9</cell><cell>34.5</cell><cell>30.8</cell><cell>45.1</cell></row><row><cell>APODA [64]</cell><cell>85.6 32.8 79.0</cell><cell>29.5</cell><cell>25.5</cell><cell cols="4">26.8 34.6 19.9 83.7</cell><cell>40.6</cell><cell cols="3">77.9 59.2 28.3 84.6</cell><cell>34.6</cell><cell>49.2</cell><cell>8.0</cell><cell>32.6</cell><cell>39.6</cell><cell>45.9</cell></row><row><cell>PatchAlign [16]</cell><cell>92.3 51.9 82.1</cell><cell>29.2</cell><cell>25.1</cell><cell cols="4">24.5 33.8 33.0 82.4</cell><cell>32.8</cell><cell cols="3">82.2 58.6 27.2 84.3</cell><cell>33.4</cell><cell>46.3</cell><cell>2.2</cell><cell>29.5</cell><cell>32.3</cell><cell>46.5</cell></row><row><cell>BL [30]</cell><cell>91.0 44.7 84.2</cell><cell>34.6</cell><cell>27.6</cell><cell cols="4">30.2 36.0 36.0 85.0</cell><cell>43.6</cell><cell cols="3">83.0 58.6 31.6 83.3</cell><cell>35.3</cell><cell>49.7</cell><cell>3.3</cell><cell>28.8</cell><cell>35.6</cell><cell>48.5</cell></row><row><cell>DT [65]</cell><cell>90.6 44.7 84.8</cell><cell>34.3</cell><cell>28.7</cell><cell cols="4">31.6 35.0 37.6 84.7</cell><cell>43.3</cell><cell cols="3">85.3 57.0 31.5 83.8</cell><cell>42.6</cell><cell>48.5</cell><cell>1.9</cell><cell>30.4</cell><cell>39.0</cell><cell>49.2</cell></row><row><cell>AdvEnt [66]</cell><cell>89.4 33.1 81.0</cell><cell>26.6</cell><cell>26.8</cell><cell cols="4">27.2 33.5 24.7 83.9</cell><cell>36.7</cell><cell cols="3">78.8 58.7 30.5 84.8</cell><cell>38.5</cell><cell>44.5</cell><cell>1.7</cell><cell>31.6</cell><cell>32.4</cell><cell>45.5</cell></row><row><cell>Source</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE IV QUANTITATIVE</head><label>IV</label><figDesc>RESULTS ON SYNTHIA ? CITYSCAPES. WE PRESENT PRE-CLASS IOU, MIOU AND MIOU*. MIOU AND MIOU* ARE AVERAGED OVER 16 AND 13 CATEGORIES, RESPECTIVELY. THE BEST ACCURACY IN EVERY COLUMN IS IN BOLD.TABLE V QUANTITATIVE RESULTS ON THE CROSS-CITY BENCHMARK: CITYSCAPES ? OXFORD ROBOTCAR. THE BEST ACCURACY IS IN BOLD.</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="8">Road SW Build Wall* Fence* Pole*</cell><cell>TL</cell><cell>TS</cell><cell>Veg. Sky</cell><cell>PR</cell><cell>Rider Car Bus Motor Bike mIoU* mIoU</cell></row><row><cell>Source</cell><cell></cell><cell cols="4">55.6 23.8 74.6</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell cols="3">6.1 12.1 74.8 79.0 55.3 19.1 39.6 23.3</cell><cell>13.7</cell><cell>25.0</cell><cell>38.6</cell><cell>?</cell></row><row><cell>MaxSquare [62]</cell><cell></cell><cell cols="4">77.4 34.0 78.7</cell><cell>5.6</cell><cell>0.2</cell><cell></cell><cell>27.7</cell><cell>5.8</cell><cell>9.8</cell><cell>80.7 83.2 58.5 20.5 74.1 32.1</cell><cell>11.0</cell><cell>29.9</cell><cell>45.8</cell><cell>39.3</cell></row><row><cell>SIBAN [17]</cell><cell></cell><cell cols="4">82.5 24.0 79.4</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell cols="3">16.5 12.7 79.2 82.8 58.3 18.0 79.3 25.3</cell><cell>17.6</cell><cell>25.9</cell><cell>46.3</cell><cell>?</cell></row><row><cell>PatchAlign [16]</cell><cell></cell><cell cols="4">82.4 38.0 78.6</cell><cell>8.7</cell><cell>0.6</cell><cell></cell><cell>26.0</cell><cell cols="3">3.9 11.1 75.5 84.6 53.5 21.6 71.4 32.6</cell><cell>19.3</cell><cell>31.7</cell><cell>46.5</cell><cell>40.0</cell></row><row><cell>AdaptSegNet [15]</cell><cell></cell><cell cols="4">84.3 42.7 77.5</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell>4.7</cell><cell>7.0</cell><cell>77.9 82.5 54.3 21.0 72.3 32.2</cell><cell>18.9</cell><cell>32.3</cell><cell>46.7</cell><cell>?</cell></row><row><cell cols="6">AdaptSegNet [15] + Ours 67.9 30.1 77.9</cell><cell>10.2</cell><cell>1.5</cell><cell></cell><cell>37.2</cell><cell cols="3">30.9 22.3 80.8 83.1 52.4 20.9 72.9 25.4</cell><cell>12.7</cell><cell>45.7</cell><cell>47.9</cell><cell>42.0</cell></row><row><cell>CLAN [18]</cell><cell></cell><cell cols="4">81.3 37.0 80.1</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell cols="3">16.1 13.7 78.2 81.5 53.4 21.2 73.0 32.9</cell><cell>22.6</cell><cell>30.7</cell><cell>47.8</cell><cell>?</cell></row><row><cell>SP-Adv [61]</cell><cell></cell><cell cols="4">84.8 35.8 78.6</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell cols="3">6.2 15.6 80.5 82.0 66.5 22.7 74.3 34.1</cell><cell>19.2</cell><cell>27.3</cell><cell>48.3</cell><cell>?</cell></row><row><cell>ASA [63]</cell><cell></cell><cell cols="4">91.2 48.5 80.4</cell><cell>3.7</cell><cell>0.3</cell><cell></cell><cell>21.7</cell><cell>5.5</cell><cell>5.2</cell><cell>79.5 83.6 56.4 21.0 80.3 36.2</cell><cell>20.0</cell><cell>32.9</cell><cell>49.3</cell><cell>41.7</cell></row><row><cell>DADA [11]</cell><cell></cell><cell cols="4">89.2 44.8 81.4</cell><cell>6.8</cell><cell>0.3</cell><cell></cell><cell>26.2</cell><cell cols="3">8.6 11.1 81.8 84.0 54.7 19.3 79.7 40.7</cell><cell>14.0</cell><cell>38.8</cell><cell>49.8</cell><cell>42.6</cell></row><row><cell>BL [30]</cell><cell></cell><cell cols="4">86.0 46.7 80.3</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell cols="3">14.1 11.6 79.2 81.3 54.1 27.9 73.7 42.2</cell><cell>25.7</cell><cell>45.3</cell><cell>51.4</cell><cell>?</cell></row><row><cell>DT [65]</cell><cell></cell><cell cols="4">83.0 44.0 80.3</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell cols="3">17.1 15.8 80.5 81.8 59.9 33.1 70.2 37.3</cell><cell>28.5</cell><cell>45.8</cell><cell>52.1</cell><cell>?</cell></row><row><cell>CCM [68]</cell><cell></cell><cell cols="4">79.6 36.4 80.6</cell><cell>13.3</cell><cell>0.3</cell><cell></cell><cell>25.5</cell><cell cols="3">22.4 14.9 81.8 77.4 56.8 25.9 80.7 45.3</cell><cell>29.9</cell><cell>52.0</cell><cell>52.9</cell><cell>45.2</cell></row><row><cell>APODA [64]</cell><cell></cell><cell cols="4">86.4 41.3 79.3</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell cols="3">22.6 17.3 80.3 81.6 56.9 21.0 84.1 49.1</cell><cell>24.6</cell><cell>45.7</cell><cell>53.1</cell><cell>?</cell></row><row><cell>AdvEnt [66]</cell><cell></cell><cell cols="4">85.6 42.2 79.7</cell><cell>8.7</cell><cell>0.4</cell><cell></cell><cell>25.9</cell><cell>5.4</cell><cell>8.1</cell><cell>80.4 84.1 57.9 23.8 73.3 36.4</cell><cell>14.2</cell><cell>33.0</cell><cell>48.0</cell><cell>41.2</cell></row><row><cell>Source</cell><cell></cell><cell cols="4">64.3 21.3 73.1</cell><cell>2.4</cell><cell>1.1</cell><cell></cell><cell>31.4</cell><cell cols="3">7.0 27.7 63.1 67.6 42.2 19.9 73.1 15.3</cell><cell>10.5</cell><cell>38.9</cell><cell>40.3</cell><cell>34.9</cell></row><row><cell>CBST [27]</cell><cell></cell><cell cols="4">68.0 29.9 76.3</cell><cell>10.8</cell><cell>1.4</cell><cell></cell><cell>33.9</cell><cell cols="3">22.8 29.5 77.6 78.3 60.6 28.3 81.6 23.5</cell><cell>18.8</cell><cell>39.8</cell><cell>48.9</cell><cell>42.6</cell></row><row><cell>MRKLD [28]</cell><cell></cell><cell cols="4">67.7 32.2 73.9</cell><cell>10.7</cell><cell>1.6</cell><cell></cell><cell>37.4</cell><cell cols="3">22.2 31.2 80.8 80.5 60.8 29.1 82.8 25.0</cell><cell>19.4</cell><cell>45.3</cell><cell>50.1</cell><cell>43.8</cell></row><row><cell>Source</cell><cell></cell><cell cols="4">44.0 19.3 70.9</cell><cell>8.7</cell><cell>0.8</cell><cell></cell><cell>28.2</cell><cell cols="3">16.1 16.7 79.8 81.4 57.8 19.2 46.9 17.2</cell><cell>12.0</cell><cell>43.8</cell><cell>40.4</cell><cell>35.2</cell></row><row><cell>MRNet [19]</cell><cell></cell><cell cols="4">82.0 36.5 80.4</cell><cell>4.2</cell><cell>0.4</cell><cell></cell><cell>33.7</cell><cell cols="3">18.0 13.4 81.1 80.8 61.3 21.7 84.4 32.4</cell><cell>14.8</cell><cell>45.7</cell><cell>50.2</cell><cell>43.2</cell></row><row><cell>MRNet [19] + Ours</cell><cell></cell><cell cols="4">83.6 40.1 81.3</cell><cell>9.6</cell><cell>0.8</cell><cell></cell><cell>36.8</cell><cell cols="3">25.8 16.3 84.5 87.1 60.3 23.9 84.9 32.3</cell><cell>19.0</cell><cell>48.4</cell><cell>52.9</cell><cell>45.9</cell></row><row><cell>Uncertainty [38]</cell><cell></cell><cell cols="4">87.6 41.9 83.1</cell><cell>14.7</cell><cell>1.7</cell><cell></cell><cell>36.2</cell><cell cols="3">31.3 19.9 81.6 80.6 63.0 21.8 86.2 40.7</cell><cell>23.6</cell><cell>53.1</cell><cell>54.9</cell><cell>47.9</cell></row><row><cell cols="2">Uncertainty [38] + Ours</cell><cell cols="4">85.6 43.9 83.9</cell><cell>19.2</cell><cell>1.7</cell><cell></cell><cell>38.0</cell><cell cols="3">37.9 19.6 85.5 88.4 64.1 25.7 86.6 43.9</cell><cell>31.2</cell><cell>51.3</cell><cell>57.5</cell><cell>50.4</cell></row><row><cell>Method</cell><cell>road</cell><cell>sidewalk</cell><cell>building</cell><cell>light</cell><cell>sign</cell><cell>sky</cell><cell>person</cell><cell>automobile</cell><cell>two-wheel</cell><cell>mIoU</cell><cell></cell></row><row><cell>Source</cell><cell cols="9">79.2 49.3 73.1 55.6 37.3 36.1 54.0 81.3 49.7</cell><cell>61.9</cell><cell></cell></row><row><cell>AdaptSegNet [15]</cell><cell cols="9">95.1 64.0 75.7 61.3 35.5 63.9 58.1 84.6 57.0</cell><cell>69.5</cell><cell></cell></row><row><cell cols="10">AdaptSegNet [15] + Ours 96.0 73.0 91.5 65.8 22.9 94.9 56.0 89.0 53.0</cell><cell>71.3</cell><cell></cell></row><row><cell>PatchAlign [16]</cell><cell cols="9">94.4 63.5 82.0 61.3 36.0 76.4 61.0 86.5 58.6</cell><cell>72.0</cell><cell></cell></row><row><cell>MRNet [19]</cell><cell cols="9">95.9 73.5 86.2 69.3 31.9 87.3 57.9 88.8 61.5</cell><cell>72.5</cell><cell></cell></row><row><cell>MRNet [19] + Ours</cell><cell cols="9">96.4 77.0 83.4 70.7 39.2 83.0 62.4 89.9 61.0</cell><cell>73.7</cell><cell></cell></row><row><cell>Uncertainty [38]</cell><cell cols="9">95.9 73.7 87.4 72.8 43.1 88.6 61.7 89.6 57.0</cell><cell>74.4</cell><cell></cell></row><row><cell>Uncertainty [38] + Ours</cell><cell cols="9">96.1 75.3 92.1 72.6 37.0 94.4 62.7 89.7 56.9</cell><cell>75.2</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VI ABLATION</head><label>VI</label><figDesc>STUDY ON THE EFFECTIVENESS OF THE PROPOSED METHOD ON A RELATIVELY VANILLA NETWORK, i.e., VGG16 [69] ON GTA5 ? CITYSCAPES. : WE RE-IMPLEMENT MRNET [19] WITH VGG16.</figDesc><table><row><cell>Method</cell><cell>Backbone</cell><cell>mIoU</cell></row><row><cell>Curriculum DA [70]</cell><cell>VGG16</cell><cell>28.9</cell></row><row><cell>Wang et al. [71]</cell><cell>VGG19</cell><cell>33.1</cell></row><row><cell>CyCADA [12]</cell><cell>VGG16</cell><cell>35.4</cell></row><row><cell>ASA [63]</cell><cell>VGG16</cell><cell>35.6</cell></row><row><cell>CBST-SP [27]</cell><cell>VGG16</cell><cell>36.1</cell></row><row><cell>DCAN [13]</cell><cell>VGG16</cell><cell>36.2</cell></row><row><cell>SP-Adv [61]</cell><cell>VGG16</cell><cell>36.5</cell></row><row><cell>LSD [26]</cell><cell>VGG16</cell><cell>37.1</cell></row><row><cell>MRNet  *  [19]</cell><cell>VGG16</cell><cell>25.5</cell></row><row><cell>MRNet  *  [19] + Ours</cell><cell>VGG16</cell><cell>39.5</cell></row></table><note>*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VII COMPARISON</head><label>VII</label><figDesc>WITH MEAN TEACHER (MT)<ref type="bibr" target="#b42">[43]</ref>.AND  STUDY THE IMPACT OF THE ADAPTIVE SAMPLER AND THE STUDENT AGGREGATION ALONE. THE RESULTS ALSO SUGGEST THAT THE ADAPTIVE SAMPLER DOES NOT IMPROVE THE SINGLE MODEL PERFORMANCE BUT HELPS COMPLEMENTARY MODEL LEARNING, FACILITATING THE FINAL "WEAK" STUDENT MODEL AGGREGATION.</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="2">mIoU</cell></row><row><cell>MRNet [19]</cell><cell></cell><cell cols="2">45.5</cell></row><row><cell cols="2">MRNet [19] + MT (Student)</cell><cell cols="2">46.6</cell></row><row><cell cols="2">MRNet [19] + MT (Teacher)</cell><cell cols="2">47.5</cell></row><row><cell>MRNet [19] + Ours</cell><cell></cell><cell cols="2">49.0</cell></row><row><cell cols="2">TABLE VIII</cell><cell></cell><cell></cell></row><row><cell cols="4">ABLATION STUDY OF ADABOOST STUDENT ON</cell></row><row><cell cols="4">GTA5+SYNTHIA?CITYSCAPES. WE ADOPT MRNET [19] AS</cell></row><row><cell>BASELINE, Method</cell><cell>Adaptive</cell><cell>Student</cell><cell>mIoU</cell></row><row><cell></cell><cell cols="2">Sampler Aggregation</cell><cell></cell></row><row><cell>MRNet [19]</cell><cell></cell><cell></cell><cell>47.6</cell></row><row><cell>w Adaptive Sampler</cell><cell></cell><cell></cell><cell>48.4</cell></row><row><cell>w Student Aggregation</cell><cell></cell><cell></cell><cell>50.6</cell></row><row><cell>MRNet [19] + Ours</cell><cell></cell><cell></cell><cell>50.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE IX COMPARISON</head><label>IX</label><figDesc>WITH MEAN TEACHER (MT) [43] FROM 10 RUNS ON CIFAR-10 USING 4000 LABELS. : WE RE-RUN THE OFFICAL CODE OF MEAN TEACHER WITH A SLIGHT BETTER PERFORMANCE.</figDesc><table><row><cell>Method</cell><cell>top1 error (%)</cell></row><row><cell>Supervised Learning</cell><cell></cell></row></table><note>*</note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>He was a professor with University of Technology Sydney, Australia. Prior to joining UTS, he was a postdoctoral researcher with the School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA. His current research interest includes machine learning and its applications to multimedia content analysis and computer vision, such as multimedia analysis and video semantics understanding.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="834" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ace: adapting to changing environments for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning from synthetic data for crowd counting in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Transferrable prototypical networks for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation through synthesis for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICME</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning semantic segmentation from synthetic data: A geometrically guided input-output adaptation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Crdoco: Pixellevel domain transfer with cross-domain consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dada: Depthaware domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dcan: Dual channel-wise alignment networks for unsupervised scene adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Uzunbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Nam</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Daml: Domain adaptation metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2980" to="2989" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domain adaptation for structured output via discriminative representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Significance-aware information bottleneck for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised scene adaptation with memory regularization in vivo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Experiments with a new boosting algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adversarial style mining for one-shot unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dlow: Domain flow for adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Ssf-dan: Separated semantic feature based domain adaptation network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networkss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Domain randomization and pyramid consistency: Simulationto-real generalization without accessing target domain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning from synthetic data: Addressing domain shift for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Vijaya</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Confidence regularized self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Uncertainty-aware consistency regularization for cross-domain semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="page">103448</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Prototypical pseudo label denoising and target structure learning for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multipseudo regularized label for generated data in person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1391" to="1403" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Feature affinity-based pseudo labeling for semi-supervised person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2891" to="2902" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Adaptive exploration for unsupervised person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1145/3369393</idno>
	</analytic>
	<monogr>
		<title level="j">TOMM</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Complementary pseudo labels for unsupervised domain adaptation on person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2898" to="2907" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unsupervised person reidentification via softened similarity learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multiple knowledge representation for big data artificial intelligence: framework, applications, and case studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1145/FITEE.2100463</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Information Technology &amp; Electronic Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1551" to="1558" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/s11263-020-01395-y</idno>
		<idno>doi:10.1007/ s11263-020-01395-y</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Training deep neural networks on noisy labels with bootstrapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep mutual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>NeurlPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Self-ensembling with gan-based data augmentation for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Domain generalization needs stochastic weight averaging for robustness on domain shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.08604</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Semi-supervised deep learning with memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Training region-based object detectors with online hard example mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">In defense of the triplet loss for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07737</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Dropout as a bayesian approximation: Representing model uncertainty in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Averaging weights leads to wider optima and better generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>UAI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Dual graph convolutional network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Dynamic graph message passing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">1 Year, 1000km: The Oxford RobotCar Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pascoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Linegar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Newman</surname></persName>
		</author>
		<idno type="DOI">10.1177/0278364916679498</idno>
		<ptr target="http://dx.doi.org/10.1177/0278364916679498" />
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research (IJRR)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Semantic-aware short path adversarial training for cross-domain semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Chew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">F</forename><surname>Lu</surname></persName>
		</author>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S0925231219315656" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">380</biblScope>
			<biblScope unit="page" from="125" to="132" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Domain adaptation for semantic segmentation with maximum squares loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Affinity space adaptation for semantic segmentation across domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2549" to="2561" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">An adversarial perturbation oriented domain adaptation approach for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Differential treatment for stuff and things: A simple unsupervised domain adaptation method for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Fully convolutional adaptation networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Content-consistent matching for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Curriculum domain adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Weakly supervised adversarial domain adaptation for semantic segmentation in urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4376" to="4386" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Shake-shake regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gastaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07485</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1979" to="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Improving the improved training of wasserstein gans: A consistency term and its dual effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">ICLR</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
