<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CHEN ET AL: SSR: AN EFFICIENT AND ROBUST FRAMEWORK FOR LULN SSR: An Efficient and Robust Framework for Learning with Unknown Label Noise</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="institution">Queen Mary University of London London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CHEN ET AL: SSR: AN EFFICIENT AND ROBUST FRAMEWORK FOR LULN SSR: An Efficient and Robust Framework for Learning with Unknown Label Noise</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T12:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite the large progress in supervised learning with neural networks, there are significant challenges in obtaining high-quality, large-scale and accurately labelled datasets. In such a context, how to learn in the presence of noisy labels has received more and more attention. As a relatively complex problem, in order to achieve good results, current approaches often integrate components from several fields, such as supervised learning, semi-supervised learning, transfer learning and resulting in complicated methods. Furthermore, they often make multiple assumptions about the type of noise of the data. This affects the model robustness and limits its performance under different noise conditions. In this paper, we consider a novel problem setting, Learning with Unknown Label Noise (LULN), that is, learning when both the degree and the type of noise are unknown. Under this setting, unlike previous methods that often introduce multiple assumptions and lead to complex solutions, we propose a simple, efficient and robust framework named Sample Selection and Relabelling (SSR), that with a minimal number of hyperparameters achieves SOTA results in various conditions. At the heart of our method is a sample selection and relabelling mechanism based on a non-parametric KNN classifier (NPK) g q and a parametric model classifier (PMC) g p , respectively, to select the clean samples and gradually relabel the noisy samples. Without bells and whistles, such as model co-training, self-supervised pre-training and semi-supervised learning, and with robustness concerning the settings of its few hyper-parameters, our method significantly surpasses previous methods on both CIFAR10/CIFAR100 with synthetic noise and real-world noisy datasets such as WebVision, Clothing1M and ANIMAL-10N. Code is available at https://github.com/MrChenFeng/SSR_BMVC2022.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>It is now commonly accepted that supervised learning with deep neural networks can provide excellent solutions for a wide range of problems, so long as there is sufficient availability of labelled training data and computational resources. However, these results have been mostly obtained using well-curated datasets in which the labels are of high quality. In the real world, it is often costly to obtain high-quality labels, especially for large-scale datasets. A common approach is to use semi-automatic methods to obtain the labels (e.g. "webly-labelled" images where the images and labels are obtained by web-crawling). While such methods can greatly reduce the time and cost of manual labelling, they also lead to low-quality noisy labels.</p><p>In such settings, noise is one of the following two types: closed-set noise where the true labels belong to one of the given classes (Set B in <ref type="figure" target="#fig_0">fig. 1</ref>) and open-set noise where the true labels do not belong to the set of labels of the classification problem (Set C in <ref type="figure" target="#fig_0">fig. 1</ref>). To deal with different types of noise, two main types of methods have been proposed, which we name here as probability-consistent methods and probability-approximate methods. Probability-consistent methods usually model noise patterns directly and propose corresponding probabilistic adjustment techniques, e.g., robust loss functions <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">33,</ref><ref type="bibr" target="#b30">44]</ref> and noise corrections based on noise transition matrix <ref type="bibr" target="#b10">[11]</ref>. However, accurate modelling of noise patterns is non-trivial, and often cannot even model open-set noise. Also, due to the necessary simplifications of probabilistic modelling, such methods often perform poorly with heavy and complex noise. More recently, probabilityapproximate methods, that is methods that do not model the noise patterns explicitly become perhaps the dominant paradigm, especially ones that are based on sample selection. Earlier methods often reduce the influence of noise samples by selecting a clean subset and training only with it <ref type="bibr" target="#b11">[12,</ref><ref type="bibr">16,</ref><ref type="bibr">22,</ref><ref type="bibr" target="#b27">41]</ref>. Recent methods tend to further employ semi-supervised learning methods, such as MixMatch <ref type="bibr" target="#b3">[4]</ref>, to fully explore the entire dataset by treating the selected clean subset as labelled samples and the non-selected subset as unlabeled samples <ref type="bibr">[18,</ref><ref type="bibr">24]</ref>. These methods, generally, do not consider the presence of open-set noise in the dataset, since most current semi-supervised learning methods can not deal with open-set noise appropriately. To address this, several methods <ref type="bibr">[27,</ref><ref type="bibr" target="#b21">35]</ref> extend the sample selection idea by further identifying the open-set noise and excluding it from the semi-supervised training.</p><p>In general, the above methods make assumptions about the pattern of the noise, such as the confidence penalty specifically for asymmetric noise in DivideMix <ref type="bibr">[18]</ref>. However, these mechanisms are often detrimental when the noise pattern does not meet the assumptionsfor example, explicitly filtering open-set noise in the absence of open-set noise may result in clean hard samples being removed. Furthermore, due to the complexity of combining multiple modules, the above methods usually need to adjust complex hyperparameters according to the type and degree of noise.</p><p>In this paper, we consider a novel problem setting -Learning with Unknown Label Noise (LULN), that is, learning when both the degree and the type of noise are unknown. Striving for simplicity and robustness, we propose a simple method for LUNL, namely Sample Selection and Relabelling (SSR) (section 3.2), with two components that are clearly decoupled: a selection mechanism that identifies clean samples with correct labels, and a relabelling mechanism that aims to recover correct labels of wrongly labelled noisy samples. These two major components are based on the two simple and necessary assumptions for LULN, namely, that samples with highly-consistent annotations with their neighbours are often clean, and that very confident model predictions are often trustworthy. Once a welllabelled subset is constructed this way we use the most basic supervised training scheme with a cross-entropy loss. Optionally, a feature consistency loss can be used for all data so as to deal better with open-set noise.</p><p>Without bells and whistles, such as semi-supervised learning, self-supervised model pretraining and model co-training, our method is shown to be robust to the values of its very few hyperparameters through extensive experiments and ablation studies and to consistently outperform the state-of-the-art by a large margin in various datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>This paper mainly focuses on the probability-approximate methods, especially methods based on sample selection. For a detailed introduction to probability-consistent methods described above, please refer to the review papers <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b17">31]</ref>. We note that we do not consider utilizing an extra clean validation dataset, such as meta-learning-based methods <ref type="bibr">[26,</ref><ref type="bibr" target="#b24">38]</ref> do.</p><p>Clean sample selection Most sample selection methods fall into two main categories:</p><p>? Prediction-based methods. Most of the recent sample selection methods do so, by relying on the predictions of the model classifier, for example on the per-sample loss <ref type="bibr" target="#b1">[2,</ref><ref type="bibr">18]</ref> or model prediction <ref type="bibr">[22,</ref><ref type="bibr" target="#b16">30]</ref>. However, the prediction-based selection is often unstable and easily leads to confirmation bias, especially in heavy noise scenarios. A few works focus on improving the sample selection quality of these methods <ref type="bibr" target="#b22">[36,</ref><ref type="bibr" target="#b32">46]</ref>. To identify open-set noise, several methods utilize the Shannon entropy of the model predictions of different samples <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">27]</ref>. Open-set noise samples that do not belong to any class should have a relatively average model prediction (larger entropy value).</p><p>? Feature-based methods. Instead of selecting samples based on the model prediction, some works try to utilize the feature representations for sample selection. Wu et al. <ref type="bibr" target="#b20">[34,</ref><ref type="bibr" target="#b21">35]</ref> try to build a KNN graph and identify clean samples through connected subgraphs. Bahri et al. <ref type="bibr" target="#b2">[3]</ref> selects clean samples with a KNN classifier in the prediction logit space, while Ortego et al. <ref type="bibr">[24]</ref> proposes an iterative KNN to alleviate the effect of noisy labels.</p><p>Our work falls in the second category. However, unlike existing methods that use complex variants of neighbouring algorithms, in our pursuit of simplicity and robustness, we use the simplest KNN classification and show that this is sufficient.</p><p>Fully exploiting the whole dataset To fully utilise the whole dataset during training and more specifically the non-selected subset, recent methods usually apply semi-supervised training methods (e.g., MixMatch <ref type="bibr" target="#b3">[4]</ref>), by considering the selected subset as labelled and the non-selected subset as unlabeled <ref type="bibr">[18]</ref>. However, most current semi-supervised learning methods can not deal with open-set samples properly. How to properly do semi-supervised learning in this setting is often referred to as open-set semi-supervised learning <ref type="bibr">[28,</ref><ref type="bibr" target="#b26">40]</ref>. In this paper, instead of adopting complex semi-supervised learning schemes, we adopt a simple relabeling and selection scheme in order to construct a clean and well-labelled subset and then train with a simple cross-entropy loss on the clean, well-labelled set and optionally, with a feature consistency loss on the whole dataset that possibly contains open-set noise and samples that cannot be well relabelled.  We view the classification network as an encoder f that extracts a feature representation and a parametric model classifier (PMC) g p that deals with the classification problem in question. We also define a non-parametric KNN classifier (NPK) g q based on the feature representations from encoder f . For brevity, we define f f f i f (x x x i ) as the feature representation of sample x x x i , and p p p i g p ( f f f i ) and q q q i g q ( f f f i ) as the prediction vectors from PMC g p and NPK g q , respectively. Following recent works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr">18,</ref><ref type="bibr">24,</ref><ref type="bibr" target="#b21">35,</ref><ref type="bibr" target="#b27">41]</ref>, we adopt an iterative scheme for our method consisting of two stages: 1. sample selection (line 3) and relabelling (line 2), and 2. model training (line 4) in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem formulation</head><formula xml:id="formula_0">Let us denote with X = {x x x i } N i=1 , x x x i ? R d ,</formula><formula xml:id="formula_1">Algorithm 1: SSR. Input: dataset (X , Y), sample selection threshold ? s , sample relabelling threshold ? r , weight of feature consistency loss ? , max epochs T 1 while i &lt; T do 2 Generate (X , Y r ) with eq. (3) ; / * sample relabelling * / 3</formula><p>Generate (X c , Y r c ) with eq. (1) and eq. (2) ; / * sample selection * / <ref type="bibr" target="#b3">4</ref> Model training with eq. (5) ; / * model training * / 5 end</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sample selection and relabelling</head><p>For a better exposition, we first introduce our sample selection mechanism. Please note, that we actually relabel the samples before each sample selection.</p><p>Clean sample selection by balanced neighbouring voting Our sample selection is based on the consistency, as quantified by a measure c i , between the label y y y r i 1 of sample x x x i and an (adjusted) distribution, q q q i , of the labels in its neighbourhood in the feature space. More specifically, let us denote the similarity between the representations f f f i and f f f j of any two samples x x x i and x x x j by s s s i j , i, j = 1, ..., N. By default, we used the cosine similarity, that is,</p><formula xml:id="formula_2">s s s i j f f f T i f f f j f f f i 2 f f f j 2</formula><p>. Let us also denote by N i the index set of the K nearest neighbours of sample x x x i in X based on the calculated similarity. Then, for each sample x x x i , we can calculate the normalised label distribution q q q i = 1 K ? n?N i y y y r n in its neighbourhood, and a balanced version, q q q i ? R M , of it that takes into consideration/compensates for the distribution ? ? ? = ? N i=1 y y y r i of the labels in the dataset. More specifically,</p><formula xml:id="formula_3">q q q i = ? ? ? ?1 q q q i ,<label>(1)</label></formula><p>where we denote with ? ? ? ?1 the vector whose entries are the inverses of the entries of the vector ? ? ? -in this way we alleviate the negative impact of possible class imbalances in sample selection. The vector q q q i can be considered as the (soft) prediction of the NPK g q classifier. We then, define a consistency measure c i between the sample's label l r i = arg max j y y y r i ( j) (section 3.1) and the prediction q q q i of the NPK as</p><formula xml:id="formula_4">c i = q q q i (l r i ) max j q q q i ( j) ,<label>(2)</label></formula><p>that is the ratio of the value of the distribution q q q i at the label l r i (eq. (3)) divided by the value of its highest peak max j q q q i ( j). Roughly speaking, a high consistency measure c i at a sample x x x i means that its neighbours agree with its current label l r i -this indicates that l r i is likely to be correct. By setting a threshold ? s to c i , a clean subset (X c , Y r c ) can be extracted. In our method, we set ? s = 1 by default, that is, we consider a sample x x x i to be clean only when its neighbours' voting q q q i is consistent with its current label y y y r i .</p><p>Noisy sample relabelling by classifier thresholding Our sample relabelling scheme aims at adding well-labelled samples to the training pool and is based on the PMC classifier g p . Specifically, we "relabel" all samples for which the classifier is confident, that is all samples i for which the prediction p p p i of the classifier PMC g p exceeds a threshold ? r . Formally,</p><formula xml:id="formula_5">l r i = ? ? ? arg max l p p p i (l), max l p p p i (l) &gt; ? r l i , max l p p p i (l) ? ? r<label>(3)</label></formula><p>Please note, that similarly to section 3.1, we denote the one-hot label corresponding to l t i as y y y t i -this will be used in eq. (1). By setting a high ? r , a highly confident sample x x x i will be relabelled -this can in turn further enhance the quality of sample selection. Note, that this scheme typically avoids mis-relabelling open-set noise samples as those tend not to have highly confident predictions. In this way, our method can deal with open-set noise datasets effectively even though we do not explicitly propose a mechanism for them.</p><p>On choices of sample selection and relabelling In this work, we utilize two different classifiers for the two stages of our scheme: for sample selection the NPK g q based on nearest neighbours in the feature space ((eq. (1) and eq. (2)) and for sample relabelling the PMC g p classifier (eq. <ref type="formula" target="#formula_5">(3)</ref>). Here, we justify/comment on this choice.</p><p>Why not PMC g p for sample selection?</p><p>Most previous works rely on the PMC g p itself to select clean samples, i.e., typically, samples with small losses. However, it is well known that such methods are not robust to complex and heavy noise. Also, these methods often require a warmup stage before sample selection -this requires prior knowledge about the difficulty and the noise ratio of the dataset. For example, a warmup stage of 50 epochs under heavy noise on the CIFAR10 dataset may result in overfitting before sample selection, while a warmup stage of 5 epochs on the mildly noisy CIFAR100 dataset may not be enough. In this paper, we rely on the smoothness of feature representations and use the NPK g q for sample selection -even a randomly initialized encoder can provide quite meaningful neighbouring relations therefore enabling us to train the model from scratch and also improves the sample selection stability and performance in heavy and complex noisy scenarios. For a more detailed discussion, please refer to Supplementary C.</p><p>Why not NPK g q for sample relabelling?</p><p>Due to the existence of noisy labels, we found that it is very difficult to make a proper choice of ? r and rely on the NPK g q for sample relabeling, especially in the early iterations. By contrast, in our scheme, PMC g p is always trained with a relatively clean subset and can perform sample relabeling more accurately. Furthermore, relabeling samples on which the classifier is confident leads to smaller gradients and smoother learning from easier samples first -even when the newly assigned labels are wrong, the influence is smaller.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Model training</head><p>In the training stage, we use the most basic form of supervised learning, i.e., using the crossentropy loss on the clean subset selected in the first stage -this updates both the encoder f and the PMC g p . With our sample relabelling mechanism, the size of the clean subset grows progressively by including more and more relabeled closed-set noise in training. Optionally, we use a feature consistency loss that enforces consistency between the feature representations of different augmentations of the same sample -this updates the encoder f and helps to learn a strong feature space on which the selection mechanism of the first stage can rely.</p><p>Supervised training using the clean subset For each sample (x x x, y y y r ) in the selected subset (X c , Y r c ), we train the encoder f and PMC g p with common cross-entropy loss, that is, L ce = ?y y y rT log g p ( f (x x x)). Moreover, to deal with the possible class imbalance in the selected subset, we simply over-sample minority classes. In the ablations study, we report the effect of balancing -the over-sampling and also the balanced sample selection in eq. (1).</p><p>Optional: feature consistency regularization using all samples Although our relabeling method can progressively relabel and introduce closed-set noise samples into training, open-set samples can also improve generalization. Motivated by commonly used prediction consistency regularization methods, we propose a feature consistency loss L f c <ref type="bibr" target="#b4">[5]</ref>. Specifically, with a projector h pro j and predictor h pred , we minimize the cosine distance 2 between two different augmented views (x x x 1 and x x x 2 ) of the same sample x x x. That is,</p><formula xml:id="formula_6">L f c = ? h h h 1 h h h 2 h h h 1 2 h h h 2 2 ,<label>(4)</label></formula><p>where h h h 1 h pred (h pro j ( f (x x x 1 ))) and h h h 2 h pro j ( f (x x x 2 )).In summary, the overall training objective is to minimize a weighted sum of L ce and L f c , that is</p><formula xml:id="formula_7">L = L ce + ? L f c .<label>(5)</label></formula><p>We set ? = 1. For brevity, we name our method as SSR when ? = 0, and SSR+ when ? = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview</head><p>In this section, we conduct extensive experiments on two standard benchmarks with synthetic label noise, CIFAR-10 and CIFAR-100, and three real-world datasets, Clothing1M <ref type="bibr" target="#b23">[37]</ref>, We-bVision [20], and ANIMAL-10N <ref type="bibr" target="#b16">[30]</ref>. For brevity, we define abbreviated names for the corresponding noise settings, such as "sym50" for 50% symmetric noise, "asym40" for 40% asymmetric noise and "all30_open50" for 30% total noise with 50% open-set noise. (more dataset and implementation details can be found in <ref type="figure">Supplementary A and B)</ref>. In section 4.2, we conduct extensive ablation experiments to show the great performance and robustness of our sample selection and relabelling mechanism w.r.t its hyperparameters with different noise types, noise ratios and dataset. In section 4.3 and section 4.4, we compare our method with the state-of-the-art in synthetic noisy datasets and real-world noisy datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablations study</head><p>Quality of sample selection and relabelling In <ref type="figure" target="#fig_3">fig. 3</ref>, we investigate the quality of sample selection and relabeling under different noise types and ratios on the CIFAR10 noisy dataset. We set ? r = 0.9 for 40asym, 20sym, all30_open50 and all30_open100 noise, while ? r = 0.8 for sym50 and sym90 noise -please refer to Supplementary A for more details on noise. We set ? s = 1 in all experiments. To summarise, we found that the number of the relabeled samples is highly related to the value of ? r across different noise ratios ( <ref type="figure" target="#fig_3">fig. 3(a)</ref>) for closed-set noise only dataset, for e.g, a lower ? r leads to more relabeled samples across different noise settings (40asym, 20sym, 50sym and 90sym). For datasets containing also open-set noise (all30_open50 and all30_open100), our relabeling mechanism is more conservative (nearly no relabelling), thus alleviating the negative impact of open-set noise. In <ref type="figure" target="#fig_3">fig. 3(b)</ref>, we show that we obtain very high relabelling accuracy with different noise and relabelling volumes, e.g., only 19% samples have correct labels originally for 90% symmetric noise while &gt;95% samples are correctly relabelled. In <ref type="figure" target="#fig_3">fig. 3(c)</ref>, we report the F-score of our sample selection. Please note that our sample selection is more challenging compared to previous sample selection methods. While previous methods usually focus on identifying clean subsets and noisy subsets based on the original labels, our method involves the relabeling of samples, which takes the risk of introducing more errors while increasing the number of clean subsets. Even so, we see that the F-score of our sample selection works well (&gt; 0.95 in most cases).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Robustness to hyper-parameters</head><p>In this section, we conduct extensive ablation studies to show the robustness of the values of the few hyperparameters with different noise types, noise ratios, and datasets. The choice of ? r controls the sample relabelling quality and proportion. Roughly speaking, the lower the ? r , the more samples will be relabelled. Similarly, the choice of ? s controls the sample selection quality and proportion -the lower the ? s , the more samples will be selected for the training stage. We set ? s = 1 for ? r ablations and ? r = 0.9 for ? s ablations. We also investigate the effects of K -the size of neighborhood of NPK g q during the sample selection stage, with ? s = 1 and ? r = 0.9. In <ref type="figure" target="#fig_4">fig. 4(a)</ref> we report results with ? s = [0, 0.8, 1.0]. Removing sample selection (? s = 0) leads to severe degradation especially for a high noise ratio (90% symmetric noise), while a relatively high ? s gives consistently high performance. In <ref type="figure" target="#fig_4">fig. 4(b)</ref>, we report the performance with different ? r on the synthetic CIFAR10 noisy dataset. Our method achieves consistently superior performance than the state-of-the-art with different ? r . In <ref type="figure" target="#fig_4">fig. 4</ref>(c), we report results with different K for the CIFAR10 dataset with 40% asymmetric noise since it is more challenging and realistic. Except for extremely small K, our method is stable and consistently better than the state-of-the-art.</p><p>Effect of balancing strategies To alleviate the possible class imbalance in the dataset, we proposed two balancing strategies, one in the sample selection [eq. (1)] and one in the model training stage [Over-sampling minority class], respectively. In table 1 we investigate the effect of using data balancing or not, on CIFAR10 with 40% asymmetric noise and also on a well-known real-world imbalanced noisy dataset, Clothing1M. It can be seen that the effect is small but positive. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation with synthetic noisy datasets</head><p>In this section, we compare our method to the most recent state-of-the-art methods and we show that it achieves consistent improvements in all datasets and at all noise types and ratios.  Evaluation with controlled closed-set noise In this section, we compare SSR/SSR+ to the most competitive recent works. <ref type="table" target="#tab_2">Table 2</ref> shows results on CIFAR10 and CIFAR100we note again for SSR/SSR+ this is without the use of model cotraining or pre-training. It is clear that our method far outperforms them (e.g. 66.6% accuracy on CIFAR100 with 90% symmetric noise), not only in the case of symmetric noise but also in the more realistic asymmetric synthetic noise settings.</p><p>Evaluation with combined open-set noise and closed-set noise     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation with real-world noisy datasets</head><p>Finally, in <ref type="table" target="#tab_4">table 3, table 5 and table 6</ref> we show results on the Clothing1M, WebVision and ANIMAL-10N datasets, respectively. To summarize, our method achieves better or competitive performance in relation to the current state-of-the-art in both large-scale web-crawled datasets and small-scale human-annotated noisy datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper we propose an efficient Sample Selection and Relabelling (SSR) framework for Learning with Unknown Label Noise (LULN). Unlike previous methods that try to integrate many different mechanisms and regularizations, we strive for a concise, simple and robust method. The proposed method does not utilize complicated mechanisms such as semisupervised learning, model co-training and model pre-training, and is shown with extensive experiments and ablation studies to be robust to the values of its few hyper-parameters, and to consistently and by large surpass the state-of-the-art in various datasets.</p><p>[ settings in all CIFAR experiments except in the corresponding ablation part. We train all modules with the same SGD optimizer for 300 epochs with a momentum of 0.9 and a weight decay of 5e-4. The initial learning rate is 0.02 and is controlled by a cosine annealing scheduler. The batchsize is fixed as 128. For WebVision, we use InceptionResNetv2 following <ref type="bibr">[18]</ref>. We train the network with SGD optimizer for 150 epochs with a momentum of 0.9 and a weight decay of 1e-4. The initial learning rate is 0.01 and reduced by a factor of 10 after 50 and 100 epochs. The batchsize is fixed as 32. For Clothing1M, we use ResNet50 following [18] with ImageNet pretrained weights. We train the network with SGD optimizer for 150 epochs with a momentum of 0.9 and weight decay of 1e-3. The initial learning rate is 0.002 and reduced by a factor of 10 after 50 and 100 epochs. The batchsize is fixed as 32. For ANIMAL-10N, we use VGG-19 <ref type="bibr" target="#b15">[29]</ref> with batch-normalization following <ref type="bibr" target="#b16">[30]</ref>. We train the network with SGD optimizer for 150 epochs with a momentum of 0.9 and weight decay of 5e-4. The initial learning rate is 0.02 and reduced by a factor of 10 after 50 and 100 epochs. The batchsize is fixed as 128. For all real-world noisy datasets, we train the model from scratch with ? s = 1, while ? r is fixed as 0.95.</p><p>Following recent works, in this work, we define three augmentation strategies: original image which we denote with 'none' augmentation for testing, random cropping+horizontal flipping which we denote as 'weak' augmentation, and 'strong' augmentation the one that further combines the augmentation policy from <ref type="bibr" target="#b7">[8]</ref>. For L ce we use 'strong' augmentation with mixup interpolations <ref type="bibr" target="#b28">[42]</ref> while for L f c , we use 'weak' augmentation for x x x 2 and 'strong' augmentation for x x x 1 in eq.(4). For mixup interpolation, following DivideMix [18], we set ?, ? as 4 for beta mixture for the CIFAR10/CIFAR100 datasets, and as 0.5 for the real-world noisy dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary C: Evaluation on different choices for sample selection</head><p>In this section, we extensively compare the performance of different sample selection mechanisms under different noise ratios and modes. More specifically, with the PMC g p and NPK g q , we compare the performance of these two classifiers in two different selection modes. Pre-defined mode means the number of noisy samples is known. That is, given a symmetric noisy dataset with noise ratio as ?, we select the top 1 ? ? percent of the samples as clean according to its loss value or prediction confidence. Automatic mode means that there is no information about the ratio of noise. In this case, we utilize the consistency measure c using NPK in our method and the GMM-based loss modelling for PMC. Note that here we only considered two simple modes for sample selection and one variant in each mode respectively. There are many different variants proposed, however, we just aim to show the robustness of NPK over PMC here. For a fair and clear comparison, we also show results of training with the whole dataset and clean subset as the bottom baseline and top baseline, respectively. Note, that in order to compare only the effect of the sample selection part, we exclude sample relabeling, strong data augmentation and optional feature consistency loss here.</p><p>In table 7, we can see that the NPK-based selection achieved better performance compared to PMC-based selection regardless of the mode, and that our choice can significantly improve the baseline (Whole dataset) without knowing the noise ratio.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary D: Distance metric for feature consistency loss</head><p>In Section 3.3, we use the cosine distance as the distance metric for feature consistency loss.</p><p>Here we also experiment with the use of the L2 distance. The results are shown in table 8, where it can be seen that there are small differences, but that the cosine similarity is in general better.   <ref type="table">Table 9</ref>: Computational cost analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Different "tigers".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>A toy example of SSR (section 3.2) with a noisy animal dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>a training set with the corresponding one-hot vector labels Y = {y y y i } N i=1 , y y y i ? {0, 1} M , where M is the number of classes and N is the number of samples. For convenience, let us also denote the label of each sample x x x i corresponding to the one-hot label vector y y y i as l i = arg j [y i ( j) = 1] ? {1, ..., M}. Finally, let us denote the true labels with Y = {y y y i } N i=1 . Clearly, for an open-set noisy label it is the case that y y y i = y y y i , y y y i / ? {0, 1} M , while for closed-set noisy samples y y y i = y y y i , y y y i ? {0, 1} M .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Effect of our sample selection and relabelling method with various noise settings. (a) The proportion of relabeled samples; (c) The corrected clean samples ratio within the relabeled part; (c)F-score of sample selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Classification accuracy with different hyper-parameters on CIFAR10 datasets. (a)? s = [0, 0.8, 1.0]; (b)? r = [0.7, 0.8, 0.9, 1]; (c) K = [1, 10, 50, 100, 150, 200, 250, 300].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Evaluation on CIFAR-10 and CIFAR-100 with closed-set noise. Methods marked with an asterisk employ semi-supervised learning, model co-training or model pre-training.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>CE</cell><cell cols="8">F-correction [25] ELR [21] RRL [19] C2D* [45] DivideMix* [18] ELR+* [21] AugDesc* [23] SSR+(ours)</cell></row><row><cell>69.21</cell><cell>69.84</cell><cell>72.87</cell><cell>74.30</cell><cell>74.84</cell><cell>74.76</cell><cell>74.81</cell><cell>75.11</cell><cell>74.83</cell></row></table><note>shows the per- formance of our method in a more complex combined noise scenario. Previous methods that are specially designed for open-set noise degrade rapidly when the open-set noise ratio is decreased from 1 to 0.5 [17, 32]. Also, the performance of the method without consider- ing open-set noise like DivideMix [18] decreases when the open-set noise ratio is increased. EDM [27] modifies the method of DivideMix to deal with combined noise, however, reports results that are considerably lower than ours.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Testing accuracy (%) on Clothing1M (methods with * utilized model cotraining).</figDesc><table><row><cell>Method</cell><cell>Noise ratio</cell><cell>0.3</cell><cell></cell><cell>0.6</cell></row><row><cell></cell><cell>Open ratio</cell><cell>0.5</cell><cell>1</cell><cell>0.5</cell><cell>1</cell></row><row><cell>ILON [32]</cell><cell>Best Last</cell><cell cols="4">87.4 90.4 80.5 83.4 80.0 87.4 55.2 78.0</cell></row><row><cell>RoG [17]</cell><cell>Best Last</cell><cell cols="4">89.8 91.4 84.1 88.2 85.9 89.8 66.3 82.1</cell></row><row><cell>DivideMix [18]</cell><cell>Best Last</cell><cell cols="4">91.5 89.3 91.8 89.0 90.9 88.7 91.5 88.7</cell></row><row><cell>EDM [27]</cell><cell>Best Last</cell><cell cols="4">94.5 92.9 93.4 90.6 94.0 91.9 92.8 89.4</cell></row><row><cell>SSR(ours)</cell><cell>Best Last</cell><cell cols="4">96.0 95.7 93.8 93.1 95.9 95.6 93.7 93.1</cell></row><row><cell>SSR+(ours)</cell><cell>Best Last</cell><cell cols="4">96.3 96.1 95.2 94.0 96.2 96.0 95.2 93.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Evaluation on CIFAR10 with combined noise.</figDesc><table><row><cell>Methods</cell><cell cols="2">WebVision</cell><cell cols="2">ILSVRC2012</cell></row><row><cell></cell><cell cols="3">Top1 Top5 Top1</cell><cell>Top5</cell></row><row><cell cols="5">Co-teaching [12] 63.58 85.20 61.48 84.70</cell></row><row><cell>DivideMix [18]</cell><cell cols="4">77.32 91.64 75.20 90.84</cell></row><row><cell>ELR+ [21]</cell><cell cols="4">77.78 91.68 70.29 89.76</cell></row><row><cell>NGC [35]</cell><cell cols="4">79.16 91.84 74.44 91.04</cell></row><row><cell>LongReMix [7]</cell><cell cols="2">78.92 92.32</cell><cell>-</cell><cell>-</cell></row><row><cell>RRL [19]</cell><cell>76.3</cell><cell>91.5</cell><cell>73.3</cell><cell>91.2</cell></row><row><cell>SSR+(ours)</cell><cell cols="4">80.92 92.80 75.76 91.76</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Testing accuracy (%) on Webvision.</figDesc><table><row><cell>Cross-Entropy</cell><cell>SELFIE [30]</cell><cell>PLC [43]</cell><cell>NCT [6]</cell><cell>SSR+(ours)</cell></row><row><cell>79.4</cell><cell>81.8</cell><cell cols="2">83.4 84.1</cell><cell>88.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table /><note>Testing accuracy on ANIMAL-10N.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>16] Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In International Conference on Machine Learning, pages 2304-2313. PMLR, 2018. [17] Kimin Lee, Sukmin Yun, Kibok Lee, Honglak Lee, Bo Li, and Jinwoo Shin. Robust inference via generative classifiers for handling noisy labels. In International Conference on Machine Learning, pages 3763-3772. PMLR, 2019.</figDesc><table><row><cell>[18] Junnan Li, Richard Socher, and Steven CH Hoi. Dividemix: Learning with noisy labels</cell></row><row><cell>as semi-supervised learning. arXiv preprint arXiv:2002.07394, 2020.</cell></row><row><cell>[19] Junnan Li, Caiming Xiong, and Steven Hoi. Learning from noisy data with robust</cell></row><row><cell>representation learning. 2020.</cell></row><row><cell>[20] Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. Webvi-</cell></row><row><cell>sion database: Visual learning and understanding from web data. arXiv preprint</cell></row><row><cell>arXiv:1708.02862, 2017.</cell></row><row><cell>[21] Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda.</cell></row><row><cell>Early-learning regularization prevents memorization of noisy labels. arXiv preprint</cell></row><row><cell>arXiv:2007.00151, 2020.</cell></row><row><cell>[22] Eran Malach and Shai Shalev-Shwartz. Decoupling" when to update" from" how to</cell></row><row><cell>update". arXiv preprint arXiv:1706.02613, 2017.</cell></row><row><cell>[23] Kento Nishi, Yi Ding, Alex Rich, and Tobias Hollerer. Augmentation strategies for</cell></row><row><cell>learning with noisy labels. In Proceedings of the IEEE/CVF Conference on Computer</cell></row><row><cell>Vision and Pattern Recognition, pages 8022-8031, 2021.</cell></row><row><cell>[24] Diego Ortego, Eric Arazo, Paul Albert, Noel E O'Connor, and Kevin McGuinness.</cell></row><row><cell>Multi-objective interpolation training for robustness to label noise. In Proceedings of</cell></row><row><cell>the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6606-</cell></row><row><cell>6615, 2021.</cell></row><row><cell>[25] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen</cell></row><row><cell>Qu. Making deep neural networks robust to label noise: A loss correction approach.</cell></row><row><cell>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,</cell></row><row><cell>pages 1944-1952, 2017.</cell></row><row><cell>[26] Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight</cell></row><row><cell>examples for robust deep learning. In International conference on machine learning,</cell></row><row><cell>pages 4334-4343. PMLR, 2018.</cell></row><row><cell>[27] Ragav Sachdeva, Filipe R Cordeiro, Vasileios Belagiannis, Ian Reid, and Gustavo</cell></row><row><cell>Carneiro.</cell></row></table><note>Evidentialmix: Learning with combined open-set and closed-set noisy la- bels. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3607-3615, 2021.[28] Kuniaki Saito, Donghyun Kim, and Kate Saenko. Openmatch: Open-set con- sistency regularization for semi-supervised learning with outliers. arXiv preprint arXiv:2105.14148, 2021.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Results with different sample selection mechanisms.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>SSR+ with different distance metric for feature consistency lossSupplementary E: Computational cost analysisIn table 9, we report the running time of each step of our model on the datasets that we have experimented with. It can be seen that the time of sample selection and relabelling is almost negligible compared to the time of gradient propagation.</figDesc><table><row><cell>Dataset(Size)</cell><cell>Model training</cell><cell></cell><cell>Sample selection and relabelling</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Feature extraction sample selection sample relabelling</cell></row><row><cell>CIFAR(50K)</cell><cell>112s</cell><cell>9s</cell><cell>1.23s</cell><cell>? 0s</cell></row><row><cell>WebVision( 65K)</cell><cell>587s</cell><cell>109s</cell><cell>1.48s</cell><cell>? 0s</cell></row><row><cell>Clothing1M(32K)</cell><cell>575s</cell><cell>57s</cell><cell>0.79s</cell><cell>? 0s</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">? 2022. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Please note, we use the labels Y r (eq. (3)) that a relabelling mechanism provides as mentioned above.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In Supplementary D we investigate the use of the L2 distance.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments: This work was supported by the EU H2020 AI4Media No. 951911 project.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary A: Dataset details</head><p>Synthetic noisy dataset CIFAR10 and CIFAR100 both consist of 50K images. Following the standard practice, for CIFAR10 and CIFAR100, we evaluate our method with two types of artificial noise: symmetric noise by randomly replacing labels of all samples using a uniform distribution; and asymmetric noise by randomly exchanging labels of visually similar categories, such as Horse ? Deer and Dog ? Cat. For closed-set noise only dataset, we test with 20%, 50%, 80% and 90% symmetric noise and 40% asymmetric noise following DivideMix Real-world noisy dataset WebVision [20] is a large-scale dataset of 1000 classes of images crawled from the Web. Following previous work [16, 18, 24], we compare baseline methods on the top 50 classes from Google images Subset of WebVision. The noise ratio is estimated to be around 20%. ANIMAL-10N <ref type="bibr" target="#b16">[30]</ref> is a smaller and recently proposed realworld dataset consisting of 10 classes of animals, that are manually labelled with an error rate that is estimated to be approximately 8%. ANIMAL-10N has similar size characteristics to the CIFAR datasets, with 50000 train images and 10000 test images. Clothing1M <ref type="bibr" target="#b23">[37]</ref> is a large-scale dataset of 14 classes of clothing images crawled from online shopping websites, consisting of 1 million noisy images. The noise ratio is estimated to be around 38.5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary B: Implementation details</head><p>We use a PresActResNet-18 <ref type="bibr" target="#b13">[14]</ref> as the backbone for all CIFAR10/100 experiments following previous works. Unlike previous methods that use specific warmup settings for CI-FAR10/CIFAR100, we train the model from scratch with ? s = 1.0 in all experiments. We set ? r = 0.8 for higher noise ratio -sym50, sym80 and sym90 noise, ? r = 0.9 for remain</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Addressing out-of-distribution label noise in webly-labelled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E O&amp;apos;</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="392" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="312" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep k-nn for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dara</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="540" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02249</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploring simple siamese representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15750" to="15758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Boosting co-teaching with compression regularization for label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shell</forename><forename type="middle">Xu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan Ak</forename><surname>Suykens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.13766</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ragav</forename><surname>Filipe R Cordeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Sachdeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Longremix</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.04173</idno>
		<title level="m">Robust learning with high confidence samples in a noisy label environment</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Patras</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.11163</idno>
		<title level="m">Adaptive soft contrastive learning</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aritra</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Training deep neural-networks using a noise adaptation layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Ben-Reuven</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.06872</idno>
		<title level="m">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A survey of label-noise representation learning: Past, present and future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.04406</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for largescale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Selfie: Refurbishing unclean samples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwanjun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minseok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae-Gil</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5907" to="5915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning from noisy labels with deep neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwanjun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minseok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yooju</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae-Gil</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Iterative learning with open-set noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu-Tao</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8688" to="8696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Symmetric cross entropy for robust learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaiyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="322" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A topological filter for learning with label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songzhu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="21382" to="21393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Fan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaojie</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingqian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Feng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.11035</idno>
		<title level="m">Ngc: A unified framework for learning with open-world noisy data</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Sample selection with uncertainty of losses for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.00445</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Faster meta update strategy for noise-robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youjiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="144" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Probabilistic end-to-end noise correction for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7017" to="7025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-task curriculum framework for open-set semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiki</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Go</forename><surname>Irie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoharu</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="438" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">How does disagreement help generalization against label corruption</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangchao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7164" to="7173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning with feature-dependent label noise: A progressive approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yikai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songzhu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.07756</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sabuncu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.07836</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Contrast to divide: Self-supervised pre-training for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgenii</forename><surname>Zheltonozhskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaim</forename><surname>Baskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Litany</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.13646</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Robust curriculum learning: from clean label detection to noisy label self-correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
