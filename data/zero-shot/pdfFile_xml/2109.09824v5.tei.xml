<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Well Googled is Half Done: Multimodal Forecasting of New Fashion Product Sales with Image-based Google Trends</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-09-16">September 16, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geri</forename><surname>Skenderi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Verona</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Joppi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Humatics Srl</orgName>
								<address>
									<settlement>Verona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Denitto</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Humatics Srl</orgName>
								<address>
									<settlement>Verona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cristani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Verona</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Humatics Srl</orgName>
								<address>
									<settlement>Verona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Well Googled is Half Done: Multimodal Forecasting of New Fashion Product Sales with Image-based Google Trends</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-09-16">September 16, 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T19:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>New fashion product sales forecasting is a challenging problem that involves many business dynamics and cannot be solved by classical forecasting approaches. In this paper, we investigate the effectiveness of systematically probing exogenous knowledge in the form of Google Trends time series and combining it with multi-modal information related to a brand-new fashion item, in order to effectively forecast its sales despite the lack of past data. In particular, we propose a neural network-based approach, where an encoder learns a representation of the exogenous time series, while the decoder forecasts the sales based on the Google Trends encoding and the available visual and metadata information. Our model works in a non-autoregressive manner, avoiding the compounding effect of large first-step errors. As a second contribution, we present VISUELLE, a publicly available dataset for the task of new fashion product sales forecasting, containing multimodal information for 5577 real, new products sold between 2016-2019 from Nunalie, an Italian fast-fashion company. The dataset is equipped with images of products, metadata, related sales, and associated Google Trends. We use VISUELLE to compare our approach against state-of-theart alternatives and several baselines, showing that our neural network-based approach is the most accurate in terms of both percentage and absolute error. It is worth noting that the addition of exogenous knowledge boosts the forecasting accuracy by 1.5% WAPE wise, revealing the importance of exploiting informative external information. The code and dataset are both available at</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sales forecasting is one of the earliest and most required forecasting applications <ref type="bibr" target="#b10">(Choi, Hui, &amp; Yu, 2013;</ref><ref type="bibr" target="#b5">Beheshti-Kashi, Karimi, Thoben, L?tjenband, &amp; Teucke, 2015)</ref>: driven by economic and financial reasons, the ability to anticipate the needs and behavior of customers can make a big difference for commercial activity, especially when large volumes of goods need to be managed. While the forecasting of time series with a known historical past has been analysed extensively (R. J. <ref type="bibr" target="#b25">Hyndman &amp; Athanasopoulos, 2021;</ref><ref type="bibr" target="#b29">Lara-Ben?tez, Carranza-Garc?a, &amp; Riquelme, 2021)</ref>, very little attention has been paid to a much more practical and challenging scenario: the forecasting of new products, which the market hasn't seen before. In many cases, such forecasts are made in a judgmental manner (R. J. <ref type="bibr" target="#b25">Hyndman &amp; Athanasopoulos, 2021)</ref> by experts that essentially take into consideration the characteristics of the newly designed product along with information on what is trending right now in the market to make an educated guess.</p><p>In this paper, we propose a non-autoregressive Transformer <ref type="bibr" target="#b42">(Vaswani et al., 2017)</ref> model dubbed GTM-Transformer, which tries to mimic this behavior by modeling the sales of new products based on information coming from several domains (modalities): the product image; textual descriptors of category, color and fabric; temporal information in the planned release date; and exogenous information on the trending tendencies of the textual descriptors in the form of Google Trends. This last component is a crucial part of GTM-Transformer, since it introduces external information on item popularity into the reasoning. Intuitively, it models what people are interested in and proves important for forecasting performance.</p><p>While it has been already shown that Google Trends can be used to predict diverse types of time series (from real estate sales to inflation expectations) (L. <ref type="bibr" target="#b44">Wu &amp; Brynjolfsson, 2015;</ref><ref type="bibr" target="#b7">Bulut, 2018;</ref><ref type="bibr" target="#b20">Hand &amp; Judge, 2012;</ref><ref type="bibr" target="#b19">Hamid &amp; Heiden, 2015;</ref><ref type="bibr" target="#b18">Guzman, 2011;</ref><ref type="bibr" target="#b4">Bangwayo-Skeete &amp; Skeete, 2015)</ref>, their adoption to clothing sales forecasting has only been suggested in <ref type="bibr" target="#b38">(Silva, Hassani, Madsen, &amp; Gee, 2019)</ref> but never tried in practice, especially in a new product forecasting setting. Technically, we demonstrate that Google Trends are valuable when encoded appropriately. Thanks to the Cross-Attention weights of our model, we find that the most useful information is systematically located around the end of the previous year's same fashion season, i.e., seven to ten months before the product is planned for exposure.</p><p>As a second contribution, we present VISUELLE: the first public dataset for new fashion product sales forecasting. VISUELLE is a repository build upon the data of a real fast fashion company, Nunalie 1 and is composed of 5577 new products and about 45M sales related to fashion seasons from 2016-2019. Each product in VISUELLE is equipped with multimodal information: an image, textual metadata, sales after the first release date, and three related Google Trends describing category, color and fabric popularity. We use VISUELLE to compare GTM-Transformer with the few and recent state-of-the-art alternatives in the new product sales forecasting literature, obtaining the best performance on several forecasting metrics. We also show that the model can be enriched with attributes which are automatically inferred from the image, considering the widely-used Fashion IQ attributes (H. <ref type="bibr" target="#b43">Wu et al., 2020)</ref>, ameliorating the final performance.</p><p>The rest of the paper is organized as follows: the ensuing Sec. will provide a general overview of the literature around forecasting in fashion and new product sales forecasting. In Sec. 3, an overview of the VISUELLE dataset is given, showing the available information and how the dataset can be used for further research on this topic. Sec. 4 explains the methodological background and details behind GTM-Transformer. In Sec. 5, the experiments are thoroughly explained and finally, the conclusions are drawn in 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">New product sales forecasting</head><p>Tackling the new product sales forecasting with machine learning tools has very few precedent cases <ref type="bibr" target="#b15">(Ekambaram et al., 2020;</ref><ref type="bibr" target="#b39">Singh, Gupta, Jha, &amp; Rajan, 2019)</ref>. The intuition followed in general is that new products will sell comparably to similar, older products; consequently, these models should be able to understand similarities among new and older products.</p><p>In <ref type="bibr" target="#b39">(Singh et al., 2019)</ref>, a variety of boosting algorithms (XGBoost, Random Forest) and Neural Networks (MLP, LSTM) are taken into account, fed with textual attributes related to category and colors, and merchandising factors such as discounts or promotions. Notably, they do not make use of image features or exogenous information. The most related work with ours is <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref>, where the authors use an autoregressive RNN model that takes past sales, auxiliary signals like the release date and discounts, textual embeddings of product attributes, and the product image as input. The model uses soft-attention to understand which of the modalities is the most important to the sales. The model then embeds and combines all these attended features into a feature vector which is fed to a GRU <ref type="bibr" target="#b9">(Cho et al., 2014)</ref> decoder and used to forecast the item sales. In contrast to our work, <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> do not make use of a "true exogenous" signal such as the Google Trends, the model is based on internal information available in the data. Additionally, the autoregressive nature of RNNs creates prediction curves which have a very common shape across products. Unfortunately the dataset and the code is proprietary and was not released. Recent work has explored the use of exogenous signals in fashion forecasting, with <ref type="bibr" target="#b27">(Joppi, Skenderi, &amp; Cristani, 2022)</ref> showing that it is possible to build informative popularity signals that are helpful for forecasting. Our works adds to the literature by using available popularity signals from the web and a Transformer-based model to predict the sales in one shot, without autoregression. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Datasets for fashion forecasting</head><p>Publicly available datasets to forecast on fashion data take into account diverse applications, dissimilar from new product forecasting. The "Clothing, shoes and jewelry" dataset has been used in <ref type="bibr" target="#b34">(Ni, Li, &amp; McAuley, 2019;</ref><ref type="bibr" target="#b2">Al-Halah, Stiefelhagen, &amp; Grauman, 2020)</ref> to forecast fashion styles, that is aggregates of products of multiple brands, in terms of popularity on Instagram. In our case the problem is different, since we are focusing on single products and not on groups of products, so we have definitely fewer data to reason on. In addition, we are considering genuine sales data, and not popularity trends. This makes our research more impactful on an industrial level. The Fashion Instagram Trends <ref type="bibr" target="#b31">(Ma et al., 2020)</ref> adds geographical information to forecast trends in specific places.</p><p>3 The VISUELLE dataset VISUELLE describes the sales between October 2016 and December 2019 of 5577 products in 100 shops of Nunalie, an Italian fast-fashion company funded in 2003. For each product, multimodal information is available, which will be detailed in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Image data</head><p>Each product is associated with an RGB image, of resolution which varies from 256 to 1193 (width) and from 256 to 1172 (height) with median values 575 (w) 722 (h) . Images have been captured in a controlled environment, in order to avoid color inaccuracies and potential biases in the predictions <ref type="bibr" target="#b35">(Nitse, Parker, Krumwiede, &amp; Ottaway, 2004)</ref>. Each image portrays the clothing item on a white background, with no person wearing it. Additionally, a binary foreground mask is provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Text data</head><p>Each product has multiple associated tags, which have been extracted with diverse procedures detailed in the following, and carefully validated by the Nunalie team. The first tag is the category, taken from a vocabulary of 27 elements, visualized in <ref type="figure">Fig. 2a</ref>; the cardinality of the products shows large variability among categories, because naturally some of them (e.g. long sleeves) are popular year-round. This fact demonstrates on particular and challenging aspect of the dataset, which renders the learning of sales dynamics over different categories non-trivial. The color tag  represents the most dominant color, and is extracted from the images with a proprietary pixel clustering algorithm, keeping the color with the most belonging pixels, and validated for each product by two human operators that must agree on it. The final vocabulary is made of 10 elements. The cardinality per color is reported in <ref type="figure">Fig. 2b</ref>. The fabric tag describes the material from which clothes are made, and comes directly from the technical sheets of the fashion items. This tag comes from a vocabulary of 58 elements, visualized in <ref type="figure">Fig. 2c</ref>; A product is sold during a particular season, and within a season, released on the market at a precise day. This temporal information is recorded as a text string. Holidays and sales periods are supplementary information which we plan to deliver for a second version of the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sales data</head><p>The sales time series have a weekly frequency and contain 12 observations each, which corresponds to the permanence of an item in the shops during a fashion season (Autumn-Winter, AW and Spring-Summer, SS). <ref type="figure">Fig. 3</ref> contains a log-density plot of the sales of all the products, merging together different categories, across corresponding seasons (SS18 and SS19 were used for clarity). This is useful to show that there are general "mean curves" where the sales peak occurs after a week and that as the weeks go by, the sales are characterized by a higher variability. An increase of the sales during the years is visible, showing that the company seems to perform well. Notably, from the release moment until 6 weeks, no external action is done by the company owners (discounts, pre/sales, additional supplying) and they had never sold out products, so we can state that the signal variability is given by the product attractiveness.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Google Trends data</head><p>Extracting Google Trends to discover the popularity of textual term describing visual data poses a paradox: the more specific the text, the least informative the signal (due to sparsity), and vice-versa. In VISUELLE we collect, for each product, three Google trends time-series by querying the API using each of the product's three associated textual attributes: color, category, f abric. The trends are downloaded starting from the release date and going back 52 weeks, essentially anticipating the release of each single item by one year. Each signal represents a percentage, reaching 1 (100%) in the moment in time when that particular attribute had the maximum search volume on Google, for the duration of the search interval. <ref type="figure" target="#fig_4">Fig.4</ref> contains examples of Google Trends in the interval 2016-2019. As visible, the nature of these signals is highly variable, spanning from highly structured to more noisy. To make the Google trends signal more reliable, we follow the "multiple sampling" strategy discussed in <ref type="bibr" target="#b32">(Medeiros &amp; Pires, 2021)</ref>. Google normalizes the search results of a query by the total searches of the location and time range chosen by the user. Then, the resulting numbers are scaled from 0 to 100, in order to represent the relative popularity. The problem is of course, because of the high amount of search queries that Google processes each day, the query results are always a sub-sample of the "true" ones and this sample may not always be the same. To avoid this occurrence, we download each Google Trend 10 times and use the mean to create a more representative signal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Background</head><p>Given a product x, we refer to its product sales time series as S(x, t) where t refers to the t-th week of market delivery, with x = 1, ..., N and t = 1, ..., T . In this work, we assume that each product x is associated with an image i, a set of textual tags T and a planned release date d, as in the VISUELLE dataset. Finally, exogenous series in the form of Google Trends are assumed to be available or collected as detailed in 3.4. The goal is to combine all of this information in an efficient and expressive way, such that we can forecast S(x, t) as accurately as possible. We would like to stress again that in the new fashion product sales forecasting scenario, we cannot have direct access to S(x, t), as the product x is new and therefore does not have past sales.</p><p>The structure of the proposed model is depicted in <ref type="figure">Fig. 5</ref>: GTM-Transformer is based on the Transformer model <ref type="bibr" target="#b42">(Vaswani et al., 2017)</ref>, but it deviates from the canonical form in two ways. Firstly, the decoder contains no self-attention block, since that the multimodal embedding that acts an input considering a non-autoregressive variant <ref type="bibr" target="#b17">(Gu, Bradbury, Xiong, Li, &amp; Socher, 2017)</ref>, motivated by two reasons: i) to avoid the compounding of errors caused by wrong initial predictions; ii) to generate the forecasted time series in one go, without any recurrence mechanism, allowing for faster training and inference. In particular, GTM-Transformer learns different representations for each input type and then projects such representations in a shared latent space to non-autoregressively forecast the sales.</p><p>Before proceeding with the explanation of the model and its different components, we give a brief explanation of the attention mechanism, since it is the driving force behind the Transformer model <ref type="bibr" target="#b42">(Vaswani et al., 2017)</ref> and most state-of-the-art neural sequence processing tasks. An attention function can be described in simple words as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and final output are all vectors. The result is calculated as a weighted sum of the values, where the weight of each value is determined by the query's compatibility function with the corresponding key. These terms may sound confusing, but they are actually simple ideas coming from information retrieval systems. For instance, when we search for a query in a search engine, the engine will try to compare the search query to a list of keys (typically metadata) linked to potential matches in their database, and then return the values that give the best matches. To learn these query-key compatibilities, also known as attention weights, the Scaled Dot-Product Attention mechanism <ref type="bibr" target="#b42">(Vaswani et al., 2017)</ref> projects the input in a common vector space and then relies on the dot-product to compute the similarity between vectors. The final output is actually a weighted average of the values according to the query-key compatibilities, because the learned attention weights are normalized to sum to one, as described by the following equations:</p><formula xml:id="formula_0">Q = WqX + Bq,<label>(1)</label></formula><formula xml:id="formula_1">K = W k X + B k ,<label>(2)</label></formula><formula xml:id="formula_2">V = WvX + Bv,<label>(3)</label></formula><formula xml:id="formula_3">? = (QK T ) d k ,<label>(4)</label></formula><formula xml:id="formula_4">y = sof tmax(?)V,<label>(5)</label></formula><p>where W and B are learnable weight and bias matrices for each transformation respectively, d k is the dimensionality of the key(K) latent space, and the sof tmax refers to the differentiable approximation of the argmax function, which outputs a categorical probability distribution. By looking at equations 4 and 5, it becomes clear why the name of this method is "Scaled Dot-Product Attention". This powerful learning technique needs several training tricks to work well with sequences in practice, such as: Positional Encoding; Masking; Learning Rate warmp-up. For a detailed explanation of the Transformer model and its inner workings, we refer the reader to <ref type="bibr" target="#b42">(Vaswani et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">GTM-Transformer</head><p>Our architecture is an encoder-decoder sequence model <ref type="bibr" target="#b40">(Sutskever, Vinyals, &amp; Le, 2014</ref>) that is composed of several blocks, which interact with each other to create a model that is able to accurately forecast S(x, t). To do this we rely mainly on dense vector representations of the different modalities and the Scaled Dot-Product Attention mechanism. The main idea behind the model is to use create a mixture between a retrieval system and a forecasting system, where the model first learns to generate an embedding for each product, and later performs a forecast. During the learning procedure, the model is able to learn and then reason on sales associations between similar and dissimilar products. In simpler words, we aim to build an architecture that is capable of learning (in a non-linear way) how to make judgemental forecasts (R. <ref type="bibr" target="#b23">Hyndman &amp; Athanasopoulos, 2018)</ref> of new fashion products. In order to do this, our model relies on its ability to retrieve similar items and understand their sales, as well as the popularity of the item tags that comes from the Google Trends. The building blocks of GTM-Transformer and their interactions are described below and depicted in <ref type="figure">Fig. 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Creating a multimodal product embedding</head><p>The first part of our architecture consists of a model that can effectively fuse the information coming from the different modalities. In order to this, we makes use of separate embedding modules for each modality, which create dense vector representations of the respective data in a shared latent space R E . Afterwards, a Feature Fusion Network takes as input these vector representations and generates a unique, multimodal dense representation for the product.</p><p>The image embedding module relies on a ResNet-50 model <ref type="bibr" target="#b21">(He, Zhang, Ren, &amp; Sun, 2015)</ref> pre-trained on ImageNet <ref type="bibr" target="#b11">(Deng et al., 2009)</ref>   <ref type="figure">Figure 5</ref>: GTM-Transformer architecture. The encoder processes the exogenous Google Trends series and learns a representative embedding thanks to the self-attention mechanism. The decoder takes as input a multimodal embedding created from the Feature Fusion Network and then relies on a crossattention mechanism to understand the implications of the Google Trend series on the multimodal embedding for the forecasting task. The output of the transformer model is then passed through a fully connected layer, to generate the sales forecast. representation using the linear transformation:</p><formula xml:id="formula_5">?i = Wi?resnet + Bi, ?i ? R E .<label>(6)</label></formula><p>The text embedding module relies on the BERT model <ref type="bibr" target="#b12">(Devlin, Chang, Lee, &amp; Toutanova, 2019)</ref> pre-trained on a large corpus comprising the Toronto Book Corpus and Wikipedia. This module takes as input the same set of textual queries used to find the Google Trend (Sec. 3.4), i.e color, category, f abric and produces an embedding ? bert ? R 768 of the words. Exploiting a pre-trained language model offers an additional advantage, which is the ability to generate a representation for any textual tag, even those that it might have never seen before. Because these language models are trained on extremely large corpora, they also add additional context that comes the typical uses of the textual tag in a sentence. The module averages the embeddings for each attribute and then uses a Fully Connected Layer to create the final textual representation:</p><formula xml:id="formula_6">?t = Wt? bert + Bt, ?t ? R E .<label>(7)</label></formula><p>The temporal features embedding module, is an MLP (Multi Layer Perceptron) that creates a set of embeddings {? d , ?w, ?m, ?y} that contains a projection of each temporal feature available for each product, extracted from the planned release date: the day of the week, the week of the year, the month and the year. Afterwards, these embeddings are concatenated and merged together through a dense layer, creating a final representation of all these temporal features:</p><formula xml:id="formula_7">?r = Wr[? d ; ?w; ?m; ?y] + Br, ?r ? R E .<label>(8)</label></formula><p>where [; ] is the concatenation operation.</p><p>The feature fusion network is another feed-forward network that merges the separate modalities together by using a cascade of fully-connected layers and a non-linear activation. This allows the model to generate an expressive and dense final product embedding in a higher dimensional space R D , D &gt; E, which also contains non-linear interactions between the different modalities:</p><formula xml:id="formula_8">? f = f (?i, ?t, ?r), ? f ? R D (9) f (?i, ?t, ?r) = W l2 ReLU (W l1 [?i; ?t; ?r]) + B l2<label>(10)</label></formula><p>where ReLU represents the Rectified Linear Unit activation function <ref type="bibr" target="#b0">(Agarap, 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Forecasting</head><p>GTM-Transformer first produces a self-attended representation of the Google Trend time series and then merges that information along with the previously explained multimodal embedding in order to forecast the future sales of a new product.</p><p>The transformer encoder takes as input a multivariate Google Trends time series (one for each textual attribute of the product). The series are projected in the same latent space R D and then are enriched with a positional encoding. This signal is then processed by the standard encoder block of <ref type="bibr" target="#b42">(Vaswani et al., 2017)</ref>, by applying Scaled Dot-product Self-Attention as described in equations 1 -5. We additionally employ masking with a block-diagonal matrix, which enforces locality <ref type="bibr" target="#b36">(Rae &amp; Razavi, 2020)</ref>. The encoder outputs ?g ? R D : a representation of the Google Trend time series enriched with information about which portions of itself are most important to the final exogenous representation for the forecasting task. This information is then fed to the decoder, acting as a prior of the popularity of the product.</p><p>The transformer decoder is the component which actually generates the forecasting. Unlike the vanilla decoder block of <ref type="bibr" target="#b42">(Vaswani et al., 2017)</ref>, we remove the Self-Attention segment, since the input coming from the Feature Fusion Network is a single representation and not a sequence. The input is fed to the Multi-Head Cross-Attention attention segment as the query, while ?g is projected as the key and query vector. Based on the explanation of the attention mechanism we provided in Sec. 4.1, this means that our model is trying to understand which part of the exogenous popularity series is most relevant to the multimodal embedding in order to generate a more accurate forecast. The decoder produces a final product embedding ? f ? R D , which is a compact representation of four different modalities: {?g, ?i, ?t, ?r}. Lastly, a Fully Connected layer projects ?p into R horizon in order to generate the forecasted time series {?(x, 1), ...,?(x, horizon)}, based on the desired forecast horizon.</p><p>Training Our proposed architecture and all of its components are trained end-to-end using the Mean Squared Error (MSE) loss function, which is minimized using Mini-Batch Gradient Descent via Adafactor <ref type="bibr" target="#b37">(Shazeer &amp; Stern, 2018)</ref>. The MSE for a batch of N items is defined as:</p><formula xml:id="formula_9">M SE(y,?) = 1 N N i=1 (y ??) 2<label>(11)</label></formula><p>Minimizing the square of the residuals is naturally a well-known and used method in regression problems, which also transfers to our work. By training our model to minimize this loss, we are trying to generate a point forecast that is as close as possible to the mean of the distribution of the sales process. It is widely known that one of the weak points of least-squares objectives is their sensitivity to outliers, which we try to overcome by performing pattern matching on the exogenous Google Trend signal. In this way, we are anticipating sale peaks by using prior online popularity, which in turn provides a data-driven approach that is both computationally cheap and does not rely on extremely complex modelling concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>The experiments start in Sec. 5.1 with a preliminary study on how Google trends correlate with the sales. The experimental protocol and implementation details are explained in Sec. 5.2. In Sec. 5.3 we analyze the first results about how our approach performs against 9 comparative approaches covering the emerging literature of new product sales forecasting. Subsequently in Sec. 5.4, an ablation study investigates the role of the different modalities we take into account, namely textual data, image data and the Google trends (see Sec. 3). The analysis of the performance on the single categories is showed in Sec. 5.5, while the analysis on different time horizons completes the series of experiments in Sec. 5.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Correlation analysis with Google Trends</head><p>The goal is to check the strength and direction of monotonic association between the sales time series and the Google Trends, motivating their use in our framework. As a preprocessing step, we test the time series for stationarity using the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test <ref type="bibr" target="#b28">(Kwiatkowski, Phillips, Schmidt, &amp; Shin, 1992)</ref>, to make sure that the potential correlations will not be simply due to the temporal component <ref type="bibr" target="#b1">(Aldrich, 1995)</ref>. 34% of the sales time series are found to be non-stationary and are not considered for this initial analysis. For each product, we utilize its associated 52-week Google Trends, based on the textual attributes. We calculate the Spearman correlation coefficient against the 12-week sales, using a sliding window protocol with window length w = 12 and stride of one step. Even though the small sample size does not encourage significance when performing correlation analysis (de Winter, Gosling, &amp; Potter, 2016), we wish to investigate the distribution of significant correlations and in particular if they are located on specific periods of the trends. In other words, we are more interested in where the correlations are located across the trends, rather than their values.</p><p>The results give a statistically significant ? coefficient in 86% of the total cases. On this selection, the strongest correlations were found to be positive, with 19% of all coefficients in the range [0.75,1]. The lags that contain the strongest correlations are contained mostly (54% of the cases) in the range <ref type="bibr">[42,</ref><ref type="bibr">30]</ref>, i.e., 42-30 weeks before the planned release date.</p><p>These findings are quite interesting, since they state that the period which is most correlated to the sales is seven to ten months before the product's release date, which corresponds loosely to the end of the same fashion season from the previous year. This preliminary analysis provides further motivation for the use of the Google Trends and is later confirmed by the cross-attention weights of GTM-Transformer in Sec. 5.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental protocol</head><p>On VISUELLE we define an experimental protocol that simulates how a fast fashion company deals with new products, focusing on two particular moments: i) the first order setup, which is when the company orders the first stock of products to be distributed in the shops, usually two months before the starting season; ii) the release setup, which is right before the start of the season, and is useful to obtain the best forecast by using all of the exogenous information at hand, so to have a preliminary idea of when to do the stock replenishment. For these two moments we use 28 and 52 timesteps long Google trends, respectively.</p><p>As forecast horizon, we consider 6 weeks, as it is the period where no interventions are made by the company, such as reordering or retirements of products (if they perform very poorly). In any case, all models classifiers have been trained assuming a 12-week prediction, and shorter horizons have been taken into account for the evaluation. This procedure maximized the performances of all the approaches. Nonetheless results at different horizons will be shown here as for our approach. To perform the experiments, we divide the data into a training and testing partition, where the testing products are composed of the 497 most recent products. The rest of the dataset (5080 products) is used for training.</p><p>We utilize the Weighted Absolute Percentage Error (R. <ref type="bibr" target="#b24">Hyndman, Koehler, Ord, &amp; Snyder, 2008)</ref> as the primary error measure. It expresses the forecasting accuracy as a ratio:</p><formula xml:id="formula_10">WAPE = T t=1 |yt ??t| T t=1 yt (12)</formula><p>where T is the forecasting horizon. WAPE is always nonnegative, and a lower value indicates a more accurate model. Even though it is a percentage-based metric, it is not bounded by 100.</p><p>For a more articulated understanding of our approach, we compute the Mean Absolute Error (MAE), also known as Mean Average Devation (MAD):</p><formula xml:id="formula_11">MAE = T t=1 |yt ??t| T<label>(13)</label></formula><p>MAE describes the mean quantity by which the forecast misses the values on their respective scale. Forecasting bias <ref type="bibr" target="#b6">(Brown, 2004)</ref> is another aspect to take into account, measuring systematic over-or underestimation of the forecast w.r.t. the correct value. Even if a slight forecast bias might not have a notable effect on store replenishment, it can lead to over-or under-supply at the central warehouse. To measure the forecasting bias, we adopt the tracking signal (TS) measure <ref type="bibr" target="#b6">(Brown, 2004;</ref><ref type="bibr" target="#b33">Nahmias &amp; Cheng, 2009)</ref>:</p><formula xml:id="formula_12">TS = T t=1 yt ??t M AE<label>(14)</label></formula><p>which is basically the signed difference between actual and prediction value, divided by the MAE. The sign of the tracking signal communicates if we have an overestimation (if negative) or an underestimation (if positive). The closer to zero, the more unbiased the forecast. In the literature, a forecasting approach is considered to be consistently biased if the tracking error is above 3.75 or below -3.75 <ref type="bibr" target="#b6">(Brown, 2004;</ref><ref type="bibr" target="#b33">Nahmias &amp; Cheng, 2009</ref>). Finally, we focus on the capability in providing a forecasting curve which resembles the ground truth, as a way to highlight whether the model has properly captured the actual signal dynamics. To this end, we exploit the Edit distance with Real Penalty (ERP) <ref type="bibr" target="#b8">(Chen &amp; Ng, 2004)</ref> which borrows from the classical Edit Distance (ED). ED works on discrete sequences, counting the number of edit operations (insert, delete, replace) that are necessary to transform one series into the other. ERP uses the following algorithm: if the Euclidean distance between prediction?t and yt is smaller than a penalty , they are considered equal (d=0) and if not they are considered different (d=1). Summing over differences along the time axis gives the final distance. Since ERP is a dissimilarity, the closer it is to 0 the better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparative results</head><p>Comparing GTM-Transformer with other approaches in the literature requires particular care, since we are the first to exploit Google Trends as exogenous variables to forecast sales for new products. For this reason, together with considering state-of-the-art alternatives in their original form, we adapt them by injecting Google Trends wherever this modification is natural, for example on models which already do process exogenous data. All the code, including the one for the competitors will be made publicly available, for the sake of fairness. To ease the reading, the name of the approaches will be followed by a square parenthesis indicating the type of information exploited within: T for textual data (category, color, fabric and release date), I for image data, G for google trends. Additionally, the name of the approaches which have been augmented with the Google Trends will be followed by a "+G". More in the detail, we consider: kNN models. These non-parametric methods methods are proposed in <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref>, and follow a common guideline for fast fashion companies: sales of new products will be similar to older, similar products they have already commercialized <ref type="bibr" target="#b41">(Thomassey, 2014)</ref>. The idea is to define a similarity metric between products and then forecast the sales of the new product by averaging the sales of the k most similar products that have sold before. Let P be set of all products and let d(xp i , xp j ), ?x ? P be the distance between any two products. We can then obtain the set of k nearest neighbors to a product K = {x1..x k |P, d}. We can then estimate the sales of the a product xp using a weighted average the sales of its neighbors K k=1 d(xp,x k ) K k=1 d(xp,x k ) y k , where y is the sales time series. The three KNN alternatives proposed in <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> are all considered here, which depend on the data they consider to capture the similarity: i) between product attributes (color + category + fabric) Attribute KNN; ii) Between product images (Image KNN); iii) Between the product attributes and images Attr. + Image KNN. In our experiments, we use the cosine distance and set k = 11.</p><p>Gradient Boosting (GBoosting) <ref type="bibr" target="#b16">(Friedman, 2001)</ref>. This fundamental technique has been used in time series forecasting either as solitary models <ref type="bibr" target="#b22">(Henzel &amp; Sikora, 2020)</ref> and recently as components of more elaborate architectures <ref type="bibr" target="#b26">(Ilic, G?rg?l?, Cevik, &amp; Baydogan, 2021)</ref>. Gradient Boosting is an ensemble model which aggregate the results from multiple Decision Trees, where we assume Gradient Boosted Trees. Decision Trees are simple, tree-like diagrams for decision making. Gradient Boosted Trees build trees one after the other, such that each new tree helps correct the errors made by the previous one. This is done by fitting the trees on the negative of the gradient of a particular loss function (similarly to Backpropagation through SGD in Neural Networks). We use 500 trees and set least squares as the optimization problem. When using this model, the additional features, both exogenous and not, are concatenated together and fed to the model.</p><p>Multimodal Encoder-Decoder RNNs, proposed as most advanced techniques in <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref>. The idea is to perform sequence learning in a two-step process, where an Encoder module takes the available information and produces a learned feature representation of the various modalities. This is then fed to an GRU <ref type="bibr" target="#b9">(Cho et al., 2014)</ref> network that acts a Decoder, which autoregressively performs the forecasting. The authors augment their architecture with Bahdanau Attention <ref type="bibr" target="#b3">(Bahdanau, Cho, &amp; Bengio, 2016)</ref>, using the last produced decoder hidden state to learn, at each prediction step, which one of the various modalities provides more important information to the forecast. In particular, we consider the two best performing techniques from the original paper, that is the Concat Multimodal RNN (Cat-MM-RNN), which which learns joint embeddings derived by concatenating embeddings of individual input modalities and the Cross-Attention RNN (X-Att-RNN), which learns multimodal attention weights and temporal attention weights to create an improved joint embedding. Both these architectures natively accomodate the use of Google Trends, so we feed the trends in the exogenous data module as depicted in <ref type="bibr">(Ekambaram et</ref>   <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> [T] 59,8 32,7(18;39) -0,88 0,40 59,8 32,7(18;39) -0,88 0,40 ImageKNN <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> [I] 62,2 34,0(19;42) -1,09 0,43 62,2 34,0(19;42) -1,09 0,43 Attr+Image KNN <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> [T+I] 61,3 33,5(19;39) -1,10 0,41 61,3 33,5(19;39) -1,10 0,41 GBoosting <ref type="bibr" target="#b16">(Friedman, 2001)</ref> [T+I] 64,1 35,0(21;41) -1,58 0,43 64,1 35,0(21;41) -1,58 0,43 GBoosting+G <ref type="bibr" target="#b16">(Friedman, 2001)</ref> [T+I+G] 63,5 34,7(20;41) -1,55 0,42 64,3 35,1(21;41) -1,71 0,43 Cat-MM-RNN <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> [T+I] 63,3 34,4(18;44) -0,67 0,42 63,3 34,4(18;44) -0,67 0,42 Cat-MM-RNN+G <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> [T+I+G] <ref type="bibr">65,9 35,8(19;45)</ref> -0,41 0,44 64,1 34,8(18;43) -0,21 0,43 X-Att-RNN <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> [T+I] 59,5 32,3(16;39) -0,32 0,38 59,5 32,3(16;39) -0,32 0,38 X-Att-RNN+G <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> [T+I+G] 59,0 32,1(17;38) -0,18 0,38 58,7 31,9(16;39) -0,88 0,38 GTM-  <ref type="table">Table 1</ref>: Results on VISUELLE. GTM-Transformer** is fed with the trends indexed by the tags automatically extracted from Fashion IQ. MAE is reported along with its values at the 25-th and 75-th percentiles in parenthesis. 2020). All neural network models are trained for 200 epochs with a batch size of 128 on an NVIDIA Titan RTX GPU. <ref type="table">Table 1</ref> reports the results, where the following facts can be pointed out:</p><p>? The use of Google Trends boosts the performance of all the models, except Concat Multimodal RNN , where the Google Trends have been simply concatenated as static data. ? Our GTM-Transformer gives the best results in both setups (first order and release setup), with the best MAE and WAPE and the second best Tracking Signal, displaying a good balance between over and underestimation. We have the best ERP, which indicates that the shapes of our forecasting curves better resemble the actual sales (as also seen in <ref type="figure">Fig. 6</ref>). ? The tracking signal indicates persistent forecasting bias if its value is above (below) 3.75 <ref type="bibr" target="#b6">(Brown, 2004;</ref><ref type="bibr" target="#b33">Nahmias &amp; Cheng, 2009)</ref>. Not one of the methods has this problem, including GTM-Transformer. This shows that even though the models have gotten much more complex, we are still able to maintain a strong balance between positive and negative errors. GTM-Transformer remains balanced even with 28-week Google Trends. ? Using shorter Google trends (28-week, <ref type="table">Table 1</ref> on the right) gives performances which in general are slightly worse. An explanation for this can be inferred when looking at the attention weights, which are explored in Sec. 5.7</p><p>To explore the generalization of the model to additional types of visual attributes, we consider the tags from Fashion IQs (H. <ref type="bibr" target="#b43">Wu et al., 2020)</ref>: they represent a widely-known approach to describe fashion items for automated retrieval purposes. We apply the attribute extraction code directly to our data, focusing on the "shape" attribute, which describes fine-grained aspects of the structure of the product <ref type="bibr">(v-neck, hem, . . . )</ref>. We discard the other types of attributes, since they consistently overlap with ours (such as the "fabric" attribute) or do not fit very well with VISUELLE, because in Fashion IQ clothes are worn by models. After the attribute extraction, we download the related Google Trends as described in Sec. 3. We dub this model in <ref type="table">Table 1</ref> as GTM-Transformer **. Interestingly, adding complementary information boosts further the model, promoting once again the use of the Google trends. Additional insight can be inferred by some qualitative results, showing two 12-week predictions ( <ref type="figure">Fig. 6)</ref>: Attribute KNN gives reasonable estimates, trying to capture the scarce performance of the first 6 weeks portrayed in the second row. Gradient Boosting overestimates both the cases, offering a graphical demonstration of its high tracking signal TS=-1.58 <ref type="table">(Table 1)</ref>. The RNN-based approaches Concat Multimodal+G, Cross Attention RNN+G seems to have a very regular slope, irrespective of the real structure of the sale signal: this is likely due to the nature of the autoregressive approach, which has learned the general sale curve dynamics and struggles with trajectories which deviate from it. With the GTM-Transformer the role of the Google Trends appears to be clear, being capable of giving more structure to the final forecast (above), lowering down the forecasting thus predicting a scarce performance (below). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation study</head><p>Ablative results refer to the 6-week forecasting horizon, using the full 52-week Google Trends, and are reported in <ref type="table">Tab</ref>  The first ablation is our model without the Google Trends, so removing the encoder module in <ref type="figure">Fig. 5 (row [I+T]</ref>). The much higher WAPE highlights the net role of the exogenous data, and is one of the main results of our study. It is worth noting that the performances are better than all of the approaches using the same kind of information (see Tab. 1), proving the good design of our architecture. The two-modality combos text + Google Trends ([T+G]) and image + Google Trends ([I+G]) give WAPE scores both around 57%, demonstrating that text and images carry complementary information which the complete GTM-Transformer is capable of combining and exploiting. Single modalities ablations instead demonstrate that the image alone [I] has the best performance, and this obviously states that it is the appearance of the product which allows for the most discrimination. Surprisingly, Google Trends [G] alone gives the second best results, while text attributes [T] alone gives the worst results, indicating once again the net value of this exogenous signal.</p><p>Finally, the [AR] row indicates the complete model, but in its autoregressive version: the performance is 4.4% worse than our GTM-Transformer, showing the benefit of the non-autoregressive design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Single category analysis</head><p>Is interesting to check how GTM-Transformer performs on different categories. <ref type="figure">Figure 7</ref> contains the separate WAPEs, where the marker size represents the cardinality of the category <ref type="figure">(Fig. 2a)</ref>. The results confirm the fact that performances are more stable for categories with a large number of products such as "Long sleeve" or "Culottes", as the amount of data available for training over these products is larger. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Varying the forecasting horizon</head><p>In this section we demonstrate the effect of the forecasting horizon on the performance. <ref type="figure" target="#fig_6">Figure 8</ref> contains the WAPE for 1, 2, 4, 6, 8 and 12 week forecasts. GTM-Transformer remains the best performing approach for all horizons, on pair at 2 weeks with Cross-Attention RNN+G. Most of the slopes show a minimum error at 6 weeks, except the Gradient Boosting which shows the second best performance at 1 week. The first 6 weeks performance varies greatly, with Attribute + Image KNN performing the worst. After 6 weeks, all the approaches have a decrease in the performance, which is natural, since the sale signal becomes more dependent on external choices (replenishments, discounts) we are not modeling here. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Model interpretability: unveiling the Google Trends</head><p>To understand the role of Google Trends in GTM-Transformer we exploit the interpretability of the Attention mechanism. To this sake we calculate where in the Google Trend the decoder assigns the highest Cross-Attention weight for the testing set, to find if there are any systematical tendencies as to where the model looks at when making the prediction. A windown binning approach is used, similarly to the correlation analysis in Sec. 5.1, and we count the number of times that the lag with the highest weight is located in that particular window. <ref type="table" target="#tab_7">Table 3</ref> contains the results, where it can be seen that the initial period of the Google Trend seems to be the most crucial, as also hinted initially by our correlation analysis.  Accurate new product forecasting is highly desirable for many reasons, as explained in the introduction: understand tendency in the sales, deciding when to replenish the warehouses, and how many products per reference to buy before the season starts. This is known as the first-order problem <ref type="bibr" target="#b14">(Donohue, 2000)</ref>, and it can be accurately simulated with the real data of VISUELLE. The goal is to order a number of products that matches the sum of future sales until the sixth week, without exceeding or underestimating. During the first six weeks then, sales will help with more  <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> 271,0 3.366.863 $ ImageKNN <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> 279,7 3.475.242 $ Attribute + Image KNN <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> 271,9 3.378.441 $ Gradient Boosting+G <ref type="bibr" target="#b26">(Ilic et al., 2021)</ref> 297,2 3.692.453 $ Concat Multimodal KNN+G <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> 359,7 4.495.977 $ Cross-Attention RNN+G <ref type="bibr" target="#b15">(Ekambaram et al., 2020)</ref> 271,5 3.393.695 $ GTM-Transformer 262,3 3.236.753 $ <ref type="table">Table 4</ref>: First-order results on VISUELLE.</p><p>predictive power in suggesting how to behave with the remaining weeks, for example deciding whether to order again or not. A general protocol to deal with the first order problem is to consider the sum of the sold products of the same period in the previous correspondent season, adding a percentage which mirrors the expected growth, and make the first order. In our case, the policy adopted by the company is to increase the orders for a product of a particular category, color and fabric by 60% of the previous average sum of sold products in the first six weeks for those attributes. We call this the 60% policy. For example, if we want to do the first order for SS19 season of a new white cotton cardigan, we take the average of sold white cotton cardigans of the previous SS18 and add the 60%.</p><p>To compute the first order error, we simply calculate the integral of the forecasting and ground truth curves for the first 6 weeks and compare them with each other, for each considered approach, including the 60% policy. To evaluate the performance, we compute the mean of all the absolute errors over all products. This tells us by how much, on average, the model is mistaken about the total sold amount and therefore the quantity of the first order. To show the real impact of such a problem, in <ref type="table">Table 4</ref> we report also the monetary discrepancy in US dollars, assuming that each reference has a cost of $25 (the average cost of a fast fashion product). In a market of around 12M dollars, the 60% policy is clearly ineffective, and all the forecasting approaches lower the discrepancy considerably, with GTM-Transformer lowering it the most.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we tackle the problem of new fashion product sales forecasting, which is a challenge that requires alternative solutions powered by machine learning and computer vision. In this scenario, we show that Google Trends are beneficial to forecasting and help augment the model's reasoning by adding a popularity prior for the items. All of this was possible thanks to a multimodal framework based on the Transformer, made non-autoregressive in order to deal with the complex dynamics which sales data exhibit, by effectively ingesting the Google Trends data. Additionally and thanks to the collaboration of Nunalie, a genuine dataset coming from the company's recent past sales has been proposed and made publicly available, equipped with ground truth sales signals and data from the image and text domain. Multiple directions can be considered for future work, starting from the use of a more "representative" popularity signal (data-centric aspect), to probabilistic modelling of the complex sales distributions of this practical and challenging problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>p s le e v e g it a n a s k ir t k im o n o d r e s s lo n g c a r d ig a n lo n g c o a t lo n g d r e s s lo n g d u s te r lo n g s le e t d r e s s s h o r t c a r d ig a n s h o r t c o a t s h o r t s le e v e s s h o r ts s le e v e le s s s o li d c o lo u r s tr a c k s u it tr a p e z e d r e s s Examples of Images Per Category</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :Figure 3</head><label>23</label><figDesc>Cardinalities of the dataset per categories (a), color (b) and fabric (c) : 25-percentile density plots of the SS18 and SS19 seasons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Examples of Google Trends time-series spanning multiple years.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 6: Qualitative Results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>1Figure 8 :</head><label>8</label><figDesc>weeks2 weeks4 weeks6 weeks8 weeks12 weeks55606570758085WAPEAttribute + Image KNNGradient Boosting+GConcat Multi-Modal+GCross-Attention RNN+GGTM-transformer Different forecasting horizon results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>to extract 2D convolutional features ?resnet ? R CxW xH , where C = 2048 is the number of final feature channels, W is the image width and H the image height. Adaptive average pooling<ref type="bibr" target="#b30">(Liu, Qi, Qin, Shi, &amp; Jia, 2018)</ref> with a square kernel of size 1 is applied, followed by a Fully Connected Layer, which generates the final image</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Sales Forecast</cell></row><row><cell cols="2">ENCODER</cell><cell></cell><cell>Dense 1 x 12</cell></row><row><cell></cell><cell></cell><cell>52 x D</cell><cell></cell></row><row><cell cols="2">Add &amp; Norm</cell><cell></cell><cell>1 x D</cell></row><row><cell cols="2">Feed-forward network</cell><cell></cell><cell>Add &amp; Norm</cell></row><row><cell cols="2">Masked Multi-Head Self-Attention Add &amp; Norm</cell><cell></cell><cell>Multi-Head Cross-Attention Add &amp; Norm Feed-forward network</cell><cell>DECODER</cell><cell>Dropout Feature Fusion Network Dense 1 x D</cell></row><row><cell></cell><cell>52 x D</cell><cell></cell><cell></cell><cell>ReLU</cell></row><row><cell>Pos. Encoding</cell><cell>+</cell><cell></cell><cell>1 x D</cell><cell>Dense</cell></row><row><cell cols="2">52 x D Embedding</cell><cell></cell><cell>Feature Fusion Network 1 x E*3</cell><cell>BatchNorm 1 x E*3</cell></row><row><cell></cell><cell>52 x 3</cell><cell>1 x E</cell><cell>1 x E</cell><cell>1 x E</cell></row><row><cell cols="2">Google Trends</cell><cell>Image Embedding</cell><cell>Text Embedding</cell><cell>Temporal Features Embedding</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>. 2.</figDesc><table><row><cell>GTM</cell><cell></cell><cell>6 Weeks</cell><cell></cell><cell></cell></row><row><cell>ablations</cell><cell>WAPE</cell><cell>MAE (25%;75%)</cell><cell>TS</cell><cell>ERP</cell></row><row><cell>[I]</cell><cell>56,4</cell><cell>30,8(16;36)</cell><cell>-0,34</cell><cell>0,36</cell></row><row><cell>[T]</cell><cell>62,6</cell><cell>34,2(19;43)</cell><cell>-1,42</cell><cell>0,43</cell></row><row><cell>[G]</cell><cell>58,2</cell><cell>31,8(17;37)</cell><cell>-0,89</cell><cell>0,38</cell></row><row><cell>[I+T]</cell><cell>56,7</cell><cell>30,9(16;38)</cell><cell>-0,32</cell><cell>0,37</cell></row><row><cell>[T+G]</cell><cell>56,8</cell><cell>31,0(14;38)</cell><cell>1,63</cell><cell>0,33</cell></row><row><cell>[I+G]</cell><cell>55,7</cell><cell>30,4(13;32)</cell><cell>1,45</cell><cell>0,30</cell></row><row><cell>[T+I+G]</cell><cell>55,2</cell><cell>30,2(15;36)</cell><cell>0,41</cell><cell>0,33</cell></row><row><cell>[AR]</cell><cell>59,6</cell><cell>32,5(14;36)</cell><cell>1,18</cell><cell>0,32</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>: 6 weeks ablative results on VISUELLE. MAE is reported with also its values at 25-th and 75-th percentiles in parenthesis.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Points of the Google Trends time series with the highest Cross-attention weights 5.8 A very practical use of our model: the first-order problem</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.nunalie.it.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This work has been partially supported by the project of the Italian Ministry of Education, Universities and Research (MIUR) "Dipartimenti di Eccellenza 2018-2022". We would like to thank Nunalie for their availability and for allowing us to publish VISUELLE.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Deep learning using rectified linear units (relu). CoRR, abs/1803.08375</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Agarap</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1803.08375" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Correlations genuine and spurious in pearson and yule. Statistical science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aldrich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="364" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Fashion Forward: Forecasting Visual Style in Fashion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Al-Halah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.06394[cs].Retrieved2020-10-25</idno>
		<ptr target="http://arxiv.org/abs/1705.06394" />
		<imprint>
			<date type="published" when="2020-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Can google data improve the forecasting performance of tourist arrivals? mixed-data sampling approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Bangwayo-Skeete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Skeete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tourism Management</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="454" to="464" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A survey on retail sales forecasting and prediction infashion markets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Beheshti-Kashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-D</forename><surname>Thoben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>L?tjenband</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Teucke</surname></persName>
		</author>
		<idno type="DOI">10.1080/21642583.2014.999389</idno>
		<ptr target="http://dx.doi.org/10.1080/21642583.2014.999389" />
	</analytic>
	<monogr>
		<title level="j">Systems Science and Control Engineering</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="154" to="161" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Smoothing, forecasting and prediction of discrete time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Brown</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Courier Corporation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Google trends and the forecasting performance of exchange rate models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bulut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="303" to="315" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the marriage of lp-norms and edit distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirtieth international conference on very large data bases-volume</title>
		<meeting>the thirtieth international conference on very large data bases-volume</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="792" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Intelligent fashion forecasting systems: Models and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-M</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Imagenet: A largescale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2009.5206848</idno>
	</analytic>
	<monogr>
		<title level="m">2009 ieee conference on computer vision and pattern recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparing the pearson and spearman correlation coefficients across distributions and sample sizes: A tutorial using simulations and empirical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>De Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Gosling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Potter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological methods</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">273</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient supply contracts for fashion goods with forecast updating and two production modes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Donohue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management science</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1397" to="1411" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Attention based Multi-Modal New Product Sales Time-series Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ekambaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Manglik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S K</forename><surname>Sajja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Raykar</surname></persName>
		</author>
		<idno type="DOI">10.1145/3394486.3403362</idno>
		<idno>doi: 10.1145/3394486.3403362</idno>
		<ptr target="https://dl.acm.org/doi/10.1145/3394486.3403362" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020-08" />
			<biblScope unit="page" from="3110" to="3118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Greedy function approximation: A gradient boosting machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<idno type="DOI">10.1214/aos/1013203451</idno>
		<ptr target="https://doi.org/10.1214/aos/1013203451doi:10.1214/aos/1013203451" />
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">O</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.02281</idno>
		<title level="m">Non-autoregressive neural machine translation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Internet search behavior as an economic forecasting tool: The case of inflation expectations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Guzman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of economic and social measurement</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="119" to="167" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Forecasting volatility with empirical similarity and google trends</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hamid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heiden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Behavior &amp; Organization</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="62" to="81" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Searching for the picture: forecasting uk cinema admissions using google trends data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Judge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Economics Letters</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1051" to="1055" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<title level="m">Deep residual learning for image recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Gradient boosting application in forecasting of performance indicators values for measuring the efficiency of promotions in fmcg retail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Henzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sikora</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hyndman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Athanasopoulos</surname></persName>
		</author>
		<title level="m">Forecasting: Principles and practice</title>
		<imprint>
			<publisher>Australia: OTexts</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Forecasting with exponential smoothing: the state space approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hyndman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Koehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Ord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Snyder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Forecasting: principles and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Hyndman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Athanasopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>OTexts</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Explainable boosted linear regression for time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ilic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>G?rg?l?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cevik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Baydogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="page">108144</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Pop: Mining potential performance of new fashion products via webly cross-modal query expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Joppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Skenderi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<idno>doi: 10.48550/ ARXIV.2207.11001</idno>
		<ptr target="https://arxiv.org/abs/2207.11001" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Testing the null hypothesis of stationarity against the alternative of a unit root: How sure are we that economic time series have a unit root</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shin</surname></persName>
		</author>
		<idno type="DOI">10.1016/0304-4076(92)90104-Y</idno>
		<ptr target="https://doi.org/10.1016/0304-4076(92)90104-Y" />
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="178" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">An experimental review on deep learning architectures for time series forecasting. CoRR, abs/2103.12057</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lara-Ben?tez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carranza-Garc?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Riquelme</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2103.12057" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Path aggregation network for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ieee conference on computer vision and pattern recognition (cvpr)</title>
		<meeting>the ieee conference on computer vision and pattern recognition (cvpr)</meeting>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Knowledge Enhanced Neural Fashion Trend Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<idno type="DOI">10.1145/3372278.3390677</idno>
		<idno>doi: 10.1145/3372278.3390677</idno>
		<ptr target="https://dl.acm.org/doi/10.1145/3372278.3390677" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 International Conference on Multimedia Retrieval</title>
		<meeting>the 2020 International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<date type="published" when="2020-06" />
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The proper use of google trends in forecasting models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Medeiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">F</forename><surname>Pires</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nahmias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<title level="m">Production and operations analysis</title>
		<meeting><address><addrLine>McGrawhill New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Justifying recommendations using distantly-labeled reviews and fine-grained aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1018</idno>
		<ptr target="https://www.aclweb.org/anthology/D19-1018doi:10.18653/v1/D19-1018" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (emnlp-ijcnlp)</title>
		<meeting>the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (emnlp-ijcnlp)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11" />
			<biblScope unit="page" from="188" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The impact of color in the e-commerce marketing of fashions: an exploratory study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Nitse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krumwiede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ottaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Marketing</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Do transformers need deep long-range memory?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Razavi</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.acl-main.672" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th annual meeting of the association for computational linguistics</title>
		<meeting>the 58th annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Adafactor: Adaptive learning rates with sublinear memory cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stern</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Googling fashion: forecasting fashion consumer behaviour using google trends</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">?</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Sciences</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">111</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rajan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.01960[cs].Retrieved2021-02-09</idno>
		<ptr target="http://arxiv.org/abs/1907.01960" />
		<title level="m">Fashion Retail: Forecasting Demand for New Items</title>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, &amp; K. Weinberger</editor>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Sales forecasting in apparel and fashion industry: A review. Intelligent fashion forecasting systems: Models and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomassey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="9" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Polosukhin, I</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Attention is all you need</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Al-Halah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rennie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<title level="m">Fashion iq: A new dataset towards retrieving images by natural language feedback</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">3. the future of prediction: How google searches foreshadow housing prices and sales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Economic analysis of the digital economy</title>
		<imprint>
			<publisher>University of Chicago Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="89" to="118" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
