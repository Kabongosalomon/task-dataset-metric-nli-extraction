<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Combinatorial Optimization for Panoptic Segmentation: A Fully Differentiable Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Abbas</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MPI for Informatics Saarland Informatics Campus</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Swoboda</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MPI for Informatics Saarland Informatics Campus</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Combinatorial Optimization for Panoptic Segmentation: A Fully Differentiable Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T19:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a fully differentiable architecture for simultaneous semantic and instance segmentation (a.k.a. panoptic segmentation) consisting of a convolutional neural network and an asymmetric multiway cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a panoptic labeling. Our formulation allows to directly maximize a smooth surrogate of the panoptic quality metric by backpropagating the gradient through the optimization problem. Experimental evaluation shows improvement by backpropagating through the optimization problem w.r.t. comparable approaches on Cityscapes and COCO datasets. Overall, our approach of combinatorial optimization for panoptic segmentation (COPS) shows the utility of using optimization in tandem with deep learning in a challenging large scale real-world problem and showcases benefits and insights into training such an architecture.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Panoptic segmentation is the task of simultaneously segmenting different semantic classes and instances of the same class <ref type="bibr" target="#b36">[37]</ref>. Panoptic segmentation is challenging since neural networks (NN) may produce conflicting predictions (i.e. boundaries separating instances that are not closed contours, instance voting schemes with multiple maxima per instance etc.). Therefore most approaches combine NNs with a post-processing step to compute a final panoptic segmentation that resolves the conflicting evidence produced by NNs. In general, joint training of NNs with post-processing algorithms is an active research area. In our work we propose a fully differentiable approach for panoptic segmentation, our post-processing being a combinatorial optimization problem.</p><p>In this work we pursue the bottom-up approach building segmentations directly from pixels and combine CNNs with the asymmetric multiway cut problem (AMWC) <ref type="bibr" target="#b41">[42]</ref>. The latter is an elegant combinatorial optimization problem that combines semantic and affinity predictions and directly produces a panoptic labeling. We train CNN and AMWC jointly so that the supervisory signal for training the CNN is influenced by the computations of the combinatorial optimization stage. The loss we propose to use for this training differs from common lower-level CNN losses and is a smooth surrogate closely corresponding to the final panoptic quality metric <ref type="bibr" target="#b36">[37]</ref>. We show in this work how our conceptual contributions, i.e. using AMWC as a differentiable module and training on surrogate panoptic quality loss can be made to work together and yield performance improvements.</p><p>The general idea of combining optimization and neural networks and train them jointly has recently enjoyed resurgent interest. The fundamental problem for the specific task of combinatorial optimization is that the output of combinatorial problem is 0-1 valued, hence the loss landscape becomes piecewise constant and simply differentiating through a solver is not possible anymore. Several methods have been proposed to address this problem <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b63">64]</ref>. To our knowledge our work is the first to utilize the perturbation techniques <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b63">64]</ref>  but suboptimal heuristic solvers. We give evidence that training works in this setting and gives performance benefits. To this end we propose a robust extension of the backpropagation technique <ref type="bibr" target="#b63">[64]</ref> that gives better empirical convergence.</p><p>Our architecture is inspired by <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16]</ref> and consists of a ResNet-50 backbone, a semantic segmentation branch for computing class costs and an affinity branch for boundary predictions. Semantic and affinity costs are taken as input by the AMWC solver that returns a panoptic labeling. We first pre-train semantic and affinity branches with simple cross-entropy losses obtaining a strong baseline that achieves a performance similar or better than other bottom-up approaches <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b68">69]</ref>. We finetune subsequently with the AMWC solver and the panoptic surrogate loss via our new robust backpropagation approach and show further performance improvements.</p><p>Current state-of-the-art approaches use very large networks (e.g. Max-DeepLab <ref type="bibr" target="#b64">[65]</ref> uses transformers containing more parameters than a ResNet-101). This might lead to the impression that advances in panoptic segmentation require deeper and more sophisticated architecture. We show that our simpler model can be significantly improved by a fully differentiable approach and argue that simpler models have not yet reached their full potential. Also, our simpler architecture allows for a more controlled setting and makes it easier to identify crucial components and measure to which extent performance improvements can be achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions</head><p>Optimization for segmentation: We propose AMWC <ref type="bibr" target="#b41">[42]</ref> as an expressive and tractable combinatorial optimization formulation to be used in an fully differentiable architecture for panoptic segmentation. We also propose a scalable heuristic for its solution. Panoptic loss surrogate: We propose a surrogate loss function that approximates the panoptic loss metric and can be used in our training setup. Backpropagation: We give an extension of the perturbation technique <ref type="bibr" target="#b63">[64]</ref> for backpropagating gradients through combinatorial solvers, improving training with suboptimal heuristic solvers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental validation:</head><p>We conduct experiments on Cityscapes <ref type="bibr" target="#b18">[19]</ref> and COCO <ref type="bibr" target="#b46">[47]</ref> and show the benefits of fully differentiable training against comparable approaches.</p><p>Our code is available at https://github.com/aabbas90/COPS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Panoptic segmentation</head><p>We categorize panoptic segmentation approaches into three categories: (i) bottom-up methods predict information on the pixel-level and then use post-processing to produce a segmentation, (ii) top-down methods proceed by first identifying regions of interest (ROI) and subsequently basing segmentation on them and (iii) hybrid methods combine bottom-up and top-down ideas. For a general overview of recent segmentation methods we refer to <ref type="bibr" target="#b50">[51]</ref>. Here we will restrict to panoptic segmentation tasks.</p><p>Top-down: Recent works include <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b74">75]</ref>. This principle has also been used with weak supervision <ref type="bibr" target="#b44">[45]</ref>. As a drawback, top-down approaches use ROIs which are mostly axis-aligned and so they can be in-efficient for scenarios containing deformable objects <ref type="bibr" target="#b62">[63]</ref>.</p><p>Bottom-up: Panoptic-DeepLab <ref type="bibr" target="#b15">[16]</ref> based on <ref type="bibr" target="#b73">[74]</ref> proposes a single-stage neural network architecture which combines instance center of mass scores with semantic segmentation to compute panoptic segmentation. They use post-processing similar to Hough-voting <ref type="bibr" target="#b5">[6]</ref>, obtaining great results and reducing the gap to top-down approaches. Subsequently, Axial-DeepLab <ref type="bibr" target="#b65">[66]</ref> made improvements using an attention mechanism to enlarge the receptive field using the post-processing scheme of <ref type="bibr" target="#b73">[74]</ref>.</p><p>The methods SSAP <ref type="bibr" target="#b26">[27]</ref> and SMW <ref type="bibr" target="#b68">[69]</ref> are most similar to our as they also use semantic and affinity scores with a graph partitioning algorithm. SMW <ref type="bibr" target="#b68">[69]</ref> additionally uses Mask-RCNN <ref type="bibr" target="#b28">[29]</ref> and SSAP solves multiple graph partitioning problems in coarse-to-fine manner. Older works such as <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b47">48]</ref> use graph partitioning schemes but only for the instance segmentation task.</p><p>Hybrid: The approaches <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b68">69]</ref> use both bottom-up (affinity scores) and top-down (bounding boxes) sources of information. Conditional convolution <ref type="bibr" target="#b62">[63]</ref> was used in <ref type="bibr" target="#b64">[65]</ref>. Transformers are used in <ref type="bibr" target="#b11">[12]</ref> and combined with Max-DeepLab in a sophisticated architecture, achieving remarkable results. They used a surrogate for the panoptic quality metric along with an instance discrimination loss similar to <ref type="bibr" target="#b70">[71]</ref>. However, Max-DeepLab imposes an upper bound on the maximum number of instances in an image and requires thresholding low confidence predictions.</p><p>In summary, bottom-up methods are generally simpler than top-down ones and require fewer hyperparameters. However, they lack global context and are generally outperformed by top-down approaches. As a solution Axial-DeepLab <ref type="bibr" target="#b65">[66]</ref> reduce this gap by incorporating long range context.</p><p>Almost all of the above-mentioned approaches use multiple loss functions (see <ref type="bibr" target="#b32">[33]</ref> for a possible solution), need thresholds for getting rid of low confidence predictions or assume an upper bound on the number of instances and therefore require hyperparameter tuning. To achieve end-to-end training, approaches of <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b64">65]</ref> design mechanisms embedded in the NNs which can compute panoptic segmentations directly but still have test-time hyperparameters (such as maximum number of instances, probability thresholding) and need more complicated architectures. Except for the above works, other approaches delegate this task to a post-processing module which does not participate in training. The motivation of our work is based on prioritizing ease-of-use and simplicity. Therefore we have chosen a bottom-up approach and propose a fully differentiable method for training with only one loss and no ad-hoc downstream refinements of the segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Algorithms as a layer in neural networks</head><p>Recently there has been great interest in training neural networks with additional layers for problemspecific constraints and prior knowledge. The works <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b40">41]</ref> provide an extensive survey and insights. An excellent overview of multiple approaches for learning graphical model parameters is given in <ref type="bibr" target="#b24">[25]</ref>. The focus of our work is on using an optimization problem as a layer in neural networks. Hence, we will mainly cover approaches for this scenario. They can be categorized as follows:</p><p>Unrolling: For training NNs together with cheap and differentiable iterative algorithms (or for algorithms that can be made differentiable e.g. by smoothing), straightforwardly computing gradients is the most simple approach. This has been done for K-means <ref type="bibr" target="#b67">[68]</ref> bipartite matching <ref type="bibr" target="#b75">[76]</ref>, conditional random fields <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b76">77]</ref>, non-linear diffusion for image restoration <ref type="bibr" target="#b14">[15]</ref> and ranking and sorting <ref type="bibr" target="#b20">[21]</ref>. The interesting study <ref type="bibr" target="#b17">[18]</ref> shows that under some stability conditions backpropagation through the last few steps of iterative procedures is enough to get good estimates of gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implicit Function Theorem:</head><p>In case solutions satisfy fixed point conditions (e.g. KKT conditions) the implicit function theorem can be used to compute gradients. This was done for quadratic programs in <ref type="bibr" target="#b1">[2]</ref>, embedding MaxSAT in neural networks <ref type="bibr" target="#b66">[67]</ref>, a large class of convex optimization problems <ref type="bibr" target="#b0">[1]</ref>, smoothed top-k selection via optimal transport <ref type="bibr" target="#b71">[72]</ref> and deep equilibrium models <ref type="bibr" target="#b4">[5]</ref>.</p><p>Problem-specific methods: Specialized approaches for backpropagating for specific problems were investigated for submodularity <ref type="bibr" target="#b22">[23]</ref> (e.g. using a graph-cut layer), belief propagation <ref type="bibr" target="#b39">[40]</ref>, dynamic programming <ref type="bibr" target="#b49">[50]</ref>, markov random fields <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b38">39]</ref> and nearest neighbor selection <ref type="bibr" target="#b56">[57]</ref>.</p><p>Gradient Estimation by Perturbation: Perturbing the objective of an optimization problem for learning has been proposed in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b52">53]</ref> for graphical model parameters. In <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b54">55]</ref> perturbation is used in the forward pass to get a differentiable estimate of the solution. Perturbing the objective in the direction of loss decrease has been proposed in <ref type="bibr" target="#b23">[24]</ref> for backpropagating through graphical model inference, in <ref type="bibr" target="#b48">[49]</ref> to estimate gradients through a structured loss and in <ref type="bibr" target="#b63">[64]</ref> to backpropagate through combinatorial optimization problems. The latter was used for ranking <ref type="bibr" target="#b59">[60]</ref> and graph matching <ref type="bibr" target="#b60">[61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Our architecture shown in <ref type="figure" target="#fig_7">Figure 2</ref> is comprised of two stages: (i) a CNN to compute semantic class and affinities for boundary predictions followed by (ii) an AMWC optimization layer producing the final panoptic labeling. We describe below our CNN architecture, the AMWC problem and finally the approach for backpropagting through the AMWC solver to optimize panoptic surrogate loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">CNN Architecture</head><p>Our CNN architecture (see <ref type="figure" target="#fig_7">Figure 2</ref>) is comprised of the following parts: a shared ResNet-50 backbone pre-trained on ImageNet <ref type="bibr" target="#b21">[22]</ref> producing feature maps for the subsequent semantic and affinity branch. Our CNN architecture corresponds to Panoptic-Deeplab <ref type="bibr" target="#b15">[16]</ref> with the exception of a modified instance segmentation branch due to different post-processing (Hough voting for vs.  <ref type="bibr" target="#b29">[30]</ref> are fed into a semantic segmentation branch to predict class scores and to an affinity branch to predict object boundaries. Costs from both branches are used in the AMWC solver for computing a panoptic labeling. Pre-training of the semantic and affinity branch is done with top-k cross-entropy losses <ref type="bibr" target="#b73">[74]</ref> (dotted arrows). For backpropagation through AMWC solver we use the panoptic quality loss (dashed arrows). The computation flow marked by solid lines is for panoptic segmentation, dotted arrow for pre-training and dashed arrows for fully differentiable training.</p><p>AMWC in our work). We also use DeepLabv3+ <ref type="bibr" target="#b13">[14]</ref> decoders for both semantic and affinity branch similar to <ref type="bibr" target="#b15">[16]</ref>. This allows for a fair comparison with <ref type="bibr" target="#b15">[16]</ref>.</p><p>Affinity predictor: The affinity branch predicts for given pairs of pixels whether they belong to the same instance. It takes two sources of inputs: (i) features from the affinity decoder and (ii) semantic segmentation costs which makes finding boundaries between different classes easier. Gradients of segmentation costs computed from affinity predictors are not backpropagated during training to preclude the affinity branch from influencing the semantic branch.</p><p>We take horizontal and vertical edges at varying distances d. For COCO we use d ? {1, 4, 16, 32, 64} and for Cityscapes d ? {1, 4, 16, 32, 64, 128}. For each d all corresponding edges are sampled and affinity scores are computed by a dedicated predictor for each distance. For long range edges with d &gt; 1 we compute edge features by taking the difference of affinity features of the edge endpoints before sending them to the predictor. This helps in capturing long-range context. Additional architectural details can be found in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">(Asymmetric) Multiway Cut</head><p>Multiway cut (MWC) <ref type="bibr" target="#b10">[11]</ref> is a combinatorial optimization problem for graph partitioning defined on a graph. In MWC a pre-defined number of classes is given and each node is assigned to one. The cost of a class assignment is given by node and edge affinity costs that give the preference of a node belonging to a certain class and endpoints of the edge to belong to the same class respectively. Hence, the multiway cut can be straightforwardly used to formulate semantic segmentation, each MWC class corresponding to a semantic class.</p><p>The AMWC problem was introduced in <ref type="bibr" target="#b41">[42]</ref> as an extension of MWC. AMWC additionally allows to subdivide some classes into an arbitrary number of sub-clusters. This allows to model segmenting a given semantic class into multiple instances for panoptic segmentation.</p><p>Mathematically, MWC and AMWC are defined on a graph G = (V, E) together with edge weights c E : E ? R and node costs c V : V ? {1, . . . , K} ? R, where K is the number of classes. The edge affinities c E indicate preference of edge endpoints to belong to the same cluster, while the node costs c V indicate preference of assigning nodes to classes. A set P ? [K] contains classes that can be partitioned. For MWC we have P = ? while for AMWC P ? [K]. Let B be the set of valid boundaries, i.e. edge indicator vectors of partitions of V</p><formula xml:id="formula_0">B = {y : E ? {0, 1} : ? C 1? . . .? C M s.t. y(ij) = 1 ? ? l = l and i ? C l , j ? C l } (1)</formula><p>where the number of clusters M is arbitrary and? is the disjoint union. The MWC and AMWC optimization problems can be written as</p><formula xml:id="formula_1">min x:V ?{1,...,K},y?B i?V c V (i, x(i)) + ij?E c E (ij) ? y(ij) s.t. y(ij) = 0, if x(i) = x(j) / ? P y(ij) = 1, if x(i) = x(j)<label>(2)</label></formula><p>The above constraints stipulate that y produces a valid clustering of the graph compatible with the node labeling x, i.e. boundaries implied by y align with class boundaries defined by x and nonpartitionable classes not in P do not possess internal boundaries. The AMWC can be thought of as a special case of InstanceCut <ref type="bibr" target="#b37">[38]</ref> that has class-dependent edge affinities, which, however, makes it less scalable. Illustrations of MWC and AMWC are given in <ref type="figure">Figure 1</ref>.</p><p>Given a feasible solution (x, y) satisfying the constraints in (2), the panoptic labeling z :</p><formula xml:id="formula_2">V ? {1, . . . , J} is computed by connected components w.r.t. y, i.e. z(i) = z(j) ? y(ij) = 0, ?ij ? E.</formula><p>Optimization algorithms for efficiently computing possibly suboptimal solutions for (2) are given in the appendix. Note that, contrary to other approaches for panoptic segmentation such as <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b72">73]</ref> AMWC neither has an upper bound on the number of instances M (which is automatically decided by the optimization problem) nor suffers from computational bottlenecks in this regard. It also does not require thresholding to get rid of low confidence predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fully differentiable training</head><p>To train our architecture along with the AMWC solver we first introduce a new robust variant of the perturbation technique for backpropagation <ref type="bibr" target="#b63">[64]</ref> which works well for our setting of a large-scale problem and suboptimal solver. Second, we introduce a smooth panoptic loss surrogate. Last, we show how to backpropagate gradients for the panoptic loss surrogate through a MWC layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Robust Perturbation for Backpropagation:</head><p>The fundamental difficulty of backpropagating through a combinatorial optimization problem is that the loss landscape is piecewise constant, since the output of the combinatorial problem is integer valued. To handle this difficulty, generally applicable perturbation techniques <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b63">64]</ref> have been proposed. They work by taking finite differences of solutions with perturbations of the original problem. The work <ref type="bibr" target="#b63">[64]</ref> interprets this as creating a continuous interpolation of the non-continuous original loss landscape.</p><p>The second difficulty is that, due to large size and NP-hardness of AMWC, we use a heuristic suboptimal solver that does not in general deliver optimal solutions. Therefore, we propose a multi-scale extension of <ref type="bibr" target="#b63">[64]</ref> for increased robustness that works well in our setting.</p><p>Assume a binary integer linear optimization layer W takes a cost vector c as input from a neural network i.e. W :</p><formula xml:id="formula_3">R n ? {0, 1} n , c ? arg min x?S c, x where S ? {0, 1} n is the set of constraints.</formula><p>Afterwards the minimizer of W is fed into a loss function L : {0, 1} n ? R. For backpropagation we need to compute the gradient ?(L?W) ?c , where L ? W is the composition of L and W. Since, this gradient is zero almost everywhere a continuous interpolation (L ? W) ? is proposed in <ref type="bibr" target="#b63">[64]</ref> where ? &gt; 0 is an interpolation range. The gradient w.r.t. the interpolation is computed by perturbation of the cost vector c by incoming gradient as follows</p><formula xml:id="formula_4">?(L ? W) ? ?c = 1 ? W(c + ??L(W(c))) ? W(c)<label>(3)</label></formula><p>while <ref type="bibr" target="#b63">[64]</ref> report that a large interval of interpolation ranges ? work well on their test problems with optimal solvers, we have not been able to confirm this for our suboptimal heuristic that only gives approximately good solutions to W. Therefore, we propose to use a multi-scale loss and its gradient</p><formula xml:id="formula_5">(L ? W) avg := 1 N N i=1 (L ? W) ?i , ?(L ? W) avg ?c = 1 N N i=1 ?(L ? W) ?i ?c<label>(4)</label></formula><p>where ? i are sampled uniformly in an interval. While the robust backpropagation formula (4) needs multiple calls to the optimization oracle W, they can be computed in parallel. In practice the computation time for a backward pass will hence not increase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Panoptic Quality Surrogate Loss:</head><p>Panoptic quality (PQ) <ref type="bibr" target="#b36">[37]</ref> is a size-invariant evaluation metric defined between a set of predicted masks and ground-truth masks for each semantic class l ? [K]. For each class, it requires to match predicted and object masks to each other w.r.t intersection-over-union (IoU) since instance labels are permutation invariant. A pair of predicted and ground truth binary masks p and g of the same class l is matched (i.e. true-positive) if IoU (p, g) ? 0.5. We write (p, g) ? T P l . For the unmatched masks, each prediction (ground-truth) is marked as false positive F P l (false negative F N l ). Since at most one match exists per ground truth mask, this matching process is well-defined <ref type="bibr" target="#b36">[37]</ref>. The PQ metric is defined as the mean of class specific PQ scores</p><formula xml:id="formula_6">P Q l = (p,g)?T P l IoU (p, g) |T P l | + 0.5(|F P l | + |F N l |)<label>(5)</label></formula><p>Note that the PQ score (5) can be arbitrarily low just by the presence of small sized false predictions <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b72">73]</ref>. A common practice to avoid such issue is to reject small predictions before computing the PQ score with some dataset specific size thresholds, before evaluation. However, this rejection mechanism is not incorporated during training.</p><p>The PQ metric (5) cannot be straightforwardly used for training due to the discontinuity of the hard threshold based matching and the rejection mechanism. Therefore we replace the hard threshold matching process for each class l by computing correspondences via a maximum weighted bipartite matching with IoU as weights. The corresponding matches are T P l , the unmatched prediction masks F P l and the unmatched ground truth masks F N l . The hard thresholding is smoothed via soft thresholding function h(u) = u 4 u 4 +(1?u) 4 centered around 0.5. The small prediction rejection mechanism for mask p is smoothed via ? l (p) = [1 + exp(?0.1(1 T p ? t l ))] ?1 centered at area threshold t l for class l. The overall surrogate PQ for class l is</p><formula xml:id="formula_7">P Q l = (p,g)?T P l h(IoU (p, g)) ? l (p) IoU (p, g) (p,g)?T P l h(IoU (p, g)) ? l (p) + 0.5{ p?F P l ? l (p) + |F N l |}<label>(6)</label></formula><p>where the term h(IoU (p, g)) models the probability of a predicted mask p being true positive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Transformation to Multiway Cut:</head><p>In order to directly train with the panoptic loss surrogate (6) via the backpropagation formula (4) we propose a transformation of the AMWC problem to a lifted MWC problem in the backward pass for computing gradients. The AMWC optimization oracle W can be written as</p><formula xml:id="formula_8">(x * , y * , z * ) = arg min x,y,z c V , x + c E , y<label>(7)</label></formula><formula xml:id="formula_9">s.t. z(i) = z(j), if y(ij) = 0 z(i) = z(j), if y(ij) = 1 (x, y) ? S, z ? Z +</formula><p>where S describes the constraint listed in (2) and the loss is calculated w.r.t panoptic labels z * i.e. W(c V , c E ) = z * . To compute the gradients as per (3) we need to perturb the cost vector associated with z in <ref type="bibr" target="#b6">(7)</ref>. However, AMWC only takes semantic costs and affinity costs as input not the panoptic costs. In other words, the gradient of (6) affects node costs of individual instances separately (i.e. they work on panoptic labels), but AMWC assumes node costs are equal for all instances of one semantic class (i.e. it works on class labels). Therefore we transform the AMWC problem into a lifted MWC problem that has a class for each panoptic label in the ground truth. This allows to optimize directly in panoptic label space and compute a gradient w.r.t semantic and affinity costs which can then be backpropagated to corresponding branches.  For the backward pass described in Algorithm 1 we define the following notation: Let J be the number of classes for the lifted MWC problem and m : [J] ? [K] the mapping from panoptic labels onto the corresponding semantic class. Algorithm 1 computes the gradient w.r.t. the simple backpropagation formula <ref type="bibr" target="#b2">(3)</ref>. For the robust backprop (4) the algorithm has to be called multiple times with the corresponding interpolation ranges ?. An illustration of the gradient computation is given in <ref type="figure" target="#fig_1">Figure 3</ref>.</p><formula xml:id="formula_10">c V (l) = c V (m(l)) + ? ?L ?z (l), ?l ? [J] 2 Multiway cut on panoptic label space: (z p , y p ) = MWC(c V , c E ) 3 Perturbed class labels: x p (i) = m(z p (i)), ?i ? V 4 Compute node cost gradients: ?L ?c V = 1 ? (x p ? x) 5 Compute edge cost gradients: ?L ?c E = 1 ? (y p ? y) 6 return ?L ?c V , ?L ?c E AMWC c V c E x y Loss z Pan. costs ?L ?z MWC c V ? c E c V Grad. comp. x p y p ? x y ?L ?c V ?L ?c E</formula><p>Line 1 in Alg. 1 merges two sources of information i.e. preference of the loss L on panoptic labels z and current class costs c V . Note that the edge costs c E are not perturbed. Afterwards, the perturbed panoptic labels z p are converted back to class labels x p on line 3 to compute the gradients. Ablation study w.r.t using simpler losses on the output of AMWC i.e. class labels x and edge labels y solver is shown in the appendix. Intuitively, applying a loss directly on edge labels does not work because small and large localization errors in edge labels are treated equally. This issue was also observed in <ref type="bibr" target="#b2">[3]</ref> for 3D instance segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>All baselines are trained on NVIDIA Quadro RTX 8000 GPUs with 48GB memory each. For fully differentiable training we use one Tesla P40 with 24GB memory and a 32 core CPU to solve all AMWC problems in the batch in parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We train and evaluate COPS on the Cityscapes <ref type="bibr" target="#b18">[19]</ref> and COCO <ref type="bibr" target="#b46">[47]</ref> panoptic segmentation datasets. We test on the validation and test sets provided by the two datasets. For evaluation on the test set we do not use validation set for training. COCO: Is more diverse and contains 118k, 5k, and 20k images for training, validation, and testing, resp. The dataset has 80 'thing' and 53 'stuff' classes. During training random scale augmentation is also used with a crop size of 640 ? 640 resolution as in <ref type="bibr" target="#b15">[16]</ref>. The values of small segment rejection thresholds (used during both training and inference) are 200, 4096 for 'thing'and 'stuff'class resp. During evaluation the input images are resized to 640 ? 640 resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training</head><p>We closely follow the implementation of Panoptic-DeepLab in <ref type="bibr" target="#b69">[70]</ref> (based on Pytorch <ref type="bibr" target="#b53">[54]</ref>), use the provided ImageNet pre-trained ResNet-50 backbone and the same learning rate parameters for training our baseline model. The Adam optimizer <ref type="bibr" target="#b34">[35]</ref> is used for all our experiments.</p><p>Resolution: The CNNs produce an output with 1/4-th the resolution in every dimension w.r.t input images, similar to Panoptic-DeepLab. This reduced input size is maintained for AMWC (instead of upsampled) to reduce computation time during full training and evaluation. The panoptic labels computed by the AMWC solver are upsampled during evaluation. Since these labels are discrete, upsampling may misalign object boundaries and small ground-truth objects can potentially be missed as well. While this can put our method at a disadvantage, our full training scheme offsets this by achieving panoptic quality even better than the performance at finest resolution of comparable methods.</p><p>Baseline pre-training: We pre-train the CNN architecture as a baseline model and for achieving a good initialization for the subsequent fully differentiable training. This also allows us to measure the additional gain by full training. In pre-training we apply the weighted top-k cross-entropy loss <ref type="bibr" target="#b73">[74]</ref> to each affinity predictor separately and also to the semantic segmentation branch. Since the main objective of the affinity classifier should be to predict instance boundaries we increase the loss by a factor of 4 for edges where at least one endpoint belongs to a 'thing' class. Additionally, we also increase the semantic and affinity loss weights of small objects by a factor of 3 following <ref type="bibr" target="#b15">[16]</ref>.</p><p>We train Cityscapes on one GPU with batch-size 12 for 250k iterations, with initial learning rate 0.001 and the decay strategies of Panoptic-DeepLab. Training takes around 8 days. COCO is trained on four GPUs with a total batch-size of 48 for 240k iterations using the same learning rate parameters as above. Training takes around 11 days.</p><p>Full training: For training COPS through AMWC solver we use only the panoptic quality surrogate loss (6) and fine-tune the semantic and affinity classifiers along with the last layer of each semantic and affinity decoder. The ResNet50 backbone and all batch normalization parameters <ref type="bibr" target="#b31">[32]</ref> are frozen. We train with batch size of 24 until training loss convergences which amounts to 3000 iterations for Cityscapes and 10000 iterations for COCO. To approximate the gradient (4) we use relatively large values of ? compared to <ref type="bibr" target="#b63">[64]</ref> since in-exact optimization might not react to small perturbations correctly (for example the backward pass solution might not even be equal to the one from the forward pass for ? ? 0). We also observed more stable training curves for larger values of N and use N = 5 in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>We compare panoptic quality (in terms of percentage) on both testing PQ test and validation PQ val splits of Cityscapes and COCO datasets, see <ref type="table" target="#tab_1">Table 1</ref>. For the testing splits evaluation requires submission to an online server. We also show performance on 'thing' classes PQ th , and stuff classes PQ st separately. To allow a fair comparison, we restrict ourselves to results of competing approaches which are closest to our setting i.e., without test-time augmentation, similar number of parameters in the network, not utilizing other sources of training data etc. For an overall comparison, we also consider at least one state-of-the-art work from each other type of method (top-down, hybrid etc.).</p><p>First, our fully trained model improves by more than 3 and 4 points in panoptic quality for Cityscapes and COCO resp. in comparison to our baseline model. This is evidence our panoptic loss surrogate and training in conjunction with the combinatorial solver works. Especially, performance on the 'thing' classes improves which have internal boundaries. We argue this is mainly due to better training of the affinity branch, which benefits more from the AMWC supervisory signal. A sample qualitative comparison between baseline and fully trained model can be seen in <ref type="figure">Figure 9</ref>, where full training shows clear visible improvements. The methods SSAP <ref type="bibr" target="#b26">[27]</ref>, SMW <ref type="bibr" target="#b68">[69]</ref> are closest to ours in-terms of the post-processing, and Panoptic-DeepLab in-terms of architecture resp. Our fully trained model outperforms SSAP even in a setting where SSAP uses test-time augmentation and a larger backbone. SMW reports results only on Cityscapes using two independent DeepLabV3+ models and a Mask-RCNN. We outperform it with our approach while still using a simpler model. While Panoptic-Deeplab outperforms our baseline model, our full training scheme outperforms it on both datasets.     In <ref type="figure" target="#fig_4">Figure 4</ref> we plot the PQ surrogate (6) during fully differentiable training using different numbers of interpolation parameter N in (4). Our proposed improvement in the backpropagation scheme of <ref type="bibr" target="#b63">[64]</ref> trains faster and achieves better panoptic quality. In <ref type="figure">Figure 5</ref> we compare our differentiable PQ surrogate <ref type="bibr" target="#b5">(6)</ref> with the exact PQ metric (5) during training. Note that PQ surrogate overestimates exact PQ because we smooth hard thresholding operators. Lastly, we see significant improvement in PQ on evaluation set already after only 24 hours of training with a batch-size of 24 (baseline training took 11 days with 48 batch-size).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Limitations</head><p>Inference times: Although parallelization can be simply done during training, our approach lacks real-time performance during inference requiring around 2 seconds per image from Cityscapes and 0.3 seconds for COCO.</p><p>Two stage training: Our training procedure two steps. First we pre-train the network using simpler losses and then finetune with panoptic quality surrogate loss by backpropagating through AMWC. We follow this approach due to computational efficiency, since the combinatorial part takes a significant amount of time. We hope that with better and faster AMWC solvers training can be converted to a single stage in the future. Moreover, we avoid finetuning the whole model with panoptic quality surrogate because IoU based metrics are not separable under expectations w.r.t. different images <ref type="bibr" target="#b7">[8]</ref>.</p><p>To get good estimates of the loss we therefore require larger batch sizes than for simpler losses used in pre-training. This restriction makes it difficult to train all layers due to GPU memory limitations. It would be interesting to train all parameters by backpropagation through the combinatorial solver and forego the need for pre-training possibly on applications with simpler losses and fast combinatorial solvers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have proposed a fully differentiable approach for panoptic segmentation incorporating a combinatorial optimization layer for post-processing and directly minimizing panoptic quality surrogate loss. Our choice has lead to a simple and elegant formulation with a minimal number of hyperparameters. We argue that learning through combinatorial optimization layers is possible and leads to improved performance even with simple and suboptimal solvers. However, backpropagation schemes should be suitably augmented for robustness in this case.</p><p>While our work suggests that combinatorial optimization is helpful in neural networks, most solvers (including the ones we used) are sequential and executed on CPU, which limits their applicability. For combinatorial optimization to become a more commonly used layer in neural networks, solvers must be designed that are inherently parallel and executable on GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>This work introduces a new fully differentiable architecture for panoptic segmentation, a fundamental task in computer vision used in down-stream tasks. The broader impact of our work depends on the concrete downstream task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Supplementary Material</head><p>A.1 AMWC Heuristic Algorithm 2 describes the heuristic we use for asymmetric multiway cut inspired by greedy additive edge contraction heuristic for multicut in <ref type="bibr" target="#b33">[34]</ref>. The algorithm proceeds by initializing each vertex belonging to a separate cluster (panoptic label). Afterwards, most similar edges are merged in a greedy fashion until similarity becomes negative (Lines 4-6), where similarity for an edge is computed in accordance with its affinity cost as well as node costs (Lines <ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref>. Whenever a merge operation is performed the corresponding edge is contracted and new edges can potentially be created <ref type="figure">(Lines 7-17)</ref>. Afterwards, the clusters belonging to non-partitionable class (i.e stuff) are merged. For finding the arg max efficiently in Line 4 we use priority-queue. Merge j with i:</p><formula xml:id="formula_11">C i = C i ? C j , C j = ? 8 Remove edge ij: E = E \ {ij} 9</formula><p>Assign joint class label:</p><formula xml:id="formula_12">x(C i ) = k ij 10 Update node costs: c V (i, k) = c V (i, k) + c V (j, k) ?k ? [K] 11</formula><p>Assign neighbours of j to i:  <ref type="bibr" target="#b24">25</ref> Function total_edge_similarity(ij) <ref type="bibr" target="#b25">26</ref> Best joint class label:</p><formula xml:id="formula_13">C i , C j : x(C i ) = x(C j ), x(C i ) / ? P do 21 C i = C i ? C j 22 C j = ? 23 end 24 return {C i } i , x</formula><formula xml:id="formula_14">k ij = arg min k?[K] [c V (i, k) + c V (j, k)] 27 Merge cost: s(ij) = c V (i, k ij ) + c V (j, k ij ) 28 Separation cost: m(ij) = c E (ij) + c V (i, x(C i )) + c V (j, x(C j )) 29</formula><p>Compute similarity: t(ij) = m(ij) ? s(ij) <ref type="bibr" target="#b29">30</ref> return t(ij) <ref type="table" target="#tab_3">Table 2</ref> contains the hyperparameters used for fully differentiable training. The data augmentation scheme is the same as the one used in Panoptic-DeepLab in <ref type="bibr" target="#b69">[70]</ref> (which we also use during baseline training). Since the panoptic quality surrogate loss is in [0, 1] we multiply it by a scalar w which in turn affects the magnitude of perturbation in the costs (Line 1 in Alg. 1). As the COCO dataset contains significantly more classes than Cityscapes, we scale the loss by a larger number to ensure that its magnitude is large enough. Notice that the gradient estimates (Lines 4-5 in Alg. 1) would always be in [?1, 1] irrespective of loss scaling.  Model statistics are shown in <ref type="table" target="#tab_4">Table 3</ref> showing number of trainable parameters and runtime for one training iteration where we compare time spent on solving AMWC and MWC problems during forward and backward pass resp.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Training details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Loss on AMWC</head><p>Here we perform an ablation study where we directly apply loss on semantic class labels x and edge labels y instead of panoptic labels. Since we do not use panoptic labels, this approach does not require transformation to MWC. The gradients can be computed by perturbing associated semantic costs c V and edge costs c E and calling the same AMWC solver in the backward pass. Given ground-truth labels x g , y g , the losses are</p><formula xml:id="formula_15">L V = 1 |V | x ? x g 1 (8) L E = 1 ? y T y g y T y g + 0.5(y T (1 ? y g ) + (1 ? y) T y g )<label>(9)</label></formula><p>Here the loss on edge labels is based on the F1-score following the approach of SMW <ref type="bibr" target="#b68">[69]</ref> to account for class-imbalance. The loss <ref type="formula" target="#formula_15">(9)</ref> is applied separately on each affinity classifier. Afterwards the approach of <ref type="bibr" target="#b63">[64]</ref> can be directly applied to compute gradients except that we use N = 5 using the robust backpropagation formula (4) for a fair comparison with the panoptic quality surrogate. Lastly, the losses are scaled to put more emphasis on small objects and 'thing' classes in the same way as done for baseline pre-training.</p><p>We conduct a comparison on Cityscapes dataset and train using the same setup as for the panoptic quality surrogate loss and use the checkpoint with lowest validation error. Results are given in <ref type="table" target="#tab_5">Table 4</ref>. We can see that optimizing PQ surrogate gives better performance and using separate losses decreases the performance especially on 'thing' classes. This is due to multiple reasons: (a) The loss applied on affinities cannot perform well w.r.t. PQ because each edge mis-classification is penalized arbitrarily instead of calculating its impact on PQ, (b) a slight localization error in boundary detection is penalized in the same way as boundary localization errors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Reproducibility</head><p>To ensure that results of fully differentiable training are reproducible we finetune our baseline with 6 random seeds on the Cityscapes dataset for 1500 iterations (instead of 3000 for our main results) and evaluate on the validation split. This introduces multiple sources of randomness in the training process due to mini-batch selection, drop-out, data augmentation etc. More importantly the values of ? in (4) change since they are also drawn randomly in an interval. The results are contained in <ref type="table" target="#tab_6">Table 5</ref> showing that all trials improve over the baseline by fully differentiable training. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Affinity classifiers</head><p>The affinity feature maps f A from the affinity decoder and node costs c V from the semantic segmentation branch are used for computing affinity scores. First f A , c V are concatenated and reduced to 256 channels by two convolutional layers. Afterwards, the result is sent to each classifier specific to an edge distance d. Each classifier predicts horizontal and vertical edge affinities. These steps are illustrated in <ref type="figure">Figure 7</ref>.</p><p>For long-range edges, we first take the difference of node features. Specifically, given node features f of shape B ? N ? H ? W ? R (where B, N, H, W correspond to batch-size, channels, height, width resp.), horizontal and vertical edge features g d h , g d v for a distance d are computed as</p><formula xml:id="formula_16">g d h (b, n, i, j) = f (b, n, i, j + d 2 ) ? f (b, n, i, j ? d 2 ) (10) g d v (b, n, i, j) = f (b, n, i + d 2 , j) ? f (b, n, i ? d 2 , j)<label>(11)</label></formula><p>This operation is marked by S d in <ref type="figure">Figure 7</ref>. Afterwards, we make use of depth-wise separable convolution with 2 groups for efficiency. Note that the indexing in <ref type="bibr" target="#b9">(10)</ref> is done in such a way that center locations of each horizontal and vertical edge match, see <ref type="figure">Figure 8</ref>. The reason is that if there is an oblique boundary in an image there is a high chance that both horizontal and vertical affinities would be low. To capture this inter-dependence the last layer of each affinity classifier does not use depth-wise separable convolution.</p><p>A.6 Other evaluation metrics  <ref type="figure">Figure 7</ref>: Classifier Q 1 predicts information about the finest scale (similar to edge detection in images). In-addition there are |D ? 1|-many classifiers (one is shown in dotted region) for long-range context. All classifiers produce a two channel output c d E containing horizontal and vertical edge costs at a distance d. S d : takes differences of node features in + neighbourhood with edge distance d giving g d h , g d v .</p><formula xml:id="formula_17">c d E Q d ?d ? D s.t. d &gt; 1 Q 1 c 1 E S d</formula><p>(C(n): n ? n conv., BN : batch-norm, R: ReLU, CG(n): C(n) with 2 groups.) <ref type="figure">Figure 8</ref>: Edge neighbourhood around a location i, j where the image contains two regions indicated by yellow and green colors. Assuming edge distance d is even. Horizontal and vertical features g d h , g d v at location i, j are computed from edge end-points. Note that both horizontal and vertical edges would have low affinity values due to presence of a boundary.</p><formula xml:id="formula_18">(i, j) (i ? d 2 , j) (i + d 2 , j) (i, j ? d 2 ) (i, j + d 2 ) g d v g d h</formula><p>better than all approaches which use ResNet-50. For the semantic segmentation task we also get a slight improvement over the baseline by fully differentiable training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6.1 Instance segmentation evaluation</head><p>Average precision (AP) is used to assess instance segmentation performance. To calculate AP one additionally requires uncertainty scores for each instance to establish a ranking. We compute the uncertainty score for an instance with mask p ? {0, 1} |V | having class label l as</p><formula xml:id="formula_19">1 |P | i?V c V (i, l)p(i) + ij?E 1[p(i) = p(j)]c E (ij) ij?E 1[p(i) = p(j)]</formula><p>Inter-cluster mean similarity</p><formula xml:id="formula_20">? ij?E 1[p(i) = p(j)]c E (ij) ij?E 1[p(i) = p(j)]</formula><p>Intra-cluster mean similarity <ref type="bibr" target="#b11">(12)</ref> A.6.2 Comparison w.r.t boundary-based quality metrics</p><p>We additionally evaluate the performance of our model using the metrics proposed in <ref type="bibr" target="#b16">[17]</ref> which focuses more on the quality of detected boundaries. The results are given in <ref type="table" target="#tab_9">Table 7</ref> which shows the despite downsampling our fully trained model can still outperform methods such as Panoptic- DeepLab <ref type="bibr" target="#b15">[16]</ref> in terms of boundary quality. We can also see that most of the performance gain of full training over baseline actually comes from increased recognition quality (RQ). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.7 AMWC without downsampling</head><p>Due to runtime issues associated with AMWC solver our results are computed at 1/4-th of the input resolution. To quantify the potential gains in quality we report results computed without this downsampling. Results are given in <ref type="table" target="#tab_10">Table 8</ref> where we see improvement in all metrics although with a significant slow down due to sequential nature of AMWC solver. Nonetheless, this shows that our results can be further improved if faster algorithms for solving AMWC are developed. We perform an oracle study where the segmentation costs c V sent as input to AMWC are replaced by ground-truth. This helps in establishing an upper bound on performance assuming that the semantic segmentation branch is performing perfectly. The affinity costs c E are still computed through the network. Results are given in <ref type="table" target="#tab_11">Table 9</ref>.</p><p>We see a substantial increase in PQ scores for COCO dataset showing that panoptic segmentation performance on COCO dataset is heavily influenced by semantic segmentation as it contains a large number of classes (133). Since the affinity costs can only make cut/merge decisions for a pair of pixels, it cannot be a major source of improvement in semantic performance (except in edge localization).</p><p>Lastly, we do not see 100% score in PQ o st because our results are downsampled by a factor of 1/4 w.r.t. the ground-truth. We argue that approaches should be compared not only in terms of their performance on benchmarks but also w.r.t. other factors such as network complexity, number of hyperparameters etc., which also matters in production. In table 10 we compare different panoptic segmentation approaches in terms of these properties. Moreover, we also mention whether these approaches can be trained end-to-end (which reduces the number of hyperparameters during training) and whether they optimize the metric-of-interest (i.e., panoptic quality). Even though for a real-world application one might not want to optimize panoptic quality directly, it can serve as a starting point for devising a metric one cares about in production.  <ref type="figure">Figure 9</ref>: Example results on Cityscapes test set</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Exemplary MWC and AMWC problems with 4 classes (K = 4). MWC is a special case of AMWC when P = ?. For P = {3} we get an AMWC problem where class 3 is partitioned into subclusters (instances) 3 A , 3 B and 3 C . Overview of our architecture: Image features computed through a ResNet-50 backbone</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Gradient computation for c V , c E for fully differentiable learning: AMWC produces semantic, edge, panoptic labels x, y, z resp. Perturbations of panoptic label costs c V are computed and sent to the MWC solver together with the original edge costs c E . Results are used to compute and return the gradients.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Cityscapes:</head><label></label><figDesc>Contains traffic related images of resolution 1024 ? 2048 where training, validation and testing splits have 2975, 500, and 1525 images for training, validation, and testing, respectively. It contains 8 'thing' and 11 'stuff' classes. During training we use random scale augmentation and crop to 512 ? 1024 resolution as done in Panoptic-DeepLab. During evaluation the input images are sent at original resolution. The values of small segment rejection thresholds (used during both training and inference) are 200, 2048 for 'thing'and 'stuff'class resp. Lastly, to handle larger occlusions we additionally use affinities at a distance of 128.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Comparison of panoptic quality surrogate loss on Cityscapes for different values of loss interpolation parameter N in<ref type="bibr" target="#b3">(4)</ref>. With N = 5 convergence is reached faster, eventhough we do not parallelize over N .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Train, eval. logs on COCO dataset during fully differentiable training. P Q train<ref type="bibr" target="#b5">(6)</ref> and P Q train (5) are computed during training. P Q eval (5) is reported on the whole COCO validation set after every 1000 iterations.(a) Our baseline: all 3 bicycles are not detected, false detections above the right car and near the left person. (b) After full training: better localization and bicycles are correctly detected Comparison of panoptic labels on Cityscapes test set. (Best viewed digitally).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Algorithm 2 :</head><label>2</label><figDesc>AMWC GREEDY EDGE CONTRACTION Input :Graph G = (V, E), node costs c V : V ? [K] ? R, edge costs c E : E ? R, partitionable classes P ? [K] Output :Clustering C 1? . . .? C M = V , Class labels of each cluster x : {C i } ? [K], 1 Initialize clustering: C i = {i} ?i ? V 2 Initialize class labels: x(C i ) = arg min k?[K] c V (i, k) ?i ? V 3 while E = ? do 4Best merge candidate: ij = arg max ab?E total_edge_similarity(ab)<ref type="bibr" target="#b4">5</ref> if t ij &lt; 0 then 6 break 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>14 E = E ? ih 15 c E (ih) = 0 16 c</head><label>141516</label><figDesc>E (ih) = c E (ih) + c E (jh) 17 end 18 end 19 Merge non-partitionable clusters: 20 for</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>on a large-scale setting with scalable 35th Conference on Neural Information Processing Systems (NeurIPS 2021). arXiv:2106.03188v3 [cs.CV] 25 Oct 2021</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Algorithm 1 :</head><label>1</label><figDesc>BACKWARD PASS Input : ?L ?z , c V , c E , solution x, y, m, ? Output : ?L ?c V , ?L ?c E</figDesc><table /><note>1 Transform node costs to panoptic and perturb:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Results on Cityscapes (above) and COCO (below) on validation and testing splits. We divide the methods into two groups where lower half for each dataset contains the approaches which are comparable to COPS with bold numbers representing the best performance in this category. R-X: ResNet-X, X-71: Xception-71, ?: Mask selection (e.g. by Mask-RCNN), *: Uses test-time augmentation. (-) Marks the results which are not reported for that setting.</figDesc><table><row><cell>Method</cell><cell cols="3">Backbone PQ test PQ test th</cell><cell>PQ test st</cell><cell cols="2">PQ val PQ val th</cell><cell>PQ val st</cell></row><row><cell></cell><cell></cell><cell cols="2">Cityscapes</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Axial-DL [66]</cell><cell>Axial-L</cell><cell>62.7</cell><cell>53.4</cell><cell>69.5</cell><cell>63.9</cell><cell>-</cell><cell>-</cell></row><row><cell>EfficientPS [52]  ?</cell><cell>Custom</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>63.9</cell><cell>66.2</cell><cell>60.7</cell></row><row><cell>Panoptic-DL [16]</cell><cell>X-71</cell><cell>60.7</cell><cell>-</cell><cell>-</cell><cell>63.0</cell><cell>-</cell><cell>-</cell></row><row><cell>Unify. PS [46]  ?</cell><cell>R-50</cell><cell>61.0</cell><cell>52.7</cell><cell>67.1</cell><cell>61.4</cell><cell>54.7</cell><cell>66.3</cell></row><row><cell>UPSNet [73]  ?</cell><cell>R-50</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>59.3</cell><cell>54.6</cell><cell>62.7</cell></row><row><cell cols="2">Panoptic-FPN [36]  ? R-101</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>58.1</cell><cell>52.0</cell><cell>62.5</cell></row><row><cell>SSAP [27] *</cell><cell>R-101</cell><cell>58.9</cell><cell>48.4</cell><cell>66.5</cell><cell>61.1</cell><cell>55.0</cell><cell>-</cell></row><row><cell>Panoptic-DL [16]</cell><cell>R-50</cell><cell>58.0</cell><cell>-</cell><cell>-</cell><cell>60.3</cell><cell>51.1</cell><cell>66.9</cell></row><row><cell>SMW [69]  ?</cell><cell>Multiple</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>59.3</cell><cell>50.6</cell><cell>65.7</cell></row><row><cell>Unify. PS [46]</cell><cell>R-50</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>59.0</cell><cell>50.2</cell><cell>65.3</cell></row><row><cell>SSAP [27]</cell><cell>R-50</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>56.6</cell><cell>49.2</cell><cell>-</cell></row><row><cell>COPS baseline</cell><cell>R-50</cell><cell>56.7</cell><cell>46.0</cell><cell>64.5</cell><cell>58.5</cell><cell>48.3</cell><cell>66.0</cell></row><row><cell>COPS full</cell><cell>R-50</cell><cell>60.0</cell><cell>51.8</cell><cell>65.9</cell><cell>62.1</cell><cell>55.1</cell><cell>67.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>COCO</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Max-DeepLab [65] MaX-S</cell><cell>49</cell><cell>54</cell><cell>41.6</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Unify. PS [46]  ?</cell><cell>R-50</cell><cell>43.6</cell><cell>48.9</cell><cell>35.6</cell><cell>43.4</cell><cell>48.6</cell><cell>35.5</cell></row><row><cell>UPSNet [73]  ?</cell><cell>R-50</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>42.5</cell><cell>48.5</cell><cell>33.4</cell></row><row><cell>Axial-DL [66]</cell><cell>Axial-S</cell><cell>42.2</cell><cell>46.5</cell><cell>35.7</cell><cell>41.8</cell><cell>46.1</cell><cell>35.2</cell></row><row><cell cols="2">Panoptic-FPN [36]  ? R-101</cell><cell>40.9</cell><cell>48.3</cell><cell>29.7</cell><cell>40.3</cell><cell>47.5</cell><cell>29.5</cell></row><row><cell>Panoptic-DL [16]</cell><cell>X-71</cell><cell>38.8</cell><cell>-</cell><cell>-</cell><cell>39.7</cell><cell>43.9</cell><cell>33.2</cell></row><row><cell>SSAP [27] *</cell><cell>R-101</cell><cell>36.9</cell><cell>40.1</cell><cell>32</cell><cell>36.5</cell><cell>-</cell><cell>-</cell></row><row><cell>Panoptic-DL [16]</cell><cell>R-50</cell><cell>35.2</cell><cell>-</cell><cell>-</cell><cell>35.5</cell><cell>37.8</cell><cell>32.0</cell></row><row><cell>COPS baseline</cell><cell>R-50</cell><cell>34.2</cell><cell>35.2</cell><cell>32.8</cell><cell>34.3</cell><cell>34.9</cell><cell>33.4</cell></row><row><cell>COPS full</cell><cell>R-50</cell><cell>38.5</cell><cell>41.0</cell><cell>34.8</cell><cell>38.4</cell><cell>40.5</cell><cell>35.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Hyperparameters for fully differentiable training. R(a, b, c): all values in [a, b] divisible by c.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Optimization</cell><cell></cell><cell></cell><cell></cell><cell>Data aug.</cell></row><row><cell>Dataset</cell><cell>?</cell><cell>N</cell><cell>w</cell><cell cols="2">LR D%</cell><cell>Crop</cell><cell>Horiz. flip</cell><cell>Resize</cell></row><row><cell>Cityscapes</cell><cell>[1, 5e3]</cell><cell>5</cell><cell cols="2">10 1e-3</cell><cell>10</cell><cell>512, 1024</cell><cell cols="2">R(512, 2048, 32)</cell></row><row><cell>COCO</cell><cell cols="4">[1e3, 5e3] 5 100 1e-4</cell><cell>10</cell><cell>640, 640</cell><cell></cell><cell>R(448, 768, 64)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Statistics of our models for Cityscapes and COCO datasets. We also report runtime breakdown (in seconds) for one training iteration with batch size 24.Lastly, we randomly set 10% of values in c V , c E to zero (indicated by D in table 2) during fully differentiable training which makes learning harder. This is similar to dropout except that it is applied to the costs of an optimization layer and secondly the costs are not normalized by dropout rate during test time. This gives a slight but consistent improvement of about 0.3 points in PQ (%) during evaluation.</figDesc><table><row><cell>Overall time includes both</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Comparison of PQ surrogate loss with separate losses on AMWC output Loss PQ PQ th PQ st Separate losses 57.8 45.7 66.6 PQ surrogate 62.1 55.1 67.2</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Reproducibility of fully differentiable training after 1500 iterations under random seeds on Cityscapes validation set. For comparison we also show performance of baseline and fully differentiable training after 3000 iterations.</figDesc><table><row><cell>Trial</cell><cell>PQ</cell><cell cols="2">PQ th PQ st</cell></row><row><cell>1</cell><cell cols="3">61.41 54.40 66.50</cell></row><row><cell>2</cell><cell cols="3">62.01 54.78 67.26</cell></row><row><cell>3</cell><cell cols="3">61.77 54.73 66.89</cell></row><row><cell>4</cell><cell cols="3">61.33 54.37 66.40</cell></row><row><cell>5</cell><cell cols="3">61.91 54.85 67.06</cell></row><row><cell>6</cell><cell cols="3">62.07 55.14 67.11</cell></row><row><cell>Baseline</cell><cell>58.5</cell><cell>48.3</cell><cell>66.0</cell></row><row><cell cols="2">Fully differentiable (final) 62.1</cell><cell>55.1</cell><cell>67.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6</head><label>6</label><figDesc>contains results of instance segmentation and semantic segmentation evaluation metrics on the Cityscapes dataset. On the instance segmentation task our fully differentiable approach performs</figDesc><table><row><cell></cell><cell></cell><cell>C(3), BN, R</cell><cell>C(3), BN, R</cell><cell>C(3), BN, R</cell><cell></cell><cell>C(1)</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>I</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell><cell></cell></row><row><cell cols="2">256</cell><cell>256</cell><cell>64</cell><cell></cell><cell>32</cell><cell cols="2">2</cell></row><row><cell cols="2">C(3), BN, R</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>g d h</cell><cell>g d v</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>CG(3), BN, R</cell><cell cols="2">CG(3), BN, R</cell><cell>C(1)</cell><cell></cell></row><row><cell>I</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>I</cell><cell></cell></row><row><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell><cell></cell></row><row><cell>256</cell><cell>K</cell><cell>256 256</cell><cell>64</cell><cell>64</cell><cell>32</cell><cell>32</cell><cell>2</cell></row><row><cell>f A</cell><cell>c V</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Instance and semantic segmentation performance (AP, mIoU resp.) on Cityscapes validation set. ?: Mask selection (e.g. by Mask-RCNN), *: Uses test-time augmentation. (-) Marks the results which are not reported for that setting.</figDesc><table><row><cell>Method</cell><cell>Backbone</cell><cell cols="2">AP(%) mIoU(%)</cell></row><row><cell>EfficientPS [52]  ?</cell><cell>Custom</cell><cell>38.3</cell><cell>79.3</cell></row><row><cell>Panoptic-FPN [36]  ?</cell><cell>ResNet-101</cell><cell>33</cell><cell>75.7</cell></row><row><cell>UPSNet [73]  ?</cell><cell>ResNet-50</cell><cell>33.3</cell><cell>75.2</cell></row><row><cell>Unify. PS [46]  ?</cell><cell>ResNet-50</cell><cell>33.7</cell><cell>79.5</cell></row><row><cell>Panoptic-DL [16]</cell><cell>Xception-71</cell><cell>35.3</cell><cell>80.5</cell></row><row><cell>Axial-DL [66]</cell><cell>Axial-L</cell><cell>35.8</cell><cell>81.0</cell></row><row><cell>Panoptic-DL [16]</cell><cell>ResNet-50</cell><cell>33.1</cell><cell>78.1</cell></row><row><cell>SSAP [27] *</cell><cell>ResNet-101</cell><cell>37.3</cell><cell>-</cell></row><row><cell>SSAP [27]</cell><cell>ResNet-50</cell><cell>31.5</cell><cell>-</cell></row><row><cell>COPS baseline</cell><cell>ResNet-50</cell><cell>32.7</cell><cell>78.5</cell></row><row><cell cols="2">COPS fully differentiable ResNet-50</cell><cell>34.1</cell><cell>79.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Evaluation w.r.t boundary based panoptic quality metrics [17] denoted by subscript 'b' computed on Cityscapes validation set Method PQ b SQ b RQ b PQ SQ RQ Panoptic-DL [16] 36.3 64.3 55.6 60.3 81.5 72.9 COPS baseline 35.2 62.3 55.9 58.5 80.3 71.8 COPS full 38.9 64.3 59.7 62.1 81.5 75.2</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Effects of downsampling in COPS evaluation performance computed on Cityscapes validation set. The runtime is computed for batch-size of 1.</figDesc><table><row><cell cols="2">Downsampling factor PQ</cell><cell>SQ</cell><cell>RQ</cell><cell>AP Runtime(sec.)</cell></row><row><cell>1/4</cell><cell cols="4">62.1 81.5 75.2 34.1</cell><cell>2</cell></row><row><cell>1</cell><cell cols="4">63.1 82.9 75.4 38.2</cell><cell>15</cell></row><row><cell>A.8 Oracle study</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Oracle study: Evaluation on subset of validation split of COCO and Cityscapes.</figDesc><table><row><cell></cell><cell>Actual results</cell><cell cols="2">Semantic Oracle</cell></row><row><cell>Dataset</cell><cell cols="3">PQ PQ th PQ st PQ o PQ o th PQ o st</cell></row><row><cell cols="3">Cityscapes 62.1 55.1 67.2 81.1</cell><cell>67</cell><cell>91.4</cell></row><row><cell>COCO</cell><cell cols="3">38.4 40.5 35.2 70.9 57.2 91.2</cell></row><row><cell cols="2">A.9 Design choices for panoptic segmentation</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 :</head><label>10</label><figDesc>Qualitative comparison of different approaches of panoptic segmentation in terms of neural network (NN) complexity, number of hyperparameters, end-to-end differentiability and whether they optimize panoptic quality at training time. Last column indicates performance on validation sets of corresponding datasets.</figDesc><table><row><cell>Methods</cell><cell cols="4">Complexity # of Hyperparams. E-to-E Opt. PQ</cell><cell>PQ</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Train</cell><cell>Eval</cell><cell></cell><cell cols="2">Citysc. COCO</cell></row><row><cell>Max-DL [65]</cell><cell>High</cell><cell>Less</cell><cell>Less</cell><cell>Partially</cell><cell>-</cell><cell>49.3</cell></row><row><cell>Eff. PS [52]</cell><cell>High</cell><cell>Many</cell><cell>Many</cell><cell></cell><cell>63.9</cell><cell>-</cell></row><row><cell>UPSNet [73]</cell><cell>High</cell><cell>Many</cell><cell>Less</cell><cell></cell><cell>59.3</cell><cell>42.5</cell></row><row><cell>Unify. PS [46]</cell><cell>High</cell><cell>Less</cell><cell>Less</cell><cell>Partially</cell><cell>61.4</cell><cell>43.4</cell></row><row><cell>Axial-DL [66]</cell><cell>Medium</cell><cell>Less</cell><cell>Less</cell><cell></cell><cell>63.9</cell><cell>41.8</cell></row><row><cell>SSAP [27]</cell><cell>Medium</cell><cell>Less</cell><cell>Less</cell><cell></cell><cell>61.1</cell><cell>36.5</cell></row><row><cell>SMW [69]</cell><cell>Medium</cell><cell>Many</cell><cell>Less</cell><cell></cell><cell>59.3</cell><cell>-</cell></row><row><cell>Panoptic-DL [16]</cell><cell>Low</cell><cell>Low</cell><cell>Less</cell><cell></cell><cell>60.2</cell><cell>35.1</cell></row><row><cell>COPS baseline</cell><cell>Low</cell><cell>Low</cell><cell>None</cell><cell></cell><cell>58.5</cell><cell>34.3</cell></row><row><cell>COPS full</cell><cell>Low</cell><cell>Low</cell><cell>None</cell><cell></cell><cell>62.1</cell><cell>38.4</cell></row><row><cell cols="2">A.10 Example results</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Michal Rol?nek for his valuable suggestions regarding backpropagation through optimization problems.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning convex optimization models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Barratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.04248</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optnet: Differentiable optimization as a layer in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="136" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Crowdsourcing the creation of image segmentation algorithms for connectomics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Arganda-Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><forename type="middle">C</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">R</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Cire?an</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarvesh</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><forename type="middle">M</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Buhmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mojtaba</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Seyedhosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><surname>Tasdizen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radim</forename><surname>Kamentsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaclav</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Uher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changming</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan</forename><forename type="middle">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erhan</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><forename type="middle">G</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Uzunbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Cardona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Sebastian</forename><surname>Schindelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroanatomy</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">142</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Conditional random fields meet deep neural networks for semantic segmentation: Combining probabilistic graphical models with deep learning for structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardino</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M?ns</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Savchynskyy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fredrik</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="52" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01377</idno>
		<title level="m">Deep equilibrium models</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generalizing the hough transform to detect arbitrary shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="122" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Estimating or propagating gradients through stochastic neurons for conditional computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>L?onard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.3432</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The lov?sz-softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amal</forename><forename type="middle">Rannen</forename><surname>Triki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">B</forename><surname>Blaschko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4413" to="4421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Local perturb-and-map for structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gedas</forename><surname>Bertasius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="585" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Berthet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Teboul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Vert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Bach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08676</idno>
		<title level="m">Learning with differentiable perturbed optimizers</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Gruia Calinescu. Multiway Cut</title>
		<imprint>
			<biblScope unit="page" from="567" to="569" />
			<date type="published" when="2008" />
			<publisher>Springer US</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">End-to-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning deep structured models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1256" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Panoptic-deeplab: A simple, strong, and fast baseline for bottom-up panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12475" to="12485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Boundary iou: Improving object-centric image segmentation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kirillov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15334" to="15342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Reverse accumulation and attractive fixed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Christianson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization Methods and Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="311" to="326" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Differentiable perturb-and-parse: Semi-supervised parsing with a structured variational autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caio</forename><surname>Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Differentiable ranking and sorting using optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Teboul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Vert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Differentiable learning of submodular models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josip</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1013" to="1023" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Implicit differentiation by perturbation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Domke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="523" to="531" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning graphical model parameters with approximate marginal inference. IEEE transactions on pattern analysis and machine intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Domke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2454" to="2467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mipaal: Mixed integer program as a layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Ferber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Wilder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bistra</forename><surname>Dilkina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milind</forename><surname>Tambe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1504" to="1511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ssap: Single-shot instance segmentation with affinity pyramid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanhu</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yupei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="642" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Campbell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.04866</idno>
		<title level="m">Deep declarative networks: A new hope</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Learning randomly perturbed structured predictors for direct loss minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hedda</forename><surname>Cohen Indelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamir</forename><surname>Hazan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.05724</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multi-task learning using uncertainty to weigh losses for scene geometry and semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7482" to="7491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Efficient decomposition of image and mesh graphs by lifted multicuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margret</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Levinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Bonneel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lavou?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Andres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1751" to="1759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Panoptic feature pyramid networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6399" to="6408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9404" to="9413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Instancecut: from edges to instances with multicut</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Levinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Savchynskyy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5008" to="5017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Joint training of generic cnn-crf models with stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitrij</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Savchynskyy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rother</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Belief propagation reloaded: Learning bp-layers for labeling problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Knobelreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Sormann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Shekhovtsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedrich</forename><surname>Fraundorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7900" to="7909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">End-to-end constrained optimization learning: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kotary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferdinando</forename><surname>Fioretto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Van Hentenryck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Wilder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.16378</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Asymmetric cuts: Joint image labeling and partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorben</forename><surname>Kroeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?rg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Kappes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ullrich</forename><surname>Beier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><forename type="middle">A</forename><surname>Koethe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hamprecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="199" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Raventos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Tagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01192</idno>
		<title level="m">Learning to fuse things and stuff</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Efficient feature learning using perturb-and-map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Weakly-and semi-supervised panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="102" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unifying training and inference for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13320" to="13328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="2" to="014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Affinity derivation and graph merge for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wengang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jizheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="686" to="703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Direct loss minimization for structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamir</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Keshet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Differentiable dynamic programming for structured prediction and attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3462" to="3471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Image segmentation using deep learning: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Minaee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><forename type="middle">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatih</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Antonio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasser</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demetri</forename><surname>Kehtarnavaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Efficientps: Efficient panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Valada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Perturb-and-map random fields: Using discrete optimization to learn and sample from energy models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="193" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dami</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maddison</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.08063</idno>
		<title level="m">Gradient estimation with stochastic softmax tricks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04658</idno>
		<title level="m">Backpropagating through structured argmax using a spigot</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Neural nearest neighbors networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Pl?tz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1087" to="1098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Seamless scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Colovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8277" to="8286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Detectors: Detecting objects with recursive feature pyramid and switchable atrous convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.02334</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Optimizing rank-based metrics with blackbox differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Rol?nek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V?t</forename><surname>Musil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marin</forename><surname>Vlastelica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Martius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7620" to="7630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Deep graph matching via blackbox differentiation of combinatorial solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Rol?nek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Swoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominik</forename><surname>Zietlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V?t</forename><surname>Musil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Martius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="407" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">End-to-end learning for graph decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10093" to="10102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.05664</idno>
		<title level="m">Conditional convolutions for instance segmentation</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Differentiation of blackbox combinatorial solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marin</forename><surname>Vlastelica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vit</forename><surname>Musil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Martius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Rolinek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Max-deeplab: End-to-end panoptic segmentation with mask transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.00759</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Axialdeeplab: Stand-alone axial-attention for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="108" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Donti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Wilder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6545" to="6554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">End to end learning and optimization on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Wilder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Ewing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bistra</forename><surname>Dilkina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milind</forename><surname>Tambe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The semantic mutex watershed for efficient bottom-up semantic instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Pape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Bailoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Kreshuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="208" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wan-Yen</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Detectron2</surname></persName>
		</author>
		<ptr target="https://github.com/facebookresearch/detectron2" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via nonparametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minshuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06504</idno>
		<title level="m">Differentiable top-k operator with optimal transport</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Upsnet: A unified panoptic segmentation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8818" to="8826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tien-Ju</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jyh-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivienne</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.05093</idno>
		<title level="m">Deeperlab: Single-shot image parser</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Sognet: Scene overlap graph network for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qijie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="12637" to="12644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Dmm-net: Differentiable mask-matching network for video object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3929" to="3938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Conditional random fields as recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardino</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dalong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1529" to="1537" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
