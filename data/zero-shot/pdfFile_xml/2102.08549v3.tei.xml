<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">First Target and Opinion then Polarity: A Two-stage Correlation Enhanced Network for Aspect Sentiment Triplet Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianzhe</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiyi</forename><surname>Wang</surname></persName>
							<email>wanghf@pku.edu.cnwangpeiyi@stu.pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicong</forename><surname>Cheng</surname></persName>
							<email>chengzhicong01@baidu.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Yin</surname></persName>
							<email>yindawei@acm.org</email>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">First Target and Opinion then Polarity: A Two-stage Correlation Enhanced Network for Aspect Sentiment Triplet Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Aspect Sentiment Triplet Extraction (ASTE) aims to extract triplets from a sentence, including target entities, associated sentiment polarities, and opinion spans which rationalize the polarities. Existing methods are short on building correlation between target-opinion pairs, and neglect the mutual interference among different sentiment triplets. To address these issues, we utilize a two-stage framework to enhance the correlation between targets and opinions: at stage one, we extract targets and opinions through sequence tagging; then we append a group of artificial tags named Perceivable Pair, which indicate the span of a specific target-opinion tuple, to the input sentence to obtain closer correlated target-opinion pair representation. Meanwhile, we reduce the negative interference between triplets by restricting tokens' attention field. Finally, the polarity is identified according to the representation of the Perceivable Pair. We conduct experiments on four datasets, and the experimental results show the effectiveness of our model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Aspect-Based Sentiment Analysis (ABSA) <ref type="bibr" target="#b9">(Liu, 2012;</ref><ref type="bibr" target="#b10">Ma et al., 2017;</ref><ref type="bibr" target="#b24">Zhao et al., 2019)</ref> task aims at identifying the sentiment associated with a specified target in a sentence. It constitutes a corner stone for sentiment analysis <ref type="bibr" target="#b5">(Feldman, 2013;</ref><ref type="bibr" target="#b21">Zhang et al., 2018)</ref> applied in different scenarios such as social media <ref type="bibr" target="#b0">(Agarwal et al., 2011)</ref>, ecommerce <ref type="bibr" target="#b4">(Fang and Zhan, 2015)</ref>, and the press industry <ref type="bibr" target="#b6">(Godbole et al., 2007)</ref>. In this paper, we focus on the Aspect Sentiment Triplet Extraction (ASTE) task. ASTE is expanded from ABSA however has two major differences: i) ASTE does not specify target entities in the sentence, instead practitioners are required to exhaustively extract all entities along with related sentiment. ii) For all extracted sentiment, the corresponding rationale, * Equal contribution.</p><p>(use, easy, POS) (other software, simpler than, NEG) (this software, simpler than, POS) High price and service , value for the money (price, NEG, High) (service, POS, High) <ref type="figure">Figure 1</ref>: An example of ASTE. The target words are colored yellow, and the opinion words are colored red. which we call "opinion", should also be included in the final output. In <ref type="figure">Figure 1</ref>, the opinion word "High" indicates a negative attitude towards the target "price" in the triplet (price, NEG, High). The prior work can be roughly divided into two categories, namely tagging-based methods and matching-based methods. To assign proper sentiment polarities to the corresponding target-opinion pairs, a principled tagging-based method  allocates a composite tag (e.g. a tuple) to each word in the sentence, which indicates the positions of target and opinion words and related sentiment. But such tagging methods fail to handle the one-opinion many-targets situations as illustrated in <ref type="figure">Figure 1</ref>. Different from the tagging-based methods, the matching-based methods adopt a "first extract and then match" pipeline. Different extraction methods correspond to specific model configurations on subtask combination, e.g. <ref type="bibr" target="#b11">Peng et al. (2020)</ref> extracts target-polarity tuples and opinion words while <ref type="bibr" target="#b20">Zhang et al. (2020)</ref> obtain target words, opinion words and sentiment polarities separately via a multi-task learning framework. Both <ref type="bibr" target="#b11">Peng et al. (2020)</ref> and <ref type="bibr" target="#b20">Zhang et al. (2020)</ref> perform pairwise matching after extraction.</p><p>The potential risks in prior work include i) the defective subtask combination. According to human perception, people naturally judge the sentiment based on target-opinion pairs, e.g. negative for "high price" and positive for "high service". Comparing with independently retrieving target, opinion and sentiment opponents <ref type="bibr" target="#b20">(Zhang et al., 2020)</ref> or matching target-polarity tuples with opinion words <ref type="bibr" target="#b11">(Peng et al., 2020)</ref>, obtaining target-opinion tuples at the first stage and then assigning corresponding sentiment polarity would be a better subtask combination. ii) the inefficiency in handling "many targets to one opinion" and "many opinions to one target" situations. Taking the opinion word "high" in <ref type="figure">Figure 1</ref> as an example, in phrase "high price" it means "expensive", when paired with "service", "high" refers to "good quality". However in prior work <ref type="bibr" target="#b11">(Peng et al., 2020;</ref><ref type="bibr" target="#b20">Zhang et al., 2020)</ref>, they first obtain the representation of word "high" through sentence encoders. Then while matching targets "service" or "price", they use the same representation for the opinion word "high" regardless of the ambiguity in different target-opinion word collocations.</p><p>To this end, we use a two-stage framework that first extracts target and opinion words in the sentence and then judges the sentiment polarity with target-opinion-tuple-aware representation. The subtask setting adheres to human cognition, i.e. making the judgement (sentiment polarity) according to the supporting evidence (target-opinion pairs). To mitigate the ambiguity in different target-opinion word collocation, we enumerate all possible targetopinion pairs and append them to the input sentence. In the "many targets to one opinion" and "many opinions to one target" situations, while matching different targets and opinions, we would choose the corresponding pair representation in the input sequence.</p><p>Specifically in the first stage, we exploit a BERTbased <ref type="bibr" target="#b2">(Devlin et al., 2018)</ref> tagging model to extract the target words and opinion words from input sentences like previous work <ref type="bibr" target="#b11">(Peng et al., 2020;</ref>. But we do not perform any other additional tasks such as sentiment classification like them at this stage. In the second stage, inspired by the mark tokens in the relation classification task <ref type="bibr" target="#b23">(Zhang et al., 2019;</ref><ref type="bibr" target="#b13">Soares et al., 2019;</ref><ref type="bibr" target="#b26">Zhong and Chen, 2020)</ref>, we use a group of artificial tags to form a specific Perceivable Pair for each targetopinion pair and append them to the input sentence. Follow the settings of <ref type="bibr" target="#b26">(Zhong and Chen, 2020)</ref>, the perceivable pairs share the same position embedding with the related words in the input sentence to explicitly point out the positions of target and opinion spans. With BERT encoder, when determining the sentiment polarity for a potential target-opinion pair, we retrieve the corresponding perceivable pair representation from the input sequence for 4-way sentiment classification. Apart from positive, neu-tral, negative labels, we assign "N/A" labels to the target-opinion pairs which can not constitute sentiment triples. As there may be many targetopinion pairs in the sequence. To avoid negative interference between them, we adopt the attention constraint from <ref type="bibr" target="#b26">(Zhong and Chen, 2020)</ref>. So when encoding a certain target-opinion pair in the input sequence, the model can only leverage the sentence representation and does not have the access to other target-opinion pairs to avoid negative interference. We summarize our contributions as follows:</p><p>? We use a two-stage framework in ASTE which extracts target-opinion pairs and then judges their sentiment polarity. The subtask combination achieves good performance and comports with human cognition.</p><p>? We utilize sequential input representation with perceivable pairs and restricted attention to enhance the correlation between target-opinion pairs, which resolves ambiguity in word collocation.</p><p>? We conducted experiments on four datasets, the experimental results show the effectiveness of our model. In addition, empirically our model performs better in complex situations like "many-to-one" relations and multiple triplets in one sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section, we will briefly review works on sentiment analysis and triplet extraction. Aspect-level Sentiment Analysis (ABSA) proposed by <ref type="bibr" target="#b12">(Pontiki et al., 2014)</ref> has recently been receiving attention from the research community. In ABSA, many different kinds of tasks have been developed. One is defined as analyzing a specified aspect's sentiment polarity in a sentence <ref type="bibr" target="#b3">(Dong et al., 2014;</ref><ref type="bibr" target="#b10">Ma et al., 2017;</ref><ref type="bibr" target="#b14">Tang et al., 2020)</ref>. Other two kinds of sentiment analysis do not specify the aspects in advance, which has a strong similarity with Aspect Sentiment Triplet Extraction (ASTE). Aspect-sentiment pair extraction <ref type="bibr" target="#b7">(Li et al., 2019)</ref>, which extracts the aspect word and its sentiment polarity from the sentence. And aspect-opinion coextraction <ref type="bibr" target="#b8">(Li et al., 2018)</ref> tends to extract aspects and opinions simultaneously. The above two tasks are both subsets of the ASTE task. The ASTE task can analyze the sentiment polarity of the target, </p><formula xml:id="formula_0">o 1 o 2 o j . . . A ij = {T-B i , T-E i , O-B j , O-E j } X p = [CLS] w 1 w 2 . . . w l [SEP] A 11 A 12 . . . A 1n . . . A ij . . . A m1 A m2 . . . A mn [SEP] + Restricted Attention Field + Shared Position Enc.</formula><p>matching Joint Matching and Sentiment Classification</p><formula xml:id="formula_1">H ij = h T-Bi , h T-Ei , h O-Bj , h O-Ej Linear + softmax ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target &amp; Opinion Extraction Joint Matching and Sentiment Classification</head><p>A <ref type="figure">Figure 2</ref>: Overview of our approach. In the target and opinion extraction stage, we tag all target and opinion words in the sentence through a sequence labeling model. Then we assign a group of artificial tags to form a specific perceivable pair A ij for each possible target i and opinion j pairs. All the perceivable pairs form the A-matrix are appended to the end of the original input in order. This sequence will be sent into another BERT with restricted attention field and shared position embedding. Then put the BERT's output corresponding A-matrix into the matching component to get the final result. and give opinion words as the classification basis, which is more practical in actual scenarios.</p><p>In addition to the ASTE, another influential triplet extraction task in the NLP community is Joint Entity and Relation Extraction (JERE). The goal of JERE is to extract entities from sentences and give the relationships between the extracted entities. In terms of model granularity when matching, the existing work on JERE can be divided into token level models <ref type="bibr" target="#b25">Zheng et al., 2017)</ref> and span level models <ref type="bibr" target="#b15">(Wadden et al., 2019;</ref><ref type="bibr" target="#b26">Zhong and Chen, 2020)</ref>. The Joint Matching and Sentiment Classification part of our framework is inspired by those span level models, emphasizing that spans need to be explicitly recognized and perceived by the model. The most similar work with us in JERE is Zhong and Chen (2020), we list the main differences between our framework and theirs from the perspective of the model structure below: i) the entities of the their JERE task may overlap, they use a span-based method for entity extraction, which is relatively inefficient because it requires searching all possible spans in the sentence. Since there is no overlap between target and opinion in our task, we adopt token classification method to obtain the range of target and opinion. In the ASTE task, this will be more efficient than their method. ii) Our marker tokens will form the Perceivable Pairs based on the pairing of target and opinion, rather than the simple pairwise combinations. iii) We use different segment id to distinguish the original input and marker combinations (Perceivable Pair) part in matching stage. iv) They put all pos-sible marker combinations in the sentence at one time only at inference time but not at training time due to model performance. In our framework, we put all possible the marker combinations (Perceivable Pair) in the sentence at the same time during training and does not affect the performance of the model, so all sentence is only calculate once during training and inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>This section will introduce our approach in detail. An overview of our approach is shown in <ref type="figure">Figure  2</ref>. We use a sequence labeling model to jointly extract the targets and opinions in the sentence first. Then assign perceivable pairs to all possible targetopinion pairs to mitigate the ambiguity in different target-opinion word collocation. After that, following Zhong and Chen (2020), we use the compound computation mechanism to improve computational efficiency and the restricted attention field to reduce the mutual influence. Finally, we take the representations of perceivable pairs as the basis for matching to get the final result.   well as an unmarked label O.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Target and Opinion Extraction</head><formula xml:id="formula_2">0 0 0 1 0 0 0 0 1 1 1 1 1 Field of Attention ? T-E attitude 3 1 attitude 7 0 1 1 T-E attitude 3 1 5 1 O-B Good O-E Good O-B terrible O-E terrible T-B taste T-E taste O-B Good O-E Good T-B taste T-E taste O-B terrible O-E terrible</formula><p>Given an input sequence with l tokens X = w 1 , w 2 , ..., w l , we first let tokens obtain contextualized representations R e = {r e 1 , r e 2 , ..., r e l } through BERT. Then we do token classification to get the extraction distributions:</p><formula xml:id="formula_3">P e i = softmax(r e i W e + b e )<label>(1)</label></formula><p>where W e ? R d?9 , b e ? R 9 , d is the dimension of encoding vectors. We extract target and opinion jointly. Correspondingly, we use cross-entropy as the loss function at this stage, which is defined as follows:</p><formula xml:id="formula_4">L e = l i=1 ?y e i logP e i<label>(2)</label></formula><p>where y e i is the one-hot vector of ground truth label. After obtaining the classification result of each token, we will merge them into the corresponding target set C t and opinion set C o for subsequent models:</p><formula xml:id="formula_5">C t = {t 1 , t 2 , ..t m } C o = {o 1 , o 2 , ..., o n }<label>(3)</label></formula><p>where m, n are the number of target and opinion words, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Joint Matching and Sentiment Classification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Perceivable Pairs</head><p>As discussed in Chapter 1, to well learn the word representation in a specific target-opinion pair, we need to let target/opinion words aware the targetopinion-tuple they are currently in. Therefore, we add the artificial tags named perceivable pair which correspond to the predicted targets and opinions from the first stage into the sentence. Indicating the span boundaries with the artificial tokens has been widely used in many Joint Entity and Relation Extraction models <ref type="bibr" target="#b23">(Zhang et al., 2019;</ref><ref type="bibr" target="#b13">Soares et al., 2019;</ref><ref type="bibr" target="#b26">Zhong and Chen, 2020)</ref>. We use the similar settings to enhance the connection between the specific target and opinion. Each perceivable pair contains four kinds of tags which correspond to the start and end of target and opinion, respectively. Each perceivable pair is defined as:</p><formula xml:id="formula_6">A ij = {T-B i , T-E i , O-B j , O-E j }<label>(4)</label></formula><p>where i, j represents the i-th target and j-th opinion in X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Compound Computations</head><p>Commonly, more than one target or opinion may appear in a sentence. If we need to obtain the representations of each possible perceivable pair of targets and opinions, we will get m * n sequences. Each of them is composed of the sentence X and one possible perceivable pair, as the input of the encoder. This will bring a high computation load for the model. Following the methods from (Zhong and Chen, 2020), we use compound computation which simultaneously considers all the possible perceivable pairs in one sequence to solve this problem.</p><p>We first get all the perceivable pairs A ij and concatenate them together as the segment X ts .</p><p>X ts ={A 11 , A 12 , ..., A 1n ,</p><formula xml:id="formula_7">A 21 , A 22 , ..., A 2n , ..., A m1 , A m2 , ..., A mn } (5)</formula><p>where m, n are the number of targets and opinions. Then we concatenate the original sequence X with X ts and get the new sequence:</p><formula xml:id="formula_8">X p = X + X ts<label>(6)</label></formula><p>At the same time, the perceivable pairs keep their corresponding position information by sharing their position embeddings with the boundary tokens of the corresponding span:</p><formula xml:id="formula_9">Position(T-B i ) = Position(t i?start ) Position(T-E i ) = Position(t i?end ) Position(O-B j ) = Position(o j?start ) Position(O-E j ) = Position(o j?end )<label>(7)</label></formula><p>Finally, different from (Zhong and Chen, 2020), we use different segment id for each token in the sequence X p to distinguish the original sentence and newly added perceivable pairs, as shown in <ref type="figure" target="#fig_0">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Restricted Attention Field</head><p>Since multiple perceivable pairs occur simultaneously in the same sequence, they interfere each other and may confuse the model. To reduce their interference, we also adopt the restricted attention field from <ref type="bibr" target="#b26">(Zhong and Chen, 2020)</ref> to let different types of tokens have different activated attention fields.</p><p>For each token in X ts , its attention field includes its corresponding perceivable pair and the original sequence X. Meanwhile, each token in the segment X ts is not visible to tokens in X. <ref type="figure" target="#fig_0">Figure 3</ref> shows an example sequence composed of the original sentence and the four perceivable pairs, which are distinguished by five different colors. In the last row, for each token we use square(s) to denote its attention field, meaning this token will attend to the segments with the corresponding colors. Formally, the attention field of tokens can be defined as follows:</p><formula xml:id="formula_10">AttnField(w i ) = X, w i / ? X ts X ? A ij , w i ? X ts<label>(8)</label></formula><p>where w i , w j ? A ij .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Matching</head><p>We put the modified sequence X p into BERT to obtain the correlation-enhanced representation:</p><formula xml:id="formula_11">R p = {h [CLS] , h 1 , ..., h [SEP] , ..., H ij , ..., h [SEP] } (9) where H ij = {h T-B i , h T-E i , h O-B j , h O-E j }.</formula><p>After that, we fuse the representation of the target i and opinion j in A ij as the representation of the perceivable pair:</p><formula xml:id="formula_12">r ij = [h T-B i ; h O-B j ]<label>(10)</label></formula><p>where ; represents vector concatenation. Finally, the representation r ij is used to predict their matching result and sentiment polarity:</p><formula xml:id="formula_13">P m ij = softmax(r ij W m + b m )<label>(11)</label></formula><p>where W m ? R 2d?4 , b m ? R 4 . Each pair of target and opinion will be classified into four categories:</p><formula xml:id="formula_14">L m = {POS, NEU, NEG} ? {O}<label>(12)</label></formula><p>where the label O indicates that this pair of words does not match. Here, we use cross-entropy as the loss function. The total loss of a sentence is the sum of each possible target-opinion pair's loss in the sentence, which is defined as follows:</p><formula xml:id="formula_15">L m = ? p i=1 q j=1 y m ij logP m ij<label>(13)</label></formula><p>where p and q are the number of targets and opinions in the sentence, respectively. y m ij is the one-hot vector of the ground-truth label of matching and sentiment polarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We utilize datasets created by  named ASTE-DATA-V2 in our experiment. Compared to ASTE-Data-V1 proposed by <ref type="bibr" target="#b11">(Peng et al., 2020)</ref>, the V2 version contains cases where one target/opinion is associated with multiple opinions/targets, which is very common in actual scenarios. The overview of datasets is listed in <ref type="table" target="#tab_2">Table  1</ref>. The division of the dataset is consistent with that of .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>We compare our method with the following baseline models, some pipeline-based methods are modified by <ref type="bibr" target="#b11">(Peng et al., 2020)</ref> for this task:</p><p>? CMLA+ is modified from CMLA . CMLA uses the attention mechanism to capture the relationship between words and jointly extract target and opinion, and CMLA+ further adds an MLP on CMLA to determine whether a triplet is correct in the matching stage.</p><p>? RINANTE+ is modified from RINANTE <ref type="bibr" target="#b1">(Dai and Song, 2019)</ref>. RINANTE is based on LSTM-CRF and fuses rules as weak supervision to capture words' dependency relations in a sentence. The way RINANTE+ determines the correctness of a triplet is the same as CMLA+.</p><p>? Li-unified-R <ref type="bibr" target="#b7">(Li et al., 2019)</ref> extracts targets, sentiment and opinion spans respectively based on a multi-layer LSTM neural architecture. The way Li-unified-R determines the correctness of a triplet is the same as CMLA+.</p><p>? <ref type="bibr" target="#b11">Peng et al. (2020)</ref> co-extracts targets with sentiment, and opinion spans like <ref type="bibr" target="#b7">(Li et al., 2019)</ref>, and uses GCN to capture dependency information to enhance the co-extraction. The way to determine the correctness of a triplet is also the same as CMLA+.</p><p>? OTE-MTL <ref type="bibr" target="#b20">(Zhang et al., 2020</ref>) is a multitask learning framework to extract aspect terms and opinion terms jointly and simultaneously parses sentiment dependencies between them.</p><p>? GTS (Wu et al., 2020) address the ASTE task in an end-to-end fashion with one unified grid tagging task. They designed an gird inference strategy to exploit mutual indication for more accurate extractions. Their models have two variants that use Glove and BERT to initialize the encoder layer.</p><p>? JET (Xu et al., 2020) converts the ASTE task into several sequence labeling subtasks. In this method, JET t takes the target words as the labeling object, and the label includes the span of the target, the sentiment polarity, and the offset of the paired opinion. JET o is similar to JET t expect the labeling objectives are opinion words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Metrics</head><p>We use precision, recall, and micro F 1 as the evaluation metrics of triple extraction, which is consistent with the previous works. Only if all the elements of a triplet, i.e., target, opinion, and their corresponding sentiment polarity are correct, it will be regarded as a correct result in evaluation. It is noted that the results of some models are directly taken from . And in the original paper of OTE-MTL <ref type="bibr" target="#b20">(Zhang et al., 2020)</ref> and GTS <ref type="bibr" target="#b18">(Wu et al., 2020)</ref>, they use ASTE-DATA-V1 datasets for training and evaluation. So we rerun their models on ASTE-DATA-V2 datasets. All the baselines implemented by us use their default  hyper-parameters and report the best results of 5 different random seeds for a fair comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Implementation Details</head><p>We implement our models based on HuggingFace's Transformers library <ref type="bibr" target="#b17">(Wolf et al., 2020)</ref> and use bert-base-uncased <ref type="bibr" target="#b2">(Devlin et al., 2018)</ref> as the base encoders. We optimize our models with a learning rate of 5e-5 by Adam, random seed range of <ref type="bibr">[1,</ref><ref type="bibr">5]</ref>. The max sequence length is set to 256, and the batch size is 8. We train 3 epochs for target and opinion extraction stage and 10 epochs for the matching stage for all the experiments. We select the final model based on the performance on development set with the hyperparameters above, and report its results on the test set. All experiments are conducted on a Linux server with Intel Xeon E5-2680, 256G of RAM and Nvidia RTX 3090. <ref type="table" target="#tab_4">Table 2</ref> reports the experimental results of our model against other baseline methods. Our model achieves state-of-the-art results on 14Lap, 16Rest, close to GTS in 14Rest, and slightly behind GTS in 15Rest. And our model achieves the best overall F 1 of the four datasets, which prove the effectiveness of the model. First, due to the strong expressive ability of BERT, the performance of the model can be improved. More importantly, our model's performance is much better than other models with BERT like JET + BERT . Because our model can traverse all possible target-opinion pairs to match, which overcome the shortcomings of tagging-based models that cannot handle one-to-many situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Method Comparison</head><p>Then, compared with OTE-MTL, which is also a matching-based method, the performance of our method is significantly better. OTE-MTL only selects the terms' original representation as the basis for matching, which cannot reflect target-opinion pairs' correlation. This may be the actual reason for the performance difference.</p><p>Finally, GTS combines the representations of target and opinion and generates specific representations for each target-opinion pair like ours. But the word representations used for combining still remain the same for different target-opinion pairs. While our model generates specific word representations for the same word in each possible pair, then combines those specific word representations to generate pair representations to establish correlations within target-opinion pairs, which results in performance improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Ablation Study</head><p>To verify the effects of the components in our framework, we conduct some ablation experiments. The results are shown in <ref type="table" target="#tab_6">Table 3</ref>.</p><p>We first verified the effectiveness of perceivable pairs by removing the start tag and the end tag of perceivable pairs, respectively. The experimental results are given in <ref type="table" target="#tab_6">Table 3</ref> a) and b). It can be seen that the performance has shown some decline. This shows that perceivable pairs are fully effective in indicating complete term spans.</p><p>After that, we completely remove the perceivable pairs from the sequence and only use the representation of the term for matching like previous matching-based methods. The results are shown in <ref type="table" target="#tab_6">Table 3</ref> c). We notice that the performance has dropped more significantly than the previous two experiments, which shows the perceivable pairs inserted into the sequence can establish the correlation between them by making target/opinion words aware the target-opinion-tuple they are current in.</p><p>Finally, we removed the tag segment's special segment id and merged it with the original sequence into one segment. The experimental results are shown in d). Since perceivable pairs are artificially added tokens, they may confuse the model if they ?? 1 service: Great food but the service was dreadful !</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[T-B]:</head><p>Great food but the service was dreadful ! are not distinguished from the original input. Then we conducted two experiments on the restricted attention field. We first removed the restricted attention field in the tag segment. All perceivable pairs in tag segment can be seen by other pairs, but the tokens in the original sequence remain the same as before. The experimental results are shown in <ref type="table" target="#tab_6">Table 3 e</ref>). Performance has dropped significantly. As discussed before, perceivable pairs are effective because they establish a strong correlation between target-opinion pairs. After removing the attention field restriction in the tag segment, tags in perceivable pairs can see all other tags in the sentence instead of being limited to the specific target-opinion pair. Thus the correlation is significantly weakened. Therefore, the performance of the model is significantly declined.</p><p>Then we go one step further and remove all restricted attention field, so all tokens in the sequence could see other tokens without any restriction. The experimental results are shown in f), exhibiting a more obvious decline than e). At this time, the pairwise correlation of the target-opinion pair no longer exists, and the original tokens see a large number of artificial tokens, which also affect their representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Case study on Perceivable Pairs</head><p>To better explore the effect of perceivable pairs in the model, we conducted a case study. We feed the  <ref type="table">Table 4</ref>: Performance comparison in complex situations with one-to-many correspondence. All the models mentioned in this table use BERT as the encoder. Due to limited space, we only list the results of two datasets. Similar results can be seen on other datasets. sequence with perceivable pairs into BERT, and check the attention weight of the target word (service) and its corresponding start tag in perceivable pair respectively. The result is shown in <ref type="figure">Figure 4</ref>. It turns out that the former will pay attention to all the opinion words (Great and dreadful) in the sentence, but only dreadful really needs to be focused. While the latter using perceivable pairs focus on the truly important words (service and dreadful). Moreover, it can be seen from the attention weight distribution that those tags in perceivable pair establish a strong correlation between the target-opinion pair. The final sentiment classification result using only the original representation of the service in the sentence is incorrectly classified as positive. In contrast, the classification based on perceivable pair is correct and marked as negative. The comparison of the two results also shows the actual effect of the perceivable pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Model performance in complex situations</head><p>We examined the performance comparison between our method and other baseline models in complex situations where there are multiple triplets in a sentence. The results are shown in <ref type="figure">Figure 5</ref>. As the number of triplets increases, the performance gap between our framework and other models becomes more obvious. Since our method uses different perceivable pairs to model all possible target-opinion pairs, as the number of triplets in the sentence increases, our method will not be greatly affected.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>An example of the input structure. Note that each target/opinion span corresponds to a start tag T-B/O-B and an end tag T-E/O-E. In the last row, for each token we use square(s) to denote its attention field, meaning this token will attention to the segments with the corresponding colors. For example,[CLS]  can only see the token colored yellow, while the first T-B:service which is colored red can see 4 more tokens that also colored red than [CLS].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Visual comparison of the attention weight between target word (service) and corresponding start tag in perceivable pairs. Performance comparison in complex situations with multiple triplets in a sentence. Due to limited space, we only show the results of the 14Lap dataset. All the models mentioned in this figure use BERT as the encoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>= . . . h [SEP] H 11 H 12 . . . H 1n . . . H ij . . . H m1 H m2 . . . H mn h [SEP] {t 1 , t 2 , . . . , t m } {o 1 , o 2 , . . . , o n }</figDesc><table><row><cell>&lt;not match&gt;, POS, NEU, NEG</cell><cell></cell></row><row><cell>o n R p Opinions Linear + softmax t m BERT Targets t 1 t i . . .</cell><cell>BERT</cell></row><row><cell>X = w 1 , w 2 , . . . , w l</cell><cell></cell></row><row><cell>Target and Opinion Extraction</cell><cell></cell></row><row><cell>[SEP] A 11 , A 12 . . . , A 1n , A 21 , A 22 , . . . , A 2n , A m1 , A m2 , . . . , A mn , [SEP] . . . , A ij , . . . ,</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Our target and opinion word extraction component is a sequence labeling model based on BERT (Devlin et al., 2018) with a B, I, O, E, S tagging system 1 , where there are four types of labels B, I, E, S with Target and Opinion (e.g., B ? Target), and 9 types in total for both target and opinion, as Sent. Pos. Neu. Neg. Sent. Pos. Neu. Neg. Sent. Pos. Neu. Neg. Sent. Pos. Neu. Neg.</figDesc><table><row><cell>Split</cell><cell></cell><cell cols="2">14Rest</cell><cell cols="2">14Lap</cell><cell cols="2">15Rest</cell><cell></cell><cell></cell><cell cols="2">16Rest</cell><cell></cell></row><row><cell>Train</cell><cell cols="2">1266 1692</cell><cell>166 480</cell><cell>906 817</cell><cell>126 517</cell><cell>605 783</cell><cell cols="2">25 205</cell><cell cols="2">857 1015</cell><cell cols="2">50 329</cell></row><row><cell>Dev</cell><cell>0,310</cell><cell>404</cell><cell>54 119</cell><cell>219 169</cell><cell>36 141</cell><cell>148 185</cell><cell>11</cell><cell>53</cell><cell>210</cell><cell>252</cell><cell>11</cell><cell>76</cell></row><row><cell>Test</cell><cell>0, 492</cell><cell>773</cell><cell>66 155</cell><cell>328 364</cell><cell>63 116</cell><cell>322 317</cell><cell cols="2">25 143</cell><cell>326</cell><cell>407</cell><cell>29</cell><cell>78</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics of 4 datasets from ASTE-DATA-V2, where Sent. denotes number of sentences, and Pos. Neu. Neg. denote numbers of positive, neutral and negative triplets respectively.</figDesc><table><row><cell></cell><cell cols="2">[CLS] Good</cell><cell>service</cell><cell></cell><cell>but</cell><cell cols="2">terrible taste</cell><cell>[SEP]</cell><cell>T-B service</cell><cell></cell><cell>T-B service</cell><cell></cell><cell>[SEP]</cell></row><row><cell>Position ID</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell></cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>5</cell><cell>24</cell></row><row><cell>Segment ID</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>CMLA+ 39.18 47.13 42.79 30.09 36.92 33.16 34.56 39.84 37.01 41.34 42.10 41.72 RINANTE+ 31.42 39.38 34.95 21.71 18.66 20.07 29.88 30.06 29.97 25.68 22.30 23.87 Li-unified-R 41.04 67.35 51.00 40.56 44.28 42.34 44.72 51.39 47.82 37.33 54.51 44.31 Peng et al. (2020) 43.24 63.66 51.46 37.38 50.38 42.87 48.07 57.51 52.32 46.96 64.24 54.21 OTE-MTL 63.07 58.25 60.56 54.26 41.07 46.75 60.88 42.68 50.18 65.65 54.28 59.42 GTS-BiLSTM 71.41 53.00 60.84 58.02 40.11 47.43 64.57 44.33 52.57 70.17 55.95 62.26 JET t 66.76 49.09 56.58 52.00 35.91 42.48 59.77 42.27 49.52 63.59 50.97 56.59 JET o 61.50 55.13 58.14 53.03 33.89 41.35 64.37 44.33 52.50 70.94 57.00 63.21 GTS + BERT 67.25 69.22 68.22 58.54 50.65 54.30 60.69 60.54 60.61 67.39 66.73 67.06 JET t + BERT 63.44 54.12 58.41 53.53 43.28 47.86 68.20 42.89 52.66 65.28 51.95 57.85 JET o + BERT 70.56 55.94 62.40 55.39 47.33 51.04 64.45 51.96 57.53 70.42 58.37 63.83 Ours 63.59 73.44 68.16 57.84 59.33 58.58 54.53 63.30 58.59 63.57 71.98 67.52</figDesc><table><row><cell>Models</cell><cell>P.</cell><cell>14Rest R.</cell><cell>F 1</cell><cell>P.</cell><cell>14Lap R.</cell><cell>F 1</cell><cell>P.</cell><cell>15Rest R.</cell><cell>F 1</cell><cell>P.</cell><cell>16Rest R.</cell><cell>F 1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Main results. P. and R. are Precision and Recall respectively. The best F 1 for each dataset have been bolded.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Original Framework 63.59 73.44 68.16 57.84 59.33 58.58 54.53 63.30 58.59 62.90 72.57 67.39 a) rm. Start Tags 57.95 70.42 63.58 48.59 57.30 52.59 50.00 59.59 54.37 57.82 71.21 63.82 b) rm. End Tags 55.78 68.41 61.46 43.57 55.08 48.65 46.19 60.00 52.20 58.53 71.40 64.33 c) rm. All Tags 40.09 64.29 49.38 41.62 56.01 47.75 36.33 55.05 43.77 42.72 68.48 52.62 d) rm. Tag Segment 51.32 72.33 60.04 43.24 59.70 50.16 47.68 61.44 53.69 55.11 71.40 62.20 e) rm. Tag Restricted Attn. 46.25 73.74 56.84 40.98 61.74 49.26 36.73 62.47 46.26 47.00 73.15 57.23 f) rm. All Restricted Attn. 43.51 73.24 54.59 41.74 59.33 49.01 34.43 60.21 43.81 43.28 71.40 53.89</figDesc><table><row><cell>Models</cell><cell>P.</cell><cell>14Rest R.</cell><cell>F 1</cell><cell>P.</cell><cell>14Lap R.</cell><cell>F 1</cell><cell>P.</cell><cell>15Rest R.</cell><cell>F 1</cell><cell>P.</cell><cell>16Rest R.</cell><cell>F 1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Results of ablation study, and rm. in this table means remove. The settings of all experiments are consistent with the main experiment.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Ours 70.18 59.07 64.15 68.36 69.54 68.95 OTE-MTL + BERT 64.33 42.15 50.93 59.37 43.68 50.33 JET o + BERT 60.49 37.55 46.34 67.59 41.95 51.77 JET t + BERT 59.62 35.63 44.60 68.00 29.31 40.96</figDesc><table><row><cell>Models</cell><cell>P.</cell><cell>14Lap R.</cell><cell>F 1</cell><cell>P.</cell><cell>15Rest R.</cell><cell>F 1</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">B, I, O, E, S denotes "B-begin", "I-inside", "O-outside", "E-end" and "S-single".</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We also investigated the one-to-many problem in which a word appears in multiple triplets in a sentence. We extract this part of the data for experiments, and the results are shown in <ref type="table">Table 4</ref>. It can be seen that in the one-to-many situation, our model also has significant performance advantages. Since our model utilizes the restricted attention field to isolate different target-opinion combinations of the same word, it will not be affected much in the complex scenario like one-to-many.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper utilize a two-stage framework for ASTE tasks. We first extract the target and opinion words by sequence labeling. Then, we use the perceivable pairs at the second stage to make target/opinion words aware the target-opnion-tuples they are currently in, which enhance the target-opinion correlation and further improve matching accuracy. Moreover, we use the compound computations to accelerate training and inference, and restricted attention field to reduce mutual interference. Results from detailed experiments show that our method achieves good performance on four datasets and gets more significant performance advantages in complex situations.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sentiment analysis of twitter data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilia</forename><surname>Vovsha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on language in social media (LSM 2011)</title>
		<meeting>the workshop on language in social media (LSM 2011)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="30" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.03750</idno>
		<title level="m">Neural aspect and opinion term extraction with mined rules as weak supervision</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Adaptive recursive neural network for target-dependent twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sentiment analysis using product review data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Techniques and applications for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronen</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="82" to="89" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large-scale sentiment analysis for news and blogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namrata</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manja</forename><surname>Srinivasaiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Icwsm</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="219" to="222" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A unified model for opinion target extraction and target sentiment prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6714" to="6721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Aspect term extraction with history attention and selective transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhimou</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00760</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Sentiment analysis and opinion mining. Synthesis lectures on human language technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Interactive attention networks for aspect-level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 26th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4068" to="4074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Knowing what, how and why: A near complete solution for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8600" to="8607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 4: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harris</forename><surname>Papageorgiou</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/S14-2004</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th international workshop on semantic evaluation</title>
		<meeting>the 8th international workshop on semantic evaluation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="27" to="35" />
		</imprint>
	</monogr>
	<note>Ion Androutsopoulos, and Suresh Manandhar</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Matching the blanks: Distributional similarity for relation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Livio Baldini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kwiatkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2895" to="2905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dependency graph enhanced dualtransformer structure for aspect-based sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiji</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6578" to="6588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Entity, relation, and event extraction with contextualized span representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulme</forename><surname>Wennberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.03546</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Coupled multi-layer attentions for co-extraction of aspect and opinion terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Grid tagging scheme for aspect-oriented fine-grained opinion extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengcan</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.234</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2576" to="2585" />
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Position-aware tagging for aspect sentiment triplet extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02609</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A multi-task learning framework for opinion triplet extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuchi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.01512</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep learning for sentiment analysis: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1253</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">End-to-end neural relation extraction with global optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guohong</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1730" to="1740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ernie: Enhanced language representation with informative entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1441" to="1451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Modeling sentiment dependencies with graph convolutional networks for aspect-level sentiment classification. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinlong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ou</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">105443</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suncong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexing</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05075</idno>
		<title level="m">Joint extraction of entities and relations based on a novel tagging scheme</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A frustratingly easy approach for entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zexuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12812</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
