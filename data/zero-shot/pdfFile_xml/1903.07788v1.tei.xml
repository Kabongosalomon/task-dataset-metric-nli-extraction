<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Probabilistic End-to-end Noise Correction for Learning with Noisy Labels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Yi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Probabilistic End-to-end Noise Correction for Learning with Noisy Labels</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning has achieved excellent performance in various computer vision tasks, but requires a lot of training examples with clean labels. It is easy to collect a dataset with noisy labels, but such noise makes networks overfit seriously and accuracies drop dramatically. To address this problem, we propose an end-to-end framework called PEN-CIL, which can update both network parameters and label estimations as label distributions. PENCIL is independent of the backbone network structure and does not need an auxiliary clean dataset or prior information about noise, thus it is more general and robust than existing methods and is easy to apply. PENCIL outperforms previous state-of-the-art methods by large margins on both synthetic and real-world datasets with different noise types and noise rates. Experiments show that PENCIL is robust on clean datasets, too.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep learning has shown very impressive performance on various vision problems, e.g., classification, detection and semantic segmentation. Although there are many factors for the success of deep learning, one of the most important is the availability of large-scale datasets with clean annotations like ImageNet <ref type="bibr" target="#b2">[3]</ref>.</p><p>However, collecting a large scale dataset with clean labels is expensive and time-consuming. On one hand, expert knowledge is necessary for some datasets such as the finegrained CUB-200 <ref type="bibr" target="#b25">[26]</ref>, which demands knowledge from ornithologists. On the other hand, we can easily collect a large scale dataset with noisy annotations through image search engines <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b19">20]</ref>. These noisy annotations can be obtained by extracting labels from the surrounding texts or using the searching keywords <ref type="bibr" target="#b27">[28]</ref>. For a huge dataset like JFT300M (which contains 300 million images), it is impossible to manually label it and inevitably about 20% noisy labels exist in this dataset <ref type="bibr" target="#b21">[22]</ref>. Hence, being able to deal with noisy labels is essential.</p><p>The label noise problem has been studied for a long time <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17]</ref>. Along with the recent successes of various deep learning methods, noise handling in deep learning has gained momentum, too <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b27">28]</ref>. However, existing methods often have prerequisites that may not be practical in many applications, e.g., an auxiliary set with clean labels <ref type="bibr" target="#b27">[28]</ref> or prior information about the noise <ref type="bibr" target="#b15">[16]</ref>. Some methods are very complex <ref type="bibr" target="#b28">[29]</ref>, which hurts their deployment capability. Overfitting to noise is another serious difficulty. For a DNN with enough capacity, it can memorize the random labels <ref type="bibr" target="#b29">[30]</ref>. Thus, some noise handling methods may finally still overfit and their performance decline seriously, i.e., they are not robust. Their accuracies on the clean test set reach a peak in the middle of the training process, but will degrade afterwards and the accuracies after the final training epoch are poor <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b23">24]</ref>.</p><p>We attack the label noise problem from two aspects. First, we model the label for an image as a distribution among all possible labels <ref type="bibr" target="#b5">[6]</ref> instead of a fixed categorical value. This probabilistic modeling lends us the flexibility to handle noise-contaminated and noise-free labels in a unified manner. Second, inspired by <ref type="bibr" target="#b22">[23]</ref>, we maintain and update the label distributions in both network parameter learning (in which label distributions act as labels) and label learning (in which label distributions are updated to correct noise). Unlike <ref type="bibr" target="#b22">[23]</ref> which updates labels simply by using the running average of network predictions, we correct noise and update our label distributions in a principled end-to-end manner. The proposed framework is called PENCIL, meaning probabilistic end-to-end noise correction in labels. The PENCIL framework only uses the noisy labels to initialize our label distributions, then iteratively correct the noisy labels by updating the label distributions, and the network loss function is computed using the label distributions rather than the noisy labels.</p><p>Our contributions are as follows.</p><p>noisy label handling. PENCIL is independent of the backbone network structure and does not need an auxiliary clean dataset or prior information about noise, thus it is easy to apply. PENCIL utilizes back-propagation to probabilistically update and correct image labels beyond updating the network parameters. To the best of our knowledge, PENCIL is the first method in this line.</p><p>? We propose a variant of the DLDL method <ref type="bibr" target="#b5">[6]</ref>, which is essential for correcting noise contained in our label distributions. PENCIL achieves state-of-the-art accuracy on datasets with both synthetic and real-world noisy labels (e.g., CIFAR-10, CIFAR-100 and Clothing1M).</p><p>? PENCIL is robust. It is not only robust in learning with noisy labels, but also robust enough to apply in datasets with zero or small amount of potential label noise (e.g., CUB-200) to improve accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>We first briefly introduce related works that inspired this work and other noise handling methods in the literature.</p><p>Deep label distribution learning was introduced in [6] (called DLDL), which was proposed to handle label uncertainty by converting a categorical label (e.g., 25 years old) into a label distribution (e.g., a normal distribution whose mean is 25 and standard deviation is 3). The DLDL method uses constant label distributions and the Kullback-Leibler divergence to compute the network loss. In PENCIL, we use label distributions for a different purpose such that the label distributions can be updated and hence noise can be probabilistically corrected. The original DLDL method did not work in our setup and we designed a new loss function in PENCIL to overcome this difficulty.</p><p>For deep learning methods, <ref type="bibr" target="#b29">[30]</ref> showed that a deep network with large enough capacity can memorize the training set labels even when they are randomly generated. Hence, they are particularly susceptible to noisy labels. Label noise can lead to serious overfitting and dramatically reduce network accuracy. However, <ref type="bibr" target="#b22">[23]</ref> observed that when the learning rate is high, DNNs may maintain relatively high accuracy (i.e., the impact of label noise is not significant). This observation was utilized in <ref type="bibr" target="#b22">[23]</ref> to maintain an estimate of the labels using the running average of network predictions with a large learning rate. Then, these estimates were used as supervision signals to train the network. PENCIL is inspired by this observation and <ref type="bibr" target="#b22">[23]</ref>, too.</p><p>Label noise is an important issue and has long been researched <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17]</ref>. There are mainly two types of label noise: symmetric noise and asymmetric noise, which are modeled in <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b20">[21]</ref>, respectively. <ref type="bibr" target="#b4">[5]</ref> is a survey of relatively early methods. <ref type="bibr" target="#b18">[19]</ref> argued that deep neural networks are inherently robust to label noise to some extent. And, deep methods have achieved state-of-the-art results in recent years. Hence, we mainly focus on noise handling in deep learning models in this section.</p><p>One intuitive and easy solution is to delete all the samples which are considered as unreliable <ref type="bibr" target="#b1">[2]</ref>. However, many difficult samples will be deleted, but these samples are important to algorithm's accuracy <ref type="bibr" target="#b7">[8]</ref>. Thus, more profound noisy label handling methods become necessary.</p><p>There are mainly two lines of attack to the the noisy label problem: constructing a special model based on noisy labels or using a robust loss function. The objective of these methods is to construct a noise-aware model which explicitly deals with noisy labels. <ref type="bibr" target="#b27">[28]</ref> constructed a model to deal with noisy labels, and tested their method on a real-world dataset collected by them. <ref type="bibr" target="#b23">[24]</ref> proposed a framework called CNN-CRF, which combined convolutional neural networks (CNN) with conditional random fields (CRF) to characterize noisy labels. <ref type="bibr" target="#b28">[29]</ref> utilized similar ideas to determine the confidence of each label. This approach is gaining popularity in recent years (e.g., in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b24">25]</ref>), and different techniques such as local inherent dimensionality have been brought into the noisy label learning domain.</p><p>Another effective approach is to design robust loss functions in order for a noise-tolerant model. Forward and backward methods <ref type="bibr" target="#b15">[16]</ref> explicitly modeled the noise transition matrix in loss computation. <ref type="bibr" target="#b6">[7]</ref> investigated the robustness of different loss functions, such as the mean squared loss, mean absolute loss and cross entropy loss. <ref type="bibr" target="#b30">[31]</ref> combined advantages of the mean absolute loss and cross entropy loss to obtain a better loss function.</p><p>[23] did not fall in these two categories. It is special in the sense that it replaced the noisy label with their own estimate of the label (i.e., running average of the network's predictions). This approach is effective in noise handling but ad-hoc. PENCIL is partly inspired by this work, but more principled and effective.</p><p>Existing methods usually have prerequisites that are impractical, such as demanding an additional clean dataset (e.g., to curb overfitting) or a groundtruth noise transition matrix. When these prerequisites are not satisfied, they often fail to produce robust models. These methods are sometimes too complex to be deployed in real-world applications. In contrast, the proposed PENCIL method does not require additional information, and it can be easily applied to any backbone network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Proposed PENCIL Method</head><p>First of all, we define the notations for our study. Column vectors are denoted in bold (e.g., x) and matrices in capital form (e.g., X). Specifically, 1 is a vector of all-ones. We use both hard labels and soft labels. The hard-label space is H = {y : y ? {0, 1} c , 1 y = 1}, and the soft-label space is S = {y : y ? [0, 1] c , 1 y = 1}. That is, a soft-label is a label distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Probabilistic modeling of noisy labels</head><p>In a c-class classification problem, we have a training set X = {x 1 , x 2 , . . . , x n }. In the ideal scenario, every image x i has a clean label y i ? H, which is a one-hot vector (i.e., equivalent to an integer between 1 and c). In our noisy label problem, the labels might be wrong with relatively high probability and we use? i ? H to denote labels which may contain noise. Using cross entropy, the loss function is</p><formula xml:id="formula_0">L = ? 1 n n i=1 c j=1? ij log f j (x i ; ?) ,<label>(1)</label></formula><p>where? ij is the j'th element of? i , f is a model's prediction (processed by the softmax function) and ? is the set of network parameters. In PENCIL, we maintain a label distribution y d i ? S = {y : y ? [0, 1] c , 1 y = 1} for every image x i , which is our estimate of the underlying noise-free label for x i . y d i is used as the pseudo-groundtruth label in our learning, which is initialized based on the noisy label? i . It is continuously updated (i.e., the noise is gradually corrected) through backpropagation. This probabilistic setting allows ample flexibility for noise correction. Note that our probabilistic modeling of the noisy labels is different from that in DLDL <ref type="bibr" target="#b5">[6]</ref>. Label distributions in DLDL are fixed and cannot be updated.</p><p>In <ref type="bibr" target="#b5">[6]</ref>, the loss function is KL-divergence:</p><formula xml:id="formula_1">L = 1 n n i=1 KL(y d i ||f (x i ; ?)), and<label>(2)</label></formula><formula xml:id="formula_2">KL(y d i ||f (x i ; ?)) = c j=1 y d ij log y d ij f j (x i ; ?) .<label>(3)</label></formula><p>This loss is used in <ref type="bibr" target="#b22">[23]</ref>, too. However, KL-divergence is an asymmetric function. Hence, if we exchange the two operands in Eq. 2, we obtain a new loss function</p><formula xml:id="formula_3">L = 1 n n i=1 KL(f (x i ; ?)||y d i ), and<label>(4)</label></formula><formula xml:id="formula_4">KL(f (x i ; ?)||y d i ) = c j=1 f j (x i ; ?) log f j (x i ; ?) y d ij .<label>(5)</label></formula><p>We will soon show that Eq. 4 is more suitable for noise handling. In fact, Eq. 2 led to very poor results in our experiments and we propose to use Eq. 4 as one of the loss functions in PENCIL. More details will be discussed in Section 3.4.  <ref type="figure" target="#fig_1">Figure 1</ref>. The PENCIL learning framework. We use label distributions y d (which is the softmax transformed version of label initialization variables?) to replace noisy labels?. The label distributions are updated in every iteration using three loss functions, among which the classification loss and compatibility loss updates y d by requiring the label distributions produce both smooth models and not too distant from the noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">End-to-end noise correction in labels</head><p>Our label distribution y d models the unknown noise-free label for x i . Hence, we need to estimate these distributions in our learning process. Let X and Y d be the union of x i and y d i (for all 1 ? i ? n), respectively. Inspired by <ref type="bibr" target="#b22">[23]</ref>, we let Y d be part of the parameters that are to be updated in the back-propagation process. That is, PENCIL not only updates the network parameters ? as in traditional networks, but also updates Y d (i.e., y d i ) in every iteration. Therefore, we optimize both network parameters and label distributions as follows: min</p><formula xml:id="formula_5">?,Y d L(?, Y d |X)<label>(6)</label></formula><p>The overall architecture of PENCIL is shown in <ref type="figure" target="#fig_1">Fig. 1</ref>.</p><p>In the PENCIL framework, three types of "labels" (y d , y and?) are involved. Label distribution y d is updated by back-propagation. In the end, y d will be a good estimate of the underlying unknown noise-free label (i.e., noise corrected label).? is a variable that assists y d to be normalized to a probability distribution, by</p><formula xml:id="formula_6">y d = softmax(?) .<label>(7)</label></formula><p>Hence,? is not constrained and can be updated freely using back-propagation, but y d is always a valid distribution. The original noisy label? does not directly impact the parameter (?) learning. However, it is useful because we use it to indirectly initialize our label distribution y d . At the start of PENCIL,? is initialized by? as follows:</p><formula xml:id="formula_7">y = K? ,<label>(8)</label></formula><p>where K is a large constant (K = 10 in our experiments), and hence from Eq. 7 we have y d ?? after this initialization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Compatibility loss</head><p>The noisy label? is also useful in PENCIL's loss computation. In fact, there are lots of (e.g., 80% of) correct labels even in datasets with noisy labels. Therefore, we should not let the estimated label distribution y d be completely different from those noisy labels?.</p><p>We define a compatibility loss L o (? , Y d ) to enforce this requirement, as</p><formula xml:id="formula_8">L o (? , Y d ) = ? 1 n n i=1 c j=1? ij log y d ij ,<label>(9)</label></formula><p>which is a classic cross entropy loss between label distribution and noisy label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Classification loss</head><p>The deviation between our label distribution y d and the network prediction f (x; ?) guides how the network parameters ? should be updated. In DLDL <ref type="bibr" target="#b5">[6]</ref> and a similar work <ref type="bibr" target="#b22">[23]</ref>, the classic KL-loss (Eq. 2) is used to calculate the distance between these two distributions. However, we find that Eq. 2 works poorly in PENCIL and propose to use Eq. 4 instead, as a new classification loss (which we denote as L c ).</p><p>Because we need to update the label distribution, we need to calculate ?Lc ?y d . If Eq. 2 is used as the classification loss L c , then ?L c</p><formula xml:id="formula_9">?y d ij = 1 + c j=1 log y d ij f j (x i ; ?) .<label>(10)</label></formula><p>And, if we use Eq. 4 as L c , we have</p><formula xml:id="formula_10">?L c ?y d ij = ? c j=1 f j (x i ; ?) y d ij .<label>(11)</label></formula><p>Then, we have the following observations for a fixed training example i and any class index j.</p><p>Case 1 If the prediction f j (x i ; ?) is much larger than label distribution y d ij , Eq. 10 leads to a medium negative gradient (because of the log), but Eq. 11 leads to a large negative gradient for updating y d ij .</p><p>Case 2 If f j (x i ; ?) is much smaller than y d j , Eq. 10 leads to a medium positive gradient while Eq. 11 leads to a gradient which is almost zero.</p><p>Suppose for x i the noisy label? i is peaked at j = 3 (i.e.,? i,3 = 1) but the true label is 7. Thus, initially y d i,3</p><p>will be the peak in our label distribution y d i . The internal smoothness inside the network may make the prediction f (x i ; ?) to (correctly) peak at j = 7. Hence, we have <ref type="bibr" target="#b2">3</ref> . Eq. 4 (Eq. 11) will then (correctly) increase y d i,7 by a large amount, while Eq. 2 (Eq. 10) will not (Case 1). Now consider the updating of y d i,3 . Eq. 2 (Eq. 10) will only decrease y d i,3 by a medium amount, and Eq. 4 (Eq. 11) will keep y d i,3 almost intact (Case 2). Combining these observations altogether, we believe that although the classic KL-loss (Eq. 2) is a good fit for other applications, our proposed Eq. 4 is more suitable for correcting the noise in labels. Hence, we use the variant of KL-loss in Eq. 4 as our classification loss L c .</p><formula xml:id="formula_11">f 7 (x i ; ?) ? i,7 and f 3 (x i ; ?) ? i,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Entropy loss</head><p>Obviously, when the prediction f (x; ?) is the same as the label distribution y d , the network will stop updating. However, f (x; ?) tend to approach y d fairly quickly, because label distributions are used as the supervision signal for learning network parameters ?. Following <ref type="bibr" target="#b22">[23]</ref>, we add an additional loss (regularization) term to avoid this problem. The entropy loss can force the network to peak at only one category rather than being flat because the one-hot distribution has the smallest possible entropy value. This property is advantageous for classification problems. The entropy loss is defined as</p><formula xml:id="formula_12">L e (f (x; ?)) = ? 1 n n i=1 c j=1 f j (x; ?) log f j (x; ?) .<label>(12)</label></formula><p>At the same time, it also helps avoid the training from being stalled in our PENCIL framework, because the label distribution is not going to be a one-hot distribution and then f (x; ?) will be different from y d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">The overall PENCIL framework</head><p>With all components ready, the PENCIL loss function is</p><formula xml:id="formula_13">L = 1 c L c (f (x; ?), Y d ) + ?L o (? , Y d ) + ? c L e (f (x; ?)) ,</formula><p>in which ? and ? are two hyperparameters. Using this loss function and the PENCIL framework's architecture in <ref type="figure" target="#fig_1">Fig. 1</ref>, we can use any deep neural network as the backbone network in <ref type="figure" target="#fig_1">Fig. 1</ref>, and then equip it with the PENCIL network to handle learning problems with noisy labels. The relationship between variables and loss functions are clearly visualized in <ref type="figure" target="#fig_1">Fig. 1</ref> as arrows. Forward computations are visualized by red solid arrows, while back-propagation computations are visualized as blue dashed arrows. The algorithmic description of the PENCIL framework is shown in Algorithm 1. We want to add two notes about PENCIL. First, the error back-propagation process in PENCIL is pretty straightforward. For example, it can be done automatically in deep learning packages that support automatic gradient computation. Second, after the network has been fully trained (cf. Section 4), those PENCIL-related components in <ref type="figure" target="#fig_1">Fig. 1</ref> are not needed at all-the backbone network alone can perform prediction for future test examples. Similar to <ref type="bibr" target="#b22">[23]</ref>, we implement our PENCIL training through 3 steps.</p><p>Backbone learning: We firstly train the backbone network with a large fixed learning rate from scratch without noise handling. As aforementioned, it is observed that when the learning rate is high, a DNN often does not overfit the label noise. Therefore, in this step, we use a fixed high learning rate with only the cross-entropy loss function in Eq. 1. The resulted DNN is the backbone network in <ref type="figure" target="#fig_1">Fig. 1</ref>.</p><p>PENCIL learning: Then, we use the PENCIL framework to update both network parameters and label distributions. The learning rate is still a fixed high value. Therefore, the network will not overfit label noise and the label distributions will correct noise in the original labels. At the end of this step, we obtain a label distribution vector for every image. Algorithmic details are shown in Algorithm 1. Note that in practice we find that updating? requires a learning rate that is much larger than that used for updating other parameters. Because the overall learning rate is fixed in this step, we simply use one single hyperparameters ? to updat? y (i.e., do not use PENCIL's overall learning rate), as</p><formula xml:id="formula_14">y ?? ? ? ?L ?? .<label>(13)</label></formula><p>Final fine-tuning: Lastly, we use the learned label distributions to fine-tune the network using only the classification loss L c (i.e., ? = ? = 0). In this step, the label distributions will not be updated and the learning rate will be gradually reduced as in common neural network training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We tested the proposed PENCIL framework on both synthetic and real-world datasets: CIFAR-100 <ref type="bibr" target="#b11">[12]</ref>, CIFAR-10 <ref type="bibr" target="#b11">[12]</ref>, CUB-200 <ref type="bibr" target="#b25">[26]</ref> and Clothing1M <ref type="bibr" target="#b27">[28]</ref>. All experiments were implemented using the PyTorch framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>CIFAR-100: Following <ref type="bibr" target="#b30">[31]</ref>, we retained 10% of the training data as the validation set, and both train and val-idation sets were noise contaminated. However, note that we did not use the validation set in our method, because PENCIL does not need a validation set.</p><p>There are two types of noises: symmetric and asymmetric. Following <ref type="bibr" target="#b30">[31]</ref>, in the symmetric noise setup, label noise is uniformly distributed among all categories, and the label noise percentage is r ? [0, 1]. For every example, if the correct label is i, then the noise-contaminated label has 1 ? r probability to remain correct, but has r probability to be drawn uniformly from the c labels. The asymmetric noise label was generated by flipping each class to the next class circularly with noise rate r ? [0, 1].</p><p>CIFAR-10: Following <ref type="bibr" target="#b22">[23]</ref>, we retained 10% of the CIFAR-10 training data as the validation set and modify the original correct labels to obtain different noisy label datasets. The setting for symmetric noise is the same as that in CIFAR-100. As for asymmetric noise, following <ref type="bibr" target="#b15">[16]</ref> the noisy labels were generated by mapping truck ? automobile, bird? airplane, deer ? horse and cat ? dog with probability r. These noise generation methods are in coincidence with confusions that often happen in the real world.</p><p>Clothing1M: Clothing1M is a large-scale dataset with noisy labels. It consists of more than one million images from 14 classes with many wrong labels. Images were obtained from several online shopping websites and labels were generated by their surrounding texts. The estimated noise level is roughly 40% <ref type="bibr" target="#b27">[28]</ref>. This dataset is seriously imbalanced and the label mistakes mostly happen between similar classes (i.e., asymmetric). There exist additional training, validation and test sets with 50k, 14k and 10k examples whose labels are believed to be clean, respectively.</p><p>CUB-200: We tested the robustness of our framework in a fine-grained classification dataset CUB-200. CUB-200 contains 11788 images of 200 species of birds, which is not considered to have the noisy label difficulty. Therefore, we tested our framework on this dataset to show that PENCIL is robust. In addition, there is probably a small percentage of noisy labels in CUB-200 <ref type="bibr" target="#b26">[27]</ref>. It is interesting to observe whether PENCIL is robust and effective in such a dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation details</head><p>Next, we describe more implementation details for each dataset.</p><p>CIFAR-100: We used ResNet-34 <ref type="bibr" target="#b8">[9]</ref> as the backbone network for fair comparison with existing methods. The learning rate was 0.35, ? = 0.1, ? = 0.4, and ? = 10000. Mean subtraction, horizontal random flip and 32?32 random crops after padding 4 pixels on each side were performed as data preprocessing and augmentation. We used SGD with 0.9 momentum, a weight decay of 10 ?4 , and batch size of 128. Following <ref type="bibr" target="#b22">[23]</ref>, the epoch numbers for three steps were 70, 130 and 120, respectively. In the last step, we used the learning rate of 0.2 and divided it by 10 after 40 and 80 epochs <ref type="bibr" target="#b22">[23]</ref>. All experiments on CIFAR-100 used the same settings as described above. In fact, we can obtain better results by further tuning the hyperparameters (e.g., as what we will soon introduce for CIFAR-10). However, we choose to use the same set of hyperparameters to demonstrate the robustness of our framework. CIFAR-10: We used PreAct ResNet-32 <ref type="bibr" target="#b9">[10]</ref> as the backbone network for fair comparison with existing methods. We used the same settings as those for CIFAR-100, except the overall learning rate, ?, ? and ? hyperparameters. On CIFAR-10, these hyperparameters are shown in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>As shown in <ref type="table" target="#tab_0">Table 1</ref>, the learning rate increases as the noise rate increases for symmetric noise. This is reasonable, because when noise rate gets higher, we need stronger robustness and we can increase the learning rate to prevent our network from overfitting. And, when the noise rate is very high (e.g., 50% asymmetric), there are too many noisy labels. Hence, we can remove the effect of noisy labels by removing L o (i.e., set ? to 0). At the same time, we require a large ? to correct these noisy labels quickly. However, after a few epochs, the noisy labels were quickly corrected to a stable state (cf. <ref type="figure" target="#fig_3">Fig. 2 and Fig. 3</ref>). Hence, we need to decrease ? linearly to prevent wrong updates in later epochs.</p><p>CUB-200: On this dataset, we used ResNet-50 <ref type="bibr" target="#b8">[9]</ref> pretrained on ImageNet. Data preprocessing and augmentation is also applied, including performing mean subtraction, horizontal random flip, resizing the image to 256 ? 256 and 224 ? 224 random crops. We used SGD with 0.9 momentum, a weight decay of 10 ?4 , and batch size of 16. The number of epochs for the three steps are 35, 65 and 60, respectively. The learning rate of the first and second step is 2 ? 10 ?3 . In the last step, the learning rate is 10 ?3 and divided by 10 after 20 epochs and 40 epochs. ? is 0.8 and we reported results for different values of ? and ? as ablation studies.</p><p>Clothing1M: We used ResNet-50 pre-trained on Ima-geNet as the backbone network for fair comparison with existing methods. Data preprocessing and augmentation are the same as those in CUB-200. We used SGD with 0.9 momentum, a weight decay of 10 ?3 , and batch size of 32. The epoch numbers of three steps are 5, 10 and 10, respectively. The first step learning rate is 1.6 ? 10 ?3 and the second step learning rate is 8 ? 10 ?4 . The last step learning rate is 5 ? 10 ?4 and divided by 10 after 5 epochs. ? = 0.08, ? = 0.8. In first 5 epochs of second step ? = 3000, and in last 5 epochs of second step ? = 500.</p><p>This dataset exists serious data imbalance. Therefore, we randomly selected a small balanced subset (using the noisy labels) to relieve the difficulty caused by imbalance. The small subset includes about 260k images and all classes have the same number of images. All our experiments on Cloth-ing1M were done with this subset in this study. However, note that this subset is not truly balanced, because the labels are noisy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results on CIFAR-100</head><p>Firstly we tested PENCIL on CIFAR-100. The results are shown in <ref type="table">Table 2</ref>. All dataset settings followed <ref type="bibr" target="#b30">[31]</ref>. The method "Forward T <ref type="bibr" target="#b15">[16]</ref>" used the groundtruth noise transition matrix (which is not available in real-world datasets), hence its numbers were not compared with other methods. Except for the 80% symmetric noise case, PENCIL significantly outperformed previous methods in all symmetric and asymmetric noise cases. Even if "Forward T " used strong prior information which should not have been used, our PENCIL method still outperformed it in most cases.</p><p>As for the 80% symmetric noise case, it revealed a failure mode of the proposed PENCIL method. When the noise rate is too high (e.g., 80%), the correct labels only form a minority group and they are too weak to bootstrap the noise correction process. Hence, PENCIL tends to fail in such high noise rate problems. Fortunately, we hardly deal with such high noise rate in real-world applications. For example, the large scale real-world image dataset JFT300M <ref type="bibr" target="#b21">[22]</ref> only includes about 20% noisy labels.</p><p>We have intentionally chosen the same set of hyperparameters in all experiments on this dataset, and the results demonstrate the robustness of our PENCIL framework to these hyperparameters. We can obtain better accuracy by using different hyperparameters for different noise rate and noise type, as shown in <ref type="table" target="#tab_0">Table 1</ref> on the CIFAR-10 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Experiments on CIFAR-10</head><p>Next, we evaluated the performance of our PENCIL framework on CIFAR-10. All the settings have been described in Section 4.2. On the original noise-free CIFAR-10 dataset, the result of our backbone network (PreAct ResNet-32) is 94.05%. Our setup followed that in <ref type="bibr" target="#b22">[23]</ref>. However, results in <ref type="bibr" target="#b22">[23]</ref> used a prior knowledge (i.e., all categories have the same number of noise-free training examples), which <ref type="table">Table 2</ref>. Results on CIFAR-100. We report the average accuracy and standard deviation of 5 trials. #1 to #5 are quoted from <ref type="bibr" target="#b30">[31]</ref>. PENCIL (#6) is the result of last epoch (without using the validation set). The row with a star * (#2) did not participate in comparison for fairness.  should not be used. For fair comparison, we implemented the "Tanaka et al. <ref type="bibr" target="#b22">[23]</ref>" method and in our implementation we did not use this prior knowledge. <ref type="table" target="#tab_2">Table 3</ref> lists results of symmetric noise for CIFAR-10. In <ref type="table" target="#tab_2">Table 3</ref>, "best" denotes the test accuracy of the epoch where the validation accuracy was optimal and "last" denotes the test accuracy of the last epoch. As aforementioned, when the learning rate is small, the deep neural network's accuracy will decline because the network memorizes all the (noisy) labels, i.e., the network is overfitting. As shown in row #1, the traditional neural network using the classic cross entropy loss is heavily affected by this difficulty. Its bestepoch test accuracy was significantly better than that of the last-epoch one. And, as the noise rate increased, the gap was even larger because the overfitting to noise became more serious as expected. On the contrary, our method and the Tanaka et al. <ref type="bibr" target="#b22">[23]</ref> did not have obvious accuracy drop between bestand last-epochs. Therefore, the proposed PENCIL method has strong robustness. As for the test set accuracy, PENCIL had a clear advantage than competing methods in <ref type="table" target="#tab_2">Table 3</ref>. The winning gap became especially apparent when the noise rate increased to larger values. For example, when the noise rate was 90%, PENCIL obtained roughly 7% higher accuracy than that of Tanaka et al. and 10% higher than that of cross entropy. <ref type="table">Table 4</ref> lists results of asymmetric noise for CIFAR-10. In terms of robustness, methods shown in row #1, #2 and #3 had the overfitting problem and their test accuracies had large gaps between the bestand last-epochs. The Tanaka et al. method experienced the same issue when the noise rate was high (50%), but was robust in other cases. Our PENCIL method, however, remained robust throughout <ref type="table">Table 4</ref>. Test accuracy on CIFAR-10 with asymmetric noise. We reported the average result of 5 trials. Rows #1, #4 and #5 were based on our own implementation. Rows #2 and #3 were quoted from <ref type="bibr" target="#b22">[23]</ref>. The methods marked with a "*" used additional information that should not be used, and need to be excluded in a fair comparison. all the experiments. The Forward <ref type="bibr" target="#b15">[16]</ref> and CNN-CRF <ref type="bibr" target="#b23">[24]</ref> methods both require the ground-truth noise transition matrix, which is hardly available in applications. Our method does not require any prior information about noise labels. <ref type="table">Table 4</ref> shows that PENCIL has been robust and is the overall accuracy winner on CIFAR-10.</p><p>We recorded the number of correct labels in PENCIL's second step. In a label distribution vector, the category corresponding to the maximum value in the probability distribution was identified as the label estimated by PENCIL. If this label was the same as the noise-free groundtruth label, we say it was correct. The results for 70% symmetric and 30% asymmetric noise on CIFAR-10 are shown in <ref type="figure" target="#fig_3">Fig. 2</ref> and <ref type="figure" target="#fig_5">Fig. 3</ref>, respectively. We can observe that PENCIL effectively and stably estimated correct labels for most examples even with high noise rates. For example, with 70% symmetric noise rate, originally only about 16000 labels were correct, but after PENCIL's learning process there are about 39000 correct labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Experiments on CUB-200</head><p>We performed additional experiments on CUB-200 with different hyperparameters ? and ?. This dataset is generally considered to contain no or only few noisy labels. Therefore, we use it to further test the robustness of PENCIL on    problems not affected by noisy labels.</p><p>The results are listed in <ref type="table" target="#tab_4">Table 5</ref>. Row #1 is the baseline (classic method) and rows #2 to #7 are PENCIL results. For a wide range of ? and ? values, PENCIL consistently exhibited competitive results (i.e., without obvious degradation). Furthermore, we observed the final label distributions, and the maximum values of all label distributions are correct (i.e., same as the correct labels). This observation shows that PENCIL works robustly in clean datasets, too.</p><p>In the settings of rows #4 to #7, PENCIL achieved higher accuracy than the baseline. In particular, row #4 is 0.71% higher. A small percentage of label noise may exist in this dataset <ref type="bibr" target="#b26">[27]</ref>. Our hypothesis is that by replacing the original one-hot label with probabilistic modeling in PENCIL, we obtained better robustness and consequently a small edge in accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Experiments on Clothing1M</head><p>Finally, we tested PENCIL on Clothing1M, which is a real-world noisy label dataset. It includes a lot of unknown structure (asymmetric) noise.</p><p>The results are shown in <ref type="table">Table 6</ref>. All results are best test accuracy. Rows #1 and #2 were quoted from <ref type="bibr" target="#b15">[16]</ref>, and row #3 was reported in <ref type="bibr" target="#b22">[23]</ref>. Although these baseline models were trained on the whole Clothing1M training set, our PENCIL used a randomly sampled pseudo-balanced subset, including about 260k images. The backbone network was ResNet-50 for all methods.  <ref type="table">Table 6</ref>. Test accuracy on the Clothing1M dataset. Rows #1 and #2 were quoted from <ref type="bibr" target="#b15">[16]</ref> and #3 was quoted from <ref type="bibr" target="#b22">[23]</ref>. These baseline methods used the complete Clothing1M training data, but our method only used a small pseudo-balanced subset (i.e., balanced in terms of noisy labels). Our method achieved state-ofthe-art result in this real-world dataset. In <ref type="table">Table 6</ref>, only noisy labeled examples were used (i.e., without using the clean training subset). The Forward <ref type="bibr" target="#b15">[16]</ref> method required the ground-truth noise transition matrix, which is not available. Hence, it used an estimated matrix instead. The Tanaka et al. <ref type="bibr" target="#b22">[23]</ref> method used the distribution of noisy labels to relieve the imbalanced problem. In our PENCIL method, we did not use any extra prior information. PENCIL achieved 1.33% higher accuracy than that of Tanaka et al. <ref type="bibr" target="#b22">[23]</ref>, 3.65% higher than Forward <ref type="bibr" target="#b15">[16]</ref> and 4.55% than cross entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We proposed a framework named PENCIL to solve the noisy label problem. PENCIL adopted label probability distributions to supervise network learning and to update these distributions through back-propagation end-to-end in every epoch. We proposed a KL-loss, which is different from previous methods but is robust for noisy label handling. The proposed PENCIL framework is end-to-end and independent of the backbone network structure, thus it is easy to deploy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1</head><label>1</label><figDesc>The proposed PENCIL framework Input: the noisy training set {x i ,? i } (1 ? i ? n), and the number of training epochs T1: initialize? i (1 ? i ? n) by Eq. 8 2: t ? 1 3: while t ? T do 4:update ? and y d i (1 ? i ? n) by forward computation and backward propagation in the mini-batch fashion using all n training examples (i.e., to finish one epoch)5:    t ? t + 1 Output: the trained network model ?, and the noise corrected labels y d i (1 ? i ? n).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Correct labels on CIFAR-10 with 70% symmetric noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 .</head><label>3</label><figDesc>Correct labels on CIFAR-10 with 30% asymmetric noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Hyperparameters for CIFAR-10 experiments. 3000 ? 0 means that ? decreases from 3000 to 0 linearly.</figDesc><table><row><cell></cell><cell cols="2">Symmetric Noise</cell><cell></cell><cell></cell></row><row><cell>noise rate (%)</cell><cell>learning rate</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>10</cell><cell>0.02</cell><cell cols="2">0.1 0.8</cell><cell>200</cell></row><row><cell>30</cell><cell>0.03</cell><cell cols="2">0.1 0.8</cell><cell>300</cell></row><row><cell>50</cell><cell>0.04</cell><cell cols="2">0.1 0.8</cell><cell>400</cell></row><row><cell>70</cell><cell>0.08</cell><cell cols="2">0.1 0.8</cell><cell>800</cell></row><row><cell>90</cell><cell>0.12</cell><cell cols="2">0.1 0.4</cell><cell>1200</cell></row><row><cell></cell><cell cols="2">Asymmetric Noise</cell><cell></cell><cell></cell></row><row><cell>noise rate (%)</cell><cell>learning rate</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>10</cell><cell>0.06</cell><cell cols="2">0.1 0.4</cell><cell>600</cell></row><row><cell>20</cell><cell>0.06</cell><cell cols="2">0.1 0.4</cell><cell>600</cell></row><row><cell>30</cell><cell>0.06</cell><cell cols="2">0.1 0.4</cell><cell>600</cell></row><row><cell>40</cell><cell>0.03</cell><cell>0</cell><cell cols="2">0.4 3000 ? 0</cell></row><row><cell>50</cell><cell>0.03</cell><cell>0</cell><cell cols="2">0.4 4000 ? 0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Cross Entropy Loss 58.72?0.26 48.20?0.65 37.41?0.94 18.10?0.82 66.54?0.42 59.20?0.18 51.40?0.16 42.74?0.61 2 Forward T * [16] 63.16?0.37 54.65?0.88 44.62?0.82 24.83?0.71 71.05?0.30 71.08?0.22 70.76?0.26 70.</figDesc><table><row><cell>#</cell><cell>method</cell><cell></cell><cell cols="2">Symmetric Noise</cell><cell></cell><cell></cell><cell cols="2">Asymmetric Noise</cell></row><row><cell></cell><cell>noise rate (%)</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>80</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell></row><row><cell cols="10">1 82?0.45</cell></row><row><cell>3</cell><cell>ForwardT [16]</cell><cell cols="3">39.19?2.61 31.05?1.44 19.12?1.95</cell><cell>8.99?0.58</cell><cell cols="4">45.96?1.21 42.46?2.16 38.13?2.97 34.44?1.93</cell></row><row><cell>4</cell><cell>Lq [31]</cell><cell cols="4">66.81?0.42 61.77?0.24 53.16?0.78 29.16?0.74</cell><cell cols="4">68.36?0.42 66.59?0.22 61.45?0.26 47.22?1.15</cell></row><row><cell>5</cell><cell>Trunc Lq [31]</cell><cell cols="3">67.61?0.18 62.64?0.33 54.04?0.56</cell><cell>29.60?0.51</cell><cell cols="4">68.86?0.14 66.59?0.23 61.87?0.39 47.66?0.69</cell></row><row><cell>6</cell><cell>PENCIL (last)</cell><cell cols="3">73.86?0.34 69.12?0.62 57.79?3.86</cell><cell>fail</cell><cell cols="4">75.93?0.20 74.70?0.56 72.52?0.38 63.61?0.23</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Test accuracy on CIFAR-10 with symmetric noise. We reported the average result of 5 trials. All results in this table were based on our own implementation.</figDesc><table><row><cell>#</cell><cell>method</cell><cell></cell><cell cols="2">Symmetric Noise</cell><cell></cell></row><row><cell></cell><cell>noise rate (%)</cell><cell>10</cell><cell>30</cell><cell>50</cell><cell>70</cell><cell>90</cell></row><row><cell cols="2">1 Cross Entropy Loss</cell><cell cols="5">best 91.66 89.00 85.15 78.09 50.74 last 88.43 72.78 53.11 33.32 16.30</cell></row><row><cell>2</cell><cell>Tanaka et al. [23]</cell><cell cols="5">best 93.23 91.23 88.50 84.51 54.36 last 93.23 91.22 88.51 84.59 53.49</cell></row><row><cell>3</cell><cell>PENCIL</cell><cell cols="5">best 93.26 92.09 90.29 87.10 61.21 last 93.28 92.24 90.36 87.18 60.80</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Tanaka et al. [23] best 92.53 91.89 91.10 91.48 75.81 last 92.64 91.92 91.18 91.55 68.35 5 PENCIL best 93.00 92.43 91.84 91.01 80.51 last 93.04 92.43 91.80 91.16 80.06</figDesc><table><row><cell>#</cell><cell>method</cell><cell></cell><cell cols="2">Asymmetric Noise</cell><cell></cell></row><row><cell></cell><cell>noise rate (%)</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>50</cell></row><row><cell cols="2">1 Cross Entropy Loss</cell><cell cols="5">best 91.09 89.94 88.78 87.78 77.79 last 85.24 80.74 76.09 76.12 71.05</cell></row><row><cell>2</cell><cell>Forward T * [16]</cell><cell cols="5">best 92.4 91.4 91.0 90.3 83.8 last 91.7 89.7 88.0 86.4 80.9</cell></row><row><cell>3</cell><cell>CNN-CRF * [24]</cell><cell cols="5">best 92.0 91.5 90.7 89.5 84.0 last 90.3 86.6 83.6 79.7 76.4</cell></row><row><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Test accuracy on CUB-200 with different hyperparameters. The accuracy of PENCIL does not decline in standard datasets with clean labels.</figDesc><table><row><cell>#</cell><cell>method</cell><cell></cell><cell>Test Accuracy (%)</cell></row><row><cell>1</cell><cell cols="2">Cross Entropy Loss</cell><cell>81.93</cell></row><row><cell></cell><cell>PENCIL</cell><cell></cell><cell></cell></row><row><cell></cell><cell>?</cell><cell>?</cell><cell></cell></row><row><cell>2</cell><cell>1000</cell><cell>0</cell><cell>81.91</cell></row><row><cell>3</cell><cell>2000</cell><cell>0</cell><cell>81.84</cell></row><row><cell>4</cell><cell>3000</cell><cell>0</cell><cell>82.64</cell></row><row><cell>5</cell><cell>1000</cell><cell>0.1</cell><cell>82.09</cell></row><row><cell>6</cell><cell>2000</cell><cell>0.1</cell><cell>82.21</cell></row><row><cell>7</cell><cell>3000</cell><cell>0.1</cell><cell>82.22</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We tested PENCIL with synthetic label noise on CIFAR-100 and CIFAR-10 with different noise types and noise rates, and outperformed current state-of-the-art methods by large margins. We also experimented on CUB-200, which is considered to be noise free. The results show that PENCIL is robust for different datasets and hyperparameters. Lastly, we tested PENCIL on the real-world large scale label noise dataset Clothing1M. On this dataset, we achieved 1.33% higher accuracy than previous state-of-the-art.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning from noisy examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dana</forename><surname>Angluin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">D</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="343" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Identifying mislabeled training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carla</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Friedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="131" to="167" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning object categories from Internet image searches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beno?t</forename><surname>Fr?nay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learning Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="845" to="869" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep label distribution learning with label ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bin-Bin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Wei</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2825" to="2838" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aritra</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1919" to="1925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discovering informative patterns and data cleaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nada</forename><surname>Matic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="181" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of noisy data for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Howard</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Duerig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">9907</biblScope>
			<biblScope unit="page" from="301" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Design of robust neural network classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><forename type="middle">Nonboe</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mads</forename><surname>Hintz-Madsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><forename type="middle">Kai</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="1205" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">CleanNet: Transfer learning for scalable image classifier training with label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuang-Huei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5447" to="5456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dimensionality-driven learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu-Tao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Sudanthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3355" to="3364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Induction of decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="106" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Training deep neural networks on noisy labels with bootstrapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Deep learning is robust to massive label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nir</forename><surname>Shavit</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10694</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Harvesting image databases from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="754" to="766" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2080</idno>
		<title level="m">Training convolutional networks with noisy labels</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Revisiting unreasonable effectiveness of data in deep learning era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiki</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiki</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoharu</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="5552" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Toward robustness against label noise in training deep discriminative neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="5601" to="5610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Iterative learning with open-set noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu-Tao</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8688" to="8696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Caltech-UCSD Birds 200</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno>CNS-TR-2010-001</idno>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning concept embeddings with combined human-machine expertise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Wilber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iljung</forename><forename type="middle">S</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="981" to="989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep learning from noisy image labels with quality embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangchao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mert</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
