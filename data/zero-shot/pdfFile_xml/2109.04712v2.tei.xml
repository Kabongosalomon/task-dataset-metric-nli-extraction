<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Balancing Methods for Multi-label Text Classification with Long-Tailed Class Distribution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Huang</surname></persName>
							<email>yi.huang.yh4@roche.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roche</forename><surname>M?stahzarlar?</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Turkey</roleName><forename type="first">San</forename><forename type="middle">A ?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdullatif</forename><surname>K?ksal</surname></persName>
							<email>abdullatif.koksal@boun.edu.tr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arzucan</forename><surname>?zg?r</surname></persName>
							<email>arzucan.ozgur@boun.edu.tr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elif</forename><surname>Ozkirimli</surname></persName>
							<email>elif.ozkirimli@roche.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Data and Analytics Chapter</orgName>
								<orgName type="institution">Roche (China) Holding Ltd</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering</orgName>
								<orgName type="institution">Bogazici University</orgName>
								<address>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Computer Engineering</orgName>
								<orgName type="institution">Bogazici University</orgName>
								<address>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Data and Analytics Chapter F. Hoffmann-La Roche AG</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Balancing Methods for Multi-label Text Classification with Long-Tailed Class Distribution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Buse Giledereli Computer Engineering Bogazici University, Turkey Data and Analytics Chapter</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-label text classification is a challenging task because it requires capturing label dependencies. It becomes even more challenging when class distribution is long-tailed. Resampling and re-weighting are common approaches used for addressing the class imbalance problem, however, they are not effective when there is label dependency besides class imbalance because they result in oversampling of common labels. Here, we introduce the application of balancing loss functions for multilabel text classification. We perform experiments on a general domain dataset with 90 labels (Reuters-21578) and a domain-specific dataset from PubMed with 18211 labels. We find that a distribution-balanced loss function, which inherently addresses both the class imbalance and label linkage problems, outperforms commonly used loss functions. Distribution balancing methods have been successfully used in the image recognition field. Here, we show their effectiveness in natural language processing. Source code is available at https://github.com/Roche/ BalancedLossNLP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Multi-label text classification is one of the core topics in natural language processing (NLP) and is used in many applications such as search <ref type="bibr" target="#b20">(Prabhu et al., 2018)</ref> and product categorization <ref type="bibr" target="#b0">(Agrawal et al., 2013)</ref>. It aims to find the related labels from a fixed-set of labels for a given text that may have multiple labels. <ref type="figure">Figure 1 demonstrates</ref>   <ref type="formula" target="#formula_7">(47)</ref>, nickel (8) <ref type="figure">Figure 1</ref>: Samples for multi-label text classification task from Reuters-21578 dataset. Only titles are shown for illustration. Numbers after the labels indicate total number of occurrences in the dataset. from the Reuters-21578 multi-label text classification dataset <ref type="bibr" target="#b9">(Hayes and Weinstein, 1990)</ref>. Here, for the document with the title PENN CENTRAL &lt;PC&gt; SELLS U.K. UNIT, the aim is to find the labels acq (acquisitions), strategic-metal, and nickel from 90 labels.</p><p>Multi-label classification becomes complicated when there is a long-tailed distribution (class imbalance) and linkage (co-occurrence) of labels. Class imbalance occurs when a small subset of the labels (namely head labels) have many instances, while majority of the labels (namely tail labels) have only a few instances. For example, half of the labels in the Reuters dataset, including copper, strategicmetal, and nickel, occur in less than 5% of the training data. Label co-occurrence or label linkage is a challenge when some head labels co-occur with rare or tail labels, resulting in bias for classification to the head labels. For example, even though the la-bel nickel occurs less frequently, the co-occurrence information of nickel/copper, nickel/strategic-metal is important for accurate modeling <ref type="figure">(Figure 1</ref>). Solutions such as resampling of the samples with lessfrequent labels in classification <ref type="bibr" target="#b7">(Estabrooks et al., 2004;</ref><ref type="bibr" target="#b2">Charte et al., 2015)</ref>, using co-occurrence information in the model initialization <ref type="bibr" target="#b10">(Kurata et al., 2016)</ref>, or providing a hybrid solution for head and tail categories with a multi-task architecture <ref type="bibr" target="#b26">(Yang et al., 2020)</ref> have been proposed in NLP, however they are not suitable for imbalanced datasets or they are dependent on the model architecture.</p><p>Multi-label classification has been widely studied in the computer vision (CV) domain, and recently has benefited from cost-sensitive learning through loss functions for tasks such as object recognition <ref type="bibr" target="#b6">(Durand et al., 2019;</ref><ref type="bibr">Milletari et al., 2016)</ref>, semantic segmentation <ref type="bibr" target="#b8">(Ge et al., 2018)</ref>, and medical imaging <ref type="bibr" target="#b12">(Li et al., 2020a)</ref>. Balancing loss functions such as focal loss <ref type="bibr" target="#b14">(Lin et al., 2017)</ref>, class-balanced loss <ref type="bibr" target="#b4">(Cui et al., 2019)</ref> and distribution-balanced loss <ref type="bibr" target="#b25">(Wu et al., 2020)</ref> provide improvements to resolve the class imbalance and co-occurrence problems in multi-label classification in CV. Loss function manipulation has also been explored <ref type="bibr" target="#b13">(Li et al., 2020b;</ref><ref type="bibr" target="#b3">Cohan et al., 2020)</ref> in NLP as it works in a model architecture-agnostic fashion by explicitly embedding the solution into the objective. For example, <ref type="bibr" target="#b13">Li et al. (2020b)</ref> has borrowed dice-based loss function from a medical image segmentation task <ref type="bibr">(Milletari et al., 2016)</ref> and reported significant improvements over the standard cross-entropy loss function in several NLP tasks.</p><p>In this work, our major contribution is the introduction of the use of balancing loss functions to the NLP domain for the multi-label text classification task. We perform experiments on Reuters-21578, a general and small dataset, and PubMed, a biomedical domain-specific and large dataset. For both datasets, the distribution balancing methods not only outperform the other loss functions for the total metrics, but also lead to significant improvement for the tail labels. We suggest that the balancing loss functions provide a robust solution for addressing the challenges in multi-label text classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Loss Functions</head><p>In NLP, Binary Cross Entropy (BCE) loss is commonly used for multi-label text classification <ref type="bibr" target="#b1">(Bengio et al., 2013)</ref>. Given a dataset {(x 1 , y 1 ), ..., (x N , y N )} with N training instances, each having a multi-label ground truth of y k = [y k 1 , ..., y k C ] ? {0, 1} C (C is the number of classes), and a classifier output z k = [z k 1 , ..., z k C ] ? R, BCE is defined as (the average reduction step is not shown for simplicity):</p><formula xml:id="formula_0">LBCE = ?log(p k i ) if y k i = 1 ?log(1 ? p k i ) otherwise.<label>(1)</label></formula><p>The sigmoid function is used for computing p k i , p k i = ?(z k i ) . The plain BCE is vulnerable to label imbalance due to the dominance of head classes or negative instances <ref type="bibr" target="#b6">(Durand et al., 2019)</ref>. Below, we describe three alternative approaches that address the class imbalance problem in long-tailed datasets in multi-label text classification. The main idea of these balancing methods is to reweight BCE so that rare instance-label pairs intuitively get reasonable "attention".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Focal loss (FL)</head><p>By multiplying a modulating factor to BCE (with the tunable focusing parameter ? ? 0), focal loss places a higher weight of loss on "hard-to-classify" instances predicted with low probability on ground truth <ref type="bibr" target="#b14">(Lin et al., 2017)</ref>. For the multi-label classification task, the focal loss can be defined as:</p><formula xml:id="formula_1">LF L = ?(1 ? p k i ) ? log(p k i ) if y k i = 1 ?(p k i ) ? log(1 ? p k i ) otherwise.</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Class-balanced focal loss (CB)</head><p>By estimating the effective number of samples, class-balanced focal loss <ref type="bibr" target="#b4">(Cui et al., 2019)</ref> further reweights FL to capture the diminishing marginal benefits of data, and therefore reduces redundant information of head classes. For multi-label tasks, each label with overall frequency n i has its balancing term</p><formula xml:id="formula_2">rCB = 1 ? ? 1 ? ? n i<label>(3)</label></formula><p>where ? ? [0, 1) controls how fast the effective number grows and the loss function becomes</p><formula xml:id="formula_3">LCB = ?rCB(1 ? p k i ) ? log(p k i ) if y k i = 1 ?rCB(p k i ) ? log(1 ? p k i ) otherwise.</formula><p>(4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Distribution-balanced loss (DB)</head><p>By integrating rebalanced weighting and negativetolerant regularization (NTR), distributionbalanced loss first reduces redundant information of label co-occurrence, which is critical in the multi-label scenario, and then explicitly assigns lower weight on "easy-to-classify" negative instances <ref type="bibr" target="#b25">(Wu et al., 2020)</ref>. First, to rebalance the weights, in the singlelabel scenario, an instance can be weighted by the resampling probability P C i = 1 C 1 n i ; while in the multi-label scenario, if following the same strategy, one instance with multiple labels can be oversampled with a probability P I = 1</p><formula xml:id="formula_4">C y k i =1 1 n i . Therefore, the rebalanced weight can be normal- ized with r DB = P C i /P I . With a smoothing func- tion,r DB = ? + ?(? ? (r DB ? ?)), mapping r DB to [?, ? + 1], the rebalanced-FL (R-FL) loss function is defined as: LR?F L = ?rDB(1 ? p k i ) ? log(p k i ) if y k i = 1 ?rDB(p k i ) ? log(1 ? p k i ) otherwise.<label>(5)</label></formula><p>Then, NTR treats the positive and negative instances of the same label differently. A scale factor ? and an intrinsic class-specific bias v i are introduced to lower the threshold for tail classes and to avoid over-suppression. </p><formula xml:id="formula_5">LNT R?F L = ?(1 ? q k i ) ? log(q k i ) if y k i = 1 ? 1 ? (q k i ) ? log(1 ? q k i ) otherwise.<label>(6)</label></formula><formula xml:id="formula_6">where q k i = ?(z k i ? v i ) for positive instances and q k i = ?(?(z k i ? v i )) for negative ones.</formula><p>The v i can be estimated by minimizing the loss function at the beginning of training with a scale factor ? and class prior</p><formula xml:id="formula_7">p i = n i /N , so that bi = ?log( 1 pi ? 1), vi = ?? ?bi<label>(7)</label></formula><p>Finally, DB integrates rebalanced weighting and NTR as</p><formula xml:id="formula_8">LDB = ?rDB(1 ? q k i ) ? log(q k i ) if y k i = 1 ?rDB 1 ? (q k i ) ? log(1 ? q k i ) otherwise.<label>(8)</label></formula><p>3 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>Two multi-label text classification datasets of different size, property and domain are used <ref type="table" target="#tab_1">(Table 1)</ref>. Reuters-21578 dataset (Distribution 1.0) contains documents that appeared on Reuters newswire in 1987 and that were manually annotated with 90 labels <ref type="bibr" target="#b9">(Hayes and Weinstein, 1990)</ref>. Here, we follow the train-test split used by <ref type="bibr" target="#b27">(Yang and Liu, 1999)</ref> to obtain 7769 training (1000 among which for validation) and 3019 test documents. The labels are equally split into head (30 with ? 35 instances), medium (31 with between 8-35 instances) and tail (30 with ? 8 instances) subsets.</p><p>PubMed dataset comes from the BioASQ Challenge (License Code: 8283NLM123) providing PubMed articles with titles and abstracts, that have been manually labelled for Medical Subject Headings (MeSH) <ref type="bibr">(Tsatsaronis et al., 2015;</ref><ref type="bibr">Coordinators, 2017)</ref>. 224,897 articles published during 2020 and 2021 are used, among which 10,000 are used for validation and testing purpose. The 18,211 labels are split by 3-quantiles into head (6018 with  <ref type="bibr">Reuters-21578 (left)</ref> and PubMed (right) using the SVM model or different loss functions. The F1 scores are reported for the total set of labels as well as for the head, medium and tail label sets, with the number of instances given in parenthesis. The experiments are performed with the SVM one-vs-rest model (SVM), the binary cross entropy (BCE), focal loss (FL), class balanced focal loss (CB), rebalanced focal loss (R-FL), negative-tolerant regularization FL (NTR-FL), distribution balance with no FL (DB-0FL), class balanced FL with negative regularization (CB-NTR) and distribution balanced loss (DB). ? 50 instances), medium (5581 with between 15-50 instances) and tail (6612 with ? 15 instances) subsets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Settings</head><p>We compare the use of different loss functions, and SVM one-vs-rest model as a classical multilabel classification baseline. For each dataset and method, we evaluate its best micro-F1 and macro-F1 scores <ref type="bibr" target="#b24">(Wu et al., 2019;</ref><ref type="bibr" target="#b15">Lipton et al., 2014)</ref> for the whole label set (total) as well as different subsets of label frequency (head/medium/tail). The loss function parameters, the classification models used, and the implementation details are provided in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>A summary of the results of different loss functions are listed in <ref type="table" target="#tab_2">Table 2</ref>. There are about 10,000 documents and 90 labels in the Reuters dataset, with an average of 150 instances per label <ref type="table" target="#tab_1">(Table 1</ref>). <ref type="figure" target="#fig_0">Figure 2</ref> shows the long-tailed distribution where only a few labels have a high number of articles and these head labels also have high co-occurrence with other labels. The impact of the skewed distribution can also be seen from the comparison between the micro-F1 (around 90 for different loss functions) and macro-F1 (around 50-60) scores <ref type="table" target="#tab_2">(Table 2)</ref>. Furthermore, among loss functions, BCE has the lowest performance for the Reuters dataset with total macro-F1 score of 47 and tail F1 scores of 0. The PubMed dataset contains around 225,000 documents with 18,000 labels <ref type="table" target="#tab_1">(Table 1</ref>) and the imbalance is even more pronounced for this large dataset (Figure in Appendix) and the difference between the total micro-F1 score (60) and the total macro-F1 score (around 15) is very high. Overall, SVM underperforms the proposed distribution balanced loss functions in both datasets.</p><p>Experiments with Reuters-21578 dataset. The loss functions FL, CB, R-FL and NTR-FL perform similar to BCE in head classes, yet outperform BCE in medium and tail classes, indicating the advantage of handling imbalance. DB provides the biggest improvement in tail class assignment; the tail micro-F1 score gains 21.49 from FL and 25.81 from CB. It outperforms prior works that also used this commonly used dataset, including approaches based on Binary Relevance, EncDec, CNN, CNN-RNN, Optimal Completion Distillation or attention-based GNN, that achieved micro-F1&lt;89.9 <ref type="bibr" target="#b17">(Nam et al., 2017;</ref><ref type="bibr" target="#b18">Pal et al., 2020;</ref><ref type="bibr">Tsai and Lee, 2020)</ref> Experiments with PubMed dataset. PubMed is a biomedical domain specific, larger dataset with bigger class imbalance. For this dataset, BCE does not work efficiently, therefore we use FL as a strong baseline. With FL, the medium and tail micro-F1 scores are 26 and 9. All other loss functions outperform FL in medium and tail classes, indicating the advantage of balancing label distribution. DB again has the highest performance for all classes but the most significant improvement is achieved for the medium (micro-F1:41) and tail (micro-F1:24) classes.</p><p>Ablation Study. We further investigate the contribution of the three layers of DB by comparing DB results with R-FL, NTR-FL and DB without the focal layer (DB-0FL). As shown in <ref type="table" target="#tab_2">Table 2</ref>, for both datasets, removing the NTR layer (R-FL) or the focal layer (DB-0FL) reduces model performance for all subsets. Removing the rebalanced weighting layer (NTR-FL) yields similar total micro-F1 (Reuters: 90, PubMed:60) but the macro-F1 as well as medium and tail F1 scores are higher with DB , showing the value of adding the rebalancing weighting layer. We also test the contribution of NTR by integrating it with CB, yielding a novel loss function CB-NTR that has not been previously explored. For both datasets, CB-NTR has better performance than CB for all class sets ( <ref type="table" target="#tab_2">Table 2</ref>). The only difference between CB-NTR and DB is the use of CB weight r CB instead of the rebalancing weightr DB . DB has very close performance to or outperforms CB-NTR in the medium and tail classes, suggesting that ther DB weight, which addresses the co-occurrence challenge, is useful.</p><p>Error Analysis. We perform an error analysis and observe that the most common errors are due to incorrect classification to similar or linked labels for all loss functions. The most common three pairs of classes confused by all loss functions for the Reuters dataset are: platinum and gold, yen and money-fx, platinum and copper. For the PubMed dataset, the most common errors are: Pandemics and Betacoronavirus, Pandemics and SARS-CoV-2, Pneumonia, Viral and Betacoronavirus, and BCE has significantly more errors for these classes compared to the other investigated loss functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We propose and compare the application of a series of balancing loss functions to address the class imbalance problem in multi-label text classification. We first introduce the loss function DB to NLP and design a novel loss function CB-NTR. The experiments show that the DB outperforms other approaches by considering long-tailed distribution and label co-occurrence, and its performance is robust to different datasets such as Reuters (90 labels, general domain) and <ref type="bibr">PubMed (18,</ref><ref type="bibr">211 labels,</ref><ref type="bibr">biomedical domain)</ref>. This study demonstrates that addressing challenges such as class imbalance and label co-occurrence through loss functions is an effective approach for multi-label text classifica-tion. It does not require additional information and can be used with all types of neural network-based models. It may also be a powerful strategy for other NLP tasks, such as part-of-speech tagging, named entity recognition, machine reading comprehension, paraphrase identification and coreference resolution, all of which usually suffer from longtailed distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>A.1 Experimental Settings Evaluation metrics. For each dataset and method, we select the threshold with the best micro-F1 score on the validation set as our final model and evaluate its performance on the test set with micro-F1 and macro-F1 scores.</p><p>Loss function parameters. We compare the performance of DB with different loss functions, where BCE or its modifications are used. The methods include: (1) BCE with all instances and labels of the same weight. (2) FL <ref type="bibr" target="#b14">(Lin et al., 2017)</ref>: we use ?=2.</p><p>(3) CB <ref type="bibr" target="#b4">(Cui et al., 2019)</ref>: we use ? =0.9. (4) R-FL <ref type="bibr" target="#b25">(Wu et al., 2020)</ref>: we use ?=0.1 and ?=10, ?=0.9 (Reuters-21578) or 0.05 (PubMed). (5)NTR-FL <ref type="bibr" target="#b25">(Wu et al., 2020)</ref>: we use ?=0.05 and ?=2. (6) DB <ref type="bibr" target="#b25">(Wu et al., 2020)</ref>: we use same parameters with R-FL and NTR-FL when applicable.</p><p>Implementation Details. We use the BertForSe-quenceClassification backbone in transformers library <ref type="bibr" target="#b23">(Wolf et al., 2020)</ref> with the bert-base-cased pretrained model <ref type="bibr" target="#b5">(Devlin et al., 2018)</ref> for Reuters-21578 dataset and the biobert-base-cased-v1.1 pretrained model <ref type="bibr" target="#b11">(Lee et al., 2019)</ref> for PubMed dataset. bert-base-cased and biobert-base-cased-v1.1 are base BERT models with 110 million parameters. The training data are truncated with a maximal length of 512 and grouped with a batch size of 32. We use AdamW with a weight decay of 0.01 as the optimizer, and determine the learning rate by hyperparameter search. The experiments are implemented in PyTorch. For Reuters-21578 dataset we use one-GPU (V100) experiments which takes 5 minutes for one epoch. For PubMed dataset, we use one-GPU (A100) experiments which takes 1 hour for one epoch. For the SVM one-vs-rest model, we use scikit-learn library <ref type="bibr" target="#b19">(Pedregosa et al., 2011)</ref> with TF-IDF features. With hyperparameter search, we apply the linear kernel and hyper-plane shifting optimized on each validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Additional Effectiveness Check</head><p>We further investigate the effectiveness of loss functions against the number of labels per instance (Table 3 in Appendix). For the Reuters dataset, we split the test instances into two groups, 2583 instances with only one label and 436 instances with multiple labels. On single-label instances, all functions from BCE to DB, have similar performance; while on multi-label instances, the performance of BCE drops more than DB. DB outperforms other <ref type="figure">Figure 3</ref>: The long-tailed distribution and label cooccurrence for the PubMed dataset. The y-axis of distribution curve is log-scale, and the co-occurence matrix is color coded based on the quad root (for better visualization) of conditional probability p(i|j) of class in the i th column on class in the j th row. functions in micro-F1 of the multi-label instance group and macro-F1 of both groups. There are &lt; 0.1% instances of PubMed dataset with a single label, so we divide instances into 3-quantiles by their number of labels. In each quantile, the novel NTR-FL, CB-NTR and DB outperform the rest of the models in all metrics. <ref type="table">Table 3</ref>: Micro and macro F1 scores for multi-label classification of Reuters-21578 (left) and PubMed (right) using different loss functions. The F1 scores are reported for the total set of labels as well as for groups split by the number of labels per instance. The experiments are performed with the binary cross entropy (BCE), focal loss (FL), class balanced focal loss (CB), rebalanced focal loss (R-FL), negative-tolerant regularization FL (NTR-FL), distribution balance with no FL (DB-0FL), class balanced FL with negative regularization (CB-NTR) and distribution balanced loss (DB). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss Function</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reuters</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>The long-tailed distribution and label cooccurrence for the Reuters-21578 dataset. The cooccurence matrix is color coded based on the conditional probability p(i|j) of class in the i th column on class in the j th row.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Dataset Statistics</figDesc><table><row><cell>Dataset</cell><cell>Statistic</cell></row><row><cell>Reuters-21578</cell><cell></cell></row><row><cell>Number of documents</cell><cell>10788</cell></row><row><cell>Number of labels</cell><cell>90</cell></row><row><cell cols="2">Average number of labels per instance 1.24</cell></row><row><cell cols="2">Average number of instances per label 148.11</cell></row><row><cell>PubMed</cell><cell></cell></row><row><cell>Number of documents</cell><cell>224897</cell></row><row><cell>Number of labels</cell><cell>18211</cell></row><row><cell cols="2">Average number of labels per instance 12.30</cell></row><row><cell cols="2">Average number of instances per label 151.88</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Micro and macro F1 scores for multi-label classification of</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>BCE 89.14/47.32 94.11/41.44 76.26/33.11 26.17/0.02 16.48/0.01 27.36/0.02 30.36/0.03 FL 89.97/56.83 94.81/50.33 77.54/40.07 58.30/13.94 53.72/7.44 59.02/10.27 59.72/8.63 CB 89.23/52.96 94.10/44.72 77.27/38.80 58.57/13.67 54.41/7.40 59.21/10.11 59.82/8.51 R-FL 89.47/54.35 95.21/47.45 74.29/38.79 57.90/14.66 53.08/7.67 58.60/10.50 59.45/8.81 NTR-FL 90.70/60.70 95.42/51.33 78.85/44.37 60.92/16.99 58.51/9.07 61.86/12.31 61.12/10.20 DB-0FL 89.45/57.98 94.48/51.80 76.63/42.26 58.95/15.15 55.14/8.11 59.84/10.90 59.85/8.94 CB-NTR 90.74/63.31 95.17/51.08 79.56/49.94 61.07/18.40 58.29/9.67 61.72/12.97 61.72/10.77 DB 90.62/64.47 94.49/54.31 81.17/50.12 60.63/19.19 57.81/9.76 61.53/13.49 61.08/11.23</figDesc><table><row><cell></cell><cell>Reuters</cell><cell>Reuters</cell><cell>PubMed</cell><cell>PubMed</cell><cell>PubMed</cell><cell>PubMed</cell></row><row><cell>Total</cell><cell>Single-label</cell><cell>Multi-label</cell><cell>Total</cell><cell>? 9 labels</cell><cell>10-14 labels</cell><cell>? 15 labels</cell></row><row><cell>miF/maF</cell><cell>miF/maF</cell><cell>miF/maF</cell><cell>miF/maF</cell><cell>miF/maF</cell><cell>miF/maF</cell><cell>miF/maF</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Igor Kulev for the helpful discussions, and the anonymous reviewers for their constructive suggestions. TUBITAK-BIDEB 2211-A Scholarship Program (to A.K.) and TUBA-GEBIP Award of the Turkish Science Academy (to A.O.) are gratefully acknowledged.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multi-label learning with millions of labels: Recommending advertiser bid phrases for web pages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Archit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashoteja</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manik</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
		<meeting>the 22nd international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2013.50</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Addressing imbalance in multilabel classification: Measures and random resampling algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Charte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Antonio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mar?a</forename><forename type="middle">J</forename><surname>Rivera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesus</forename><surname>Del</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page" from="3" to="16" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SPECTER: Document-level representation learning using citation-informed transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Weld</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/gkx1095</idno>
	</analytic>
	<monogr>
		<title level="m">Online. Association for Computational Linguistics. NCBI Resource Coordinators. 2017. Database resources of the National Center for Biotechnology Information</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="8" to="13" />
		</imprint>
	</monogr>
	<note>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2019.00949</idno>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9260" to="9269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning a deep convnet for multi-label classification with partial labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mehrasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2019.00074</idno>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="647" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A multiple resampling method for learning from imbalanced data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Estabrooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taeho</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathalie</forename><surname>Japkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="36" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multievidence filtering and fusion for multi-label classification, object detection and semantic segmentation based on weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sibei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Construe/tis: A system for content-based indexing of a database of news stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">P</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the The Second Conference on Innovative Applications of Artificial Intelligence, IAAI &apos;90</title>
		<meeting>the The Second Conference on Innovative Applications of Artificial Intelligence, IAAI &apos;90</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="49" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improved neural network-based multi-label classification with better initialization leveraging label cooccurrence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gakuto</forename><surname>Kurata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="521" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BioBERT: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonjin</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunkyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan</forename><surname>Ho So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btz682</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A multilabel classification model for full slice brain computerised tomography image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanghui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Feng</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12859-020-3503-0</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">200</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dice loss for dataimbalanced NLP tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxian</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjun</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.45</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="465" to="476" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2017.324</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting><address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2999" to="3007" />
		</imprint>
	</monogr>
	<note>Kaiming He, and Piotr Doll?r</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Optimal thresholding of classifiers to maximize f1 measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balakrishnan</forename><surname>Naryanaswamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Berlin Heidelberg</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="225" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">V-net: Fully convolutional neural networks for volumetric medical image segmentation</title>
		<idno type="DOI">10.1109/3DV.2016.79</idno>
	</analytic>
	<monogr>
		<title level="m">2016 Fourth International Conference on 3D Vision (3DV)</title>
		<editor>Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi</editor>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="565" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Maximizing subset accuracy with recurrent neural networks in multilabel classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinseok</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneldo</forename><surname>Loza Menc?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hyunwoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>F?rnkranz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Magnet: Multi-label text classification using attention-based graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muru</forename><surname>Selvakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malaikannan</forename><surname>Sankarasubbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAART (2)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="494" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Parabel: Partitioned label trees for extreme classification with application to dynamic search advertising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashoteja</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil</forename><surname>Kag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrutendra</forename><surname>Harsola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference</title>
		<meeting>the 2018 World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="993" to="1002" />
		</imprint>
	</monogr>
	<note>Rahul Agrawal, and Manik Varma</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Order-free learning alleviating exposure bias in multi-label classification</title>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Second Innovative Applications of Artificial Intelligence Conference</title>
		<editor>Che-Ping Tsai and Hung-yi Lee. 2020</editor>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="6038" to="6045" />
		</imprint>
	</monogr>
	<note>The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Ion Androutsopoulos, and Georgios Paliouras. 2015. An overview of the bioasq large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Michael R Alvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krithara</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12859-015-0564-6</idno>
	</analytic>
	<monogr>
		<title level="m">Sergios Petridis, Dimitris Polychronopoulos, Yannis Almirantis, John Pavlopoulos, Nicolas Baskiotis, Patrick Gallinari, Thierry Artieres, Axel Ngonga</title>
		<meeting><address><addrLine>Norman Heino, Eric Gaussier, Liliana Barrio-Alvers, Michael Schroeder</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">138</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning to learn and predict: A metalearning approach for multi-label classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1444</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4354" to="4364" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Distribution-balanced loss for multi-label classification in long-tailed datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqiu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58548-8_10</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="162" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">HSCNN: A hybrid-Siamese convolutional neural network for extremely imbalanced multi-label text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenshuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fumiyo</forename><surname>Fukumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanming</forename><surname>Ye</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.545</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6716" to="6722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A re-examination of text categorization methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1145/312624.312647</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;99</title>
		<meeting>the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;99<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
