<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Regularizing Generative Adversarial Networks under Limited Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Merced</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Merced</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Yonsei University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilong</forename><surname>Yang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Waymo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Regularizing Generative Adversarial Networks under Limited Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>5 15 25 35 45 Full data 50% 25% 15% 10% BigGAN + DA + DA + ! !" (Ours) Size of ImageNet training set BigGAN + DA BigGAN + DA + ! !" (Ours) 10% ImageNet training set 10% ImageNet FID? BigGAN 42.99 + DA 37.71 + ! $% 27.51 + DA + ! $% 24.38 Norfolk terrier Indigo bunting Jack-o'-lantern</p><p>FID? Figure 1: Regularizing GANs under limited training data. (left) Image generation trained on 10% ImageNet training set;</p><p>(right) FID scores vs. ImageNet training set size. The proposed regularization method 1) addresses the limited training data issue for the GAN models, and 2) is empirically complementary to the recent data augmentation approaches <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b81">82]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Recent years have witnessed the rapid progress of generative adversarial networks (GANs). However, the success of the GAN models hinges on a large amount of training data. This work proposes a regularization approach for training robust GAN models on limited data. We theoretically show a connection between the regularized loss and an f -divergence called LeCam-divergence, which we find is more robust under limited training data. Extensive experiments on several benchmark datasets demonstrate that the proposed regularization scheme 1) improves the generalization performance and stabilizes the learning dynamics of GAN models under limited training data, and 2) complements the recent data augmentation methods. These properties facilitate training GAN models to achieve state-of-theart performance when only limited training data of the Ima-* Work done during HY's internship at Google Research. geNet benchmark is available. The source code is available at https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Generative adversarial networks (GANs) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b46">47]</ref> have made significant progress in recent years on synthesizing high-fidelity images. The GAN models are the cornerstone techniques for numerous vision applications, such as data augmentation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, domain adaptation <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>, image extrapolation <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b65">66]</ref>, image-to-image translation <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b85">86]</ref>, and visual content creation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b71">72]</ref>.</p><p>The success of the GAN methods heavily relies on a large amount of diverse training data which is often laborexpensive or cumbersome to collect <ref type="bibr" target="#b75">[76]</ref>. As the example of the BigGAN <ref type="bibr" target="#b6">[7]</ref> model presented in <ref type="figure">Figure 1</ref>, the performance significantly deteriorates under the limited training data. Consequently, several very recent approaches <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b83">84]</ref> have been developed to address the data insufficiency issue. A representative task in this emerging research direction aims to learn a robust class-conditional GAN model when only a small proportion of the ImageNet data <ref type="bibr" target="#b58">[59]</ref> are available for the training. Generally, existing methods exploit data augmentation, either conventional or differentiable augmentation, to increase the diversity of the limited training data. These data augmentation approaches have shown promising results on several standard benchmarks.</p><p>In this paper, we address the GAN training task on limited data from a different perspective: model regularization. Although there are numerous regularization techniques for the GAN models in the literature <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b84">85]</ref>, none of them aim to improve the generalization of the GAN models trained on limited data. In contrast, our goal is to learn robust GAN models on limited training data that can generalize well on out-of-sample data. To this end, we introduce a novel regularization scheme to modulate the discriminator's prediction for learning a robust GAN model. Specifically, we impose an 2 norm between the current prediction of the real image and a moving average variable that tracks the historical predictions of the generated image, and vice versa. We theoretically show that, under mild assumptions, the regularization transforms the WGAN <ref type="bibr" target="#b1">[2]</ref> formulation towards minimizing an f -divergence called LeCamdivergence <ref type="bibr" target="#b35">[36]</ref>. We find that the LeCam-divergence is more robust under the limited training data setting.</p><p>We conduct extensive experiments to demonstrate the three merits of the proposed regularization scheme. First, it improves the generalization performance of various GAN approaches, such as BigGAN <ref type="bibr" target="#b6">[7]</ref> and StyleGAN2 <ref type="bibr" target="#b31">[32]</ref>. Second, it stabilizes the training dynamics of the GAN models under the limited training data setting. Finally, our regularization approach is empirically complementary to the data augmentation methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b81">82]</ref>. As presented in <ref type="figure">Figure 1</ref>, we obtain state-of-the-art performance on the limited (e.g., 10%) ImageNet dataset by combining our regularization (i.e., R LC ) and the data augment method <ref type="bibr" target="#b81">[82]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Generative adversarial networks. Generative adversarial networks (GANs) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b78">79]</ref> aim to model the target distribution using adversarial learning. Various adversarial losses have been proposed to stabilize the training or improve the convergence of the GAN models, mainly based on the idea of minimizing the f -divergence between the real and generated data distributions <ref type="bibr" target="#b54">[55]</ref>. For example, Goodfellow et al. <ref type="bibr" target="#b13">[14]</ref> propose the saturated loss that minimizes the JS-divergence between the two distributions. Similarly, the LSGAN <ref type="bibr" target="#b46">[47]</ref> formulation leads to minimizing the ? 2 -divergence <ref type="bibr" target="#b55">[56]</ref>, and the EBGAN <ref type="bibr" target="#b80">[81]</ref> approach optimizes the total variation distance <ref type="bibr" target="#b1">[2]</ref>. On the other hand, some models are designed to minimize the integral probability metrics (IPM) <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b63">64]</ref>, such as the WGAN <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15]</ref> frameworks. In this work, we design a new regularization scheme that can be applied to different GAN loss functions for training the GAN models on the limited data.</p><p>Learning GANs on limited training data. With the objective of reducing the data collection effort, several studies <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b75">76]</ref> raise the concern of insufficient data for training the GAN models. Training the GAN models on limited data is challenging because the data scarcity leads to the problems such as unstable training dynamics, degraded fidelity of the generated images, and memorization of the training examples. To address these issues, recent methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b83">84]</ref> exploit data augmentation as a mean to increase data diversity, hence preventing the GAN models from overfitting the training data. For example, Zhang et al. <ref type="bibr" target="#b79">[80]</ref> augment the real images and introduce a consistency loss for training the discriminator. The DA <ref type="bibr" target="#b81">[82]</ref> and ADA <ref type="bibr" target="#b29">[30]</ref> approaches share a similar idea of applying differential data augmentation on both real and generated images, in which ADA further develops an adaptive strategy to adjust the probability of augmentation. In contrast to prior work, we tackle this problem from a different perspective of model regularization. We show that our method is conceptually and empirically complementary to the existing data augmentation approaches.</p><p>Regularization for GANs. Most existing regularization methods for GAN models aim to accomplish two goals: 1) stabilizing the training to ensure the convergence <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49]</ref>, and 2) mitigating the mode-collapse issue <ref type="bibr" target="#b59">[60]</ref>. As the GAN frameworks are known for unstable training dynamics, numerous efforts have been made to address the issue using noise <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b62">63]</ref>, gradient penalty <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b57">58]</ref>, spectral normalization <ref type="bibr" target="#b49">[50]</ref>, adversarial defense <ref type="bibr" target="#b84">[85]</ref>, etc. On the other hand, a variety of regularization approaches <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b77">78]</ref> are proposed to alleviate the model-collapse issue, thus increasing the diversity of the generated images. Compared with these methods, our work targets a different goal: improving the generalization of the GAN models trained on the limited training data.</p><p>Robust Deep Learning. Robust deep learning aims to prevent the deep neural networks from overfitting or memorizing the training data. Recent methods have shown successes in overcoming training data bias such as label noise <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b76">77]</ref> and biased data distributions <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b70">71]</ref>. Recently, few approaches <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b66">67]</ref> have been proposed for learning the robust GAN model. While these approaches are designed to overcome label or image noise in a corrupted training set, we improve the generalization of the GAN models trained on the limited uncorrupted training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generator</head><p>Discriminator Exponential moving average</p><formula xml:id="formula_0">Loss (0, 1) ( ) ( ( )) ! " # Eq. (3)</formula><p>Limited training data $ Eq. (2) <ref type="figure">Figure 2</ref>: Algorithmic overview. During the GAN training stage, we use the exponential moving average variables, called anchors, to track the discriminator predictions. The anchors are then used to compute the regularized discriminator loss described in Eq. (3) to improve the generalization performance of the GAN models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>We first review the GAN models, then detail our regularization scheme. Finally, we discuss the connection between the proposed method and the LeCam-divergence along with the effect on robust learning under the limited data setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Generative Adversarial Networks</head><p>A GAN model consists of a discriminator D and a generator G. Let V D and L G denote the training objectives of the discriminator D and generator G, respectively. The training of the GAN frameworks can be generally illustrated as:</p><formula xml:id="formula_1">max D VD, VD = E x?T fD(D(x)) + E z?pz fG(D(G(z))) (1) min G LG, LG = E z?pz gG(D(G(z))) ,<label>(2)</label></formula><p>where p z is the prior distribution (e.g., N (0, I)) and T is the training (observed) image set used to approximate the data distribution. The notations f D , f G , and g G in Eq. (2) represent the mapping functions from which various GAN losses can be derived (cf. <ref type="bibr" target="#b41">[42]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Regularizing GANs under Limited Data</head><p>Our goal is to improve the performance of the GAN models when the training set T merely contains a limited amount of data, as the example shown in <ref type="figure">Figure 1</ref>. Different from the existing data augmentation methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b81">82]</ref>, we approach this problem by incorporating the regularization on the discriminator. We present the overview of the proposed method in <ref type="figure">Figure 2</ref>. The core idea is to regulate the discriminator predictions during the training phase. Specifically, we introduce two exponential moving average <ref type="bibr" target="#b34">[35]</ref> variables ? R and ? F , called anchors, to track the discriminator's predictions of the real and generated images. The computation of the anchors ? R and ? F is provided in Eq. <ref type="bibr" target="#b24">(25)</ref>.We then use the identical objective L G described in Eq. (2) for training the generator, and minimize the regularized objective L D for the discriminator:</p><formula xml:id="formula_2">min D L D , L D = ?V D + ?R LC (D),<label>(3)</label></formula><p>where R LC is the proposed regularization term:</p><formula xml:id="formula_3">RLC = E x?T D(x)??F 2 + E z?pz D(G(z))??R 2 . (4)</formula><p>At first glance, the objective in Eq.</p><p>(3) appears counterintuitive since the regularization term R LC pushes the discriminator to mix the predictions of real and generated images, as opposed to differentiating them. However, we show in Section 3.3 that R LC offers meaningful constraints for optimizing a more robust objective. Moreover, we empirically demonstrate in Section 4 that with the appropriate weight ?, this simple regularization scheme 1) improves the generalization under limited training data, and 2) complements the existing data augmentation methods. Why moving averages? Tracking the moving average of the prediction reduces the variance across mini-batches and stabilizes the regularization term described in Eq. (4). Intuitively, the moving average becomes stable while the discriminator's prediction gradually converges to the stationary point. We find this holds for the GAN models used in our experiments (e.g., <ref type="figure">Figure 8</ref>). We illustrate a general case of using two moving average variables ? R and ? F in <ref type="figure">Figure 2</ref>. In some cases, e.g., in theoretical analysis, we may use a single moving average variable to track the predictions of either real or generated images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Connection to LeCam Divergence</head><p>We show the connection of the proposed regularization to the WGAN <ref type="bibr" target="#b1">[2]</ref> model and an f -divergence called LeCam (LC)-divergence <ref type="bibr" target="#b35">[36]</ref> or triangular discrimination <ref type="bibr" target="#b72">[73]</ref>. Under mild assumptions, our regularization method can enforce WGANs to minimize the weighted LC-divergence. We show that the LC-divergence 1) can be used for training GAN models robustly under limited training data, and 2) has a close relationship with the f -divergences used in other GAN models <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b80">81]</ref>. We first revisit the definition of the f -divergence. For two discrete distributions Q(x) and P (x), an f -divergence is defined as:</p><formula xml:id="formula_4">0 1 2 3 4 5 P(x) Q(x) 1 0 1 2 3 4 5 f( P(x) Q(x) ) LeCam-divergence JS-divergence Total Variance KL-divergence ? 2 -divergence</formula><formula xml:id="formula_5">D f (P Q) = x Q(x)f ( P (x) Q(x) )<label>(5)</label></formula><p>if f is a convex function and f (1) = 0. The fdivergence plays a crucial role in GANs as it defines the underlying metric to align the generated distribution p g (x) and data distribution p d (x). For instance, Goodfellow et al. <ref type="bibr" target="#b13">[14]</ref> showed that the saturated GAN minimizes the JS-divergence <ref type="bibr" target="#b39">[40]</ref> between the two distributions:</p><formula xml:id="formula_6">C(G) = 2JS(p d p g ) ? log(4),<label>(6)</label></formula><p>where C(G) is the virtual objective function for the generator when D is fixed to the optimal. Similarly, the LSGAN <ref type="bibr" target="#b46">[47]</ref> method leads to minimizing the ? 2divergence <ref type="bibr" target="#b55">[56]</ref> and the EBGAN <ref type="bibr" target="#b80">[81]</ref> scheme minimizes the total variation distance <ref type="bibr" target="#b1">[2]</ref>. More recently, the Wasserstein distance <ref type="bibr" target="#b1">[2]</ref>, which does not belong to the f -divergence family, introduces a different distribution measurement. However, the performance of WGANs and similar models, e.g., BigGAN <ref type="bibr" target="#b6">[7]</ref>, deteriorates when the training data is limited. We show that incorporating the proposed regularization into these GAN models improves the generalization performance, especially under limited training data. Next, we show the connection between the regularized WGANs and LC-divergence. Proposition 1. Consider the regularized objective in Eq. (3) for the WGAN <ref type="bibr" target="#b1">[2]</ref>, where R LC is with a single anchor and ? &gt; 0. Assume that with respect to a fixed generator G, the anchor converges to a stationary value ? (? &gt; 0). Let C(G) denote the virtual objective function of the generator for the fixed optimal D. We have:</p><formula xml:id="formula_7">C(G) = ( 1 2? ? ?)?(p d p g ),<label>(7)</label></formula><p>where ?(P Q) is the LeCam (LC)-divergence aka the triangular discrimination <ref type="bibr" target="#b35">[36]</ref> given by:</p><formula xml:id="formula_8">?(P Q) = x (P (x) ? Q(x)) 2 (P (x) + Q(x)) .<label>(8)</label></formula><p>Since the divergence is non-negative, we need ? &lt; 1 2? , which indicates the regularization weight should not be too large. The proof is given in Section A.2. We note that the analysis in Proposition 1, which uses only a single anchor, is a simplified regularizer of our method described in Section 3.2. To achieve better performance and more general applications, we use 1) two anchors and 2) apply the regularization term to the hinge <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b38">39]</ref> and nonsaturated loss <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32]</ref> in the experiments. We note this is not a rare practice in the literature. For example, Goodfellow et al. <ref type="bibr" target="#b13">[14]</ref> show theoretically the saturated GAN loss minimizes the JS-divergence. However, in practice, they use the non-saturated GAN for superior empirical results.</p><p>After drawing the connection between LC-divergence and regularized WGANs, we show that the LC-divergence is a robust f -divergence when limited data is available. <ref type="figure" target="#fig_0">Figure 3</ref> illustrates several common f -divergences, where the x-axis plots the input to the function f in Eq. <ref type="formula" target="#formula_5">(5)</ref>, i.e., P (x)/Q(x), and the y-axis shows the function value of f . Note that the input P (x)/Q(x) is expected to be erroneous when limited training data is available, and likely to include extremely large/small values. <ref type="figure" target="#fig_0">Figure 3</ref> shows that the LC-divergence helps obtain a more robust function value for extreme inputs. In addition, the LC-divergence is symmetric and bounded between 0 and 2 which attains the minimum if and only if p d = p g . These properties demonstrate the LC-divergence as a robust measurement when limited training data is available. This observation is consistent with the experimental results shown in Section 4.</p><p>Proposition 2 (Properties of LeCam-divergence). LCdivergence ? is an f -divergence with following properties:</p><p>? ? is non-negative and symmetric.</p><p>? ?(p d p g ) is bounded, with the minimum 0 when p d = p g and the maximum 2 when p d and p g are disjoint.</p><formula xml:id="formula_9">? ?-divergence is a symmetric version of ? 2 -divergence, i.e., ?(P Q) = ? 2 (P M ) + ? 2 (Q M ), where M = 1 2 (P + Q). ? The following inequalities hold [45]: 1 4 ?(P, Q) ? JS(P, Q) ? 1 2 ?(P, Q) ? 1 2 T V (P, Q),</formula><p>where JS and T V represent JS-divergence and Total Variation.</p><p>Proposition 2 shows that the LC-divergence is closely related to the f -divergences used in other GAN methods. For example, it is a symmetric and smoothed ? 2 -divergence used in the LSGAN <ref type="bibr" target="#b46">[47]</ref>. The weighted ? lower bounds the JS-divergence used in the saturated GAN <ref type="bibr" target="#b13">[14]</ref> and the Total Variation distance used in the EBGAN <ref type="bibr" target="#b80">[81]</ref> approaches.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>We conduct extensive experiments on several benchmarks to validate the efficacy of our method on training the leading class-conditional BigGAN <ref type="bibr" target="#b6">[7]</ref> and unconditional StyleGAN2 <ref type="bibr" target="#b31">[32]</ref> models on the limited data.</p><p>Datasets. The CIFAR 10/100 <ref type="bibr" target="#b33">[34]</ref> and ImageNet <ref type="bibr" target="#b58">[59]</ref> datasets are standard benchmarks for the image generation models. The resolutions of the images in the CIFAR, Ima-geNet datasets are 32x32, and 128x128, respectively. Evaluation metrics. We use two common metrics: Inception Score (IS) <ref type="bibr" target="#b59">[60]</ref> and Fr?chet Inception Distance (FID) <ref type="bibr" target="#b17">[18]</ref>. Unless specified otherwise, we follow the evaluation protocol in the DA paper <ref type="bibr" target="#b81">[82]</ref> that reports the average and standard deviation values over three evaluation trials.</p><p>Setups. We conduct the CIFAR experiments using the Big-GAN <ref type="bibr" target="#b6">[7]</ref> framework implemented by Zhao et al. <ref type="bibr" target="#b81">[82]</ref>. <ref type="bibr" target="#b0">1</ref> We train the BigGAN model on TPU for the ImageNet experiments. <ref type="bibr" target="#b1">2</ref> Finally, the StyleGAN2 <ref type="bibr" target="#b31">[32]</ref> framework is trained and evaluated using the implementation from Zhao et al. <ref type="bibr" target="#b81">[82]</ref> and Karras et al. <ref type="bibr" target="#b29">[30]</ref>. <ref type="bibr" target="#b12">13</ref> As for the hyperparameter settings, we use the decay factor of 0.99 for the exponential moving average variables. We set the regular- ization weight ? to 0.3, 0.01 for the CIFAR, ImageNet experiments, respectively.</p><p>Baselines. We compare three types of baseline methods on the CIFAR datasets. The first group are GAN models that optimize various loss functions including nonsaturated <ref type="bibr" target="#b13">[14]</ref>, LS <ref type="bibr" target="#b46">[47]</ref>, and RaHinge <ref type="bibr" target="#b26">[27]</ref>. Second, we compare with three regularization methods: instance noise <ref type="bibr" target="#b62">[63]</ref>, zero-centered gradient penalty (GP-0) <ref type="bibr" target="#b47">[48]</ref> and consistency regularization (CR) <ref type="bibr" target="#b79">[80]</ref>. Finally, we compare with two recent differentiable data augmentation methods DA <ref type="bibr" target="#b81">[82]</ref> and ADA <ref type="bibr" target="#b29">[30]</ref> that address the limited data issue for GANs. For the experiments on other datasets, we focus on comparing with the state-of-the-art methods. For a fair comparison, we compare the baseline methods under the same GAN backbone using their official implementation on each dataset, except <ref type="table" target="#tab_4">Table 5</ref> in which we cite the numbers of <ref type="bibr" target="#b81">[82]</ref> reported in the original paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results on CIFAR-10 and CIFAR-100</head><p>As shown in <ref type="table" target="#tab_0">Table 1</ref>, the proposed method improves the generalization performance of the BigGAN model. The comparison between other GAN models shows the competitive performance of the proposed method, especially under limited training data. These results substantiate that our regularization method minimizes a sensible divergence on limited training data. To further understand the impact on the training dynamics, we plot the FID scores during the training stage in <ref type="figure" target="#fig_1">Figure 4</ref>. The proposed method stabilizes the training process on limited data (i.e., FID scores deteriorate in a later stage) and achieves the lowest FID score at the final iteration (100K). This result suggests that our method can stabilize the GAN training process on limited data.   <ref type="figure">Figure 5</ref>: Zero-centered gradient penalty values. We visualize the values of zero-centered gradient penalty (GP-0) <ref type="bibr" target="#b47">[48]</ref> during the training stage. The proposed regularization also constrains the values without explicitly minimizing the GP-0 loss.</p><p>We compare our method with three regularization methods: instance noise <ref type="bibr" target="#b62">[63]</ref>, GP-0 <ref type="bibr" target="#b47">[48]</ref> and CR <ref type="bibr" target="#b79">[80]</ref> in <ref type="table" target="#tab_1">Table 2</ref>. Notice that the spectral norm regularization <ref type="bibr" target="#b49">[50]</ref> is used by default in the BigGAN model <ref type="bibr" target="#b6">[7]</ref>. For the GP-0 method, we apply the gradient penalty only on real images. Our regularization scheme performs favorably against these regularization methods, particularly under the limited data setting. Despite the improvement under the limited data, the GP-0 approach degrades the FID performance when using the full training data. We note that a similar observation is raised in the BigGAN paper <ref type="bibr" target="#b6">[7]</ref>. In <ref type="figure">Figure 5</ref>, we visualize the GP-0 values of the models trained with the GP-0 and our methods during the training stage. Interestingly, the proposed method also constrains the GP-0 values, although it does not explicitly minimize the GP-0 loss.</p><p>Finally, we combine our regularization method with data augmentation and show it is complementary to the recent data augmentation methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b81">82]</ref>. As presented in <ref type="table" target="#tab_2">Table 3</ref>, the proposed approach improves the performance of DA and ADA, especially under the limited data settings. Note that the data augmentation methods tackle the problem from different perspectives and represent the prior state-ofthe-art on limited training data before this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison to State-of-the-art on ImageNet</head><p>ImageNet <ref type="bibr" target="#b58">[59]</ref> is a challenging dataset since it contains more categories and images with higher resolution. Considering the variance of the model performance, we follow the evaluation protocol in the BigGAN paper <ref type="bibr" target="#b6">[7]</ref>. Specifically, we run the training/evaluation pipeline three times using different random seeds, then report the average performance. We present the quantitative results in <ref type="table" target="#tab_3">Table 4</ref>. The proposed method improves the resistance of the BigGAN model against the scarce training data issue (e.g., ? 3.75 in FID under 25% data). It is noteworthy that the performance variance of our models is reduced in most cases (e.g., 2.59 ? 1.73 in FID under 25% data), suggesting its capability in stabilizing the training process. <ref type="table" target="#tab_4">Table 5</ref> demonstrates the quantitative results compared to the state-of-the-art model that uses the DA <ref type="bibr" target="#b81">[82]</ref> method. Both the quantitative results and qualitative comparison presented in <ref type="figure" target="#fig_2">Figure 6</ref> validate that the proposed method complements the data augmentation approach. We achieve state-of-the-art performance on the limited (e.g., 10%) Ima-geNet dataset by combining our regularization and the data augment approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison with Data Augmentation</head><p>We use the StyleGAN dataset to conduct the experiments.Experiment details are provided in Section A.3. As presented in <ref type="table" target="#tab_2">Table 3</ref> and <ref type="table" target="#tab_6">Table 6</ref>, the proposed method improves the performance of the StyleGAN2 model trained with(out) data augmentation <ref type="bibr" target="#b29">[30]</ref> in all cases. We note that different from BigGAN, the StyleGAN2 model minimizes the non-saturated <ref type="bibr" target="#b13">[14]</ref> GAN loss and uses the gradient penalty GP-0 <ref type="bibr" target="#b47">[48]</ref> in the default setting. This shows that the proposed regularization scheme can be applied to other GAN loss functions along with existing regularization approaches.</p><p>We make a comparison in <ref type="table" target="#tab_7">Table 7</ref> to summarize the (dis)advantages of the data augmentation and our methods. First, the data augmentation approaches yield more   <ref type="bibr" target="#b81">[82]</ref>. ? denotes the result is quoted from <ref type="bibr" target="#b81">[82]</ref>. significant gain than the proposed method when the training data is extremely limited. Nevertheless, our method can further improve the performance of data augmentation due to the complementary nature of the two methods. Second, the data augmentation approaches may degrade the performance when the training images are sufficiently diverse (e.g., the full dataset). This is consistent with the observation described in <ref type="bibr" target="#b29">[30]</ref>. In comparison, our regularization method may not suffer the same problem.</p><formula xml:id="formula_10">Methods Full data 50% data 25% data 10% data IS ? FID ? IS ? FID ? IS ? FID ? IS ? FID</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Analysis and Ablation Studies</head><p>We use the BigGAN model and the CIFAR-10 dataset to conduct the analysis and ablation studies.</p><p>Regularization strength for R LC . We conduct a sensitive study on the regularization weight ?. As shown in <ref type="figure" target="#fig_5">Figure 7(b)</ref>, weights greater than 0.5 degrade the performance. This agrees with our analysis in Eq. (7) that larger weights ? result in negative divergence values. Generally, the proposed method is effective when the weight ? is in a reasonable range, e.g., [0.1, 0.5] in <ref type="figure" target="#fig_5">Figure 7</ref> Regularizing real vs. generated image predictions. Our default method regularizes the predictions of both real images D(x) and generated images D(G(z)). In this experiment, we investigate the effectiveness of separately regularizing the two terms D(x) and D(G(z)). As shown in      Discriminator predictions. We visualize the discriminator predictions during training in <ref type="figure">Figure 8</ref>. Without regularization, the predictions of real and generated images diverge rapidly as the discriminator overfits the limited training data. On the other hand, the proposed method, as described in Eq. (4), penalizes the difference between predictions of real and generated images, thus keeping the predictions in a particular range. This observation empirically substantiates that the discriminator's prediction gradually converges to the stationary point, and so do the moving average variables ? R and ? F .</p><p>Model size. Since reducing the model capacity may allevi-  <ref type="figure">Figure 8</ref>: Discriminator predictions. We visualize the discriminator predictions from the BigGAN model on the CIFAR-10 dataset during the training stage. The proposed method prevents the predictions of real images D(x) and generated images D(G(z)) from diverging under the limited (e.g., 20%) data setting.</p><p>ate the overfitting problem, we investigate the performance of using a smaller model size for both generator and discriminator. <ref type="figure" target="#fig_5">Figure 7(a)</ref> shows the results of progressively halving the number of channels in both the generator and discriminator. The improvement made by our method increases with the model size, as the overfitting issue is more severe for the model with higher capacity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>In this work, we present a regularization method to train the GAN models under the limited data setting. The proposed method achieves a more robust training objective for the GAN models by imposing a regularization loss to the discriminator during the training stage. In the experiments, we conduct experiments on various image generation datasets with different GAN backbones to demonstrate the efficacy of the proposed scheme that 1) improves the performance of the GAN models, especially under the limited data setting and 2) can be applied along with the data augmentation methods to further enhance the performance. In future, we plan the training data scarcity issue for 1) the conditional GAN tasks such as image extrapolation, imageto-image translation, etc, and 2) the robust GAN learning on large-scale noisy training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Supplementary Materials</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Overview</head><p>In this supplementary document, we first provide the theoretical justification for Proposition 1 in the paper. Second, we describe the implementation details. Finally, we present additional experimental results, including those of training the GAN model on only hundreds of images, i.e., low-shot image generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Theoretical Analysis</head><p>Proposition 3. Consider the regularized objective in Eq.(1) and (2) in the paper for the WGAN <ref type="bibr" target="#b1">[2]</ref>, where R LC is with a single anchor and ? &gt; 0. Assume that with respect to a fixed generator G, the anchor converges to a stationary value ? (? &gt; 0). Let C(G) denote the generator's virtual objective for the fixed optimal D. We have:</p><formula xml:id="formula_11">C(G) = ( 1 2? ? ?)?(p d p g ),<label>(9)</label></formula><p>where ?(P Q) is the LeCam-divergence aka the triangular discrimination <ref type="bibr" target="#b35">[36]</ref> given by:</p><formula xml:id="formula_12">?(P Q) = x (P (x) ? Q(x)) 2 (P (x) + Q(x))<label>(10)</label></formula><p>Proof. In the following, we use p d (x) to denote the target distribution and simplify Ez?p z (x) D(G(z)) using</p><formula xml:id="formula_13">Ex?p g (x) D(x)</formula><p>. With a single anchor, the proposed regularization has the following form:</p><formula xml:id="formula_14">R LC (D) = E x?p d (x) D(x) + ? 2 + E x?pg(x) D(x) ? ? 2 ,<label>(11)</label></formula><p>where ? ? 0 is the anchor for the real images, i.e., ? R in the Equation (4) in the paper. Note that since D(G(z)) ? 0, when using a single anchor we have that ? R = ?? F = ?.</p><p>Consider the regularized objective of the discriminator:</p><formula xml:id="formula_15">min L(D) = min E x?pg(x) D(x) ? E x?p d (x) D(x) + ?R LC (D) (12) = min E x?pg(x) D(x) ? E x?p d (x) D(x) + ? E x?p d (x) D(x) + ? 2 + ? E x?pg(x) D(x) ? ? 2 (13) = min E x?p d (x) ? D(x) + ? 2 ? D(x) + E x?pg(x) ? D(x) ? ? 2 + D(x) (14) = min E x?p d (x) ? D(x) + ? 2 ? D(x) ? ? + 1 4? + E x?pg(x) ? D(x) ? ? 2 + D(x) ? ? + 1 4? + C (15) = min ? E x?p d (x) D(x) + ? ? 1 2? 2 + ? E x?pg(x) D(x) + 1 2? ? ? 2 + C<label>(16)</label></formula><p>where C = 2? ? 1 2? . We now derive the optimal discriminator D * with respect to a fixed G. According to the assumption, near convergence of D * , C approaches a constant value. This is a mild assumption because we found that the discriminator predictions always converge to the stationary points in all of the experiments for both the WGAN and BigGAN models (cf. <ref type="figure">Figure 8</ref> in the main paper). Hypothetically speaking, in rare cases where this criterion might not hold, we may anneal the decay factor in the moving average ? gradually to 1.0 near while D approaches convergence. In the following, we treat C as a constant value and compute D * from:</p><formula xml:id="formula_16">D(x) * = argmin D L(D) = ? x p d (x)(D(x) + ? ? 1 2? ) 2 + p g (x)(D(x) ? ? + 1 2? ) 2 dx (17) dL(D) dx = 2? p d (x)(D(x) + ? ? 1 2? ) + p g (x)(D(x) ? ? + 1 2? ) = 0 (18) =? (p d (x) + p g (x))D(x) + (p d (x) ? p g (x))(? ? 1 2? ) = 0 (19) =? D * (x) = (p d (x) ? p g (x))( 1 2? ? ?) p d (x) + p g (x)<label>(20)</label></formula><p>Full data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>20% data</head><p>Discriminator predictions</p><formula xml:id="formula_17">!(#) !(%(&amp;)) !(#) !(%(&amp;)) BigGAN:</formula><p>BigGAN + ' !" (Ours): <ref type="figure">Figure 9</ref>: Discriminator predictions. We visualize the discriminator predictions from the BigGAN model on the CIFAR-10 dataset during the training stage. The proposed method prevents the predictions of real images D(x) and generated images D(G(z)) from diverging under the limited (e.g., 20%) data setting.</p><p>Consider the following generator's objective when D is fixed:</p><formula xml:id="formula_18">min G L(G) = ? E x?pg(x) D(x) + E x?p d (x) D(x)<label>(21)</label></formula><p>Notice that as the regularization term is only added to the discriminator, and the generator's objective is kept the same. Then we have:</p><formula xml:id="formula_19">C(G) = x p d (x)D * (x) ? p g (x)D * (x) dx (22) = ( 1 2? ? ?) x (p d (x) ? p g (x)) 2 p d (x) + p g (x) dx (23) = ( 1 2? ? ?)?(p d (x) p g (x)),<label>(24)</label></formula><p>where ? is the LeCam divergence and 1 2? ? ? is the weight of the divergence. Since the divergence is non-negative, we need ? &lt; 1 2? . For example, if ? = 1, then ? &lt; 0.5. This indicates the weight ? in the proposed regularization term R LC should not be too large.</p><p>The proof is then completed.</p><p>Discussion on the theoretical results. Our method is inspired by the theoretical analysis in Proposition 3. In our experiments, we employ modifications to optimize the performance. We note this is not a rare practice in the literature. For example, Goodfellow et al. <ref type="bibr" target="#b13">[14]</ref> show theoretically the saturated GAN loss minimizes the JS-divergence. However, in practice, they use the non-saturated GAN due to the superior empirical performance. Specifically, our method incorporates two modifications. First, it uses two anchors for the discriminator predictions of both real and generated images. Our ablation study in <ref type="table" target="#tab_6">Table 6</ref> in the main paper shows this leads to a performance gain. Second, we extend our method to regularize other GAN losses in the leading-performing GAN models such as the BigGAN <ref type="bibr" target="#b6">[7]</ref> and StyleGAN2 <ref type="bibr" target="#b31">[32]</ref> models. The former has a similar objective as the WGAN that applies the hinge loss <ref type="bibr" target="#b38">[39]</ref>. Using a similar procedure in <ref type="bibr" target="#b1">[2]</ref>, we might be able to extend the result in Proposition 3 when the discriminator predictions are within the margin boundaries.</p><p>We empirically substantiate the analysis by showing the proposed regularization prevents the discriminator predictions from diverging on the limited training data. As shown in <ref type="figure">Figure 9</ref>, without regularization, the predictions of real and generated images diverge rapidly under the limited data setting. On the other hand, the proposed method keeps the predictions within -1 and +1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Implementation Details</head><p>Exponential moving average. We implement the exponential moving average operation using the following formulation:  <ref type="table" target="#tab_0">Table 10</ref>: IS scores on the CIFAR dataset. We report the average IS scores (?) of three evaluation runs to supplement <ref type="table" target="#tab_0">Table  1</ref> in the paper. The best performance is in bold and the second best is underscored.  <ref type="figure">Figure 10</ref>: Qualitative comparisons under limited training data. We show the generation results on the 25% ImageNet dataset. The baseline models trained with our approach synthesize more realistic images.</p><formula xml:id="formula_20">? (t) = ? ? ? (t?1) + (1 ? ?) ? v (t) ,<label>(25)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Additional Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4.1 CIFAR-10 and CIFAR-100</head><p>We report the results of WGAN on the CIFAR-10 dataset in <ref type="table" target="#tab_10">Table 9</ref>. Although the proposed method is able to improve the performance of the WGAN model, the performance of the WGAN backbone is inferior to that of the BigGAN backbone and is also more sensitive to the hyperparameter setting. Therefore, we use the BigGAN backbone in our CIFAR and ImageNet experiments. In addition, <ref type="table" target="#tab_0">Table 10</ref> presents the IS scores to complement the FIS scores reported in <ref type="table" target="#tab_0">Table 1</ref> in the paper for the CIFAR experiments. Necessity of exponential moving averages (EMAs). We validate the necessity of the EMAs in the table below with the BigGAN model on the 20% CIFAR datasets. Specifically, we compute our regularization with constant anchors by setting 1) ? R =1 and ? F =?1 following the LS-GAN <ref type="bibr" target="#b42">[43]</ref> 2) ? F =?0.5 and ? R =0.5 <ref type="figure">(Figure 9</ref> shows ? 0.5 is similar to the converged value of EMAs.) The results in <ref type="table" target="#tab_0">Table 11</ref> show that using EMAs empirically facilitates the discriminator to converge to the better local optimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4.2 ImageNet</head><p>We show additional qualitative comparisons between the baseline (i.e., BigGAN <ref type="bibr" target="#b6">[7]</ref>) and the proposed method (i.e., BigGAN + R LC ) in <ref type="figure">Figure 10</ref>. Combining the qualitative results shown in <ref type="figure" target="#fig_2">Figure 6</ref> in the paper, we find that the proposed approach improves the visual quality of the generated images compared to the baseline models with and without data augmentation. <ref type="table" target="#tab_0">Table 12</ref>: Quatitative results on the low-shot image generation datasets. We report the average FID scores (?) of three evaluation runs. The best performance is bold and the second best is underscored. Using the proposed regularization approach along with data augmentation to train the model on only 100 (Obama, Grumpy cat, Panda), 160 (Cat), or 389 (Dog) images perform favorably against the transfer learning techniques that pre-train the model on 70000 images.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4.3 Low-Shot Image Generation</head><p>In this experiment, we consider a more extreme scenario where only a few dozens of images are available for training a GAN model. This setting is known as the low-shot image generation problem <ref type="bibr" target="#b81">[82]</ref>. Recent solutions focus on adapting an exiting GAN model pre-trained on other large datasets. The adaptation strategies include optimizing the whole GAN model <ref type="bibr" target="#b74">[75]</ref>, modifying the batch statics <ref type="bibr" target="#b52">[53]</ref>, using an additional mining network <ref type="bibr" target="#b73">[74]</ref>, and fine-tuning parts of the GAN model <ref type="bibr" target="#b50">[51]</ref>. We use the experimental setting in the DA <ref type="bibr" target="#b81">[82]</ref> paper that trains and evaluates the StyleGAN2 model on datasets that contain only 100 (Obama, Grumpy cat, Panda), 160 (Cat), or 389 (Dog) images. <ref type="bibr" target="#b6">7</ref> We set the regularization weight ? to 0.0001. The quantitative comparisons are shown in <ref type="table" target="#tab_0">Table 12</ref>. The StyleGAN2 model trained with the proposed regularization and data augmentation methods from scratch performs favorably against the existing adaptation-based techniques. Note that the adaptation-based approaches require to pre-train the StyleGAN2 model on the FFHQ dataset consisting of 70000 images. We also perform the interpolation in the latent space, and present the image generation results in <ref type="figure" target="#fig_7">Figure 11</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Comparison of various f -divergences. The xand y-axis denote the input and the value of the function f in the f -divergence in Eq. (5). For extremely large or small inputs of P (x)/Q(x), LeCam-divergence yields the most robust values of f (P (x)/Q(x)). The weighted LeCamdivergence is plotted where the weight is 1 2? ? ? = 1 4 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>FID curves during the training on the CIFAR-10 dataset. The proposed method 1) improves the best performance, and 2) stabilizes the training dynamic of the Big-GAN model under the limited (e.g., 20%) data setting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>BigGAN + DA (FID: 13.28) BigGAN + DA + ! !" (Ours) (FID: 11.16) (FID: 37.71) BigGAN + DA + ! !" (Ours) (FID: 24.38) Qualitative comparisons under limited training data. We show the generation results on the (top) 10% and (bottom) 25% ImageNet dataset. The baseline models trained with our approach synthesize more realistic images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Different (a) model sizes and (b) regularization strengths. The scores are computed on the (a) 10% and (b) 20% CIFAR-10 datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 :</head><label>11</label><figDesc>Low-shot generation results. We train the StyleGAN2 model with the proposed regularization and data augmentation methods on the 100 grumpy cat (top), Obama (middle), and panda (bottom) images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Quantitative results on the CIFAR dataset. We report the average FID scores (?) of three evaluation runs. The best performance is in bold and the second best is underscored.</figDesc><table><row><cell>Methods</cell><cell></cell><cell></cell><cell>CIFAR-10</cell><cell></cell><cell></cell><cell>CIFAR-100</cell></row><row><cell></cell><cell></cell><cell>Full data</cell><cell>20% data</cell><cell>10% data</cell><cell>Full data</cell><cell>20% data</cell><cell>10% data</cell></row><row><cell cols="2">Non-saturated GAN [14]</cell><cell>9.83?0.06</cell><cell>18.59?0.15</cell><cell>41.99?0.18</cell><cell>13.87?0.08</cell><cell>32.64?0.19</cell><cell>70.50?0.38</cell></row><row><cell>LS-GAN [47]</cell><cell></cell><cell>9.07?0.01</cell><cell>21.60?0.11</cell><cell>41.68?0.18</cell><cell>12.43?0.11</cell><cell>27.09?0.09</cell><cell>54.69?0.12</cell></row><row><cell cols="2">RaHinge GAN [27]</cell><cell>11.31?0.04</cell><cell>23.90?0.22</cell><cell>48.13?0.33</cell><cell>14.61?0.21</cell><cell>28.79?0.17</cell><cell>52.72?0.18</cell></row><row><cell>BigGAN [7]</cell><cell></cell><cell>9.74?0.06</cell><cell>21.86?0.29</cell><cell>48.08?0.10</cell><cell>13.60?0.07</cell><cell>32.99?0.24</cell><cell>66.71?0.01</cell></row><row><cell cols="2">BigGAN + R LC (Ours)</cell><cell>8.31?0.05</cell><cell>15.27?0.10</cell><cell cols="2">35.23?0.14 11.88?0.12</cell><cell cols="2">25.51?0.19 49.63?0.16</cell></row><row><cell>Full data</cell><cell></cell><cell>20% data</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>FID</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Non-saturated</cell><cell>LS</cell><cell>RaHinge</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BigGAN</cell><cell cols="2">BigGAN + !" (Ours)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison to GAN regularization methods. We report the average FID (?) scores on the CIFAR datasets. LC (Ours) 8.31?.05 15.27?.10 11.88?.12 25.51?0.<ref type="bibr" target="#b18">19</ref> </figDesc><table><row><cell>Method</cell><cell cols="2">CIFAR-10</cell><cell cols="2">CIFAR-100</cell></row><row><cell></cell><cell>Full data</cell><cell>20% data</cell><cell>Full data</cell><cell>20% data</cell></row><row><cell>BigGAN [7]</cell><cell>9.74?.06</cell><cell>21.86?.29</cell><cell>13.60?.07</cell><cell>32.99?.24</cell></row><row><cell>+ noise [63]</cell><cell>9.64?.06</cell><cell>21.87?.11</cell><cell>13.88?.07</cell><cell>32.38?.01</cell></row><row><cell>+ CR [80]</cell><cell>8.96?.10</cell><cell cols="2">20.62?.10 11.59?.05</cell><cell>36.91?.12</cell></row><row><cell>+ GP-0 [48]</cell><cell cols="2">10.30?.16 19.10?.08</cell><cell>14.67?.08</cell><cell>29.85?.04</cell></row><row><cell>+ R</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Quantitative comparisons to data augmentation. We report the average FID (?) scores of three evaluation runs.</figDesc><table><row><cell>Methods</cell><cell cols="2">CIFAR-10</cell><cell cols="2">CIFAR-100</cell><cell cols="2">StyleGAN</cell></row><row><cell></cell><cell>Full</cell><cell>10%</cell><cell>Full</cell><cell>10%</cell><cell>Full</cell><cell>1K</cell></row><row><cell>BigGAN [7] + DA [82]</cell><cell>8.75?0.05</cell><cell>23.34?0.28</cell><cell>11.99?0.10</cell><cell>35.39?0.16</cell><cell>-</cell><cell>-</cell></row><row><cell>BigGAN + DA + R LC (Ours)</cell><cell>8.46?0.06</cell><cell cols="2">16.69?0.02 11.20?0.09</cell><cell>27.28?0.05</cell><cell>-</cell><cell>-</cell></row><row><cell>StyleGAN2 [32] + ADA [30]</cell><cell>2.68?0.02</cell><cell>6.72?0.03</cell><cell>3.04?0.02</cell><cell>14.06?0.07</cell><cell>3.82?0.01</cell><cell>23.27?0.14</cell></row><row><cell>StyleGAN2 + ADA+ R LC (Ours)</cell><cell>2.47?0.01</cell><cell>6.56?0.02</cell><cell>2.99?0.01</cell><cell cols="2">13.01?0.02 3.49?0.04</cell><cell>21.70?0.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Quantitative results on the ImageNet dataset. We report the mean IS (?) and FID (?) scores of three training runs.</figDesc><table><row><cell>Methods</cell><cell></cell><cell cols="2">Full data</cell><cell cols="2">50% data</cell><cell cols="2">25% data</cell></row><row><cell></cell><cell></cell><cell>IS ?</cell><cell>FID ?</cell><cell>IS ?</cell><cell>FID ?</cell><cell>IS ?</cell><cell>FID ?</cell></row><row><cell>BigGAN [7]</cell><cell></cell><cell>90.48?12.7</cell><cell>8.60?1.08</cell><cell>80.26?5.55</cell><cell>9.83?0.94</cell><cell>61.05?6.43</cell><cell>18.22?2.59</cell></row><row><cell cols="2">BigGAN + R LC (Ours)</cell><cell cols="2">93.00?3.27 7.27?0.14</cell><cell cols="2">89.94?6.67 9.13?0.84</cell><cell cols="2">65.66?4.96 14.47?1.73</cell></row><row><cell>Full data</cell><cell></cell><cell>20% data</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GP-0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BigGAN</cell><cell cols="2">BigGAN + GP-0</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">BigGAN + ! !" (Ours)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Comparison to the state-of-the-art on the limited ImageNet training data.. We train and evaluate the Big-GAN [7] model following the same evaluation protocol in</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Quantitative results of the StyleGAN2<ref type="bibr" target="#b31">[32]</ref> model. We report the average FID (?) scores of three evaluation runs.</figDesc><table><row><cell>Method</cell><cell cols="2">70k images 30k images</cell><cell>10k images</cell><cell>5k images</cell><cell>1k images</cell></row><row><cell>StyleGAN2 [32]</cell><cell>3.79?0.02</cell><cell>6.19?0.05</cell><cell>14.96?0.05</cell><cell>25.88?0.09</cell><cell>72.07?0.04</cell></row><row><cell>StyleGAN2 + R LC (Ours)</cell><cell>3.66?0.02</cell><cell>5.78?0.03</cell><cell>14.58?0.04</cell><cell cols="2">23.83?0.11 63.16?0.11</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Comparisons with data augmentation methods. We report the FID (?) scores of the StyleGAN2 backbone.</figDesc><table><row><cell>Method</cell><cell>Full data</cell><cell>1K data</cell></row><row><cell>StyleGAN2 [32]</cell><cell>3.71?0.01</cell><cell>72.07?0.04</cell></row><row><cell>+ DA [82]</cell><cell>4.21?0.03</cell><cell>25.17?0.09</cell></row><row><cell>+ ADA [30]</cell><cell>3.81?0.01</cell><cell>23.27?0.14</cell></row><row><cell>+R LC</cell><cell>3.66?0.02</cell><cell>63.16?0.11</cell></row><row><cell>+ ADA + R LC</cell><cell>3.49?0.04</cell><cell>21.70?0.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Ablation study on regularizing real vs. generated image predictions. We train and evaluate the Big-GAN [7] model on the CIFAR-10 dataset, then report the average FID (?) scores.</figDesc><table><row><cell>Real Generated</cell><cell>Full data</cell><cell>20% data</cell></row><row><cell></cell><cell>9.74?0.06</cell><cell>21.86?0.29</cell></row><row><cell></cell><cell>8.73?0.04</cell><cell>20.47?0.36</cell></row><row><cell></cell><cell>8.79?0.09</cell><cell>18.18?0.08</cell></row><row><cell></cell><cell>8.31?0.03</cell><cell>15.27?0.10</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 ,</head><label>8</label><figDesc>regularizing both terms achieves the best result.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Comparisons to WGAN on the CIFAR-10 dataset. We report the average FID (?) scores of three evaluation runs.Full CIFAR-10 7.86?.07 18.86?.13 7.98?.02 15.79?.11 9.07?0.03 9.74?0.06 9.31?0.04 8.31?0.05</figDesc><table><row><cell>Methods</cell><cell cols="2">WGAN [2]</cell><cell cols="2">WGAN + RLC (Ours)</cell><cell cols="2">BigGAN [7]</cell><cell cols="2">BigGAN + RLC (Ours)</cell></row><row><cell></cell><cell>IS (?)</cell><cell>FID (?)</cell><cell>IS (?)</cell><cell>FID (?)</cell><cell>IS (?)</cell><cell>FID (?)</cell><cell>IS (?)</cell><cell>FID (?)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 :</head><label>11</label><figDesc>Ablation study on exponential moving averages (EMAs). We validate the impact of the EMAs by replacing the EMAs with the constant values. We train and evaluate the BigGAN model on the CIFAR dataset in this experiment.</figDesc><table><row><cell>FID(?)</cell><cell>EMAs</cell><cell>[? R =0.5, ? F =?0.5]</cell><cell>[? R =1, ? F =?1]</cell></row><row><cell>CIFAR 10</cell><cell>15.27?0.10</cell><cell>30.64?0.05</cell><cell>19.81?0.03</cell></row><row><cell>CIFAR 100</cell><cell>25.51?0.19</cell><cell>30.03?0.11</cell><cell>27.54?0.07</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/mit-han-lab/data-efficient-gans 2 https://github.com/google/compare_gan 3 https://github.com/NVlabs/stylegan2-ada</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/mit-han-lab/data-efficient-gans/tree/master/DiffAugment-biggan-cifar</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank anonymous reviewers for their useful comments. This work is supported in part by the NSF CAREER Grant #1149783. We fix the decay factor ? to 0.99 in all experiments.</p><p>CIFAR-10 and CIFAR-100. We set the weight ? of regularization term to 0.3, and adopt the default hyper-parameters of the baseline method in the implementation by Zhao et al. <ref type="bibr" target="#b81">[82]</ref>. <ref type="bibr" target="#b3">4</ref> Specifically, we use the batch size of 50, learning rate of 2e ? 4 for the generator G and discriminator D, 4 D update steps per G step, and translation + cutout for the DA <ref type="bibr" target="#b81">[82]</ref> method.</p><p>ImageNet. We use the Compare GAN codebase <ref type="bibr" target="#b4">5</ref> for the experiments on the ImageNet dataset. The random scaling, random horizontal flipping operations are used to pre-process the images. We keep the default hyper-parameter settings for the baseline methods (i.e., BigGAN <ref type="bibr" target="#b6">[7]</ref>, BigGAN + DA <ref type="bibr" target="#b81">[82]</ref>). As for our approach, we use the batch size of 2048, learning rate of 4e?4 for D and 1e?4 for G, 2 D update steps per G step, and the regularization weight ? of 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparisons with Data Augmentation</head><p>We train and evaluate the StyleGAN2 <ref type="bibr" target="#b31">[32]</ref> framework on the FFHQ <ref type="bibr" target="#b30">[31]</ref> dataset, where the image size is 256 ? 256. We set the regularization weight ? to 3e ? 7 in this experiment. We use the ADA <ref type="bibr" target="#b29">[30]</ref> codebase <ref type="bibr" target="#b5">6</ref> and the DA [82] source code <ref type="bibr" target="#b6">7</ref> for the experiments shown in <ref type="table">Table 3</ref> and <ref type="table">Table 6</ref> in the paper, respectively. Since the StyleGAN2 model uses the softplus mapping function for computing the GAN loss, the gradients of the discriminiator predictions around zero are much smaller than those in the BigGAN <ref type="bibr" target="#b6">[7]</ref> model that uses the hinge function i.e., BigGAN: 0.8, StyleGAN2: 10 ?3 in the last layer of the discriminator). Therefore, we use a much smaller regularization weight ? of 3e ? 7. Though the weight ? is smaller on the FFHQ dataset, we can observe the impact of our method by comparing StyleGAN2 (?=0) and StyleGAN2+R LC (?=3e ? 7) in <ref type="table">Table 3</ref>, 6 and 7 in the paper. Moreover, the ablation study results in <ref type="figure">Fig 7(b)</ref> suggest our approach is relatively insensitive to the value of ? under the same backbone. As for the other hyper-parameters, we keep the setting used in the original implementations.</p><p>Reproducing results of previous methods. We obtain quantitatively comparable results in most experiments. However, there are few cases that we fail to reproduce the results reported in the original paper. First, compared to <ref type="table">Table 3</ref> in the DA <ref type="bibr" target="#b81">[82]</ref> paper, we obtain different results of training the StyleGAN2 model on the 5k and 1k FFHQ datasets, respectively. Second, the result of training the StyleGAN model with the ADA [30] method on the 1k FFHQ dataset is slightly different from that reported in 7(c) in the ADA paper. On the other hand, the result of training the StyleGAN2 model on the full FFHQ dataset is similar to that shown in the DA and ADA papers. As a result, we argue that the different sets of limited data sampled for training the StyleGAN model (using the different random seeds) cause the performance discrepancy observed under the limited data setting.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>where ? is the moving average variable (i.e., ? R and ? F ), v (t) is the current value at training step t, and ? is the decay factor.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Im-age2stylegan++: How to edit the embedded images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rameen</forename><surname>Abdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yipeng</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Wonka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wasserstein gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devansh</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Jastrzkebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maxinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tegan</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asja</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic photo manipulation with a generative image prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hendrik</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Peebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<idno>2019. 1</idno>
	</analytic>
	<monogr>
		<title level="m">ACM TOG (Proc. SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Began: Boundary equilibrium generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Schumm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10717</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ambientgan: Generative models from lossy measurements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Bora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros G</forename><surname>Dimakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mode regularized generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanran</forename><surname>Tong Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Advaug: Robust adversarial augmentation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chieh</forename><surname>Hubert Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Tulyakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.00675</idno>
		<title level="m">In&amp;out: Diverse image outpainting via gan inversion</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Gan-based synthetic medical image augmentation for increased cnn performance in liver lesion classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maayan</forename><surname>Frid-Adar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Idit</forename><surname>Diamant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyal</forename><surname>Klang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Amitai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hayit</forename><surname>Greenspan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">321</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Synthetic data augmentation using gan for improved liver lesion classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maayan</forename><surname>Frid-Adar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyal</forename><surname>Klang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Amitai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hayit</forename><surname>Greenspan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Biomedical Imaging</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards gan benchmarks which require generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Coteaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Progressive domain adaptation for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han-Kai</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Han</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maneesh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semantic view synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multimodal unsupervised image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Transforming and projecting images into class-conditional generative networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minyoung</forename><surname>Huh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On stabilizing generative adversarial training with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Jenni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Beyond synthetic noise: Deep learning on controlled noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mason Liu Di</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The relativistic discriminator: a key element missing from standard gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexia</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Noise robust generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuhiro</forename><surname>Kaneko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Label-noise robust generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuhiro</forename><surname>Kaneko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Training generative adversarial networks with limited data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miika</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janne</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Analyzing and improving the image quality of stylegan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miika</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janne</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Kodali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Abernethy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07215</idno>
		<title level="m">On convergence and stability of gans</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Asymptotic methods in statistical decision theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucien</forename><forename type="middle">Le</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cam</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ding</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maneesh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Drit++: Diverse image-to-image translation via disentangled representations. IJCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Simaug: Learning robust representations from simulation for trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><forename type="middle">Hyun</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><surname>Chul Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.02894</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Geometric gan. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Divergence measures based on the shannon entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Chun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Mallya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.02793</idno>
		<title level="m">Generative adversarial networks for image and video synthesis: Algorithms and applications</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Narges Razavian, and Carlos Fernandez-Granda. Early-learning regularization prevents memorization of noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Niles-Weed</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Normalized diversification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiao</forename><surname>Wangni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">A class of new metrics based on triangular discrimination. Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoxiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingqing</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="361" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Mode seeking generative adversarial networks for diverse image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Least squares generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">Paul</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smolley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Which training methods for gans do actually converge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The numerics of gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Spectral normalization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiki</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuichi</forename><surname>Yoshida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Freeze discriminator: A simple baseline for fine-tuning gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangwoo</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.10964</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Integral probability metrics and their generating classes of functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Applied Probability</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="429" to="443" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Image generation from small datasets via batch statistics adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuhiro</forename><surname>Noguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Confident learning: Estimating uncertainty in dataset labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Curtis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Northcutt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><forename type="middle">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">fgan: Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling. The London, Edinburgh, and Dublin Philosophical Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Science</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">302</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Bin Yang, and Raquel Urtasun. Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Stabilizing training of generative adversarial networks through regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ImageNet Large Scale Visual Recognition Challenge. IJCV</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Learning hybrid image templates (hit) by information projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangzhang</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Amortised map inference for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Casper Kaae S?nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Husz?r</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.04490</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Bridging the gap between f -gans and wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Veegan: Reducing mode collapse in gans using implicit variational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akash</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lazar</forename><surname>Valkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Michael U Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Boundless: Generative adversarial networks for image extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Robustness of conditional gans to noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Kiran Koshy Thekumparampil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zinan</forename><surname>Khetan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewoong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Trung</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viet-Hung</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Bao</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trung-Kien</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Cheung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.05338</idno>
		<title level="m">Towards good practices for data augmentation in gan training</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Regularizing metalearning via gradient dropout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Wen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sifei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Modeling artistic workflows for image generation and editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Cross-domain few-shot classification via learned feature-wise transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Retrievegan: Image synthesis via differentiable patch retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">On the concept and measure of information contained in an observation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Istv?n</forename><surname>Vincze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contributions to Probability</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1981" />
			<biblScope unit="page" from="207" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Minegan: effective knowledge transfer from gans to target domains with few images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abel</forename><surname>Gonzalez-Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Herranz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Transferring gans: generating images from limited data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenshen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Herranz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abel</forename><surname>Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Gonzalez-Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raducanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Detecting overfitting of deep generative networks via latent recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Rabin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo?c</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Faster meta update strategy for noise-robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youjiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Diversity-sensitive conditional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingdong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunseok</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianchen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Self-attention generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Odena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Consistency regularization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2020</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Energybased generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Differentiable augmentation for data-efficient gan training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Improved consistency regularization for gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.04724</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Image augmentations for gan training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.02595</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Don&apos;t let your discriminator be fooled</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brady</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
