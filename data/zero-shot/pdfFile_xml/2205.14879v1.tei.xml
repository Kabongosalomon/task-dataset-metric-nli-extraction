<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Easter2.0: IMPROVING CONVOLUTIONAL MODELS FOR HANDWRITTEN TEXT RECOGNITION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Chaudhary</surname></persName>
							<email>kartikgill@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Data Scientist Bangalore</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Bali</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Staff Data Scientist</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Easter2.0: IMPROVING CONVOLUTIONAL MODELS FOR HANDWRITTEN TEXT RECOGNITION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Handwritten Text Recognition ? Convolutional Neural Networks ? OCR</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional Neural Networks (CNN) have shown promising results for the task of Handwritten Text Recognition (HTR) but they still fall behind Recurrent Neural Networks (RNNs)/Transformer based models in terms of performance. In this paper, we propose a CNN based architecture that bridges this gap. Our work, Easter2.0, is composed of multiple layers of 1D Convolution, Batch Normalization, ReLU, Dropout, Dense Residual connection, Squeeze-and-Excitation module and make use of Connectionist Temporal Classification (CTC) loss. In addition to the Easter2.0 architecture, we propose a simple and effective data augmentation technique 'Tiling and Corruption (T ACo)' relevant for the task of HTR/OCR. Our work achieves state-of-the-art results on IAM handwriting database when trained using only publicly available training data. In our experiments, we also present the impact of T ACo augmentations and Squeeze-and-Excitation (SE) on text recognition accuracy. We further show that Easter2.0 is suitable for few-shot learning tasks and outperforms current best methods including Transformers when trained on limited amount of annotated data. Code and model is available at: https://github.com/kartikgill/Easter2.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>20%</head><p>40% 60% 80% 100% Easter2.0(Ours) T ransf ormer <ref type="bibr" target="#b6">[7]</ref> Seq2Seq <ref type="bibr" target="#b6">[7]</ref> GRCL <ref type="bibr" target="#b1">[2]</ref> F CN/CT C <ref type="bibr" target="#b0">[1]</ref>  In the context of handwritten text recognition, very few works have used entirely convolutional architectures devoid of any recurrence <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>. Some recent works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15]</ref> combine CNNs with a gating mechanism to compensate for the dependency on LSTM cells, known as Gated Convolutional Neural Networks (GCN). GCN architectures have been shown to outperform fully convolutional architectures yet they lag behind RNN/Transformer based architectures such as <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>.</p><p>Recurrent Neural Networks (RNN) work well for large variety of tasks including Handwritten Text Recognition (HTR). LSTM based models can handle long term context in sequences but at the cost of long learning times and potentially a huge number of parameters. Work by Voigtlaender et. al. <ref type="bibr" target="#b11">[12]</ref> uses multi-dimensional LSTM to learn dependencies over both axis (horizontal and vertical), which makes them even slower.The most common architectures have a combination of CNN and RNN, where CNN is used for feature extraction from images and RNN is used for modeling sequential context <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b2">3]</ref>. Works by Michael and Labahn et. al. <ref type="bibr" target="#b9">[10]</ref> and Kang and Toledo et. al. <ref type="bibr" target="#b17">[17]</ref> improve CNN+LSTM architectures with use of various attention mechanisms. While some works such as <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b20">20]</ref> have also experimented with sequence-to-sequence approaches.</p><p>Recent progress in tasks associated with text recognition has achieved state-of-the-art (SOTA) results using Transformerbased architectures <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b6">7]</ref>. Some of these works use a CNN-based backbone with self-attention as encoders to understand images <ref type="bibr" target="#b8">[9]</ref>. Li and Lv et. al. <ref type="bibr" target="#b8">[9]</ref> use pre-trained Computer Vision(CV) and Natural Language Processing (NLP) models to improve Transformer-based encoder-decoder architecture to achieve SOTA results on IAM handwriting dataset without an external language model. This approach leverages a large sized synthetic training set and multiple pre-trainings with a large number of training parameters.</p><p>We believe that the biggest challenge in developing an HTR system is not modeling but obtaining sufficient amounts of high quality training data. In this paper we address this problem by presenting a method that achieves encouraging results with very less amount of training samples. We also propose a CNN based architecture, Easter2.0, that is data efficient, parameter-efficient, compute-efficient, latency-efficient and is easy to understand and deploy. Our model utilizes multiple layers of 1D Convolution, Batch Normalization, ReLU, Dropout, Dense Residual Connections, a Squeeze-and-Excitation (SE) <ref type="bibr" target="#b12">[13]</ref> module and make use of Connectionist Temporal Classification (CTC) loss <ref type="bibr" target="#b21">[21]</ref>. The SE module improves access to global context for our proposed CNN architecture. Easter2.0 has advantages from both worlds, i.e., speed and parameter efficiency of CNN and access to global context similar to RNN/Transformers (using the SE module). The contributions of this paper are summarized as follows:</p><p>1. We propose T ACo, a simple and novel data augmentation technique for Handwritten Text Recognition with experimental results to prove it's effectiveness.</p><p>2. We present Easter2.0, a novel CNN based architecture for the task of end-to-end handwritten text line recognition that utilizes only 1D Convolutions with dense residual connections and a squeeze-and-excitation module.  3. Easter2.0 is recurrence-free, parameter efficient, fast and simple convolutional architecture that achieves state-of-the-art results on IAM handwritten test set when trained using only publicly available data (IAM-Train set).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Tiling and Corruption Augmentation(T ACo)</head><p>We introduce a simple and effective augmentation technique for the task of handwritten text line recognition. T ACo augmentations help the model to learn useful features and achieve good results even on very small training sets.</p><p>Tiling refers to cutting the input image into multiple small tiles of equal size (T w ). After tiling, a fraction (C p ) of the tiles is replaced with corrupted ones as part of the corruption step (C p is a hyper-parameter used to set the corruption probability). Finally, tiles are stitched back together in the same order to get the augmented image(see <ref type="figure" target="#fig_4">figure 4</ref>). Tile width T w is sampled from a uniform distribution from H 10 to maximum tile width parameter T max (where H is height of input image). T ACo augmentations can be applied on an input image across height(H), width(W ) or both. The T ACo augmentation algorithm is presented in algorithm-1:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Tiling and Corruption (T ACo)</head><p>1: procedure APPLYT ACo(img) 2:</p><formula xml:id="formula_0">H, W ? Shape of img 3: T w ? sample from uniform distribution [ H 10 , T max ] 4:</formula><p>tiles ? cut and return a list of image tiles each with width = T w 5:</p><p>for i = 1 ? length(tiles) do <ref type="bibr">6:</ref> p ? random floating point number from range [0.0, 1.0) using pseudo-random number generator <ref type="bibr">7:</ref> if p &lt;= C p then C p :Corruption Probability 8:</p><formula xml:id="formula_1">tiles[i] ? a corrupt tile of width (T w ) tile replacement 9:</formula><p>augmented_img ? join back tiles in the same order <ref type="bibr">10:</ref> return augmented_img </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model Architecture</head><p>The architecture of Easter2.0 is inspired by the design of Easter <ref type="bibr" target="#b0">[1]</ref> which is a fully convolutional architecture with only 1D convolutions. However, there are some key differences in our proposed Easter2.0 architecture. Easter2.0 makes use of dense residual connections and a squeeze-and-excitation module to introduce global context into local features. Sections 3.1 to 3.3 describe components of our model in more detail and section 3.4 describes the final configuration of Easter2.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Convolution Blocks</head><p>Easter2.0 has overall 14 layers and each layer represents one of the 3 types of convolution blocks A, B or C as shown in <ref type="figure" target="#fig_2">figure 2</ref>). Block type-A is composed of a standard 1D convolutional layers followed by layers of batch normalization, ReLU and dropout. Block type-B has R repetitions of Block type-A with a residual connection. The residual connection is first projected through a 1 x 1 convolution to balance the number of channels followed by a batch normalization layer. The output of this batch normalization layer is then added to the output of SE layer in the last convolution block, just before the layers of ReLU and Dropout (see <ref type="figure" target="#fig_2">figure 2</ref>). The SE layer is only present in the last convolution block of Block type-B, just after the batch normalization layer(see <ref type="figure" target="#fig_2">figure 2</ref>). Block type-C is only used as the last layer of our model. Block type-C regulates size of output via 1x1 convolution layers and is followed by a softmax layer to calculate the distribution of probabilities over the characters of given vocabulary.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dense Residual Connections</head><p>Easter2.0 utilizes dense residual connections as shown in the Block type-B of <ref type="figure" target="#fig_2">figure 2</ref>. The dense residual connections <ref type="bibr" target="#b22">[22]</ref> are obtained by adding the output of a convolution block to the inputs of all following blocks of type-B as shown in the figure 2. We found dense residual connections to be performing better than normal residual connections at the cost of small increase in training parameters (more details in the experiments section).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Squeeze-and-Excitation</head><p>We use a 1-D version of squeeze-and-excitation module to introduce global context as depicted in <ref type="figure" target="#fig_3">figure 3</ref>. SE module squeezes the local features into a single global context vector of weights and broadcasts this context back to each local feature vector through element-wise multiplication of context weights with features. We present experimental study on how SE module improves the model performance. Checkout the pseudo-code for our SE module implementation 2 which is very similar to the works of Hu and Shen et. al. <ref type="bibr" target="#b12">[13]</ref> and Han and Zhang et. al. <ref type="bibr" target="#b13">[14]</ref>.</p><p>Algorithm 2 Squeeze-and-Excitation-1D(SE) 1: procedure ADD_GLOBAL_CONTEXT(data,f ilters)</p><p>2:</p><p>x ? GlobalAveragePooling1D on data 3:</p><p>x ? FullyConnected (units= f ilters</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8</head><p>) on x Bottleneck 4:</p><p>x ? ReLU on x 5:</p><p>x ? FullyConnected (units=f ilters) on x <ref type="bibr">6:</ref> weights ? Sigmoid on x 7:</p><p>final_data ? Element-wise Multiplication (weights, data) context broadcasted <ref type="bibr">8:</ref> return f inal_data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Configuration</head><p>Easter2.0 has a total 14 blocks of convolution layers. <ref type="table" target="#tab_0">Table 1</ref> summarizes the architectural details. First two layers are type-A blocks (B1 and B2) with kernel width of 3 and a stride of 2. Next 3 blocks are type-B blocks (B3 to B5) with kernel widths of 5, 7 and 9 respectively with dense residual connections. Blocks B6 and B7 are again type-A blocks with kernel widths of 11 and 1 respectively. Block B6 has a dilation rate of 2. Block B8 is a type-C block. All blocks except B8, have dropout layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>The biggest challenge for OCR/HTR tasks is obtaining good quality labelled dataIAM handwriting database <ref type="bibr" target="#b23">[23]</ref> is a popular benchmark for comparing HTR models. Recent studies have utilised synthetic/internal datasets in addition to IAM-Training set to obtain SOTA results on IAM-Test set. Curation and usage of such synthetic datasets presents difficulties in reproducibility. We only make use of publicly available datasets for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">IAM</head><p>The IAM handwritten dataset is composed of 1,539 scanned form pages from 657 writers. It corresponds to handwritten English text images also available as grayscaled images. There are 79 characters in the alphabet. We only focus on the line level dataset. IAM-A has about 6, 482, 976 and 2, 915 lines for training, validation and test datasets respectively. IAM-B has about 6, 161, 940 and 1, 861 lines for training, validation and test datasets respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Long-Lines</head><p>Long line samples are obtained by randomly choosing two training images and stacking them horizontally (with a small white background image in between) to form a long line and labels are concatenated with a space. This introduces examples with long lengths, multiple handwritings, strokes, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Details</head><p>The experiments are carried out with Tensorflow <ref type="bibr" target="#b24">[24]</ref> toolkit with a weighted Connectionist Temporal Classification (w-CTC)(similar to <ref type="bibr" target="#b0">[1]</ref>) as loss function. We have used Adam optimizer with an initial learning rate of 10 ?3 and a batch size of 32 with early stopping criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation</head><p>We use case-sensitive Character Error Rate (CER) as evaluation metric to compare results in our experiments. We also provide model parameters from our experiments. The CER is computed as the Levenshtein distance which is the sum of the character substitutions (Sc), insertions (Ic) and deletions (Dc) that are needed to transform one string into the other, divided by the total number of characters in the groundtruth (N c). Formally,</p><formula xml:id="formula_2">CER(%) = (Sc + Ic + Dc) N c ? 100 (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>In this section, we present results for different experiments based on different configurations discussed so far.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Effect of Residual Connections:</head><p>Residual connections improve training when networks are deep. <ref type="table" target="#tab_1">Table  2</ref> shows the effect of residual connections on performance. We found out that dense residual connections outperform normal residual connections by a good margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Effect of Normalization:</head><p>In our study, we evaluate performance of our model with 2 normalization techniques: batch normalization <ref type="bibr" target="#b25">[25]</ref> and layer normalization <ref type="bibr" target="#b26">[26]</ref> and also without normalization. Experiment results are shown in <ref type="table" target="#tab_2">Table 3</ref>. We found that batch normalization outperforms layer normalization. Both normalization techniques help model train faster and achieve better results than the case without normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Effect of Squeeze-and-Excitation:</head><p>The squeeze-and-excitation module introduces the global context into convolutions. We found that adding SE to our network improves the model performance with a small increase in parameters. <ref type="table" target="#tab_1">Table 2</ref> shows the accuracy improvements when SE module is applied to Easter2.0 with dense as well as normal residual connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>Effect of T ACo Augmentations: T ACo being a simple augmentation technique improves the model performance considerably. <ref type="table" target="#tab_3">Table 4</ref> shows that T ACo improves CER irrespective of the type of corruption applied to certain parts of the image. We finally went ahead with random-noise as a type of corruption in rest of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Effect of Tile Width:</head><p>We experimented with different values of maximum tile widths (T max ) while applying T ACo augmentations (check section 2). In our experiments, we found out that T ACo improves Easter2.0 irrespective of tile widths (see <ref type="table" target="#tab_4">Table 5</ref>). Model achieves best results when T max =H (H is height of input image).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Effect of Input Length:</head><p>Our experiments suggest that Easter2.0 works well irrespective of input length and thus a good option for recognizing longer sequences. <ref type="figure" target="#fig_6">Figure 6</ref> shows the CER analysis wrt. the input length on IAM-offline test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.</head><p>Few-shot Training: Easter2.0 is ideal for few-shot training and produces state-of-the-art (SOTA) results with very small amount of annotated data. <ref type="table" target="#tab_5">Table 6</ref> shows some experiments that we conducted with limited  number of training samples. We found out that Easter2.0 outperforms SOTA works including Transformers <ref type="bibr" target="#b6">[7]</ref> when training data is small (see tables 6 and 7). As obtaining large amount of good quality annotated data is a challenge in many recognition tasks, Our solution can be a choice in such scenarios. External language model can improve our model further however we have only presented greedy decoding results in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8.</head><p>Comparison with the State-of-the-Art: <ref type="table" target="#tab_6">Table 7</ref> compares current state-of-the-art results on IAM-Test set. Easter2.0 beats previous SOTA results with a good margin when only publicly available data is used for training. Many state-of-the-art (SOTA) solutions use pre-trainings and large internal/synthetic datasets to boost model accuracy. As everyone has their own way to collect synthetic/internal data, it makes the model comparison unfair. To avoid this bias, we train Easter2.0 only with publicly available IAM-offline training set <ref type="bibr">(6,482 lines)</ref>. We present SOTA results on IAM-test set having 2,915 lines (see <ref type="table" target="#tab_6">table 7</ref>). However, when synthetic/Internal data is allowed Diaz et al., <ref type="bibr" target="#b7">[8]</ref> and TrOCR <ref type="bibr" target="#b8">[9]</ref> achieve SOTA results on IAM-Test set with CER 2.75 and 2.89 respectively.      <ref type="bibr" target="#b7">[8]</ref> S-Attn / CTC Yes 2.75 -In this paper, we proposed a convolutional architecture for the task of handwritten text recognition that utilizes only 1D convolutions, dense residual connections and a SE module. We also proposed a simple and effective data augmentation technique-T ACo useful for OCR/HTR tasks. We have presented experimental study on components of Easter2.0 architecture including dense residual connections, normalization choices, SE module, TACo variations and few-shot training. Our work achieves SOTA results on IAM-Test set when training data is limited, also Easter2.0 has very small number of trainable parameters compared to other solutions. The proposed architecture can be used in search of smaller, faster and efficient OCR/HTR solutions when available annotated data is limited.</p><p>A APPENDIX-Easy Examples <ref type="figure">Figure 7</ref> shows some clean examples (From IAM-Offline Test partition) that were easy for model. In these examples, Easter2.0 doesn't make any mistake and recognises full sentence correctly. Sometimes these mistakes are due to noisy input, and sometimes even label is incorrect. We didn't explicitly correct any labels for our experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Few-shot training and performance comparison in terms of case-sensitive CER with different portions of publicly available IAM-Training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Easter2.0 Architecture: (Lef t) Block type-A has 1-DCNN, Batch Norm, ReLU and Dropout layers. (M iddle) Block type-C has 1DCNN followed by a Softmax layer. (Right) Block type-B has repetitions of type-A blocks with Dense Residual Connections and SE module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>1D Squeeze-and-Excitation module applies a sequence of steps starting with average pooling on local features followed by two fully connected layers to get context vector. The context vector is multiplied element wise with local features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>T ACo augmentation examples. (T op) Example of Vertical Tiling (across width) and Corruption with random noise. (Bottom) Shows Horizontal Tiling (across height) and Corruption with random noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>T ACo augmentation examples of IAM-Handwritten-lines. (T op) Example with only Vertical T ACo. (Center) Represents Horizontal T ACo. (Bottom) An example of hybrid (Vertical + Horizontal) T ACo.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Effect of Input Length on model performance (in terms of CER).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :Figure 8 :Figure 8</head><label>788</label><figDesc>Examples where model doesn't make any mistake Examples where model makes mistakes B APPENDIX-Difficult Examples shows some difficult examples (From IAM-Offline Test partition) where model makes mistakes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Easter2.0 configuration. The kernel size is for the window size across width and convolutions are across height.</figDesc><table><row><cell cols="4">Block Block Conv #Output</cell><cell cols="2">Kernel Other</cell><cell>Dropout</cell></row><row><cell>ID</cell><cell>type</cell><cell cols="3">layers Channels Size</cell><cell></cell><cell></cell></row><row><cell cols="2">B1,B2 A</cell><cell>1</cell><cell>128</cell><cell>3</cell><cell>stride=2</cell><cell>0.2</cell></row><row><cell>B3</cell><cell>B</cell><cell>3</cell><cell>256</cell><cell>5</cell><cell cols="2">dense residual 0.2</cell></row><row><cell>B4</cell><cell>B</cell><cell>3</cell><cell>256</cell><cell>7</cell><cell cols="2">dense residual 0.2</cell></row><row><cell>B5</cell><cell>B</cell><cell>3</cell><cell>256</cell><cell>9</cell><cell cols="2">dense residual 0.3</cell></row><row><cell>B6</cell><cell>A</cell><cell>1</cell><cell>512</cell><cell>11</cell><cell>dilation=2</cell><cell>0.4</cell></row><row><cell>B7</cell><cell>A</cell><cell>1</cell><cell>512</cell><cell>1</cell><cell>-</cell><cell>0.4</cell></row><row><cell>B8</cell><cell>C</cell><cell>1</cell><cell>#Vocab</cell><cell>1</cell><cell>-</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Effects of Residual Connections and SE module evaluated in terms of case-sensitive Character Error Rate (CER) on IAM-Test set. This experiment uses IAM-B partition (see section 4.1.1)</figDesc><table><row><cell cols="4">Residual Type SE layer CER(%) #param</cell></row><row><cell>-</cell><cell>-</cell><cell>10.47</cell><cell>5.8M</cell></row><row><cell>Normal</cell><cell>-</cell><cell>10.24</cell><cell>5.9M</cell></row><row><cell>Dense</cell><cell>-</cell><cell>9.18</cell><cell>6.1M</cell></row><row><cell>Normal</cell><cell></cell><cell>8.95</cell><cell>6.0M</cell></row><row><cell>Dense</cell><cell></cell><cell>8.90</cell><cell>6.1M</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell cols="2">Effect of Normalization choices evaluated in terms of case-sensitive Character Error Rate (CER) on IAM-Test</cell></row><row><cell>set. This experiment uses IAM-A partition (see section 4.1.1)</cell><cell></cell></row><row><cell cols="2">Normalization Type CER(%)</cell></row><row><cell>-</cell><cell>11.42</cell></row><row><cell>Layer Norm</cell><cell>9.05</cell></row><row><cell>Batch Norm</cell><cell>8.73</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Effect of T ACo augmentation-variations evaluated in terms of case-sensitive Character Error Rate (CER) on IAM-Test set. This experiment uses IAM-B partition (see section 4.1.1)</figDesc><table><row><cell cols="4">Corruption Type Vertical Horizontal CER(%)</cell></row><row><cell>-</cell><cell>-</cell><cell>-</cell><cell>8.90</cell></row><row><cell>Black</cell><cell></cell><cell>-</cell><cell>7.80</cell></row><row><cell></cell><cell></cell><cell></cell><cell>8.21</cell></row><row><cell>White</cell><cell></cell><cell>-</cell><cell>8.29</cell></row><row><cell></cell><cell></cell><cell></cell><cell>8.09</cell></row><row><cell>Mean</cell><cell></cell><cell>-</cell><cell>7.78</cell></row><row><cell></cell><cell></cell><cell></cell><cell>7.77</cell></row><row><cell>Random</cell><cell></cell><cell>-</cell><cell>7.76</cell></row><row><cell></cell><cell></cell><cell></cell><cell>7.72</cell></row><row><cell>Miscellaneous</cell><cell></cell><cell>-</cell><cell>8.32</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Effect of T ACo-Tile width evaluated in terms of case-sensitive Character Error Rate (CER) on IAM-Test set. This experiment uses IAM-A partition (see section 4.1.1)</figDesc><table><row><cell>Corruption</cell><cell cols="2">Tile Width CER(%)</cell></row><row><cell>-</cell><cell>-</cell><cell>10.71</cell></row><row><cell cols="2">random, vertical H/2</cell><cell>8.92</cell></row><row><cell cols="2">random, vertical H</cell><cell>8.73</cell></row><row><cell cols="2">random, vertical 2 ? H</cell><cell>9.33</cell></row><row><cell cols="2">random, vertical 4 ? H</cell><cell>9.37</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Few-shot training and results comparison with SOTA solutions evaluated in terms of case-sensitive Character</figDesc><table><row><cell cols="8">Error Rate (CER) on IAM-Test set. This experiment uses IAM-A partition (see section 4.1.1)</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell></cell><cell cols="2">CER (%)</cell><cell></cell><cell cols="2">Time (s) #param (M)</cell></row><row><cell></cell><cell></cell><cell>10%</cell><cell>20%</cell><cell>40%</cell><cell>60%</cell><cell cols="2">80% 100%</cell></row><row><cell>Seq2Seq[7]</cell><cell></cell><cell>-</cell><cell cols="5">20.61 16.15 15.61 12.18 11.91 338.7</cell><cell>37</cell></row><row><cell>Transformer w/CNN[7]</cell><cell></cell><cell>-</cell><cell cols="5">73.81 17.34 10.14 10.11 7.62 202.5</cell><cell>100</cell></row><row><cell>Easter2.0 (Ours)</cell><cell></cell><cell cols="5">38.90 19.32 14.14 10.05 9.41</cell><cell>8.73 51</cell><cell>6.1</cell></row><row><cell cols="2">Easter2.0 + Long-Lines(4.1.2)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>6.21 51</cell><cell>6.1</cell></row><row><cell></cell><cell>30</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>IAM-Test CER (%)</cell><cell>10 20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">V alidation T est</cell></row><row><cell></cell><cell></cell><cell cols="6">[0-40] [41-45] [46-50] [51-55] [56-60] [61-100]</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Input Length Category</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Comparison with previous solutions using case-sensitive CER on IAM-Test set (line-level test set with greedy decoding). These results use IAM-A partition (see section 4.1.1)</figDesc><table><row><cell>Training Data</cell><cell>Model</cell><cell>Architecture</cell><cell cols="3">External LM CER(%) #param(M)</cell></row><row><cell>IAM (6k)</cell><cell>Ingle et al., 2019[2]</cell><cell>GRCL</cell><cell>No</cell><cell>14.1</cell><cell>10.6</cell></row><row><cell></cell><cell>Chaudhary et al.,2021[1]</cell><cell>FCN/CTC</cell><cell>No</cell><cell>9.8</cell><cell>28</cell></row><row><cell></cell><cell>Kang et al., 2020[7]</cell><cell cols="2">Transformer w/ CNN No</cell><cell>7.62</cell><cell>100</cell></row><row><cell></cell><cell>Wang et al.[27]</cell><cell>DAN, FCN/GRU</cell><cell>No</cell><cell>6.4</cell><cell>-</cell></row><row><cell></cell><cell>Easter2.0 (Ours)</cell><cell>1DCNN-SE/ CTC</cell><cell>No</cell><cell>6.21</cell><cell>6.1</cell></row><row><cell cols="2">Synthetic + IAM Kang et al., 2020 [7]</cell><cell cols="2">Transformer w/ CNN No</cell><cell>4.67</cell><cell>100</cell></row><row><cell></cell><cell cols="2">Bluche and Messina, 2017[3] GCRNN / CTC</cell><cell>Yes</cell><cell>3.2</cell><cell>-</cell></row><row><cell></cell><cell>TrOCR(LARGE) 2021[9]</cell><cell>Transformer</cell><cell>No</cell><cell>2.89</cell><cell>558</cell></row><row><cell>Internal + IAM</cell><cell>Michael et al., 2019[10]</cell><cell cols="2">LSTM/LSTM w/Attn No</cell><cell>4.87</cell><cell>-</cell></row><row><cell></cell><cell>Ingle et al., 2019[2]</cell><cell>GRCL</cell><cell>No</cell><cell>4.0</cell><cell>10.6</cell></row><row><cell></cell><cell>Diaz et al., 2021[8]</cell><cell cols="2">Transformer w/ CNN No</cell><cell>2.96</cell><cell>-</cell></row><row><cell></cell><cell>Diaz et al., 2021</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Easter: Simplifying text recognition using only 1d convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Bali</surname></persName>
		</author>
		<ptr target="https://caiac.pubpub.org/pub/fm5sy88o" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Canadian Conference on Artificial Intelligence</title>
		<meeting>the Canadian Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A scalable handwritten text recognition system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuhisa</forename><surname>R Reeve Ingle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashok C</forename><surname>Baccash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Popat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Gated convolutional recurrent neural networks for multilingual handwriting recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Th?odore</forename><surname>Bluche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronaldo</forename><surname>Messina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IAPR international conference on document analysis and recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="646" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Intelligent character recognition using fully convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Ptucha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felipe</forename><forename type="middle">Petroski</forename><surname>Such</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suhas</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Brockler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vatsala</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hutkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="604" to="613" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Accurate, data-efficient, unconstrained text recognition with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yousef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Khaled</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Usama S</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohammed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page">107482</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1251" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Pay attention to what you read: Non-recurrent handwritten text-line recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pau</forename><surname>Riba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mar?al</forename><surname>Rusi?ol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Forn?s</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauricio</forename><surname>Villegas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.13044</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Rethinking text line recognition models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hernandez Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyang</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reeve</forename><surname>Ingle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuhisa</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.07787</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Trocr: Transformer-based optical character recognition with pre-trained models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengchao</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinei</forename><surname>Florencio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cha</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.10282</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Evaluating sequence-to-sequence models for handwritten text recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Labahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Gr?ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jochen</forename><surname>Z?llner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1286" to="1293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dropout improves recurrent neural networks for handwriting recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Th?odore</forename><surname>Bluche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Kermorvant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?r?me</forename><surname>Louradour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 14th international conference on frontiers in handwriting recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="285" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Handwriting recognition with large multidimensional long short-term memory recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Voigtlaender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Doetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="228" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Cheng</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anmol</forename><surname>Gulati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.03191</idno>
		<title level="m">Contextnet: Improving convolutional neural networks for automatic speech recognition with global context</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Recurrence-free unconstrained handwritten text recognition using gated fully convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Coquenet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cl?ment</forename><surname>Chatelain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Paquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 17th International Conference on Frontiers in Handwriting Recognition (ICFHR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data augmentation for recognition of handwritten words and lines using a cnn-lstm network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Curtis</forename><surname>Wigington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="639" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<title level="m">Easter2.0: Improving Convolutional models for Handwritten Text Recognition</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Alicia Forn?s, and Mar?al Rusinol. Convolve, attend and spell: An attention-based sequence-to-sequence model for handwritten word recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Toledo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pau</forename><surname>Riba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauricio</forename><surname>Villegas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="459" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Joint line segmentation and transcription for end-to-end handwritten paragraph recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Th?odore</forename><surname>Bluche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="838" to="846" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">An efficient end-to-end neural model for handwritten text recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lovekesh</forename><surname>Vig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.07965</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Offline continuous handwriting recognition using sequence to sequence neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Sueiras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose F</forename><surname>Velez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">289</biblScope>
			<biblScope unit="page" from="119" to="128" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Fern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faustino</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Lavrukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huyen</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><forename type="middle">Teja</forename><surname>Gadde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jasper</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03288</idno>
		<title level="m">An end-to-end convolutional neural acoustic model</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The iam-database: an english sentence database for offline handwriting recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U-V</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Document Analysis and Recognition</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="46" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} symposium on operating systems design and implementation ({OSDI} 16)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Decoupled attention network for text recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianwen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxiang</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="12216" to="12224" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
