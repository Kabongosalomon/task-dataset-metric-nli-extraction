<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stepwise Feature Fusion: Local Guides Global</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-06-28">28 Jun 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong-Liverpool University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Liverpool</orgName>
								<address>
									<settlement>Liverpool</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiming</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong-Liverpool University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feilong</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong-Liverpool University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Meng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong-Liverpool University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jionglong</forename><surname>Su</surname></persName>
							<email>jionglong.su@xjtlu.edu.cnsifan.song19@student.xjtlu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong-Liverpool University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sifan</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong-Liverpool University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Liverpool</orgName>
								<address>
									<settlement>Liverpool</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Stepwise Feature Fusion: Local Guides Global</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-06-28">28 Jun 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Polyp segmentation ? Deep learning ? Generalization</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Colonoscopy, currently the most efficient and recognized colon polyp detection technology, is necessary for early screening and prevention of colorectal cancer. However, due to the varying size and complex morphological features of colonic polyps as well as the indistinct boundary between polyps and mucosa, accurate segmentation of polyps is still challenging. Deep learning has become popular for accurate polyp segmentation tasks with excellent results. However, due to the structure of polyps image and the varying shapes of polyps, it is easy for existing deep learning models to overfit the current dataset. As a result, the model may not process unseen colonoscopy data. To address this, we propose a new state-of-the-art model for medical image segmentation, the SSFormer, which uses a pyramid Transformer encoder to improve the generalization ability of models. Specifically, our proposed Progressive Locality Decoder can be adapted to the pyramid Transformer backbone to emphasize local features and restrict attention dispersion. The SSFormer achieves stateof-the-art performance in both learning and generalization assessment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Colorectal cancer (CRC) is common cancer whose cancer risk may be reduced through early screening and removal of colon polyps <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9]</ref>. However, accurate polyp segmentation is still a challenge due to the variable size and shape of polyps, as well as the indistinct boundaries between polyps and mucosa <ref type="bibr" target="#b5">[6]</ref>. An accurate segmentation algorithm based on deep learning can effectively improve the accuracy and efficiency of polyp segmentation. Many image segmentation models based on the Convolutional Neural Networks (CNN) recently achieved excellent learning ability in several polyp segmentation benchmarks. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b24">25]</ref> However, due to the top-down modeling method of the CNN model and the variability in the morphology of polyps but relatively simple structure of the polyps image, this model lacks generalization ability and is difficult to process unseen datasets. To improve the generalization ability of the deep learning model, we shall incorporate the Transformer architecture into the polyp segmentation task.</p><p>The Transformer <ref type="bibr" target="#b17">[18]</ref> was initially proposed as a bottom-up model architecture in the natural language processing (NLP) community. <ref type="bibr">Dosovitskiy et al.</ref> proposed the Vision Transformer (ViT) <ref type="bibr" target="#b4">[5]</ref> that achieved superior performance in image classification tasks. The Transformer is different from CNN which the weight parameters are trained in the kernel to extract and mix the features among elements in the receptive field. In contrast, the Transformer obtains similarities of all patch pairs through the dot product between the patch vectors to adaptively extract and mix features between all patches. This enables the Transformer to have an efficient global receptive field and reduces the inductive bias of the model. As a result, the Transformer has a more robust generalization ability than CNN and Multilayer Perceptron-like structures <ref type="bibr" target="#b11">[12]</ref>. However, the low inductive bias and powerful global receptive field make it difficult for the Transformer model to capture task-specific critical local details adequately. In addition, with the deepening of the Transformer model, the global features are continuously mixed and converged <ref type="bibr" target="#b23">[24]</ref>, resulting in attention dispersion. These make it difficult for the Transformer model to accurately predict detailed information in the dense prediction task of semantic segmentation.</p><p>In order to achieve high generalization and accurate polyp automatic segmentation, a novel state-of-the-art (SOTA) medical image segmentation model, SSFormer, is proposed which uses a pyramid Transformer encoder <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b9">10]</ref> for excellent generalization and multi-scale feature processing capabilities. In our model, the Progressive Locality Decoder (PLD), based on a multi-stage feature aggregation structure, functions as the decoder. The multi-stage feature aggregation structure can enable features of different depths and expressive powers to guide each other, which we believe can address the problems of attention dispersion and underestimation of local features to improve the detail processing ability. Segformer <ref type="bibr" target="#b21">[22]</ref> optimized the encoder of the pyramid structure of PVT <ref type="bibr" target="#b18">[19]</ref> and proposed a multi-stage feature aggregation decoder, which predicts features of different scales and depths separately through simple upsampling and then parallel fusion. SETR <ref type="bibr" target="#b22">[23]</ref> uses the traditional Transformer as the encoder and proposes an MLA decoder with a multi-stage feature aggregation structure. Their excellent performances demonstrate that the decoding method of multi-stage feature aggregation is beneficial to improving the performance of Transformer in dense prediction tasks. Our proposed PLD adopts a stepwise adaptive method to emphasise local features and integrate them into global features, making the fusion of features more efficient.</p><p>The main contributions of this paper are: 1) We introduce the pyramid Transformer architecture into the polyp segmentation task to increase the generalization ability of the neural network; 2) We propose a new decoder PLD suitable for Transformer feature pyramids, which can smooth and effectively emphasise the local features in the Transformer to improve the detailed information processing ability of the neural network; 3) Our proposed SSFormer improves the SOTA performances of the ETIS benchmark, CVC-ClinicDB benchmark, and Kvasir  benchmark by about 3%, 1.8%, and 1%, respectively. In addition, SSFormer has achieved state-of-the-art and superior performance in 2018 Data Science Bowl and ISIC-2018 benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Transformer encoder</head><p>In order for our model to have enough generalization ability and multi-scale feature processing ability to carry out polyp segmentation, we use the Transformer based on the pyramid structure instead of CNN as the encoder. To this end, we adopt the encoder design of PVTv2 <ref type="bibr" target="#b19">[20]</ref> and Segformer to construct the encoder. They both use the convolution operation to replace the PE operation of the traditional Transformer for consistency of spatial information, excellent performance and stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Aggregate local and global features stepwise (PLD)</head><p>Experiments <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b22">23]</ref> have demonstrated that the sufficiency of local features obtained in the shallow part of the Transformer directly affects the performance of the model. However, we believe that the existing Transformer model lacks local and detailed information processing ability to focus on critical detailed features (such as contour, veins and texture). As a result, this makes it difficult for the model to locate the more decisive local feature distribution (mucosa can be considered a distribution composed of local features such as unique veins and textures). We propose a novel multi-stage feature aggregation decoder PLD for feature pyramids to address this issue. <ref type="figure" target="#fig_1">Fig. 1(a)</ref> shows that the PLD consists of the Local Emphasis (LE) module and the Stepwise Feature Aggregation (SFA) module. The experimental section compares PLD with other existing decoders with various encoders that can generate feature pyramids. We compare the attention distribution before the final prediction of several typical multi-stage feature aggregation decoders for Transformers. As demonstrated in <ref type="figure" target="#fig_2">Fig. 2(a)</ref>, after PLD fuses multi-stage features, the prediction head can accurately focus on critical targets. In addition, our PLD can be used for other Pyramid Transformer encoders and can improve the model's accuracy. There is a further demonstration in Section 3.3 . Local Emphasis In the Transformer, each patch in the image will mix the information of all other patches, even if their correlation is not high. After a large number of self-attention operations, the feature streams will converge, further exacerbating the attention dispersion or attention collapse <ref type="bibr" target="#b23">[24]</ref>. Furthermore, we argue that the attention matrix in the self-attention mechanism can be viewed as a global non-preset convolution kernel. We designed the LE module using the local receptive field of the convolution kernel to increase the macro weights of the patches around the query patch to refocus attention on neighboring features thus reducing attention dispersion. In <ref type="figure" target="#fig_1">Fig. 1(b)</ref>, the module consists of the convolution operators, activation functions, and a bilinear upsampling layer. We utilize the fixed receptive field of the convolution operator to mix the features of the adjacent patches of each patch, thereby increasing the associated weights of the adjacent patches to the center patch, thus emphasizing the local features of each patch. Since the feature types of the feature streams from different depths are different, we do not share the convolution weights for the feature streams at different levels in the feature pyramid. The formula for strengthening local features is as follows:</p><formula xml:id="formula_0">F le,i = ReLU (Conv i (C, C)(ReLU (Conv i (C i , C)(F i )))),<label>(1)</label></formula><p>where F le,i refer to the local emphasized feature from stage i, Conv i (C in , C out ) and Linear(C in , C out ) refer to a convolutional and linear layer with input channel C in and output channel C out . From the feature map given in <ref type="figure" target="#fig_1">Fig. 1(a)</ref>, it can be seen that the LE can effectively clean up cluttered noises and emphasize critical local features. In <ref type="figure" target="#fig_2">Fig. 2(b)</ref>, after the feature stream passes through LE, the disordered attention is re-condensed along with critical details such as contours and boundaries.</p><p>Stepwise Feature Aggregation (SFA) Experiments <ref type="bibr" target="#b12">[13]</ref> have demonstrated that the amount of information interacted through residual connections <ref type="bibr" target="#b6">[7]</ref> in the Transformer is more significant than that of the CNN model. This phenomenon can be understood as the weak correlation between the features of different depths in the Transformer, requiring a lot of information interaction for the layers of different depths to guide each other. As such, we believe that direct parallel aggregation of features of different stages with significant differences in depth in Transformer may generate an information gap.</p><p>In order for the feature aggregation to be as smooth as possible, the SFA progressively fuses the features of different levels in the feature pyramid from the top to bottom. From the perspective of the change of feature streams, it can be considered that the local features of the shallower layers are progressively fused into the global features of the deeper layer. This feature fusion method can reduce the information gap between the fused high-dimensional and lowdimensional features. As given in <ref type="figure" target="#fig_2">Fig. 2(c)</ref>, local features gradually guide the attention of the model to critical regions in the SFA. In <ref type="figure" target="#fig_1">Fig. 1(a)</ref>, the SFA consists of feature fusion units, linear fusion layers, and a linear prediction layer. The feature map of the fused structure in <ref type="figure" target="#fig_1">Fig. 1(a)</ref> (image with red border) shows that the SFA effectively incorporates local features into high-dimensional features and guides the feature stream into critical regions.</p><formula xml:id="formula_1">F i?1,i = ? ? ? Linear(2C, C)(Concat(F i?1 , F i )), OR, Linear(C, C)(Add(F i?1 , F i )),<label>(2)</label></formula><p>Since the feature stream has the same shape after passing through the LE module, we can use concatenation or addition operation in the feature fusion unit as Equation 2. In <ref type="table">Table 4</ref>, we see that both perform equally well. Concatenation is the default in SSFormer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Stepwise Segmentation Transformer</head><p>Based on the different encoder scales, we propose the SSFormer-S (Standard) and the SSFormer-L (Large) model. They achieve SOTA and competitive performance in several polyp segmentation benchmarks. Details are given in the experimental section. Moreover, SSFormer also achieved SOTA and competitive performance in ISIC-2018 and 2018 DATA Science Bowl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>Dataset and Evaluation Matrix Since the colon polyp segmentation task requires the model to have both accurate prediction and generalization capabilities, the performance of model on experimental and unseen benchmark datasets needs to be assessed separately. Therefore, following the experimental scheme of MSRF-Net <ref type="bibr" target="#b15">[16]</ref>, we train and test SSFormer on the Kavsir-SEG <ref type="bibr" target="#b7">[8]</ref> and CVC-ClinicDB <ref type="bibr" target="#b0">[1]</ref> benchmark datasets, respectively, to assess the accurate prediction and learning ability of models in the Kavsir-SEG and CVC-ClinicDB test set, respectively. In order to assess the generalization ability of SSFormer, we tested the model trained in Kavsir-SEG on CVC-ClinicDB and vice versa.</p><p>We refer to the experimental scheme of PraNet <ref type="bibr" target="#b5">[6]</ref> and UACANet <ref type="bibr" target="#b8">[9]</ref> that randomly extract 1450 images from the Kavsir and CVC-ClinicDB benchmark datasets to construct a training set (For fairness evaluation, we used the same training set as UACANet and PraNet), then test the model trained in this training set on the CVC-ColonDB <ref type="bibr" target="#b1">[2]</ref> and ETIS <ref type="bibr" target="#b14">[15]</ref> benchmark datasets. This test can demonstrate our model's accurate prediction and generalization ability in unseen datasets. Due to the variety of types and sizes of polyps in ETIS, it is the most challenging benchmark. The ISIC-2018 <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17]</ref> and 2018 Data Science Bowl <ref type="bibr" target="#b2">[3]</ref> benchmark datasets were also used in additional experiments. To unify the performance measures of the above two schemes, we only use mean Dice and mean IoU as evaluation matrices in our experimentation.</p><p>Implementation details We implement our model in PyTorch, which an NVIDIA TESLA A100 GPU accelerates. The AdamW optimizer is used with an initial learning rate of 0.0001, a decay rate of 0.1, and a decay period of 40 epochs. The training period is 200 epochs. Our loss function is the combined loss of Dice loss and BCE loss. During training, we resize the image to 352 ? 352. We employ random flipping, scaling, rotation, and random dilation and erosion as data augmentation operations. <ref type="table">Table 1</ref>. The performance of the SOTA methods was trained and tested on the same benchmark dataset, used to assess learning ability, the scores in the table refer to <ref type="bibr" target="#b15">[16]</ref> .    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalization Ability</head><p>We test the SSFormer trained on the CVC-ClinicDB and Kvasir datasets on the Kvasir and CVC-ClinicDB benchmarks, respectively. As mentioned in Section 3.1, this test result can reflect the generalization ability of our model. In <ref type="table" target="#tab_1">Table 2</ref>, our model achieves outstanding performance using this testing scheme. In addition, to further assess the generalization ability of SSFormer, we refer to the experimental scheme of PraNet, use the training set constructed from part of the Kvasir and CVC-ClinicDB datasets for training, and test the model on the CVC-ColonDB and ETIS benchmarks. The results in <ref type="table" target="#tab_2">Table 3</ref> demonstrate that our model significantly improves the SOTA performance (3%) in the most challenging ETIS and achieves superior performance in CVC-ColonDB. <ref type="figure" target="#fig_3">Fig. 3</ref> gives the prediction accuracy of our model on the ETIS benchmark. These results can prove that SSFormer has robust generalization and accurate prediction abilities. (The scores in <ref type="table" target="#tab_1">Table 2</ref> and <ref type="table" target="#tab_2">Table 3</ref> are obtained from <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b24">25]</ref>) <ref type="table">Table 4</ref>. Different encoder and decoder combinations performance with the same hyperparameter settings. The performance of different encoder and decoder combinations. The score is the performance of the model on the (CVC-ClinicDB, Kvasir) dataset group. (SeD is Segformer's Decoder, MiT is the Segformer's Encoder, and the CvT is proposed in <ref type="bibr" target="#b20">[21]</ref>) Encoder\Decoder MLA <ref type="bibr" target="#b22">[23]</ref> SeD <ref type="bibr" target="#b21">[22]</ref> PLD-Cat PLD-Add  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Study</head><p>In <ref type="table">Table 4</ref>, the PLD performs the best with the MiT. We believe that this is because the convolution operation inside MiT can maintain the consistency of the spatial information of the model. Furthermore, the experiments in <ref type="table" target="#tab_4">Table 5</ref> demonstrate the effectiveness of the PLD and its components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this research, we propose a novel deep learning model SSFormer, with robust generalization and learning ability. These are critical for polyp segmentation. Furthermore, we find that our model also demonstrates powerful learning ability in ISIC-2018 and 2018 Data Science Bowl benchmarks in additional experiments. We believe that the SSFormer has great potential to improve deep learning performance in other medical image segmentation tasks. Furthermore, experiments demonstrate that our proposed local feature emphasis module effectively constrains the attention dispersion of Transformers. Therefore, our research can be further used to optimize the Transformer backbone network for the general computer vision community and high generalizability medical applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>(a) the Overview of SSFormer; (b) the structure of Local Emphasis module. In this figure, The lines with arrows and the feature maps next to them represent unemphasized features, local emphasized features, and fused features from top to bottom along the feature stream direction, respectively. The remainder of the PLD in Figure (a), excluding the Local Emphasis (LE), is the Stepwise Feature Aggregation (SFA). Feature fusion units can use concatenation (Cat) or addition (+) operations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>(a) Attention heatmap for different decoder(SeD is Segformer's Decoder) (b) Attention Heatmap for the LE module (c) Attention Heatmap for the SFA Attention heatmap of feature flow through the PLD process.Figure (a)shows that the LE module successfully focuses the model's attention on critical details.Figure (b)shows that the SFA structure effectively constrains the model's chaotic attention stepwise to fine critical regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Predicted results of different methods</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>We split the CVC-ClinicDB and Kvasir benchmark datasets into 80% training set, 10% evaluation set and 10% test set according to the first scheme mentioned in Section 3.1.Table 1demonstrates that our model improves the SOTA result by about 1.8% on the CVC-ClinicDB benchmark and about 1% on the Kvasir benchmark. These performances demonstrate the superior accurate prediction and learning abilities of SSFormer.Furthermore, to assess the performance of SSFormer on other medical segmentation benchmarks, we conduct additional experiments on the ISIC-2018 and 2018 Data Science Bowl benchmark datasets. The results inTable 1reveal that our model achieves the SOTA and excellent performance on two benchmarks, 2018 Data Science and ISIC-2018, respectively.</figDesc><table><row><cell>Dataset</cell><cell>CVC-ClinicDB Kvasir-SEG</cell><cell cols="3">ISIC-2018 2018 Data-Sci Bowl</cell></row><row><cell>Methods</cell><cell cols="2">mDice mIoU mDice mIoU mDice mIoU</cell><cell>mDice</cell><cell>mIoU</cell></row><row><cell>U-Net</cell><cell cols="2">0.9145 0.8654 0.8629 0.8176 0.8554 0.7847</cell><cell>0.9080</cell><cell>0.8314</cell></row><row><cell>U-Net++</cell><cell cols="2">0.8453 0.7559 0.7475 0.6313 0.8094 0.7288</cell><cell>0.7705</cell><cell>0.3010</cell></row><row><cell cols="3">Deeplabv3+ 0.8897 0.8706 0.8965 0.8575 0.8772 0.8128</cell><cell>0.8857</cell><cell>0.8367</cell></row><row><cell>MSRF-Net</cell><cell cols="2">0.9420 0.9043 0.9217 0.8914 0.8824 0.8373</cell><cell>0.9224</cell><cell>0.8534</cell></row><row><cell cols="3">SSFormer-S 0.9268 0.8759 0.9261 0.8743 0.9195 0.8615</cell><cell>0.9254</cell><cell>0.8652</cell></row><row><cell cols="3">SSFormer-L 0.9447 0.8995 0.9357 0.8905 0.9242 0.8675</cell><cell>0.9230</cell><cell>0.8614</cell></row><row><cell>3.2 Results</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Learning ability</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Generalization Test 1</figDesc><table><row><cell cols="2">Train Set CVC-ClinicDB Kvasir-SEG</cell></row><row><cell>Test set</cell><cell>Kvasir-SEG CVC-ClinicDB</cell></row><row><cell>Methods</cell><cell>mDice mIoU mDice mIoU</cell></row><row><cell>U-Net</cell><cell>0.6222 0.4588 0.7172 0.6133</cell></row><row><cell>U-Net++</cell><cell>0.5926 0.4564 0.4265 0.3345</cell></row><row><cell cols="2">Deeplabv3+ 0.6746 0.5327 0.6509 0.5385</cell></row><row><cell>MSRF-Net</cell><cell>0.7575 0.6337 0.7921 0.6498</cell></row><row><cell cols="2">SSFormer-S 0.7790 0.6977 0.7966 0.7229</cell></row><row><cell cols="2">SSFormer-L 0.8270 0.7348 0.8339 0.7573</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Generalization Test 2</figDesc><table><row><cell>Train Set</cell><cell cols="3">Kvasir &amp; CVC-ClinicDB</cell></row><row><cell cols="3">Test Set CVC-ColonDB</cell><cell>ETIS</cell></row><row><cell>Method</cell><cell cols="3">mDice mIoU mDic mIoU</cell></row><row><cell>UACANet-S</cell><cell>0.783</cell><cell cols="2">0.704 0.694 0.615</cell></row><row><cell>UACANet-L</cell><cell>0.751</cell><cell cols="2">0.678 0.766 0.689</cell></row><row><cell>CaraNet</cell><cell>0.773</cell><cell cols="2">0.689 0.747 0.672</cell></row><row><cell>PraNet</cell><cell>0.712</cell><cell cols="2">0.640 0.628 0.567</cell></row><row><cell>SSformer-S</cell><cell>0.772</cell><cell cols="2">0.697 0.767 0.698</cell></row><row><cell cols="4">SSformer-L 0.802 0.721 0.796 0.720</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>The effect of PLD components on model performance. The score in the table follow (mDice, mIOU).</figDesc><table><row><cell>Decoder\Dataset Kvasir-SEG</cell><cell cols="2">ISIC-2018 2018 Data-Science Bowl</cell></row><row><cell cols="2">Without PLD 0.869, 0.918 0.855, 0.894</cell><cell>0.835, 0.904</cell></row><row><cell cols="2">LE 0.877, 0.925 0.860, 0.909</cell><cell>0.850, 0.915</cell></row><row><cell cols="2">SFA 0.885, 0.930 0.863, 0.918</cell><cell>0.858, 0.920</cell></row><row><cell cols="2">LE+SFA 0.891, 0.936 0.868, 0.924</cell><cell>0.861, 0.923</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments This work was supported by the Key Program Special Fund in XJTLU (KSF-A-22).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Wm-dova maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fern?ndez-Esparrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vilari?o</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards automatic polyp detection with a polyp appearance model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vilarino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3166" to="3182" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Nucleus segmentation across imaging experiments: the 2018 data science bowl</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Caicedo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Karhohs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Cimini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ackerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mcquin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1247" to="1253" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Skin lesion analysis toward melanoma detection: A challenge at the 2017 international symposium on biomedical imaging (isbi), hosted by the international skin imaging collaboration (isic)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gutman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Helba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Dusza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liopyris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 15th international symposium on biomedical imaging</title>
		<meeting><address><addrLine>In</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="168" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<title level="m">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pranet: Parallel reverse attention network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="263" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Kvasir-seg: A segmented polyp dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia Modeling</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Uacanet: Uncertainty augmented context attention for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Multimedia</title>
		<meeting>the 29th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2167" to="2175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Simvit: Exploring a simple vision transformer with sliding windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Caranet: Context axial reverse attention network for segmentation of small medical objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loew</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07368</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Intriguing properties of vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Naseer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ranasinghe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Do vision transformers see like convolutional neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Toward embedded detection of polyps in wce images for early diagnosis of colorectal cancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Histace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Romain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Granado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer assisted radiology and surgery</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="283" to="293" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Msrf-net: A multi-scale residual fusion network for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.07451</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The ham10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosendahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Attention is all you need. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pyramid vision transformer: A versatile backbone for dense prediction without convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="568" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">L D P F K S D L T L P L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<title level="m">Pvtv2: Improved baselines with pyramid vision transformer</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cvt: Introducing convolutions to vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="22" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Segformer: Simple and efficient design for semantic segmentation with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6881" to="6890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.11886</idno>
		<title level="m">Deepvit: Towards deeper vision transformer</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Unet++: A nested u-net architecture for medical image segmentation. In: Deep learning in medical image analysis and multimodal learning for clinical decision support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Rahman Siddiquee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="3" to="11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
