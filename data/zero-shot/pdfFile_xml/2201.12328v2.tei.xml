<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Toward Training at ImageNet Scale with Differential Privacy</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-02-08">February 8, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Chien</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roxana</forename><surname>Geambasu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Terzis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhradeep</forename><surname>Thakurta</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Toward Training at ImageNet Scale with Differential Privacy</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-02-08">February 8, 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differential privacy (DP) is the de facto standard for training machine learning (ML) models, including neural networks, while ensuring the privacy of individual examples in the training set. Despite a rich literature on how to train ML models with differential privacy, it remains extremely challenging to train real-life, large neural networks with both reasonable accuracy and privacy.</p><p>We set out to investigate how to do this, using ImageNet image classification as a poster example of an ML task that is very challenging to resolve accurately with DP right now. This paper shares initial lessons from our effort, in the hope that it will inspire and inform other researchers to explore DP training at scale. We show approaches that help make DP training faster, as well as model types and settings of the training process that tend to work better in the DP setting. Combined, the methods we discuss let us train a Resnet-18 with DP to 47.9% accuracy and privacy parameters ? = 10, ? = 10 ?6 . This is a significant improvement over "naive" DP training of ImageNet models, but a far cry from the 75% accuracy that can be obtained by the same network without privacy. The model we use was pretrained on the Places365 data set as a starting point. We share our code at https://github. com/google-research/dp-imagenet, calling for others to build upon this new baseline to further improve DP at scale.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine learning (ML) models are becoming increasingly valuable for improved performance across a variety of consumer products, from recommendations to automatic image classification and labeling. However, despite aggregating large amounts of data, it is possible for models to encode -and thus, in theory, "reveal" -characteristics of individual entries from the training set. For example, experiments in controlled settings have shown that language models trained using email datasets may sometimes encode sensitive information included in the training data <ref type="bibr" target="#b8">[9]</ref> and may have the potential to reveal the presence of a particular user's data in the training set <ref type="bibr">[36]</ref>. As such, it is important to prevent the encoding of such characteristics from individual training entries.</p><p>The standard rigorous solution to this problem is differential privacy (DP) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b13">14]</ref>. DP randomizes a computation over a dataset (such as training of an ML model) to bound the "leakage" of individual entries in the dataset through the output of the computation (the model). The randomness ensures that the model is almost as likely to be output independent of the presence or absence of any individual entry in the training set. This "almost as likely" is quantified by a privacy parameter, ? &gt; 0. If ? is small, the model cannot encode -and thus cannot "reveal" -much information about any individual entry.</p><p>Despite significant amounts of research in DP and machine learning, both on the theoretical front <ref type="bibr" target="#b10">[11,</ref><ref type="bibr">29,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr">37,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr">31,</ref><ref type="bibr" target="#b32">45,</ref><ref type="bibr">35,</ref><ref type="bibr" target="#b29">42,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr">39</ref>] and on the empirical front <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b30">43]</ref> over the past decade, training ML models with DP remains challenging in practice, which limits its adoption. First, DP often impacts utility, such as model accuracy. The impact on accuracy comes from the randomness introduced into the computation to eliminate memorization of individual entries in some models, which can help accuracy. Sometimes, the utility loss resulting from DP training is acceptable (or even could represents an improvement), but more often it is dramatically negative, making the resulting model useless. For example, when you simply switch from SGD to DP-SGD [37, <ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b1">2]</ref> to train a Resnet-18 or Resnet-50 on ImageNet, you get near-zero accuracy for any reasonable value of ?. Second, existing implementations of DP-SGD are inefficient <ref type="bibr">[40]</ref>. Indeed, DP-SGD involves some expensive operations, like computing per-example gradients instead of per-minibatch gradients as non-private SGD. This invalidates certain optimizations that are present in typical ML frameworks. In production, this overhead can be prohibitive, especially if the model needs to be retrained often. These two challenges have been preventing, on one hand, industry from adopting DP more widely and on the other hand, the research community from making progress on readying DP for wider adoption. For example, most DP research papers evaluate DP algorithms on very small datasets, such as MNIST, CIFAR-10, or UCI. This paper shares initial results from our ongoing effort to train a large image classification model on ImageNet using differential privacy while maintaining high accuracy and minimizing computational cost. We split the paper in two parts: (1) the main body, which communicates the main lessons we have learned to date and (2) a hefty appendix that includes significantly more data from our experimentation. Our goal is to inspire and inform other researchers who want to explore DP training at scale, including settings that work (our lessons) and those that may not (also covered in the appendix).</p><p>A first lesson we communicate (Section 2.2) is that a substantial amount of exploration -of architectures, techniques, and hyperparameters -is needed to discover a training setting that performs well with DP, and this exploration is impaired by the significant overheads of DP SGD implementations in most ML frameworks. We recommend JAX as a good ML framework to perform such exploration in, because it is surprisingly effective at automatically optimizing otherwise very expensive DP operations. A second lesson comes from our initial exploration of a few training settings for ImageNet, which combined let us DP-train a Resnet-18 to 47.9% accuracy and privacy parameter ? = 10 (Section 3), when pre-trained on Places365 data set. This marks a good improvement compared to "naive" DP training, which achieves few percent accuracy for the same privacy parameter, but it remains far from the 75% accuracy that can be obtained by the same network without privacy.</p><p>We share our code at https://github.com/google-research/dp-imagenet. By sharing an early snapshot of the lessons, results, and code from our ongoing project, we hope to energize others to work on improving DP for ambitious tasks such as Ima-geNet, as a proxy for challenging production-scale tasks. Our 47.9%-accuracy/? = 10 model should serve as a baseline to further improve upon to make DP training closer to practical at scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Privacy Notions and DP-SGD</head><p>ML Privacy Attacks. ML models are statistical aggregates of their underlying training data. Despite this, they have been shown to contain -and therefore, in theory, expose to attacks -information about the specific examples used to train them. For instance trained ML models, and even their predictions, have been shown to enable membership inference attacks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr">36</ref>] (e.g., an learns that a particular user was in the training set for a disease detection model), and reconstruction attacks <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b9">10]</ref> (e.g., an attacker reconstructs social security numbers from a language model).</p><p>Differential Privacy (DP). DP randomizes a computation over a dataset (such as training of an ML model) to bound the "leakage" of individual entries in the dataset through the output of the computation (the model). Intuitively, enforcing DP on the training procedure for an ML model ensures that the model is almost as likely to be output independent of the presence or absence of any individual entry in the training set; hence, the model cannot encode, and thus leak, much information about any individual entry. DP is known to address the preceding ML privacy attacks [36, <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b25">26]</ref>. At a high level, membership and reconstruction attacks work by finding data points that make the observed model more likely: if those points were in the training set, the likelihood of the observed output increases. DP prevents these attacks, as no specific data point can drastically increase the likelihood of the model outputted by the training procedure.</p><p>We state the formal definition of DP here.</p><p>Definition 2.1 (Differential privacy <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b13">14]</ref>). A randomized algorithm A is (?, ?)differentially private if, for any pair of datasets D and D differing in exactly one data point (called neighboring datasets) i.e., one data point is added or removed, and for all events S in the output range of A, we have</p><formula xml:id="formula_0">Pr[A(D) ? S] ? e ? ? Pr[A(D ) ? S] + ?,</formula><p>where the probability is over the randomness of A.</p><p>For meaningful privacy guarantees, ? is assumed to be a small constant, and ? 1/n where n is the size of D. DP-SGD. DP-SGD is currently the most widely-used differentially private machine learning algorithm in practice. Along with its practical success, it also provides optimal privacy/utility trade-offs analytically <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b6">7]</ref>. The full algorithm is described in Algorithm 1.</p><p>Algorithm 1 Differentially private stochastic gradient descent (DP-SGD)</p><formula xml:id="formula_1">Require: Data set D = {d 1 , ? ? ? , d n } with d i ? D, loss function: : R p ? D ? R,</formula><p>clipping norm: C, number of iterations: T , noise multiplier: ? 1: Randomly initialize ? 0 . 2: for t = 0, . . . , T ? 1 do 3:</p><formula xml:id="formula_2">Randomly select a mini-batch of examples B t ? D 4: g t ? d?Bt clip (? (? t ; d)), where clip(v) = v ? min 1, C v 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>? t+1 ? one step of first order optimization with gradient g t + N 0, (?C) 2 6: end for</p><formula xml:id="formula_3">7: return 1 T T t=1 ? t or ? T .</formula><p>The privacy guarantee of DP-SGD comes from that of Gaussian mechanism with privacy amplification by subsampling and privacy composition. In Step 4, clipping upper-bounds the 2 norm of each gradient in the mini-batch to be C, and thus the 2 norm of g t changes by at most C when we add or remove one example from the minibatch B t . Suppose ? t is the noise multiplier needed to achieve ? t -differential privacy in step t when B t is arbitrarily chosen. If, instead, B t is formed by sampling k examples u.a.r. and i.i.d. from D, then privacy amplification by sampling <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b31">44]</ref> allows one to scale down the noise to ? t ? (k/n) while achieving the same privacy guarantee. Similar subsampling schemes and analyses can be found in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr">31,</ref><ref type="bibr" target="#b38">51]</ref>. We can then accumulate the privacy loss in each step using composition, and obtain the final privacy cost of releasing all intermediate models</p><formula xml:id="formula_4">{? t } T t=1 as ? = O ? T ? t .</formula><p>In this paper we use DP-SGD privacy analysis to compute (?, ?)-DP guarantees for our experiments. We report ? at ? = 10 ?6 ? 1 DATASET SIZE in most of the results. However using smaller ? would only result in minor increase of ?, see Appendix I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Automatically Fast DP Training with JAX</head><p>The previous section describes how DP-SGD works at a high level. To understand why it is slow, let us compare SGD with DP-SGD in more detail. One step of SGD works as follows: (0) Draw a batch of examples from the dataset. (1) (Forward Pass) Compute the loss function on the batch. (2) (Backward Pass) Then compute an average of the gradients with respect to the model parameters, and apply the average gradients to the model parameters using a chosen learning rate and optimizer. DP-SGD differs as follows. In each step, gradients are computed individually for each example instead of for the whole batch. Then, these per-example gradients are clipped to be within an 2 -norm, C, to control the sensitivity of the gradient average computation. After clipping, gradients of all examples are added together and Gaussian noise is added to the gradient vector, per the Gaussian mechanism described above.</p><p>Finally, this clipped and noised gradient vector is applied to model parameters using the chosen learning rate and optimizer. This per-example gradient clipping slows down DP-SGD compared to SGD for the following reason. By default, ML frameworks -such as Tensorflow and PyTorchdo not directly compute per-example gradients and only provide aggregate, per-batch gradients. A na?ve way to obtain per-example gradients is to loop over the examples in the batch, or to configure a batch size equal to one example. Unfortunately, this approach loses all the benefits of parallel batch computations and results in N times slowdown compared to regular SGD, where N is the batch size.</p><p>However, the lack of parallelization is not an inherent issue of per-example clipping. If one manually writes the mathematical expressions for per-example gradient clipping, then it can be done in a parallel way at a cost of approximately one Forward and two Backward Passes. The Forward Pass proceeds as usual. At a first Backward Pass, norms of per-example gradients are accumulated. At a second Backward Pass, normalized gradients are computed. Thus, beyond this "1.5x" overhead, the overhead of a DP-SGD instantiation within a specific ML framework is probably caused by a suboptimal implementation of these operations inside the ML framework, rather than some inherent inefficiency of DP-SGD. This idea is inspired by <ref type="bibr" target="#b20">[21]</ref>.</p><p>Some DP-SGD libraries <ref type="bibr" target="#b35">[48]</ref> take the approach of manually implementing necessary per-example operations in an efficient way. This is valuable, however it can be time-consuming, error prone, and, importantly, difficult to evolve as new techniques for more effective DP-SGD training arise that may require changes within the underlying mathematical formulas. Thus we prefer to avoid such manual approach.</p><p>[40] first observed that using JAX, a high-performance computational library based on XLA one can do efficient auto-vectorization and just-in-time compilation of the mathematical expressions needed for evaluating the clipped mini-batch gradient. In this work too, we rely on JAX's autovectorization capabilities to compute the clipped minibatch gradients necessary for the execution of DP-SGD. While [40] empirically demonstrated the observation on CIFAR-10, we do the same on ImageNet. We confirm that JAX can do all the parallelization and optimization necessary for per-example gradient computations automatically. <ref type="table" target="#tab_6">Table 1</ref> shows the performance of DP and non-private training on MNIST and CI-FAR10 (corroborating the observation by <ref type="bibr">[40]</ref>). For both datasets we are using small convnets which are commonly used in DP literature <ref type="bibr" target="#b1">[2,</ref><ref type="bibr">34]</ref> These performance improvements can be quite important for research explorations with large networks, such as Resnet-18/Resnet-50 on ImageNet, whose runtimes without privacy are already orders of magnitude higher. <ref type="table" target="#tab_1">Table 2</ref> shows the runtime per training epoch in seconds for ImageNet on JAX when run on eight GPUs in parallel, for Resnet-18 and Resnet-50. Compared to non-private training, our JAX implementation is within 2x overhead, which we deem is fairly close to that rough theoretical best of "1.5x," and also within reasonable realm for DP exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Effective Training Settings for DP</head><p>Armed with this relatively faster JAX engine for DP-SGD training, we set out to answer the following question: Of the multitude of potential training settings -including model architectures, hyperparameter values, batch sizes, known DP methods, with their own settings -which combination can lead to both good accuracy and privacy on ImageNet? We are still at the beginnings of answering this question, and many more explorations remain to be done, but in this section we summarize a few observations we have made so far. They are:</p><p>Obs. 1: Choice of model matters, in particular smaller models tend to work better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Obs. 2:</head><p>More epochs is better than lower noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Obs. 3: Hyperparameter tuning makes a big difference.</head><p>Obs. 4: Extremely large batch size improves the privacy-utility tradeoff.</p><p>Obs. 5: Transfer learning from public data significantly boosts accuracy.  Similar observations can be found scattered in prior DP literature, but to our knowledge they have not been all combined and evaluated together. Our contribution thus lies in evaluating these methods on the ambitious ImageNet classification task, where we find they yield a reasonable new baseline for DP-training at scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Obs. 1: Choice of model matters</head><p>A large variety of models have been developed for non-private training on ImageNet and the question of which model design (if any) is more suitable for DP training is still wide open. In our exploration, we wanted to start with not too small but also not too big models, so we chose the Resnet-v2 [23] model family. Within that, we chose to focus on Resnet-50 and Resnet-18: the former is generally considered as a sufficiently powerful model for this dataset; the latter is a smaller model for comparison. We applied known rules to adapt these models for DP training. In particular, any crossbatch procedure during training -such as through batch normalization -breaks privacy analysis of DP-SGD and must be replaced with a per-batch procedure. In Resnet-50 and Resnet-18, we thus replaced batch normalization with group normalization <ref type="bibr" target="#b33">[46]</ref>.</p><p>In evaluating Resnet-50 and Resnet-18, we observe that model size impacts accuracy differently than one might expect in non-private training. In non-private training, one rule of thumb is that complex learning tasks, such as image classification on Ima-geNet, tend to do better with larger, more expressive networks. In DP training, larger is not always better. To obtain a desired level of privacy, ?, DP-SGD calls for adding a fixed amount of noise, ?, to every parameter independently of the model size. Thus, applying DP-SGD to large models causes a larger shift in the parameters of large models compared to smaller ones, which can lead to a negative effect on accuracy. <ref type="table" target="#tab_3">Table 3</ref> compares accuracies of Resnet-18 and Resnet-50 without DP, while <ref type="table" target="#tab_4">Table 4</ref> compares them with DP. Without DP <ref type="table" target="#tab_3">(Table 3)</ref>, we show accuracies achieved at different epochs, with tuned learning rate (LR) and a fixed LR = 0.4. The larger Resnet-50 tends to do better across the board. With DP (  for non-private training may not work for DP training. We also investigated the effect of model structure and size in CIFAR-10. Appendix H describes the methodology and results. There too, in the low ? regime, smaller and simpler networks tend to have better accuracy than networks that do best in non-private learning.</p><p>There is some limited prior work studying relationship between model size and accuracy with DP training. We found that such results for image models <ref type="figure">(Figure 1</ref> in <ref type="bibr">[32]</ref>, <ref type="table" target="#tab_1">Table 20</ref> in <ref type="bibr" target="#b30">[43]</ref>) agree with ours -larger models tend to perform worse. However results for language models are quite opposite. As reported in [30] during DP fine-tuning of language models, larger model architecture tends to be beneficial. We hypothesize that this is related to the following facts. First of all, the gradient spectrum of language models differ significantly from that of vision models <ref type="bibr" target="#b2">[3]</ref>. Second, (noisy) gradient descent tends to respect low-dimensional subspace induced by the gradients <ref type="bibr">[38]</ref>. Thus finetuning of language models might be happening in lower dimensional subspace when larger model size is beneficial. Nevertheless, future research in this direction is needed to fully understand these differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Obs. 2: More epochs is better than lower noise</head><p>Privacy loss bound ? of a DP-SGD training depends on noise multiplier ? and number of training steps. Higher noise multiplier ? leads to lower ?, but typically worse accuracy. Longer training leads to higher ? as described in Section 2. At the same time, at least in non-private setting, training for longer typically helps to achieve higher accuracy. Thus if one to set a fixed ? and wants to maximize accuracy, a natural question arises: Is it better to train longer with higher noise multiplier or train for fewer epochs with lower noise? <ref type="figure">Figure 1</ref> shows the accuracy achieved by Resnet-18 when training for increasing number of epochs while keeping the privacy loss ? constant by correspondingly decreasing the noise multiplier ?. In these experiments, training longer and with higher noise multiplier gives better accuracy than training for fewer epochs but with less noise. Nevertheless, accuracy reaches an upper bound somewhere between 40 and 70 epochs. Top-1 accuracy (c) ? = 9.7 ? 10 6 <ref type="figure">Figure 1</ref>: Resnet-18 accuracy while training for different number of epochs but keeping constant ?. We tuned learning rate independently and reported the best accuracy for each combination of ? and number of epochs. Specific accuracy numbers for these plots are available in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Obs. 3: Hyperparameter tuning makes a big difference</head><p>Training with DP-SGD requires setting extra hyper-parameters, such as the noise multiplier ? and the clipping norm C. Moreover, we observed that additional tuning of learning rate is typically necessary. The noise multiplier ? should be chosen to satisfy desired privacy budget. The clipping norm and learning rate should be tuned jointly for the best result. Appendix D gives results from our exploration of various values for learning rate and clipping norm. Here, we formulate a few observations we made experimentally on how to tune these parameters.</p><p>We observed that there is typically some threshold valueC, such that the best private accuracy is obtained when the clipping norm is smaller thanC. Below theC threshold, a wide range of values of the clipping norm can be used as long as the learning rate is adjusted accordingly. Specifically, when the clipping norm is decreased k times, the learning rate should be increased k times to maintain similar accuracy. However, a larger learning rate (with smaller clipping norm) may lead to less stable training, thus we recommend keeping the clipping norm close toC.</p><p>Overall, we recommend the following procedure to tune the clipping norm and learning rate: 2% Privacy loss bound ? 9.8 ? 10 8 6.1 ? 10 7 3.5 ? 10 6 6.7 ? 10 4 It is important to acknowledge that the preceding procedure for hyper-parameter tuning does not preserve privacy. We leave it for future work to develop such a private procedure, perhaps based on recent results [33].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Obs. 4: Large batch size improves the privacy-utility tradeoff</head><p>In theory, it is known that large minibatch size improves utility in DP-SGD, with fullbatch training giving the best outcome <ref type="bibr" target="#b28">[41,</ref><ref type="bibr" target="#b5">6]</ref>. (Here, full-batch training refers to using the entire dataset as the batch for each iteration.) Recently, <ref type="bibr" target="#b3">[4]</ref> corroborated this observation empirically on language models (e.g., BERT). Since, language models tend to have a different gradient profile (see <ref type="figure" target="#fig_4">Figure 5</ref> in <ref type="bibr" target="#b2">[3]</ref>) than vision models, it is nonobvious at the outset that a similar phenomenon would hold in the problem setup we consider. Via empirical evaluation, we demonstrate that the observations of <ref type="bibr" target="#b3">[4]</ref> extend to vision models too.</p><p>In practice, for large datasets like ImageNet, full batch does not fit into GPU/TPU memory, and an attempt to distribute it will result in a prohibitively large number of accelerators. For example, Resnet-50 training on one accelerator will typically fit a batch size of 64 or 128. Thus, full-batch training on ImageNet would require more than 9000 accelerators in distributed data-parallel regime. Fortunately, large batch and full batch training can be simulated by accumulating gradients over several steps before applying them, a process called virtual steps and already implemented in some DP libraries, including Opacus. <ref type="table" target="#tab_7">Table 5</ref> shows that joint scaling of batch size, number of training epochs and noise multiplier can lead to decrease of ? while maintaining a similar accuracy level. A batch size of 16*1024 means to make one gradient step, we accumulate in memory 16 virtual steps each with 1024 examples. As we increase the batch size, we must keep the number of training steps the same to maintain the same accuracy. This results in larger number training epochs as we increase batch size. <ref type="table" target="#tab_7">Table 5</ref> is demonstrational: the ? values shown there are entirely unacceptable for privacy. In <ref type="figure" target="#fig_1">Figure 2</ref>, we plot the ? value at different batch size, when the noise / batch ratio and the number of steps are fixed. However, the same effect of large-batch size being advantageous can be witnessed for more reasonable values of ?, albeit with much lower accuracy outcomes. For example, with a batch size of 16 * 1024 and 10 epochs, the Resnet-18 will obtain an accuracy of 5.8% for ? = 2.2 ? 10 5 . But with a much larger batch size of 1024 * 1024 (full-batch training) and a corresponding larger number of epochs of 640 (to preserve the total number of steps), the Resnet-18 will obtain a roughly equivalent 6.2% accuracy but for a (perhaps) more reasonable ? = 72. A recent work <ref type="bibr" target="#b11">[12]</ref> studies full-batch DP-SGD algorithm as an instantiation of Langevin Diffusion, and show a tighter privacy/utility trade-offs as compared to the standard optimization viewpoint <ref type="bibr" target="#b7">[8]</ref>. While the impact of this approach is yet to be realized in practice (as the improvement only holds for smooth and strongly convex losses), it is an important research direction to explore. For our paper, however, we remain in the realm of standard optimization view of DP-SGD, and instead combine large-batch training with transfer learning from public data, which offers a significant boost in accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Obs. 5: Transfer learning from public data significantly boosts accuracy</head><p>Pre-training on "public" data followed by DP fine-tuning on private data has previously been shown to improve accuracy on other benchmarks <ref type="bibr" target="#b30">[43,</ref><ref type="bibr" target="#b36">49,</ref><ref type="bibr">30]</ref>. We confirm the same effect on ImageNet. A big question with transfer learning is what public data to use for a given task. We were surprised to see that reasonable choices are quite effective. We pre-trained our models on Places365 <ref type="bibr" target="#b37">[50]</ref>, another image classification dataset, before fine-tuning them with DP-SGD on ImageNet. Places365 contains 1.8M images of various scenes with 365 labels describing the scene. This dataset has only images of landscapes and buildings, not of animals as ImageNet, so it is quite different. Thus we consider the pair (Places365, ImageNet) as a reasonable proxy for real world setups of public and private datasets.</p><p>In our experiments, we first non-privately train Resnet-18 on Places365 to 54.96% accuracy (see Appendix F). Then we strip the last linear layer of the model and replace it with a randomly initialized one with the 1000 output classes of the ImageNet classification. Finally, we try different schemes of fine-tuning this model on ImageNet with DP-SGD.</p><p>In a first set of experiments, we compared finetuning with training from scratch and explored whether keeping some layers frozen helps to increase accuracy, see   <ref type="table">Table 7</ref>: Accuracy of Resnet18 model which was pre-trained on Places365 and finetuned with DP-SGD on ImageNet. Each accuracy number was obtained by running learning rate sweep. Noise multiplier for each experiment was chosen in a way that in the end of the training ? = 10. Bold numbers highlight the best accuracy in each row, i.e. the best accuracy when number of training epochs and frozen blocks is fixed.</p><p>also suggest that freezing more layers tend to be better. It's possible that freezing less layers may work well when batch size and number of epochs are increased, however we didn't explore any further increase of number of epochs with finetuning in this paper.</p><p>In the second set of experiments we restrict ourself to freezing most of the network layers, and in this setup studied how batch size and number of epochs affect the final private accuracy, see table 7. These experiments reinforces our observation that longer training is generally better when ? is fixed. At the same we see that increase of batch size only helps to a certain point, after which it is actually hurting accuracy. As was mentioned earlier, increase of batch size generally should be done together with increasing number of epochs. Thus we hypothesize that number of training epochs in table 7 was not large enough to see benefits of batch sizes 256 * 1024 and 1024 * 1024.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Combining everything together</head><p>Combining all experiments and observations from previous sections, we managed to train a Resnet-18 on ImageNet to 47.9% accuracy with privacy budget ? = 10 by using the following hyperparameters:</p><p>? Start with a model pre-trained on Places365.</p><p>? Finetune this model on ImageNet with DP-SGD for 70 epochs with batch size 64 * 1024.</p><p>? Use cosine decay learning rate schedule with a warmup for 1 epochs. Maximum learning rate is 7.68.</p><p>? Use Nesterov momentum optimizer with standard decay 0.9.</p><p>? Use weight decay loss term with a coefficient 10 ?4 .</p><p>? Set clipping norm C = 1 and choose noise multiplier ? to satisfy privacy budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work we make a first attempt to train a model on ImageNet dataset with differential privacy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Resnet training without DP</head><p>We trained Resnet-18 and Resnet-50 models without differential privacy for various number of epochs, as shown table 3. We used the following training setup in these experiments:</p><p>? Nesterov momentum optimizer with momentum 0.9.</p><p>? Learning rate warmup for the first 5 epochs to maximum learning rate, followed by cosine decay to zero. In most of the non-private experiments we used the same maximum learning rate 0.4 which was originally tuned for 90 epochs Resnet-50 training. In some experiments we did additional tuning of the learning rate, which may result in a few percent accuracy boost.</p><p>? Weight decay loss term with coefficient 10 ?4 . We tried different values of weight decay coefficient and found that 10 ?4 is the best one.</p><p>? Total batch size was 1024 and training was done on 8 v100 GPUs or 8-core TPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Resnet training with DP-SGD</head><p>For DP-SGD training we generally used similar setup as for non-private training (see appendix A): Nesterov momentum optimizer, learning rate warmup followed by cosine decay, weight decay 10 4 and training on 8 GPUs or 8 TPU cores. The main differences is that we used DP-SGD version of the optimizer <ref type="bibr" target="#b1">[2]</ref>, which requires to set two extra parameters: clipping norm C and noise multiplier ?. Another difference is that we have to re-tune learning rate compared to non-private training. Additionally when training for 10 epochs we typically used only one epoch to warmup learning rate.</p><p>It should be noted that in our implementation Gaussian noise is added independently per GPU or per TPU core. This means that total noise added to the gradients has standard deviation of ? = ? 8? 1 where ? 1 is a standard deviation of noise added to single replica. That's why many tables in this report are showing ?/ ? 8 which is equal to standard deviation of per-replica noise.</p><p>We note that the ? of DP-SGD is computed through R?nyi differential privacy (RDP) analysis, and the conversion between RDP to DP can be affected by the choice of RDP orders. In this paper, we use a function <ref type="bibr" target="#b0">[1]</ref> in TF-Privacy to compute the DP ?. Due to the choice of RDP orders there, ? might be overestimated, especially in the low privacy / large ? regime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Experiments with fixed epsilon and different number of epochs</head><p>We did a series of experiments where we set ? to a desired value and then vary number of training epochs and other parameters. To run these experiments we need to compute noise multiplier ? based on desired ?, batch size, number of training epochs, etc... However privacy accountants from DP-SGD libraries typically provide a way to compute ? given noise multiplier, but not the other way around. To overcome this difficulty we used a routine from Tensorflow Privacy which computes ? based on noise multiplier and did a binary search with branching by geometric mean to find ? corresponding to the desired ?.</p><p>Plots with results of the experiments with fixed ? and different number of epochs are provided in the <ref type="figure">Figure 1</ref> in the main body of the paper.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Hyperparameter tuning for DP-SGD</head><p>While longer training can generally help increase utility, we found that training for 10 epochs is generally provide a reasonable idea of what we can expect in terms of accuracy. Thus to be able to do large hyperparameter sweeps within limited compute budget we restricted most of the hyperparameter sweeps to 10 epochs. For 10 epoch training of Resnet-18 we did a joint sweep of learning rate and clipping norm for various value of noise multiplier ?. For each value of ? we did one fine grained sweep of learning rate from {1, 2, 4, 8, 16, 40} and another coarse sweep where learning rate was increasing as a power of 10.</p><p>Results for non-private training with gradient clipping are provided in <ref type="figure">figure 3</ref>. As could be seen from the heatmap, model reaches highest accuracy for all C larger than 10. We can conclude that when C &gt; 10 clipping is no longer happening and it becomes effectively equivalent to training without clipping.</p><p>Results with non zero noise multiplier ? are provided in <ref type="figure">figure 4</ref>. In all of these experiments the best accuracy is obtained when C &lt; 10. This could be explained by the fact that standard deviation of Gaussian noise added to the gradients is computed 0.0008 0.008 0.08 0. as a product of C and ?. Thus if C is much large than the norm of the gradients then model updates will be dominated by the noise which will result in low utility. Another observation, that the subset of hyperparameters which correspond to the best utility lies on the curve learning rate ? C = const. This could be explained by the fact that if C is decreased k times then learning rate has to be increased also k times in order to keep updates roughly the same. Nevertheless, we observed that extremely high learning rates together with extremely low C typically lead to lower accuracy and less stable training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Details of large batch training sweep</head><p>We explored various combinations of batch size and number of training epochs to study how large batch training can help improving utility with DP-SGD, see table <ref type="bibr" target="#b8">9</ref>. In these experiments we used the following set of hyperparameters:</p><p>? Total Gaussian noise added on every training step has standard deviation ? = 0.001 ? ? 8 ? BatchSize 1024 . ? Clipping norm C was set to 1 in all experiments.</p><p>? Number of learning rate warmup epochs was set to <ref type="bibr">1 10</ref> of total number of training epochs.</p><p>? Learning rate was set to 16.0 in all experiments. While typically, it's recommended to scale learning rate when increasing the batch size <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b34">47,</ref><ref type="bibr" target="#b23">24]</ref>, it didn't seem to work well in this experiment. Specifically we have tried different learning rates from the set {4,    There is an input 7x7 convolution before the first block group and fully connected logits layer after the last block group. Each block group contains 2 residual blocks. Each residual blocks contains two convolutions with normalization layers and residual connection. Note that some of the residual blocks had projection and/or pooling operation on their residual connection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G DP-SGD finetuning experiments</head><p>We performed finetuning experiments on Resnet18 while optionally freezing some of the layers. Due to the structure of Resnet18 (see <ref type="figure" target="#fig_4">figure 5</ref>) we decided that it's most convenient to freeze layers at a block group level. So we did experiments for the following configurations of frozen/trainable layers:</p><p>? None frozen block groups. Entire network is trainable.</p><p>? 1 frozen block groups. Input convolution and block group 1 are frozen.</p><p>? 2 frozen block groups. Input convolution, block groups 1 and 2 are frozen.</p><p>? 3 frozen block groups. Input convolution, block groups 1, 2 and 3 are frozen.</p><p>? 4 frozen block groups. Everything except the last fully connected layer is frozen. Only last fully connected layer (logits layer) is trainable.</p><p>In the first set of experiments we did initial learning rate sweep using batch size 1024 to identify feasible range of learning rates for finetuning, and then run a series of DP-SGD experiments with frozen layers and batch size 1024*1024, see table 11. As could be seen from the table, when number of frozen block groups is less than 4 accuracy stays pretty low. Thus we focused further experiments on cases of 4 or 3 frozen block groups.</p><p>For 3 and 4 frozen block groups we did non private finetuning to estimate upper bound of accuracy which is possible to achieve, see table 12.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frozen block groups None</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Experiments on CIFAR-10</head><p>We aim to examine the effect of model size on the privacy-utility tradeoff. We consider a class of neural networks which includes the one used for differentially private CIFAR-10 classification in a few previous work <ref type="bibr">[34,</ref><ref type="bibr" target="#b26">27]</ref>. This class of networks, which we denote as simpleVGG, can be abstracted in the following way. A simpleVGG consists of multiple "blocks" and a linear layer, connected by max-pooling layers; each "block" consists of multiple convolution layers with the same number of channels. In the experiments, we will consider three sets of simpleVGG, in which we vary the number of convolution channels, number of layers per block, and the number of blocks, respectively. We fix the fully connected layer to size 128, and use tanh as the activation function. We use simpleVGG-32(2)-64(2)-128(2)-128 to denote a network with three blocks, each having two convolution layers with 32, 64 and 128 channels, and a fully connected layer of size 128 in the end. This is the neural network that has been used in previous work <ref type="bibr">[34,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>We train each neural network on CIFAR-10 for 100 epochs with batch size 500. We consider three different privacy levels for each setting: noise ? = 0.5, 1.5 and ? = 3.5, corresponding to ? = 47.41, 3.45, and 1.20 at ? = 10 ?5 . For each setting, we keep the clip norm to be 1.0 and use a momentum optimizer with learning rate tuned from {0.001, 0.002, 0.005, . . . , 0.1, 0.2, 0.5}.</p><p>In <ref type="figure" target="#fig_5">Figure 6</ref>, we plot the final test accuracy of 7 different simpleVGGs under different privacy levels, each with the learning rate that achieves the best final test accuracy. We compare networks with different number of convolution channels, different number of convolution layers per block, and different number of blocks in the three subplots. Clearly, in the non-private setting, accuracy increases with the complexity of the network. As ? grows, the gap becomes smaller and the simpler network gets the best accuracy when we vary the number of channels and number of convolution layers per block. In most of the text of the paper we provide (?, ?)-DP guarantees for fixed ? = 10 ?6 , i.e. ? ? 1 DATASET SIZE . In practice, these privacy guarantees come from DP-SGD privacy accountant and could be recomputed for different values of ?. <ref type="figure" target="#fig_6">Figure 7</ref> shows ? computed at different values of ? for our best training run, which achieves ? 48% final top-1 accuracy. 10 11 10 10 10 9 10 8 10 7 10 6 10 5 Delta </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>? value as batch size increases, with noise / batch size ratio and number of steps kept fixed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 Figure 3 :</head><label>13</label><figDesc>Sweep of clipping norm and learning rate when ? = 0. Left plot correspond to coarse sweep of hyperparameters, right plot correspond to more fine-grained sweep of learning rate. Values in the table is model accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Structure of Resnet-v2-18. Resnet18 contains 4 block groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Test accuracy for simpleVGGs on CIFAR-10. Averaged over 3 repeated runs. I Values of ? at different ?.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Relationship between ? and ? for our best training run, which achieves ? 48% top-1 accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>. Our results measure the time per training epoch in seconds, averaged over entire training (15 epochs for Average time per training epoch in seconds for ImageNet on JAX. Experiments run on eight V100 GPUs.It could be seen that DP-SGD training time for Resnet-18 and Resnet-50 is similar despite the fact that Resnet-18 is a smaller model. We didn't investigate this performance difference in details, but suspect that it might be related to the fact that Resnet-50 using bottleneck residual blocks, while Resnet-18 is using non-bottleneck blocks.</figDesc><table><row><cell>Dataset</cell><cell>DP/No DP</cell><cell cols="2">JAX (ours) Resnet-18 Resnet-50</cell></row><row><cell>ImageNet</cell><cell>DP</cell><cell>555.05</cell><cell>546.69</cell></row><row><cell>ImageNet</cell><cell>No DP</cell><cell>275.5</cell><cell>365.96</cell></row></table><note>MNIST, 90 epochs for CIFAR10). To minimize influence of data loader on the perfor- mance we cached datasets in memory. For non-private training, JAX and PyTorch do not show a consistent advantage over one another in these experiments, although they both show an advantage over Tensorflow. For DP training, JAX is consistently faster than both Opacus and TF-Privacy: 24 ? 44% improvement per epoch over Opacus and 76 ? 86% over TF-Privacy.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Comparison of Resnet-18 and Resnet-50 top-1 accuracy without DP, depending on number of training epochs.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 )</head><label>4</label><figDesc>, we show accuracies achieved at 10 epochs for various ? values with batch size 1024. Resnet-18 tends to outperform Resnet-50 when ? is low (and hence the privacy guarantees are better). On the other hand, when ? is very large, Resnet-50 starts to outperform Resnet-18 again, consistent with the non-private behavior. Further research is needed into whether simply using a smaller network, as we do here, is the right way to reduce dimensionality and the impact of DP noise on NN training. Another option might be to adapt ? to the statistics of individual parameters, as done in AdaClip[35]. Overall, though, our results point to the importance of adapting model architecture to DP training, since what tends to work Resnet-18 3.7% 6.9% 11.3% 45.7% 55.4% 56.0% 56.3% 56.4% Resnet-50 2.4% 5.0% 7.7% 44.3% 58.8% 57.8% 58.2% 58.6%</figDesc><table><row><cell>DP</cell><cell>4.6</cell><cell>13.2</cell><cell>71</cell><cell>privacy loss bound ? ? 10 7 10 9 10 11</cell><cell>10 13</cell><cell>10 15</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Comparison of the best Resnet-18 and Resnet-50 top-1 accuracies obtained at 10 epochs and batch size 1024, for various values of the privacy loss bound ? and fixed ? = 10 ?6 . The different ? values are obtained by applying to the gradient vector noise from Gaussian distributions with different standard deviations, ? ? {0.56, 0.42, 0.28, 2.8 ? 10 ?2 , 2.8 ? 10 ?3 , 2.8 ? 10 ?4 , 2.8 ? 10 ?5 , 2.8 ? 10 ?6 }, respectively. Clipping norm is fixed C = 1. Each accuracy number for Resnet-18 is obtained by sweeping over learning rates in {1, 2, 4, 8, 16, 40}. Each accuracy number for Resnet-50 is obtained by sweeping over learning rates in {0.4, 0.8, 1.6, 4, 8, 16, 40}.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>1 .</head><label>1</label><figDesc>Find a good set of hyperparameters in a non-private case (for example from a public dataset). Let ? pub be the good non-private learning rate.2. Sweep over various values of the clipping norm C with fixed learning rate ? puband zero noise ? = 0. Find the smallestC for which DP model accuracy remains close to the non-private model accuracy.3. Set the clipping norm toC and set the noise multiplier ? based on desired privacy budget. Run a learning rate sweep and find a good learning rate?. TypicallyC and? would be a reasonably good combination of hyperparameters for private training.4. Further grid search in the vicinity ofC and? may bring additional improvement of the accuracy.</figDesc><table><row><cell>Batch size</cell><cell>1024</cell><cell cols="3">4*1024 16*1024 64*1024</cell></row><row><cell>Num epochs</cell><cell>10</cell><cell>40</cell><cell>160</cell><cell>640</cell></row><row><cell>Accuracy</cell><cell>56%</cell><cell>57.5%</cell><cell>57.9%</cell><cell>57.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Resnet-18 accuracy and privacy (?) on ImageNet with increasingly large batches. All experiments used noise multiplier ? = 0.</figDesc><table><row><cell>001 ?</cell><cell>?</cell><cell>8 ? BatchSize 1024</cell><cell>and learn-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>table 6 .</head><label>6</label><figDesc>Unsurprisingly, finetuning is always better than training from scratch. These results</figDesc><table><row><cell></cell><cell cols="3">10 epochs 40 epochs 70 epochs</cell></row><row><cell>From scratch</cell><cell>12.0%</cell><cell>19.0%</cell><cell>20.6%</cell></row><row><cell>No frozen layers</cell><cell>29.2%</cell><cell>34.9%</cell><cell>37.7%</cell></row><row><cell>1 frozen block group</cell><cell>29.8%</cell><cell>35.1%</cell><cell>38.0%</cell></row><row><cell>2 frozen block groups</cell><cell>30.7%</cell><cell>36.0%</cell><cell>38.8%</cell></row><row><cell>3 frozen block groups</cell><cell>32.5%</cell><cell>38.9%</cell><cell>40.7%</cell></row><row><cell>4 frozen block groups</cell><cell>33.5%</cell><cell>36.3%</cell><cell>36.9%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Comparison of finetuning vs training from scratch with differential privacy. First row is training from scratch, other rows are finetuning with different number of frozen layers. Privacy budget was set to ? = 10 in all experiments. We used batch size 4 * 1024 and each accuracy number was obtained by sweeping learning rate in {0.016, 0.048, 0.16, 0.48, 1.6, 4.8, 16.0}. Bold number highlights the best accuracy in each column.</figDesc><table><row><cell>Frozen</cell><cell>Batch</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>block</cell><cell>size ?</cell><cell cols="5">4*1024 16*1024 64*1024 256*1024 1024*1024</cell></row><row><cell cols="2">groups Number of</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>epochs ?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>10</cell><cell>32.5%</cell><cell>39.6%</cell><cell>33.0%</cell><cell>18.6%</cell><cell>3.3%</cell></row><row><cell>3</cell><cell>40</cell><cell>38.9%</cell><cell>44.0%</cell><cell>44.9%</cell><cell>36.4%</cell><cell>17.0%</cell></row><row><cell></cell><cell>70</cell><cell>40.7%</cell><cell>45.0%</cell><cell>47.9%</cell><cell>41.7%</cell><cell>18.4%</cell></row><row><cell></cell><cell>10</cell><cell>33.5%</cell><cell>36.1%</cell><cell>37.0%</cell><cell>33.6%</cell><cell>23.1%</cell></row><row><cell>4</cell><cell>40</cell><cell>36.3%</cell><cell>37.2%</cell><cell>37.8%</cell><cell>37.0%</cell><cell>33.1%</cell></row><row><cell></cell><cell>70</cell><cell>36.9%</cell><cell>37.7%</cell><cell>38.0%</cell><cell>38.1%</cell><cell>34.7%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>To achieve this we study how various techniques and training parameters can affect accuracy of DP-SGD training. Combination of all of this findings enables us to train Resnet-18 on ImageNet to 47.9% accuracy with private budget ? = 10. While it may look relatively low compared to typical Resnet accuracy obtained in non-private training, one should keep in mind that "naive" Resnet training with DP-SGD on Im-ageNet will typically result in either only few percent accuracy or very high epsilon (which means lack of privacy).[29] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization and high-dimensional regression. In Conference on Learning Theory, pages 25-1, 2012. Thomas Steinke, Om Thakkar, and Abhradeep Thakurta. Evading the curse of dimensionality in unconstrained private glms. In Arindam Banerjee and Kenji Fukumizu, editors, Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, pages 2638-2646. PMLR, 13-15 Apr 2021.</figDesc><table><row><cell>[30] Xuechen Li, Florian Tramer, Percy Liang, and Tatsunori Hashimoto. Large lan-</cell></row><row><cell>guage models can be strong differentially private learners. In International Con-</cell></row><row><cell>ference on Learning Representations, 2022.</cell></row><row><cell>[31] H Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang.</cell></row><row><cell>Learning differentially private recurrent language models. arXiv preprint</cell></row><row><cell>arXiv:1710.06963, 2017.</cell></row><row><cell>[32] Nicolas Papernot, Steve Chien, Shuang Song, Abhradeep Thakurta, and Ulfar</cell></row><row><cell>Erlingsson. Making the shoe fit: Architectures, initializations, and tuning for</cell></row><row><cell>learning with privacy, 2020.</cell></row><row><cell>[33] Nicolas Papernot and Thomas Steinke. Hyperparameter tuning with renyi differ-</cell></row><row><cell>ential privacy, 2021.</cell></row><row><cell>arXiv preprint</cell></row><row><cell>arXiv:1908.07643, 2019.</cell></row><row><cell>[36] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Member-</cell></row><row><cell>ship inference attacks against machine learning models. In 2017 IEEE Symposium</cell></row><row><cell>on Security and Privacy (SP), pages 3-18, 2017.</cell></row><row><cell>[37] Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. Stochastic gradient</cell></row><row><cell>descent with differentially private updates. In 2013 IEEE Global Conference on</cell></row><row><cell>Signal and Information Processing, pages 245-248. IEEE, 2013.</cell></row><row><cell>[38] Shuang Song, [39] Shuang Song, Om Thakkar, and Abhradeep Thakurta. Characterizing private</cell></row><row><cell>clipped gradient descent on convex generalized linear problems. arXiv preprint</cell></row><row><cell>arXiv:2006.06783, 2020.</cell></row><row><cell>[40] Pranav Subramani, Nicholas Vadivelu, and Gautam Kamath. Enabling fast differ-</cell></row><row><cell>entially private sgd via just-in-time compilation and vectorization. arXiv preprint</cell></row><row><cell>arXiv:2010.09063, 2020.</cell></row></table><note>[34] Nicolas Papernot, Abhradeep Thakurta, Shuang Song, Steve Chien, and?lfar Erlingsson. Tempered sigmoid activations for deep learning with differential pri- vacy. arXiv preprint arXiv:2007.14191, 2020.[35] Venkatadheeraj Pichapati, Ananda Theertha Suresh, Felix X Yu, Sashank J Reddi, and Sanjiv Kumar. Adaclip: Adaptive clipping for private sgd.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell>contains detailed</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Resnet-18 accuracy while training for different number of epochs but keeping constant ?. For each of the experiments we did a learning rate sweep in {0.1, 0.2, 0.5, 1, 2, 4, 8, 16, 40} and reported the best accuracy. Row 10/1 correspond to training for 10 epochs with 1 epoch of learning rate warmup. Experiments in all other row used 5 epochs of learning rate warmup.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>Figure 4: Sweep of clipping norm and learning rate with various values of noise. Left column correspond to coarse sweep of both learning rate and clipping norm, right column correspond to more fine grained sweeps of learning rate. Values in the table is model accuracy.training model for 10 epochs with DP-SGD. We observed that learning rate 16 was the best or very close to the best for all considered batch sizes. ? 10 8 1.5 ? 10 7 2.2 ? 10 5 1.1 ? 10 3 ? 10 9 6.1 ? 10 7 8.9 ? 10 5 4.2 ? 10 3</figDesc><table><row><cell>Batch</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>size ?</cell><cell>1024</cell><cell cols="5">4*1024 16*1024 64*1024 256*1024 1024*1024</cell></row><row><cell>Num</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>epochs ?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>10</cell><cell>56%</cell><cell>35.5%</cell><cell>5.8%</cell><cell>1.6%</cell><cell>0.44%</cell><cell>0.14%</cell></row><row><cell></cell><cell cols="5">9.8 23</cell><cell>5.6</cell></row><row><cell>20</cell><cell>56.4%</cell><cell>53.1%</cell><cell>18.8%</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2 ? 10 9</cell><cell cols="2">3.0 ? 10 7 4.4 ? 10 5</cell><cell></cell><cell></cell><cell></cell></row><row><cell>40</cell><cell>61.7%</cell><cell>57.5%</cell><cell>39.5%</cell><cell>10%</cell><cell>1.3%</cell><cell>0.44%</cell></row><row><cell></cell><cell cols="5">3.9 48</cell><cell>11.9</cell></row><row><cell>80</cell><cell></cell><cell></cell><cell>54.3%</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>1.8 ? 10 6</cell><cell></cell><cell></cell><cell></cell></row><row><cell>160</cell><cell></cell><cell></cell><cell>57.9%</cell><cell>37.5%</cell><cell>8%</cell><cell>0.95%</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">3.5 ? 10 6 1.7 ? 10 4</cell><cell>120</cell><cell>28</cell></row><row><cell>640</cell><cell></cell><cell></cell><cell></cell><cell>57.2%</cell><cell>36.2%</cell><cell>6.2%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>6.7 ? 10 4</cell><cell>326</cell><cell>72.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 9 :Table 10 :</head><label>910</label><figDesc>ImageNet training using extremely large batches. Rows correspond to different number of training epochs, columns -to batch size. Each cell contains two numbers, top one is the accuracy and bottom one is ?. If cell is empty then corresponding experiment was not run.We tried to train Resnet-18 on Places365 for different number of epochs and with different learning rates, all other hyperparameters were the same as in case of ImageNet training (see appendix A). Our results are summarized in table 10. Since accuracy increase going from 40 to 80 epochs was very small we didn't try longer training and simply picked the training run with the best accuracy as a starting point for all finetuning experiments. Accuracy of Resnet-18 trained on Places365 dataset. Each accuracy number was obtained by sweeping learning rate in {0.02, 0.04, 0.08, 0.2, 0.4, 0.8, 1.6}.</figDesc><table><row><cell cols="4">F Pre-training on Places365 dataset</cell><cell></cell></row><row><cell>Num epochs</cell><cell>10</cell><cell>20</cell><cell>40</cell><cell>80</cell></row><row><cell cols="5">Best accuracy 51.41 53.16 54.26 54.96</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 11 :</head><label>11</label><figDesc>Private finetuning experiments with frozen layers. Training was done for 10 epochs with privacy budget ? ? 6. In this experiments we used Nesterov momentum optimizer with cosine learning rate decay and learning rate warmup for 1 epoch. We used batch size 1024 * 1024. Each accuracy number was obtained by sweeping learning rate in {4.096, 12.288, 40.96, 122.88, 409.6, 1228.8, 4096.0}</figDesc><table><row><cell>Frozen block groups</cell><cell>3</cell><cell>4</cell></row><row><cell cols="3">Best non private accuracy 66.7% 41.7%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 12 :</head><label>12</label><figDesc>Best results of non-private finetuning of Resnet18 model. All experiment were run for 80 epochs with batch size 1024 and by sweeping learning rate in {0.004, 0.012, 0.04, 0.12, 0.4, 1.2, 4.0}.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<ptr target="https://github.com/tensorflow/privacy/blob/a749ce4e3041003383be524f5efc3961ec6c1568/tensorflow_privacy/privacy/analysis/compute_dp_sgd_privacy_lib.py#L49" />
		<title level="m">Tensorflow Privacy library</title>
		<imprint>
			<biblScope unit="page" from="2022" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2016 ACM SIGSAC Conf. on Computer and Communications Security (CCS&apos;16)</title>
		<meeting>of the 2016 ACM SIGSAC Conf. on Computer and Communications Security (CCS&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient full-matrix adaptive regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Bullins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="102" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Large-scale differentially private BERT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Badih</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasin</forename><surname>Manurangsi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Membership privacy in microRNA-based studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Berrang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Humbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Manoharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGSAC Conference on Computer and Communications Security</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Stability of stochastic gradient descent on nonsmooth convex losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raef</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Crist?bal</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Private stochastic convex optimization with optimal rates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raef</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhradeep Guha</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d&apos;Alch?-Buc, Emily B. Fox, and Roman Garnett</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-14" />
			<biblScope unit="page" from="11279" to="11288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Private empirical risk minimization: Efficient algorithms and tight error bounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raef</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhradeep</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2014 IEEE 55th Annual Symp. on Foundations of Computer Science (FOCS)</title>
		<meeting>of the 2014 IEEE 55th Annual Symp. on Foundations of Computer Science (FOCS)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="464" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The secret sharer: Evaluating and testing unintended memorization in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?lfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jernej</forename><surname>Kos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th USENIX Conference on Security Symposium</title>
		<meeting>the 28th USENIX Conference on Security Symposium</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dawn Song,?lfar Erlingsson, Alina Oprea, and Colin Raffel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Tram?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Extracting training data from large language models</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Differentially private empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Monteleoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand D</forename><surname>Sarwate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1069" to="1109" />
			<date type="published" when="2011-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Differential privacy dynamics of langevin diffusion and noisy gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishav</forename><surname>Chourasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Revealing information while preserving privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irit</forename><surname>Dinur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kobi</forename><surname>Nissim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems</title>
		<meeting>the Twenty-second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Our data, ourselves: Privacy via distributed noise generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishnaram</forename><surname>Kenthapadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moni</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology-EUROCRYPT</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="486" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kobbi</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Third Conf. on Theory of Cryptography (TCC)</title>
		<meeting>of the Third Conf. on Theory of Cryptography (TCC)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="265" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Exposed! A survey of attacks on private data. Annual Review of Statistics and Its Application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Steinke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ullman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Robust traceability from trace amounts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Steinke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salil</forename><surname>Vadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 56th Annual Symposium on Foundations of Computer Science</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Amplification by shuffling: From local to central differential privacy via anonymity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?lfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananth</forename><surname>Raghunathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2468" to="2479" />
		</imprint>
	</monogr>
	<note>Kunal Talwar, and Abhradeep Thakurta</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Private stochastic convex optimization: Optimal rates in linear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Fifty-Second ACM Symp. on Theory of Computing (STOC&apos;20)</title>
		<meeting>of the Fifty-Second ACM Symp. on Theory of Computing (STOC&apos;20)</meeting>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Hiding among the clones: A simple and nearly optimal analysis of privacy amplification by shuffling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Audra</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.12803</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Efficient per-example gradient computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.01799</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Yangqing Jia, and Kaiming He. Accurate, large minibatch SGD: training imagenet in 1 hour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<editor>Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Train longer, generalize better: closing the generalization gap in large batch training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itay</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Soudry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Towards practical differentially private convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Iyengar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Near</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Om</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhradeep</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lun</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evaluating differentially private machine learning in practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bargav</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Practical and private (deep) learning without sampling or shuffling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Om</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhradeep</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">What can we learn privately?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Homin</forename><forename type="middle">K</forename><surname>Shiva Prasad Kasiviswanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kobbi</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sofya</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">D</forename><surname>Raskhodnikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">49th Annual IEEE Symp. on Foundations of Computer Science (FOCS)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="531" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Private empirical risk minimization beyond the worst case: The effect of the constraint set geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhradeep</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<idno>abs/1411.5417</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Differentially private learning with adaptive clipping. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Om</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galen</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Differentially private learning needs better features (or much more data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Tram?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Boneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Subsampled renyi differential privacy and analytical moments accountant</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiva</forename><surname>Prasad Kasiviswanathan</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics</title>
		<editor>Kamalika Chaudhuri and Masashi Sugiyama</editor>
		<meeting>the Twenty-Second International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2019-04" />
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="16" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Bolt-on differential privacy for scalable stochastic gradient descentbased analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">F</forename><surname>Naughton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data, SIGMOD</title>
		<editor>Semih Salihoglu, Wenchao Zhou, Rada Chirkova, Jun Yang, and Dan Suciu</editor>
		<meeting>the 2017 ACM International Conference on Management of Data, SIGMOD</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Group normalization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Scaling SGD batch size to 32k for imagenet training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Gitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yousefpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Testuggine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.12298</idno>
		<title level="m">Opacus: User-friendly differential privacy library in pytorch</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Differentially private fine-tuning of language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arturs</forename><surname>Backurs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivakanth</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Huseyin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautam</forename><surname>Inan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janardhan</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kulkarni</surname></persName>
		</author>
		<editor>Yin Tat Lee, Andre Manoel, Lukas Wutschitz, Sergey Yekhanin, and Huishuai Zhang</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Poission subsampled r?nyi differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7634" to="7642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simplevgg-32</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page">128</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simplevgg-32</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page">128</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">SimpleVGG</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">128</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simplevgg-32</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page">128</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simplevgg-32</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page">128</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
