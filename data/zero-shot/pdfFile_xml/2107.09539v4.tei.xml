<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parametric Scattering Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanel</forename><surname>Gauthier</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universit? de Montr?al</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Mila -Quebec AI Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Th?rien</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Mila -Quebec AI Institute</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Concordia University</orgName>
								<address>
									<settlement>Montreal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Waterloo University</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Als?ne-Racicot</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universit? de Montr?al</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Mila -Quebec AI Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muawiz</forename><surname>Chaudhary</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Mila -Quebec AI Institute</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Concordia University</orgName>
								<address>
									<settlement>Montreal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Rish</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universit? de Montr?al</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Mila -Quebec AI Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Belilovsky</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Mila -Quebec AI Institute</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Concordia University</orgName>
								<address>
									<settlement>Montreal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Eickenberg</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Flatiron Institute</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><forename type="middle">Guy</forename><surname>Wolf</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universit? de Montr?al</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Mila -Quebec AI Institute</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Parametric Scattering Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The wavelet scattering transform creates geometric invariants and deformation stability. In multiple signal domains, it has been shown to yield more discriminative representations compared to other non-learned representations and to outperform learned representations in certain tasks, particularly on limited labeled data and highly structured signals. The wavelet filters used in the scattering transform are typically selected to create a tight frame via a parameterized mother wavelet. In this work, we investigate whether this standard wavelet filterbank construction is optimal. Focusing on Morlet wavelets, we propose to learn the scales, orientations, and aspect ratios of the filters to produce problem-specific parameterizations of the scattering transform. We show that our learned versions of the scattering transform yield significant performance gains in small-sample classification settings over the standard scattering transform. Moreover, our empirical results suggest that traditional filterbank constructions may not always be necessary for scattering transforms to extract effective representations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The scattering transform, proposed in <ref type="bibr" target="#b29">[29]</ref>, is a cascade of wavelets and complex modulus nonlinearities, which can be seen as a convolutional neural network (CNN) with fixed, predetermined filters. This construction can be used to build representations with geometric invariants and is shown to be stable to deformations. It has been demonstrated to yield impressive results on problems involving highly structured <ref type="bibr">*</ref>   <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b38">38]</ref>, outperforming a number of other classic signal processing techniques. Since scattering transforms are instantiations of CNNs, they have been studied as mathematical models for understanding the impressive success of CNNs in image classification <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b30">30]</ref>. As discussed in <ref type="bibr" target="#b11">[12]</ref>, first-order scattering coefficients are similar to SIFT descriptors <ref type="bibr" target="#b27">[27]</ref>, and higher-order scattering can provide insight into the information added with depth <ref type="bibr" target="#b30">[30]</ref>. Moreover, theoretical and empirical study of information encoded in scattering networks indicates that they often promote linear separability, which leads to effective representations for downstream classification tasks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b31">31]</ref>.</p><p>Scattering-based models have been shown to be useful in several applications involving scarcely annotated or limited labeled data <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b36">36]</ref>. Indeed, most breakthroughs in deep learning in general, and CNNs in particular, involve significant effort in collecting massive amounts of well-annotated data to be used when training deep overparameterized networks. While big data is becoming increasingly prevalent, there are numerous applications where the task of annotating more than a small number of samples is infeasible, giving rise to increasing interest in smallsample learning tasks and deep-learning approaches towards them <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b43">43]</ref>. Recent work has shown that, in image classification, state-of-the-art results can be achieved by hybrid networks that harness the scattering transform as their early layers followed by learned layers based on a wide residual network architecture <ref type="bibr" target="#b33">[33]</ref>. Here, we further advance this research avenue by proposing to use the scattering paradigm not only as fixed preprocessing layers in a concatenated architecture, but also as a parametric prior to learn filters in a CNN. This allows us to also shed light on whether the standard wavelet construction <ref type="bibr" target="#b28">[28]</ref> is an optimal approach for building filterbanks from a mother-wavelet for discriminative tasks.</p><p>Recall that the scattering construction is based on complex wavelets, generated from a mother wavelet via dilations and rotations, aimed to cover the frequency plane while having the capacity to encode informative variabil-ity in input signals <ref type="bibr" target="#b11">[12]</ref>. Further, discrete parameterization and indexing of these operations (i.e., by dilation scaling or rotation angle) have traditionally been carefully constructed to ensure the resulting filter bank forms an efficient tight frame <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b29">29]</ref> with well-established energy preservation properties. On the other hand, it has been observed that the first layers of convolutional networks resemble wavelets but may not necessarily form a tight frame <ref type="bibr" target="#b24">[24]</ref>. The question then arises: is it necessary to use the standard wavelet filterbank construction? Here, we relax the standard construction by considering another alternative where a small number of wavelet parameters used to create the wavelet filterbanks are optimized for the task at hand.</p><p>To our knowledge, this is the first work that aims to learn the wavelet filters of scattering networks in 2D signals. Related work and the empirical protocol are summarized in Sec. 3. and Sec. 4 respectively. In Sec. 4.1, we compare scattering parameterizations obtained from optimizing over different datasets. In Sec. 4.2, we evaluate the robustness of our parametric scattering networks to deformation. In Sec. 4.3, we demonstrate the advantages of our approach in limited labeled data settings and study the adaptation of the wavelet parameters toward a supervised task. In Sec. 4.4, we investigate the adaptation of the parametrized scattering using an unsupervised objective. Finally, in Sec. 4.5 we evaluate the computational and memory complexity of our hybrid networks. Further technical details appear in appendices, and code accompanying the work is available at https://github.com/ bentherien/parametricScatteringNetworks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Learning useful representations from little training data <ref type="bibr" target="#b8">[9]</ref> is arduous and a reality in a variety of domains such as in biomedicine and healthcare. Recent works have tried to tackle this problem. Lezama et al. <ref type="bibr" target="#b26">[26]</ref> replace the categorical cross-entropy loss with a geometric loss called Orthogonal Low-rank Embedding (OL?) to reduce the intraclass variance and enforce inter-class margins. <ref type="bibr">Barz and Denzler [8]</ref> also propose to replace the categorical crossentropy loss, but this time with the cosine loss function in order to decrease overfitting in the small-sample classification settings. The cosine loss function, as opposed to the softmax function used with cross-entropy, does not push the logits of the true class to infinity. Other methods show promise by incorporating prior knowledge into the model <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b23">23]</ref>. Oyallon et al. <ref type="bibr" target="#b33">[33]</ref> introduce hybrid networks where the scattering transform with fixed wavelets was shown to be an effective replacement for early layers of learned convolutional networks on a wide residual network architecture. Cotter and Kingsbury <ref type="bibr" target="#b14">[15]</ref> also propose a hybrid network called a learnable ScatterNet, where learning layers are intermixed between the scattering or-ders, unlike our work where only a few parameters governing the wavelet construction are modified. Ulicny et al. <ref type="bibr" target="#b41">[41]</ref> propose Harmonic Networks (HN), a hybrid network consisting of fixed Discrete Cosine Transform filters combined with learnable weights in CNNs.</p><p>Related to our work, adding learnable components to existing wavelet-based representations has been considered in a number of recent works in the context of time-series <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b35">35]</ref>. Balestriero et al. <ref type="bibr" target="#b5">[6]</ref> and Seydoux et al. <ref type="bibr" target="#b35">[35]</ref> learn a spline-parametrized mother wavelet for 1D problems. Similarly, Cosentino and Aazhang <ref type="bibr" target="#b13">[14]</ref> parametrized the group transform in the context of time-series data. Our work, alternatively, focuses on 2D problems and maintains the canonical Morlet wavelet parameterization, but allows deviation from a tight-frame filter bank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Parameterization of Scattering Networks</head><p>We first revisit the formulation of traditional scattering convolution networks in Sec. 3.1 and introduce our parametric scattering transform in Sec. 3.2 and 3.4. Finally, Sec. 3.3 discusses scattering parameter initialization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Scattering Networks</head><p>For simplicity, we focus here on 2D scattering networks up to their 2nd order. Subsequent orders can be computed by following the same iterative scheme, but have been shown to yield negligible energy <ref type="bibr" target="#b11">[12]</ref>. Given a signal x(u), where u is the spatial position index, we compute the scattering coefficients S 0 x, S 1 x, S 2 x, of order 0, 1, and 2 respectively. For an integer J, corresponding to the spatial scale of the scattering transform, and assuming an N ? N signal input with one channel, the resulting feature maps are of size N 2 J ? N 2 J , with channel sizes varying with the scattering coefficient order (i.e., 1 channel at order 0, JL channels at order 1 and L 2 J(J ? 1)/2 channels at order 2).</p><p>To calculate 0th-order coefficients, we consider a lowpass filter ? J with a spatial window of scale 2 J , such as a Gaussian smoothing function. We then convolve this filter with the signal and downsample by a factor of 2 J to obtain S 0 x(u) = x * ? J (2 J u). Due to the low-pass filtering, highfrequency information is discarded here and is recovered in higher-order coefficients via wavelets introduced as in a filter bank.</p><p>Morlet wavelets are a typical example of filters used in conjunction with the scattering transform, and are defined as</p><formula xml:id="formula_0">? ?,?,?,? (u) = e ??D? R ? (u)? 2 /(2? 2 ) (e i?u ? ? ?),<label>(1)</label></formula><p>where ? is a normalization constant to ensure wavelets integrate to 0 over the spatial domain, u ? = u 1 cos ? + u 2 sin ?, R ? is the rotation matrix of angle ? and D ? = 1 0 0 ? .</p><p>The four parameters can be adjusted and are presented in <ref type="table">Table 1</ref>. From one wavelet ? ? ? ,? ? ,? ? ,? ? (u), the traditional </p><formula xml:id="formula_1">-2j ? ? ? ,? ? ,? ? ,? ? (2 -j R ? (u))},</formula><p>which is then completed with the lowpass ? J . This can be written in terms of the parameters in <ref type="table">Table 1</ref> as</p><formula xml:id="formula_2">? 2 j ? ? ,? ? ??,2 -j ? ? ,? ? (u) = ?(2 -j R ? (u))</formula><p>. By slight abuse of notations, we use ? ? here, ? = (? j , ?, ? j , ? j ), to denote such wavelets indexed by ? and j. The resulting set of filters is visualized in the frequency domain in <ref type="figure" target="#fig_2">Figure 2</ref>. First-order scattering coefficients are calculated by first convolving the input signal with one of the generated complex wavelets (i.e., indexed by the parameters in <ref type="table">Table 1</ref>) and downsampling the resulting filtered signal by the scale factor 2 j1 of the wavelet chosen. Then, a pointwise complex modulus is used to add nonlinearity, and the resulting real signal is smoothed via a low-pass filter. Finally, another downsampling step is applied, this time by a factor of 2 J?j1 , to obtain an optimally compressed output size. Mathematically, we have</p><formula xml:id="formula_3">S 1 x(? 1 , u) = |x * ? ?1 | * ? J (2 J u).<label>(2)</label></formula><p>The resulting feature map has J ? L channels, based on the number of wavelets in the generated family. Second-order coefficients are generated similarly, with the addition of another cascade of wavelet transform and modulus operator before the low-pass smoothing, i.e.,</p><formula xml:id="formula_4">S 2 x(? 1 , ? 2 , u) = ||x * ? ?1 | * ? ?2 | * ? J (2 J u). (3)</formula><p>Due to the interaction between the bandwidths and frequency supports of first and second order, only coefficients with j 1 &lt; j 2 have significant energy. Hence, the secondorder output yields a feature map with 1 2 J(J ? 1)L 2 channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Morlet Canonical Parameterization</head><p>While the wavelet filters are traditionally fixed, we let the network learn the optimal parameters of each wavelet. In other words, we constrain our filters to always be Morlet wavelets by only optimizing the parameters in <ref type="table">Table 1</ref>. We call this approach the Morlet canonical parameterization of the wavelet. To provide such data-driven optimization of scattering parameters, we show, in Appendix C, that it is possible to backpropagate through this construction. We adapted the Kymatio software package <ref type="bibr" target="#b3">[4]</ref> to create the learnable scattering network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Initialization</head><p>To evaluate the importance of the standard wavelet construction, we consider two initializations and study their impact on resulting performance in both learned and nonlearned settings. First, the standard wavelet construction follows common implementations of the scattering transform by setting ? j,? = 0.8 ? 2 j , ? j,? = 3? 4 2 -j , and ? j,? = 4 L for j = 1, . . . , J, ? = 1, . . . , L, while for each j, we set ? j,? to be equally spaced on [0, ?). The construction ensures the resulting filter bank forms an efficient tight frame. Thus, we call this construction the tight-frame initialization. Second, as an alternative, we consider a random initialization where these parameters are sampled as</p><formula xml:id="formula_5">? j,? ? log(U [exp 1, exp 5]), ? j,? ? U [0.5, 1], ? j,? ? U [0.5, 1.5], and ? j,? ? U [0, 2?].</formula><p>That is, orientations are selected uniformly at random on the circle, the filter width ? is selected using an exponential distribution across available scales and the spatial frequency ? is chosen to be in the interval [0.5, 1], which lies in the center of the feasible range between aliasing (&gt; ?) and the fundamental frequency of the signal size (2?/N where N is the number of pixels). Finally, we select the aspect ratio variable to vary around the spherical setting of 1.0, with a bias towards stronger orientation selectivity (0.5) compared to lesser orientation selectivity (1.5). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KTH-TIPS2</head><p>COVIDx-CRX2 CIFAR-10 tight-frame <ref type="figure" target="#fig_2">Figure 2</ref>. Parametric scattering network learns dataset specific filters. The graph (top right) shows the filterbank distance over epochs as the filters are trained on different datasets. We visualize dataset specific parameterizations of scattering filterbanks (border colors from the legend) in Fourier space. The x and y axis are the frequency axis. Scattering filters optimized for natural (CIFAR-10) and medical image (COVIDx CRX2) become more orientation-selective, i.e., thinner in the Fourier domain. On the other hand, filters optimized for texture discrimination (KTH-TIPS2) become less orientation-selective and deviate most from a tight-frame setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Morlet Equivariant Parameterization</head><p>In the Morlet canonical parameterization approach, the canonical parameters of each filter are learned. As an alternative method, we consider the Morlet equivariant parameterization in which the number of learnable parameters is reduced by a factor L compared to the Morlet canonical parameterization. Each filter per scale is constructed using the same four parameters in <ref type="table">Table 1</ref>: ?, ?, ? and ?. However, the global orientation of the L filters for each scale are set to be [?, ? + ? L , ? + 2? L , . . . , ? + (L?1)? L ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Our empirical evaluations are based on three image datasets: CIFAR-10, COVIDx CRX-2, and KTH-TIPS2. CIFAR-10 and KTH-TIPS2 are natural image and texture recognition datasets, correspondingly. They are often used as general-purpose benchmarks in similar image analysis settings <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b36">36]</ref>. COVIDx CRX-2 is a dataset of X-ray scans for COVID-19 diagnosis; its use here demonstrates the viability of our parametric scattering approach in practice, e.g., in medical imaging applications.</p><p>We evaluate the use of the parametrized scattering with two common models. In the first case, we consider the scattering as feeding into a simple linear model (denoted LL). The LL configurations are used to evaluate the linear separability of the obtained scattering representations and have the added benefit of providing a more interpretable model. In the second case, we take the approach of <ref type="bibr" target="#b33">[33]</ref> and consider the scattering as the first stage of a deeper CNN, specifically a Wide Residual Network (WRN) <ref type="bibr" target="#b44">[44]</ref>. The architecture of the WRN hybrid is described in more detail in Appendix B.</p><p>For both models (LL and WRN), we compare learned parametric scattering networks (LS) to fixed ones (S). For learned scattering (LS), we consider two scattering parameterization approaches: Morlet canonical, described in Sec. 3.2 and Morlet equivariant, described in Sec. 3.4. To show the importance of the parametric approach, we also ablate the naive parameterization where all pixels of the wavelets are adapted, which we refer to as a pixel-wise parameterization. For each scattering architecture, we consider both random and tight-frame (TF) initialization. The fixed scattering models determined by the TF construction are equivalent to traditional scattering transforms. Finally, we also compare our approach to a fully learned WRN (with no scattering priors) and ResNet-50 <ref type="bibr" target="#b18">[19]</ref> applied directly to input data. We note that the latter is unmodified form its ImageNet architecture and that we do not initialize it with pre-trained weights.</p><p>Across all scattering configurations, a batchnormalization layer with learnable affine parameters is added after all scattering layers. Classification is performed via a softmax layer yielding the final output. All models are trained using cross-entropy loss, minimized by stochastic gradient descent with momentum of 0.9. Weight decay is applied to the linear model and to the WRN. The learning rate is scheduled according to the one cycle policy <ref type="bibr" target="#b39">[39]</ref>. Implementation details specific to each dataset are described in Appendix A. We replicate some of the experiments with learnable scattering networks followed by WRN on CIFAR-10, COVIDx-CRX2, and KTH-TIPS2 using the cosine loss function <ref type="bibr" target="#b7">[8]</ref>. The results are reported in Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Exploring Dataset-specific Parameterizations</head><p>We first compare dataset-specific Morlet wavelet parameterizations and evaluate their similarities to a tight frame. Specifically, we train our parametric scattering networks us-  ing the canonical Morlet wavelet formulation with a linear classification layer and qualitatively compare the similarities of the learned filter bank to the tight-frame initialization. To facilitate quantitative comparison, we use a distance metric for comparing the sets of Morlet wavelet filters and Morlet wavelet filterbanks (i.e., scattering network instantiations), allowing us to measure deviations from the tight-frame initialization. We evaluate distances between two individual Morlet wavelets as</p><formula xml:id="formula_6">?(M 1 , M 2 ) = (? 1 , ? 1 , ? 1 ) T ? (? 2 , ? 2 , ? 2 ) T 2 + arcdist(? 1 , ? 2 ) where M i = (? i , ? i , ? i , ? i ) T denotes</formula><p>the parameterization of the Morlet wavelet. We use the arc distance on the unit circle to compare values of theta. Since the set of learned scattering filters does not have a canonical order, to compare a learned scattering network to the tight frame scattering network, we use a matching algorithm to match one set of filters to another. Specifically, we first compute ? between all combinations of filter pairs from both networks, then use a minimum cost bipartite matching algorithm <ref type="bibr" target="#b25">[25]</ref> to find the minimal distance match between the two sets of filters. The final distance we use as a notion of similarity between two scattering networks is the sum of ? for all matched pairs in the bipartite graph. Henceforth, we will refer to this distance as the filterbank distance.</p><p>The graph in <ref type="figure" target="#fig_2">Figure 2</ref> leverages the filterbank distance to show the evolution of scattering networks initialized from a tight frame and trained on different datasets. Each network is trained on 1188 samples of its respective dataset (the standard size for KTH-TIPS2). All filters deviate quickly from a tight frame, but KTH-TIPS2's keep changing the longest and ultimately deviate the most. We also observe that filters initialized with the random initialization of Sec. 3 become more similar to our tight-frame initialization during the course of training (see <ref type="figure" target="#fig_2">Figure 12</ref> in Appendix I.4).</p><p>On the left-hand side of <ref type="figure" target="#fig_2">Figure 2</ref>, we visualize the dataset-specific scattering network parameterizations in Fourier space. White contours are drawn around each Morlet wavelet for clarity. The top black border corresponds to tight-frame initialization at J=2, shown for comparison to CIFAR-10 in blue (also J=2). The bottom black border corresponds to tight-frame initialization at J=4, shown for comparison to COVIDX-CRX2 red and KTH-TIPS2 yellow (both J=4).</p><p>The filters optimized on the KTH-TIPS2 texture dataset (yellow) become less orientation-selective (wider in Fourier space) than the tight-frame initialization, with filters at J=0 becoming the least orientation-selective of the whole filter bank. We note that the filters at spatial scales J= 2 and 3 seem to change the most from a tight frame as illustrated in the appendix <ref type="figure" target="#fig_6">(Fig. 10</ref>). In contrast, the filters optimized on COVIDx-CRX2 become more orientation-selective in general i.e., thinner in Fourier space, while changing the most at spatial scale J=0 as shown in the appendix <ref type="figure" target="#fig_8">(Fig. 8</ref>). The filters optimized on CIFAR-10 mirror those optimized on COVIDx-CRX2, also becoming more orientation-selective than their tight-frame counterparts. We suspect that this is due to a reliance on edges for object classification datasets, which seem to require more orientation-selective filters. On the other hand, the morlet wavelets optimized for texture classification seem to discard some edge information in favor of less orientation-specific filters. Each dataset-specific parameterization seems to discard unneeded information from the tight-frame initialization in favor of accentuating problem-specific attributes. In Sec. 4.3, we demonstrate these learned filters are not only interpretable but improve task performance, suggesting the tight frame is not optimal for many problems of interest. Nonetheless, a tight-frame does constitute a good starting point for learning. Indeed, the dataset-specific parameterizations for COVIDX-CRX2 and KTH-TIPS2 are, visually, very different, yet they move similar filterbank distances from the tight-frame initialization (see <ref type="figure" target="#fig_2">fig.2</ref>), which are small relative to the distances observed for randomly initialized and trained models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Robustness to Deformation</head><p>In <ref type="bibr" target="#b29">[29]</ref>, it is shown that the scattering transform is stable to small deformations of the form x(u ? ? (u)) where x(u) is a signal and ? a diffeomorphism. Given the substantial changes to the filter composition in the learning process, we ask now whether these seem to significantly deviate from the stability result obtained from the carefully handcrafted construction proposed in <ref type="bibr" target="#b29">[29]</ref> and extensively used in previous work e.g., <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17]</ref>. To evaluate the robustness of our parametric scattering networks to different geometric distortions, we apply several tractable deformations to a chest X-ray image x with varying deformation strength and encode all images with different (learned and fixed) scattering networks. The learned ones are trained using the Morlet canonical wavelet formulation with a linear classification layer. The transformed image is denoted byx. For each of the different deformation strengths, we plot the Euclidean distance between the scattering feature constructed from the original image S(x) and the scattering feature constructed from the transformed image S(x). We then normalize the obtained distance by S(x) to measure the relative deviation in scattering coefficients (handcrafted or learned). <ref type="figure" target="#fig_1">Figure  3</ref> demonstrates representative results for a small rotation, shear and scale on images from the COVIDx datasets, while additional deformations are shown in Appendix G. We observe that the substantial change in the filter construction retains the scattering robustness properties for these simple deformations, thus indicating that the use of learned filters (instead of designed ones) does not necessarily detract from the stability of the resulting transform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Small Data Regime</head><p>We evaluate the parametric scattering network in limited labeled data settings. Following the evaluation protocol from <ref type="bibr" target="#b33">[33]</ref>, we subsample each dataset at various sample sizes to showcase the performance of scattering-based architectures in the small data regime. In our experiments, we train on a small random subset of the training data but always test on the entire test set as done in <ref type="bibr" target="#b33">[33]</ref>. To obtain comparable and reproducible results, we control for deterministic GPU behavior and assure that each model is initialized the same way for the same seed. Furthermore, we use the same set of seeds for models evaluated on the same number of samples. For instance, the TF learnable hybrid with a linear model would be evaluated on the same ten seeds as the fixed tight-frame hybrid with a linear model when trained on 100 samples of CIFAR-10. Some fluctuation is inevitable when subsampling datasets. Hence all our figures include averages and standard error calculated over different seeds.</p><p>CIFAR-10 consists of 60,000 images from ten classes. The train set contains 50,000 class-balanced samples, while the test set contains the remaining images. <ref type="table" target="#tab_3">Table 2</ref> reports the evaluation of our learnable scattering approach on CIFAR-10 with training sample sizes of 100, 500, 1K, and 50K. The training set is augmented with horizontal flipping, random cropping, and pre-specified autoaugment <ref type="bibr" target="#b15">[16]</ref> for CIFAR-10. We used autoaugment <ref type="bibr" target="#b15">[16]</ref> to showcase the best possible small-sample results and ablate this component in Appendix E. We use a spatial scale of J = 2 in the scattering transforms.</p><p>As shown in <ref type="table" target="#tab_3">Table 2</ref>, the scattering networks with wavelets optimized pixel-wise perform the worst in the small-data regime. It shows that with limited labeled samples, there is not enough data and too many learnable parameters to learn effectively the pixels of the wavelets. Adding more constraints (i.e., constraining the wavelets to be Morlet) is beneficial in this setting. We also observe that the Morlet canonical parameterization yields a similar performance to the Morlet equivariant parameterization (i.e., most standard errors overlap). Thus, adding even more con- straints, by reducing the number of learnable parameters in the parametric scattering transform, does not degrade the performance in the small-data regime. We observe that randomly initialized learnable with canonical parameterization only achieves similar performance to TF learnable canonical when trained on the whole dataset. These results suggest the TF initialization, derived from rigorous signal processing principles, is empirically beneficial as a starting point in the very few sample regime but can be improved upon by learning. Among the linear models, our TF-initialized learnable scattering networks (i.e., Morlet canonical and equivariant) significantly outperform all others in few sample settings. This demonstrates that learnable scattering networks obtain a more linearly separable representation than their fixed counterparts, perhaps by building greater datasetspecific intra-class invariance. <ref type="figure" target="#fig_6">Figure 1</ref> shows the real part of the canonical wavelet filters before and after optimization on the entire training set. In Appendix D, we visualize canonical equivariant wavelet filters. Among the WRN hybrid models, the TF-initialized canonical learnable scattering performs best. Canonical TF learnable still improves over TF fixed when paired with a WRN, indicating some loss of information in the fixed scattering representation is mitigated by data-driven tuning or optimization. Finally, our approach outperforms the fully trained ResNet-50 and outperforms the WRN-16-8 on 100 and 500 training samples, demonstrating the effectiveness of the scattering prior in the small data regime. However, the WRN-16-8 outperforms our model on 1,000 samples and 50,000 samples.  <ref type="table" target="#tab_4">Table 3</ref> reports our evaluation on sample sizes of 100, 500, and 1K images. We use the same protocol as for CIFAR-10. Morlet canonical parameterization yields similar performance to the Morlet equivariant parameterization (i.e., most standard errors overlap), as also observed with CIFAR-10.</p><p>When the scattering networks are postpended with a linear layer, TF-initialized learnable (i.e., Morlet canonical and equivariant) performs better than TF fixed, showing the viability of our approach on real-world data. We observe that randomly initialized learnable yields lower performance than TF learnable on 100 and 500 samples. On 1K, it achieves similar performance, demonstrating that random initialization can achieved comparable performance to TF with enough data. WRN-16-8 performs worse than TFinitialized learnable followed with a linear layer. When combined with a CNN, TF-initialized learnable also performs better than TF fixed and outperforms WRN-16-8 and ResNet-50.</p><p>KTH-TIPS2 contains 4,752 images from 11 material classes. The images captured the material at scales. Each class is divided into four samples (108 images each) of different scales. Using the standard protocol, we train the model on one sample (11 * 108 images), while the rest are used for testing <ref type="bibr" target="#b40">[40]</ref>. In total, each training set contains 1,188 images. <ref type="table" target="#tab_4">Table 3</ref> reports the classification accuracies. With TF initialization and a linear layer, we observe that the performance is similar for the different architectures. The performance of randomly initialized learnable is also similar to TF. The fixed and randomly initialized model perform the worst, showing that even poorly initialized filters can effectively be optimized. Altogether, these results further corroborate our previous findings, notably that TF initialization acts as a good prior for scattering networks. Out of all the WRN hybrid models, the TF-initialized learnable model using canonical parameterization achieves the highest average accuracy. We note that while WRN increases the performance compared to the linear layer, it also signif- icantly increases the total number of parameters, therefore exhibiting a tradeoff between performance and model complexity. The WRN-16-8 and ResNet-50 perform extremely poorly relative to hybrid models, showing the effectiveness of the scattering priors for texture discrimination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Unsupervised Learning of Parameters</head><p>We have studied the adaptation of the wavelet parameters towards a supervised task. We now perform a preliminary investigation to determine if the scattering representation can be improved in a purely unsupervised manner. We consider the recently popularized SimCLR framework <ref type="bibr" target="#b12">[13]</ref>, which encourages representations from two data augmentations of the same input to lie close together. We learn scattering network parameters with the canonical Morlet parameterization on CIFAR-10 using this unsupervised objective function and subsequently evaluate the discriminativeness of the features under a standard linear evaluation experiment on the full CIFAR-10 dataset and in the small data regimes comparing them to the standard scattering transform. The results are shown in <ref type="table" target="#tab_5">Table 4</ref>. We observe the unsupervised learning of filter parameters can improve the scattering representation under standard unsupervised learning evaluation protocols.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Computational and memory complexity</head><p>The computational complexity of scattering networks and parametric scattering networks is directly related to the FFT (Fast Fourier transform), O(N ? log(N )) for an image of size (N ? N). In practice, the computational and memory complexity of our parametric scattering networks varies due to a number of factors.To summarize these factors, we compare runtime (higher is faster), memory, and parameter count per architecture and image size in <ref type="table" target="#tab_6">Table 5</ref>. The models were trained using an NVIDIA Tesla T4 GPU. We observe that fixed scattering is two to three times faster than learned scattering for all image sizes and hybrid models. In contrast, WRN-16-8 is faster than LS+WRN at image size 32 2 , but slower for larger images. This is due to the scattering transform's substantial spatial dimension reduction, which leads to speed and memory benefit versus regular CNNs <ref type="bibr" target="#b29">[29]</ref>. While gradient computation of Morlet parameters adds compute overhead, learned scattering is still efficient with much fewer parameters than CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitations</head><p>There are two limitations to this study that could be addressed in future research. First, the current implementa-  <ref type="bibr" target="#b45">[45]</ref> tion is limited to two-dimensional data. In future work, the implementation could naturally be extended to onedimensional and three-dimensional data. Second, for popular datasets, such as CIFAR-10, there are pre-trained models available. In the study, to compare performance with our approach, we considered a fully learned WRN-16-8 and ResNet-50, but we did not consider pre-trained models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This work showcases the competitive results of adapting a small number of Morlet wavelet filter parameters in scattering convolutional networks <ref type="bibr" target="#b11">[12]</ref>. We demonstrate that filters learned by parametric scattering can be interpreted in the context of specific tasks (e.g., becoming thinner in object classification tasks that require sensitivity to edges). We also empirically demonstrate that our parametric scattering transform shares similar deformation stability to the traditional scattering transform. Overall, we find that our hybrid parametric scattering architectures (with LL and WRN) achieve state-of-the-art classification results in the low-data regime. These results verge upon bridging the gap between the handcrafted filter design in traditional scattering transforms, which provides tractable properties and supports low-parameter models, and fully parameterized convolutional neural networks, which lack interpretability but are more flexible.</p><p>In the future, our results can lead to work investigating the impact of downsampling on the representations learned by the parametric scattering network, as well as application to uncertainty estimation by leveraging the low parameter CNN in a Bayesian framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation Details</head><p>This section describes the implementation details for each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. CIFAR-10</head><p>CIFAR-10 consists of consists of 60,000 images of size 32 ? 32 ? 3 from ten classes. The linear models were trained using a max learning rate of 0.06 for all parameters on 5K, 1K, 500, and 500 epochs for 100, 500, 1K, 50K samples, respectively. The hybrid WRN models were trained using a max learning rate of 0.1 on 3K, 2K, 1K, and 200 epochs for 100, 500, 1K, and 50K samples respectively. We use batch gradient descent except when the models are trained with 50K samples where we use mini-batch gradient descent of size 1024. On the entire training set, we also train the models on 10 seeds and, in all cases, the standard errors are always inferior to 0.3. All scattering networks use a spatial scale J = 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. COVIDx CRX-2</head><p>COVIDx CRX-2 is a two-class (positive and negative) dataset of 1024 ? 1024 ? 1 chest X-Ray images of COVID-19 patients <ref type="bibr" target="#b42">[42]</ref>. In our experiments, we always train on a class-balanced subset of the training set. We resize the images to 260 ? 260 and train our network with random crops of 224 ? 224 pixels. The only data augmentation we use is random horizontal flipping. All models were trained on 400 epochs using a max learning rate of 0.01. All hybrid models are trained with a mini-batch size of 128. All scattering networks use a spatial scale J = 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. KTH-TIPS2</head><p>We resize the images to 200 ? 200 and train our network with random crops of 128 ? 128 pixels. The training data is augmented with random horizontal flips and random rotations. All scattering networks use a spatial scale of 4. We set the maximum learning rate of the scattering parameters to 0.1 while it is set to 0.001 for all other parameters. All hybrid models are trained with a mini-batch size of 128. The hybrid linear models are trained for 250 epochs, while the hybrid WRN models are trained for 150 epochs. We evaluate each model, training it with four different seeds on each sample of material, amounting to 16 total runs. All scattering networks use a spatial scale J = 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Wide Residual Network Hybrid Architecture</head><p>In the experiments of Sec. 4, the scattering networks are combined with a WRN hybrid described in <ref type="bibr" target="#b31">[31]</ref>. We follow a similar architecture to the WRN hybrid used in <ref type="bibr" target="#b33">[33]</ref>. The description of the architecture used for the experiments is given in <ref type="table">Table 6</ref>. We use the same architecture for all the datasets. The architecture consists of a scattering network that greatly reduces the spatial resolution of the input followed by a WRN. The CIFAR-10 scattering stage yields output with 8?8 spatial resolution (scattering with J=2). Similarly, the KTH-TIPS2 data and COVIDx-CRX2 data give outputs with 16?16 and 8?8 spatial resolutions respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Backpropagation through the Parametric Scattering Network</head><p>We show here that it is possible to backpropagate through this construction. Namely, we verify the differentiability of this construction by explicitly computing the partial derivatives with respect to these parameters. First, the R-linear derivative of the complex modulus f (z) = |z| is f ? (z) = z |z| . Next, we show the differentiation of convolution with wavelets with respect to their parameters. For simplicity, we focus here on differentiation of the Gabor portion 1 of the filter construction from Eq. 1, written as:</p><formula xml:id="formula_7">?(u) = exp(? 1 2? 2 (u 2 1 (cos 2 (?) + sin 2 (?)? 2 ) + u 2 2 (cos 2 (?)? 2 + sin 2 (?)) + 2 cos(?) sin(?)u 1 u 2 (1 ? ? 2 )) + i?(cos(?)u 1 + sin(?)u 2 )).<label>(4)</label></formula><p>Its derivatives with respect to the parameters are</p><formula xml:id="formula_8">?? ?? (u) = 1 ? 2 (u 2 cos ? ? u 1 sin ?)(i?? 2 + u 1 (? 2 ? 1) cos ? + u 2 (? 2 ? 1) sin ?)?(u); (5) ?? ?? (u) = 1 ? 3 (u 2 1 (cos 2 ? + ? 2 sin 2 ?) + u 2 2 (? 2 cos 2 ? + sin 2 ?) + 2u 1 u 2 cos ? sin ?(1 ? ? 2 ))?(u); (6) ?? ?? (u) = i(u 1 cos ? + u 2 sin ?)?(u); and (7) ?? ?? (u) = ? 1 ? 2 (u 2 1 ? sin 2 ? + u 2 2 ? cos 2 ? ? 2u 1 u 2 ? cos ? sin ?)?(u).<label>(8)</label></formula><p>Finally, the derivative of the convolution with such filters is given by ? ?? (f * ?)(t) = f (t ? u) ?? ?? (u)du where ? is any of the filter parameter from <ref type="table">Table 1</ref>. It is easy to verify that these derivations can be chained together to propagate through the scattering cascades defined in Sec. 3.1. We can now learn these jointly with other parameters in an end-to-end differentiable architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Equivariant Filters</head><p>We observe that, in some cases, using equivariant filters yields better accuracy, as shown in <ref type="table" target="#tab_3">Table 2</ref>. <ref type="figure" target="#fig_3">Figure 4</ref> illustrates equivariant filters initialized using tight frame construction before and after optimization. The scattering network is combined with a linear layer and trained on 500 training samples of CIFAR-10. The spatial scale is set to J = 2. Similarly, <ref type="figure" target="#fig_4">Figure 5</ref> illustrates equivariant filters initialized randomly before and after optimization. In the two figures, each row corresponds to a different spatial scale (J). Since J is set to 2, we have two rows. We observe that the filters in each row are the exactly the same, except for the global orientation of the wavelet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. No Autoaugment Ablation</head><p>The training set of CIFAR-10 is augmented with pre-specified autoaugment in <ref type="table" target="#tab_3">Table 2</ref> to demonstrate the best possible results. To understand the effect of autoaugment, we replicate the same experiments except for not augmenting the training set with autoaugment. <ref type="table">Table 7</ref> reports the performance of the different architectures on CIFAR-10. We observe that the scattering networks followed by WRN underperform when no autoaugment is used. The difference in performance between using autoaugment and not using it is smaller when the scattering network is followed with a linear layer. Surprisingly, the performance of the scattering networks followed with a linear layer trained on all data increased without autoaugment. It seems that in the case of a scattering network followed by a linear model, autoaugment is not as useful as with a deep model on top and can also be harmful in some cases.   <ref type="table">Table 7</ref>. CIFAR-10 mean accuracy and std. error over 10 seeds with J = 2 and multiple training sample sizes. The table compares the effect of augmenting the training set with pre-specified autoaugment. When the scattering network is followed by a WRN, using autoaugment is necessary to obtain better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Init.</head><p>Arch </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Cosine Loss Ablation</head><p>We replicate the experiments of Sec. 4 with learnable scattering networks followed by a WRN on CIFAR-10, COVIDx-CRX2, and KTH-TIPS2. We use the same parameters except for using the cosine loss function <ref type="bibr" target="#b7">[8]</ref> instead of cross-entropy. The cosine loss is described in Sec. 2. Wavelet filters are initialized using the tight frame construction. <ref type="table" target="#tab_9">Table 8</ref> demonstrates the average accuracy on the three datasets. For CIFAR-10 and COVIDx-CRX2, the performance is lower when models are trained using the cosine loss. The same behavior is not observed when the models are trained on KTH-TIPS2. In fact, the performance increases slightly by using the cosine loss function. Thus, cosine loss can improve performance over small data regimes for some datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Robustness to Deformations</head><p>In Section 4.2, we investigated if the parametric scattering transform is stable to small deformations (i.e., rotation, scale and shear). Here, we explore additional deformations. Models used were pre-trained and evaluated using the COVIDxCRX-2 setup mentioned in Section 4.2 with a linear classifer head. The additional deformations explored are translation and several diffeomorphisms (denoted Custom 1 and Custom 2). The strengths for the all the deformations used ranges from 0 to the maximum value given in <ref type="table" target="#tab_10">Table 9</ref>, except for scale which goes from 1 to its maximum value. Additional results are depicted in <ref type="figure" target="#fig_5">Figure 6</ref>. Custom 1, ? 1 ? (u), and Custom 2, ? 2 ? (u), are defined as such:</p><formula xml:id="formula_9">? 1 ? (u) = ? 0.3u 2 1 + 0.2u 2 2 0.2(0.2u 1 ) , ? 2 ? (u) = ? 0.3(u 2 1 + u 2 2 ) ?0.3(2u 1 u 2 )</formula><p>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Details of Training Unsupervised Scattering with SimCLR Objective</head><p>The learnable scattering networks with tight-frame and random initializations were pretrained on CIFAR-10 via the Sim-CLR method using a temperature of 0.5 and batch size of 128 for 500 epochs. The following basic augmentations were used as part of the SimCLR augmentation pipeline: random crop and resize, random flip, and color distortion. The optimizer used was Adam, with a learning rate of 1e-3, similar to settings from <ref type="bibr" target="#b12">[13]</ref>. Scattering weights were then frozen and used as the backbone for a linear evaluation. For linear evaluation, we used SGD with the same optimization settings as our experiments on CIFAR-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Dataset Specific parameterizations</head><p>The following figures <ref type="bibr" target="#b6">(7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11)</ref> show individual filter assignments obtained by hungarian matching as described in in 4.1. They also show the individual parameter values of each filter by adopting a common naming scheme for each title. The first letter of the title is either F (fixed filters) or O (optimized filters). The next character is always a number and corresponds to the ID of the match. For all Oixxxxxxx titles, there will be a corresponding Fixxxxxxxx title; these filters correspond to the ith match. The next character is always D (distance). It is superseded by a numerical value, the Morlet wavelet distance (see 4.1) between the filter and its match. The next character is the Gaussian window scale ?, followed by a number corresponding to the magnitude of the distances between the ? parameters of both filters. The next character is the aspect ratio ?, followed by a number corresponding to the magnitude of the distances between the ? parameters of both filters. The next character is the frequency scale ?, followed by a number corresponding to the magnitude of the distances between the ? parameters of both filters. We omit the filter orientation ? as it is easy enough to perceive visually.  <ref type="figure">Figure 7</ref>. Filters trained on 1188 samples of COVIDx-CRX2 for 500 epochs, the first, third, fifth, and seventh rows correspond to filters optimized from a tight-frame, while the second, fourth, sixth, and eighth rows correspond to tight-frame initialized filters. The filters are displayed in pairs correspond to the 'closest' (by our distance metric defined above) filters of both types. For instance, the first filter of row one matches the first filter of row 2.    <ref type="figure">Figure 9</ref>. Filters trained on 1188 samples of KTH-TIPS2 for 500 epochs, the first, third, fifth, and seventh rows correspond to filters optimized from a tight-frame, while the second, fourth, sixth, and eighth rows correspond to tight-frame initialized filters. The filters are displayed in pairs correspond to the 'closest' (by our distance metric defined above) filters of both types. For instance, the first filter of row one matches the first filter of row two.    <ref type="figure" target="#fig_6">Figure 11</ref>. Filters trained on 1190 samples of CIFAR-10 for 500 epochs, the first and third, rows correspond to filters optimized from a tight-frame, while the second and fourth rows correspond to tight-frame initialized filters. The filters are displayed in pairs correspond to the 'closest' (by our distance metric defined above) filters of both types. For instance, the first filter of row one matches the first filter of row two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.4. Dataset Specific initializations with a Random Initialization</head><p>In <ref type="figure" target="#fig_2">Figure 12</ref>, we show how the filters adapt when initialization begins from a random setting. We note the deviation to tight frame is much greater than in the case where we initialize in a tight frame. However, as per our filterbank distance, we observe the filters do move closer to the tight frame than their initialization.  <ref type="figure" target="#fig_2">Figure 12</ref>. The graph shows the filterbank distance over epochs as the filters, initialized from random initialization, are trained on different datasets. To the left, we visualize dataset specific parameterizations of scattering filterbanks in Fourier space. The graph on the right shows that the randomly initialized filterbanks become more similar to a tight frame during training.</p><p>In this section, we investigate the effect of modifying the number of filters (L) per spatial scale on CIFAR-10. We use the same settings and hyperparameters as described in Appendix A. So far, in all experiments, we have set the number of filters per scale at 8 for fair comparison with parameters.</p><p>For this ablation, we train a parametric scattering network followed by a linear layer where the wavelets are initialized using the tight frame construction and the canonical parameterization. The spatial scale is set to 2. We do not use autoaugment on the training set since, as shown in Appendix E, autoaugment can be harmful when the scattering network is followed by a linear layer. <ref type="table">Table 10</ref> shows the accuracy of the full training set for different values of L. We observe that the performance increases when the number of filters per scale also increases. Around 14-16 filters per spatial scale, the performance seems to have stopped increasing. <ref type="table">Table 11</ref> demonstrates the mean accuracy over different sizes of training samples where the number of filters per scale is set to 8 or 16. We also consider the fixed version of the scattering transform. Over all training sample sizes, we observe that the highest performance is obtained with learnable scattering using 16 filters per spatial scale. When the scattering network is fixed, we observe that performances are lower with 16 filters instead of 8. It seems that increasing the number of filters per scale is only beneficial in the learned version of the scattering network. <ref type="table">Table 10</ref>. CIFAR-10 accuracy of learnable scattering followed by a linear layer (LS + LL) and multiple numbers of filters per scale (L) trained on all the training set. The wavelet filters are initialized using the tight frame construction and the canonical parameterization. The spatial scale is set to 2. No autoaugment is used for this experiment. We observe that the performance increases when the number of filters per scale (L) also increases. Around 14 filters per spatial scale, the performance seems to have stopped increasing.  <ref type="table">Table 11</ref>. CIFAR-10 mean accuracy and std. error over 10 seeds with multiple training sample sizes and different values of L. The wavelet filters are initialized using the tight frame construction. The spatial scale is set to 2. No autoaugment is used for this experiment. Over all training sample sizes, we observe that the highest performance is obtained with learnable scattering using 16 filters per spatial scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Arch.</head><p>Parameterization </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K. Perturbing a Converged Parameterization Ablation</head><p>The training accuracies and losses over epochs are shown in <ref type="figure" target="#fig_1">Figure 13</ref> for LS+L and S+L. We observe that both networks are following similar patterns. Local minima are expected here (see results with different init <ref type="figure" target="#fig_6">Figure 1</ref>), as in any non-convex problem. To showcase learnable scattering's stability to stochastic optimization, we perform an ablation below <ref type="figure" target="#fig_3">(Figures 14 &amp;  15</ref>) for trained LS+L, where each parameter is perturbed and then individually optimized. We find that they all return rapidly to the (local) optimum. L. Visualizing Parameter Values over Time <ref type="figure" target="#fig_5">Figure 16</ref> shows, on the left, a Morlet wavelet filter before training and, in the middle, the same wavelet filter after training. The parametric scattering network was trained for 1K epochs on 1000 samples of CIFAR-10. We use the Morlet canonical parameterization. We observe that the global orientation has changed during training. <ref type="figure" target="#fig_5">Figure 16 (right)</ref> shows the values of the parameters from <ref type="table">Table 1</ref> over the training steps. We observe that the value of all parameters changed during training. However, the aspect ratio seems to have returned to its initial value. In <ref type="figure" target="#fig_5">Figure 16</ref> (right), we also show the value of ? ? ?, which is a proxy for the wavelet scale factor, over the steps. The value of ? ? ? is smaller after training. This can be observed in <ref type="figure" target="#fig_5">Figure 16 (left-middle)</ref>, where the wavelet after training seems to be more compressed than before training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Before After</head><p>Parameter Values</p><p>Steps <ref type="figure" target="#fig_5">Figure 16</ref>. Parameter values over time. Real part of Morlet wavelet filters initialized with tight-frame schemes before (left) and after (middle) training. The network was trained for 1K epochs on 1000 samples of CIFAR-10. We use the Morlet canonical wavelet parameterization. The plot (right) shows the parameter values over epochs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Normalized distances between scattering representations of an image and its deformation. Our parametric scattering transform shares similar stability to deformations as the scattering transform.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>COVIDx CRX- 2</head><label>2</label><figDesc>is a two-class (positive and negative) dataset of chest X-Ray images of COVID-19 patients [42]. The train set contains 15,951 unbalanced images, while the test set contains 200 positive and 200 negative images. The spatial scale of the scattering transform is set to J = 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Example of equivariant filters initialized using tight frame construction. (Top) Real part of wavelet filters before optimization. (Bottom) Real part of wavelet filters after optimization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Example of equivariant filters initialized randomly. (Top) Real part of wavelet filters before optimization. (Bottom) Real part of wavelet filters after optimization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Normalized distances between scattering representations of an image and its deformation. (Left) Translation. (Middle) Custom 1 Transformation. (Right) Custom 2 Transformation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>I. 1 .</head><label>1</label><figDesc>COVIDX-CRX2 O0D0.8 0.6 0.0 0.3 O1D0.4 0.4 0.0 0.1 O2D0.6 0.5 0.2 0.1 O3D1.0 0.7 0.1 0.3 O4D0.7 0.6 0.1 0.2 O5D0.6 0.6 0.1 0.3 O6D0.9 0.8 0.0 0.4 O7D1.0 0.7 0.1 0.6 F0D0.8 0.6 0.0 0.3 F1D0.4 0.4 0.0 0.1 F2D0.6 0.5 0.2 0.1 F3D1.0 0.7 0.1 0.3 F4D0.7 0.6 0.1 0.2 F5D0.6 0.6 0.1 0.3 F6D0.9 0.8 0.0 0.4 F7D1.0 0.7 0.1 0.6 O8D0.5 0.3 0.1 0.3 O9D0.7 0.4 0.3 0.3 O10D0.5 0.4 0.1 0.2 O11D0.3 0.2 0.0 0.2 O12D0.4 0.3 0.0 0.2 O13D0.2 0.2 0.1 0.1 O14D0.5 0.3 0.1 0.3 O15D0.2 0.1 0.1 0.2 F8D0.5 0.3 0.1 0.3 F9D0.7 0.4 0.3 0.3 F10D0.5 0.4 0.1 0.2 F11D0.3 0.2 0.0 0.2 F12D0.4 0.3 0.0 0.2 F13D0.2 0.2 0.1 0.1 F14D0.5 0.3 0.1 0.3 F15D0.2 0.1 0.1 0.2 O16D0.4 0.3 0.2 0.1 O17D0.5 0.3 0.2 0.3 O18D0.6 0.2 0.3 0.3 O19D0.4 0.2 0.2 0.0 O20D0.6 0.2 0.3 0.3 O21D0.5 0.3 0.2 0.3 O22D0.4 0.2 0.2 0.1 O23D0.2 0.1 0.1 0.1 F16D0.4 0.3 0.2 0.1 F17D0.5 0.3 0.2 0.3 F18D0.6 0.2 0.3 0.3 F19D0.4 0.2 0.2 0.0 F20D0.6 0.2 0.3 0.3 F21D0.5 0.3 0.2 0.3 F22D0.4 0.2 0.2 0.1 F23D0.2 0.1 0.1 0.1 O24D0.1 0.2 0.1 0.1 O25D0.3 0.2 0.2 0.1 O26D0.3 0.2 0.2 0.2 O27D0.1 0.1 0.0 0.1 O28D0.2 0.2 0.1 0.1 O29D0.3 0.1 0.2 0.1 O30D0.3 0.2 0.2 0.0 O31D0.3 0.2 0.3 0.2 F24D0.1 0.2 0.1 0.1 F25D0.3 0.2 0.2 0.1 F26D0.3 0.2 0.2 0.2 F27D0.1 0.1 0.0 0.1 F28D0.2 0.2 0.1 0.1 F29D0.3 0.1 0.2 0.1 F30D0.3 0.2 0.2 0.0 F31D0.3 0.2 0.3 0.2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>O0D0. 2 0</head><label>2</label><figDesc>.0 0.1 0.1 O1D0.2 0.1 0.0 0.2 O2D0.3 0.2 0.1 0.2 O3D0.3 0.3 0.1 0.1 O4D0.3 0.2 0.0 0.2 O5D0.4 0.3 0.1 0.0 O6D0.4 0.2 0.0 0.3 O7D0.4 0.3 0.1 0.0 F0D0.2 0.0 0.1 0.1 F1D0.2 0.1 0.0 0.2 F2D0.3 0.2 0.1 0.2 F3D0.3 0.3 0.1 0.1 F4D0.3 0.2 0.0 0.2 F5D0.4 0.3 0.1 0.0 F6D0.4 0.2 0.0 0.3 F7D0.4 0.3 0.1 0.0 O8D0.4 0.4 0.0 0.2 O9D0.5 0.4 0.1 0.2 O10D0.5 0.2 0.2 0.3 O11D0.5 0.2 0.2 0.3 O12D0.5 0.4 0.2 0.2 O13D0.6 0.4 0.1 0.1 O14D0.6 0.4 0.1 0.2 O15D0.6 0.5 0.2 0.2 F8D0.4 0.4 0.0 0.2 F9D0.5 0.4 0.1 0.2 F10D0.5 0.2 0.2 0.3 F11D0.5 0.2 0.2 0.3 F12D0.5 0.4 0.2 0.2 F13D0.6 0.4 0.1 0.1 F14D0.6 0.4 0.1 0.2 F15D0.6 0.5 0.2 0.2 O16D0.6 0.5 0.2 0.2 O17D0.6 0.2 0.2 0.2 O18D0.6 0.5 0.0 0.2 O19D0.6 0.5 0.1 0.3 O20D0.7 0.2 0.1 0.3 O21D0.7 0.4 0.2 0.1 O22D0.7 0.2 0.2 0.4 O23D0.7 0.7 0.1 0.2 F16D0.6 0.5 0.2 0.2 F17D0.6 0.2 0.2 0.2 F18D0.6 0.5 0.0 0.2 F19D0.6 0.5 0.1 0.3 F20D0.7 0.2 0.1 0.3 F21D0.7 0.4 0.2 0.1 F22D0.7 0.2 0.2 0.4 F23D0.7 0.7 0.1 0.2 O24D0.8 0.6 0.2 0.4 O25D0.8 0.3 0.2 0.4 O26D0.9 0.0 0.8 0.1 O27D0.9 0.2 0.7 0.4 O28D1.0 0.5 0.2 0.6 O29D1.1 0.8 0.1 0.2 O30D1.1 0.9 0.1 0.2 O31D1.1 0.4 0.7 0.8 F24D0.8 0.6 0.2 0.4 F25D0.8 0.3 0.2 0.4 F26D0.9 0.0 0.8 0.1 F27D0.9 0.2 0.7 0.4 F28D1.0 0.5 0.2 0.6 F29D1.1 0.8 0.1 0.2 F30D1.1 0.9 0.1 0.2 F31D1.1 0.4 0.7 0.8</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>Filters trained on 1188 samples of COVIDx-CRX2 for 500 epochs, the first, third, fifth, and seventh rows correspond to filters optimized from a tight-frame, while the second, fourth, sixth, and eighth rows correspond to tight-frame initialized filters. The filters are displayed in pairs correspond to the 'closest' (by our distance metric defined above) filters of both types. For instance, the first filter of row one matches the first filter of row 2. The filters are displayed in increasing order of their distances. The top left corner corresponds to the filters that changed the least from their initialization, while the filters in the bottom right corner changed the most.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>I. 2 .</head><label>2</label><figDesc>KTH-TIPS2 O0D0.5 0.2 0.2 0.3 O1D0.6 0.2 0.2 0.2 O2D0.9 0.0 0.8 0.1 O3D1.1 0.4 0.7 0.8 O4D0.9 0.2 0.7 0.4 O5D0.5 0.2 0.2 0.3 O6D0.3 0.2 0.1 0.2 O7D0.2 0.0 0.1 0.1 F0D0.5 0.2 0.2 0.3 F1D0.6 0.2 0.2 0.2 F2D0.9 0.0 0.8 0.1 F3D1.1 0.4 0.7 0.8 F4D0.9 0.2 0.7 0.4 F5D0.5 0.2 0.2 0.3 F6D0.3 0.2 0.1 0.2 F7D0.2 0.0 0.1 0.1 O8D1.0 0.5 0.2 0.6 O9D0.3 0.2 0.0 0.2 O10D0.8 0.3 0.2 0.4 O11D0.8 0.6 0.2 0.4 O12D0.7 0.2 0.2 0.4 O13D0.4 0.2 0.0 0.3 O14D0.7 0.2 0.1 0.3 O15D0.2 0.1 0.0 0.2 F8D1.0 0.5 0.2 0.6 F9D0.3 0.2 0.0 0.2 F10D0.8 0.3 0.2 0.4 F11D0.8 0.6 0.2 0.4 F12D0.7 0.2 0.2 0.4 F13D0.4 0.2 0.0 0.3 F14D0.7 0.2 0.1 0.3 F15D0.2 0.1 0.0 0.2 O16D0.6 0.5 0.0 0.2 O17D0.6 0.4 0.1 0.1 O18D0.4 0.4 0.0 0.2 O19D0.5 0.4 0.1 0.2 O20D0.6 0.4 0.1 0.2 O21D0.7 0.4 0.2 0.1 O22D0.6 0.5 0.1 0.3 O23D0.5 0.4 0.2 0.2 F16D0.6 0.5 0.0 0.2 F17D0.6 0.4 0.1 0.1 F18D0.4 0.4 0.0 0.2 F19D0.5 0.4 0.1 0.2 F20D0.6 0.4 0.1 0.2 F21D0.7 0.4 0.2 0.1 F22D0.6 0.5 0.1 0.3 F23D0.5 0.4 0.2 0.2 O24D0.6 0.5 0.2 0.2 O25D0.4 0.3 0.1 0.0 O26D1.1 0.8 0.1 0.2 O27D0.7 0.7 0.1 0.2 O28D1.1 0.9 0.1 0.2 O29D0.4 0.3 0.1 0.0 O30D0.6 0.5 0.2 0.2 O31D0.3 0.3 0.1 0.1 F24D0.6 0.5 0.2 0.2 F25D0.4 0.3 0.1 0.0 F26D1.1 0.8 0.1 0.2 F27D0.7 0.7 0.1 0.2 F28D1.1 0.9 0.1 0.2 F29D0.4 0.3 0.1 0.0 F30D0.6 0.5 0.2 0.2 F31D0.3 0.3 0.1 0.1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>O0D0. 1 0</head><label>1</label><figDesc>.1 0.0 0.1 O1D0.1 0.2 0.1 0.1 O2D0.2 0.2 0.1 0.1 O3D0.2 0.2 0.1 0.1 O4D0.2 0.1 0.1 0.1 O5D0.2 0.1 0.1 0.2 O6D0.3 0.2 0.2 0.0 O7D0.3 0.2 0.0 0.2 F0D0.1 0.1 0.0 0.1 F1D0.1 0.2 0.1 0.1 F2D0.2 0.2 0.1 0.1 F3D0.2 0.2 0.1 0.1 F4D0.2 0.1 0.1 0.1 F5D0.2 0.1 0.1 0.2 F6D0.3 0.2 0.2 0.0 F7D0.3 0.2 0.0 0.2 O8D0.3 0.2 0.3 0.2 O9D0.3 0.2 0.2 0.2 O10D0.3 0.1 0.2 0.1 O11D0.3 0.2 0.2 0.1 O12D0.4 0.2 0.2 0.1 O13D0.4 0.2 0.2 0.0 O14D0.4 0.3 0.0 0.2 O15D0.4 0.4 0.0 0.1 F8D0.3 0.2 0.3 0.2 F9D0.3 0.2 0.2 0.2 F10D0.3 0.1 0.2 0.1 F11D0.3 0.2 0.2 0.1 F12D0.4 0.2 0.2 0.1 F13D0.4 0.2 0.2 0.0 F14D0.4 0.3 0.0 0.2 F15D0.4 0.4 0.0 0.1 O16D0.4 0.3 0.2 0.1 O17D0.5 0.4 0.1 0.2 O18D0.5 0.3 0.2 0.3 O19D0.5 0.3 0.2 0.3 O20D0.5 0.3 0.1 0.3 O21D0.5 0.3 0.1 0.3 O22D0.6 0.5 0.2 0.1 O23D0.6 0.2 0.3 0.3 F16D0.4 0.3 0.2 0.1 F17D0.5 0.4 0.1 0.2 F18D0.5 0.3 0.2 0.3 F19D0.5 0.3 0.2 0.3 F20D0.5 0.3 0.1 0.3 F21D0.5 0.3 0.1 0.3 F22D0.6 0.5 0.2 0.1 F23D0.6 0.2 0.3 0.3 O24D0.6 0.2 0.3 0.3 O25D0.6 0.6 0.1 0.3 O26D0.7 0.6 0.1 0.2 O27D0.7 0.4 0.3 0.3 O28D0.8 0.6 0.0 0.3 O29D0.9 0.8 0.0 0.4 O30D1.0 0.7 0.1 0.3 O31D1.0 0.7 0.1 0.6 F24D0.6 0.2 0.3 0.3 F25D0.6 0.6 0.1 0.3 F26D0.7 0.6 0.1 0.2 F27D0.7 0.4 0.3 0.3 F28D0.8 0.6 0.0 0.3 F29D0.9 0.8 0.0 0.4 F30D1.0 0.7 0.1 0.3 F31D1.0 0.7 0.1 0.6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 .</head><label>10</label><figDesc>Filters trained on 1188 samples of KTH-TIPS2 for 500 epochs, the first, third, fifth, and seventh rows correspond to filters optimized from a tight-frame, while the second, fourth, sixth, and eighth rows correspond to tight-frame initialized filters. The filters are displayed in pairs correspond to the 'closest' (by our distance metric defined above) filters of both types. For instance, the first filter of row one matches the first filter of row two. The filters are displayed in increasing order of their distances. The top left corner corresponds to the filters that changed the least from their initialization, while the filters in the bottom right corner changed the most.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>I. 3 .</head><label>3</label><figDesc>CIFAR-10 O0D0.5 0.5 0.1 0.2 O1D0.4 0.4 0.0 0.0 O2D0.6 0.3 0.2 0.3 O3D0.8 0.1 0.7 0.2 O4D0.5 0.5 0.1 0.1 O5D0.8 0.7 0.0 0.0 O6D0.6 0.5 0.1 0.2 O7D0.5 0.2 0.2 0.2 F0D0.5 0.5 0.1 0.2 F1D0.4 0.4 0.0 0.0 F2D0.6 0.3 0.2 0.3 F3D0.8 0.1 0.7 0.2 F4D0.5 0.5 0.1 0.1 F5D0.8 0.7 0.0 0.0 F6D0.6 0.5 0.1 0.2 F7D0.5 0.2 0.2 0.2 O8D0.3 0.0 0.2 0.1 O9D0.4 0.2 0.2 0.2 O10D0.5 0.2 0.3 0.0 O11D0.9 0.8 0.3 0.4 O12D0.5 0.2 0.2 0.3 O13D0.4 0.3 0.2 0.1 O14D1.5 0.6 1.2 0.4 O15D0.6 0.6 0.2 0.0 F8D0.3 0.0 0.2 0.1 F9D0.4 0.2 0.2 0.2 F10D0.5 0.2 0.3 0.0 F11D0.9 0.8 0.3 0.4 F12D0.5 0.2 0.2 0.3 F13D0.4 0.3 0.2 0.1 F14D1.5 0.6 1.2 0.4 F15D0.6 0.6 0.2 0.0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 13 .Figure 14 .Figure 15 .</head><label>131415</label><figDesc>Plots comparing the training accuracies and losses over epochs of LS+LL and S+LL. Note that scattering parameters are only optimized for LS+LL. The networks were trained for 500 epochs on 1000 samples of CIFAR-10. (left) ? parameter of a learned parameterization is perturbed and returns to an almost identical orientation after gradient based optimization. (right) ? parameter of a learned parameterization is perturbed and returns to an almost identical frequency scale after gradient based optimization. (left) ? parameter of a learned parameterization is perturbed and returns to an almost identical gaussian window scale after gradient based optimization. (right) ? parameter of a learned parameterization is perturbed and returns to an almost identical aspect ratio after gradient based optimization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Equal contributions. ? Equal senior author contribution. This research was partially funded by NSERC CGS-M [S.G.,L.A.] and URA [B.T.] scholarhips; NSERC Discovery Grant RGPIN-2021-04104. [E.B.]; IVADO PRF Grant [I.R.,E.B.,G.W.]; and CIFAR AI Chairs [I.R.,G.W.]. We acknowledge resources provided by Compute Canada and Calcul Quebec. The content is solely the responsibility of the authors and does not necessarily represent the official views of funding agencies. Correspondence to: eugene.belilovsky@concordia.ca, meickenberg@flatironinstitute.org, guy.wolf@umontreal.ca signals</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Initialized wavelet filters pre and post-training. Real part of Morlet wavelet filters initialized with tight-frame (left) and random (right) schemes before (top) and after (bottom) training. The filters were optimized on the entire CIFAR-10 training set with linear model. We use the Morlet canonical wavelet parameterization. For the tight-frame filters, we observe substantial changes in both scale and aspect ratio. On the other hand, all random filters undergo major changes in orientation and scale.</figDesc><table><row><cell></cell><cell cols="2">Tight-Frame</cell><cell>Random Initialization</cell></row><row><cell cols="4">Figure 1. Table 1. Canonical Parameters of Morlet wavelet</cell></row><row><cell>Param</cell><cell>Role</cell><cell>Param</cell><cell>Role</cell></row><row><cell>?</cell><cell>Gaussian window scale</cell><cell>?</cell><cell>Global orientation</cell></row><row><cell>?</cell><cell>Frequency scale</cell><cell>?</cell><cell>Aspect Ratio</cell></row></table><note>wavelet filterbank is obtained by dilating it by factors 2 j , 0 ? j &lt; J, and rotating by L angles ? equally spaced over the circle, to get {2</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>CIFAR-10 mean accuracy and std. error over 10 seeds, with J = 2 and multiple training sample sizes. Learnable scattering with TF initialization improves performance for all architectures, while randomly initialized scattering requires more training data to reach similar performance. ? 0.57 52.68 ? 0.31 57.43 ? 0.17 69.57</figDesc><table><row><cell>Arch.</cell><cell>Init.</cell><cell cols="2">Parameterization 100 samples</cell><cell>500 samples</cell><cell>1000 samples</cell><cell>All</cell></row><row><cell cols="5">LS+LL ? 37.84 LS+LL ? TF Canonical TF Equivariant 39.69 ? 0.56 51.98 ? 0.25</cell><cell>57.01 ? 0.16</cell><cell>66.65</cell></row><row><cell>LS+LL</cell><cell>TF</cell><cell>Pixel-Wise</cell><cell>32.30 ? 0.69</cell><cell>47.14 ? 0.91</cell><cell>51.87 ? 0.34</cell><cell>64.53</cell></row><row><cell>S +LL</cell><cell>TF</cell><cell>-</cell><cell>36.01 ? 0.55</cell><cell>48.12 ? 0.25</cell><cell>53.25 ? 0.24</cell><cell>65.58</cell></row><row><cell>LS+LL ?</cell><cell cols="2">Rand Canonical</cell><cell>34.81 ? 0.60</cell><cell>49.6 ? 0.39</cell><cell>55.72 ? 0.39</cell><cell>69.39</cell></row><row><cell>LS+LL ?</cell><cell cols="2">Rand Equivariant</cell><cell>34.67 ? 0.73</cell><cell>46.59 ? 0.60</cell><cell>52.95 ? 0.36</cell><cell>65.64</cell></row><row><cell>LS+LL</cell><cell cols="2">Rand Pixel-Wise</cell><cell>29.44 ? 0.41</cell><cell>42.14 ? 0.27</cell><cell>47.44 ? 0.43</cell><cell>62.72</cell></row><row><cell>S +LL</cell><cell cols="2">Rand -</cell><cell>29.77 ? 0.47</cell><cell>41.85 ? 0.41</cell><cell>46.3 ? 0.37</cell><cell>57.72</cell></row><row><cell>LS+WRN ?</cell><cell>TF</cell><cell>Canonical</cell><cell cols="3">43.60 ? 0.87 63.13 ? 0.29 70.14 ? 0.26</cell><cell>93.61</cell></row><row><cell>LS+WRN ?</cell><cell>TF</cell><cell>Equivariant</cell><cell>39.86 ? 1.59</cell><cell>62.85 ? 0.32</cell><cell>69.52 ? 0.23</cell><cell>92.57</cell></row><row><cell>LS+WRN</cell><cell>TF</cell><cell>Pixel-Wise</cell><cell>39.20 ? 0.80</cell><cell>54.14 ? 0.68</cell><cell>57.59 ? 0.48</cell><cell>92.97</cell></row><row><cell>S +WRN</cell><cell>TF</cell><cell>-</cell><cell>43.16 ? 0.78</cell><cell>61.66 ? 0.32</cell><cell>68.16 ? 0.27</cell><cell>92.27</cell></row><row><cell>LS+WRN ?</cell><cell cols="2">Rand Canonical</cell><cell>41.42 ? 0.65</cell><cell>59.84 ? 0.40</cell><cell>67.40 ? 0.28</cell><cell>93.36</cell></row><row><cell>LS+WRN ?</cell><cell cols="2">Rand Equivariant</cell><cell>40.84 ? 1.02</cell><cell>60.81 ? 0.40</cell><cell>68.62 ? 0.31</cell><cell>92.53</cell></row><row><cell>LS+WRN</cell><cell cols="2">Rand Pixel-Wise</cell><cell>31.49 ? 0.63</cell><cell>45.85 ? 0.43</cell><cell>50.72 ? 0.28</cell><cell>91.86</cell></row><row><cell>S +WRN</cell><cell cols="2">Rand -</cell><cell>32.08 ? 0.46</cell><cell>46.84 ? 0.21</cell><cell>52.76 ? 0.33</cell><cell>85.35</cell></row><row><cell>WRN-16</cell><cell>-</cell><cell>-</cell><cell>38.78 ? 0.72</cell><cell>62.97 ? 0.41</cell><cell cols="2">71.37 ? 0.31 96.84</cell></row><row><cell>ResNet-50</cell><cell>-</cell><cell>-</cell><cell>33.17 ? 0.92</cell><cell>52.13 ? 0.74</cell><cell>64.42 ? 0.40</cell><cell>91.23</cell></row></table><note># params : 156k for S+LL; 155k for LS+LL; 22.6M for S+WRN; 22.6M for LS+WRN; 22.3M for WRN; and 22.5M for ResNet ?: ours; TF: Tight-Frame; LS: Learnable Scattering; S: Scattering; Rand: Random</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>COVIDx CRX-2 and KTH-TIPS2 mean accuracy &amp; std. error with J = 4 over 10 seeds and 16 seeds respectively. (COVIDx CRX-2) TF-initialized learnable scattering network performs better than models that do not incorporate scattering priors. (KTH-TIPS2) Similarly, the WRN-16-8 and ResNet-50 perform extremely poorly relative to hybrid models trained on KTH-TIPS2.</figDesc><table><row><cell>Arch.</cell><cell>Init.</cell><cell cols="4">Parameterization C-100 samples C-500 samples C-1000 samples</cell><cell>KTH-1188 samples</cell></row><row><cell>LS+LL ?</cell><cell>TF</cell><cell>Canonical</cell><cell>82.30 ? 1.78</cell><cell>88.50 ? 0.71</cell><cell>89.90 ? 0.40</cell><cell>66.09 ? 1.05</cell></row><row><cell>LS+LL ?</cell><cell>TF</cell><cell>Equivariant</cell><cell>83.06 ? 1.53</cell><cell>87.56 ? 0.94</cell><cell>89.15 ? 0.60</cell><cell>66.41 ? 1.24</cell></row><row><cell>S +LL</cell><cell>TF</cell><cell>-</cell><cell>81.08 ? 1.88</cell><cell>87.20 ? 0.77</cell><cell>89.23 ? 0.69</cell><cell>66.17 ? 1.10</cell></row><row><cell>LS+LL ?</cell><cell cols="2">Rand Canonical</cell><cell>76.85 ? 1.50</cell><cell>86.45 ? 0.95</cell><cell>89.70 ? 0.65</cell><cell>65.79 ? 0.85</cell></row><row><cell>LS+LL ?</cell><cell cols="2">Rand Equivariant</cell><cell>76.73 ? 1.57</cell><cell>85.64 ? 1.38</cell><cell>87.98 ? 0.55</cell><cell>65.31 ? 1.42</cell></row><row><cell>S +LL</cell><cell cols="2">Rand -</cell><cell>76.08 ? 1.56</cell><cell>84.13 ? 0.91</cell><cell>86.80 ? 0.41</cell><cell>61.37 ? 0.82</cell></row><row><cell>LS+WRN ?</cell><cell>TF</cell><cell>Canonical</cell><cell>81.20 ? 1.73</cell><cell>90.50 ? 0.70</cell><cell>93.68 ? 0.35</cell><cell>69.23 ? 0.67</cell></row><row><cell>LS+WRN ?</cell><cell>TF</cell><cell>Equivariant</cell><cell>81.86 ? 2.07</cell><cell>91.56 ? 0.52</cell><cell>93.97 ? 0.34</cell><cell>68.55 ? 0.80</cell></row><row><cell>S +WRN</cell><cell>TF</cell><cell>-</cell><cell>80.85 ? 1.85</cell><cell>89.05 ? 0.59</cell><cell>91.90 ? 0.54</cell><cell>68.84 ? 0.71</cell></row><row><cell>LS+WRN ?</cell><cell cols="2">Rand Canonical</cell><cell>80.95 ? 1.54</cell><cell>88.08 ? 0.70</cell><cell>91.65 ? 0.55</cell><cell>68.30 ? 0.47</cell></row><row><cell>LS+WRN ?</cell><cell cols="2">Rand Equivariant</cell><cell>80.12 ? 1.76</cell><cell>87.44 ? 1.17</cell><cell>91.40 ? 0.67</cell><cell>67.50 ? 0.72</cell></row><row><cell>S +WRN</cell><cell cols="2">Rand -</cell><cell>80.63 ? 1.73</cell><cell>86.68 ? 0.59</cell><cell>90.60 ? 0.50</cell><cell>66.29 ? 0.36</cell></row><row><cell>WRN-16</cell><cell>-</cell><cell>-</cell><cell>80.50?1.15</cell><cell>85.95 ? 2.04</cell><cell>88.82 ? 1.64</cell><cell>51.24 ? 1.37</cell></row><row><cell>ResNet-50</cell><cell>-</cell><cell>-</cell><cell>74.04 ? 1.35</cell><cell>86.45 ? 0.51</cell><cell>90.86 ? 0.57</cell><cell>44.95 ? 0.65</cell></row></table><note>C: COVIDx CRX-2 # params : 493K for LS/S+LL; 23.7M for LS/S+WRN; 22.3M for WRN;23.5M for ResNet KTH: KTH-TIPS2 # params : 883K for LS/S+LL; 23.8M for LS/S+WRN; 22.3M for WRN; 23.5M for ResNet ?: ours; TF: Tight-Frame; LS: Learnable Scattering; S: Scattering; Rand: Random</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Scattering and learned unsupervised scattering features evaluated by training a linear classifier on CIFAR-10. We observe the unsupervised learned scattering improves the representation.<ref type="bibr" target="#b36">36</ref>.01 ? 0.55 48.12 ? 0.25 53.25 ? 0.24 65.58 ? 0.04 Unsupervised Learnt Scattering 38.05 ? 0.45 52.92 ? 0.28 57.76 ? 0.25 68.47 ? 0.04</figDesc><table><row><cell>Method</cell><cell>100 samples</cell><cell>500 samples</cell><cell>1000 samples</cell><cell>All</cell></row><row><cell>Scattering (Fixed)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Comparison of training runtime, inference runtime, GPU memory, and parameter count per architecture and image size.</figDesc><table><row><cell>Architecture LS+L</cell><cell>Img. size 32 2</cell><cell>Train ( imgs sec ) 264</cell><cell>Infer. ( imgs sec ) 542</cell><cell>GPU Mem. (GB) 0.3</cell><cell>#Params (Million) 0.2</cell><cell></cell></row><row><cell>S+L LS+WRN S+WRN</cell><cell>32 2 32 2 32 2</cell><cell>650 232 498</cell><cell>656 430 588</cell><cell>0.1 1.6 1.4</cell><cell>0.2 22.6 22.6</cell><cell>CIFAR</cell></row><row><cell>WRN-16-8*</cell><cell>32 2</cell><cell cols="2">510 1695</cell><cell>4.2</cell><cell>11.0</cell><cell></cell></row><row><cell>LS+L</cell><cell>128 2</cell><cell>42</cell><cell>102</cell><cell>5.4</cell><cell>0.8</cell><cell></cell></row><row><cell>S+L LS+WRN S+WRN</cell><cell>128 2 128 2 128 2</cell><cell>123 42 115</cell><cell>123 101 120</cell><cell>0.5 8.5 3.3</cell><cell>0.8 23.8 23.8</cell><cell>KTH</cell></row><row><cell>WRN-16-8*</cell><cell>128 2</cell><cell>31</cell><cell>90</cell><cell>61.1</cell><cell>11.0</cell><cell></cell></row><row><cell>LS+L</cell><cell>224 2</cell><cell>24</cell><cell>72</cell><cell>13.7</cell><cell>0.5</cell><cell></cell></row><row><cell>S+L LS+WRN S+WRN</cell><cell>224 2 224 2 224 2</cell><cell>78 22 58</cell><cell>79 67 71</cell><cell>1.3 16.1 2.9</cell><cell>0.5 23.7 23.7</cell><cell>COVID</cell></row><row><cell>WRN-16-8*</cell><cell>224 2</cell><cell>10</cell><cell>36</cell><cell>49.6</cell><cell>11.0</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* from</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>? 0.62 49.67 ? 0.33 53.96 ? 0.48 70.71 ? 0.03 Yes 43.60 ? 0.87 63.13 ? 0.29 70.14 ? 0.26 93.61 ? 0.12 Rand LS+WRN ? Yes 41.42 ? 0.65 59.84 ? 0.40 67.4 ? 0.28 93.36 ? 0.19</figDesc><table><row><cell></cell><cell>.</cell><cell cols="2">AA 100 samples</cell><cell>500 samples</cell><cell>1000 samples</cell><cell>All</cell></row><row><cell>TF</cell><cell>LS+LL ?</cell><cell cols="2">Yes 37.84 ? 0.57</cell><cell cols="3">52.68 ? 0.31 57.43 ? 0.17 69.57 ? 0.1</cell></row><row><cell>TF</cell><cell>LS+LL ?</cell><cell>No</cell><cell cols="2">39.70 ? 0.62 50.74 ? 0.30</cell><cell>54.76 ? 0.22</cell><cell>74.94 ? 0.06</cell></row><row><cell>TF</cell><cell>S +LL</cell><cell cols="2">Yes 36.01 ? 0.55</cell><cell>48.12 ? 0.25</cell><cell>53.25 ? 0.24</cell><cell>65.58 ? 0.04</cell></row><row><cell cols="5">TF 37.55 Rand LS+LL ? S +LL No Yes 34.81 ? 0.60 49.6 ? 0.39</cell><cell cols="2">55.72 ? 0.39 69.39 ? 0.41</cell></row><row><cell cols="2">Rand LS+LL ?</cell><cell>No</cell><cell>32.64 ? 0.38</cell><cell>42.88 ? 0.23</cell><cell>47.40 ? 0.32</cell><cell>74.71 ? 0.08</cell></row><row><cell cols="2">Rand S +LL</cell><cell cols="2">Yes 29.77 ? 0.47</cell><cell cols="2">41.85 ? 0.41 46.3 ? 0.37</cell><cell>57.72 ? 0.1</cell></row><row><cell cols="2">Rand S +LL</cell><cell>No</cell><cell cols="2">31.71 ? 0.34 40.57 ? 0.32</cell><cell>44.42 ? 0.51</cell><cell>61.79 ? 0.31</cell></row><row><cell cols="3">TF LS+WRN ? TF LS+WRN ? No</cell><cell>34.95 ? 0.96</cell><cell>54.21 ? 0.39</cell><cell>62.17 ? 0.28</cell><cell>90.17 ? 0.34</cell></row><row><cell>TF</cell><cell>S +WRN</cell><cell cols="5">Yes 43.16 ? 0.78 61.66 ? 0.32 68.16 ? 0.27 92.27 ? 0.05</cell></row><row><cell>TF</cell><cell>S +WRN</cell><cell>No</cell><cell>35.15 ? 0.43</cell><cell>52.77 ? 0.35</cell><cell>60.72 ? 0.21</cell><cell>89.05 ? 0.38</cell></row><row><cell cols="3">Rand LS+WRN ? No</cell><cell>31.08 ? 1.00</cell><cell>48.37 ? 0.76</cell><cell>55.41 ? 0.49</cell><cell>88.80 ? 0.47</cell></row><row><cell cols="2">Rand S +WRN</cell><cell cols="5">Yes 32.08 ? 0.46 46.84 ? 0.21 52.76 ? 0.33 85.35 ? 1.06</cell></row><row><cell cols="2">Rand S +WRN</cell><cell>No</cell><cell>27.73 ? 0.43</cell><cell>41.05 ? 0.32</cell><cell>47.19 ? 0.37</cell><cell>79.67 ? 0.59</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>?: ours TF: tight-frame LS: Learnable Scattering AA: Autoaugment # params : 156k for S+LL; 155k for LS+LL; 11M for S+WRN; 22.6M LS+WRN; and 22.3M for WRN only</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 .</head><label>8</label><figDesc>CIFAR-10, COVIDx-CRX2 and KTH-TIPS2 mean accuracy and std. error using cosine loss function.</figDesc><table><row><cell cols="2">Init. Arch.</cell><cell>Dataset</cell><cell>Loss</cell><cell>100 samples</cell><cell>500 samples</cell><cell>1000 samples</cell><cell>1188 samples</cell></row><row><cell>TF</cell><cell cols="2">LS+WRN CIFAR-10</cell><cell>CE</cell><cell>43.6 ? 0.87</cell><cell cols="3">63.13 ? 0.29 70.14 ? 0.26 -</cell></row><row><cell>TF</cell><cell cols="2">LS+WRN CIFAR-10</cell><cell cols="2">Cosine 42.94 ? 0.77</cell><cell>61.42 ? 0.26</cell><cell>68.29 ? 0.18</cell><cell>-</cell></row><row><cell>TF</cell><cell cols="2">LS+WRN COVIDx</cell><cell>CE</cell><cell cols="4">81.20 ? 1.73 90.50 ? 0.70 93.68 ? 0.35 -</cell></row><row><cell>TF</cell><cell cols="2">LS+WRN COVIDx</cell><cell cols="2">Cosine 80.03 ? 2.16</cell><cell>89.53 ? 0.89</cell><cell>92.75 ? 0.65</cell><cell>-</cell></row><row><cell>TF</cell><cell cols="3">LS+WRN KTH-TIPS2 CE</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>69.23 ? 0.67</cell></row><row><cell>TF</cell><cell cols="4">LS+WRN KTH-TIPS2 Cosine -</cell><cell>-</cell><cell>-</cell><cell>70.86 ? 0.67</cell></row></table><note>TF: tight-frame LS: Learnable Scattering S: Scattering CE: Cross-Entropy Loss</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 .</head><label>9</label><figDesc>Deformations and their maximum value</figDesc><table><row><cell cols="2">Deformation Maximum Value</cell></row><row><cell>Custom1</cell><cell>1</cell></row><row><cell>Custom2</cell><cell>1</cell></row><row><cell>Rotation</cell><cell>10</cell></row><row><cell>Scale</cell><cell>1.4</cell></row><row><cell>Shear</cell><cell>5</cell></row><row><cell>Translation</cell><cell>22</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Canonical 16 39.73 ? 0.39 54.17 ? 0.36 58.36 ? 0.29 77.33</figDesc><table><row><cell></cell><cell></cell><cell>L</cell><cell>100 samples</cell><cell>500 samples</cell><cell>1000 samples</cell><cell>All</cell></row><row><cell cols="2">LS+LL ? Canonical</cell><cell>8</cell><cell cols="2">39.70 ? 0.62 50.74 ? 0.30</cell><cell>54.76 ? 0.22</cell><cell>74.94</cell></row><row><cell>LS+LL ? S +LL</cell><cell>-</cell><cell>8</cell><cell cols="2">37.55 ? 0.62 49.67 ? 0.33</cell><cell>53.96 ? 0.48</cell><cell>70.71</cell></row><row><cell>S +LL</cell><cell>-</cell><cell cols="3">16 35.85 ? 0.48 48.2 ? 0.27</cell><cell>52.74 ? 0.25</cell><cell>70.64</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">It is not difficult to extend this derivation to Morlet wavelets, but the resulting expressions are rather cumbersome and left out for brevity.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Joint time-frequency scattering for audio classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>And?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lostanlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Joint time-frequency scattering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>And?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lostanlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="3704" to="3718" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep scattering spectrum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>And?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="4114" to="4128" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scattering transforms in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom?s</forename><surname>Mathieu Andreux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Angles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Exarchakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaspar</forename><surname>Leonarduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis</forename><surname>Rochette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Thiry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Zarka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>And?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belilovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">60</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generative latent implicit conditional optimization when learning from small sample</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Idan</forename><surname>Azuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphna</forename><surname>Weinshall</surname></persName>
		</author>
		<idno>2021. 4</idno>
	</analytic>
	<monogr>
		<title level="m">2020 25th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<biblScope unit="page" from="8584" to="8591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spline filters for end-to-end deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randall</forename><surname>Balestriero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Cosentino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Baraniuk</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="364" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Interpretable super-resolution via a learned time-series representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randall</forename><surname>Balestriero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07713</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep learning on small datasets without pre-training using cosine loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Barz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Denzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1371" to="1380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Learning from few samples: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nihar</forename><surname>Bendre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Hugo Terashima Mar?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Najafirad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.15484</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tune it or don&apos;t use it: Benchmarking data-efficient image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Brigato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Barz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Iocchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Denzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Visual Inductive Priors for Data-Efficient Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Vipriors 1: Visual inductive priors for data-efficient deep learning challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert-Jan</forename><surname>Bruintjes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Attila</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><forename type="middle">Baptista</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Osman</forename><surname>Semih Kayhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Van Gemert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03768</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Invariant scattering convolution networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1872" to="1886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno>abs/2002.05709</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learnable group transform for time-series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Cosentino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnaam</forename><surname>Aazhang</surname></persName>
		</author>
		<idno>PMLR, 2020. 2</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="2164" to="2173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A learnable scatternet: Locally invariant convolutional layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fergal</forename><surname>Cotter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="350" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autoaugment</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09501</idno>
		<title level="m">Learning augmentation policies from data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Solid harmonic wavelet scattering for predictions of molecule properties. The Journal of chemical physics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Eickenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Exarchakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Hirn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis</forename><surname>Thiry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep symmetry networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">M</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Wavelet scattering regression of quantum chemical energies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Hirn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Poilvert</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Multiscale Modeling &amp; Simulation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="827" to="863" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Hirn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Poilvert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.02077</idno>
		<title level="m">Quantum energy regression using scattering transforms</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Structured receptive fields in cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Van Gemert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyu</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On translation invariance in cnns: Convolutional layers can exploit absolute spatial location</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">C</forename><surname>Osman Semih Kayhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gemert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harold W Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Naval research logistics quarterly</title>
		<imprint>
			<date type="published" when="1955" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ole: Orthogonal low-rank embedding-a plug and play geometric loss for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos?</forename><surname>Lezama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Mus?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8109" to="8118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distinctive image features from scaleinvariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A wavelet tour of signal processing. Elsevier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Group invariant scattering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1331" to="1398" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Understanding deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">374</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Scaling the scattering transform: Deep hybrid networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Oyallon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Belilovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5618" to="5627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Oyallon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5940</idno>
		<title level="m">Generic deep networks with wavelet scattering</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Scattering networks for hybrid representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Oyallon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Belilovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="2208" to="2221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Geometric wavelet scattering networks on compact riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Perlmutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Hirn</surname></persName>
		</author>
		<idno>PMLR, 2020. 1</idno>
	</analytic>
	<monogr>
		<title level="m">Mathematical and Scientific Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="570" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Clustering earthquake signals and background noises in continuous seismic data with unsupervised deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?onard</forename><surname>Seydoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randall</forename><surname>Balestriero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piero</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><forename type="middle">De</forename><surname>Hoop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Campillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rotation, scaling and deformation invariant scattering for texture discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Rigid-motion scattering for texture classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Mallat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1403.1687</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Wavelet scattering networks for atomistic systems with extrapolation of material properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Sinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Brumwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Kwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">84109</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Super-convergence: Very fast training of neural networks using large learning rates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholay</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Topin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">11006</biblScope>
			<biblScope unit="page">1100612</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Locally-transferred fisher vectors for texture classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lauren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>O&amp;apos;donnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4912" to="4920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Harmonic networks with limited training samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Ulicny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">A</forename><surname>Krylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rozenn</forename><surname>Dahyot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th European Signal Processing Conference (EUSIPCO)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Covidnet: A tailored deep convolutional neural network design for detection of covid-19 cases from chest x-ray images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Zhong Qiu Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Harmonic networks: Deep translation and rotation equivariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><forename type="middle">J</forename><surname>Garbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniyar</forename><surname>Turmukhambetov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><forename type="middle">J</forename><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
		<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Wide residual networks. arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
