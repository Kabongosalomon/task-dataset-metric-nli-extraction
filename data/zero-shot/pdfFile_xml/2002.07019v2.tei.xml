<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Prove Theorems by Learning to Generate Theorems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
							<email>mingzhew@cs.princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
							<email>jiadeng@cs.princeton.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Prove Theorems by Learning to Generate Theorems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider the task of automated theorem proving, a key AI task. Deep learning has shown promise for training theorem provers, but there are limited humanwritten theorems and proofs available for supervised learning. To address this limitation, we propose to learn a neural generator that automatically synthesizes theorems and proofs for the purpose of training a theorem prover. Experiments on real-world tasks demonstrate that synthetic data from our approach improves the theorem prover and advances the state of the art of automated theorem proving in Metamath. Code is available at https://github.com/princeton-vl/MetaGen. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada. arXiv:2002.07019v2 [cs.LO] 30 Oct 2020</p><p>Recently, Huang (2019) introduced a two-player game which encourages players to learn to predict the consistency of logical formulas by self-play. These two players behave symmetrically and compete with each other in the game. In contrast, our generator and prover execute different tasks, and are co-operative. In addition, their game remains a theoretical proposal without any empirical validation, whereas we have performed experiments on large-scale data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automated theorem proving aims to automatically generate a proof given a conjecture (the target theorem) and a knowledge base of known facts, all expressed in a formal language. Automated theorem proving is useful in a wide range of applications, including the verification and synthesis of software and hardware systems <ref type="bibr" target="#b12">(Gu et al., 2016;</ref><ref type="bibr" target="#b6">Darvas et al., 2005;</ref><ref type="bibr" target="#b21">Kern &amp; Greenstreet, 1999)</ref>.</p><p>Automated theorem proving boils down to a search problem: finding the sequence of symbol manipulations that generate a valid proof. The fundamental challenge lies in the explosion of search space, in particular with long proofs and large knowledge bases. The success of theorem proving thus relies on effective heuristics that guide the prover by deciding the next step the prover should take.</p><p>Deep learning has emerged as a promising approach to learning search heuristics in an automated theorem prover <ref type="bibr" target="#b15">(Irving et al., 2016;</ref><ref type="bibr" target="#b38">Whalen, 2016;</ref><ref type="bibr" target="#b25">Loos et al., 2017;</ref><ref type="bibr" target="#b1">Bansal et al., 2019a;</ref><ref type="bibr" target="#b24">Lee et al., 2019)</ref>. The search process fundamentally reduces to a sequence of actions on manipulating a set of symbols. Thus a deep network can be trained to select the best action at each step.</p><p>A key challenge is how to train such networks. Prior work has used human-written theorems and proofs to perform imitation learning and has shown promising results <ref type="bibr" target="#b25">(Loos et al., 2017;</ref><ref type="bibr" target="#b42">Yang &amp; Deng, 2019;</ref><ref type="bibr" target="#b38">Whalen, 2016;</ref><ref type="bibr" target="#b27">Paliwal et al., 2019)</ref>. The training data consists of theorems and proofs manually written by human experts in a formal language, and the prover is trained to imitate the proof steps demonstrated by humans.</p><p>However, relying on human-written data has a major drawback: such data has limited availability and scalability. Writing theorems and proofs in a formal language requires highly specialized knowledge and skills, including mathematics, computer programming, and proficiency in the particular formal language. For a CS graduate student, it can take months to master a new formal language such as Mizar, Metamath or HOLight <ref type="bibr" target="#b39">(Wiedijk, 2003)</ref>, after which it can take days to formalize a single page of a math textbook. This makes it impractical to crowdsource human-written proofs at large scale.</p><p>In this paper, we propose to train a theorem prover using synthetic data. The basic idea is to construct a generator that automatically synthesizes new theorems and their proofs, which serve to augment human-written data for training the prover. To generate a new theorem and its proof, the generator performs a sequence of symbol manipulations, similar to a prover. It repeatedly applies inference rules on a set of existing theorems and combines their proofs to form the proof of the new theorem. It is important to note that despite the similarity of operations, the generator has a much easier task than the prover. The generator just needs to generate some new theorem of its own choice, whereas the prover needs to find the proof for a particular target theorem specified by someone else.</p><p>One challenge of generating synthetic theorems is that there are infinitely many possibilities but the prover can only use a finite amount of them during training. Not all theorems are equally useful as training data. Thus a key question is how to generate synthetic theorems that are more useful. To this end we make the generator learnable by parameterizing it with deep networks.</p><p>We hypothesize that the generated data will be more useful if they are similar to human-written data. Therefore we use human-written data to train a generator. We consider two scenarios. If the human-written data consist of both theorem statements and their proofs, we train the generator to follow the proof steps in the forward direction, so that a well-trained generator would derive theorems humans tend to derive. If the human-written data consist of only theorem statements but not their proofs, i.e. no human actions to imitate, we use reinforcement learning to let the generator discover good actions that lead to synthetic theorems that are similar to the human-written theorems. To measure similarity between synthetic theorems and human theorems, we use a discriminator trained to distinguish the human theorems from synthetic ones, similar to GANs <ref type="bibr" target="#b11">(Goodfellow et al., 2014)</ref>.</p><p>We instantiate our approach in Metamath <ref type="bibr" target="#b26">(Megill &amp; Wheeler, 2019)</ref>, a popular language for formal mathematics, and with Holophrasm <ref type="bibr" target="#b38">(Whalen, 2016)</ref>, a Metamath neural prover. We propose a neural theorem generator called "MetaGen", which synthesizes new theorems and their proofs expressed in the formalism of Metamath. To the best of our knowledge, MetaGen is the first neural generator of synthetic training data for theorem proving. Experiments on real-world Metamath tasks show that synthetic data from MetaGen can help train better provers, advancing the state of art in theorem proving on Metamath.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Automated theorem proving Our work is related to prior work on learning to prove theorems <ref type="bibr" target="#b38">(Whalen, 2016;</ref><ref type="bibr" target="#b10">Gauthier et al., 2018;</ref><ref type="bibr" target="#b1">Bansal et al., 2019a;</ref><ref type="bibr" target="#b42">Yang &amp; Deng, 2019;</ref><ref type="bibr" target="#b25">Loos et al., 2017;</ref><ref type="bibr" target="#b0">Balunovic et al., 2018;</ref><ref type="bibr" target="#b20">Kaliszyk et al., 2018;</ref><ref type="bibr" target="#b2">Bansal et al., 2019b;</ref><ref type="bibr" target="#b29">Polu &amp; Sutskever, 2020)</ref>. Our work directly builds off of Holophrasm <ref type="bibr" target="#b38">(Whalen, 2016)</ref>, a neural-augmented theorem prover for Metamath. It contains three deep networks to generate actions and initial values to guide proof search following the UCT algorithm <ref type="bibr" target="#b23">(Kocsis &amp; Szepesv?ri, 2006)</ref>. <ref type="bibr" target="#b29">Polu &amp; Sutskever (2020)</ref> also build the theorem prover for Metamath by adopting the GPT-like network architectures and pretraining methods and generating proof steps autoregressively.</p><p>TacticToe <ref type="bibr" target="#b10">(Gauthier et al., 2018)</ref>, DeepHOL <ref type="bibr" target="#b1">(Bansal et al., 2019a)</ref> and ASTactic <ref type="bibr" target="#b42">(Yang &amp; Deng, 2019)</ref> are learning-based theorem provers based on interactive theorem provers HOL4 <ref type="bibr" target="#b31">(Slind &amp; Norrish, 2008)</ref>, HOL Light <ref type="bibr" target="#b13">(Harrison, 2009</ref>) and Coq <ref type="bibr" target="#b3">(Bertot &amp; Cast?ran, 2004)</ref> respectively. <ref type="bibr" target="#b27">Paliwal et al. (2019)</ref> improves DeepHOL by representing formulas as graphs. <ref type="bibr" target="#b25">Loos et al. (2017)</ref> proposes to learn clause selection by deep learning inside the first-order logic prover E <ref type="bibr" target="#b30">(Schulz, 2002)</ref>.</p><p>All of these methods are orthogonal to our approach because all of their provers are learned from human-written training data, whereas our prover is trained from human data augmented with synthetic data. Our contribution is on the generation of synthetic data and using such data to train a prover. <ref type="bibr" target="#b20">Kaliszyk et al. (2018)</ref>; <ref type="bibr">Bansal et al. (2019a,b)</ref>; <ref type="bibr" target="#b0">Balunovic et al. (2018)</ref> use reinforcement learning to train provers with only human-written theorems or SMT conjectures but not proofs. During training, a prover collects rewards only upon finding full proofs. In contrast, we always train our prover using imitation learning. Under the same setting with only human-written theorems but not proofs, we use reinforcement learning to train our generator, whose reward is the similarity between a generated theorem and human-written theorems, as measured by an adversarial discriminator. Our reinforcement learning task is much easier because the reward is continuous and there are many ways to generate theorems similar to human-written ones. <ref type="bibr" target="#b43">Zombori et al. (2019);</ref><ref type="bibr" target="#b8">Fawzi et al. (2019)</ref> construct theorem provers by training on randomly generated synthetic theorems and evaluate the learned prover on synthetic theorems. The main difference of our approach is that our generator is optimized through learning, as opposed to random generation. <ref type="bibr" target="#b20">Kaliszyk et al. (2018)</ref>; <ref type="bibr" target="#b16">Jakub?v &amp; Urban (2019)</ref>; <ref type="bibr" target="#b36">Urban et al. (2008)</ref>; <ref type="bibr" target="#b18">Kaliszyk et al. (2014)</ref>; <ref type="bibr" target="#b28">Piotrowski &amp; Urban (2018)</ref> train theorem provers iteratively. They repeatedly apply the trained prover on existing human theorems and generate new machine proofs to train the prover further. In these methods, only new proofs are synthesized and the synthetic proofs are only for existing human theorems; no new theorems are synthesized. In contrast, our approach synthesizes both new theorems and new proofs which could cover a much larger space of possible derivations than the proofs of existing human theorems. <ref type="bibr" target="#b34">Urban (2004)</ref>; ;  extract proof tasks from the proofs of human-written theorems, such as the intermediate inference steps or their variants. That is, they extract "sub-proofs" from existing proofs. In contrast, we generate entirely new theorems and new proofs that are not part of any existing proofs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthetic theorem generation</head><p>Our work is also related to the line of work on conjecturing <ref type="bibr" target="#b4">(Chvalovsk? et al., 2019;</ref><ref type="bibr" target="#b35">Urban &amp; Jakub?v, 2020;</ref><ref type="bibr" target="#b5">Colton, 2012)</ref>, which aims to generate mathematical conjectures automatically. The generated conjectures are not necessarily true, and their proofs are not required. In contrast, each of our synthetic theorem is guaranteed to be correct and its proof is automatically available.</p><p>Automatic goal generation by self-play Our work is similar to the line of work in reinforcement learning <ref type="bibr" target="#b9">(Florensa et al., 2018;</ref><ref type="bibr" target="#b32">Sukhbaatar et al., 2017</ref><ref type="bibr" target="#b33">Sukhbaatar et al., , 2018</ref><ref type="bibr" target="#b7">Durugkar &amp; Stone, 2018</ref>) that deploys two agents in adversary self-play, where one agent to generate tasks for another agent to accomplish. We pursue similar ideas in the new context of theorem proving by learning to generate synthetic theorems to train the prover. Also of note is that we have no adversarial self-play. The goal of the generator is to discover novel theorems similar to human-written ones, not to beat the prover.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background on Metamath</head><p>Metamath is a language for developing formal mathematics. It is one of the simplest formal systems. It has only one inference rule, called substitution, but is universally applicable in formalizing a large portion of mathematics 1 and different types of logic <ref type="bibr" target="#b26">(Megill &amp; Wheeler, 2019)</ref>.</p><p>Expression and theorem A basic building block of Metamath is expressions. An expression is a sequence of tokens that follows a set of grammar rules called "generating axioms". A token is either a constant or a variable. For example, x + 2 * y = y + (x + y) is an expression, where x and y are two variables. Each expression corresponds to a unique parse tree where each internal node represents a generating axiom and each leaf node is a token.</p><p>A theorem consists of a set of expressions, one expression as its assertion and zero or more expressions as its hypotheses. The theorem can be understood to state that the hypotheses (e.g. x 2 = 1 and x &gt; 0) entail the assertion (e.g. x = 1). Some examples of theorems are shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>Substitution The only inference rule in Metamath is substitution, which transforms one expression by replacing each variable with a non-empty new expression. For example, the expression A = B can be transformed to E + F = C * D by the substitution A ? E + F and B ? C * D.</p><p>Given two expressions a and b, we say b can reach a or a is reachable from b if there exists a substitution that transforms b to a. This is equivalent to saying that the parse tree of b can be obtained by "trimming" the parse tree of a-repeatedly picking an internal node, removing all its descendants, and replacing it with a variable node. Reachability can be checked by comparing parse trees; an algorithm is described in Appendix B.</p><p>Proof step A proof step is the basic unit of reasoning. A proof step in Metamath has two parts: (1) a theorem and (2) a substitution that maps each variable in the theorem to a new expression. A proof step serves to establish entailment between expressions based on the invoked theorem. For example, let t be the theorem over1i, with the hypothesis A = B and the assertion (A F C) = (B F C), where {A, B, C, F } is the set of variables in t. Let ? be a substitution that maps each variable in t to a new expression: A ? 2, B ? (1 + 1), C ? 2 and F ? +. By replacing variables in t with their corresponding expressions given by ?, we have a new hypothesis 2 = (1 + 1) and a new assertion (2 + 2) = ((1 + 1) + 2) This proof step (t, ?) establishes that the new hypothesis 2 = (1 + 1) entails the new assertion (2 + 2) = ((1 + 1) + 2) based on theorem t. The new assertion is called the conclusion and the new hypothesis is called the precondition. Because a theorem has one assertion and zero or more hypotheses, a proof step thus has one conclusion and zero or more preconditions.</p><p>Proof A theorem is proved if we can construct a proof tree that connects the hypotheses of the theorem to its assertion through entailment. The root node of a proof tree is the assertion of the theorem. Each leaf node of the tree is either a hypothesis of the theorem or empty. Each internal node of the tree is an expression and is associated with a proof step that uses an pre-existing theorem, together with an appropriate substitution, to establish the entailment of this internal node by its child nodes. Note that if an internal node has an empty child, it means that the proof step has no preconditions. An example proof tree is shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>A proof is a sequence of proof steps that can be obtained by traversing a proof tree in pre-order. This linearized proof is an equivalent to the tree representation. In this work we will use "proof" and "proof tree" interchangeably.</p><p>Corpus A corpus consists of a set of axioms and a sequence of theorems and their corresponding proofs. The proof of each theorem uses only the axioms and the preceding theorems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Approach</head><p>Task setup We use the standard theorem proving setup in prior work <ref type="bibr" target="#b15">Irving et al. (2016)</ref>; <ref type="bibr" target="#b1">Bansal et al. (2019a)</ref>; <ref type="bibr" target="#b38">Whalen (2016)</ref>. A proof task consists of a target theorem (or "target" in short) to be proved and a set of background theorems to be used as known facts. For each theorem in a corpus, we construct a proof task using the theorem as the target theorem and all preceding theorems (i.e. the theorems that humans had available when they were proving the target theorem) as the background theorems. In other words, each theorem in the corpus corresponds to a unique proof task that uses the theorem as the target. We randomly split all theorems into three disjoint sets: a training set, a validation set, and a test set. Accordingly, we have three corresponding sets of proof tasks using the theorems as targets. More details about this setup in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generator</head><p>We propose MetaGen, a neural generator that performs forward reasoning to synthesize theorems. It takes a set of training proof tasks as input and outputs a set of synthetic theorems. These synthetic theorems are then combined with original training proof tasks to train the theorem prover (as shown in the right of <ref type="figure" target="#fig_0">Fig. 1</ref>). The basic operation is generating a proof step-selecting an existing theorem and constructing a substitution. From this single proof step we can derive a new theorem. Now, we can treat this new theorem as an existing theorem and repeat to generate additional new theorems.</p><p>One issue requiring special handling is avoiding generating "meaningless" theorems. A meaningless theorem is one that includes falsehood in its hypotheses-as a result it is always provable regardless what the assertion says. It is possible to generate such a theorem if we allow arbitrary substitutions in constructing a proof step. For example, the hypothesis A = B can be substituted into 1 = 2. Such theorems are valid but unlikely to be useful as training data.</p><p>To avoid meaningless theorems, in constructing a proof step, we require that each new hypothesis produced by substitution must be identical to the full expression of a node in an existing proof tree (either the root, a leaf, or an internal node), such as the five expressions in yellow boxes in <ref type="figure" target="#fig_0">Fig. 1</ref>. This prevents introducing false expressions as hypotheses, provided that the existing proofs have no false expressions. See Appendix D about more discussion on meaningless theorems A second issue is generating new theorems with multi-step proofs. A single proof step gives a shallow tree. To generate theorems with longer proofs, we "graft" this shallow tree with existing proof trees or subtrees. For a leaf node e of the shallow tree, we can replace it with an existing proof tree (or subtree) whose root node is also e. For example, suppose the shallow tree proves that x 2 = 1 and x &gt; 0 entail x = 1, and there already exists another tree proving that x 3 &gt; 0 entails x &gt; 0. Then we can join the two trees to generate a new tree proving that x 3 &gt; 0 and x 2 = 1 entail x = 1.</p><p>To generate theorems and proofs more similar to human-written ones, we impose an additional constraint that a synthesized proof step can only invoke a theorem that has appeared as a background theorem in a training proof task. This is because in the ground-truth proof for a proof task, only the background theorems are invoked in proof steps. This means that we do not invoke any synthesized theorems. To implement this constraint, the generator constructs proof steps using a restricted set of "invocable" theorems pre-specified as input to the generator.</p><p>Initializing existing proof trees The generator takes as input a set E of existing theorems and optionally their proof trees, and a set I of invocable theorems, where E and I are the union of the target and background theorems of the training proof tasks respectively. To enable tree grafting, it first builds a set G of existing proof trees. For every theorem in E, if its proof tree is available, for every node e in its proof tree, we add to G the subtree that is rooted at e and contains all nodes below e. Otherwise, we add to G every hypothesis of this theorem as a single node proof tree.</p><p>Two proof trees are considered equivalent if they have the same root node and the same leaf nodes, i.e. they prove the same theorem. Among equivalent trees, we only keep the smallest one. As a result, G contains all sub-proof trees from all the existing theorems that can be grafted to a new proof step.</p><p>Generating new theorems To generate a new theorem, the key procedure is to construct a proof step and a set S of existing proof trees such that S is a subset of G and each precondition of this proof step matches the root node of a proof tree in S. This is achieved in three steps as follows:</p><p>1. Pick an invocable theorem t ? I according to the frequencies of invocable theorems being used in the proofs of the existing theorems.</p><p>Relevance network of generator The relevance network in step 2 is a deep network trained to pick a proof tree from a set of candidates by scoring and ranking them. It uses the same design as the relevance network in Holophrasm Whalen (2016) (see Sec. 4.2) but has different inputs and purposes. It takes two sequences of tokens as input. One input sequence represents the root and leaf nodes of a proof tree. The other sequence consists of two parts. One part represents the leaf nodes of the proof trees that have been selected for preceding hypotheses (the hypotheses are processed one by one). The other part represents the assertion and hypotheses of the invocable theorem transformed by the current substitution, except for the current hypothesis to be processed which is represented by a special token. Two GRU encoders convert each input sequence to an embedding vector, followed by a bilinear layer to output a score from the two vectors. In practice, we limit the number of candidate trees to 2000 for tractability.</p><p>Substitution network of generator The substitution network generates the substitution for a target variable of an invocable theorem. It uses the same design as the "generation network" in Holophrasm Whalen (2016) (see Sec. 4.2) but has different inputs and purposes. It is a sequence-tosequence model with the encoder-decoder GRU network. It takes as input the sequence of tokens that represents the assertion of the invocable theorem and the leaf nodes of the existing proof trees that have been selected to construct a proof step. The target variable is represented by a special token. The network outputs a sequence of tokens, sampled one by one based on the softmax probabilities.</p><p>Generator training We propose two strategies to train the relevance network and the substitution network, depending on the availability of human-written proofs.</p><p>Our generator can work without learnable parameters if we remove the two deep network and sample new proof steps by randomly picking existing proof trees and generating substitutions. We call such a generator as MetaGen-Rand.</p><p>Given human-written proofs, we train MetaGen-IL by imitation learning. Given a proof step (t, ?) in a human-written proof tree s, each transformed hypothesis h(?) of theorem t is an internal node of tree s and is the root of a subtree; we train the relevance network to imitate this step by selecting this subtree among a large set of candidates.</p><p>For a variable f that appears in the assertion but not the hypotheses of t, the substitution network is trained to produce its human-written substitute expression ?(f ).</p><p>In the case of only human-written theorems but not their proofs, we can no longer perform imitation learning. We instead use reinforcement learning. The objective is to learn actions to maximize the similarity between the generated theorems and human-written theorems. We propose two reward functions to evaluate a generated theorem and update the two deep networks toward the higher rewards via the Reinforce algorithm <ref type="bibr" target="#b41">Williams (1992)</ref>. The first reward function is the cross-entropy of a generated theorem given by a language model trained from the human-written theorems. The generator from this reward is called MetaGen-RL-LM.</p><p>The second reward function is given by an adversarial loss similar to <ref type="bibr">GAN (Goodfellow et al., 2014</ref>)-a binary classifier to distinguish the human-written theorems from the generated ones. It is pretrained to separate human-written theorems from the theorems generated by MetaGen-Rand, and then updated on-the-fly to separate human-written theorems from the theorems generated by the current generator. The generator is updated to minimize the adversarial loss. We call this generator MetaGen-RL-Adv.</p><p>More details about the deep networks of the generator are presented in Appendix F.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Prover</head><p>We use Holophrasm <ref type="bibr" target="#b38">(Whalen, 2016)</ref> as our theorem prover and augment its training with synthetic data. Given a proof task, Holophrasm conducts backward reasoning to prove the target theorem as described in Appendix E. For completeness we briefly summarize how Holophrasm works and refer the reader to <ref type="bibr" target="#b38">Whalen (2016)</ref> and Appendix E for more details.</p><p>Holophrasm uses Monte Carlo Tree Search (MCTS) to explore multiple branches of actions to find a proof tree. It involves three learnable deep networks: a payoff network to determine which branch is  <ref type="formula">(2019)</ref>, we instantiate and validate our approach on a single formal system, but our approach is applicable to other formal systems such as HOL Light, Coq and Isabelle.</p><p>Our approach can be applied to a new system under the following conditions: (1) the search heuristics of the theorem prover can be trained by imitating ground truth proofs;</p><p>(2) the proof of a theorem is a tree of intermediate goals, and a proof steps demonstrate the entailment of a goal by its children;</p><p>(3) an intermediate goal in the proof is equivalent to a legal theorem. These conditions are satisfied by the formal systems mentioned above.</p><p>To adapt our approach to a new system, the main effort is to rewrite the procedure of sampling proof steps, by replacing substitution with inference rules of the new system. HOL Light, Coq and Isabelle only provide tactics as inference rules to decompose a goal into subgoals for backward reasoning. However, to generate new theorems, we need to execute the corresponding reverse tactics, which are unavailable in their ML environments. We leave the experiments on these systems as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Dataset We experiment on two Metamath knowledge bases: iset.mm and set.mm. iset.mm formalizes intuitionistic logic and contains 463 axioms and 8916 theorems, which give rise to 8916 corresponding proof tasks. These proof tasks are divided into 7123 training tasks, 890 validation tasks and 903 test tasks. We use the same version of set.mm as <ref type="bibr" target="#b38">Whalen (2016)</ref>. It formalizes the ZFC set theory and contains 1099 axioms and 27218 theorems, which give rise to 27218 corresponding proof tasks. These proof tasks are divided into 21786 training tasks, 2712 validation tasks and 2720 test tasks.</p><p>Training protocol On set.mm, we control for the number of human proofs provided during training. Specifically, we compare our approach to baselines while including either 0%, 10%, or 100% of the human proofs. We also report the baseline with 20% human proofs for comparison.  Implementation details We train the generator on the training set and use the trained generator to generate synthetic theorems and proofs. The prover is trained on both training and synthetic proofs.</p><p>On iset.mm, we generate 1M unique synthetic theorems. On set.mm, we generate 300K unique theorems for the setting of 0% of human proofs (after discarding any duplicates) and 1M unique theorems for 10% of the human training proofs. We generate 10M theorems for the setting of 100% of human proofs, by generating 1M unique theorems a time (maximum allowed by memory limit) and repeating 10 times.</p><p>During the training of the relevance network of the prover, we filter out the "trivial" proof steps. A goal is trivial if it is reachable from the assertion of a background theorem b and b has no hypotheses, because this goal can be decomposed by b without generating any new subgoals. By removing the training proof steps that have trivial goals when we train the relevance network, the performance of the prover is improved as shown in Tab. 3.</p><p>Please refer to Appendix F for more details about the implementation and baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results</head><p>To validate the effectiveness of our theorem generator, we evaluate provers trained on the synthetic data and compare them against various baselines.</p><p>Relevance network of prover We evaluate how synthetic data can improve the relevance network of Holophrasm. The relevance network assigns a score to each candidate background theorem. We use two metrics: (1) top-k accuracy defined as the percentage of times a groundtruth background theorems is ranked in the top k and (2) mean reciprocal rank (MRR) of every groundtruth background theorem among all candidates of its corresponding proof step. Both of them are the higher the better.</p><p>We evaluate the relevance network combined with different generators. We also evaluate with tf-idf similarity between sequences of tokens. In Tab. 1, we see that synthetic data brings significant improvement in all settings and the best performance is achieved with our trained generators.</p><p>Substitution network of prover We evaluate how synthetic data can improve the substitution network of Holophrasm. The substitution network predicts the probability of each token at each position under teacher forcing. We use two metrics: (1) accuracy, defined as the percentage of times the tokens in the groundtruth substitutions have the highest probabilities and (2) the average probability to generate the groundtruth substitutions normalized by its length. Tab. 2 reports the results, including the result of a language model. In all settings, synthetic data brings significant improvement. The best performance is achieved with our trained generators.</p><p>Prover To evaluate the prover as a whole, we follow the same protocol of Whalen (2016) (more details in Appendix F.2) and report the number of theorems proved. We compare with the original Holophrasm prover proposed by <ref type="bibr" target="#b38">Whalen (2016)</ref> trained by imitation learning on human-written proofs only. With zero human-written proofs for prover training, we also evaluate TF-IDF &amp; LM, an ablated version of Holophrasm that needs no training proofs-we remove the relevance network and instead pick a background theorem using tf-idf similarity; we replace the substitution network with a language model of theorem statements.</p><p>As shown in Tab. 3, the performance of the prover shares the same pattern as the relevance and substitution network. On both iset.mm and set.mm, the provers trained on synthetic data consistently prove more theorems than the provers trained on human proofs only. On set.mm, with 10% human proofs, the use of synthetic proofs almost achieve the same effect by doubling the number of human proofs (472 vs 476 proved theorems). The provers trained with learnable generators perform better than the provers trained with MetaGen-Rand.</p><p>Our GPU re-implementation of Holophrasm finds 557 proofs trained on 100% of human proofs, more than the number reported in <ref type="bibr" target="#b38">Whalen (2016)</ref>. We believe this is due to the fact that our prover runs faster on GPUs.</p><p>By removing the trivial proof steps from the training data of the relevance network of the prover, the number of proved theorems on the test set increases from 574 to 600.</p><p>Polu &amp; Sutskever (2020) demonstrate significant improvement on theorem proving of the set.mm benchmark by using very large Transformer <ref type="bibr" target="#b37">(Vaswani et al., 2017</ref>) models. Their model can prove 29.22% of test theorems (our percentage is 22.06%). We note a couple potential differences in experimental setup, which may make our results not directly comparable. They appear to use a different version of the set.mm knowledge base which has about 38k proofs (ours has 27218 proofs); their evaluation protocol may be different (our prover has a time limit of 5 minutes for each run while their time limit is not mentioned).</p><p>Please refer to Appendix G for the examples of synthetic theorems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have proposed a neural generator that automatically synthesizes theorems and proofs for the purpose of training a theorem prover. Experiments on real-world tasks have demonstrated that synthetic data from our approach improves the theorem prover and advances the state of the art of automated theorem proving in Metamath.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>Our work addresses automated theorem proving. A successful automated theorem prover can help us write programs that are provably correct, which is essential to safety-critical applications, such as software for autonomous driving. On the other hand, since the correctness of the found proofs and synthesized programs relies on the correctness of the underlying theorem prover, bugs in the prover can lead to catastrophic failure. Algorithm 3 summarizes the procedure to construct a proof step and the set S of existing proof trees. Algorithm 4 summarizes the complete procedure of MetaGen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Meaningless theorems</head><p>Tree "grafting" can potentially introduce meaningless theorems by combining conflicting hypotheses. For example, suppose the shallow tree proves that x 2 = 1 and x &gt; 0 entail x = 1, we can replace the leaf node x &gt; 0 with a subtree proving x = 5 entails x &gt; 0, which leads to a new tree proving that x = 5 and x 2 = 1 entail x = 1, which is meaningless. Unfortunately, there does not appear to be an easy way to avoid meaningless theorems resulting from tree grafting, because this would require checking the consistency of an arbitrary set of expressions, which can be as hard as general theorem proving. Despite this limitation, however, we still perform tree grafting because a lot of interesting mathematics do result from nontrivial combination of hypotheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Holophrasm</head><p>In this section we provide more background on the Holophrasm prover <ref type="bibr" target="#b38">Whalen (2016)</ref>. we refer the reader to <ref type="bibr" target="#b38">Whalen (2016)</ref> for more details.</p><p>Backward Reasoning To construct a proof tree of a target theorem, a straightforward strategy is to search backwards. We start with a single root node-the assertion of the new theorem-and pick a proof step that establishes the entailment of the root node. We expand the tree by adding the preconditions of this proof step as children of the root node. We repeatedly expand the tree by adding children to leaf nodes, until each leaf node is either empty or a hypothesis of the target theorem. This construction process can be understood as recursive goal decomposition: the assertion of the target theorem is the original goal; by picking a proof step we decompose the original goal into subgoals, Algorithm 2 Initializing existing proof trees Input: existing theorems E, existing proofs P Output: existing proof trees G G ? ? for theorem t in E do for hypothesis h in h t do Add h to G end for Add t to G as a one-step proof tree end for for proof tree p in P do for node e in p do g ? the largest subtree of p rooted at e. Add g to G end for end for Algorithm 3 Constructing a proof step Input: existing proof trees G, invocable theorems I Output:</p><formula xml:id="formula_0">proof step (t, ?), proof trees S Sample an invocable theorem t ? I ?, S ? ?, ? for hypothesis h in h t do C ? { g | g ? G ? Reachable(h, r g , ?)</formula><p>} {r g is the root node of proof tree g. C is the set of compatible existing proof trees} Sample a proof tree g ? C using softmax of the relevance network scores ? ? the substitution that transforms h to r g Add ? , g to ?, S end for for variable f in b do if f not in ? then Generate an expression e using the substitution network ?(f ) ? e end if end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 4 MetaGen</head><p>Input: existing theorems E, existing proofs P , int N Output: generated theorems Initialize existing proof trees G from E and P repeat Construct a proof step (t, ?) with proof trees S g ? the one-step proof tree of (t, ?) for hypothesis h in h t do {h(?) is a leaf node of the one-step proof tree g} Find s ? S such that r s = h(?) Replace h(?) with s in g {tree grafting} end for Add the new tree g to G until G reaches the expected volume N which are the preconditions of the proof step; then for each subgoal we repeat this process until all subgoals are resolved.</p><p>Obviously, each time we expand the tree, we may have multiple choices of proof steps and most of them will lead to dead ends. We thus need to explore multiple alternatives, which gives rise to  <ref type="bibr">[10,</ref><ref type="bibr">15,</ref><ref type="bibr">20]</ref> a search process where we need to keep track of what paths have been explored and decide which paths to explore further.</p><p>Proof search Backward reasoning in Holophrasm Whalen <ref type="formula">(2016)</ref> is implemented with a proof search tree, which keeps track of the exploration of multiple branches of actions to search for a complete proof tree. A proof search tree has two kinds of nodes, expressions and proof steps. An expression node has multiple proof steps as children and each proof step establishes the entailment of this expression by the preconditions. A proof step node has its preconditions as children. A expression is labeled solved if it is a hypothesis of the target theorem or any proof step in its children is solved. A proof step is labeled solved if it has no precondition or all of its preconditions are solved. A complete proof is found if the root node, which is the assertion of the target theorem, is solved.</p><p>Holophrasm maintains a payoff of each node in the proof search tree and uses Monte Carlo Tree Search (MCTS) to extend the proof search tree. The prover runs in iterations. In each iteration, it travels down from the root node. After visiting an expression, it either creates a new proof step as a new child or visits its best-performing child according to the UCB <ref type="bibr" target="#b23">(Kocsis &amp; Szepesv?ri, 2006)</ref> algorithm. After visiting a proof step, it travels to its worst-performing child with the lowest payoff. When an expression node is created, it is assigned an initial payoff and has no children. When a proof step node is created, its preconditions are also created as its children and the payoff of this proof step is the lowest payoff among its children. A pass continues until a new proof step is created.</p><p>The main heuristics of the prover are how to construct a proof step and what is the initial payoff of an expression. Similar to the generator, the prover constructs a proof step by using a relevance network to pick a background theorem, and a substitution network to generate a substitution for the selected background theorem. The initial payoff of an expression is calculated by a payoff network.</p><p>Relevance network of Holophrasm The relevance network of the prover is a deep network trained to pick a background theorem b to establish the entailment of an expression e, for the purpose of proving a target theorem t. It takes as input two sequences of symbols. One sequence represents the assertion and hypotheses of b. Another one represents e and the hypotheses of t. Two GRU encoders convert each sequence to an embedding vector, followed by a bilinear layer to output a score from two embeddings. The background theorem with the highest score is selected to construct the next proof step. The relevance network is trained to pick the background theorem that is used in the groundtruth proof step.</p><p>Substitution network of Holophrasm The substitution network generates the substitution for a target variable of a background theorem b for the purpose of proving a target theorem t. It is a sequence-to-sequence model with an encoder-decoder GRU network. It takes as input a sequence of symbols that represents the hypotheses of t and the hypotheses of b. The target variable is replaced by a special token. It is trained to generate the substitutions of groundtruth proof steps under teacher forcing. When it is called by the prover, it generates multiple substitution candidates for each target variable via beam search.</p><p>Payoff network of Holophrasm The payoff network calculates the payoff of an expression as the probability of this expression being used in the proof tree of a target theorem. It consists of a GRU network followed by two linear layers and the sigmoid, and takes as input a sequence of symbols that represents the expression to be evaluated and the hypotheses of the target theorem.</p><p>The payoff network is trained as a binary classifier to distinguish the expressions in groundtruth proof trees (called positive expressions) from other expressions. Since the payoff network is used to evaluate an expression added to the proof search tree, which is a precondition of a newly generated proof step, the training examples of the payoff network are generated in a similar way. For each positive expression, proof steps that establish the entailment of this expression are constructed by using the pretrained relevance and substitution network. The positive expressions from the preconditions of these proof steps are filtered out and the payoff network is trained to distinguish the positive expressions from the rest of preconditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Additional Implementation details</head><p>We implement MetaGen and Holophrasm with the same network architectures as used by <ref type="bibr" target="#b38">Whalen (2016)</ref>. For all of our networks in the generator and the prover, we use bidirectional GRUs to encode input sequences, and use the Adam <ref type="bibr" target="#b22">(Kingma &amp; Ba, 2014)</ref> optimizer to update parameters. The batch size is 100 unless otherwise noted.</p><p>Task setup It is important to note that a theorem can serve both as a target theorem in the test set and as a background theorem in the training set. This is a standard setup and is not "training on the test set"-a background theorem is used as a known fact in a training proof task and only its statement is provided, not its proof; seeing the statement of a background theorem during training does not tell us how to prove it during testing.</p><p>Input representation of the relevance and substitution network Here we provide more details on the input representation of the relevance and substitution network, which take sequences as input. We use the same form of input representations as used by <ref type="bibr" target="#b38">Whalen (2016)</ref>.</p><p>To represent an expression in a sequential form, one option is to use its "surface form". For example, "(1+1)=2" is simply given as such. Another option is to serialize its parse tree. The parse tree of "(1+1)=2" has two generating axioms. The first axiom is the root node of its parse tree and generates an expression in the form of "A=B". The second axiom is the left child of the root node and generates an expression in the form of "(C+D)" and this expression is used to substitute the variable A in the first axiom. The right child of the first axiom is the token "2". Both of the left child and the right child of the second axiom are the token "1". Then we can represent "(1+1)=2" as a sequence of symbols (t = , t + , 1, 1, 2), where each symbol is a node in the parse tree and t = and t + represent two generating axioms. This new sequence is obtained by traversing the parse tree in pre-order. Following <ref type="bibr" target="#b38">Whalen (2016)</ref>, we use the second option to represent expressions as input to our network.</p><p>Following <ref type="bibr" target="#b38">Whalen (2016)</ref>, we also make use of the graph structure of the parse tree. Each node in the input sequence is converted to a feature vector by a learnable embedding layer. Then the feature of this node is concatenated with another four-dimension vector describing the depth of the node, the degree of the node, the degree of its parent, and its position into the children of its parent. The concatenated vector is fed into the GRU encoder of the relevance and substitution network.</p><p>Multiple expressions are represented by their concatenation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1. Generator</head><p>Configuration of GRUs All of the GRUs in the generator have two layers and 256-dimensional hidden units.</p><p>Training relevance network of MetaGen-IL The relevance network of MetaGen-IL is updated to minimize the cross-entropy loss. Each training sample has one groundtruth proof tree and 10 negative candidates that are randomly sampled from compatible proof trees. It is trained for 60 epochs. The learning rate is set to 10 ?4 initially and halved after 30, 40 and 50 epochs.</p><p>Training substitution network of MetaGen-IL The substitution network of MetaGen-IL is trained for 40 epochs. The learning rate is set to 5 ? 10 ?4 initially and halved after 20, 26 and 32 epochs.</p><p>Training of MetaGen-RL To train MetaGen-RL-LM, we learn the language model of human-written theorems by utilizing a one-layer GRU with 64-dimensional hidden units. It is trained for 200 epochs. The learning rate is set to 5 ? 10 ?4 initially and halved after 80, 120 and 160 epochs.  <ref type="figure">? (A + B)</ref>) C : COMPLEX NUMBER SET.</p><formula xml:id="formula_1">B ? C ? exp(?i ? (A + B)) ? (2 ? i) i = ? ?1. ? G ? R ? E ? R ? sin( G+E 2 + 1) ? R R : REAL NUMBER SET. ? ? F : X ? Y ? ? RAN(F ) ? Y F: BIJECTION FROM X TO Y. RAN(F ): RANGE OF F . N = {x ? Z|M ? x} ? ? K ? N ? Z : INTEGER SET M ? {x ? Z|M ? x ? x ? K} r = q ? 2 ? y mod p x = y ? F (r ? y) = F (s ? x) MOD: MODULO OPERATION s = q ? 2 ? x mod p</formula><p>To train MetaGen-RL-Adv, we train a binary classifier using the same architecture as the payoff network of Holophrasm, which contains a two-layer GRU with 128-dimensional hidden units and two subsequent linear layers. It is pretrained to distinguish human-written theorems from 300K synthetic theorems generated by MetaGen-Rand. Then it is updated on-the-fly to distinguish human-written theorems from the synthetic theorems generated in the most recent 20 episodes.</p><p>For both MetaGen-RL-LM and MetaGen-RL-Adv, we train the generator for 700 episodes with the learning rate fixed to 10 ?4 . We deploy 10 parallel threads to synthesize new theorems by utilizing the current generator. Each thread generates 50 theorems in one episode and synchronizes the set G of existing proof trees with other threads for every 20 episodes. We clip policy gradients whose norm is larger 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2. Prover</head><p>Configuration of GRUs In the relevance and substitution network of the prover, all GRUs have two layers and 256-dimensional hidden units. We found 256-dimensional GRUs have slightly better performance than the 128-dimensional GRUs that are used by <ref type="bibr" target="#b38">Whalen (2016)</ref>. The GRU in the payoff network of the prover has two layers and 128-dimensional hidden units.</p><p>Training of the prover All three networks of the prover are trained by imitation learning. The relevance network and the substitution network are trained on both human-written proofs and synthetic proofs. The payoff network is trained on human-written proofs only.</p><p>The relevance network of the prover is trained to minimize the cross-entropy loss. Each training sample contains one groundtruth background theorem and 10 negative candidates that are randomly sampled from all background theorems that can be applied in this step. <ref type="table" target="#tab_4">Table 4</ref> presents the settings of learning rate schedules and the ratio of synthetic training samples per batch, for the training of the relevance and substitution network of the prover.</p><p>In all experiments, the payoff network is trained for 30 epochs. The learning rate is set to 10 ?4 initially and halved after 15, 20 and 25 epochs.</p><p>Evaluation protocol Following the evaluation protocol used by <ref type="bibr" target="#b38">Whalen (2016)</ref>, the prover attempts to prove each target theorem in the test set three times with the beam search width of the substitution network set to 1, 5, or 20. The prover stops if it has executed 10000 MCTS passes or hit the time limit of 5 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3. Baseline</head><p>Without human-written proofs, we compare our approach with a baseline that needs no training proofs. We remove the relevance network of the prover and pick a background theorem according to the tf-idf similarity between an expression and a background theorem, as proposed by <ref type="bibr" target="#b2">Bansal et al. (2019b)</ref>. We replace the substitution network of the prover with a language model trained on the statements of human-written theorems. We use this language model to generate an expression as the substitution of a target variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Examples of generated theorems</head><p>Some examples of synthetic theorems are presented in the <ref type="table" target="#tab_5">Table 5</ref>. Some are trivial (first and fourth), whereas others are fairly interesting-the third theorem involves a non-trivial statement about trigonometric functions and complex numbers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Left: A proof task. Middle: The proof tree of the theorem 3eqtri. Each leaf node is a hypothesis and each internal node corresponds to a proof step. Right: The overview of our approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Performance of the relevance network of the prover on validation data of iset.mm (top two rows) and set.mm (starting from the third row).</figDesc><table><row><cell>Human</cell><cell>Synthetic</cell><cell>Generator</cell><cell>Model</cell><cell cols="3">Top-1 Top-5 Top-20</cell><cell>MRR</cell></row><row><cell>proofs</cell><cell>proofs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>7123 (ISET)</cell><cell>0</cell><cell>-</cell><cell>RELEVANCE</cell><cell cols="2">43.27 69.57</cell><cell>89.68</cell><cell>0.5535</cell></row><row><cell>7123 (ISET)</cell><cell>1M</cell><cell>MetaGen-IL</cell><cell>RELEVANCE</cell><cell cols="2">45.10 71.00</cell><cell>89.46</cell><cell>0.5699</cell></row><row><cell>0</cell><cell>0</cell><cell>-</cell><cell>TF-IDF</cell><cell cols="2">14.28 21.13</cell><cell>32.55</cell><cell>0.1877</cell></row><row><cell>0</cell><cell>0</cell><cell>-</cell><cell>RELEVANCE</cell><cell>0.96</cell><cell>5.33</cell><cell>15.67</cell><cell>0.0445</cell></row><row><cell>0</cell><cell>300K</cell><cell>MetaGen-Rand</cell><cell>RELEVANCE</cell><cell cols="2">24.22 37.27</cell><cell>49.92</cell><cell>0.3093</cell></row><row><cell>0</cell><cell>300K</cell><cell cols="4">MetaGen-RL-LM RELEVANCE 24.74 37.66</cell><cell>54.22</cell><cell>0.3182</cell></row><row><cell>0</cell><cell>300K</cell><cell cols="4">MetaGen-RL-Adv RELEVANCE 25.07 39.33</cell><cell>50.23</cell><cell>0.3242</cell></row><row><cell>2179 (10%)</cell><cell>0</cell><cell>-</cell><cell>RELEVANCE</cell><cell cols="2">41.24 67.56</cell><cell>86.84</cell><cell>0.5356</cell></row><row><cell>2179 (10%)</cell><cell>1M</cell><cell>MetaGen-Rand</cell><cell>RELEVANCE</cell><cell cols="2">45.44 70.13</cell><cell>88.33</cell><cell>0.5692</cell></row><row><cell>2179 (10%)</cell><cell>1M</cell><cell>MetaGen-IL</cell><cell>RELEVANCE</cell><cell cols="2">46.10 71.12</cell><cell>89.38</cell><cell>0.5772</cell></row><row><cell>4358 (20%)</cell><cell>0</cell><cell>-</cell><cell>RELEVANCE</cell><cell cols="2">47.02 72.45</cell><cell>89.48</cell><cell>0.5870</cell></row><row><cell>21786 (100%)</cell><cell>0</cell><cell>-</cell><cell>RELEVANCE</cell><cell cols="2">51.52 78.56</cell><cell>93.41</cell><cell>0.6367</cell></row><row><cell>21786 (100%)</cell><cell>10M</cell><cell>MetaGen-Rand</cell><cell>RELEVANCE</cell><cell cols="2">52.08 77.76</cell><cell>92.83</cell><cell>0.6375</cell></row><row><cell>21786 (100%)</cell><cell>10M</cell><cell>MetaGen-IL</cell><cell>RELEVANCE</cell><cell cols="2">53.20 78.73</cell><cell>93.13</cell><cell>0.6474</cell></row></table><note>more promising, a relevance network to pick a background theorem to construct a proof step, and a substitution network 2 to generate substitutions.4.3 Applicability to other formal systems As is standard in related work Loos et al. (2017); Irving et al. (2016); Kaliszyk et al. (2018); Yang &amp; Deng</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance of the substitution network of the prover on validation data of iset.mm (top two rows) and set.mm (starting from the third row).</figDesc><table><row><cell cols="2">Human proofs Synthetic proofs</cell><cell>Generator</cell><cell>Model</cell><cell>Prob</cell><cell>Accuracy</cell></row><row><cell>7123 (ISET)</cell><cell>0</cell><cell>-</cell><cell>SUBSTITUTION</cell><cell>0.1723</cell><cell>49.45</cell></row><row><cell>7123 (ISET)</cell><cell>1M</cell><cell>MetaGen-IL</cell><cell>SUBSTITUTION</cell><cell>0.2554</cell><cell>57.81</cell></row><row><cell>0</cell><cell>0</cell><cell>-</cell><cell>LAUGUAGE MODEL</cell><cell>0.0032</cell><cell>9.06</cell></row><row><cell>0</cell><cell>0</cell><cell>-</cell><cell>SUBSTITUTION</cell><cell>0.0008</cell><cell>0.01</cell></row><row><cell>0</cell><cell>300K</cell><cell>MetaGen-Rand</cell><cell>SUBSTITUTION</cell><cell>0.0103</cell><cell>29.68</cell></row><row><cell>0</cell><cell>300K</cell><cell>MetaGen-RL-LM</cell><cell>SUBSTITUTION</cell><cell>0.0181</cell><cell>24.33</cell></row><row><cell>0</cell><cell>300K</cell><cell>MetaGen-RL-Adv</cell><cell>SUBSTITUTION</cell><cell>0.0186</cell><cell>31.38</cell></row><row><cell>2179 (10%)</cell><cell>0</cell><cell>-</cell><cell>SUBSTITUTION</cell><cell>0.2738</cell><cell>58.91</cell></row><row><cell>2179 (10%)</cell><cell>1M</cell><cell>MetaGen-Rand</cell><cell>SUBSTITUTION</cell><cell>0.3203</cell><cell>61.78</cell></row><row><cell>2179 (10%)</cell><cell>1M</cell><cell>MetaGen-IL</cell><cell>SUBSTITUTION</cell><cell>0.3710</cell><cell>66.56</cell></row><row><cell>4358 (20%)</cell><cell>0</cell><cell>-</cell><cell>SUBSTITUTION</cell><cell>0.3765</cell><cell>67.07</cell></row><row><cell>21786 (100%)</cell><cell>0</cell><cell>-</cell><cell>SUBSTITUTION</cell><cell>0.6142</cell><cell>81.57</cell></row><row><cell>21786 (100%)</cell><cell>10M</cell><cell>MetaGen-Rand</cell><cell>SUBSTITUTION</cell><cell>0.6439</cell><cell>81.85</cell></row><row><cell>21786 (100%)</cell><cell>10M</cell><cell>MetaGen-IL</cell><cell>SUBSTITUTION</cell><cell>0.6847</cell><cell>83.90</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Number of theorems proved on test data of iset.mm (top two rows) and set.mm (starting from the third row). ?: without removing the trivial proof steps from the training data of the relevance network.</figDesc><table><row><cell>Human</cell><cell>Synthetic</cell><cell>Generator</cell><cell>Prover</cell><cell>Test proofs</cell></row><row><cell>proofs</cell><cell>proofs</cell><cell></cell><cell></cell><cell>found</cell></row><row><cell>7123 (ISET)</cell><cell>0</cell><cell>-</cell><cell>HOLOPHRASM</cell><cell>378</cell></row><row><cell>7123 (ISET)</cell><cell>1M</cell><cell>MetaGen-IL</cell><cell>HOLOPHRASM</cell><cell>398</cell></row><row><cell>0</cell><cell>0</cell><cell>-</cell><cell>TF-IDF &amp; LM</cell><cell>312</cell></row><row><cell>0</cell><cell>0</cell><cell>-</cell><cell>HOLOPHRASM</cell><cell>219</cell></row><row><cell>0</cell><cell>300K</cell><cell>MetaGen-Rand</cell><cell>HOLOPHRASM</cell><cell>346</cell></row><row><cell>0</cell><cell>300K</cell><cell>MetaGen-RL-LM</cell><cell>HOLOPHRASM</cell><cell>351</cell></row><row><cell>0</cell><cell>300K</cell><cell>MetaGen-RL-Adv</cell><cell>HOLOPHRASM</cell><cell>357</cell></row><row><cell>2179 (10%)</cell><cell>0</cell><cell>-</cell><cell>HOLOPHRASM</cell><cell>454</cell></row><row><cell>2179 (10%)</cell><cell>1M</cell><cell>MetaGen-Rand</cell><cell>HOLOPHRASM</cell><cell>457</cell></row><row><cell>2179 (10%)</cell><cell>1M</cell><cell>MetaGen-IL</cell><cell>HOLOPHRASM</cell><cell>472</cell></row><row><cell>4358 (20%)</cell><cell>0</cell><cell>-</cell><cell>HOLOPHRASM</cell><cell>476</cell></row><row><cell>21786 (100%)</cell><cell>0</cell><cell>-</cell><cell>HOLOPHRASM('16)</cell><cell>388</cell></row><row><cell>21786 (100%)</cell><cell>0</cell><cell>-</cell><cell>HOLOPHRASM</cell><cell>557</cell></row><row><cell>21786 (100%)</cell><cell>10M</cell><cell>MetaGen-Rand</cell><cell>HOLOPHRASM</cell><cell>565</cell></row><row><cell>21786 (100%)</cell><cell>10M</cell><cell>MetaGen-IL</cell><cell>HOLOPHRASM  ?</cell><cell>574</cell></row><row><cell>21786 (100%)</cell><cell>10M</cell><cell>MetaGen-IL</cell><cell>HOLOPHRASM</cell><cell>600</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Algorithm 1 Function Reachable(n a , n b , ?) Input: node n a , node n b , substitution ? Output: True if n b could reach n a , otherwise False if n b represents a variable f then if f in ? then if ?(f ) = n a then return True {Consistent with the current substitution}</figDesc><table><row><cell>else</cell></row><row><cell>return False {Conflict with a preceding branch}</cell></row><row><cell>end if</cell></row><row><cell>else</cell></row><row><cell>?(f ) = n a {Variable f should be replaced by n a }</cell></row><row><cell>return True</cell></row><row><cell>end if</cell></row><row><cell>else</cell></row><row><cell>if n a and n b represent the same generating axiom or constant then</cell></row><row><cell>for i = 1 to len(c na ) do</cell></row><row><cell>{c n is the list of children of node n}</cell></row><row><cell>if Reachable(c na [i], c n b [i], ?) = false then</cell></row><row><cell>{A pair of child nodes doesn't match}</cell></row><row><cell>return False</cell></row><row><cell>end if</cell></row><row><cell>end for</cell></row><row><cell>{Every child of n b could reach a child of n a }</cell></row><row><cell>return True</cell></row><row><cell>else</cell></row><row><cell>return False {Two nodes have different values}</cell></row><row><cell>end if</cell></row><row><cell>end if</cell></row><row><cell>C. Pseudo-code for MetaGen</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Training details of the relevance network and the substitution network of the prover.</figDesc><table><row><cell>Network</cell><cell cols="4">Data Human Synthetic data Training</cell><cell>Initial</cell><cell>Epoch to halve</cell></row><row><cell></cell><cell>set</cell><cell>proofs</cell><cell>per batch</cell><cell>epochs</cell><cell>learning rate</cell><cell>learning rate</cell></row><row><cell>RELEVANCE</cell><cell>ISET</cell><cell>100%</cell><cell>20%</cell><cell>40</cell><cell>10 ?3</cell><cell>[12 20 28]</cell></row><row><cell>SUBSTITUTION</cell><cell>ISET</cell><cell>100%</cell><cell>70%</cell><cell>40</cell><cell>5 ? 10 ?4</cell><cell>[16, 24, 32]</cell></row><row><cell>RELEVANCE</cell><cell>SET</cell><cell>0%</cell><cell>100%</cell><cell>5</cell><cell>10 ?3</cell><cell>-</cell></row><row><cell>SUBSTITUTION</cell><cell>SET</cell><cell>0%</cell><cell>100%</cell><cell>5</cell><cell>5 ? 10 ?4</cell><cell>-</cell></row><row><cell>RELEVANCE</cell><cell>SET</cell><cell>10%</cell><cell>70%</cell><cell>20</cell><cell>10 ?3</cell><cell>[8, 12, 16]</cell></row><row><cell>SUBSTITUTION</cell><cell>SET</cell><cell>10%</cell><cell>70%</cell><cell>60</cell><cell>5 ? 10 ?4</cell><cell>[15, 30, 45]</cell></row><row><cell>RELEVANCE</cell><cell>SET</cell><cell>100%</cell><cell>50%</cell><cell>16</cell><cell>10 ?3</cell><cell>[5, 12, 14]</cell></row><row><cell>SUBSTITUTION</cell><cell>SET</cell><cell>100%</cell><cell>50%</cell><cell>24</cell><cell>5 ? 10 ?4</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Examples of synthetic theorems from MetaGen-IL trained on all human proofs of set.mm. (log e) ? A = A e = 2.71828...</figDesc><table><row><cell>Hypothesis</cell><cell>Assertion</cell><cell>Comment</cell></row><row><cell>?</cell><cell>(3 ? 1) + (1 + 0) = 1 + 3</cell><cell>SIMPLE ARITHMETIC.</cell></row><row><cell>A ? C</cell><cell>sin(A + B) = (exp(i</cell><cell></cell></row></table><note>?</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Its largest knowledge base, set.mm ranks 3rd in the "Formalizing 100 Theorems" challenge<ref type="bibr" target="#b40">(Wiedijk, 2019)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">. Initialize the set S of proof trees as empty. Initialize the substitution ? for t as empty. For each hypothesis h of theorem t, apply the current substitution ? to hypothesis h to obtain the transformed expression h(?), find all compatible proof trees, those whose root nodes are reachable from h(?)-h(?) can be transformed to the root nodes by substitution, which can be determined by comparing parse trees-and perform the following:? Select a compatible proof tree c using a relevance network (to be described later). For each variable that has not been substituted in h, update ? by assigning the variable a substitute expression to match the root of c. Add tree c to set S.If no compatible proof tree exists, go toStep 1 and rebuild this proof step from scratch.3. If a variable appears in a hypothesis of t, its substitution has been determined by matching this hypothesis with the root of a compatible proof tree. For the remaining variables that appear exclusively in the assertion of t, use a subtitution network (to be described later) to generate substitute expressions for them.This proof step gives a one-step proof tree, which we expand to a multi-step proof tree by grafting the trees in set S onto its leaves. This multi-step proof tree is added to G for subsequent generation. We repeat this procedure to get a set of synthetic theorems (pseudo-code in Appendix C).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">called the generation network in<ref type="bibr" target="#b38">Whalen (2016)</ref> but renamed here to avoid confusion with the generator.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Task setup</head><p>We use the standard theorem proving setup in prior work <ref type="bibr" target="#b15">Irving et al. (2016)</ref>; <ref type="bibr" target="#b1">Bansal et al. (2019a)</ref>; <ref type="bibr" target="#b38">Whalen (2016)</ref>. Suppose we have a sequence of theorems (t 1 , t 2 , ..., t n ), where each theorem appear at the order it is proved by mathematicians. For each theorem t i , we construct a proof task that proving t i (as the target theorem) using all its preceding theorems (t 1 , ..., t i?1 ) (as the background theorems), such that the prover has the same set of known facts as mathematicians to prove t i . Then we randomly split the five proof tasks into three sets for training, validation and testing.</p><p>It is important to note that a theorem can serve both as a target theorem in the test set and as a background theorem in the training set. This is a standard setup and is not "training on the test set"-a background theorem is used as a known fact in a training proof task and only its statement is provided, not its proof; seeing the statement of a background theorem during training does not tell us how to prove it during testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Checking reachability between expressions</head><p>For an expression e, let r e be the root node of the parse tree of e. Each node in the parse tree represents either a generating axiom (if internal node) or a token (if leaf node). We check if expression b can reach expression a by comparing their parse trees r a and r b through the following procedure:</p><p>1. Initialize the substitution ? as empty. 2. Compare the two root nodes.</p><p>? If root node r b represents a variable f , do the following: This procedure is summarized in Algorithm 1.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to solve smt formulas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balunovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bielik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vechev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10317" to="10328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An environment for machine learning of higher order logic theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wilcox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Holist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="454" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Learning to reason in large theories without imitation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10501</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Coq&apos;art: the calculus of inductive constructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bertot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cast?ran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">First experiments with data driven conjecturing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chvalovsk?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th Conference on Artificial Intelligence and Theorem Proving</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Automated theory formation in pure mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Colton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A theorem proving approach to analysis of secure information flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Darvas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>H?hnle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sands</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Security in Pervasive Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="193" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adversarial goal generation for intrinsic motivation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Durugkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning dynamic polynomial proofs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Fawzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4181" to="4190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic goal generation for reinforcement learning agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Florensa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v80/florensa18a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>Dy, J. and Krause, A.</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm?ssan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tactictoe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.00595</idno>
		<title level="m">Learning to reason with hol4 tactics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Certikos: An extensible architecture for building certified concurrent {OS} kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sj?berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Costanzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} Symposium on Operating Systems Design and Implementation</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="653" to="669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Light</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Theorem Proving in Higher Order Logics</title>
		<editor>Berghofer, S., Nipkow, T., Urban, C., and Wenzel, M.</editor>
		<meeting>the 22nd International Conference on Theorem Proving in Higher Order Logics<address><addrLine>TPHOLs; Munich, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">5674</biblScope>
			<biblScope unit="page" from="60" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">On learning to prove</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.11099</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deepmath-deep sequence models for premise selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>E?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2235" to="2243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Hammering mizar by learning clause guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jakub?v</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.01677</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning-assisted theorem proving with millions of lemmas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of symbolic computation</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="109" to="128" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Machine learner for automated reasoning 0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vysko?il</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.2359</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">.4 and 0.5. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Lemmatization for stronger reasoning in large theories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vysko?il</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Frontiers of Combining Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="341" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reinforcement learning of theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ol??k</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8822" to="8833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Formal verification in hardware design: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Greenstreet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Design Automation of Electronic Systems (TODAES)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="193" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bandit based monte-carlo planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kocsis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szepesv?ri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on machine learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="282" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Mathematical reasoning in latent space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11851</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Deep network guided proof search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kaliszyk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06972</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Metamath: A Computer Language for Mathematical Proofs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Megill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wheeler</surname></persName>
		</author>
		<ptr target="http://us.metamath.org/downloads/metamath.pdf" />
		<imprint>
			<date type="published" when="2019" />
			<publisher>Lulu Press</publisher>
			<pubPlace>Morrisville, North Carolina</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paliwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10006</idno>
		<title level="m">Graph representations for higher-order logic and theorem proving</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning premise selection in binary setting with atp feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Piotrowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Atpboost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Automated Reasoning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="566" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Generative language modeling for automated theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03393</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">E-a brainiac theorem prover</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ai Communications</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2, 3</biblScope>
			<biblScope unit="page" from="111" to="126" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A brief overview of hol4</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Slind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norrish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Theorem Proving in Higher Order Logics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="28" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Intrinsic motivation and automatic curricula via asymmetric self-play</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kostrikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fergus</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1703.05407</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Learning goal embeddings via self-play for hierarchical reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fergus</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1811.09083</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Mptp-motivation, implementation, first experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="319" to="339" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jakub?v</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14664</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">First neural conjecturing datasets and experiments. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Malarea sg1-machine learner for automated reasoning with semantic guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pudl?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vysko?il</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Automated Reasoning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="441" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Holophrasm: a neural automated theorem prover for higher-order logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Whalen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.02644</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Formal proof sketches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wiedijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Types for Proofs and Programs</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="378" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Formalizing 100 theorems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wiedijk</surname></persName>
		</author>
		<ptr target="http://www.cs.ru.nl/~freek/100/" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning to prove theorems via interacting with proof assistants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zombori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Csisz?rik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urban</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.13100</idno>
		<title level="m">Towards finding longer proofs</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
