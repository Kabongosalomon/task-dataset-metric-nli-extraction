<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Deep Knowledge Distillation framework for EEG assisted enhancement of single-lead ECG based sleep staging</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaibhav</forename><surname>Joshi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sricharan</forename><surname>Vijayarangan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preejith</forename><surname>Sp</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohanasankar</forename><surname>Sivaprakasam</surname></persName>
						</author>
						<title level="a" type="main">A Deep Knowledge Distillation framework for EEG assisted enhancement of single-lead ECG based sleep staging</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T18:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatic Sleep Staging study is presently done with the help of Electroencephalogram (EEG) signals. Recently, Deep Learning (DL) based approaches have enabled significant progress in this area, allowing for near-human accuracy in automated sleep staging. However, EEG based sleep staging requires an extensive as well as an expensive clinical setup. Moreover, the requirement of an expert for setup and the added inconvenience to the subject under study renders it unfavourable in a point of care context. Electrocardiogram (ECG), an unobtrusive alternative to EEG, is more suitable, but its performance , unsurprisingly, remains sub-par compared to EEG-based sleep staging. Naturally, it would be helpful to transfer knowledge from EEG to ECG, ultimately enhancing the model's performance on ECG based inputs. Knowledge Distillation (KD) is a renowned concept in DL that looks to transfer knowledge from a better but potentially more cumbersome teacher model to a compact student model. Building on this concept, we propose a cross-modal KD framework to improve ECG-based sleep staging performance with assistance from features learned through models trained on EEG. Additionally, we also conducted multiple experiments on the individual components of the proposed model to get better insight into the distillation approach. Data of 200 subjects from the Montreal Archive of Sleep Studies (MASS) was utilized for our study. The proposed model showed a 14.3% and 13.4% increase in weighted-F1-score in 4-class and 3-class sleep staging, respectively. This demonstrates the viability of KD for performance improvement of single-channel ECG based sleep staging in 4-class(W-L-D-R) and 3-class(W-N-R) classification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Sleep is a complex dynamic biological process that occurs in multiple cyclical stages. Typically, sleep is studied in sleep medicine by conducting a polysomnography (PSG) study, where multiple bio-signals are acquired during sleep. Electroencephalogram (EEG) signal is the gold standard for sleep studies considering its interpretability with brain activation, the pivot of sleep mechanism. Typically, Sleep staging is done by experts manually for 30/20 s epochs, based on the sleep staging rules and guidelines by AASM (American Academy of Sleep Medicine) <ref type="bibr" target="#b0">[1]</ref> or <ref type="bibr">Rechtschaffen and Kales (1968)</ref> (the 'R and K rules') <ref type="bibr" target="#b1">[2]</ref>. Given that manual sleep staging is time-consuming, several automated sleep staging algorithms, including NN based approaches <ref type="bibr" target="#b2">[3]</ref>, have been developed in recent history with remarkable performance on par with human accuracy. Conventionally, sleep is classified into five sleep stages: W, wakefulness; N1, a light sleep Different stages of sleep are characterized by the different patterns and frequencies observed in the EEG signal during sleep. However, EEG being obtrusive remains impractical in a non-clinical setup. Furthermore, brain-body interaction during sleep implies that other bio-signals can also capture the stages of sleep <ref type="bibr" target="#b3">[4]</ref>.</p><p>An alternative to the EEG is the Electrocardiogram (ECG) which is not only less obtrusive but also readily integrated into a point of care setup through wearable devices. Q.Li et al. <ref type="bibr" target="#b4">[5]</ref> achieved substantial results using ECG signal for sleep staging by extracting ECG Derived Respiration (EDR) and Respiratory Sinus Arrhythmia (RSA) based features for cross spectral spectrogram from a vast PSG dataset (SHHS, CinC, SLPDB) which helped to generalize the model better. In their work, Convolution Neural Network (CNN) was used for feature extraction, which was subsequently fed to Support Vector Machines (SVM) for sleep stage classification. They achieved an accuracy of 75.4% and 65.9% on SLPDB and SHHS, respectively, for 4-class sleep stage classification. Fonseca et al. <ref type="bibr" target="#b5">[6]</ref> used Linear Discriminant (LD) on 80 expert features extracted from ECG and Respiratory Inductance Plethysmography (RIP), which achieved an accuracy of 69% for 4-class sleep staging and 80% for 3-class sleep staging. Radha et al. <ref type="bibr" target="#b6">[7]</ref> used LSTM based temporal model approach for sleep staging on explicitly extracted 132 HRV features from ECG signal and achieved 77% accuracy. N. Sridhar et al. <ref type="bibr" target="#b7">[8]</ref> also achieved 77% accuracy with 2 stage CNNs by ECG-derived heart rate on a vast dataset comprising SHHS, MESA and CinC. Despite the increasing body of work, studies show that the performance of ECG based sleep staging remains vastly inferior to EEG based sleep staging <ref type="bibr" target="#b2">[3]</ref> <ref type="bibr" target="#b8">[9]</ref>. It would be immensely beneficial to combine the benefits of unobtrusive monitoring with improved accuracy. While multi-modal fusion methods for sleep staging get features of both signals and have been shown to provide improved accuracy <ref type="bibr" target="#b5">[6]</ref> <ref type="bibr" target="#b8">[9]</ref>, this setup requires multiple signal acquisition during inference. Thus, it is of great interest to employ the primary modality, EEG, to inform ECG based modelling without significant overhead during inference.</p><p>Knowledge Distillation (KD) in deep networks has recently garnered much traction to efficiently compress and transfer relevant information from extensive networks to more compact ones. Hinton et al. <ref type="bibr" target="#b9">[10]</ref> proposed a response based KD method to distil and transfer information from the softmax layer of a larger size teacher model to a student model to achieve better generalization. Romero et arXiv:2112.07252v2 [eess.SP] 5 Feb 2022 al. <ref type="bibr" target="#b10">[11]</ref> proposed a feature-based KD by deriving knowledge from the intermediate feature maps rather than the softmax layers. Zagoruyko et al. <ref type="bibr" target="#b11">[12]</ref> introduced the concept of transferring attention maps of the intermediate feature layers to enhance the distillation process. This was also extended across modalities spawning a separate subfield of cross-modal distillation <ref type="bibr" target="#b12">[13]</ref>. Deriving inspiration from these approaches, we propose a cross-modal KD approach combining response based and feature-based distillation that would enable multi-modal training of EEG and ECG while allowing for unimodal testing, enabling the usage of ECG alone during inference. To the best of our knowledge, this is the first study designed to validate the viability of KD to enhance ECG based sleep staging. Additionally, we compare the proposed model against individual components of the KD framework and subsequently demonstrate its efficacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Formulation</head><p>Let x eeg ? R ?S and x ecg ? R ?S be the EEG and ECG waveforms, sampled at rate S for ? seconds, respectively. Let F(eeg; ? eeg ) and F(ecg; ? ecg ) be the models which take in T fixed-length connected segments, each of length i, from x eeg and x ecg respectively. Let e be the frequency at which the signal is segmented,where the objective is to independently map x eeg and x ecg to [e * ?] labels, where each label is based on i= S/e sampled points. While thirty second intervals are usually considered (i.e., e = 1/30 Hz), the architecture we adapt is capable of handling different frequencies during inference. Specifically, the model F(eeg; ? eeg ) and F(ecg; ? ecg ) maps x eeg and x ecg to class confidence scores for predicting K classes in all T segments. The loss function optimized by the teacher model, F(eeg; ? eeg ), is the Weighted Cross Entropy(WCE) defined as:</p><formula xml:id="formula_0">L(x eeg , y) = T ? i=1 1/ T ? i=1 (?w yi ) * l i eeg (1)</formula><p>where w yi is the class weight based on the number of samples belonging to a particular class in the training set and</p><formula xml:id="formula_1">l i eeg = w y i * log(exp(x (i,y i ) eeg )/ K ? c=1 exp(x (i,c) eeg )<label>(2)</label></formula><p>The next process involves feature based distillation of the intermediate attention maps from trained teacher model, F(eeg; ? eeg ), to the untrained student model, F(ecg; ? ecg ). To obtain effective information distillation, we adopt the following Attention Transfer (AT) loss <ref type="bibr" target="#b11">[12]</ref>:</p><formula xml:id="formula_2">L AT = ? j?I || Q j ecg ||Q j ecg || 2 ? Q j eeg ||Q j eeg || 2 || 2<label>(3)</label></formula><p>where Q j ecg =vec(F ecg (A j ecg )) and Q j eeg =vec(F eeg (A j eeg )) represent the j-th pair of student and teacher attention maps in a vectorized form, I denote the set of teacher-student convolution layers which is selected for AT. In our framework, j iterates through the feature map across the whole architecture, distilling the attention maps from all the layers.</p><p>Subsequently, the pretrained student model F(ecg; ? ecgpre ), optimizes the sum of WCE and the response based distillation loss defined as:</p><formula xml:id="formula_3">L(x ecg , y) = (1 ? ?) * T ? i=1 1/ T ? i=1 (?w yi ) * l i ecg + ?T 2 d * l i dist (4)</formula><p>where alpha is the weight between distillation loss and classification loss, T d is the softmax temperature and</p><formula xml:id="formula_4">l i ecg = w y i * log(exp(x (i,y i ) ecg )/ K ? c=1 exp(x (i,c) ecg )<label>(5)</label></formula><formula xml:id="formula_5">l i dist = KLDiv(p(x ecg , T d ), p(x eeg , T d )) (6) p(x, T d ) = log(exp(x (i,y i ) /T d )/ K ? c=1 exp(x (i,c) /T d )<label>(7)</label></formula><p>Where KLDiv is the Kulback Leibler Divergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Architectural Details</head><p>The base architecture for both the teacher, F(eeg; ? eeg ) and the student, F(ecg; ? ecg ) is partially adapted from U-Time <ref type="bibr" target="#b2">[3]</ref>, considering three major reasons: 1) Optimized on EEG -U-Time was originally optimized for EEG based sleep staging, thereby maximizing the feature transfer from EEG to ECG. 2) Segmentation at inference time -A U-Time model trained to segment for every 30s may be used to output sleep stages at a higher frequency, i.e., every 20s, at inference time. 3) Benefit of being fully convolutional -U-Time, as opposed to other architectures, can be applied across multiple datasets which contain variations without any architecture or hyperparameter tuning.</p><p>Minor changes to the architecture were done to optimize the ECG baseline, which must be improved effectively. An additional layer increased the depth of the network in the Encoder and Decoder of the original network. Furthermore, differences in sampling rates implying different window sizes had required the modification of the spatial reduction occurring at each max-pooling layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Dataset Description</head><p>In this study, we utilize the Montreal Archive of Sleep Studies (MASS) <ref type="bibr" target="#b13">[14]</ref> dataset comprising of whole-night recordings from 200 participants [97 males (aged 42.9 ? 19.8 years) and 103 females (aged 38.3 ? 18.9 years); age range: 18-76 years]; organized according to their research and acquisition protocols into five subsets of recordings, SS1-SS5. All subjects included in this cohort are healthy controls, except for 15 included in SS1, diagnosed with Mild Cognitive Impairment (MCI) according to a neuropsychological evaluation. We used EEG and ECG data from all the subjects, i.e. 200 subjects in total. From the EEG electrodes(positioned according to the international 10-20 system), C3-A2/C4-A1 EEG electrodes and Lead 1 ECG were used for our study. The data was resampled down to 200 Hz from their respective original sampling rate to maintain uniformity. We also converted the data with 20s segment annotations to 30s segment by including 5-second data on both extremes. We modified sleep stage annotations N1, N2 into Light Sleep(L) and N3, N4 into Deep Sleep(D) for our 4-class (W-L-D-R) classification and combined N1, N2, N3, N4 into NREM(N) for our 3-class(W-N-R) classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental Procedures</head><p>The 200 subject data was split subject-wise into trainvalidation-test sets with 80:10:10 split for W-R-N and W-R-L-D staging, which ensured that no data from the same subject existed across the splits. For all the experiments, the best model was saved based on the validation metrics inspected during training and finally evaluated on the holdout test-set after completion of training. The metrics used to evaluate the model on the holdout test set were weighted F1 score and accuracy as done in <ref type="bibr" target="#b2">[3]</ref>. The weighted-F1 score calculated the metric for each class separately and averaged the metrics across classes, weighting each class by its support (tp + fn) to counter the inherent imbalance in the sleep stages. We identically conducted all the experiments for both W-L-D-R and W-N-R classification following the framework shown in <ref type="figure" target="#fig_1">Fig.1</ref> 2) Final Training (Step 2): F(ecg; ? ecgpre ) from Step 1 is further trained on distillation loss(Eq.4) for optimizing the weights of the ECG. The value of T was chosen as 1, as given in <ref type="bibr" target="#b9">[10]</ref> and alpha was empirically chosen to provide ideal weights to distillation and classification loss. The mechanism followed of the distillation methods is as follows:</p><p>1) AT+SD+CL(proposed method):</p><p>Step 1 is executed followed by step 2 with ? = 0.5 in Eq.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) AT+CL(ablation method):</head><p>Step 1 is executed followed by step 2 with ? = 0 in Eq.4, which results in training on the classification loss independently in Eq.1. 3) SD+CL(ablation method): Only step 2 is executed with ? = 0.5 in Eq.4. 1 Each configuration was trained for 150 epochs with learning rate(LR) of 10 ?3 . The model was implemented in Pytorch on an Nvidia GTX3090Ti 24GB GPU. <ref type="bibr" target="#b1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RESULTS</head><p>Given that the primary intention of this work is to establish the efficacy of KD, we compare the distillation frameworks against their respective baseline. <ref type="table">Table.</ref>I shows the performance of our models on the holdout test data. Increments in performance were observed for both weighted-F1-score and accuracy metrics for the proposed AT+SD+CL distillation method as well as ablation methods for both 3-class and 4 class sleep staging. The SD+CL model was the best performing model for 4-class, where the weighted-F1 score improved to 0.51 from 0.45 of ECG baseline (weighted-F1 improved by 14.3%, Accuracy improved by 15.6%). For 3class, AT+CL was the best performing model with weighted-F1 improved to 0.66 from 0.58 of ECG baseline( weighted-F1 improved by 13.4%, Accuracy improved by 18.1%). However, all the distillation models outperformed the ECG baseline model, which supports our idea of applying KD for ECG based sleep staging. <ref type="table">Table.</ref>II gives insight into the class-wise performances of distillation methods. The best improvement was observed for Light sleep(L) in 4-class staging where weighted-F1 improved from 0.47 to 0.61 by SD+CL ablation method. For 3class staging, the best improvement was observed for NREM  class with weighted-F1 increasing from 0.65 to 0.77 by the AT+CL ablation method. Noticeably, other classes have marginally underperformed. This is potentially due to the imprecise feature training owing to class imbalance during training. Additionally, the proposed AT+SD+CL distillation showed reasonable improvement across all classes in both 4-class and 3-class, thus relatively robust against the class imbalance during feature learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DISCUSSION</head><p>From the above-indicated results, we demonstrate the viability of the KD approach for ECG based sleep staging as the proposed model outperformed the ECG baseline significantly. However, combining response-based (SD) and feature-based (AT) distillation does not always yield improved results over using these distillation modes separately. This highlights the complexity of the interplay between these two modes of KD and suggests that combining these two distillation modes may require independent optimization. <ref type="figure">Figure.</ref>2 aids in analyzing the feature learning in the bottleneck layer, which contains the most compressed representation. The figure shows two scenarios for 4-class sleep staging; case 1, when the proposed model predicts accurately, but ECG baseline predicts incorrectly; case 2, when the KD model predicts incorrectly, but ECG baseline predicts accurately. It is evident that distilled model's features in case 1 optimal feature learning, ultimately improving performance. However, in case 2, the distilled model's feature distinctively differs from the ECG and the EEG baseline, resulting in misguided feature learning. This could be partially attributed to the class imbalance which may lead to asymmetric distillation as can be seen in <ref type="table" target="#tab_1">Table II</ref>.</p><p>Despite the promising performance improvement brought about by KD, there are few limitations in our study. Firstly, The baseline ECG model utilized in this paper can be improved by using temporal models like Long Short Term Memory networks (LSTM) which capture sparsely distributed features over time. Furthermore, using additional unobtrusive modalities along with ECG have been shown to enhance sleep staging. Previous works <ref type="bibr" target="#b7">[8]</ref>[5] which achieved notable performance on ECG based sleep staging have been trained on an extensively large dataset (&gt;4000 records), whereas our study used a relatively compact dataset. Future work would involve translating the benefits of KD to multiple DL architectures, ultimately improving overall accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>We conclude this study with the following contributions which we believe broadens the current knowledge in ECG based sleep staging. We validate the potency of a KD framework for performance improvement of ECG in sleep staging. We analyze the individual components of the KD framework and subsequently dissect the features in the bottleneck layer to understand the reasons for improved performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>), Indian Institute of Technology (IIT-M), India sricharanv@htic.iitm.ac.in 2 is with Department of Electrical Engineering, Indian Institute of Technology, Madras (IITM), India period in Non-REM stages; N2, an intermediate stage; N3, a deep sleep stage; and REM Rapid Eye Movement stage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Proposed Knowledge Distillation framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Bottleneck layer feature for case1:KD model correct,ECG base incorrect; case2:ECG baseline correct, KD model incorrect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>. Baselines were trained by optimizing on WCE loss as in Eq.1 and the KD experiment optimizing the loss in Eq.4. Additionally, we conducted two experiments to understand the individual components of our proposed model. The primary components of all the experiments involve two major steps:</figDesc><table /><note>1) Feature Training (Step 1): F(ecg; ? ecg ) optimizes the loss (Eq.3) between EEG and ECG features with EEG weights being frozen. This trains the feature maps in the ECG model to mimic the feature maps of the EEG model.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I PERFORMANCE</head><label>I</label><figDesc>OF KD AND ITS COMPONENTS</figDesc><table><row><cell>No. of classes</cell><cell>Experiments</cell><cell cols="2">weighted F1 Accuracy</cell></row><row><cell></cell><cell>EEG Baseline</cell><cell>0.85</cell><cell>0.85</cell></row><row><cell></cell><cell>ECG Baseline</cell><cell>0.45</cell><cell>0.44</cell></row><row><cell>W-R-L-D</cell><cell>SD + CL</cell><cell>0.51</cell><cell>0.51</cell></row><row><cell></cell><cell>AT + CL</cell><cell>0.50</cell><cell>0.50</cell></row><row><cell></cell><cell>AT + SD + CL</cell><cell>0.50</cell><cell>0.49</cell></row><row><cell></cell><cell>EEG Baseline</cell><cell>0.90</cell><cell>0.90</cell></row><row><cell></cell><cell>ECG Baseline</cell><cell>0.58</cell><cell>0.56</cell></row><row><cell>W-R-N</cell><cell>SD + CL</cell><cell>0.61</cell><cell>0.60</cell></row><row><cell></cell><cell>AT + CL</cell><cell>0.66</cell><cell>0.66</cell></row><row><cell></cell><cell>AT + SD + CL</cell><cell>0.64</cell><cell>0.63</cell></row><row><cell cols="4">1 AT: Attention Transfer; SD: Softmax Distillation; CL: Classification</cell></row><row><cell>Loss</cell><cell></cell><cell></cell><cell></cell></row></table><note>2 Code will be provided on acceptance</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II</head><label>II</label><figDesc></figDesc><table><row><cell></cell><cell cols="5">KD METHODS CLASS WISE RESULTS</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">4 class F1 score</cell><cell></cell><cell cols="3">3 class F1 score</cell></row><row><cell></cell><cell>W</cell><cell>L</cell><cell>D</cell><cell>R</cell><cell>W</cell><cell>N</cell><cell>R</cell></row><row><cell>EEG Baseline</cell><cell cols="4">0.89 0.86 0.81 0.82</cell><cell cols="3">0.89 0.93 0.80</cell></row><row><cell>ECG Baseline</cell><cell cols="4">0.57 0.47 0.30 0.40</cell><cell cols="3">0.51 0.65 0.40</cell></row><row><cell>SD + CL</cell><cell>0.54</cell><cell>0.61</cell><cell cols="2">0.31 0.35</cell><cell cols="3">0.53 0.70 0.34</cell></row><row><cell>AT + CL</cell><cell cols="4">0.54 0.57 0.34 0.40</cell><cell>0.52</cell><cell cols="2">0.77 0.37</cell></row><row><cell cols="5">AT + SD + CL 0.57 0.56 0.29 0.41</cell><cell cols="3">0.52 0.73 0.39</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The aasm manual for the scoring of sleep and associated events: Rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Iber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Terminology and Technical Specification</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A manual for standardized terminology, techniques and scoring system for sleep stages in human subjects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rechtschaffen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
	<note>Brain information service</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">U-time: A fully convolutional network for time series segmentation applied to sleep staging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perslev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Darkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Jennum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4415" to="4426" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Correlation of sleep eeg frequency bands and heart rate variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Abdullah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cosic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cvetkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="5014" to="5017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep learning in the cross-time frequency domain for sleep staging from a single-lead electrocardiogram</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Shashikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nemati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Clifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physiological measurement</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">124005</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sleep stage classification with ecg and respiratory effort</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haakma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Aarts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rolink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physiological measurement</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">2027</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sleep stage classification from heart-rate variability using long short-term memory neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cerny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Anderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Aarts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep learning for automated sleep staging using instantaneous heart rate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shoeb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stephens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kharbouch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Shimol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Burkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghoreyshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ digital medicine</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sleep staging from electrocardiography and respiration with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ganglberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Panneerselvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Leone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Quadri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goparaju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Tesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Akeju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sleep</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">306</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6550</idno>
		<title level="m">Fitnets: Hints for thin deep nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Knowledge distillation: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Maybank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1789" to="1819" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Montreal archive of sleep studies: an open-access resource for instrument benchmarking and exploratory research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O&amp;apos;reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carrier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of sleep research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="628" to="635" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
