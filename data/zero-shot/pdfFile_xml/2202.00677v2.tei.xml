<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AN EMBARRASSINGLY SIMPLE CONSISTENCY REGULARIZATION METHOD FOR SEMI-SUPERVISED MEDICAL IMAGE SEGMENTATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hritam</forename><surname>Basak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engg</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Bhattacharya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engg</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engg</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rukhshanda</forename><surname>Hussain</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engg</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engg</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agniv</forename><surname>Chatterjee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engg</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AN EMBARRASSINGLY SIMPLE CONSISTENCY REGULARIZATION METHOD FOR SEMI-SUPERVISED MEDICAL IMAGE SEGMENTATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T22:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Semi-supervised Learning</term>
					<term>Medical Im- age Segmentation</term>
					<term>Interpolation</term>
					<term>Consistency Regularization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The scarcity of pixel-level annotation is a prevalent problem in medical image segmentation tasks. In this paper, we introduce a novel regularization strategy involving interpolationbased mixing for semi-supervised medical image segmentation. The proposed method is a new consistency regularization strategy that encourages segmentation of interpolation of two unlabelled data to be consistent with the interpolation of segmentation maps of those data. This method represents a specific type of data-adaptive regularization paradigm which aids to minimize the overfitting of labelled data under high confidence values. The proposed method is advantageous over adversarial and generative models as it requires no additional computation. Upon evaluation on two publicly available MRI datasets: ACDC and MMWHS, experimental results demonstrate the superiority of the proposed method in comparison to existing semi-supervised models. Code is available at: https://github.com/hritam-98/ICT-MedSeg</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Supervised medical image segmentation is a widely explored problem in computer vision, achieving exponential growth recently. These methods mostly rely upon deep learning, requiring large-scale pixel-wise annotation data. However, acquiring huge amounts of labelled medical data is tedious and expensive, thus methods alleviating this requirement are highly expedient. Semi-Supervised Learning (SSL) is a promising direction in this regard, requiring only a few labelled data and compensating for the large portion of unlabelled data by generating pseudo labels. Recently, SSL-based methods have been widely recognized for their superior performance in medical image segmentation. They not only eliminate the necessity of large-scale annotations but also produce accurate segmentation results that are very close to those obtained from supervised models.</p><p>Recently, Bai et al. <ref type="bibr" target="#b0">[1]</ref> proposed an iterative SSL framework where pseudo labels are generated after every iteration ? Equal contribution; * Corresponding Author and refined using conditional random field (CRF). Adversarial learning is another popular method for utilizing unlabelled data. Zhang et al. <ref type="bibr" target="#b1">[2]</ref> proposes a deep adversarial network (DAN) that encourages the segmentation of unlabelled data to be similar to those of labelled data. The state-of-the-art SSL segmentation model mean-teacher network is recently extended by Yu et al. <ref type="bibr" target="#b2">[3]</ref> for uncertainty-aware left atrium segmentation.</p><p>Consistency regularization is another plausible solution in this direction, that encourages realistic perturbations of an unlabelled image to produce consistent segmentation maps. For example, Bortsova et al. <ref type="bibr" target="#b3">[4]</ref> proposes a transformationconsistent segmentation network, capable of exploring the equivariance of elastic perturbations for precise lung X-ray segmentation and Li et al. <ref type="bibr" target="#b4">[5]</ref> proposes a semi-supervised segmentation framework using transformation consistency, encouraging consistent predictions of the network-in-training for different perturbation of the same input. Unlike these methods, which rely upon the low-density region assumption, our proposed method chooses perturbation directed towards another unlabelled sample, thereby reducing the necessity of expensive gradient calculation.</p><p>On the other hand, interpolation-based regularizers have been achieving state-of-the-art performance in various tasks and across multiple architectures. Recently, this idea has been extended to an unsupervised setting by Berthelot et al. <ref type="bibr" target="#b5">[6]</ref> where the authors propose that utilizing realism of the latent space interpolation from autoencoder can improve model learning. Driven by this speculation and the aforementioned success of consistency regularization in SSL methods, in this paper we investigate an interpolation-based mixing technique in a semi-supervised setting and its utility in medical image segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">METHODOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Consistency Regularization with Interpolation</head><p>Consistency Regularization has been used in existing literature as a means to enhance the robustness of a network pipeline by enforcing the network against various perturbations on the unlabelled data, to increase the generalizability of these new data points. Among them, the most effective perturbation would be in the adversarial direction -in the direction almost perpendicular to the decision boundary between the positive and negative examples, i.e., the direction in which the network is most liable to misclassify the pixels. However, most existing literature incorporates perturbations that may or may not be in the adversarial direction, and thus, results in loss of generalizability. Some other methods do perturb the input in the adversarial direction but require a large amount of unlabelled data and thus, might not be feasible in the biomedical domain.</p><p>Thus, we have proposed a pixel-wise data perturbation strategy as consistency regularization in our work, which operates as described. The network is trained in such a way so as to ensure stable and accurate segmentation of image points interpolated from existing points. Considering two unlabelled image data-points u 1 and u 2 , we interpolate another unlabelled image point M ? (u 1 , u 2 ), where M ? (u 1 , u 2 ) = ?u 1 + (1 ? ?)u 2 , for some hyperparameter ?. Now, consistency regularization is applied between the output of the interpolated image data-point f (M ? (u 1 , u 2 ) and the interpolation of the outputs of the original unlabelled</p><formula xml:id="formula_0">points M ? (f (u 1 ), f (u 2 )) = ?f (u 1 ) + (1 ? ?)f (u 2 )</formula><p>. This exploits the fact that the network learns to predict a pixel-level segmentation mask of the input images, and further, consistency is maintained between the outputs of the interpolated inputs and the interpolated outputs of the original inputs.</p><p>Thus, the unlabelled samples in the datasets are used to generate the new interpolated images and the corresponding pseudo-labels. It takes two unlabelled images as input and returns the interpolated image and the corresponding pseudolabel, which is used by the network pipeline. Therefore, the Consistency Regularization technique can be summarized as:</p><formula xml:id="formula_1">M ? (f ? (u 1 ), f ? (u 2 )) f ? (M ? (u 1 , u 2 ))<label>(1)</label></formula><p>This data mixing technique would help the model learn more robust features improving the semi-supervised learning on subsequent (target) tasks since random perturbations do not guarantee adversarial perturbation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Objective Function</head><formula xml:id="formula_2">Consider labelled samples (x i , y i ) ? L l from joint distribu- tion P (X, Y ) and unlabelled samples (u i , u j ) ? L ul from borderline distribution P (X) = P (X,Y ) P (X|Y ) .</formula><p>Using SGD for every iteration t, the encoder-decoder parameter ? is updated minimising the objective function:</p><formula xml:id="formula_3">L = L CE + r(t).L U<label>(2)</label></formula><p>where L CE is the cross entropy loss applied over the labelled data L l and L U is the interpolation consistency regularization loss applied over the unlabelled data L ul , r(t) is the ramp function adjusting the weight of L U after every iteration. L U is calculated over (u i , u j ) of sampled minibatches and the pseudo labels? i = F ? (u i ) and? j = F ? (u j ) (? is the exponential moving average of ?). Next, interpolation u m = M ? (u i , u j ) and model prediction? m = F ? (u m ) are computed updating ? to bring? m closer to the interpolation of the pseudo labels, M ? (? i ,? j ). The deviation in? m and M ? (? i ,? j ) is penalised using the mean squared loss. Therefore, L U can be expressed as:</p><formula xml:id="formula_4">L U = E ui,uj ?L ul l(F ? (M ? (u i , u j )), M ? (F ? (u i ), F ? (u j )))<label>(3)</label></formula><p>Our overall approach is depicted in <ref type="figure" target="#fig_0">Figure 1</ref> and algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTS AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset and Experimental Setup</head><p>The experiments for evaluating the model performance was carried out on two public datasets: the ACDC 2017 <ref type="bibr" target="#b9">[10]</ref> dataset consisting of 100 short-axis cardiac MRI volumes with expert annotations for three structures: left and right ventricle and myocardium and the MMWHS <ref type="bibr" target="#b10">[11]</ref> dataset, hosted in MICCAI 2017, consisting of 20 cardiac MRI samples with expert annotations for seven structures: left and right ventricle, left and right atrium, pulmonary artery, myocardium, and ascending aorta. The datasets were split into train, validation, and test sets, where 2 volumes were considered for validation purposes in both the datasets. The test set consists of 20 and 5 volumes for ACDC 2017 and MMWHS, respectively. The rest of the data was used for training. To study the segmentation performance with respect to the labelled data, we have experimented with 1.25%, 2.5%, and 10% labelled volumes for ACDC 2017 and 10%, 20%, and 40% labelled volumes for the MMWHS dataset, following the existing works in literature <ref type="bibr" target="#b8">[9]</ref>. We have used ResNet-50 as the encoder backbone of our architecture, using an ADAM optimizer with an initial learning rate of 1e-5. For </p><formula xml:id="formula_5">= ?u1 + (1 ? ?)u2 while (t ? T) do Sample labelled mini-batch {(xp, yp)} P p=1 ? L l Supervised CE loss LCE ({(f ? (xp), yp)} P p=1 ) Sample two unlabelled batches {(ui, uj)} U k=1 ? L ul Generate pseudo-labels {?i,?j} U k=1 = {f ? (ui, uj)} U k=1</formula><p>Interpolation um = M?(ui, uj), ym = M?(?i,?j)</p><formula xml:id="formula_6">Interpolated pseudo-label ?m = f ? (um) Unsupervised loss LU = M SE({ym,?m} U m=1 ) Overall model loss L = LCE + r(t)LU Gradient computation G ? ?? L ? ? ? Update parameter ? ?? (1 ? ?)? + ?? ? ?? step(G ? , ?) end while return ?</formula><p>evaluation purposes, we have used three widely used metrics: Dice Similarity Score (DSC), Average Symmetric Distance (ASD), and Hausdorff Distance (HD). Average of all the metric scores over all the classes and reported in this paper. Mixing parameter ? was set experimentally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Results on the ACDC 2017 Dataset</head><p>We achieve DSC of 73.56%, 79.05%, and 89.80% on the ACDC 2017 dataset for 1.25%, 2.5%, and 10% labelled volumes respectively. For the same set of experiments, ASD of 1.981, 1.546, and 1.229 and HD of 6.719, 5.820, and 4.473 were obtained respectively. The merits of the model can be better appreciated by referring to the comparison with other state-of-the-art methods, shown in <ref type="table" target="#tab_0">Table 1</ref>, where we have compared our obtained results using 10% labelled volumes only. A higher Dice score at a lower percentage of labelled data indicates that the model is capable of generalizing the data efficiently by making use of a lesser number of labelled samples. As seen in the table, our approach uses a low number of labelled samples and produces the best results in terms of DSC and HD, whereas methods like <ref type="bibr" target="#b1">[2]</ref> use double the amount of labelled data, yet achieve inferior performance as compared to our results, proving the efficiency and robustness of our model. Only Peng et al. <ref type="bibr" target="#b6">[7]</ref> uses a lower number of labelled data, but produces poorer results as well. Our method produces a reasonably better result by making use of only 10% of the labelled data available for training.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Results on the MMWHS Dataset</head><p>Upon evaluation on the MMWHS dataset, DSC of 66.86%, 71.24%, and 79.83% have been achieved using 10%, 20%, and 40% labelled volumes, respectively. ASD scores of 2.671, 2.207, and 1.819 and HD values of 5.073, 4.288, and 3.047 were achieved for these experiments, respectively. The efficacy of the proposed technique can be verified by comparison with existing state-of-the-art techniques as shown in <ref type="table" target="#tab_0">Table 1</ref>, where we have compared our results obtained using 40% annotated data only, yet achieving superior performance as compared to methods with 50% labelled data. The results were reported from the papers directly. All the other parameters were the same as those methods, to maintain fair comparison. Peng et al. <ref type="bibr" target="#b6">[7]</ref> use the least number of labelled samples in their method, but they have produced vastly substandard results. Whereas, our method obtains better results as compared to most state-of-the-art methods, by using 40% labelled data in the entire training set. The results achieved by Zhang et al. <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> are very close to ours, however, they have used a larger percentage of labelled data for training. <ref type="figure" target="#fig_2">Figure 2</ref> represents the results obtained using different percentages of labelled data from the training set. It is obvious that employing more labelled data while training will produce  <ref type="figure" target="#fig_3">Figure 3</ref> offers a visual comparison of the proposed method with a few of the state-of-theart methods existing in contemporary literature. A careful inspection of the image shows that our method generates labels that are the closest to the ground truth (GT) when compared to the other methods. ASD scores were not reported in most of the methods in the literature for both the datasets and hence not considered for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION AND FUTURE WORK</head><p>Recently, machine learning has had a transformative impact on various applications, but its effectiveness is impacted due to the lack of labelled data, especially in medical imaging, where availing of those annotations is extremely difficult.</p><p>Here we have tried to address this shortcoming by developing a semi-supervised learning strategy that encourages consistency regularization by interpolation. It is advantageous over the previous SSL models in multiple aspects: unlike adversarial perturbations or generative models, it requires almost no additional computations. Moreover, our proposed model outperforms several state-of-the-art SSL methods by utilizing fewer annotations than these methods. In future, we plan to extend the work by interpolating at the hidden representations to boost the performance and evaluate the performance in general computer vision problems to assess its robustness. We further plan to extend the experimentation by adding more variability between the two interpolating images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">COMPLIANCE WITH ETHICAL STANDARDS</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Overall framework of our proposed architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Input: L l : Distribution of labelled samples; L ul : Distribution of unlabelled samples Define: f ? (?): Segmentation network with trainable parameter ? f ? (?) : Segmentation network with parameter ?exponential moving average of ? T : Total number of iterations; r(t): ramp function ?: exponential moving average change rate M?(u1, u2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Comparison of results obtained by using different percentages of labelled data in training set on ACDC 2017 (left) and MMWHS (right) dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Comparative image of the segmentation masks of our model, along with the other semi-supervised models</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of the proposed method with State-of-the-art methods on the ACDC 2017 Dataset and MMWHS dataset.</figDesc><table><row><cell>Methods</cell><cell cols="3">ACDC 2017 labelled data (as % of the training set) DSC(%) HD (mm)</cell><cell cols="3">MMWHS (as % of the training set) labelled data DSC(%) HD(mm)</cell></row><row><cell>Peng et al.[7]</cell><cell>5%</cell><cell>85.76</cell><cell>-</cell><cell>13.30%</cell><cell>55.75</cell><cell>-</cell></row><row><cell>Mix-Up[8]</cell><cell>10%</cell><cell>86.3</cell><cell>-</cell><cell>50%</cell><cell>79.6</cell><cell>-</cell></row><row><cell>Chaitanya et al[9]</cell><cell>10%</cell><cell>88.6</cell><cell>-</cell><cell>50%</cell><cell>79.4</cell><cell>-</cell></row><row><cell>Adversarial Training[2]</cell><cell>20%</cell><cell>79.1</cell><cell>5.16</cell><cell>50%</cell><cell>77.9</cell><cell>3.20</cell></row><row><cell>Ours</cell><cell>10%</cell><cell>89.8</cell><cell>4.47</cell><cell>40%</cell><cell>79.83</cell><cell>3.05</cell></row><row><cell cols="3">superior performance. However, we can observe from the fig-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">ure that our model can produce results very close to the super-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">vised method (that uses 100% labelled train data) by employ-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">ing only a small percentage (10% for ACDC 2017 and 40%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>for MMWHS) of annotations.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semi-supervised learning for networkbased cardiac mr image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Oktay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sinclair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rajchl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tarroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep adversarial networks for biomedical image segmentation utilizing unannotated images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fredericksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="408" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Uncertaintyaware self-ensembling model for semi-supervised 3d left atrium segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="605" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-supervised medical image segmentation via learning consistency under transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bortsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dubost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hogeweg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Katramados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="810" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Transformation-consistent self-ensembling model for semisupervised medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="523" to="534" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Understanding and improving interpolation in autoencoders via an adversarial regularizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.07543</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Boosting semi-supervised image segmentation with global and local mutual information regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jizong</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pedersoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Desrosiers</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.04813</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">D</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Contrastive learning of global and local features for medical image segmentation with limited annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Erdil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep learning techniques for automatic mri cardiac multi-structures segmentation and diagnosis: Is the problem solved?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lalande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cervenansky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2514" to="2525" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-scale patch and multimodality atlases for whole heart segmentation of mri</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
