<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Long-Tailed Recognition Using Class-Balanced Experts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Sharma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Informatics</orgName>
								<orgName type="department" key="dep2">Saarland Informatics Campus</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Informatics</orgName>
								<orgName type="department" key="dep2">Saarland Informatics Campus</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">CISPA Helmholtz Center for Information Security</orgName>
								<orgName type="department" key="dep2">Saarland Informatics Campus</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
							<email>schiele@mpi-inf.mpg.defritz@cispa.saarland</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Informatics</orgName>
								<orgName type="department" key="dep2">Saarland Informatics Campus</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Long-Tailed Recognition Using Class-Balanced Experts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning enables impressive performance in image recognition using large-scale artificially-balanced datasets. However, real-world datasets exhibit highly class-imbalanced distributions, yielding two main challenges: relative imbalance amongst the classes and data scarcity for mediumshot or fewshot classes. In this work, we address the problem of long-tailed recognition wherein the training set is highly imbalanced and the test set is kept balanced. Differently from existing paradigms relying on data-resampling, cost-sensitive learning, online hard example mining, loss objective reshaping, and/or memory-based modeling, we propose an ensemble of class-balanced experts that combines the strength of diverse classifiers. Our ensemble of class-balanced experts reaches results close to state-of-the-art and an extended ensemble establishes a new state-of-the-art on two benchmarks for long-tailed recognition. We conduct extensive experiments to analyse the performance of the ensembles, and discover that in modern large-scale datasets, relative imbalance is a harder problem than data scarcity. The training and evaluation code is available at https://github.com/ssfootball04/ class-balanced-experts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the past decades, deep learning has boosted success in image recognition to a new level <ref type="bibr" target="#b13">[14]</ref>. The availability of large-scale datasets with thousands of images in each class <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b46">47]</ref> has been a major factor in this revolution. However, these datasets are manually curated and artificially balanced, as opposed to real-world datasets that exhibit a highly skewed and class-imbalanced distribution in a longtailed shape: a few common classes and many more rare classes. To address this practical challenge, in this work, we focus on the problem of long-tailed recognition, wherein datasets exhibit a natural power-law distribution <ref type="bibr" target="#b31">[32]</ref>, allowing us to assess model performance on four folds: Manyshot classes (? 100 samples), Mediumshot classes (20 ? 100 samples), Fewshot classes (&lt; 20 samples), and All classes. Training data follows a highly class-imbalanced distribution, and testing data is balanced so that equally good performance over all classes is crucial <ref type="bibr" target="#b23">[24]</ref>.</p><p>The two main challenges for a long-tailed classification model are relative imbalance amongst the classes, and data scarcity or unobservable data modes <ref type="bibr" target="#b12">[13]</ref>. Existing techniques for imbalanced classification have focused on data re-sampling arXiv:2004.03706v2 [cs.CV] 19 Oct 2020 <ref type="figure">Fig. 1</ref>: Our pipeline for long-tailed recognition: an ensemble of experts trained on class-balanced subsets of Manyshot, Mediumshot, and Fewshot data. We transfer knowledge from Manyshot to Mediumshot and Fewshot classes by initialising experts with a Baseline model trained on all the data. Expert models classify samples outside their subset as out-of-distribution and output partial posteriors that are fused into a full posterior to obtain the final prediction. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13]</ref> and cost-sensitive learning <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b2">3]</ref> to re-weigh the loss objective or counter relative imbalance, while techniques for fewshot learning have employed data augmentation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref>, classifier weight prediction <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b27">28]</ref>, or prototype-based non-parametric methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b23">24]</ref> to address data scarcity.</p><p>Unlike the aforementioned paradigms, we instead revisit the classic approach of ensemble of experts <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b16">17]</ref> and adapt it to long-tailed recognition. We first decompose the imbalanced classification problem into balanced classification problems by splitting the long-tailed training classes into balanced subsets. Then we train an expert on each balanced subset, so-called Manyshot, Mediumshot, or Fewshot data, with out-of-distribution detection for samples outside an expert's class-balanced subset. This explicitly tackles the issue of relative imbalance, and prevents competition between Manyshot and Fewshot classes during training.</p><p>Further, to use all available data for learning feature representations and to transfer knowledge from Manyshot to Mediumshot and Fewshot classes, we initialise the feature extractor of each expert using a Baseline model trained on the entire dataset. This simple and effective approach reaches close to stateof-the-art results without involving more complex models or sophisticated loss objectives. Moreover, the decomposition into class-balanced subsets allows us to analyse the upper bound on performance in each data regime. Specifically, our experiments with an Oracle upper bound allow us to bring Fewshot and Mediumshot accuracy on par with Manyshot accuracy, revealing that in modern large-scale datasets the data scarcity for Mediumshot and Fewshot classes can be effectively handled using knowledge transfer from Manyshot classes. Therefore, relative imbalance is a more severe problem.</p><p>We also leverage the flexibility and modularity of the ensemble framework to create larger and more diverse ensembles using existing solutions for long-tailed recognition. In particular, we involve the following methods in the solution space: (1) a Baseline model without any bells or whistles; (2) feature learning followed by classifier finetuning with uniform class sampling <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b40">41]</ref>; (3) data augmentation using feature generation networks <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b40">41]</ref>; and (4) knowledge transfer through prototype-based memory representation <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b23">24]</ref>. The extended ensemble consisting of all these models outperforms the current state-of-the-art on two benchmark datasets by a significant margin.</p><p>Our contributions in this work can be summarised as follows: <ref type="bibr" target="#b0">(1)</ref> We propose an effective and modular ensemble of experts framework for long-tailed recognition that decomposes the imbalanced classification problem into multiple balanced classification problems. Our framework utilises all available data for learning feature representations and transfers this knowledge from Manyshot to Mediumshot and Fewshot classes. The results of our ensemble of class-balanced experts are close to the state-of-the-art performance on two longtailed benchmark datasets, ImageNet-LT and Places-LT <ref type="bibr" target="#b23">[24]</ref>.</p><p>(2) We enrich our ensemble with a diverse set of existing solutions for longtailed recognition, namely data re-sampling, data augmentation using synthesised features, and prototype-based classification, and establish a new state-ofthe-art for long-tailed recognition.</p><p>(3) We analyse the upper bound performance of our approach in the following manner: we assume Oracle access to the experts containing the ground truth classes of the test samples in their class-balanced subsets. We discover that data scarcity for rare classes is not a severe issue in modern large-scale datasets. Rather, relative imbalance is the main bottleneck.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Imbalanced classification and long-tailed recognition. There is a long history of research in imbalanced classification <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b31">32]</ref>, in binary and more generally multi-class classification problems. Classic problems that naturally encounter class imbalance are face attribute detection <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b17">18]</ref>, object detection <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b22">23]</ref>, and image defect detection <ref type="bibr" target="#b42">[43]</ref>. Prior work on image classification <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref> deals with long-tailed datasets, but only recently a benchmark for the problem on the ImageNet and Places dataset was proposed by <ref type="bibr" target="#b23">[24]</ref>. They also propose splits for open-world classification, but in this work we only consider long-tailed recognition and we report the performance of our methods on the proposed ImageNet-LT and Places-LT. We summarise below the existing solutions for imbalanced classification and long-tailed recognition. Data re-sampling heuristics and cost-sensitive learning. These are classic ways to tackle long-tailed recognition. A more balanced data distribution is achieved by randomly over-sampling fewshot classes or randomly under-sampling of manyshot classes <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13]</ref>. However, over-sampling suffers from overfitting on fewshot classes while under-sampling cannot take full benefit of available data for generalization on manyshot classes. Other work has focused on hard example mining <ref type="bibr" target="#b4">[5]</ref> or cost-sensitive learning <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b2">3]</ref> reasoned from class frequencies.</p><p>Instead, to augment our ensemble of class-balanced experts, we use a uniform class sampling procedure in mini-batch training for finetuning the classifier after a representation learning phase, which has the advantage that all data is used to learn representations while decision boundary learning takes class imbalance into account. This has also been employed before in related zero-shot learning <ref type="bibr" target="#b40">[41]</ref> and fewshot learning <ref type="bibr" target="#b30">[31]</ref> work. Synthetic data augmentation. This is a classic technique that synthesises features for minority classes based on feature space similarities <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12]</ref>. More recently, generative models have been employed in zero-shot <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref> and fewshot learning <ref type="bibr" target="#b35">[36]</ref> literature to automatically generate images or feature embeddings for data-starved classes. In this work, we use the f-VAEGAN-D2 model from <ref type="bibr" target="#b40">[41]</ref> that generates feature embeddings conditioned on available class embeddings using a VAE-GAN model, and integrate it into our ensemble of experts framework. Prototype-based models and knowledge transfer. Prototype-based networks <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33]</ref> maintain a memory module for all the classes such that each class is equally represented regardless of sample frequency. In particular, Liu et al. <ref type="bibr" target="#b23">[24]</ref> learn prototype-based features on-the-fly to effectively transfer knowledge from manyshot classes to fewshot classes. We integrate their model into our ensemble due to its ability to perform consistently well across the entire class spectrum. Transfer learning <ref type="bibr" target="#b26">[27]</ref> addresses data imbalance by transferring abundant features of manyshot classes to those of fewshot classes. Recent work includes transferring the intra-class variance <ref type="bibr" target="#b41">[42]</ref> and transferring semantic deep features <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b23">24]</ref>. We instead transfer knowledge across the dataset by initialising our expert models with a baseline model pre-trained on the entire dataset. Ensemble learning. Ensemble methods are a well-studied topic in machine learning literature. In particular, a variety of ensemble-based methods using boosting <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b33">34]</ref>, bagging <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20]</ref>, stacking <ref type="bibr" target="#b34">[35]</ref>, and evolutionary selection of classifiers <ref type="bibr" target="#b20">[21]</ref> have been employed for imbalanced datasets. However, they all consider ensembles with the same kind of model and task. Our approach is related to the work of Hinton et al. <ref type="bibr" target="#b16">[17]</ref> who train an ensemble of experts over disjoint semantically-close subsets of classes, thereby each expert deals with a different classification task. We instead train our experts on subsets of classes that are intrinsically balanced to counter relative imbalance and prevent competition between manyshot and fewshot classes during training. Moreover, we integrate a diverse set of models for long-tailed recognition into our ensemble of experts. Out-of-distribution detection and confidence calibration. Modern neural networks can function both as classification models and detectors for out-ofdistribution examples <ref type="bibr" target="#b14">[15]</ref>. Recent works focus on adding small perturbations in input space and applying temperature scaling <ref type="bibr" target="#b21">[22]</ref>, and adding loss terms to push out-of-distribution examples towards uniform confidence <ref type="bibr" target="#b15">[16]</ref>. Related work on confidence calibration tries to fix overconfident predictions on in-distribution data using temperature scaling <ref type="bibr" target="#b9">[10]</ref>. We instead focus on learning an ensemble of class-balanced experts for long-tailed recognition, where the problem of out-ofdistribution detection arises when dealing with samples from outside an expert's subset, and jointly calibrate experts' confidences to fuse their posteriors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We propose an ensemble of experts for solving the problem of long-tailed recognition. We split the long-tailed dataset into (approximately) class-balanced subsets, and a separate classification model, or expert, is trained for each subset. Expert models identify samples belonging to classes outside their subset as outof-distribution; therefore we train them to produce low confidence predictions on these samples. During inference, each classification model yields a partial posterior distribution for test samples, the ensemble of which is fused to form a complete posterior distribution. Our entire pipeline is depicted in <ref type="figure">Fig. 1</ref>. The modularity of our framework allows us to explictly address the problem of relative imbalance, and moreover analyse the upper bounds for performance in each data regime using Oracle access to experts containing ground truth classes of test samples in their class-balanced subsets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Long-tailed recognition using class-balanced experts</head><p>The task of long-tailed visual recognition is as follows: given class-imbalanced</p><formula xml:id="formula_0">training set D Train = {(x i , y i )} n i=1</formula><p>and class-balanced validation set D Val and class-balanced test set D Test , the objective is to maximise test accuracy on four folds, Manyshot classes (? 100 samples), Mediumshot classes (20 ? 100 samples), Fewshot classes (&lt; 20 samples), and All classes. This is a hard problem, since any high performing model must deal with the two problems of relative imbalance and data scarcity. Relative imbalance leads to biased classification boundaries wherein accuracy on fewshot samples is compromised in favor of manyshot samples that dominate the training objective. Data scarcity leads to representations that do not model unobserved data modes and is more severe. To tackle both these issues, we sort the class-imbalanced training set D Train according to class frequencies and partition it into contiguous classbalanced subsets D Manyshot , D Mediumshot and D Fewshot . This is visualised in <ref type="figure" target="#fig_0">Fig. 2</ref>. For each subset, we train separate classification models or experts, that are initialised using a model pre-trained on the entire dataset. Consequently we obtain the expert models E Manyshot , E Mediumshot and E Fewshot corresponding to each class-balanced subset. The feature extractor part of each expert model E is initialised using the Baseline model pre-trained on the entire training set D Train . This enables knowledge transfer from Manyshot to Mediumshot and Fewshot classes. In this work, the expert models E and the Baseline model are deep fully convolutional neural networks with softmax classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Out-of-distribution detection for experts</head><p>The expert models identify samples from classes outside their class-balanced subset as out-of-distribution or OOD for short, therefore we train them using an out-of-distribution detection strategy. Observe that this is a hard problem, since here OOD examples come from within the same distribution albeit from extra classes within the dataset, as opposed to standard out-of-distribution detection wherein OOD samples come from an entirely different dataset.</p><p>Training with reject class. We add a reject class to the softmax classifier of each expert. For instance, E Manyshot treats samples from D Mediumshot ? D Fewshot as a single reject class. This introduces imbalance since the reject class has far more samples than any other class, therefore we undersample reject class samples appropriately during training. We correct for the statistical bias by incrementing its logit score by the log of the undersampling ratio. We note that samples in the reject class have very high variance and are therefore hard to fit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fusing expert posteriors</head><p>We consider various baseline strategies and propose a novel joint calibration module to fuse expert posteriors E (x) into a complete posterior distribution. The final prediction and confidence scores are taken from this posterior, denoted as q(x), using the argmax operation.</p><p>KL-divergence minimisation. We find the full posterior distribution for each sample, by minimising its KL-divergence with all the partial posterior distributions predicted by the experts <ref type="bibr" target="#b16">[17]</ref>, that is,</p><formula xml:id="formula_1">min q(x) E KL(E (x)||q(x))</formula><p>where q(x) is parameterised using logits z and a softmax function as q(x) = sof tmax(z). Note that probabilities corresponding to out-of-distribution classes for the expert E are summed up into one probability score in q(x) to align the two distributions.</p><p>Soft-voting. We find the full posterior by summing up the partial posteriors directly and normalising the sum to 1,</p><formula xml:id="formula_2">q(x) = E g(E (x)) E 1</formula><p>Here g(.) is a function that converts an expert's partial posterior into a full posterior. Since experts are trained with a reject class, g(.) averages reject class probability score across out-of-distribution classes corresponding to expert E .</p><p>Expert selection. We train a 3-way classifier on the validation set, taking the partial posterior vectors E (x) of each expert E as input, to predict for a sample x the expert model E that contain's the sample's ground truth class in its class-balanced subset. Thus, for instance, the classifier learns to predict that a manyshot sample lies in the class-balanced subset of the manyshot expert E Manyshot . The full posterior q(x) is then given by g(E (x)) for the predicted expert E , where g(.) is defined similarly as before.</p><p>Model stacking. We train a single layer linear softmax classifier to predict the full posterior q(x) from the partial posterior vectors E (x) of each expert E . The vectors E (x) are concatenated to form a feature embedding for the softmax classifier which is trained by optimising the cross entropy loss on the validation set. This is a standard way for ensemble fusion known as model stacking <ref type="bibr" target="#b38">[39]</ref>.</p><p>Joint calibration. We calibrate the partial posteriors E (x) by learning scaling and shift parameters before adding up the posteriors similarly to soft-voting,</p><formula xml:id="formula_3">q(x) = E g(? SM (w E z E (x) + b E )) Z</formula><p>where ? SM denotes the softmax operation, w E and b E are scale and shift parameters respectively, z E (x) denotes the logit scores of expert E for sample x, denotes elementwise multiplication of two vectors, Z is a normalisation factor, and g(.) is defined as before. We learn scale and shift parameters by minimising the cross entropy loss on the validation set. This module effectively learns the right alignment for experts' partial posteriors before performing soft-voting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Datasets. We use the object-centric ImageNet-LT and scene-centric Places-LT datasets for long-tailed recognition, released by Liu et al. <ref type="bibr" target="#b23">[24]</ref>. The training set statistics are depicted in <ref type="table" target="#tab_0">Table 1</ref>. ImageNet-LT has an imbalanced training set with 115,846 images for 1,000 classes from ImageNet-1K <ref type="bibr" target="#b3">[4]</ref>. The class frequencies follow a natural power-law distribution <ref type="bibr" target="#b31">[32]</ref> with a maximum number of 1,280 images per class and a minimum number of 5 images per class. The validation and testing sets are balanced and contain 20 and 50 images per class respectively. Places-LT has an imbalanced training set with 62,500 images for 365 classes from Places-2 <ref type="bibr" target="#b46">[47]</ref>. The class frequencies follow a natural power-law distribution <ref type="bibr" target="#b31">[32]</ref> with a maximum number of 4,980 images per class and a minimum number of 5 images per class. The validation and testing sets are balanced and contain 20 and 100 images per class respectively. Evaluation metrics. We report average top-1 accuracy across the four folds, Manyshot classes (? 100 samples), Mediumshot classes (20 ? 100 samples), Fewshot classes (&lt; 20 samples), and All classes. Since the test set is balanced across all classes, the average accuracy and mean precision coincide. These four metrics are important for fine-grained evaluation since high accuracy on All classes does not imply high accuracy on Fewshot classes or Mediumshot classes. Implementation Details. For the Baseline model, we take a Resnet-10 backbone for ImageNet-LT, following <ref type="bibr" target="#b23">[24]</ref>. We initialise the model with Gaussian weights, use an initial learning rate of 0.2, and train for 100 epochs with a cosine learning rate schedule <ref type="bibr" target="#b24">[25]</ref>. For Places-LT, we start with an ImageNet pre-trained Resnet-152 model, and finetune it with 0.01 learning rate for the first 30 epochs followed by 0.1 exponential decay in every 10 epochs. To train expert models, we initialise the feature extractor of each expert E from the Baseline model, and finetune it on its class-balanced subset. For E Mediumshot and E Fewshot , we freeze the lower layers of the feature extractor and only learn the top few layers. The number of learnable layers is a hyperparameter that is fixed by measuring performance on the validation set. To train experts with the reject class, we fix the undersampling ratio for samples from the reject class by measuring performance on the validation set. Note that the classifier for each expert E is smaller than the Baseline model; it equals the number of classes in the expert's class-balanced subset, plus an additional reject class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Oracle Performance</head><p>To estimate the upper bound of our approach, we consider the performance with Oracle access to expert selection information, that is, with apriori knowledge of the expert E that contains the ground-truth class of a test sample in its classbalanced subset. The results are depicted in <ref type="table" target="#tab_1">Table 2 and Table 3</ref>. The Oracle outperforms the Baseline by a significant margin on Mediumshot, Fewshot and All accuracy. Moreover, it is significantly interesting to note that the Oracle accuracies on Mediumshot and Fewshot classes are on par with Manyshot accuracy. This illustrates that performance drops on Mediumshot and Fewshot classes result from relative imbalance rather than data scarcity. Therefore, in principle, it is possible for a classification model to match Fewshot and Mediumshot accuracy with Manyshot accuracy in modern large-scale datasets. It is also interesting to see that the Manyshot accuracy does not improve much by using an Oracle, suggesting that Manyshot accuracy is already saturated in the Baseline model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Effect of joint calibration module</head><p>We apply the methods outlined in Sec. 3.3 for fusing expert posteriors and compare their performance on ImageNet-LT and Places-LT. The results are depicted in <ref type="table" target="#tab_3">Table 4 and Table 5</ref>. KL-div minimisation and Soft-voting yield the highest  Fewshot accuracy, however All accuracy is much lower than the other methods. Expert selection and Stacking are better than KL-div minimisation and Soft-voting on Manyshot, Mediumshot and All accuracy, but worse on Fewshot accuracy. The Joint-calibration module obtains the best Manyshot, Mediumshot and All accuracy, even though Fewshot accuracy suffers.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Diverse ensembles with experts</head><p>In this section, we extend our ensemble using existing long-tailed recognition solutions and analyse the performance of various combinations of models in the ensemble. We experiment with the following models: (i) The Baseline model, (ii) The three expert models, E Manyshot , E Mediumshot and E Fewshot fused using Softvoting, collectively referred to as Experts, (iii) Classifier finetuning with uniform class sampling, wherein we freeze the feature extractor of the Baseline model and finetune the classifier with uniform class sampling. This is referred to as Uniform class sampling or Uniform, (iv) Data augmentation for Mediumshot and Fewshot classes using a conditional generative model from class embeddings to feature embeddings, denoted as GAN based augmentation or simply GAN, (v) Knowledge transfer from Manyshot to Fewshot classes using a learned convex combination of class prototypes from <ref type="bibr" target="#b23">[24]</ref>, denoted as Liu et. al.. The performances of these base models are depicted in <ref type="figure" target="#fig_1">Fig. 3a</ref> and <ref type="figure" target="#fig_1">Fig. 3c</ref>. Notice how the performance of the Baseline model degrades from Manyshot to Mediumshot to Fewshot accuracy. The Expert models give the highest accuracy on the Fewshot classes, but are worse on Manyshot accuracy.</p><p>We combine all these models into a single ensemble, take one model out and see the effect on the performance. To keep the analysis simple, we use Soft-voting for fusing posteriors from all the models, since it doesn't involve learning additional parameters. This ablation is depicted in <ref type="figure" target="#fig_1">Fig. 3b</ref> and <ref type="figure" target="#fig_1">Fig. 3d</ref>. As expected, the diverse ensembles give higher All accuracy than the base models. Taking Experts out causes performance drop on Mediumshot, Fewshot and All accuracy, and increase in accuracy on Manyshot classes. This suggests that the Experts are important in the ensemble for high Mediumshot and Fewshot accuracy. On the other hand, taking the Baseline model out of the ensemble causes an increase in Fewshot accuracy while Manyshot accuracy drops. The ablation also reveals the inherent trade-off between Manyshot and Fewshot accuracy; an appropriate combination of models can tilt accuracy in favor of Manyshot or Fewshot classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison to the state-of-the-art</head><p>We now compare our ensemble of class-balanced experts and the diverse ensemble described in the previous section to the state-of-the-art on the test set of ImageNet-LT and Places-LT. All ensemble combinations use the joint calibration module to fuse model posteriors as it gives us the highest average accuracy.  The results are depicted in <ref type="table" target="#tab_5">Table 6</ref> and <ref type="table" target="#tab_6">Table 7</ref>. We observe that Ours (Experts) gives us close to state-of-the-art results, and Ours (All) establishes a new stateof-the-art on both the benchmark datasets. This validates our hypothesis that an ensemble of class-balanced expert models is a simple and effective strategy for dealing with long-tailed datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Discussion</head><p>There is significant difference between the results depicted in <ref type="table" target="#tab_1">Table 2 and Table 3, and Table 6</ref> and <ref type="table" target="#tab_6">Table 7</ref>. This shows that the various strategies used for fusing expert posteriors are sub-optimal. To analyse the underlying cause, we take our ensemble of class-balanced experts and plot a confusion matrix, each entry showing the percentage of samples from dataset D that are classified by expert model E . For the preliminary analysis we use Soft-voting for fusing expert posteriors. <ref type="figure" target="#fig_2">Fig. 4a</ref> shows the result for Places-LT. The plot shows there is significant confusion amongst experts; experts aren't selected optimally for classes to which a test sample belongs. We term this phenomenon as Expert collision. We further consider each expert's confidence in its predictions. We take the confidence or the maximum softmax probability (MSP) from the expert posteriors and plot confidence histograms. We do this for E Manyshot on its class-balanced subset D Manyshot , for samples from the test set it correctly classifies, and for E Fewshot on the same test samples from D Manyshot . This is depicted in <ref type="figure" target="#fig_2">Fig. 4b</ref> and <ref type="figure" target="#fig_2">Fig. 4c</ref>. The plots show that E Manyshot has high confidence predictions while E Fewshot has low confidence predictions on these samples. However, to avoid Expert collision both the confidence histograms should have a reasonable margin in between and not overlap. <ref type="figure" target="#fig_2">Fig. 4d</ref> and <ref type="figure" target="#fig_2">Fig. 4e, 4f</ref> respectively show the confusion matrix and confidence histograms after joint calibration. It's essential to align confidences of the three experts correctly, and this is precisely what joint calibration does by learning scale and shift parameters for each class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This article presented an ensemble of class-balanced experts framework for longtailed recognition. Our effective and modular strategy explicitly tackles relative imbalance without resorting to complex models or sophisticated loss objectives. We decompose the imbalanced classification problem into balanced classification problems that are more tractable, and train separate expert models for Manyshot, Mediumshot and Fewshot subsets of the data with a reject class for samples lying outside an expert's class-balanced subset. We scale and shift experts' partial posteriors to jointly calibrate experts' predictions, and our ensemble of class-balanced experts reaches close to state-of-the-art performance on two long-tailed benchmarks. We also extend our ensemble with diverse existing solutions for long-tailed recognition and establish a new state-of-the-art on the two benchmark datasets. Moreover, our experiments with an Oracle upper bound reveal that performance drops on Mediumshot accuracy and Fewshot accuracy are caused by relative imbalance and not data scarcity for rare classes. Therefore, it is possible to bring Mediumshot and Fewshot accuracy on par with Manyshot accuracy by remedying relative imbalance in modern large-scale datasets, which motivates further research in this direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Dataset splitting: We decompose ImageNet-LT into (relatively) class-balanced Manyshot, Mediumshot, and Fewshot data subsets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>(a) ImageNet-LT: Base Models (b) ImageNet-LT: Take-One-Out Ensembles (c) Places-LT: Base Models (d) Places-LT: Take-One-Out Ensembles From L-R: Performance of -Base Models, and Take-One-Out ensembles. All results are evaluated on the testing set. Top and bottom rows correspond to ImageNet-LT and Places-LT respectively. Best viewed in color with zoom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Top (bottom): Before (after) joint calibration. L-R: Expert confusion matrix, confidence histograms of E Manyshot for samples it correctly classifies in E Manyshot , and E Fewshot for the same samples. All results on Places-LT. Joint calibration aligns experts' confidences and decreases expert collision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics for training sets in ImageNet-LT and Places-LT.</figDesc><table><row><cell>Datasets</cell><cell cols="4">Attributes Many Medium Few</cell><cell>All</cell></row><row><cell cols="2">ImageNet-LT Classes</cell><cell>391</cell><cell>473</cell><cell cols="2">136 1,000</cell></row><row><cell></cell><cell>Samples</cell><cell cols="4">89,293 24,910 1,643 115,846</cell></row><row><cell>Places-LT</cell><cell>Classes</cell><cell>132</cell><cell>162</cell><cell>71</cell><cell>365</cell></row><row><cell></cell><cell>Samples</cell><cell cols="2">52,862 8,834</cell><cell cols="2">804 62,500</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance of Oracle vs Baseline on ImageNet-LT.</figDesc><table><row><cell>Method</cell><cell cols="2">Many Medium Few All</cell></row><row><cell>Baseline</cell><cell>54.3 26.2</cell><cell>5.8 34.4</cell></row><row><cell cols="3">Experts (Oracle) 54.2 43.3 45.7 47.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Performance of Oracle vs Baseline on Places-LT.</figDesc><table><row><cell>Method</cell><cell cols="3">Many Medium Few All</cell></row><row><cell>Baseline</cell><cell>45.4</cell><cell>25.6</cell><cell>9.0 29.5</cell></row><row><cell cols="4">Experts (Oracle) 47.3 46.1 46.5 46.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Effect of joint calibration module for ImageNet-LT.</figDesc><table><row><cell>Module</cell><cell cols="2">Many Medium Few All</cell></row><row><cell>KL-div min.</cell><cell>25.3</cell><cell>20.5 39.1 21.9</cell></row><row><cell>Soft-Voting</cell><cell>26.3</cell><cell>21.3 38.9 25.6</cell></row><row><cell cols="2">Expert Selection 38.3</cell><cell>32.6 17.2 32.8</cell></row><row><cell>Stacking</cell><cell>28.1</cell><cell>27.5 33.8 28.6</cell></row><row><cell cols="3">Joint Calibration 43.2 34.3 18.9 35.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Effect of joint calibration module for Places-LT.</figDesc><table><row><cell>Module</cell><cell cols="2">Many Medium Few All</cell></row><row><cell>KL-div min.</cell><cell>30.2</cell><cell>31.7 28.9 30.4</cell></row><row><cell>Soft-Voting</cell><cell>30.0</cell><cell>31.8 28.9 30.6</cell></row><row><cell cols="2">Expert Selection 32.6</cell><cell>31.8 24.5 30.7</cell></row><row><cell>Stacking</cell><cell>28.2</cell><cell>36.0 26.2 31.3</cell></row><row><cell cols="3">Joint Calibration 37.2 35.3 26.3 34.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Results on ImageNet-LT, using backbone Resnet-10. *Results obtained from the author's code. ?Results taken directly from<ref type="bibr" target="#b23">[24]</ref>.</figDesc><table><row><cell>Methods</cell><cell cols="3">Many Medium Few All</cell></row><row><cell cols="2">Lifted Loss ? [26] 35.8</cell><cell cols="2">30.4 17.9 30.8</cell></row><row><cell cols="2">Focal Loss ? [23] 36.4</cell><cell>29.9</cell><cell>16 30.5</cell></row><row><cell cols="2">Range Loss ? [45] 35.8</cell><cell cols="2">30.3 17.6 30.7</cell></row><row><cell>FSLwF ? [9]</cell><cell>40.9</cell><cell>22.1</cell><cell>15 28.4</cell></row><row><cell>Liu et al. ? [24]</cell><cell>43.2</cell><cell cols="2">35.1 18.5 35.6</cell></row><row><cell>Baseline</cell><cell cols="2">54.3 26.2</cell><cell>5.7 34.4</cell></row><row><cell>Uniform</cell><cell>46.5</cell><cell cols="2">33.0 13.3 35.6</cell></row><row><cell>GAN</cell><cell>46.4</cell><cell cols="2">30.0 15.2 34.4</cell></row><row><cell>Liu et al.* [24]</cell><cell>40.8</cell><cell cols="2">33.3 16.6 33.9</cell></row><row><cell cols="2">Ours (Experts) 43.2</cell><cell cols="2">34.3 18.9 35.7</cell></row><row><cell>Ours (All )</cell><cell cols="3">48.2 37.0 21.5 39.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Results on Places-LT, using backbone Resnet-152. *Results obtained from the author's code.?Results taken directly from<ref type="bibr" target="#b23">[24]</ref>.</figDesc><table><row><cell>Methods</cell><cell cols="3">Many Medium Fews All</cell></row><row><cell cols="2">Lifted Loss ? [26] 41.1</cell><cell cols="2">35.4 24.0 35.2</cell></row><row><cell cols="2">Focal Loss ? [23] 41.1</cell><cell cols="2">34.8 22.4 34.6</cell></row><row><cell cols="2">Range Loss ? [45] 41.1</cell><cell cols="2">35.4 23.2 35.1</cell></row><row><cell>FSLwF ? [9]</cell><cell>43.9</cell><cell cols="2">29.9 29.5 34.9</cell></row><row><cell>Liu et al. ? [24]</cell><cell>44.7</cell><cell cols="2">37.0 25.3 35.9</cell></row><row><cell>Baseline</cell><cell cols="2">45.4 25.6</cell><cell>9.0 29.5</cell></row><row><cell>Uniform</cell><cell>41.3</cell><cell cols="2">35.5 25.2 35.6</cell></row><row><cell>GAN</cell><cell>42.7</cell><cell cols="2">33.3 22.5 34.6</cell></row><row><cell>Liu et al.* [24]</cell><cell>41.4</cell><cell cols="2">37.1 19.2 35.2</cell></row><row><cell cols="2">Ours (Experts) 37.2</cell><cell cols="2">35.3 26.3 34.2</cell></row><row><cell>Ours (All )</cell><cell cols="3">43.6 39.9 27.7 38.9</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The battle against the long tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Big Data and Statistical Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Smote: synthetic minority over-sampling technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAIR</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Class rectification hard mining for imbalanced deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICCCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A multiple resampling method for learning from imbalanced data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Estabrooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational intelligence</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Multi-modal cycle-consistent generalized zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A review on ensembles for the class imbalance problem: bagging-, boosting-, and hybridbased approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Barrenechea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bustince</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1321" to="1330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning from imbalanced data sets with boosting and data generation: the databoost-im approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L</forename><surname>Viktor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD Explorations Newsletter</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Borderline-smote: a new over-sampling method in imbalanced data sets learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Mao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>ICIC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning from imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Garcia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>TKDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A baseline for detecting misclassified and out-ofdistribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations</title>
		<meeting>International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep anomaly detection with outlier exposure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Deep imbalanced learning for face recognition and attribute prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adaptive mixtures of local experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Nowlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Hulse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Napolitano</surname></persName>
		</author>
		<title level="m">Comparing boosting and bagging techniques with noisy and imbalanced data. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cost-sensitive decision tree ensembles for effective imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krawczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wo?niak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schaefer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Enhancing the reliability of out-of-distribution image detection in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2018</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<title level="m">Sgdr: Stochastic gradient descent with warm restarts</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning and transferring mid-level image representations using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1717" to="1724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Low-shot learning with imprinted weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5822" to="5830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Few-shot image recognition by predicting parameters from activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7229" to="7238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Meta-transfer learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The devil is in the tails: Fine-grained classification in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.01450</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Boosting support vector machines for imbalanced data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and information systems</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Diversity analysis on imbalanced data sets by using ensemble models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>CIDM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Low-shot learning from imaginary data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning to learn: Model regression networks for easy small sample learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
		<title level="m">Stacked generalization. Neural networks</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Feature generating networks for zeroshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">f-vaegan-d2: A feature generating framework for any-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Feature transfer learning for face recognition with under-represented data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Learning to detect multiple photographic defects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>WACV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Twenty years of mixture of experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Yuksel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Gader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1177" to="1193" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Range loss for deep face recognition with long-tailed training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Unequaltraining for deep face recognition with long-tailed noisy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Capturing long-tail distributions of object subcategories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
