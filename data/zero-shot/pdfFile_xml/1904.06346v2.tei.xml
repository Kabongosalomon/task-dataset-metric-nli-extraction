<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Prior-aware Neural Network for Partially-Supervised Multi-Organ Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyin</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Song Bai</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Wang</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">ByteDance Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Facebook</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Han</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">PAII Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><surname>Fishman</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">The Johns Hopkins Medical Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Prior-aware Neural Network for Partially-Supervised Multi-Organ Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Accurate multi-organ abdominal CT segmentation is essential to many clinical applications such as computeraided intervention. As data annotation requires massive human labor from experienced radiologists, it is common that training data are partially labeled, e.g., pancreas datasets only have the pancreas labeled while leaving the rest marked as background. However, these background labels can be misleading in multi-organ segmentation since the "background" usually contains some other organs of interest. To address the background ambiguity in these partially-labeled datasets, we propose Prior-aware Neural Network (PaNN) via explicitly incorporating anatomical priors on abdominal organ sizes, guiding the training process with domain-specific knowledge. More specifically, PaNN assumes that the average organ size distributions in the abdomen should approximate their empirical distributions, prior statistics obtained from the fully-labeled dataset. As our training objective is difficult to be directly optimized using stochastic gradient descent, we propose to reformulate it in a min-max form and optimize it via the stochastic primal-dual gradient algorithm. PaNN achieves state-of-the-art performance on the MICCAI2015 challenge "Multi-Atlas Labeling Beyond the Cranial Vault", a competition on organ segmentation in the abdomen. We report an average Dice score of 84.97%, surpassing the prior art by a large margin of 3.27%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This work focuses on multi-organ segmentation in abdominal regions which contain multiple organs such as liver, pancreas and kidneys. The segmentation of internal structures on medical images, e.g., CT scans, is an essential prerequisite for many clinical applications such as computer-aided diagnosis, computer-aided intervention and radiation therapy. Compared with other internal structures such as heart or brain, abdominal organs are much more difficult to segment due to the morphological and structural complexity, low contrast of soft tissues, etc.</p><p>With the development of deep convolutional neural networks (CNNs), many medical image segmentation problems have achieved satisfactory results only when fullsupervision is available <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b3">4]</ref>. Despite the recent progress, the annotation of medical radiology images is extremely expensive, as it must be handled by experienced radiologists and carefully checked by additional experts. This results in the lack of high-quality labeled training data. More critically, how to efficiently incorporate domain-specific expertise (e.g., anatomical priors) with segmentation models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25]</ref>, such as organ shape, size, remains an open issue.</p><p>Our key observation is that, in medical image analysis domain, instead of scribbles <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref> , points <ref type="bibr" target="#b2">[3]</ref> and image-level tags <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b39">40]</ref>, there exists a considerable number of datasets in the form of abdominal CT scans <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref>. To meet different research goals or practical usages, these datasets are annotated to target different organs (a subset of abdominal organs), e.g., pancreas datasets <ref type="bibr" target="#b30">[31]</ref> only have the pancreas labeled while leaving the rest marked as background. <ref type="figure">Figure 2</ref>. Overview of the proposed PaNN for partially-supervised multi-organ segmentation. It is trained with a small set of fullylabeled dataset and several partially-labeled datasets. The PaNN regularizes that the organ size distributions of the network output should approximate their prior statistics in the abdominal region obtained from the fully-labeled dataset.</p><p>The aim of this work is to fully leverage these existing partially-annotated datasets to assist multi-organ segmentation, which we refer to as partial supervision. To address the challenge of partial supervision, an intuitive solution is to simply train a segmentation model directly on both the labeled data and the partially-labeled data in the semi-supervised manner <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b25">26]</ref>. However, it 1) fails to take advantages of the fact that medical images are naturally more constrained compared with natural images <ref type="bibr" target="#b23">[24]</ref>; 2) is intuitively misleading as it treats the unlabeled pixels/voxels as background. To overcome these issues, we propose Prior-aware Neural Network (PaNN) to handle such background ambiguity via incorporating prior knowledge on organ size distributions. We achieve this via a prior-aware loss, which acts as an auxiliary and soft constraint to regularize that the average output size distributions of different organs should approximate their prior proportions. Based on the anatomical similarities ( <ref type="figure" target="#fig_0">Fig. 1</ref>) across different patient scans <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b14">15]</ref>, the prior proportions are estimated by statistics from the fully-labeled data. The overall pipeline is illustrated in <ref type="figure">Fig. 2</ref>. It is important to note that the training objective is hard to be directly optimized using stochastic gradient descent. To address this issue, we propose to formulate our objective in a min-max form, which can be well optimized via the stochastic primal-dual gradient algorithm <ref type="bibr" target="#b19">[20]</ref>. To summarize, our contributions are three-fold: 1) We propose Prior-aware Neural Network, which incorporates domain-specific knowledge from medical images, to facilitate multi-organ segmentation via using partiallyannotated datasets.</p><p>2) As the training objective is difficult to be directly optimized using stochastic gradient descent, it is essential to re-formulate it in a min-max form and optimize via stochastic primal-dual gradient <ref type="bibr" target="#b19">[20]</ref>.</p><p>3) PaNN significantly outperforms previous state-of-thearts even using fewer annotations. It achieves 84.97% on the MICCAI2015 challenge "Multi-Atlas Labeling Beyond the Cranial Vault" in the free competition for organ segmentation in the abdomen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Currently, the most successful deep learning techniques for semantic segmentation stem from a common forerunner, i.e., Fully Convolutional Network (FCN) <ref type="bibr" target="#b20">[21]</ref>. Based on FCN, many recent advanced techniques have been proposed, such as DeepLab <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref>, SegNet <ref type="bibr" target="#b0">[1]</ref>, PSPNet <ref type="bibr" target="#b42">[43]</ref>, RefineNet <ref type="bibr" target="#b17">[18]</ref>, etc. Most of these methods are based on supervised learning, hence requiring a sufficient number of labeled training data to train. To cope with scenarios where supervision is limited, researchers begin to investigate the weakly-supervised setting <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b8">9]</ref>, e.g., only boundingboxes or image-level labels are available, and the semisupervised setting <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b34">35]</ref>, i.e., unlabeled data are used to enlarge the training set. Papandreou et al. <ref type="bibr" target="#b25">[26]</ref> propose EM-Adapt where the pseudo-labels of the unknown pixels are estimated in the expectation step and standard SGD is performed in the maximization step. Souly et al. <ref type="bibr" target="#b34">[35]</ref> demonstrate the usefulness of generative adversarial networks for semi-supervised segmentation.</p><p>In the medical imaging domain, it becomes more intractable to acquire sufficient labeled data due to the difficulty of annotation, as the annotation has to be done by experts. Although fully-supervised methods (e.g., UNet <ref type="bibr" target="#b29">[30]</ref>, VoxResNet <ref type="bibr" target="#b3">[4]</ref>, DeepMedic <ref type="bibr" target="#b13">[14]</ref>, 3D-DSN <ref type="bibr" target="#b10">[11]</ref>, HNN <ref type="bibr" target="#b31">[32]</ref>) have achieved remarkable performance improvement in tasks such as brain MR segmentation, abdominal singleorgan segmentation and multi-organ segmentation, semi-or weakly-supervised learning is still a far more realistic solution. For example, Bai et al. <ref type="bibr" target="#b1">[2]</ref> proposed an EM-based iterative method, where a CNN is alternately trained on labeled and post-processed unlabeled sets. In <ref type="bibr" target="#b41">[42]</ref>, supervised and unsupervised adversarial costs are involved to address semi-supervised gland segmentation. DeepCut <ref type="bibr" target="#b28">[29]</ref> shows that weak annotations such as bounding-boxes in medical image segmentation can also be utilized by performing an iterative optimization scheme like <ref type="bibr" target="#b25">[26]</ref>.</p><p>However, these methods fail to capture the anatomical priors <ref type="bibr" target="#b18">[19]</ref>. Inclusion of priors in medical imaging could potentially have much more impact compared with their usage in natural images since anatomical objects in medical images are naturally more constrained in terms of shape, location, size, etc. Some recent works <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25]</ref> demonstrate that these priors can be learned by a generative model. But these methods will induce heavy computational overhead. Kervadec et al. <ref type="bibr" target="#b14">[15]</ref> proposed that directly imposing inequality constraints on sizes is also an effective way of incorporating anatomical priors. Unlike these methods, we propose to learn from partial annotations by embedding the abdominal region statistics in the training objective, which requires no additional training budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Prior-aware Neural Network</head><p>Our work aims to address the multi-organ segmentation problem with the help of multiple existing partially-labeled datasets. Given a CT scan where each element indicates the Housefield Unit (HU) of a voxel, the goal is to find the predicted labelmap of each pixel/voxel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Partial Supervision</head><p>We consider a new supervision paradigm, i.e., partial supervision, for multi-organ segmentation. This is motivated by the fact that there exists a considerable number of datasets with only one or a few organs labeled in the form of abdominal CT scans <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref> in medical image analysis, which can serve as partial supervision for multi-organ segmentation (see the list in the appendix). Based on domain knowledge, our approach assumes the following characteristics of the datasets which are common in medical image analysis. First, the scanning protocols of medical images are well standardized, e.g., brain, head and neck, chest, abdomen, and pelvis in CT scans, which means that the internal structures are consistent in a limited range according to the scanning protocol (see <ref type="figure" target="#fig_0">Fig. 1</ref>). Second, internal organs have anatomical and spatial relationships such as gastrointestinal track, i.e., stomach, duodenum, small intestine, and colon are connected in a fixed order.</p><p>The partially-supervised setting can be formally defined as below. Given a fully-labeled dataset S L = {I L , Y L } with the annotation Y L known and T partially-labeled datasets S P = {S P1 , S P2 , ...S P T } with the t-th dataset defined as S Pt = {I Pt , Y Pt }. L = {1, 2, ..., n L } and P t = {1, 2, ..., n Pt } denote the image indices for S L and S Pt , respectively. For each element y ij ? Y L , y ij denotes the annotation of the j-th pixel in the i-th image I i ? I Pt and is selected from L, where L denotes the abdominal organ space, i.e., L = {spleen, pancreas, liver, ...}. For the t-th partially-labeled dataset S Pt , y ij ? Y Pt is selected from L Pt ? L. In 2D-based segmentation models, the i-th input I i is a sliced 2D image from either Axial, Coronal or Saggital view of the whole CT scan <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b38">39]</ref>. In 3D-based segmentation models, I i is a cropped 3D patch from the whole CT volume <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22]</ref>. Note that semi-supervision and fully-supervision are two extreme cases of partial supervision, when the set of partial labels is an empty set (L Pt = ) and is equal to the complete set (L Pt = L), respectively.</p><p>A naive solution is to simply train a segmentation network from both the fully-labeled data and the partiallylabeled data and alternately update the network parameters and the segmentations (pseudo-labels) for the partiallylabeled data <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b1">2]</ref>. While these EM-like approaches have achieved significant improvement compared with fully-supervised methods, they require high-quality pseudolabels and fail to explicitly incorporate anatomical priors on shape or size.</p><p>To address this issue, we propose a Prior-aware Neural Network (PaNN), aiming at explicitly embedding anatomical priors without incurring any additional budget. More specifically, the anatomical priors are enforced by introducing an additional penalty which acts as a soft constraint to regularize that the average output distributions of organ sizes should mimic their empirical proportions. This prior is obtained by calculating the organ size statistics of the fullylabeled dataset. An overview of the overall framework is shown in <ref type="figure">Fig. 2</ref>, and the detailed training procedures will be introduced in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Prior-aware Loss</head><p>Consider a segmentation network parameterized by ?, which outputs probabilities p. Let q ? R (|L|+1)?1 be the label distribution in the fully-labeled dataset, with q l describing the proportion of the l-th label (organ). Then, we estimate the average predicted distribution of the pixels in the partially-labeled datasets as</p><formula xml:id="formula_0">p = 1 N T t=1 i?P t j pij,<label>(1)</label></formula><p>where p ij = [p 0 ij , p 1 ij , ..., p</p><p>|L| ij ] denotes the probability vector of the j-th pixel in the i-th input slice I i , and N is the total number of pixels/voxels. Recall that T is the total number of partially-labeled datasets.</p><p>To embed the prior knowledge, the prior-aware loss is defined as</p><formula xml:id="formula_1">KL marginal (q|p) l KL(q l |p l ) = ? l q l logp l + (1 ? q l ) log(1 ?p l ) + const = ?{q logp + (1 ? q) log(1 ?p)} + const,<label>(2)</label></formula><p>which measures the matching probability of the two distributions q andp via Kullback-Leibler divergence. Note that each class is treated as one vs. rest when calculating the matching probabilities. Therein, the rationale of Eq. <ref type="formula" target="#formula_1">(2)</ref> is that the output distributionsp of different organ sizes should approximate their empirical marginal proportions q, which generally reflects the domain-specific knowledge.</p><p>Note that q is a global estimation of label distribution of the fully-labeled training data, which remains unchanged. Consequently, H(q) is constant which can be omitted during the network training. Nevertheless, we observe that it is still problematic to directly apply stochastic gradient descent, as we will detail in Sec. 3.3.</p><p>Specifically in our case, our final training objective is</p><formula xml:id="formula_2">min ?,Y P JL(?) + ?1JP(?, YP) + ?2JC(?),<label>(3)</label></formula><p>where J L (?) and J P (?, Y P ) are the cross entropy loss on the fully-labeled data and the partially-labeled data, respectively. And Y P denotes the computed pseudo-labels as well as existing partial labels from the partially-labeled dataset(s). Note that the prior-aware loss J C is used as a soft global constraint to stablize the training process. Concretely, J L (?) is defined as</p><formula xml:id="formula_3">J L = ? 1 N i?L j |L| l=0 1(yij = l) log p l ij ,<label>(4)</label></formula><p>where p l ij denotes the softmax probability of the j-th pixel in the i-th image to the l-th category. J P (?, Y P ) is given by</p><formula xml:id="formula_4">J P = ? 1 N T t=1 i?Pt j |L| l=0 {1(y ij = l) log p l ij +1(y ij = l) log p l ij },<label>(5)</label></formula><p>where the first term corresponds to the pixels with their labels Y P given, i.e., y ij ? L Pt . The second term corresponds to unlabeled background pixels, and Y P needs to be estimated during the model training as a kind of pseudosupervision, i.e., y ij ? L ? L Pt .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Derivation</head><p>By substituting Eq. (1) into Eq. (2) and expanding q,p into scalars, we rewrite Eq. (2) as</p><formula xml:id="formula_5">J C = ? |L| l=0 {q l log 1 N T t=1 i?Pt j p l ij + (1 ? q l ) log(1 ? 1 N T t=1 i?Pt j p l ij )} + const.</formula><p>(6) From Eq. (2) and Eq. <ref type="formula">(6)</ref> we can see that the average distributionp of organ sizes is inside the logarithmic loss, which is very different from standard machine learning loss such as Eq. (4) and Eq. <ref type="formula" target="#formula_4">(5)</ref> where the average is outside logarithmic loss. And directly minimizing by stochastic gradient descent is very difficult as the true gradient induced by Eq. <ref type="formula" target="#formula_1">(2)</ref> is not a summation of independent terms, the stochastic gradients would be intrinsically biased <ref type="bibr" target="#b19">[20]</ref>.</p><p>To remedy this, we propose to optimize the KL divergence term using stochastic primal-dual gradient <ref type="bibr" target="#b19">[20]</ref>. Our goal here is to transform the prior-aware loss into an equivalent min-max problem by taking the sample average out of the logarithmic loss. We introduce two auxiliary variables to assist the optimization, i.e., the primal variable ? and the dual variable ?. First, the following identity holds</p><formula xml:id="formula_6">? log ? = max ? (?? + 1 + log(??))<label>(7)</label></formula><p>due to the property of the log function. Based on Eq. <ref type="formula" target="#formula_6">(7)</ref>, we define ? ? R |L|?1 as the dual variable associated to the primal variablep, and define ? ? R |L|?1 as the dual variable associated to the primal variable (1 ?p). Then, we have</p><formula xml:id="formula_7">? logp l = max ? l p l ? l + 1 + log(?? l ) ? log(1 ?p l ) = max ? l (1 ?p l )? l + 1 + log(?? l ) ,<label>(8)</label></formula><p>where ? l (or ? l ) denotes the l-th element of ? (or ?). Substituting them into Eq. (2)/Eq. <ref type="formula">(6)</ref>, maximizing the KL divergence is equivalent to the following min-max optimization problem:</p><formula xml:id="formula_8">min ? max ?,? l q l p l ? l + 1 + log(?? l ) + l (1 ? q l ) (1 ?p l )? l + 1 + log(?? l ) ? min ? max ?,? l q l ? l ? (1 ? q l )? l p l + q l log(?? l ) + l (1 ? q l ) ? l + log(?? l ) ,<label>(9)</label></formula><p>which brings the sample average out of the logarithmic loss. Note that we ignore the constant in the above formulas. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Model Training</head><p>We consider training a fully convolutional network <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b29">30]</ref> for multi-organ segmentation, where the input images are either 2D slices <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b44">45]</ref> or 3D cropped patches <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22]</ref>. The training procedure can be divided into two stages.</p><p>In the first stage, we only train on the fully-labeled dataset S L by optimizing Eq. (4) via stochastic gradient descent (also means ? 1 = 0 and ? 2 = 0 in Eq. <ref type="formula" target="#formula_2">(3)</ref>). The goal of this stage is to find a proper initialization ? 0 for the network weights, which stabilizes the later training procedure.</p><p>In the second stage, we train the model on the union of the fully-labeled dataset S L and partially-labeled dataset(s) S P via Eq. (3). As can be drawn, we have two groups of variables, i.e., the network weights ? and the three auxiliary variables {?, ?, Y P }. We adopt an alternating optimization, which can be decomposed into two subproblems:</p><p>? Fixing ?, Updating {?, ?, Y P }. With the network weights ? given, we can first estimate the pesudo-labels Y P of background pixels in the partially-labeled dataset(s) S P . Meanwhile, the optimization of ? and ? is a maximization problem. Hence, we do stochastic gradient ascent to learn ? and ?. As for the initialization, we set ? to ?1/q and set ? to ?1/(1 ? q), respectively.</p><p>? Fixing {?, ?, Y P }, Updating ?. By fixing the three auxiliary variables, we can then update the network weights ? via the standard stochastic gradient descent.</p><p>As can be seen, our algorithm is formulated as a minmax optimization. We summarize the detailed procedure of optimization in Algorithm 1. As for the partially-labeled dataset(s) S P , we use a spleen segmentation dataset 1 (referred as A), a pancreas segmentation dataset 2 (referred as B) and a liver segmentation dataset 1 (referred as C). To make these partially-labeled datasets balanced, 40 cases are evenly selected from each dataset to constitute the partial supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Following the standard cross-validation evaluation <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b38">39]</ref>, we randomly partition the fully-labeled dataset S L into 5 complementary folds, each of which contains 6 cases, then apply the standard 5-fold crossvalidation. For each fold, we use 4 folds (i.e., 24 cases) as full supervision and test on the remaining fold.</p><p>The evaluation metric we use is the Dice-S?rensen Coefficient (DSC), which measures the similarity between the prediction voxel set Z and the ground-truth set Y. Its mathematical definition is DSC(Z, Y) = 2?|Z?Y| |Z|+|Y| . We report an average DSC of all the testing cases over the 13 labeled anatomical structures for performance evaluation.</p><p>Implementation Details. Similar to <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39]</ref>, we use the soft tissue CT window range of [?125, 275] HU. The intensities of each slice are then rescaled to [0.0, 255.0]. Random rotation of [0, 15] is used as an online data augmentation. Our implementations are based on the current state-ofthe-art 2D 3 <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b5">6]</ref> and 3D models 4 <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b27">28]</ref>. We provide an extensive study about how partially-labeled datasets facilitate multi-organ segmentation task and list thorough comparisons under different settings.</p><p>As described in Sec. 3.4, the whole training procedure is divided into two stages. The first stage is the same as fully-supervised training, i.e., we train exclusively on the fully-labeled dataset S L for a certain number of iterations M1.</p><p>In the second stage, we switch to the min-max optimization on the union of the fully-labeled dataset and partiallylabeled datasets for M2 iterations. In each mini-batch, the sampling rate of labeled data and partially-labeled data is 3 : 1. It has been suggested <ref type="bibr" target="#b1">[2]</ref> that it is less necessary to update the pseudo-label Y P per iteration. Hence, Y P is updated every 10K iterations in practice. In addition, the hyperparameters ? 1 and ? 2 are set to be 1.0 and 0.1, respectively. The same decay policy of learning rate is utilized as that used in the first stage. In the second stage, the initial learning rate for the minimization step and the maximization step are set as 10 ?5 and 2 ? 10 ?5 , respectively. For 2D implementations, the initial learning rate of the first stage is 2 ? 10 ?5 and a poly learning rate policy is employed. M1 and M2 are set as 40K and 30K, respectively. Following <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14]</ref>, we apply multi-scale inputs (scale factors are {0.75, 1.0, 1.25, 1.5, 1.75, 2.0}) in both training and testing phase. For 3D implementations, the initial learning rate of the first stage is 5e ?4 and a fixed learning rate policy is employed. M1 and M2 are set as 80K and 100K, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental Comparison</head><p>We compare the proposed PaNN with a series of stateof-the-art algorithms, including 1) the fully-supervised approach (denoted as "-fully-sup"), where we train exclusively only on the fully-labeled dataset S L , 2) the semisupervised approach (denoted as "-semi-sup"), where we train the network on both the fully-labeled dataset S L and the partially-labeled dataset(s) S P while treating S P as unlabeled following the representative method <ref type="bibr" target="#b1">[2]</ref>, and 3) the naive partially-supervised approach (denoted as "-partialsup"), where we also train the network on both S L and S P while treating the partial labels as they are. Different from PaNN, we set ? 2 = 0 in Eq. (3) to verify the efficacy of the prior-aware loss.</p><p>Benefit of Partial Supervision. As shown from <ref type="table" target="#tab_0">Table 1</ref>, among three kinds of supervisions, partial supervision obtains the best performance followed by the semi-supervision and full supervision. It is no surprise to observe such a phenomenon for two reasons. First, compared with full supervision, semi-supervision has more training data, though part of them is not annotated. Second, compared with semi-supervision, partial supervision involves more annotated pixels in the organ of interest. <ref type="table" target="#tab_0">Table 1</ref>, PaNN generally achieves better performance than the naive partially-supervised methods, which demonstrates the effectiveness of our proposed PaNN. For example, when setting the partial dataset as the union of A, B and C, PaNN achieves the best result either using 2D models or 3D models. 2D models generally observe a better performance in each setting compared with 3D models. This is probably due to the fact that current 3D models only act on local patches (e.g., 64 ? 64 ? 64), which results in lacking holistic information <ref type="bibr" target="#b37">[38]</ref>. A detailed discussion of 2D and 3D models is listed in <ref type="bibr" target="#b15">[16]</ref>. More specifically, PaNN outperforms the naive partiallysupervised method by 1.28% with ResNet-50 and by 1.69% with ResNet-101 as the backbone model, respectively. Additionally, we also observe a convincing performance gain of 0.45% using 3D UNet <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b29">30]</ref> as the backbone model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of PaNN. From</head><p>Meanwhile, by increasing the number of partiallylabeled datasets (from using only A, B or C to the union of three), the performance improvements of different methods are also different. For example, with the ResNet-101 as the backbone, the largest improvement obtained under semisupervision is 0.82% (from 76.37% to 77.19%), and that of partial supervision is 0.51% (from 76.84% to 77.35%). By contrast, PaNN obtains a much more remarkable improvement of 1.56% (from 77.48% to 79.04%). Such an observation suggests that PaNN is capable of handling more partially-labeled training data and is less susceptible to the background ambiguity.</p><p>Organ-by-organ Analysis. To reveal the detailed effect of PaNN, we present an organ-by-organ analysis in <ref type="figure" target="#fig_2">Fig. 3</ref>. We use ResNet-50 as the backbone model (ResNet-101 has a similar trend) and the partially-labeled dataset C (indicates that the liver is the target organ).</p><p>In <ref type="figure" target="#fig_2">Fig. 3</ref>, we observe clear statistical improvements over the fully-supervised method for almost every organ (pvalues p &lt; 0.001 hold for 11/13 of all abdominal organs).  Great improvements are also observed for those difficult organs, i.e., organs either in small sizes or with complex geometric characteristics such as gallbladder (from 67.26% to 72.26%), esophagus (from 69.35% to 71.21%), stomach (from 84.09% to 87.21%), IVC (from 77.34% to 80.70%), portal vein &amp; splenic vein (from 66.74% to 68.75%), pancreas (from 71.45% to 73.62%), right adrenal gland (from 53.65% to 55.56%) and left adrenal gland (from 49.51% to 53.63%). This promising result indicates that our method distills a reasonable amount of knowledge from additional partially-labeled data and the regularization loss can help facilitate the network to enhance the discriminative information to a certain degree.</p><p>Meanwhile, we also observe a distinct performance improvement for organs other than the partially-labeled structures (i.e., the liver). For instance, the performance of gallbladder, stomach, IVC, pancreas are boosted from 68.97%, 85.57%, 78.59%, 71.94% to 72.26%, 87.21%, 80.70%, 73.62%, respectively. This suggests that the superiority of PaNN not only originates from more training data, but also from the fact that PaNN can effectively incorporate anatomical priors on organ sizes in abdominal regions, which is helpful for multi-organ segmentation.</p><p>Qualitative Evaluation. We also show a set of qualitative examples, i.e., 5 slices from 3 cases, in <ref type="figure" target="#fig_4">Fig. 4</ref>, where we zoom in to visualize the finer details of the improved region.</p><p>In these samples, we observe that PaNN is the only method that successfully detects the pancreatic tail in <ref type="figure" target="#fig_4">Fig. 4(a)</ref>. In <ref type="figure" target="#fig_4">Fig. 4(b)</ref>, all other methods fail to detect the portal vein and splenic vein while PaNN demonstrates an almost perfect detection of these veins. For <ref type="figure" target="#fig_4">Fig. 4(c)</ref> to <ref type="figure" target="#fig_4">Fig. 4(e)</ref>, apart from the evident improvements of the pancreas, left adrenal gland, one of the smallest abdominal organs, is also clearly segmented by PaNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">MICCAI 2015 Multi-Atlas Labeling Challenge</head><p>We test our model in the 2015 MICCAI Multi-Atlas Abdomen Labeling challenge. The top model (denoted as "PaNN" in <ref type="table">Table 4</ref>) we submit is based on ResNet-101, and trained on all 30 cases of the fully-labeled dataset S L and the union of three partially-labeled datasets A, B and C. The evaluation metric employed in this challenge includes the Dice scores, average surface distances <ref type="bibr" target="#b31">[32]</ref> and Hausdorff distances <ref type="bibr" target="#b21">[22]</ref>. We compare PaNN with the other top submissions of the challenge leaderboard in <ref type="table">Table 4</ref>. As it shows, the proposed PaNN achieves the best performance under all the three evaluation metrics, easily surpassing prior best result by a large margin. Without using any additional data and even randomly removing partial labels from the challenge data, our method (denoted as "PaNN*" in <ref type="table">Table 4</ref>) stills obtains the state-of-the-art re-    sult of 83.17%, outperforming the previous best result of DLTK UNet <ref type="bibr" target="#b27">[28]</ref> by 2% in average Dice. It is noteworthy that our method is far from its potential maximum performance as we only use 2D single view algorithms. It is suggested <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b43">44</ref>] that using multi-view algorithms or model ensemble can boost the performance further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Generalization to Other Datasets</head><p>We also apply our algorithm to a different set of abdominal clinical CT images, where 20 cases are used for training and 15 cases are used for testing. A total of 9 structures (spleen, right kidney, left kidney, gallbladder, liver, stomach, aorta, IVC, pancreas) are manually labeled. Each case was segmented by four experienced radiologists, and con-firmed by an independent senior expert. Each CT volume consists of 319 ? 1051 slices of 512 ? 512 pixels, and has voxel spatial resolution of ([0.523 ? 0.977] ? [0.523 ? 0.977] ? 0.5)mm 3 . We use the union of all 3 datasets A, B, and C as the partial supervision. The results are summarized in <ref type="table" target="#tab_7">Table 5</ref>, where the proposed PaNN also achieves better results compared with existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we have presented PaNN, for multi-organ segmentation, as a way to better utilize existing partiallylabeled datasets. In several applications such as radiation therapy or computer-aided surgery, physicians and surgeons have been doing segmentation of target structures. Meanwhile, to handle the background ambiguity brought by the partially-labeled data, the proposed PaNN exploits the anatomical priors by regularizing the organ size distributions of the network output should approximate their prior statistics in the abdominal region. Our proposed PaNN shows promising results using state-of-the-art models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Summary of Partially-labeled Datasets</head><p>To facilitate the research on partially-supervised multi-organ segmentation, we have collected a list of partially-labeled datasets to the best of our knowledge. We present them in <ref type="table">Table 4</ref> for the fellow researchers to explore partial supervision in multi-organ segmentation problems by leveraging these partially-labeled datasets. Note that our method can be also easily applied to these datasets for improving the segmentation performance.  <ref type="table">Table 4</ref>. Summary of partially-labeled datasets for multi-organ segmentation. N denotes the number of annotated cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Qualitative Evaluation</head><p>We include more qualitative results in <ref type="figure" target="#fig_5">Fig. 5</ref>, where we also show improved regions compared with fully-supervision other than the pancreas, portal vein &amp; splenic vein, left adrenal gland as discussed in the main manuscript. In <ref type="figure" target="#fig_5">Fig. 5</ref>, we can see an evident improvement of the pancreas (row 1-3), the gallbladder (row 2), the left adrenal gland (row 3-4), the stomach (row 3-6), and the portal vein &amp; the splenic vein (row 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Generalization to Other Datasets</head><p>The complete results of <ref type="table" target="#tab_4">Table 3</ref> in the main manuscript are summarized in <ref type="table" target="#tab_7">Table 5</ref>, where the proposed PaNN also achieves the best performance compared with existing methods.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>3D Visualization of several abdominal organs (liver, spleen, left kidney, right kidney, aorta, inferior vena cava) to show the similarity of patient-wise abdominal organ size distributions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4. 1 .</head><label>1</label><figDesc>Experiment Setup Datasets and Evaluation Metric. We use the training set released in the MICCAI 2015 Multi-Atlas Abdomen La-beling Challenge as the fully-labeled dataset S L , which contains 30 abdominal CT scans with 3779 axial contrastenhanced abdominal clinical CT images in total. For each case, 13 anatomical structures are annotated, including spleen, right kidney, left kidney, gallbladder, esophagus, liver, stomach, aorta, inferior vena cava (IVC), portal vein &amp; splenic vein, pancreas, left adrenal gland, right adrenal gland. Each CT volume consists of 85 ? 198 slices of 512 ? 512 pixels, with a voxel spatial resolution of ([0.54 ? 0.54] ? [0.98 ? 0.98] ? [2.5 ? 5.0])mm 3 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Performance comparison (DSC) in box plots of 13 abdominal structures, where the partially-labeled dataset C is used with ResNet-50 as the backbone model. Our proposed PaNN improves the overall mean DSC and also reduces the standard deviation. Kidney/AG (R), Kidney/AG (L) stand for the right and left kidney/adrenal gland, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Qualitative comparison of different methods, where the partially-labeled dataset C is used as partial supervision with ResNet-101 as the backbone model. We exhibit 3 cases (5 slices) as examples. Improved segmentation regions are zoomed in from the axial view to demonstrate finer details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Qualitative comparison of different methods, where all the 3 partially-labeled datasets A,B,C are used as the partial supervision with ResNet-101 as the backbone model. We exhibit 5 cases (6 slices) as examples. Improved segmentation regions are zoomed in from the axial view to demonstrate finer details. Besides the pancreas, portal vein &amp; splenic vein, left adrenal gland, we also show other improved regions such as the stomach, gallbladder, etc.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 :</head><label>1</label><figDesc>The training procedure of PaNN</figDesc><table><row><cell>Input:</cell></row><row><cell>Fully-labeled training data SL;</cell></row><row><cell>Partially-labeled training data SP;</cell></row><row><cell>Hyperparameters: ?1, ?2;</cell></row><row><cell>Output:</cell></row><row><cell>Segmentation model ?;</cell></row></table><note>begin Train the segmentation model ? on SL; Compute the prior distribution q on SL; Initialize ? = ?1/q and ? = 1/(1 ? q); repeat Estimate pesudo-labels YP with ?; Update ? and ? via stochastic gradient ascent; Update ? via stochastic gradient descent; return ?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Performance comparison on the 2015 MICCAI Multi-Atlas Abdomen Labeling challenge leaderboard. Our method achieves the largest Dice score and the smallest average surface distances and Hausdorff distances. PaNN* only uses 80% of the training data as the fully-supervised dataset and use the rest 20% data as partially-labeled data (by randomly removing labels of 8/13 organs), without using extra data. In this table, we only show 8/13 organs' average Dice scores due to the space limit.</figDesc><table><row><cell>Name</cell><cell cols="6">Spleen Kidney(R) Kidney(L) Gallbladder Esophagus Liver Aorta</cell><cell>IVC</cell><cell cols="3">Average Mean Surface Hausdorff Dice Distance Distance</cell></row><row><cell>AutoContext3DFCN [33]</cell><cell>0.926</cell><cell>0.866</cell><cell>0.897</cell><cell>0.629</cell><cell>0.727</cell><cell cols="2">0.948 0.852 0.791</cell><cell>0.782</cell><cell>1.936</cell><cell>26.095</cell></row><row><cell>deedsJointCL [13]</cell><cell>0.920</cell><cell>0.894</cell><cell>0.915</cell><cell>0.604</cell><cell>0.692</cell><cell cols="2">0.948 0.857 0.828</cell><cell>0.790</cell><cell>2.262</cell><cell>25.504</cell></row><row><cell>dltk0.1 unet sub2 [28]</cell><cell>0.939</cell><cell>0.895</cell><cell>0.915</cell><cell>0.711</cell><cell>0.743</cell><cell cols="2">0.962 0.891 0.826</cell><cell>0.815</cell><cell>1.861</cell><cell>62.872</cell></row><row><cell>results 13organs p0.7</cell><cell>0.890</cell><cell>0.898</cell><cell>0.883</cell><cell>0.685</cell><cell>0.754</cell><cell cols="2">0.936 0.870 0.819</cell><cell>0.817</cell><cell>4.559</cell><cell>38.661</cell></row><row><cell>PaNN* (ours)</cell><cell>0.961</cell><cell>0.901</cell><cell>0.943</cell><cell>0.704</cell><cell>0.783</cell><cell cols="2">0.972 0.913 0.835</cell><cell>0.832</cell><cell>1.641</cell><cell>25.176</cell></row><row><cell>PaNN (ours)</cell><cell>0.968</cell><cell>0.920</cell><cell>0.953</cell><cell>0.729</cell><cell>0.790</cell><cell cols="2">0.974 0.925 0.847</cell><cell>0.850</cell><cell>1.450</cell><cell>18.468</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Performance comparison on a newly collected dataset. Full results are included in the appendix.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 .</head><label>5</label><figDesc>Performance comparison on a newly collected high-quality abdominal dataset, where our method achieves the best result.</figDesc><table><row><cell>Groundtruth</cell><cell>Fully</cell><cell>Semi</cell><cell>Partially</cell><cell>PaNN</cell></row><row><cell></cell><cell>Supervised</cell><cell>Supervised</cell><cell>Supervised</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Available at http://medicaldecathlon.com 2 Available at https://wiki.cancerimagingarchive.net/ display/Public/Pancreas-CT 3 https://github.com/tensorflow/models/tree/ master/research/deeplab 4 https://github.com/DLTK/DLTK</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This work was partly supported by the Lustgarten Foundation for Pancreatic Cancer Research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Semi-supervised learning for network-based cardiac mr image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Oktay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sinclair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rajchl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tarroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">What&apos;s the point: Semantic segmentation with point supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bearman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="549" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Voxresnet: Deep voxelwise residual networks for brain segmentation from 3d mr images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic image segmentation with task-specific edge detection using cnns and a discriminatively trained domain transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>I?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>3d u-</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Anatomical priors in convolutional networks for unsupervised biomedical segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">3d deeply supervised network for automatic liver segmentation from ct volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Multi-organ segmentation using deeds, selfsimilarity context and joint fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Heinrich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient multi-scale 3d cnn with fully connected crf for accurate brain lesion segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">F</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Kane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Constrained-cnn losses for weakly supervised segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kervadec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deep learning for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.02000</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scribblesup: Scribble-supervised convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3159" to="3167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Refinenet: Multipath refinement networks for high-resolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">D</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A survey on deep learning in medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A A</forename><surname>Setio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ciompi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghafoorian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">I</forename><surname>S?nchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="60" to="88" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An unsupervised learning method exploiting sequential output statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">V-net: Fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Ahmadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on 3D Vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Automatic lymph node cluster segmentation using holistically-nested neural networks and structured optimization in ct images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Nogues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bertasius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsehay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<editor>MIC-CAI</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Incorporating prior knowledge in medical image segmentation: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Nosrati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01092</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Anatomically constrained neural networks (acnns): application to cardiac image enhancement and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Oktay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>De Marvao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dawes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Oregan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Weakly-and semi-supervised learning of a dcnn for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Fully convolutional multi-class multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Ktena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rajchl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.06853</idno>
		<title level="m">Dltk: State of the art reference implementations for deep learning on medical images</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Object segmentation from bounding box annotations using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rajchl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Oktay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Passerat-Palmbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Damodaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<editor>MIC-CAI</editor>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deeporgan: Multi-level deep convolutional networks for automated pancreas segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Turkbey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Spatial aggregation of holisticallynested convolutional neural networks for automated pancreas localization and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical image analysis</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="94" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A multi-scale pyramid of 3d fully convolutional networks for abdominal multi-organ segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sugino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Misawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A large annotated medical image dataset for the development and evaluation of segmentation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Antonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bakas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bilello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Farahani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopp-Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Landman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Menze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09063</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semi supervised semantic segmentation using generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Souly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Normalized cut loss for weakly-supervised cnn segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Djelouah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schroers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1818" to="1827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On regularized losses for weakly-supervised cnn segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Djelouah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ben Ayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schroers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="507" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Abdominal multi-organ segmentation with organ-attention networks and statistical fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.08414</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Training multi-organ segmentation networks with sample selection by relaxed upper confident bound</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In MICCAI</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Tell me what you see and i will show you where it is</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3190" to="3197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Recurrent saliency transformation network: Incorporating multi-stage visual cues for small organ segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page" from="8280" to="8289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Deep adversarial networks for biomedical image segmentation utilizing unannotated images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fredericksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
		<editor>MIC-CAI</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Semi-supervised 3d abdominal multi-organ segmentation via deep multi-planar co-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="121" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A fixed-point model for pancreas segmentation in abdominal ct scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
