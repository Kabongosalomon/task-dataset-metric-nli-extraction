<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Document-level Event Extraction via Heterogeneous Graph-based Interaction Model with a Tracker</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runxin</forename><surname>Xu</surname></persName>
							<email>runxinxu@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="laboratory" key="lab2">MOE</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Liu</surname></persName>
							<email>tianyu0421@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="laboratory" key="lab2">MOE</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">ByteDance AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="laboratory" key="lab2">MOE</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Document-level Event Extraction via Heterogeneous Graph-based Interaction Model with a Tracker</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Document-level event extraction aims to recognize event information from a whole piece of article. Existing methods are not effective due to two challenges of this task: a) the target event arguments are scattered across sentences; b) the correlation among events in a document is non-trivial to model. In this paper, we propose Heterogeneous Graph-based</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Event Extraction (EE) is one of the key and challenging tasks in Information Extraction (IE), which aims to detect events and extract their arguments from the text. Most of the previous methods <ref type="bibr" target="#b1">(Chen et al., 2015;</ref><ref type="bibr" target="#b13">Nguyen et al., 2016;</ref><ref type="bibr" target="#b24">Yang et al., 2019;</ref><ref type="bibr" target="#b5">Du and Cardie, 2020b)</ref> focus on sentence-level EE, extracting events from a single sentence. The sentence-level model, however, fails to extract events whose arguments locate in different sentences, which is much more common in real-world scenarios. Hence, extracting events at the document-level is critical and has attracted much attention recently <ref type="bibr" target="#b3">Du and Cardie, 2020a;</ref><ref type="bibr" target="#b6">Du et al., 2020)</ref>. Though promising, document-level EE still faces two critical challenges. Firstly, the arguments of an event record may scatter across sentences, which requires a comprehensive understanding of the cross-sentence context. <ref type="figure">Figure 1</ref> illustrates an example that one Equity Underweight (EU) and one Equity Overweight (EO) event records are extracted from a financial document. It is less challenging to extract the EU event because all the related arguments appear in the same sentence (Sentence 2). However, for the arguments of EO record, Nov 6, 2014 appears in Sentence 1 and 2 while Xiaoting Wu in Sentence 3 and 4. It would be quite challenging to identify such events without considering global interactions among sentences and entity mentions. Secondly, a document may express several correlated events simultaneously, and recognizing the interdependency among them is arXiv:2105.14924v1 [cs.CL] 31 May 2021 fundamental to successful extraction. As shown in <ref type="figure">Figure 1</ref>, the two events are interdependent because they correspond to exactly the same transaction and therefore share the same StartDate. Effective modeling on such interdependency among the correlated events remains a key challenge in this task.  extracts events from a central sentence and query the neighboring sentences for missing arguments, which ignores the cross-sentence correspondence between augments. <ref type="bibr">Though Zheng et al. (2019)</ref> takes a first step to fuse the sentences and entities information via Transformer, they neglect the interdependency among events. Focusing on single event extraction, <ref type="bibr" target="#b3">Du and Cardie (2020a)</ref> and <ref type="bibr" target="#b6">Du et al. (2020)</ref> concatenate multiple sentences and only consider a single event, which lacks the ability to model multiple events scattered in a long document.</p><p>To tackle the aforementioned two challenges, in this paper, we propose a Heterogeneous Graphbased Interaction Model with a Tracker (GIT) for document-level EE. To deal with scattered arguments across sentences, we focus on the Global Interactions among sentences and entity mentions. Specifically, we construct a heterogeneous graph interaction network with mention nodes and sentence nodes, and model the interactions among them by four types of edges (i.e., sentence-sentence edge, sentence-mention edge, intra-mention-mention edge, and inter-mentionmention edge) in the graph neural network. In this way, GIT jointly models the entities and sentences in the document from a global perspective.</p><p>To facilitate the multi-event extraction, we target on the Global Interdependency among correlated events. Concretely we propose a Tracker module to continually tracks the extracted event records with a global memory. In this way, the model is encouraged to incorporate the interdependency with other correlated event records while predicting.</p><p>We summarize our contributions as follows:</p><p>? We construct a heterogeneous graph interaction network for document-level EE. With different heterogeneous edges, the model could capture the global context for the scattered event arguments across different sentences.</p><p>? We introduce a novel Tracker module to track the extracted event records. The Tracker eases the difficulty of extracting correlated events, as interdependency among events would be taken into consideration.</p><p>? Experiments show GIT outperforms the previous state-of-the-art model by 2.8 F1 on the large-scale public dataset  with 32, 040 documents, especially on crosssentence events and multiple events scenarios (with 3.7 and 4.9 absolute increase on F1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>We first clarify some important notions. a) entity mention: a text span within document that refers to an entity object; b) event argument: an entity playing a specific event role. Event roles are predefined for each event type; c) event record: an entry of a specific event type containing arguments for different roles in the event. For simplicity, we use record for short in the following sections. Following , given a document composed of sentences D = {s i } |D| i=1 and a sentence containing a sequence of words s i = {w j } |s i | j=1 , the task aims to handle three sub-tasks : 1) entity extraction:</p><formula xml:id="formula_0">extracting entities E = {e i } |E| i=1</formula><p>from the document to serve as argument candidates. An entity may have multiple mentions across the document. 2) event types detection: detecting specific event types that are expressed by the document. 3) event records extraction: finding appropriate arguments for the expressed events from entities, which is the most challenging and also the focus of our paper. The task does not require to identify event triggers <ref type="bibr" target="#b25">(Zeng et al., 2018;</ref><ref type="bibr" target="#b10">Liu et al., 2019b)</ref>, which reduces manual effort of annotation and the application scenarios becomes more extensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>As shows in <ref type="figure" target="#fig_0">Figure 2</ref>, GIT first extracts candidate entities through sentence-level neural extractor (Sec 3.1). Then we construct a heterogeneous graph to model the interactions among sentences and entity mentions (Sec 3.2), and detect event types expressed by the document (Sec 3.3). Finally we introduce a Tracker module to continuously track all the records with global memory, in which we utilize the global interdependency among records for multi-event extraction (Sec 3.4).  former <ref type="bibr" target="#b17">(Vaswani et al., 2017)</ref>:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Entity Extraction</head><formula xml:id="formula_1">{g 1 , . . . , g |s| } = Transformer({w 1 , . . . , w |s| })</formula><p>The word representation of w j is a sum of the corresponding token and position embeddings.</p><p>We extract entities at the sentence level and formulate it as a sequence tagging task with BIO (Begin, Inside, Other) schema. We leverage a conditional random field (CRF) layer to identify entities. For training, we minimize the following loss:</p><formula xml:id="formula_2">L ner = ? s?D log P (y s |s)<label>(1)</label></formula><p>where y s is the golden label sequence of s. For inference, we use Viterbi algorithm to decode the label sequence with the maximum probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Heterogeneous Graph Interaction Network</head><p>An event may span multiple sentences in the document, which means its corresponding entity mentions may also scatter across different sentences. Identifying and modeling these entity mentions in the cross-sentence context is fundamental in document EE. Thus we build a heterogeneous graph G which contains entity mention nodes and sentence nodes in the document D. In the graph G, interactions among multiple entity mentions and sentences can be explicitly modeled. For each entity mention node e, we initialize node embedding h To capture the interactions among sentences and mentions, we introduce four types of edges.</p><p>Sentence-Sentence Edge (S-S) Sentence nodes are fully connected to each other with S-S edges. In this way, we can easily capture the global properties in the document with sentence-level interactions, e.g., the long range dependency between any two separate sentences in the document would be modeled efficiently with S-S edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence-Mention Edge (S-M)</head><p>We model the local context of an entity mention in a specific sentence with S-M edge, specifically the edge connecting the mention node and the sentence node it belongs to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intra-Mention-Mention Edge (M-M intra )</head><p>We connect distinct entity mentions in the same sentences with M-M intra edges. The co-occurrence of mentions in a sentence indicates those mentions are likely to be involved in the same event. We explicitly model this indication by M-M intra edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inter-Mention-Mention Edge (M-M inter )</head><p>The entity mentions that corresponds to the same entity are fully connected with each other by M-M inter edges. As in document EE, an entity usually corresponds to multiple mentions across sentences, we thus use M-M inter edge to track all the appearances of a specific entity, which facilitates the long distance event extraction from a global perspective.</p><p>In Section. 4.5, experiments show that all of these four kinds of edges play an important role in event detection, and the performance would decrease without any of them.</p><p>After heterogeneous graph construction * , we apply multi-layer Graph Convolution Network (Kipf and Welling, 2017) to model the global interactions. Given node u at the l-th layer, the graph convolutional operation is defined as follows:</p><formula xml:id="formula_3">h (l+1) u = ReLU ? ? k?K v?N k (u) {u} 1 c u,k W (l) k h (l) v ? ? where K represents different types of edges, W (l) k ? R dm?dm is trainable parameters. N k (u)</formula><p>denotes the neighbors for node u connected in k-th type edge and c u,k is a normalization constant. We then derive the final hidden state h u for node u,</p><formula xml:id="formula_4">h u = W a [h (0) u ; h (1) u ; . . . ; h (L) u ] where h (0)</formula><p>u is the initial node embedding of node u, and L is the number of GCN layers.</p><p>Finally, we obtain the sentence embedding matrix S = [h 1 h 2 . . . h |D| ] ? R dm?|D| and entity embedding matrix E ? R dm?|E| . The i-th entity may have many mentions, where we simply use string matching to detect entity coreference following  , and the entity embedding E i is computed by the average of its mention node embedding, E i = Mean({h j } j?Mention(i) ). In this way, the sentences and entities are interactively represented in a context-aware way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Event Types Detection</head><p>Since a document can express events of different types, we formulate the task as a multi-label classification and leverage sentences feature matrix S to * Traditional methods in sentence-level EE also utilize graph to extract events <ref type="bibr" target="#b21">Yan et al., 2019)</ref>, based on the dependency tree. However, our interaction graph is heterogeneous and have no demands for dependency tree.  detect event types:</p><formula xml:id="formula_5">A = MultiHead(Q, S, S) ? R dm?T R = Sigmoid(A W t ) ? R T</formula><p>where Q ? R dm?T and W t ? R dm are trainable parameters, and T denotes the number of possible event types. MultiHead refers to the standard multi-head attention mechanism with Query/Key/Value. Therefore, we derive the event types detection loss with golden label R ? R T :</p><formula xml:id="formula_6">L detect = ? T t=1 I R t = 1 log P (R t |D) + I R t = 0 log (1 ? P (R t |D))<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Event Records Extraction</head><p>Since a document is likely to express multiple event records and the number of records cannot be known in advance, we decode records by expanding a tree orderly as previous methods did . However, they treat each record independently. Instead, to incorporate the interdependency among event records, we propose a Tracker module, which improves the model performance.</p><p>To be self-contained, we introduce the ordered tree expanding in this paragraph. In each step, we extract event records of a specific event type. The arguments extraction order is predefined so that the extraction is modeled as a constrained tree expanding task ? . Taking Equity Freeze records as an example, as shown in <ref type="figure">Figure 3</ref>, we firstly extract EquityHolder, followed by FrozeShares and others. Starting from a virtual root node, the tree expands by predicting arguments in a sequential order. As there may exist multiple eligible entities for the event argument role, the current node will expand several branches during extraction, with different entities assigned to the current role. This branching operation is formulated as multi-label classification task. In this way, each path from the root node to the leaf node is identified as a unique event record.</p><p>Interdependency exists extensively among different event records. For example, as shown in <ref type="figure">Figure 1</ref>, an Equity Underweight event record is closely related to an Equity Overweight event record, and they may share some key arguments or provide useful reasoning information. To take advantage of such interdependency, we propose a novel Tracker module inspired by memory network <ref type="bibr" target="#b20">(Weston et al., 2015)</ref>. Intuitively, the Tracker continually tracks the extracted records on-the-fly and store the information into a global memory. When predicting arguments for current record, the model will query the global memory and therefore make use of useful interdependency information of other records.</p><p>In detail, for the i-th record path consisting of a sequence of entities, the Tracker encodes the corresponding entity representation sequence U i = [E i1 , E i2 , ...] into an vector G i with an LSTM (last hidden state) and add event type embedding. Then the compressed record information is stored in the global memory G, which is shared across different event types as shown in <ref type="figure">Figure 3</ref>. For extraction, given a record path U i ? R dm?(J?1) with the first J ? 1 arguments roles, we predict the J-th role by injecting role-specific information into entity representations, E = E + Role J , where Role J is the role embedding for the J-th role. Then we concatenate E, sentences feature S, current entities path U i , and the global memory G, followed by a transformer to obtain new entity feature matrix E ? R dm?|E| , which contains global role-specific ? We simply adopt the order used by  information for all entity candidates. ?</p><formula xml:id="formula_7">[ E, S, U i , G] = Transformer([E; S; U i ; G])</formula><p>We treat the path expansion as a multi-label classification problem with a binary classifier over E i , i.e., predicts whether the i-th entity is the next argument role for the current record and expand the path accordingly as shown in <ref type="figure">Figure 3</ref>.</p><p>During training, we minimize the following loss:</p><formula xml:id="formula_8">L record = ? n?N D |E| t=1 log P (y n t |n)<label>(3)</label></formula><p>where N D denotes the nodes set in the event records tree, and y n t is the golden label. If the t-th entity is validate for the next argument in node n, then y n t = 1, otherwise y n t = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Training</head><p>We sum the losses coming from three sub-tasks with different weight respectively in Eq. <ref type="formula" target="#formula_2">(1)</ref>, <ref type="formula" target="#formula_6">(2)</ref> and <ref type="formula" target="#formula_8">(3)</ref> as follows:</p><formula xml:id="formula_9">L all = ? 1 L ner + ? 2 L detect + ? 3 L record</formula><p>More training details are shown in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We evaluate our model on a public dataset proposed by    <ref type="table">Table 1</ref>: F1 scores on test set. GIT achieves the best performance. We also list the results reported in  in Appendix B, and GIT consistently outperforms other baselines. EF/ER/EU/EO/EP refer to specific event types, and Overall denotes micro F1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments Setting</head><p>In our implementation of GIT, we use 8 and 4 layers Transformer <ref type="bibr" target="#b17">(Vaswani et al., 2017)</ref> in encoding and decoding module respectively. The dimensions in hidden layers and feed-forward layers are the same as previous work , i.e., 768 and 1, 024. We also use L = 3 layers of GCN, and set dropout rate to 0.1, batch size to 64. GIT is trained using Adam (Kingma and Ba, 2015) as optimizer with 1e ? 4 learning rate for 100 epochs. We set ? 1 = 0.05, ? 2 = ? 3 = 1 for the loss function. Three sub-tasks of the document-level EE are all evaluated by F1 score. Due to limited space, we leave the results of entity extraction and event types detection in Appendix B, which shows GIT only slightly outperform Doc2EDAG, because we mainly focus on event record extraction and the methods are similar to Doc2EDAG for these two sub-tasks. In the following, we mainly report and analyze the results of event record extraction.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines and Metrics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Main Results</head><p>Overall performance. The results of the overall performance on the document-level EE dataset is illustrated in <ref type="table">Table 1</ref>. As <ref type="table">Table 1</ref> shows, our GIT consistently outperforms other baselines, thanks to better modelling of global interactions and interdependency. Specifically, GIT improves 2.8 micro F1 compared with the previous state-of-the-art, Doc2EDAG, especially 4.5 improvement in Equity Underweight (EU) event type. Cross-sentence records scenario. There are more than 99.5% records of the test set are crosssentence event records, and the extraction becomes gradually more difficult as the number of their involved sentences grows. To verifies the effectiveness of GIT to capture cross-sentence information, we first calculate the average number of sentences that the records involve for each document, and sort them in ascending order. Then we divide them into four sets I/II/III/IV with equal size. Documents in Set. IV is considered to be the most challenging as it requires the most number of sentences to successfully extract records. As <ref type="table" target="#tab_4">Table 2</ref> shows, GIT consistently outperforms Doc2EDAG, especially on the most challenging Set. IV that involves the most sentences, by 3.7 F1 score. It suggests that GIT can well capture global context and mitigate the arguments-scattering challenge, with the help of the heterogeneous graph interaction network.</p><p>Multiple records scenario. GIT introduces the tracker to make use of global interdependency among event records, which is important in multiple records scenario. To illustrate its effectiveness, we divide the test set into single-record set (S.) containing documents with one record, and multi-record set (M.) containing those with multiple records. As shown in <ref type="table">Table.</ref> 3, F1 score on M.      is much lower than that on S., indicating it is challenging to extract multiple records. However, GIT still surpasses other strong baselines by 4.9 ? 35.3 on multi-record set (M.). This is because GIT is aware of other records through the T racker module, and leverage the interdependency information to improve the performance ? . ? <ref type="bibr" target="#b13">Nguyen et al. (2016)</ref> maintain three binary matrices to memorize entities and events states. Although they aim at sentence-level EE that contains fewer entities and event records, it would be also interesting to compare with them and we leave it as future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Analysis</head><p>We conduct further experiments to analyze the key modules in GIT more deeply.</p><p>On the effect of heterogeneous graph interaction network. The heterogeneous graph we constructed contains four types of edges. To explore their functions, we remove one type of edges at a time, and remove the whole graph network finally. Results are shown in <ref type="table" target="#tab_7">Table 4</ref>, including micro F1 and F1 on the four sets, which are divided by the number of involved sentences for records as we did before. The micro F1 would decreases 1.0 ? 1.4 without a certainty type of edge. Besides, removing the whole graph causes an significant drop by 2.0 F1, especially for Set IV by 2.5, which requires the most number of sentences to extract the event record. It demonstrates that the graph interaction network helps improve the performance, especially on records involving many sentences, and all kinds of edges play an important role for extraction.</p><p>On the effect of Tracker module. GIT can leverage interdependency among records based on the information of other event records tracked by Tracker. To explore its effect, firstly, we remove the global interdependency information between records of different event types, by clearing the global memory whenever we extract events for an-? [5] The shareholder of the company, Quanlie Chen, pledged 52.4 million to GDZQ Co., Ltd. in 2018, and supplemented the pledge recently because of the decline of the share price. ? [7] Since the borrowings have been paid off, Quanlie Chen completed the pledge cancellation procedures of 35.5 million that were pledged to GTJA Co., Ltd. on <ref type="bibr">Nov 7, 2018</ref>  other new event type (GIT-Own Type). Next, we remove all the tracking information except the own path for a record, to explore whether the tracking of other records makes effect indeed (GIT-Own Path). Finally, we remove the whole Tracker module (GIT-No Tracker). As <ref type="table" target="#tab_8">Table 5</ref> shows, the F1 in GIT-OT/GIT-OP decreases by 0.5/1.2, suggesting the interdependency among records of both the same and different event types do play an essential role. Besides, their F1 decrease in M. by 0.7/1.5 are more than those in S. by 0.8/1.0, verifying the effectiveness of the Tracker in multi-event scenarios. Moreover, the performances are similar between GIT-OP and GIT-NT, which also provides evidence that other records do help. We also reveal F1 on documents with different number of records in <ref type="figure" target="#fig_6">Figure 4</ref>. The gap between models with or without Tracker raises as the number of records increases, which validates the effectiveness of our Tracker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Case Study</head><p>Figure 5 demonstrates a case of the predictions of Doc2EDAG and GIT for Equity Pledge (EP) event types. The TotalHoldingShares and TotalPledged-Shares information lies in Sentence 8, while the PledgedShares and Pledgee information for Record 2 lies in Sentence 5. Though Doc2EDAG fails to extract these arguments in Record 2 (colored in red), GIT succeeds because it can capture interactions between long-distance sentences, and utilize the information of Record 1 (325.4 million and 218.6 million) thanks to the Tracker model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Sentence-level Event Extraction. Previous approaches mainly focus on sentence-level event extraction. <ref type="bibr" target="#b1">Chen et al. (2015)</ref> propose a neural pipeline model that identifies triggers first and then extracts argument roles. Nguyen et al. <ref type="formula" target="#formula_2">(2016)</ref> use a joint model to extract triggers and argument roles simultaneously. Some studies also utilize dependency tree information <ref type="bibr" target="#b21">Yan et al., 2019)</ref>. To utilize more knowledge, some studies leverage document context , pre-trained language model <ref type="bibr" target="#b24">(Yang et al., 2019)</ref>, and explicit external knowledge <ref type="bibr" target="#b9">(Liu et al., 2019a;</ref><ref type="bibr" target="#b16">Tong et al., 2020)</ref> such as WordNet <ref type="bibr" target="#b12">(Miller, 1995)</ref>. <ref type="bibr" target="#b5">Du and Cardie (2020b)</ref> also try to extract events in a Question-Answer way. These studies usually conduct experiments on sentencelevel event extraction dataset, ACE05 <ref type="bibr" target="#b18">(Walker et al., 2006)</ref>. However, it is hard for the sentence-level models to extract multiple qualified events spanning across sentences, which is more common in real-world scenarios.</p><p>Document-level Event Extraction. Documentlevel EE has attracted more and more attention recently. <ref type="bibr" target="#b22">Yang and Mitchell (2016)</ref> use well-defined features to handle the event-argument relations across sentences, which is, unfortunately, quite nontrivial.  extract events from a central sentence and find other arguments from neighboring sentences separately. Although  use Transformer to fuse sentences and entities, interdependency among events is neglected. <ref type="bibr" target="#b3">Du and Cardie (2020a)</ref> try to encode the sentences in a multi-granularity way and <ref type="bibr" target="#b6">Du et al. (2020)</ref> leverage a seq2seq model. They conduct experiments on MUC-4 <ref type="bibr" target="#b15">(Sundheim, 1992)</ref> dataset with 1, 700 documents and 5 kinds of entity-based arguments, and it is formulated as a table-filling task, coping with single event record of single event type. However, our work is different from these studies in that a) we utilize heterogeneous graph to model the global interactions among sentences and mentions to capture cross-sentence context, b) and we leverage the global interdependency through Tracker to extract multiple event records of multiple event types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Although promising in practical application, document-level EE still faces some challenges such as arguments-scattering phenomenon and multiple correlated events expressed by a single document. To tackle the challenges, we introduce Heterogeneous Graph-based Interaction Model with a Tracker (GIT). GIT uses a heterogeneous graph interaction network to model global interactions among sentences and entity mentions. GIT also uses a Tracker to track the extracted records to consider global interdependency during extraction. Experiments on large-scale public dataset  show GIT outperforms previous stateof-the-art by 2.8 F1. Further analysis verifies the effectiveness of GIT especially in cross-sentence events extraction and multi-event scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Training Details</head><p>To mitigate the error propagation due to the gap between training and inference phrase (i.e., the extracted entities are ground truth during training but predicted results during inference), we adopt scheduled sampling strategy <ref type="bibr" target="#b0">(Bengio et al., 2015)</ref> as  did. We gradually switch the entity extraction results from golden label to what the model predicts on its own. Specifically, from epoch 10 to epoch 20, we linearly increase the proportion of predicted entity results from 0% to 100%. We implement GIT under PyTorch <ref type="bibr" target="#b14">(Paszke et al., 2017)</ref> and DGL <ref type="bibr" target="#b19">(Wang et al., 2019)</ref> based on codes provided by .</p><p>All the experiments (including the baselines) are run with the same 8 Tesla-V100 GPUs and the same version of python dependencies to ensure the fairness.</p><p>Hyperparameters trials are listed in <ref type="table" target="#tab_11">Table 6</ref>. The value of hyperparameters we finally adopted are in bold. Note that we do not tune all the hyperparameters, and make little effort to select the best hyperparameters for our GIT.   <ref type="table">Table 7</ref>: Results of entity extraction sub-task on the test set. The performance of different models are similar, for the reason that they all utilize the same structure and methods to extract entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Evaluation Results</head><p>We have showed the evaluation results of event records extraction in the paper for document-level event extraction. In this section, we also illustate the results of entity extraction in <ref type="table">Table.</ref> 7 and event types detection in <ref type="table">Table.</ref> 8. Moreover, the comprehensive results of event record extraction is shown in <ref type="table">Table.</ref> 10, including results reported in  with precison, recall and F1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Complete Document for the Examples</head><p>We show an example document in <ref type="figure">Figure 1</ref> in the paper. To better illustrate, we translate it from Chinese into English and make some simplication.</p><p>Here we present the original complete document example in <ref type="figure" target="#fig_9">Figure 7</ref>. For the specific meanings of argument roles, we recommend readers to refer to .</p><p>We also demonstrate an case study in <ref type="figure">Figure 5</ref> in the paper. Now we also show its original Chinese version in <ref type="figure">Figure 6</ref>.        <ref type="figure">Figure 1</ref>. Sentences in red color are presented in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Overview of our GIT. Firstly, sentences of the document are fed into the encoder to obtain contextualized representation, followed by a CRF layer to extract entities. Then GIT constructs a heterogeneous graph interaction network with mention nodes and sentence nodes, which captures the global interactions among them based on GCNs. After obtaining document-aware representations of entities and sentences, GIT detects event types and extracts records through the decoding module with a Tracker. The Tracker tracks extracted records with global memory, based on which the decoding module incorporates global interdependency among correlated event records. Different entities are marked by different colors. M: Mingting Wu. X: Xiaoting Wu. N: Nov 6, 2014. S: 7.2 million.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>=</head><label></label><figDesc>Mean({g j } j?e ) by averaging the representation of the contained words. For each sentence node s, we initialize node embedding h (0) s = Max({g j } j?s ) + SentPos(s) by maxpooling all the representation of words within the sentence plus sentence position embedding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc> proposes DCFEE that extracts arguments from the identified central sentence and queries surrounding sentences for missing arguments. The model has two variants, DCFEE-S and DCFEE-M. DCFEE-S produces one record at a time, while DCFEE-M produces multiple possible argument combinations by the closest distance from the central sentence. Besides, Doc2EDAG uses transformer encoder to obtain sentence and entity embeddings, followed by another transformer to fuse cross-sentence context. Then multiple events are extracted simultaneously. Greedy-Dec is a variant of Doc2EDAG, which produces only one record greedily.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>M intra -1.3 -0.5 -1.4 -2.4 -1.5 -M-M inter -1.1 -0.5 -1.6 -1.4 -1.7 -Graph -2.0 -1.8 -1.5 -2.0 -2.5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>F1 scores on documents with different number of event records. The F1 gap between w/ (GIT) and w/o Tracker (GIT-NT) becomes wider as the number of event records of documents increases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>1 2Figure 5 :</head><label>15</label><figDesc>The case study of our proposed GIT and Doc2EDAG, with their key prediction difference colored in red. Related entities are colored in blue. GIT successfully extract TotalHoldingShares and TotalPledgedShares for Record 2, while Doc2EDAG fails. The complete content are provided in Appendix C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>The original complete document corresponding to the running example in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Given a sentence s = {w j } |s| j=1 ? D, we encode s into a sequence of vectors {g j }</figDesc><table><row><cell>[1] Mingting Wu decreased ... 7.2 million shares ... on Nov 6, 2014.</cell><cell>CRF layer</cell><cell>Decoding Module</cell><cell>Global Memory</cell></row><row><cell>[2] The 7.2 million shares ... Mingting Wu ? to Xiaoting Wu.</cell><cell>Encoder</cell><cell></cell><cell></cell></row><row><cell>[3] Xiaoting Wu is the daughter of Mingting Wu ?</cell><cell>Classifier</cell><cell cols="2">EntityPledge EntityFreeze EntityOverweight</cell></row><row><cell></cell><cell></cell><cell>?</cell><cell>?</cell></row><row><cell></cell><cell></cell><cell cols="2">|s i | j=1 using Trans-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Figure 3: The decoding module of GIT. Three Equity Freeze records have been extracted completely, and GIT is predicting the StartDate role for the Equity Pledge records (in the dashed frame ), based on the global memory where Tracker tracks the records on-the-fly. Both entity E and F are predicted as the legal StartDate role while A is not. Pre-defined argument roles are shown in the blue box, and GIT extracts records in this order. Capital letters (A-K) refer to different entities. A path from root to leaf node represents one unique event record.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Equity Overweight (EO) and Equity Pledge (EP), with 35 different kinds of argument roles in total. We follow the standard split of the dataset, 25, 632/3, 204/3, 204 documents for training/dev/test set. The dataset is quite challenging, as a document has 20 sentences and consists of 912 tokens on average. Besides, there are roughly 6 sentences involved for an event record, and 29% documents express multiple events.</figDesc><table><row><cell>Model</cell><cell>EF</cell><cell cols="2">ER EU EO EP Overall</cell></row><row><cell>DCFEE-S</cell><cell cols="2">46.7 80.0 47.5 46.7 56.1</cell><cell>60.3</cell></row><row><cell>DCFEE-M</cell><cell cols="2">42.7 73.3 45.8 44.6 53.8</cell><cell>56.6</cell></row><row><cell cols="3">Greedy-Dec 57.7 79.4 51.2 50.0 54.2</cell><cell>61.0</cell></row><row><cell cols="3">Doc2EDAG 71.0 88.4 69.8 73.5 74.8</cell><cell>77.5</cell></row><row><cell>GIT (ours)</cell><cell cols="2">73.4 90.8 74.3 76.3 77.7</cell><cell>80.3</cell></row></table><note>? , which is constructed from Chinese financial documents. It consists of up to 32, 040 documents which is the largest document- level EE dataset by far. It focuses on five event types: Equity Freeze (EF), Equity Repurchase (ER), Equity Underweight (EU),? To distinguish different parts in the concatenated vector, we also add segment embedding, which is omitted in Eq. 3.4.? https://github.com/dolphin-zs/ Doc2EDAG/blob/master/Data.zip</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: F1 scores on four sets with growing average</cell></row><row><cell>number of involved sentences for records (increases</cell></row><row><cell>from I to IV). The highest improvement of GIT comes</cell></row><row><cell>from event records involving the most sentences (Set</cell></row><row><cell>IV) by 3.7 F1 score compared with Doc2EDAG.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>38.1 83.0 55.5 52.3 41.4 49.2 43.6 62.4 52.2 69.0 50.3 DCFEE-M 45.3 40.5 76.1 50.6 48.3 43.1 45.7 43.3 58.1 51.2 63.2 49.4 Greedy-Dec 74.0 40.7 82.2 50.0 61.5 35.6 63.4 29.4 78.6 36.5 77.8 37.0 Doc2EDAG 79.7 63.3 90.4 70.7 74.7 63.3 76.1 70.2 84.3 69.3 81.0 67.4</figDesc><table><row><cell>Model</cell><cell>EF</cell><cell>ER</cell><cell>EU</cell><cell>EO</cell><cell>EP</cell><cell>Overall</cell></row><row><cell cols="7">DCFEE-S 55.7 GIT (ours) 81.9 65.9 93.0 71.7 82.0 64.1 80.9 70.6 85.0 73.5 87.6 72.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>F1 scores on single-record (S.) and multi-record (M.) sets.</figDesc><table><row><cell>Model</cell><cell>F1</cell><cell>I</cell><cell>II</cell><cell>III</cell><cell>IV</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>The decrease of F1 scores on ablation study for GIT's heterogeneous graph interaction network. Removing the heterogeneous graph leads to significant drop on F1, especially for records involving the most sentences (i.e., ?2.5 F1 on Set IV).</figDesc><table><row><cell>Model</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>S.</cell><cell>M.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Performance of GIT on ablation study for the T racker module. The removal of the Tracker (GIT-NT) brings about higher F1 decrease on M. than that on S.. S.: Single-record set, M.: Multi-record set.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>.[8] As of today, Quanlie Chen holds a total of 325.4 million of the company, and there are still 218.6 million in pledge status. ?</figDesc><table><row><cell></cell><cell>No.</cell><cell>Pledger</cell><cell>PledgedShares</cell><cell>Pledgee</cell><cell cols="2">TotalHoldingShares TotalPledgedShares</cell><cell>?</cell></row><row><cell>Doc2EDAG</cell><cell>1</cell><cell>Quanlie Chen</cell><cell>35.5 million</cell><cell>GTJA Co., Ltd.</cell><cell>325.4 million</cell><cell>218.6 million</cell><cell>?</cell></row><row><cell></cell><cell>2</cell><cell>Quanlie Chen</cell><cell>52.4 million</cell><cell>GDZQ Co., Ltd.</cell><cell>NULL</cell><cell>NULL</cell><cell>?</cell></row><row><cell></cell><cell>No.</cell><cell>Pledger</cell><cell>PledgedShares</cell><cell>Pledgee</cell><cell cols="2">TotalHoldingShares TotalPledgedShares</cell><cell>?</cell></row><row><cell>GIT</cell><cell></cell><cell>Quanlie Chen</cell><cell>35.5 million</cell><cell>GTJA Co., Ltd.</cell><cell>325.4 million</cell><cell>218.6 million</cell><cell>?</cell></row><row><cell></cell><cell></cell><cell>Quanlie Chen</cell><cell>52.4 million</cell><cell>GDZQ Co., Ltd.</cell><cell>325.4 million</cell><cell>218.6 million</cell><cell>?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Hyperparameters for our proposed GIT.We choose the final checkpoints for test according to the Micro F1 performance on the dev set.Table 9illustrates the best epoch in which the model achieves the highest Micro F1 on the dev set and their according F1 score.</figDesc><table><row><cell>Model</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>DCFEE-S</cell><cell cols="3">86.5 88.6 87.6</cell></row><row><cell>DCFEE-M</cell><cell cols="3">86.6 89.0 87.8</cell></row><row><cell cols="4">Greedy-Dec 87.5 89.8 88.6</cell></row><row><cell cols="4">Doc2EDAG 88.0 90.0 89.0</cell></row><row><cell>GIT (ours)</cell><cell cols="3">85.8 92.6 89.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>F1 scores results of event types detection sub-task on the test set. All the models obtains more than 90.0 micro F1 score. GIT slightly outperform Doc2EDAG.</figDesc><table><row><cell>Model</cell><cell cols="2">Best Epoch EF</cell><cell cols="2">ER EU EO EP Overall</cell></row><row><cell>DCFEE-S</cell><cell>86</cell><cell cols="2">51.3 73.0 44.1 51.4 58.6</cell><cell>58.7</cell></row><row><cell>DCFEE-M</cell><cell>87</cell><cell cols="2">52.5 69.1 43.9 47.2 55.9</cell><cell>55.8</cell></row><row><cell>Greedy-Dec</cell><cell>90</cell><cell cols="2">57.5 76.0 55.1 49.3 57.0</cell><cell>59.1</cell></row><row><cell>Doc2EDAG</cell><cell>89</cell><cell cols="2">75.2 85.2 71.6 80.0 77.9</cell><cell>78.7</cell></row><row><cell>GIT (ours)</cell><cell>89</cell><cell cols="2">78.3 87.6 74.7 80.9 79.8</cell><cell>80.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 9 :</head><label>9</label><figDesc>The best epoch in which the models achieve the highest micro F1 score on the dev set and the corresponding performance.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>8 56.1 67.7 54.4 60.3 DCFEE-M ? 44.6 40.9 42.7 75.2 71.5 73.3 51.4 41.4 45.8 42.8 46.7 44.6 55.3 52.4 53.8 58.1 55.2 56.6 Greedy-Dec ? 78.5 45.6 57.7 83.9 75.3 79.4 69.0 40.7 51.2 64.8 40.6 50.0 82.1 40.4 54.2 80.4 49.1 61.0 Doc2EDAG ? 78.7 64.7 71.0 90.0 86.8 88.4 80.4 61.6 69.8 77.2 70.1 73.5 76.7 73.0 74.8 80.3 75.0 77.5 GIT (ours) ? 78.9 68.5 73.4 92.3 89.2 90.8 83.9 66.6 74.3 80.7 72.3 76.3 78.6 76.9 77.7 82.3 78.4 80.3</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 10 :</head><label>10</label><figDesc>Comprehensive results of event record extraction. Results with ? are results reported in. Results with are ? results we implement on our own. Our GIT consistently outperform other baselines.</figDesc><table><row><cell cols="2">EquityUnderweight</cell><cell cols="2">EquityOverweight</cell></row><row><cell>EquityHolder</cell><cell>???</cell><cell>EquityHolder</cell><cell>???</cell></row><row><cell>TradedShares</cell><cell>720000?</cell><cell>TradedShares</cell><cell>720000?</cell></row><row><cell>StartDate</cell><cell>2014?11?6?</cell><cell>StartDate</cell><cell>2014?11?6?</cell></row><row><cell>EndDate</cell><cell>2014?11?6?</cell><cell>EndDate</cell><cell>2014?11?6?</cell></row><row><cell>LaterHolding Shares</cell><cell>NULL</cell><cell>LaterHolding Shares</cell><cell>720000?</cell></row><row><cell>AveragePrice</cell><cell>NULL</cell><cell>AveragePrice</cell><cell>NULL</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Changzhi Sun, Mingxuan Wang, and the anonymous reviewers for their thoughtful and constructive comments. This paper is supported in part by the National Key R&amp;D Program of China under Grand No.2018AAA0102003, the National Science Foundation of China under Grant No.61936012 and 61876004.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Scheduled sampling for sequence prediction with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the 28th International Conference on Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Event extraction via dynamic multipooling convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P15-1017</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Collective event detection via a hierarchical and bias tagging networks with gated multilevel attention mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yantao</forename><surname>Jia</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1158</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Document-level event role filler extraction using multi-granularity contextualized encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.714</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th</title>
		<meeting>the 58th</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Event extraction by answering (almost) natural questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Document-level event-based extraction using generative template-filling transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.09249</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploiting the ground-truth: An adversarial imitation based knowledge distillation approach for event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33016754</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 33rd AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Event detection without triggers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shulin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinpeng</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1080</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Jointly multiple events extraction via attentionbased graph information aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhunchen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heyan</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1156</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Wordnet: A lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1145/219717.219748</idno>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Joint event extraction via recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Thien Huu Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1034</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS-W</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Overview of the fourth Message Understanding Evaluation and Conference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><forename type="middle">M</forename><surname>Sundheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth Message Uunderstanding Conference</title>
		<imprint>
			<publisher>MUC</publisher>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving event detection via open-domain trigger knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meihan</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.522</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ace 2005 multilingual training corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Medero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihao</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mufei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qipeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Deep graph library: Towards efficient and scalable deep learning on graphs. ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Event detection with multi-order graph convolution and aggregated attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangbin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1582</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Joint extraction of events and entities within a document context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1033</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">DCFEE: A document-level Chinese financial event extraction system based on automatically labeled training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-4009</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploring pre-trained language models for event extraction and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linbo</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1522</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scale up event extraction learning via automatic training data generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongde</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Document embedding enhanced event detection with hierarchical and supervised attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2066</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Doc2EDAG: An end-to-end document-level framework for Chinese financial event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shun</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Bian</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1032</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>??????????(????&amp;quot;??&amp;quot;)??????????????????????????????</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>??????????????????</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>???????????????????????????????????????????????????? ????????</surname></persName>
		</author>
		<idno>?????2017-108)????????????????????????????????? ?????(?????2018-010?2018-013</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<title level="m">???????????????????????????????35500000?(???????1.35%)??? ?????????????2018?9?7??9?10?????????????????????????????? ????</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">1?????????????????????????(????)?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The original complete document corresponding to the case study in Figure 5</title>
	</analytic>
	<monogr>
		<title level="j">Figure</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
	<note>Sentences in red color are presented in Figure 5</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>?????300126</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>????</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2014" to="075" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>??????????????????????????????????????????? ?????</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>????????????(????&amp;quot;??</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2014" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<title level="m">?????????1????????????????????????????????? ??????????????????????????????</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
