<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ISyNet: Convolutional Neural Networks design for AI accelerator</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-08-22">August 22, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Letunovskiy</surname></persName>
							<email>letunovskiy.alexey@huawei.com</email>
							<affiliation key="aff0">
								<orgName type="department">Intelligent systems and Data science Technology center</orgName>
								<orgName type="institution">Huawei Technologies Co., Ltd Moscow</orgName>
								<address>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Korviakov</surname></persName>
							<email>korviakov.vladimir1@huawei.com</email>
							<affiliation key="aff0">
								<orgName type="department">Intelligent systems and Data science Technology center</orgName>
								<orgName type="institution">Huawei Technologies Co., Ltd Moscow</orgName>
								<address>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Polovnikov</surname></persName>
							<email>vladimir.polovnikov@math.msu.ru</email>
							<affiliation key="aff1">
								<orgName type="institution">Lomonosov Moscow State University</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasiia</forename><surname>Kargapoltseva</surname></persName>
							<email>nastyakargapoltseva1996@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Lomonosov Moscow State University</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Mazurenko</surname></persName>
							<email>mazurenko.ivan1@huawei.com</email>
							<affiliation key="aff0">
								<orgName type="department">Intelligent systems and Data science Technology center</orgName>
								<orgName type="institution">Huawei Technologies Co., Ltd Moscow</orgName>
								<address>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Lomonosov Moscow State University</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yepan</forename><surname>Xiong</surname></persName>
							<email>xiongyepan@huawei.com</email>
							<affiliation key="aff0">
								<orgName type="department">Intelligent systems and Data science Technology center</orgName>
								<orgName type="institution">Huawei Technologies Co., Ltd Moscow</orgName>
								<address>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ISyNet: Convolutional Neural Networks design for AI accelerator</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-08-22">August 22, 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years Deep Learning reached significant results in many practical problems, such as computer vision, natural language processing, speech recognition and many others. For many years the main goal of the research was to improve the quality of models, even if the complexity was impractically high. However, for the production solutions, which often require real-time work, the latency of the model plays a very important role. Current state-of-the-art architectures are found with neural architecture search (NAS) taking model complexity into account. However, designing of the search space suitable for specific hardware is still a challenging task. To address this problem we propose a measure of hardware efficiency of neural architecture search space -matrix efficiency measure (MEM); a search space comprising of hardware-efficient operations; a latency-aware scaling method; and ISyNet -a set of architectures designed to be fast on the specialized neural processing unit (NPU) hardware and accurate at the same time. We show the advantage of the designed architectures for the NPU devices on ImageNet <ref type="figure">(Figure 1</ref>) and the generalization ability for the downstream classification and detection tasks.</p><p>? NPU-efficient search space design having high MEM value; arXiv:2109.01932v2 [cs.CV]  </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Specialized neural processing unit (NPU) hardware was developed for fast neural network inference and training. The core feature of these devices is a design of highly optimized matrix multiplication unit, as the most computationally expensive operations -convolution and fully-connected layer -can be reduced to matrix multiplication. Speed of deep neural networks (DNN) inference and training on NPU devices depends not only on amount of matrix multiplication operations, but also on optimal data transfer and vector operations. To design a set of architectures fast for specific device and accurate at the same time a researcher needs to pass the following steps: find and construct a search space, adapt search method for the developed search space, decide how to take complexity of architectures into account. To address these issues we propose several steps, which make process of architectures search much easier. Our main contributions presented in this paper are:</p><p>? matrix efficiency measure (MEM) -novel measure for numerical evaluation of efficiency of DNN architectures and search spaces to the NPU hardware;</p><p>? NPU-efficient scaling algorithm that allows to scale architectures with respect to the latency on the target hardware;</p><p>? ISyNet -novel family of NPU-efficient architectures that provide optimal accuracy vs. latency trade-off and have strong generalization ability proven on various downstream datasets and computer vision tasks. We open-sourced ISyNet architectures in MindSpore Model Zoo. https://gitee.com/mindspore/models/tree/master/research/cv/ISyNet 2 Background and Related Art  Search of accurate and fast architectures for computer vision was a tricky work for a long time. VGGNet <ref type="bibr" target="#b39">[40]</ref> with 19 convolutional layers was proposed in 2014 and showed the benefit of constructing complex powerful models. ResNet <ref type="bibr" target="#b6">[7]</ref> architectures were proposed in 2015 to overcome the problem of training very deep networks. This work gave technology for successful training of architectures up to 200 layers with the help of residual connections. One of the first and still popular research works considering model complexity is a MobileNet architectures family <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b38">39]</ref>. Authors used depth-wise separable convolutions to build lightweight deep neural networks. NAS was developed to change paradigm of neural networks construction and automate the work of human researchers. NAS consists of 3 main parts: search space, search method and response function. The search space is defined as a subspace of all architectures limited by some manually defined constraints. The choice of the search space is a key point of NAS. However, it isn't deeply discussed in the literature. Typical search spaces are: hierarchical search space <ref type="bibr" target="#b42">[43]</ref> and cell-based search space <ref type="bibr" target="#b48">[49]</ref>. Main search methods are reinforcement learning (RL) <ref type="bibr" target="#b47">[48]</ref>, evolutionary algorithms (EA) <ref type="bibr" target="#b33">[34]</ref>, surrogate-model based optimization (SMBO) <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25]</ref> and one-shot approaches <ref type="bibr" target="#b22">[23]</ref>. RL, EA and SMBO are time consuming, but found architectures outperform to those found by one-shot method <ref type="bibr" target="#b35">[36]</ref>. As a response function authors typically use task-specific metrics (classification top1 accuracy, detection mAP and so on) possibly combined with complexity penalty <ref type="bibr" target="#b1">[2]</ref>.</p><p>Thanks to NAS, automatically constructed architectures became state-of-the-art first for small datasets such as CIFAR-10 <ref type="bibr" target="#b45">[46]</ref> and later for big datasets such as ImageNet <ref type="bibr" target="#b43">[44]</ref>. Platform-aware NAS <ref type="bibr" target="#b42">[43]</ref> allows to look for models with a good trade-off between the accuracy and the latency on the mobile devices. NAS requires a huge amount of computational resources, that's why it's computationally expensive to obtain architectures for all necessary complexity scenarios. To overcome this problem scaling methods are used <ref type="bibr" target="#b43">[44]</ref>. EfficientNet series of architectures obtained by NAS and scaled with compound scaling are now state-of-the-art on the ImageNet <ref type="bibr" target="#b30">[31]</ref>. While compound scaling considers FLOPS as a complexity measure of an architecture other researches show that total activations number in the model has stronger influence to the latency on the real hardware than the FLOPS <ref type="bibr" target="#b31">[32]</ref>. Authors of the EfficientNet-EdgeTPU <ref type="bibr" target="#b5">[6]</ref> models family designed to be efficient on the Google Edge TPU devices conclude that theoretical computation measures (MACs, FLOPS) are not an optimal proxy for the real latency and use special cycle-accurate performance simulator. In our work we use surrogate-model based optimization. This approach uses a surrogate modelf to approximate the response function f . This model is trained on meta-dataset which contains architecture descriptors and their response values gathered during the architecture search: H = {(? 1 , f (? 1 )), (? 2 , f (? 2 )), ...}. Generally, surrogate model is trained to minimize squared error:</p><formula xml:id="formula_0">L = (?, f (?))?H (f (?) ? f (?)) 2 .</formula><p>In practice very precise estimation is not necessary as long as surrogate provides a useful ranking to identify promising candidate. After candidate ? * is trained and evaluated corresponding meta instances (? * , f (? * ) are added to H and the surrogate model is updated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">NPU design and constraints</head><p>There exist a number of AI acceleration hardware (e.g. Google Cloud TPU <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b15">16]</ref>, NVidia Jetson <ref type="bibr" target="#b28">[29]</ref>, Huawei Ascend <ref type="bibr" target="#b11">[12]</ref>, Intel Movidius Myriad <ref type="bibr" target="#b12">[13]</ref>), and these devices set a constraints for the DNNs to be deployed. These devices are typically good at parallelizable tasks of tensor and matrix multiplications and additions as well as other operations commonly used in DNNs, such as activation functions and other element-wise operations. In our paper we consider the optimization for Ascend 310 NPU based on DaVinci architecture <ref type="bibr" target="#b10">[11]</ref>, however, our model can be implemented for any AI accelerators that support 2D convolution with non-square kernels. Example of an application for this platform can be found in <ref type="bibr" target="#b44">[45]</ref>.</p><p>The AI core is a main part of Ascend 310 NPU and it executes tensor and vector operations. Three main compute units of AI Core are: the cube unit, which performs the matrix multiplications, including the fully-connected layers and the convolutions; the vector unit which executes the vector operations like an element-wise sum of tensors, batch normalization <ref type="bibr" target="#b13">[14]</ref> and the activation functions; the scalar unit which is responsible for the scalar operations and controls the program flow and addressing.</p><p>The cube unit performs multiplication of two 16x16 float16 matrices or 16x32 and 32x16 int8 matrices at a time, and this is one of the most important constraint imposed by the design of the cube unit. Matrices of larger size are multiplied by parts. If a size of multiplied matrices is less than specified they will be padded by zeros. It is acceptable, but the highest cube unit utilization is reached for the matrices with a size divisible by 16 or 32 depending on the computation precision. The vector unit is responsible for the vector computations. It provides less computational power than the cube unit, but the capabilities of computations are more flexible. To process and store the data there are several storage units in AI core and in some scenarios data data buses may become a bottleneck.</p><p>What properties should an NPU-efficient neural architecture search space have?</p><p>? For all shapes of tensors (including weights and activations) that are processed by the Cube Unit divisibility by 16 (considering float16 precision) is preferable.</p><p>? Matrix operations are more preferable than vector operations and operations with data. Operations that could be reduced to matrix multiplication (e.g. Convolutions and Fully-connected layers) are preferable over operations that can be done on the Vector Unit only. The only exception is "operator fusion" mechanism that allows to fuse vector operations following matrix operation into one fused operation. An example of such efficient fusion is a sequence (Convolution ? BatchNorm ? Activation).</p><p>? When possible it is better to avoid an element-wise product, sum and permutation.</p><p>? Every operation in a computational graph requires input and output data to be transferred, which increases the total latency. Branched architectures like DenseNet <ref type="bibr" target="#b9">[10]</ref> or Inception <ref type="bibr" target="#b40">[41]</ref> should be avoided. Chain-like graph is preferable. The number of residual connections should be minimized.</p><p>? Lightweight activation functions (e.g. ReLU) are preferable over complex ones (e.g. Swish <ref type="bibr" target="#b32">[33]</ref>, Mish <ref type="bibr" target="#b26">[27]</ref> or GELU [8])</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Matrix Efficiency Measure</head><p>To evaluate efficiency of specific architectures and whole search spaces to NPU we propose a novel Matrix Efficiency Measure (MEM). Let us consider three most important sources of latency during neural networks inference: matrix operations, vector operations and data transfer (including input, output and weights). Scalar operations are negligible and not counted for simplicity. For each operation o i in Neural Network A we can define the following measures: m(o i ) -the number of matrix operations; v(o i ) -the number of vector operations. d(o i ) -the number of input, output data and weights of the operation. Matrix efficiency measure for architecture A = {o 1 , o 2 , . . . , o N } can be estimated as follows:</p><formula xml:id="formula_1">M EM (A) = w m ? N i=1 m(o i ) N i=1 (w m ? m(o i ) + w v ? v(o i ) + w d ? d(o i ))<label>(1)</label></formula><p>?A : M EM (A) ? [0; 1) and the closer M EM (A) to 1 the more efficient A to NPU design, because matrix operations are preferable over the others. For a specific design space D = {A 1 , A 2 , . . . , A K } mean matrix efficiency measure can be estimated as follows:</p><formula xml:id="formula_2">mM EM (D) = 1 K ? K j=1 M EM (A j );<label>(2)</label></formula><p>The closer mM EM (D) to 1 the more efficient whole design space D to NPU design.</p><p>To find values of w m , w v and w d we train the following linear regression model that approximates latency of architecture A:</p><formula xml:id="formula_3">lat(A) = w 0 + w m ? N i=1 m(o i ) + w v ? N i=1 v(o i ) + w d ? N i=1 d(o i )<label>(3)</label></formula><p>In our experiments we found that: w 0 = 0.773; w m = 2.57e?9;   However, BatchNorm and activation placed after convolution operation can be efficiently fused into one operator and do not result in significant slowdown at the inference stage. Elementwise addition and concatenation operations are widely used in residual blocks, which is essential for convergence of the model training. Thus, we can't avoid these blocks at all, but can use them flexibly, depending on real impact to the model properties.</p><formula xml:id="formula_4">w v = ?1.26e?8; w d = 3.</formula><formula xml:id="formula_5">1.5e+11 0 2.0e+7 9.6e?1 Conv3x3 5.4e+10 0 1.4e+7 9.2e?1 Conv7x1 4.2e+10 0 1.3e+7 9.0e?1 Conv5x1 2.3e+10 0 1.2e+7 8.8e?1 Conv3x1 1.8e+10 0 1.1e+7 8.2e?1 Conv1x1 6.0e+9 0 1.05e+7 6.2e?1 DepthW iseConv5x5 3.3e+8 0 1.01e+7 8.6e?2 DepthW iseConv3x3 1.2e+8 0 1.01e+7 3.2e?2 P ooling3x3 0 2.2e+7 1.1e+7 0 ReLU 0 6.5e+6 1.3e+7 0 ReLU 6 0 1.3e+7 1.3e+7 0 Swish 0 1.3e+7 1.3e+7 0 BatchN orm 0 5.2e+7 1.3e+7 0 ElementwiseAdd 0 6.5e+6 1.9e+7 0 Concatenation 0 0 2.6e+7 0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Search space design</head><p>To optimize architecture search we propose the search space, which incorporates only suitable for NPU operations and use flexible block length, width to add additional freedom in NAS. This search space is defined by the following set of rules:</p><p>? Model is divided into N S stages, N S ? [1, .., 6] is not fixed, but limited;</p><p>? Every stage s ? [1, ..., N S] is divided into blocks B s of identical structure. The number of blocks N B s ? <ref type="bibr">[1, .., 20]</ref> in each stage is not fixed, but limited;</p><p>? Every block B s is divided into four edges (E s,i ) each of them can be a convolution with kernel 1x1, 3x3, 5x5, 7x7, sequence of convolutions with non-square kernels 1x3+3x1, 1x5+5x1, 1x7+7x1 or an identity operation;</p><p>? Output of the block could be summed up with its input by a skip connection which is defined by the flag SK s ? [0, 1] for all blocks in the stage s;</p><p>? Each convolution edge has the follow-up normalization operation (BatchNorm) and coupled with an activation (ReLU)</p><p>? Last non-identity edge could be uncoupled with activation which is defined by flag LA s ? [0, 1] for all blocks in the stage s.</p><p>? The number of output channels of block B i is 2 3+i+CIs , where CI s ? [0, 2] is searched non-negative integer defined for all blocks in the stage s;</p><p>? The number of output channels for every intermediate (except the last one) edge of blocks in the stage s is multiplied by EF s -positive integer searched parameter;</p><p>? First block of stage differs from all others. It has stride 2 in the first non-identity edge and no skip connection Flexible block length and skip connections together with hardware-efficient operations make the proposed search space better for hardware-targeted NAS. Comparison of mMEM values for different search spaces are shown in the table 2. ISyNet space outperforms ResNet <ref type="bibr" target="#b6">[7]</ref>, MobileNetV2 <ref type="bibr" target="#b38">[39]</ref> and MNasNet <ref type="bibr" target="#b42">[43]</ref> search spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Search method</head><p>As it is shown in <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b5">6]</ref> FLOPS and MACs are not the best option to measure the complexity for the real hardware. In our work we use the accuracy and the latency surrogate models for efficient and more accurate search of the architectures and scaling. Overall scheme of ISyNAS, NPU-aware neural architecture search approach, is shown on the <ref type="figure" target="#fig_2">Figure 2</ref>. We use a surrogate model (SM) based optimization. To train SM we encode each architecture according to the proposed notation of search space design with following vector: </p><formula xml:id="formula_6">E = (N S, [V 1 , V 2 , ..., V N S ]),</formula><p>The value of E s,i ? [0, 7] is coded with following encoding: (conv1x1: 0, conv3x3: 1, conv5x5: 2, conv7x7: 3, conv1x3+conv3x1: 4, conv1x5+conv5x1: 5, conv1x7+conv7x1: 6, Identity: 7). If N S &lt; 6 encoding vector is padded with zeros. For SM we use LSTM architecture to process the encoded vector and apply fully-connected layer to the resulting embedding. We train two different SM for the accuracy and the latency. To train SM we collected dataset of 400 architectures trained on ImageNet and measured on Ascend 310 NPU with batch16.  We use following training procedure to collect dataset: SGD optimizer with momentum 0.9, 2 epochs warmup to maximum learning rate 0.4, 120 epochs with exponential learning rate decay, multiplying by 0.1 every 30 epochs, weight decay 0.0001, 8 NVidia V100 GPUs, total batch size 1024, O1 optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Scaling algorithm</head><p>Tan et al. <ref type="bibr" target="#b43">[44]</ref> proposed a method of compound architecture scaling which performs the small exhaustive search of the scaling parameters for width, depth and input resolution. For this purpose we select the parameters of architecture related to depth (N B s ) and width (EF s , CI s ) and measure their impact on the accuracy and the latency. We have empirically found that increase of parameters related to the depth provide better accuracy/latency trade-off, than increase of parameters related to width. Out result matches experimental results obtained in <ref type="bibr" target="#b18">[19]</ref>. Scaling of the input resolution affects only ImageNet performance, while does not affect the downstream tasks which are often use different resolution. Thus, we scale only depth of models and use the different scaling coefficients for the different stages. We use the latency as a scaling complexity function by carefully estimating latency of blocks. We perform the small brute-force search of scaling coefficients to find Pareto frontier of the scaled architectures. The comparison of our scaling method with the compound scaling is shown on the figure 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Architectures</head><p>Found ISyNet architectures are described in the table 3. Every architecture is defined by its stages. Stages are defined by block patterns and number of blocks (N B). Block patterns are defined by the list of operations, presence of last activation (LA) and skip connection (SK). Architectures N0, N1, N2, N3 are found by NAS, while N1-S1, N1-S2, N1-S3 are found by scaling method from architecture N 1. The process of the search took about 20000 GPU*hours which is comparable with the other approaches <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">ImageNet experiments</head><p>To train our models on ImageNet <ref type="bibr" target="#b37">[38]</ref> we use one server with 8 Ascend 910 NPUs and the following training setup: AdamW optimizer; 40 epochs warmup to maximum learning rate 0.001; 550 epochs with cosine learning rate decay, weight decay 0.05; batch size 1024 (128 per device); RandAugment <ref type="bibr" target="#b2">[3]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Transfer learning experiments</head><p>To verify generalization ability of ISyNet models we do the transfer learning experiments for the following downstream datasets and tasks: classification (CIFAR-10, CIFAR-100 <ref type="bibr" target="#b17">[18]</ref>, Caltech 101 <ref type="bibr" target="#b19">[20]</ref>, Flowers <ref type="bibr" target="#b27">[28]</ref>, Oxford-IIIT Pet <ref type="bibr">[</ref>   Stanford Cars <ref type="bibr" target="#b16">[17]</ref>, Food-101 <ref type="bibr" target="#b0">[1]</ref>) and object detection (Pascal VOC 2007 <ref type="bibr" target="#b3">[4]</ref>, as a backbone for YOLOv3 <ref type="bibr" target="#b34">[35]</ref>; MS COCO <ref type="bibr" target="#b20">[21]</ref>, as a backbone for Faster R-CNN <ref type="bibr" target="#b36">[37]</ref>). The details about experimental setup are presented in the supple-  In this paper we study the problem of efficiency of neural networks for NPU devices -specialized AI accelerators. To address the question of "NPU-efficiency" estimation we propose M EM -novel measure of matrix computations efficiency in Neural Networks. With the help of M EM we design the search space for our convolutional backbones and do Neural Architecture Search in this space. Finally, we propose ISyNet -the family of NPU-efficient convolutional backbones that outperform strong NPU-efficient baselines by a significant margin and prove good generalization properties of ISyNet on many Computer Vision datasets and tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Transfer learning experimental setup</head><p>For all classification tasks we used the following fine-tuning setup: SGD optimizer with momentum 0.9; learning rate 0.02; 300 epochs with exponential learning rate decay, multiplying it by 0.97 every 2.4 epochs; weight decay 0.0001; 8 NVidia V100 GPUs, total batch size 512; RandAugment augmentation policy; Exponential Moving Average of model weights with coefficient 0.9999. For the object detection on Pascal VOC with YOLOv3 we used the following setup: image size 608x608, batch size 64 per GPU, 2 NVidia V100 GPU, 52000 iterations of SGD optimizer starting with learning rate 0.0005. We change the learning rate to 0.0001, 0.0002, 0.0005, 0.001, 0.0001 and 0.00001 at steps 400, 700, 900, 1000, 40000 and 45000.</p><p>For the object detection on COCO with Faster R-CNN we used the following setup: image size 608x608, batch size 32 per GPU, 8 NVidia V100 GPU, 120000 iterations of SGD optimizer starting with learning rate 0.0001. We change the learning rate to 0.01, 0.001, 0.0001 at steps 5000, 60000 and 80000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Ablation study for the MEM model</head><p>To study the impact of the latency regression model to M EM value we trained several classic regression models to predict the latency based on the number of matrix operations, vector operations and amount of data transfer for each architecture. The results are presented in the table 6.</p><p>Let f is a regression model and A is an arbitrary architecture with number of matrix, vector and data transfer operations m(A), v(A) and d(A) respectively. Then</p><formula xml:id="formula_8">latency(A) = f (m(A), v(A), d(A))</formula><p>According to the table 6, all models show similar R 2 score and mean average percentage error (MAPE), but the linear regression model has better or equal quality of the prediction and has the interpretable coefficients which is more important for our study. Thus, we made a decision to use linear regression to estimate M EM . Note that we didn't consider such models as nearest neighbors regression and decision trees regression because these models weren't clearly interpretable in our task. It is important to note that values of M EM score for different architectures are consistent across different regression algorithms.  Dependency of latency on different types of operations is shown on the <ref type="figure" target="#fig_7">Figure 5</ref>. For some plots (e.g. latency vs. number of memory operations) near-linear dependency exists. For other plots linearity is not so clear, but the linear regression is still correspond to the maximal density of the data points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Ablation study for the training procedure</head><p>To investigate the impact of each training trick we sequentially disable them and train model ISyNet-N0. Results are shown in the table 7. We have found that the most beneficial tricks are BatchNorm after classifier's Fully Connected layer; Exponential Moving Averege <ref type="bibr" target="#b14">[15]</ref>  training for longer time with smooth decay of learning rate (we multiply it by 0.97 every 2.4 epochs similar to <ref type="bibr" target="#b42">[43]</ref>); All the listed tricks improve ISyNet-N3 by 4.69 top-1 ImageNet accuracy.   <ref type="table">Table 8</ref>: The impact of training tricks to the accuracy of ISyNet-N0. ML denotes mutual learning <ref type="bibr" target="#b46">[47]</ref>; RA denotes RandAugment <ref type="bibr" target="#b2">[3]</ref>; LBN denotes Batch Normalization <ref type="bibr" target="#b13">[14]</ref> after classifier's fully connected layer; LT denotes number of training epochs, where '-' is 90 epochs and '+' is 550 epochs;</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Accuracy/latency trade-off for different models on ImageNet. 'ISyNet-N' curve shows our models results; 'ResNet baseline' denotes original ResNet results; 'ResNet+' denotes original ResNet models trained with our training procedure; 'Mo-bileNetV2' and 'EfficientNet-EdgeTPU'<ref type="bibr" target="#b5">[6]</ref> curves denote original corresponding architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Overall scheme of ISyNAS -NPU-aware architectures search algorithm. Algorithm is based on 2 surrogate models (SM). One for accuracy and another for latency. After gathering meta-dataset of architectures and training SMs we sample architectures with limited latency and good estimation of accuracy. Meta-dataset updated and SMs retrained. Best found models scaled with scaling procedure and trained with long improved training procedure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>V</head><label></label><figDesc>s = (LA s , N B s , EF s , SK s , CI s , E s,0 , E s,1 , E s,2 , E s,3 ), s ? [1, ..., N S]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Accuracy/latency trade-off for our ISyNet scaling vs compound scaling. ISyNet scaling shows better results than the compound scaling due to heterogeneous stages scaling and targeting to the NPU latency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>augmentation policy; Deep Mutual Learning<ref type="bibr" target="#b46">[47]</ref> with larger model (for ISyNet models ISyNet-N3, for ResNet models ResNet-101), BatchNorm after the last fully-connected layer ("LastBN"), label smoothing. The ablation study for the listed tricks is presented in the supple-mentary materials. Training results are shown in the table 4 and Pareto frontiers are illustrated on the figure 1. For the fair comparison we train the ResNet models with our training procedure and they are presented in the table and figure as ResNet+. For the MobileNetV2 architectures our procedure does not bring an improvement and we use an original results. Latency of all resulting architectures are measured on the Ascend 310 NPU with batch size 16 and reduced to a single image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>on model parameters; Deep Mutual Learning with stronger peer model<ref type="bibr" target="#b46">[47]</ref>; and Dependency of latency on different types of operations. These plots show how the latency depends on the number of matrix, vector and data transfer operations. Additionally, we show the dependency between number of vector operations and data transfer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>36e?8. This model has mean absolute percentage error 12.54% and coefficient of determination 0.94 which is reasonable for such a simple model. Negative value of w v can be explained by the fact that m(o i ), v(o i ) and d(o i ) are not linearly independent.We used linear regression model because of its simplicity and interpretability. Ablation study for the latency models is presented in the supplementary materials.Table 1shows hardware efficiency of operations according to our model. Conv7x7, Conv5x5, Conv3x3, Conv1x1 and convolutions with non-squared kernel (7x1, 5x1, 3x1) show similar efficiency. Depthwise convolutions efficiency</figDesc><table><row><cell>Operation</cell><cell cols="4">#Matrix ops. #Vector ops. Data ops. MEM(op)</cell></row><row><cell>Conv7x7</cell><cell>2.9e+11</cell><cell>0</cell><cell>2.9e+7</cell><cell>9.7e?1</cell></row><row><cell>Conv5x5</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Averaged matrix, vector, data and M EM characteristics of different operations are less by one order. Operations which do not have matrix operations (poolings, activations, BatchNorms, addition and concatenation) are considered as non-efficient for NPU.</figDesc><table><row><cell>Design space</cell><cell cols="2">#arch mM EM</cell></row><row><cell>ResNet</cell><cell>1000</cell><cell>0.294</cell></row><row><cell>MobileNetV2</cell><cell>100</cell><cell>0.167</cell></row><row><cell>MNasNet</cell><cell>100</cell><cell>0.17</cell></row><row><cell cols="2">ISyNet-N (ours) 3800</cell><cell>0.378</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>mM EM of different design spaces. Average mM EM of proposed design space is better, then ResNet due to flexible block length and skip-connections. MobileNet and MNasNet search space mM EM is worse due to non-optimal NPU operations.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Specification of found architectures.</figDesc><table><row><cell>Model</cell><cell cols="5">Top-1 acc. Latency, ms. # Params, ?10 6 MACs, ?10 9 MEM</cell></row><row><cell>ISyNet-N0</cell><cell>75.03</cell><cell>0.43</cell><cell>9.59</cell><cell>1.13</cell><cell>0.214</cell></row><row><cell>ResNet-18+</cell><cell>74.3</cell><cell>0.63</cell><cell>11.69</cell><cell>2.28</cell><cell>0.439</cell></row><row><cell>ISyNet-N1</cell><cell>76.41</cell><cell>0.72</cell><cell>7.42</cell><cell>2.85</cell><cell>0.399</cell></row><row><cell>ISyNet-N1-S1</cell><cell>76.78</cell><cell>0.74</cell><cell>7.82</cell><cell>2.88</cell><cell>0.391</cell></row><row><cell>ISyNet-N1-S2</cell><cell>77.45</cell><cell>0.83</cell><cell>8.86</cell><cell>3.34</cell><cell>0.395</cell></row><row><cell>ISyNet-N1-S3</cell><cell>78.25</cell><cell>0.97</cell><cell>10.81</cell><cell>4.12</cell><cell>0.399</cell></row><row><cell>ResNet-34+</cell><cell>77.95</cell><cell>1.05</cell><cell>21.8</cell><cell>4.63</cell><cell>0.497</cell></row><row><cell>ISyNet-N2</cell><cell>79.07</cell><cell>1.1</cell><cell>19.43</cell><cell>4.93</cell><cell>0.351</cell></row><row><cell>ISyNet-N3</cell><cell>80.43</cell><cell>1.55</cell><cell>20.47</cell><cell>7.32</cell><cell>0.394</cell></row><row><cell>ResNet-50+</cell><cell>80.18</cell><cell>1.64</cell><cell>25.56</cell><cell>5.19</cell><cell>0.286</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>ISyNet performance results on ImageNet. Table shows, that ResNet-18 and ResNet-34 have very good MEM due to optimization of NPU devices to these specific architectures. In the same time average MEM of ResNet space has lower MEM according to table 2. It allow us to find architectures in our space, which outperform ResNets. We don't show results for other type of architectures like MobileNet, EfficientNet as they are non-efficient on NPU according to figure 1.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Results of transfer learning for different downstream tasks. Latency (in ms.) is plotted along the horizontal axis. Target metrics on the corresponding dataset are plotted along the vertical axis of each plot. Curves show stable improvement over ResNet architectures both for classification downstream datasets and as backbone for detection datasets. mentary materials. Results of transfer learning are presented in the Table 5 and illustrated on the Figure 4. We compare our models with the results of ResNet+ architectures trained with the same procedure as ISyNet. In most cases our architectures outperform results of ResNet which proves good generalization ability of the ISyNet. S1 97.86 85.73 95.74 97.95 92.35 92.59 88.40 78.40 38.0 ISyNet-N1-S2 98.05 85.91 95.74 98.21 92.65 92.83 88.59 78.94 38.4 ISyNet-N1-S3 97.88 86.23 96.03 98.36 93.57 92.86 89.06 79.13 39.4</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Flower 102</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Oxf rd-IIIT Pets</cell><cell></cell><cell></cell><cell>F d-101</cell></row><row><cell>99</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>93 94</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>90</cell></row><row><cell>98</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>92</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>88</cell></row><row><cell>97</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ResNet ISyNet</cell><cell>90 91</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ResNet ISyNet</cell><cell>86</cell><cell>ResNet ISyNet</cell></row><row><cell></cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1.0</cell><cell>1.2</cell><cell>1.4</cell><cell>1.6</cell><cell></cell><cell cols="6">0.4 0.6 0.8 1.0 1.2 1.4 1.6</cell><cell>0.4 0.6 0.8 1.0 1.2 1.4 1.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Stanf rd Cars</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">?ifar 10</cell><cell></cell><cell></cell><cell>?ifar 100</cell></row><row><cell>93 94</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>98.5 99.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>87</cell></row><row><cell>92</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>98.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>86</cell></row><row><cell>90 91</cell><cell cols="7">0.4 0.6 0.8 1.0 1.2 1.4 1.6 ResNet ISyNet</cell><cell>96.5 97.0 97.5</cell><cell cols="6">0.4 0.6 0.8 1.0 1.2 1.4 1.6 ResNet ISyNet</cell><cell>85 84</cell><cell>0.4 0.6 0.8 1.0 1.2 1.4 1.6 ResNet ISyNet</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Caltech-101</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">?OC2007</cell><cell></cell><cell></cell><cell>COCO</cell></row><row><cell>97</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>96</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.80</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.40</cell></row><row><cell>95</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ResNet</cell><cell>0.78</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ResNet</cell><cell>0.38</cell><cell>ResNet</cell></row><row><cell>94</cell><cell cols="7">0.4 0.6 0.8 1.0 1.2 1.4 1.6 ISyNet</cell><cell>0.76</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10</cell><cell>12</cell><cell>14 ISyNet</cell><cell>0.36</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10 ISyNet</cell></row><row><cell cols="6">Figure 4: Model</cell><cell></cell><cell>CIFAR-10</cell><cell cols="2">CIFAR-100</cell><cell>Caltech-101</cell><cell>Flowers</cell><cell></cell><cell>Oxford-IIIT Pet</cell><cell>Stanford Cars</cell><cell>Food-101</cell><cell>VOC 2007</cell><cell>COCO</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ISyNet-N0</cell><cell></cell><cell cols="9">97.55 84.31 95.05 97.55 90.31 90.58 85.39</cell><cell>76</cell><cell>36.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">ResNet-18+</cell><cell></cell><cell>97.35</cell><cell cols="2">83.9</cell><cell cols="6">94.92 97.19 91.39 90.28 85.89 76.54 35.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ISyNet-N1</cell><cell></cell><cell cols="9">97.92 85.27 95.44 97.97 91.86 92.68 88.16</cell><cell>78</cell><cell>37.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">ISyNet-N1-ResNet-34+</cell><cell></cell><cell cols="9">98.17 86.13 95.05 97.64 93.30 92.09 87.99 79.67 39.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ISyNet-N2</cell><cell></cell><cell cols="9">98.07 86.65 95.87 98.59 93.55 92.62 88.60 78.30 39.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ISyNet-N3</cell><cell></cell><cell>98.3</cell><cell cols="2">87.1</cell><cell cols="6">96.26 98.72 93.46 93.46 89.69 80.90 41.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">ResNet-50+</cell><cell></cell><cell cols="9">98.15 86.96 96.26 98.47 93.22 92.77 89.82 78.18 39.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>ISyNet transfer learning performance results on the downstream tasks</figDesc><table><row><cell>6 Conclusions</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Results of different latency prediction models. Linear Regression, Ridge Regression and Bayesian Ridge Regression models were used with default hyperparameters. SGD Regressor and Linear SVR models were used with squared epsilon insensitive loss, Orthogonal Matching Pursuit was used with number of nonzero coefficients is equal to 3.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>The impact of training tricks to the accuracy of ISyNet-N3. ML denotes mutual learning<ref type="bibr" target="#b46">[47]</ref>; RA denotes RandAugment<ref type="bibr" target="#b2">[3]</ref>; LBN denotes Batch Normalization<ref type="bibr" target="#b13">[14]</ref> after classifier's fully connected layer; LT denotes number of training epochs, where '-' is 90 epochs and '+' is 550 epochs; AW denotes AdamW optimizer<ref type="bibr" target="#b23">[24]</ref>; LS denotes Label Smoothing regularization<ref type="bibr" target="#b41">[42]</ref> </figDesc><table><row><cell>#</cell><cell cols="4">Tricks RA DML LT LBN</cell><cell>Top-1 Acc.</cell><cell>?</cell></row><row><cell>1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>68.89</cell><cell></cell></row><row><cell>2</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>+</cell><cell>71.59</cell><cell>+2.7</cell></row><row><cell>3</cell><cell>-</cell><cell>-</cell><cell>+</cell><cell>+</cell><cell>73.11</cell><cell>+1.52</cell></row><row><cell>4</cell><cell>-</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>75.11</cell><cell>+2.0</cell></row><row><cell>5</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>75.32</cell><cell>+0.21</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Food-101 -mining discriminative components with random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Bossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Comput Vis</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Google. Edge TPU</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Accelerator-aware neural network design using automl</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suyog</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berkin</forename><surname>Akin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Gaussian error linear units (gelus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Densely connected convolutional networks</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Da Vinci Architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huawei</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Ascend 310 AI Processor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huawei</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Intel Movidius Myriad? X Vision Processing Unit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Intel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML)</title>
		<meeting>the 32nd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Averaging weights leads to wider optima and better generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitrii</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timur</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A domain-specific architecture for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="50" to="59" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International IEEE Workshop on 3D Representation and Recognition</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Searching for fast model families on datacenter accelerators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqun</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="594" to="611" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Microsoft coco: Common objects in context</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia Li Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Darts: Differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Neural architecture optimization</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Matching pursuits with time-frequency dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Mish: A self regularized non-monotonic activation function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diganta</forename><surname>Misra</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automated flower classification over a large number of classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria-Elena</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Indian Conference on Computer Vision, Graphics and Image Processing</title>
		<imprint>
			<date type="published" when="2008-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Embedded Systems for Next-Generation Autonomous Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nvidia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cats and dogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<title level="m">Meta pseudo labels</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Kaiming He, and Piotr Doll?r. Designing network design spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilija</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><forename type="middle">Prateek</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Searching for activation functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Yolov3: An incremental improvement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A comprehensive survey of neural architecture search: Challenges and solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengzhen</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Tensor yard: One-shot algorithm of hardware-friendly tensor-train decomposition for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuar</forename><surname>Taskynov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Korviakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Mazurenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yepan</forename><surname>Xiong</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Sample-efficient neural architecture search by learning action space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Deep mutual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
