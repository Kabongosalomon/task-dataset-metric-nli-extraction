<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unbiased Teacher v2: Semi-supervised Object Detection for Anchor-free and Anchor-based Detectors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<addrLine>2 Meta</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Yao</forename><surname>Ma</surname></persName>
							<email>cyma@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<addrLine>2 Meta</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
							<email>zkira@gatech.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<addrLine>2 Meta</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unbiased Teacher v2: Semi-supervised Object Detection for Anchor-free and Anchor-based Detectors</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the recent development of Semi-Supervised Object Detection (SS-OD) techniques, object detectors can be improved by using a limited amount of labeled data and abundant unlabeled data. However, there are still two challenges that are not addressed: (1) there is no prior SS-OD work on anchor-free detectors, and (2) prior works are ineffective when pseudo-labeling bounding box regression. In this paper, we present Unbiased Teacher v2, which shows the generalization of SS-OD method to anchor-free detectors and also introduces Listen2Student mechanism for the unsupervised regression loss. Specifically, we first present a study examining the effectiveness of existing SS-OD methods on anchor-free detectors and find that they achieve much lower performance improvements under the semi-supervised setting. We also observe that box selection with centerness and the localization-based labeling used in anchor-free detectors cannot work well under the semi-supervised setting. On the other hand, our Listen2Student mechanism explicitly prevents misleading pseudo-labels in the training of bounding box regression; we specifically develop a novel pseudo-labeling selection mechanism based on the Teacher and Student's relative uncertainties. This idea contributes to favorable improvement in the regression branch in the semi-supervised setting. Our method, which works for both anchor-free and anchor-based methods, consistently performs favorably against the state-of-the-art methods in VOC, COCO-standard, and COCO-additional.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep learning models have achieved remarkable performance on object detection tasks in recent years, though the strong performance heavily relies on training a network with abundant images with human-annotated labels. To reduce the label supervision for training object detectors, Semi-Supervised Object Detection (SS-OD) methods have been proposed to leverage only limited labeled data but more abun-dant unlabeled data to improve performance <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b37">38]</ref>. Existing state-of-the-art SS-OD methods apply self-training techniques, which generate pseudo-labels and enforce the consistency between unlabeled data with different augmentations. Despite the significant improvement, there are still two remaining issues that are left untackled: <ref type="bibr" target="#b0">(1)</ref> there is no prior SS-OD work on anchor-free detectors and (2) prior works are ineffective in pseudo-labeling on the bounding box regression.</p><p>First, anchor-free detectors have been recently getting more attention in the community of object detection <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b41">42]</ref>, with the promise of achieving competitive accuracy, computational efficiency, and potential generalization to new datasets or environments <ref type="bibr" target="#b36">[37]</ref>. In spite of these advances, existing SS-OD works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26]</ref> mainly focus on anchor-based detectors (e.g., Faster-RCNN <ref type="bibr" target="#b20">[21]</ref> and SSD <ref type="bibr" target="#b18">[19]</ref>) but do not empirically verify their effectiveness on anchor-free detectors. In fact, when we adapt recent state-ofthe-art SS-OD methods to anchor-free detectors, we observe that, compared with its improvement on anchor-based models, the improvement is much smaller on anchor-free models (see <ref type="figure">Figure 1a</ref> and <ref type="table">Table 1</ref>). With extensive analysis provided in Section 3.2, we find that some advanced techniques performing favorably in the fully-supervised setting do not work in the semi-supervised setting with limited supervision. For example, the centerness score becomes unreliable for box selection under the semi-supervised setting, and the localization-based labeling method is not robust to the localization noise in pseudo-labels.</p><p>Second, following the Teacher-Student framework, the existing SS-OD works <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b37">38]</ref> apply an unsupervised regression loss with the pseudo-boxes generated from confidence thresholding (i.e., a threshold on the box score). However, we find that this approach inherits some potential issues that can be further addressed. For instance, (1) instead of using one single metric (e.g., box score or box IoU) to jointly represent the quality of four boundaries, the confidence/uncertainty of each boundary should be predicted individually; <ref type="bibr" target="#b1">(2)</ref> confidence in the classification branch might not be able to reflect the quality of boundary prediction on (a) (b) <ref type="figure">Figure 1</ref>. To improve the unsupervised regression loss, we propose (a) Listen2Student, which explicitly compares the prediction uncertainties between the Teacher and the Student and selects these instances where the teacher has lower uncertainty than the student. We then enforce the unsupervised regression loss on these selected regression pseudo-labels. (b) Anchor-free detectors are rapidly developed recently, while adapting the pseudo-labeling method on the anchor-free models results in less improvements compared with the anchor-based detectors. the regression branch. Instead, we propose to predict uncertainties on the regression branch to select pseudo-labels for boundary prediction; (3) Lastly, simply relying on Teacher's confidence/uncertainty prediction to select pseudo labels for regression cannot prevent misleading instances for the regression task. Instead, we propose to exploit the relative uncertainties between the Teacher and Student to select the boundary-level pseudo-labels, in which the Teacher has lower uncertainty than the Student. Integrating the three components, we propose Listen2Student to improve the unsupervised regression loss for the SS-OD tasks, as shown in <ref type="figure">Figure 1b</ref>.</p><p>We demonstrate that our proposed method achieves significant improvements compared to the state-of-the-art SS-OD methods when using both anchor-free and anchor-based detectors on several SS-OD benchmarks, including COCOstandard, COCO-additional, and VOC. We also provide ablation studies to examine the effectiveness of our Lis-ten2Student. We summarize the main contributions as follows:</p><p>? We show the generalization of our proposed semisupervised method on both anchor-based and anchorfree detectors. To the best of our knowledge, we are the first to examine the anchor-free models on SS-OD, and we identify core issues in applying SS-OD methods on anchor-free detectors.</p><p>? We explicitly remove misleading instances in regression pseudo-labels by considering relative uncertainty estimation from the Teacher and Student predictions. We provide analyses to verify effectiveness of our approach on anchor-free and anchor-based detectors.</p><p>? Based on our empirical study on anchor-free and anchor-based detectors, our method shows favorable improvements against the state-of-the-art methods. With the proposed method, we also bridge the performance gap between anchor-free and anchor-based detectors under the semi-supervised setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Anchor-Free Object Detectors. The development of deep learning models has resulted in significant improvements on object detection tasks. Existing object detectors consist of anchor-based detectors <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b31">32]</ref> and anchor-free detectors <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42]</ref>. Specifically, anchor-based detectors predict the box shift and scaling for the pre-defined anchor-boxes, and each predicted box is labeled according to its intersection-over-union (IoU) score to the ground-truth boxes. Based on label assignment (i.e., assign classification labels to predicted instances) and subsampling of foreground-background anchor boxes, the models are then trained to perform object detection. Despite remarkable results that have been achieved, applying anchorbased detectors on new datasets requires experts to tune hyper-parameters <ref type="bibr" target="#b9">[10]</ref> related to anchor-boxes, which limits the ability to adapt to new datasets or environments <ref type="bibr" target="#b36">[37]</ref>.</p><p>Alternatively, anchor-free models alleviate these concerns by removing the pre-defined anchor-boxes in detection models. For example, keypoint-based anchor-free detectors eliminated the need for designing a set of anchor boxes by representing a box as two corner points <ref type="bibr" target="#b12">[13]</ref>, a center point with four extreme points <ref type="bibr" target="#b39">[40]</ref>, and a center point with the box weight and height <ref type="bibr" target="#b38">[39]</ref>. Similarly, FCOS <ref type="bibr" target="#b28">[29]</ref> removed the pre-defined anchor-boxes and predicted a classification score, distances to four boundaries, and a centerness score for each pixel. Several works improved the performance of the anchor-free model by proposing an adaptive sample selection <ref type="bibr" target="#b36">[37]</ref>, jointly training the centerness and classification branches with soft-labels <ref type="bibr" target="#b15">[16]</ref>, soft-selecting the pyramid levels <ref type="bibr" target="#b40">[41]</ref>, and modeling the boundary uncertainty <ref type="bibr" target="#b14">[15]</ref>. In this paper, we use FCOS <ref type="bibr" target="#b28">[29]</ref> as our base anchor-free model, since it is publicly available and widely used in existing anchor-free models <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b40">41]</ref>.</p><p>Semi-Supervised Object Detection. Semi-supervised learning (SSL) for image classification has been rapidly developed and obtained promising results in recent years. Existing SSL image classification works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref> apply input augmentations/perturbations and consistency regularization on unlabeled images to improve the model trained with the limited amount of labeled data. Inspired by these works, several semi-supervised object detection works have been proposed to exploit similar ideas to train object detectors in a semi-supervised manner. For example, CSD <ref type="bibr" target="#b8">[9]</ref> apply a left-right consistency loss to enforce prediction consistency between horizontally flipped unlabeled images. Some other works <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b37">38]</ref> exploit pseudo-labeling, where a model iteratively generates the pseudo-labels of unlabeled data and add the confident predictions into the training data. STAC <ref type="bibr" target="#b25">[26]</ref> uses the limited amount of labeled data to train an object detector, which is used to generate the pseudo-labels for unlabeled data in an offline manner. To refine the quality of pseudo-labels, Instant-Teaching <ref type="bibr" target="#b37">[38]</ref> proposes a co-rectify scheme to rectify the false prediction between two identical but independently trained models. Humble Teacher <ref type="bibr" target="#b26">[27]</ref> applies exponential moving average (EMA) and soft pseudo-labels to improve against the model trained on labeled data only. Unbiased Teacher <ref type="bibr" target="#b19">[20]</ref> proposes to generate the pseudo-labels in an online fashion, and the quality of pseudo-labels is further improved by addressing the pseudo-labeling bias issue. Soft-Teacher <ref type="bibr" target="#b32">[33]</ref> proposes a simple background-weighted loss and box variance filter to improve performance against the supervised baselines. While they can improve the performance in the semi-supervised setting, existing works only present their results on anchor-based detectors. We are thus interested in investigating the generalization of the state-ofthe-art methods (i.e., pseudo-labeling) on anchor-free models and improving the performance of anchor-free models for semi-supervised object detection tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Background: Semi-supervised Object Detection and Pseudo-labeling</head><p>With the goal of learning an object detector in a semisupervised setting, we assume a set of labeled images <ref type="table">Table 1</ref>. Adaption of Unbiased Teacher <ref type="bibr" target="#b19">[20]</ref> to an anchor-free model. The performance is degraded when applying Unbiased Teacher on the anchor-free model (FCOS). <ref type="bibr">COCO</ref> </p><formula xml:id="formula_0">D s = {x s i , y s i } Ns i=1 and unlabeled images D u = {x u i } Nu i=1</formula><p>are available during training. In order to address semi-supervised object detection, existing works <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b37">38]</ref> exploit the pseudo-labeling method. Specifically, this line of works contains two stages: 1) The burn-in stage and 2) the mutual learning stage. In the burn-in stage, with the available labeled data, an initial object detector is trained with the standard supervised losses,</p><formula xml:id="formula_1">L sup = i L(x s i , y s i ).</formula><p>In the mutual learning stage, the pretrained object detector is duplicated into a Student and a Teacher model initially. Then, in each training iteration, the Teacher model takes the weakly-augmented unlabeled images as input and predicts the bounding boxes, and the instances with the box score higher than a threshold ? (i.e., confidence thresholding) are selected as the pseudo-labels.</p><p>Based on the pseudo-labels and the same unlabeled image but with a stronger augmentation, the unsupervised loss L unsup is computed and combined with the supervised loss L sup to train the Student model,</p><formula xml:id="formula_2">? s ? ? s + ? ?(Lsup+?uLunsup) ??s , where L unsup = i L(x u i ,? u i ).</formula><p>To refine the quality of the pseudo-labels, the Teacher model weight (? t ) can be further updated with the Student model weight (? s ) via Exponential Moving Average (EMA) as shown in <ref type="bibr" target="#b19">[20]</ref>.</p><p>Although the existing works <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b37">38]</ref> based on pseudolabeling have presented significant improvements on anchorbased detectors (i.e., Faster-RCNN), it is still unclear whether such a method is applicable to anchor-free detectors. This motivates us to investigate its generalization to anchorfree detectors, and we provide our findings and show that the state-of-the-art SS-OD method is not effective as it is mostly designed for anchor-based detectors (in Section 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pseudo-labeling on Anchor-Free Detectors</head><p>We take the widely used FCOS model <ref type="bibr" target="#b28">[29]</ref> as an example of anchor-free detector for studying SS-OD task. FCOS <ref type="bibr" target="#b28">[29]</ref> has three major prediction branches: 1) a classifier for performing object category classification, 2) a centerness branch for indicating the probability of being the center of foreground objects, and 3) a regressor for estimating the distances to the boundaries of an object. These models usually exploit fully convolutional layers and perform pixel-wise predictions. To train the model, all pixels inside the ground-truth boxes are labeled as foreground and the remaining pixels as background, and regression loss and centerness loss are only  <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b36">37]</ref> are defined as the multiplication of the centerness scores and the classification scores, and we find that (c) box scores of pseudoboxes is dominated by the centerness scores, which are unreliable in semi-supervised setting (see Appendix for further details). enforced in these foreground instances. For more details of anchor-free detectors, please refer to the FCOS paper <ref type="bibr" target="#b28">[29]</ref>. As shown in <ref type="figure">Figure 1b</ref> and <ref type="table">Table 1</ref>, we observe that simply applying the existing state-of-the-art SS-OD methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26]</ref> on anchor-free detectors obtains much smaller improvements compared with anchor-based detectors. We attribute this to the following two factors. Centerness bias issue. As presented in <ref type="figure" target="#fig_0">Figure 2b</ref> and Table 2, we notice that selecting the pseudo-boxes based on box scores performs worse than solely relying on classification scores in the semi-supervised setting, while FCOS <ref type="bibr" target="#b28">[29]</ref> shows using box scores leads to better results in the fullysupervised setting. We observed that this is because the box scores of some anchor-free detectors <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b36">37]</ref> are defined as the multiplication of classification scores and centerness scores (see <ref type="figure" target="#fig_0">Figure 2a</ref>), and the pseudo-boxes selected based on the box scores have relatively high centerness scores but low classification scores (see <ref type="figure" target="#fig_0">Figure 2c</ref>). This reveals that the box scores are dominated by the centerness scores in the pseudo-labeling mechanism. However, with the limited amount of labels used in the training, the centerness scores are not reliable for reflecting whether a prediction is a foreground instance since there is no supervision to suppress the centerness scores for background instances in the centerness branch <ref type="bibr" target="#b0">1</ref> . As a result, these selected high centerness pseudo- <ref type="bibr" target="#b0">1</ref> A similar observation was also made in Generalized Focal Loss <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>Foreground Pseudo-box</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Center-Sampling Localization-based Class. Label Standard</head><p>Precision: 0% Precision: 10% Precision: 32% Recall: 0%</p><p>Recall: 55% Recall: 10% (a) (b) <ref type="figure">Figure 3</ref>. Illustration of Unreliable label assignments. (a) Existing techniques for improving fully-supervised anchor-free detectors such as Center Sampling <ref type="bibr" target="#b28">[29]</ref> and localization-based classification labels <ref type="bibr" target="#b15">[16]</ref> are less robust to the localization noise (e.g., box center shifted) in pseudo-boxes, and the pixel-wise recall and precision of these two techniques are lower than the standard label assignment. Thus, (b) our empirical evaluation shows that the standard label assignment leads to a better result. boxes are likely to be the background instances, and adding these false-positive pseudo-boxes in the semi-supervised training degrades the effectiveness of the pseudo-labeling and also aggravates the centerness bias issue. Unreliable Label Assignment. To improve the performance of the fully-supervised anchor-free detector, several works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b38">39]</ref> proposed to use soft classification labels, which are weighted based on the bounding box localization as presented in <ref type="figure">Figure 3a</ref>. Similarly, FCOS <ref type="bibr" target="#b28">[29]</ref> also presented an advanced label assignment technique, centersampling, which regards the instances close to the center of the object as foreground instances and improves against the model using the standard label assignment that labels all instances insides ground-truth boxes as foreground and the remaining instances as background. Although the above techniques improve the anchor-free detectors during fullysupervised training, we found that they are not effective or even detrimental during semi-supervised training (see <ref type="figure">Figure 3b</ref> and <ref type="table" target="#tab_2">Table 3</ref>). We hypothesize that this is because the pseudo-boxes can have localization noise (either due to the center of the box being shifted or the box has incorrect width and height), and using center-sampling or the Localizationbased soft labels makes pixel-wise predictions incorrectly labeled as either foreground (false positive) or background (false negative). For instance, as shown in <ref type="figure">Figure 3</ref>, the precision and recall of center-sampling is much lower than standard for this particular example with reasonable amount of localization noise. To alleviate the centerness bias issue, we select the pseudo-boxes based on classification score only (and ignore the centerness score) in limited-supervision scenarios, since we empirically found that classification score is more reliable to represent the objectness of the predicted instances especially under limited supervision. In this way, the falsepositive pseudo-labels are less likely to impede the effectiveness of pseudo-labeling and thus improve the performance of pseudo-labeling. We also train the classifier with the hard labels (i.e., one-hot vector) rather than the soft labels with the box localization weighting. Finally, instead of using the center-sampling, we use the standard label assignment method, which labels all elements inside the bounding boxes as the foreground and the remaining as the background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Listen2Student for Unsupervised Regression Loss</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Limitations of confidence thresholding for regression</head><p>While confidence thresholding has been demonstrated to work well in classification (image-level <ref type="bibr" target="#b24">[25]</ref> or box-level <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b37">38]</ref>), we observed solely relying on the box confidence cannot effectively remove the misleading instances in the box regression, and there are several reasons why it does not perform favorably: (1) First, the confidence thresholding in existing works selects pseudo-boxes based on the box scores, which only reflect the confidence of object classification in Faster-RCNN <ref type="bibr" target="#b19">[20]</ref>, and there is no explicit module estimating the confidence (or uncertainty) of regression prediction, i.e., the regression branch only predicts the boundary location without any metric indicating localization uncertainty in vanilla object detectors. (2) Second, using one single score (e.g., centerness or IoU score) to jointly represent the quality of four predicted boundaries is not accurate, as it is hard to obtain a pseudo-box with four equally precise boundaries under the limited-supervision setting. <ref type="formula">(3)</ref> Lastly, unlike pseudo-labels for discrete object categories, the real-valued regression outputs are unbounded. Selecting pseudo-boxes solely based on the Teacher's confidence cannot explicitly prevent misleading instances in the pseudo label for regression, because the Teacher can still provide a regression direction that is contradictory to the ground-truth direction. Similar observations are also found in prior works in knowledge distillation for regression tasks <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b22">23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Listen2Student</head><p>To address the above concerns and improve the regression branch with the Teacher-Student mechanism, we aim to select the beneficial instances and remove misleading instances for the training of the regression branch. Intuitively, we develop a novel way to use relative prediction information between the Student and Teacher; to our knowledge this is the first instance of moving beyond using just the Teacher's prediction information. Specifically, as shown in <ref type="figure" target="#fig_1">Figure 4</ref>, the beneficial instance of boundary prediction is defined as: the instance that satisfies ||d t ?d g || ? ||d s ?d g ||, whered t is the Teacher's regression prediction,d s is the Student's regression prediction, and d g is the ground-truth regression label. As a comparison, the misleading instance of regression is expressed as the instance satisfying ||d t ? d g || &gt; ||d s ? d g ||.</p><p>Uncertainty prediction for regression. While we were hoping to use ground-truth labels d g to decide whether the predictions from the Teacher is better or not, in reality, the ground-truth labels are not available for SS-OD. Therefore, we propose to predict the localization uncertainty, which loosely correlates with the error to the ground-truth label (i.e., ||d t ? d g || and ||d s ? d g ||) for the unlabeled data. As shown in <ref type="figure" target="#fig_1">Figure 4</ref>, the localization uncertainty of each boundary prediction is derived by adding an additional branch, which has the same output size as the boundary distance regression branch. The localization uncertainty branch is jointly trained with the boundary distance branch, and we use the negative power log-likelihood loss (NPLL) <ref type="bibr" target="#b13">[14]</ref> 2 as the regression loss,</p><formula xml:id="formula_3">L sup reg = i ? i ( ( (d s ? d g ) 2 2? s 2 + 1 2 log ? s 2 ) + 2 log 2?),</formula><p>where ? i is the IoU score between the predicted box and the ground-truth box, and ? s is the predicted uncertainty of the Student.</p><p>Relative uncertainties for pseudo-label selection. With the uncertainty estimation, we first loosely remove the boundaries where student has very small localization uncertainty ? s ? ? s . We then propose a selection mechanism which explicitly takes not only the Teacher's localization uncertainty ? i t but also the Student's localization uncertainty ? i s into account for the pseudo-label selection. By selecting the beneficial instances where the Teacher has lower localization uncertainty than the Student with a margin ?, our unsupervised regression loss is thus defined as</p><formula xml:id="formula_4">L unsup reg = i ||d i t ?d i s ||, if ? i t + ? ? ? i s 0, otherwise ,<label>(1)</label></formula><p>where ? ? 0 is a margin between the localization uncertainties of Teacher and Student. Note that the unsupervised regression loss is computed in the boundary level rather than the box level, so some boundaries of a box are used to computed unsupervised regression loss while the others are not.</p><p>The core idea of this mechanism is that the Teacher should only guide the Student with the instances that the Teacher has lower uncertainty than the student, as it indicates that the Teacher has a potentially lower error. By contrast, for the instances, which the Teacher has higher uncertainty than the Student, we should not enforce the loss, as the Teacher is likely to predict worse than the Student and thus mislead the Student for these instances. Based on this selection mechanism, we can explicitly prevent gradients from misleading instances from degrading the performance of the regression branch. Our regression branch can thus gradually be refined and obtain more accurate boundary prediction. It is worth noting that the localization uncertainty branch is an individual branch and only used in the training stage, thus introducing no additional computation during inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Settings and Implementation Details</head><p>Experimental Settings. We follow the experimental settings presented in the existing semi-supervised object detection works <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26]</ref>. Specifically, we use MS-COCO <ref type="bibr" target="#b17">[18]</ref> and PASCAL VOC <ref type="bibr" target="#b3">[4]</ref> and examine our proposed method on three experimental scenarios, COCO-standard, COCOadditional, and VOC. For COCO-standard, we randomly sample 0.5, 1, 2, 5, and 10% labeled training data as our labeled set, and the remaining data as the unlabeled set. For COCO-additional, we use COCO2017-labeled as labeled set and COCO2017-unlabeled as the unlabeled set. We evaluate on COCO2017-val for both COCO-standard and COCOadditional as in previous works. As for VOC, VOC2007trainval is used as the labeled set, and VOC2012-trainval and COCO20cls are used as the unlabeled set. All trained models in VOC experiment are evaluated on VOC2007-test.</p><p>Model Architecture. In order to examine the effectiveness of anchor-free models for semi-supervised object detection, we chose FCOS <ref type="bibr" target="#b28">[29]</ref> as our base anchor-free models since it is widely adopted in existing anchor-free works <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b40">41]</ref>. As the existing works mainly focus on anchor-based models and use Faster-RCNN <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26]</ref> or SSD <ref type="bibr" target="#b8">[9]</ref>, we also adapt the existing SS-OD methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26]</ref> to the anchor-free model (e.g., FCOS). Implementation Details. Our implementation is based on Detectron2 <ref type="bibr" target="#b30">[31]</ref>. To train our model, we use SGD optimizer with the learning rate 0.01, and each batch contains 8 labeled images and 8 unlabeled images unless specified. We use the unsupervised loss weight ? u = 3.0 and classification threshold ? = 0.5, and we set ? = 0.1 as the margin between localization uncertainties of Teacher and Student and ? s = 0.5. We adapt the data augmentation used in Unbiased Teacher and applied the scale jittering used in SoftTeacher <ref type="bibr" target="#b32">[33]</ref> without using any geometric augmentation during training, as we empirically find that the scale jittering leads to a significant improvement. More details are listed in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results on Anchor-free Detector</head><p>COCO-standard. We adapt three anchor-based methods, CSD <ref type="bibr" target="#b8">[9]</ref>, STAC <ref type="bibr" target="#b25">[26]</ref>, and Unbiased Teacher <ref type="bibr" target="#b19">[20]</ref>, to the anchor-free models, and each method was ran five times and their means and variances are reported, as presented in <ref type="table">Table 4</ref>. Our model consistently performs favorably against the baseline methods under different degrees of supervision, and the improvement gap is larger when the level of supervision is lower. Our experiments on VOC and COCO-additional also result in a similar trend as well (see Appendix for experimental results).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results on Anchor-based Detector</head><p>In addition to the results on the anchor-free model, we are also interested whether our proposed method can generalize to different types of object detectors. Specifically, we apply our unsupervised regression loss on Unbiased Teacher and modify the regression branch to predict the localization uncertainty with an additional branch as we did in Section 3.3. We examine our Listen2Student on the Faster-RCNN for COCO-standard, VOC, and COCO-additional as follows.</p><p>COCO-standard. As presented in <ref type="table" target="#tab_4">Table 5</ref>, compared with the state-of-the-art SS-OD methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b32">33]</ref>, our method obtains higher mAP under the cases where 0.5% to 10% data are labeled. Under different batch sizes, we could maintain the improvement gap against existing SS-OD methods and further improve the performance to 35.08 mAP under COCO-standard 10% case. In addition, we also find that the performance gap between the anchor-free and anchorbased detectors is reduced by using our framework, and this verifies the generalization of our proposed Listen2Student to both anchor-free and anchor-based detectors.</p><p>VOC and COCO-additional. To verify whether our framework can improve the object detector trained with the unlabeled set, we also consider VOC in <ref type="table" target="#tab_5">Table 7</ref> and COCOadditional in <ref type="table" target="#tab_6">Table 8</ref>. With VOC07 used as the labeled set, our model can leverage VOC12 to achieve 56.87 mAP, and using VOC12+COCO20cls as the unlabeled set can further improve the model and achieve 58.08mAP. On the <ref type="table">Table 4</ref>. Experimental results of the anchor-free model (FCOS-ResNet50) on COCO-standard. * We reimplement and adapt to FCOS-ResNet50. We randomly sample labeled data and run each method 5 times, and we report the mean and standard deviation for each result. We used 8 labeled images and 8 unlabeled images for all results presented in this  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Effectiveness of Unsupervised Regression Loss</head><p>We compare the methods including 1) our proposed Lis-ten2Student 2) No unsupervised regression loss, and 3) using confidence thresholding and enforcing L1 loss, as used in existing works <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b37">38]</ref>. To further understand how these methods contribute to the improvement of bounding box regression, we provide an mAP breakdown from AP55 to AP95 of each method in <ref type="table">Table 6</ref>. It is worth noting that we only change the unsupervised regression loss across these methods and keep the remaining objective functions and modifications the same across all variants.</p><p>We observe that, although the confidence thresholding can improve the easier evaluation metrics (e.g., AP55), it cannot improve or even degrades the results on stricter evaluation metrics (e.g., AP95). This shows that simply using the confidence thresholding cannot prevent misleading pseudolabels from degrading the performance on extremely precise boundary predictions. In contrast, our Listen2Student shows consistent improvements on all evaluation metrics and leads to favorable results, especially on these stricter evaluation metrics. This empirically confirms that our Listen2Student contributes to the more precise bounding box prediction, as our Listen2Student enforces the boundary-wise unsupervised regression loss, which exploits the pseudo-labels derived by <ref type="table">Table 6</ref>. Average precision (AP) breakdown of unsupervised regression methods. We also report the absolute improvement of each unsupervised regression loss method against the model without the unsupervised regression loss. AP55 AP60 AP65 AP 70 AP75 AP80 AP85 AP90 AP95 comparing the uncertainty estimation of each boundary prediction.</p><p>Limitations and future works. Although we have shown the improvement and generalization on anchor-free and anchor-based detectors, applying SSOD methods on a large-scale unlabeled dataset (e.g., OpenImage) remains a challenge. We also find that the localization uncertainty estimation for boundary prediction leaves room for improvement to be integrated with the relative thresholding mechanism. There are other challenges such as unseen objects in the unlabeled dataset or domain shift between datasets. While these topics are not our focus in this paper, they are worth exploring in future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we examined the existing SS-OD methods on anchor-free models and presented the SS-OD benchmarks on anchor-free detectors. By identifying and addressing the core issues that existed in the pseudo-labeling method on anchor-free detectors, our method can improve against the state-of-the-art methods. We further pre- sented Listen2Student, a novel method that uses relative Teacher/Student uncertainties to explicitly prevent the misleading regression pseudo-labels and select beneficial regression pseudo-labels in a boundary-wise manner. This enables the regression branch to benefit from the use of unlabeled images. In the experiment sections, we examine each method in three different SS-OD tasks and present consistent improvements. We also provide an extensive study to verify the effectiveness and generalization of our proposed Listen2Student mechanism on both anchor-free and anchor-based detectors. Concerning negative societal impacts, we think it is essential to be aware that there exists the risk that object detection techniques (not just our method) are used in surveillance systems. Also, as this line of works relies on low-labeled data for the model training, this aggravates the risk of data bias toward historically disadvantaged groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgments</head><p>Yen-Cheng Liu and Zsolt Kira were partly supported by DARPA's Learning with Less Labels (LwLL) program under agreement HR0011-18-S-0044, as part of their affiliation with Georgia Tech.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Illustration of Centerness bias issue. (a) Selecting pseudo-boxes based on box scores leads to worse results in semisupervised learning compared with selecting based on classification scores. (b) Box scores of the anchor-free detectors</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>(a) Beneficial/Misleading regression pseudo-labels and (b) Listen2Student. (a) We categorize the regression pseudolabels into beneficial and misleading instances, and (b) our Lis-ten2Student prevents the misleading regression pseudo-labels and thus improves the regression branch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>While box selection based on box score leads to higher detection accuracy in fully-supervised settings, it performs worse than box selection based on classification scores under semi-supervised learning settings. Fully-supervised results are from FCOS<ref type="bibr" target="#b28">[29]</ref>.</figDesc><table><row><cell></cell><cell cols="2">Class. score Box score</cell><cell>?</cell></row><row><cell>Fully-supervised</cell><cell>33.50</cell><cell>37.10</cell><cell>+3.60</cell></row><row><cell>Semi-supervised</cell><cell>17.79</cell><cell>15.12</cell><cell>-2.67</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table><row><cell>Fully-supervised</cell><cell>37.10</cell><cell>38.10</cell><cell>+1.00</cell></row><row><cell>Semi-supervised</cell><cell>17.79</cell><cell>14.96</cell><cell>-2.83</cell></row></table><note>While the Center-Sampling improves the anchor-free detec- tors in fully-supervised setting, it degrades the performance in the semi-supervised setting. Fully-supervised results from FCOS [29].w/o Center-Sampling w/ Center-Sampling ?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>table .</head><label>.</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="3">Anchor-free detectors on COCO-standard</cell><cell></cell></row><row><cell></cell><cell>0.5%</cell><cell>1%</cell><cell>2%</cell><cell>5%</cell><cell>10%</cell></row><row><cell>Supervised</cell><cell>5.42 ? 0.01</cell><cell>8.43 ? 0.03</cell><cell>11.97 ? 0.03</cell><cell>17.01 ? 0.01</cell><cell>20.98 ? 0.01</cell></row><row><cell>CSD [9]*</cell><cell>5.76 ? 0.55 (+0.34)</cell><cell>9.23 ? 0.08 (+0.80)</cell><cell>12.53 ? 0.04 (+0.56)</cell><cell>18.09 ? 0.08 (+1.08)</cell><cell>22.06 ? 0.01 (+1.08)</cell></row><row><cell>STAC [26]*</cell><cell>8.79 ? 0.12 (+3.37)</cell><cell>11.97 ? 0.12 (+3.54)</cell><cell>15.50 ? 0.16 (+3.53)</cell><cell>20.36 ? 0.05 (+3.35)</cell><cell>24.31 ? 0.02 (+3.33)</cell></row><row><cell cols="2">Unbiased Teacher [20]* 10.27 ? 0.13 (+4.85)</cell><cell>14.61 ? 0.10 (+6.18)</cell><cell>18.70 ? 0.21 (+6.73)</cell><cell>23.99 ? 0.12 (+6.98)</cell><cell>28.18 ? 0.01 (+7.20)</cell></row><row><cell>Ours</cell><cell cols="5">16.25 ? 0.18 (+10.83) 22.71 ? 0.42 (+14.28) 26.03 ? 0.12 (+14.06) 30.08 ? 0.04 (+13.07) 32.61 ? 0.03 (+11.63)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Experimental results of anchor-based models (FasterRCNN-ResNet50) on COCO-standard. For a fair comparison, we make the batch size consistent to the baseline methods. ?: using labeled/unlabeled batch size 32/32, *: using batch size labeled/unlabeled batch size 8/40, and rest of the results using batch size 8/8. We randomly sample labeled data and run each method 5 times, and we report the mean and standard deviation for each result. ? 0.49 (+14.<ref type="bibr" target="#b18">19</ref>) 24.79 ? 0.30 (+15.74) 28.23 ? 0.05 (+15.53) 32.05 ? 0.04 (+13.58) 35.02 ? 0.02 (+11.16) Unbiased Teacher [20] ? 16.94 ? 0.23 (+10.11) 20.75 ? 0.12 (+11.72) 24.30 ? 0.07 (+11.60) 28.27 ? 0.11 (+9.80) 31.50 ? 0.10 (+7.64) Ours ? 21.26 ? 0.21 (+14.43) 25.40 ? 0.36 (+16.35) 28.37 ? 0.03 (+15.67) 31.85 ? 0.09 (+13.38) 35.08 ? 0.02 (+11.22)other hand, with the COCO2017-unlabeled set, our model can perform favorably against the object detector trained on COCO2017-train and achieve 44.75 mAP. Note that we train our model for 720k iterations and do not tune the inference threshold (same as SoftTeacher). Training the model longer or tuning the inference threshold can potentially further improve the performance. These results confirm the effectiveness of our framework on improving the existing object detector using the extra unlabeled images.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Anchor-based detectors on COCO-standard</cell><cell></cell></row><row><cell></cell><cell>0.5%</cell><cell>1%</cell><cell>2%</cell><cell>5%</cell><cell>10%</cell></row><row><cell>Supervised</cell><cell>6.83 ? 0.15</cell><cell>9.05 ? 0.16</cell><cell>12.70 ? 0.15</cell><cell>18.47 ? 0.22</cell><cell>23.86 ? 0.81</cell></row><row><cell>CSD [9]</cell><cell>7.41 ? 0.21 (+0.58)</cell><cell>10.51 ? 0.06 (+1.46)</cell><cell>13.93 ? 0.12 (+1.23)</cell><cell>18.63 ? 0.07 (+0.16)</cell><cell>22.46 ? 0.08 (-1.40)</cell></row><row><cell>STAC [26]</cell><cell>9.78 ? 0.53 (+2.95)</cell><cell>13.97 ? 0.35 (+4.92)</cell><cell>18.25 ? 0.25 (+5.55)</cell><cell>24.38 ? 0.12 (+5.86)</cell><cell>28.64 ? 0.21 (+4.78)</cell></row><row><cell>Humble Teacher [27]</cell><cell>-</cell><cell>16.96 ? 0.38 (+7.91)</cell><cell>21.72 ? 0.24 (+9.02)</cell><cell>27.70 ? 0.15 (+9.23)</cell><cell>31.61 ? 0.28 (+7.74)</cell></row><row><cell>Instant Teaching [38]</cell><cell>-</cell><cell>18.05 ? 0.15 (+9.00)</cell><cell>22.45 ? 0.15 (+9.75)</cell><cell>26.75 ? 0.05 (+8.28)</cell><cell>30.40 ? 0.05 (+6.54)</cell></row><row><cell>Unbiased Teacher [20]</cell><cell>14.36 ? 0.09 (+7.53)</cell><cell>18.33 ? 0.19 (+9.28)</cell><cell>22.23 ? 0.21 (+9.53)</cell><cell>26.65 ? 0.31 (+8.18)</cell><cell>29.56 ? 0.24 (+5.70)</cell></row><row><cell>ISMT [34]</cell><cell>-</cell><cell>18.88 ? 0.74 (+9.83)</cell><cell>22.43 ? 0.56 (+9.73)</cell><cell>26.37 ? 0.24 (+7.90)</cell><cell>30.53 ? 0.52 (+6.67)</cell></row><row><cell>Ours</cell><cell cols="4">17.51 ? 0.24 (+10.68) 21.84 ? 0.13 (+12.79) 26.14 ? 0.01 (+13.44) 30.06 ? 0.14 (+11.59)</cell><cell>33.50 ? 0.03 (+9.64)</cell></row><row><cell>SoftTeacher [33] *</cell><cell>-</cell><cell>20.46 ? 0.39 (+11.41)</cell><cell>-</cell><cell cols="2">30.74 ? 0.08 (+12.27) 34.04 ? 0.14 (+10.18)</cell></row><row><cell>Ours*</cell><cell>21.02</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 .</head><label>7</label><figDesc>No regression 29.71 27.34 24.64 21.38 17.55 13.27 +1.25 +1.56 +1.67 +2.09 +2.34 +2.14 +1.61 +0.23 Results of the Anchor-based model (Faster-RCNN) on VOC.</figDesc><table><row><cell>8.33</cell><cell>3.45</cell><cell>0.35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 .</head><label>8</label><figDesc>Results of the Anchor-based model (Faster-RCNN) on COCO-additional. *We adapt the scale jitter used in Soft-Teacher<ref type="bibr" target="#b32">[33]</ref> to Unbiased Teacher and it leads to significant improvement.</figDesc><table><row><cell>Methods</cell><cell>mAP</cell></row><row><cell>Supervised</cell><cell>40.90</cell></row><row><cell>CSD [9]</cell><cell>38.52</cell></row><row><cell>STAC [26]</cell><cell>39.21</cell></row><row><cell>Humble Teacher [27]</cell><cell>42.37</cell></row><row><cell>Unbiased Teacher* [20]</cell><cell>44.06</cell></row><row><cell>SoftTeacher [33]</cell><cell>44.50</cell></row><row><cell>Ours</cell><cell>44.75</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Listen2Student is not limited to NPLL, and other regression uncertainty estimation methods<ref type="bibr" target="#b6">[7]</ref> are also potentially applicable.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5049" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Rogerio S Feris, and Nuno Vasconcelos. A unified multi-scale deep convolutional neural network for fast object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanfu</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning efficient object detection models with knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guobin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Note-rcnn: Noise tolerant ensemble rcnn for semisupervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mixup as locally linear out-of-manifold regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongyi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3714" to="3722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bounding box regression with uncertainty for accurate object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianren</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marios</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ieee/cvf conference on computer vision and pattern recognition</title>
		<meeting>the ieee/cvf conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2888" to="2897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">AugMix: A simple data processing method to improve robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno>2020. 3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Consistency-based semi-supervised learning for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jisoo</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungeui</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeesoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nojun</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A survey of deep learning-based object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Licheng</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="128837" to="128868" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Foveabox: Beyound anchor-based object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuchun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="7389" to="7398" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<idno>2017. 3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cornernet: Detecting objects as paired keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hei</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Localization uncertainty estimation for anchor-free object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngwan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joong-Won</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyung-Il</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joungyoul</forename><surname>Park</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.15607</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generalized focal loss v2: Learning reliable localization quality estimation for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generalized focal loss: Learning qualified and distributed bounding boxes for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision (CVPR)</title>
		<meeting>the IEEE international conference on computer vision (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unbiased teacher for semi-supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wen</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehran</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1163" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distilling knowledge from a deep pose regressor network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhamad</forename><surname>Risqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Saputra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">Pb</forename><surname>De Gusmao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasin</forename><surname>Almalioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Training region-based object detectors with online hard example mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A simple semi-supervised learning framework for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04757</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Humble teachers teach better students for semi-supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihe</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuting</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="3132" to="3141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fcos: Fully convolutional one-stage object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Region proposal by guided anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wan-Yen</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Detectron2</surname></persName>
		</author>
		<ptr target="https://github.com/facebookresearch/detectron2" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">End-toend semi-supervised object detection with soft teacher</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengde</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyun</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09018</idno>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Interactive self-training with mean teachers for semisupervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qize</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xihan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="5941" to="5950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6023" to="6032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bridging the gap between anchor-based and anchorfree detection via adaptive training sample selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongqiang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Instant-teaching: An end-to-end semi-supervised object detection framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaohui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07850</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Objects as points. In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Bottom-up object detection by grouping extreme and center points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Soft anchor-point object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marios</forename><surname>Savvides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Feature selective anchor-free module for single-shot object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marios</forename><surname>Savvides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
