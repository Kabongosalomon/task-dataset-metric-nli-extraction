<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Generalization in Federated Learning by Seeking Flat Minima</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debora</forename><surname>Caldarola</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Politecnico di Torino</orgName>
								<address>
									<postCode>2 CINI</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Politecnico di Torino</orgName>
								<address>
									<postCode>2 CINI</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Ciccone</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Politecnico di Torino</orgName>
								<address>
									<postCode>2 CINI</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Generalization in Federated Learning by Seeking Flat Minima</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Cifar10/100</term>
					<term>Landmarks-User-160k</term>
					<term>Idda) and tasks (large scale classi- fication</term>
					<term>semantic segmentation</term>
					<term>domain generalization)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Models trained in federated settings often suffer from degraded performances and fail at generalizing, especially when facing heterogeneous scenarios. In this work, we investigate such behavior through the lens of geometry of the loss and Hessian eigenspectrum, linking the model's lack of generalization capacity to the sharpness of the solution. Motivated by prior studies connecting the sharpness of the loss surface and the generalization gap, we show that i) training clients locally with Sharpness-Aware Minimization (SAM) or its adaptive version (ASAM) and ii) averaging stochastic weights (SWA) on the server-side can substantially improve generalization in Federated Learning and help bridging the gap with centralized models. By seeking parameters in neighborhoods having uniform low loss, the model converges towards flatter minima and its generalization significantly improves in both homogeneous and heterogeneous scenarios. Empirical results demonstrate the effectiveness of those optimizers across a variety of benchmark vision datasets (e.g.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Federated Learning (FL) <ref type="bibr" target="#b38">[57]</ref> is a machine learning framework enabling the training of a prediction model across distributed clients while maintaining their privacy, never disclosing local data. In recent years it has had a notable resonance in the world of computer vision, with applications ranging from large-scale classification <ref type="bibr" target="#b30">[31]</ref> to medical imaging <ref type="bibr" target="#b23">[24]</ref> to domain generalization <ref type="bibr" target="#b36">[55]</ref> and many others <ref type="bibr">[48,</ref><ref type="bibr">88,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b62">81]</ref>. The learning paradigm is based on communication rounds where a sub-sample of clients trains the global model independently on their local datasets, and the produced updates are later aggregated on the server-side. The heterogeneous distribution of clients' data, which is usually non-i.i.d. and unbalanced, poses a major challenge in realistic federated scenarios, leading to degraded convergence performances [89, <ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">50]</ref>. Locally, the model has only access to a small portion of the data failing to generalize to the rest of the underlying distribution. That contrasts with the standard centralized training, where the learner can uniformly sample from the whole distribution. While many promising works in the literature focus on regularizing the local objective to align the global and local solutions, thus reducing the client drift <ref type="bibr" target="#b31">[50,</ref><ref type="bibr">38,</ref><ref type="bibr" target="#b0">1]</ref>, less attention has been given to the explicit optimization of the loss function for finding better minima. Several works studied the connection between the sharpness of the loss surface and model's generalization <ref type="bibr" target="#b27">[28,</ref><ref type="bibr">39,</ref><ref type="bibr">46,</ref><ref type="bibr">42,</ref><ref type="bibr" target="#b52">71,</ref><ref type="bibr">34,</ref><ref type="bibr" target="#b12">13]</ref>, and proposed effective solutions based on the minimization of the derived generalization bound [85, <ref type="bibr" target="#b19">20,</ref><ref type="bibr">44]</ref> or on averaging the network's parameters along the trajectory of SGD <ref type="bibr">[33]</ref>.</p><p>In this work, we first analyze the heterogeneous federated scenario to highlight the causes behind the poor generalization of the federated algorithms. We hypothesize during local training the model overfits the current distribution, and the resulting average of the updates is strayed apart from local minima. Thus, the global model is not able to generalize to the overall underlying distribution and has a much slower convergence rate, i.e. it needs a much larger number of rounds to reach the performance of the homogeneous setting. To speed up training and reduce the performance gap in the case of non-i.i.d. data, we look at improving the generalization ability of the model. Motivated by recent findings relating the geometry of the loss and the generalization gap <ref type="bibr">[39,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr">46,</ref><ref type="bibr">36]</ref> and by the achievements in the field of Vision Transformers <ref type="bibr" target="#b12">[13]</ref>, we analyze the loss landscape in the federated scenario and find out that models converge to sharp minima ( <ref type="figure">Fig.1</ref>), hence the poor generalization. As a solution, we introduce methods of the current literature that explicitly look for flat minima: i) Sharpness-Aware Minimization (SAM) <ref type="bibr" target="#b19">[20]</ref> and its adaptive version (ASAM) [44] on the client-side and ii) Stochastic Weight Averaging (SWA) [33] on the server-side. These modifications, albeit simple, surprisingly lead to significant improvements. Their use is already effective if taken individually, but the best performance is obtained when combined. The resultant models exhibit smoother loss surfaces and improved final performance consistently across several vision tasks. To summarize, our main contributions are:</p><p>-We analyze the behavior of models trained in heterogeneous and homogeneous federated scenarios by looking at their convergence points, loss surfaces and Hessian eigenvalues, linking the lack in generalization to sharp minima.</p><p>-To encourage convergence towards flatter minima, we introduce SAM and ASAM in the local client-side training and SWA in the aggregation of the updates on the server-side. The resultant models show smoother loss landscapes and lower Hessian eigenvalues, with improved generalization capacities. -We test our approach on multiple vision tasks, i.e. small and large scale classification <ref type="bibr" target="#b30">[31]</ref>, domain generalization <ref type="bibr" target="#b6">[7]</ref> and semantic segmentation <ref type="bibr" target="#b37">[56,</ref><ref type="bibr" target="#b11">12]</ref>. -We compare our method with strong data augmentations techniques and state-of-the-art FL algorithms, further validating its effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>We describe here the existing approaches closely related to our work. For a comprehensive analysis of the state of the art in FL, we refer to [37,49,86].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Statistical Heterogeneity in Federated Learning</head><p>Federated Learning is a topic in continuous growth and evolution. Aiming at a real-world scenario, the non-i.i.d. and unbalanced distribution of users' data poses a significant challenge. The statistical heterogeneity of local datasets leads to unstable and slow convergence, suboptimal performance and poor generalization of the global model [89, <ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>. FedAvg <ref type="bibr" target="#b38">[57]</ref> defines the standard optimization method and is based on multiple local SGD <ref type="bibr" target="#b47">[66]</ref> steps per round. The serverside aggregation is a weighted average of the clients' updates. This simple approach is effective in homogeneous scenarios. Still, it fails to achieve comparable performance against non-i.i.d. data due to local models straying from each other and leading the central model away from the global optimum <ref type="bibr">[38]</ref>. To mitigate the effect of the client drift, many works enforce regularization in local optimization so that the local model is not led too far apart from the global one <ref type="bibr" target="#b31">[50,</ref><ref type="bibr">38,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr">48]</ref>. Indeed, averaging models/gradients collected from clients having access to a limited subset of tasks may translate into oscillations of the global model and suboptimal performance on the global distribution <ref type="bibr" target="#b35">[54]</ref>. Therefore, other lines of research look at improving the aggregation stage using server-side momentum <ref type="bibr" target="#b29">[30]</ref> and adaptive optimizers <ref type="bibr" target="#b45">[64]</ref>, or aggregating task-specific parameters <ref type="bibr" target="#b52">[71,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. In this work, we attempt to explain the behavior of the model in federated scenarios by looking at the loss surface and convergence minima, which is, in our opinion, a fundamental perspective to fully understand the reasons behind the degradation of heterogeneous performance relative to centralized and homogeneous settings. To this end, we focus on explicitly seeking parameters in uniformly low-loss neighborhoods, without any additional communication cost. By encouraging local convergence towards flatter minima, we show that the generalization capacity of the global model is consequently improved. Moreover, thanks to the cyclical average of stochastic weights -accumulated along the trajectory of SGD during rounds on the server-side -broader regions of the weight space are explored, and wider optima are reached. Referring to the terminology introduced by [84], we aim at bridging the participation gap introduced by unseen clients distributions. Concurrently, <ref type="bibr" target="#b44">[63]</ref> provide a theoretical analysis of SAM in FL, matching the convergence rates of the existing methods. Unlike our work, they do not explicitly focus on the issue of statistical heterogeneity in vision tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Real-world Vision Scenarios in Federated Learning</head><p>Research on FL has mainly focused on algorithmic aspects, often overlooking its application to real scenarios and vision tasks. Here, we perform an analysis of the following real-world settings. Large-scale Classification. Synthetic federated datasets for classification tasks are usually limited in size and do not offer a faithful representation of reality in the data distribution across clients <ref type="bibr" target="#b30">[31]</ref>. <ref type="bibr" target="#b30">[31]</ref> addresses such issue by adapting the large-scale Google Landmarks v2 <ref type="bibr" target="#b58">[77]</ref> to the federated context, using authorship information. We employ the resulting Landmarks-User-160k in our experiments. Semantic Segmentation. A crucial task for real-world applications <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b42">61]</ref>, e.g. autonomous driving <ref type="bibr" target="#b51">[70,</ref><ref type="bibr" target="#b55">74]</ref>, is Semantic Segmentation (SS), which assigns each image pixel to a known category. Most studies of SS in FL focus on medical imaging applications and propose ad hoc techniques to safeguard the patients' privacy <ref type="bibr" target="#b49">[68,</ref><ref type="bibr" target="#b33">52,</ref><ref type="bibr" target="#b63">82,</ref><ref type="bibr" target="#b5">6]</ref>. Differently, <ref type="bibr" target="#b39">[58]</ref> focuses on object segmentation using prototypical representations. A recently studied application is FL in autonomous driving, motivated by the large amount of privacy-protected data collected by self-driving cars: the authors of <ref type="bibr" target="#b18">[19]</ref> propose a new benchmark for analyzing such a scenario, FedDrive. None of those works study the relation between loss landscape and convergence minima of the proposed solution. We apply our approach to the FedDrive benchmark and prove its efficacy in addressing the federated SS task. Domain Generalization. When it comes to image data collected from devices around the world, it is realistic to assume there may be different domains resulting from the several acquisition devices, light, weather conditions, noise, or viewpoints. With the rising development of FL and the privacy concerns, the problem of Domain Generalization (DG) <ref type="bibr" target="#b6">[7]</ref> in a federated setting becomes crucial. DG aims to learn a domain-agnostic model capable of satisfying performances on unseen domains, and its application to federated scenarios is still poorly studied. For instance, <ref type="bibr" target="#b36">[55,</ref><ref type="bibr" target="#b56">75]</ref> focus on domain shifts deriving from equipment in the medical field, while <ref type="bibr" target="#b18">[19]</ref> analyzes the effects of changing landscapes and weather conditions in the setting of autonomous driving. We show that our approach improves generalization to unseen domains both in classification and SS tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Flat Minima and Generalization</head><p>To understand neural networks' generalization, several theoretical and empirical studies analyze its relationship with the geometry of the loss surface <ref type="bibr" target="#b27">[28,</ref><ref type="bibr">39,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr">46,</ref><ref type="bibr">36]</ref>, connecting sharp minima with poor generalization. "Flatness" <ref type="bibr" target="#b27">[28]</ref> is defined as the dimension of the region connected around the minimum in which the training loss remains low. Interestingly, it has been shown [36] that sharpnessbased measures highly correlate with generalization performance. The above studies lead to the introduction of Sharpness-Aware Minimization (SAM) <ref type="bibr" target="#b19">[20]</ref> which explicitly seeks flatter minima and smoother loss surfaces through a simultaneous minimization of loss sharpness and value during training. As highlighted by <ref type="bibr">[44]</ref>, SAM is sensitive to parameter re-scaling, weakening the connection between loss sharpness and generalization gap. ASAM [44] solves such issue introducing the concept of adaptive sharpness. Encouraged by their effectiveness across a variety of architectures and tasks <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b3">4]</ref>, we ask whether SAM and ASAM can improve generalization in FL as well and find it effective even in the most difficult scenarios. In addition, <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b16">17]</ref> show that local optima found by SGD are connected through a path of near constant loss and that ensambling those points in the weight space leads to high performing networks. Building upon these insights, <ref type="bibr">[33]</ref> proposes to average the points traversed by SGD to improve generalization and indeed show the model converges towards wider optima. We modify this approach for FL and use it to cyclically ensemble the models obtained with FedAvg on the server side.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Behind the Curtain of Heterogeneous FL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Federated Learning: Overview</head><p>The standard federated framework is based on a central server exchanging messages with K distributed clients. Each device k has access to a privacyprotected dataset D k made of N k images belonging to the input space X . The goal is to learn a global model f ? parametrized by ? ? W ? R d , where f ? : X ? Y when solving the classification task and f ? : X ? Y Np in semantic segmentation, with Y being the output space and N p the total number of pixels of each image. We assume the structure of ? to be identical across all devices. The learning procedure spans over T communications rounds, during which a subset of clients C receives the current model parameters ? t with t ? [T ] and trains it on D k ?k ? C, minimizing a local loss function L k (? t ) : W ? X ? Y ? R + . In FedAvg <ref type="bibr" target="#b38">[57]</ref>, the global model is updated as a weighted average of the clients' updates ? t k , aiming at solving the global objective arg min ??R d 1 N k?C N k L k (?), with N = k?C N k being the total training images. In particular, from the generalization perspective -defined D k?[K] D k the overall clients' data, D its distribution and L D = 1 / k N k k?[K] N k L k (?) the training loss -we aim at learning a model having low population loss L D (?)</p><formula xml:id="formula_0">E (x,y)?D E D [L k (y, f (x, ?))] [84].</formula><p>The difference between the population and training losses defines the generalization gap, i.e. the ability of the model to generalize to unseen data <ref type="bibr" target="#b19">[20]</ref>.</p><p>In realistic scenarios, given two clients i and j, D i likely follows a different distribution than D j , i.e. D i = D j , and the loss L i (?) ?i ? [K] is typically non-convex in ?. The loss landscape comprehends a multiplicity of local minima leading to models with different generalization performance, i.e. significantly different values of L D (?) <ref type="bibr" target="#b19">[20]</ref>. Moreover, at each round, the model is likely not to see the entire distribution, further widening the generalization gap <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b25">26]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Where Heterogeneous FL Fails at Generalizing</head><p>In order to fully understand the behavior of a model trained in a heterogeneous federated scenario, we perform a thorough empirical analysis from different perspectives. Our experimental setup replicates that proposed by <ref type="bibr" target="#b30">[31]</ref> both as regards the dataset and the network. The Cifar100 dataset [43], widely used as benchmark in FL, is split between 100 clients, following a Dirichlet distribution with concentration parameter ?. To replicate a heterogeneous scenario, we choose ? ? {0, 0.5}, while ? is set to 1000 for the homogeneous one. The model is trained over 20k rounds. Fore more details, please refer to Appendix C. Model Behavior in Heterogeneous and Homogeneous Scenarios. In <ref type="figure" target="#fig_2">Fig.  3</ref>, we compare the training trends in centralized, homogeneous and heterogeneous federated settings: in the latter, not only is the trend much noisier and more unstable, but the performance gap is considerable. Consequently, we question the causes of such behavior. First of all, we wonder if the heterogeneous distribution of the data totally inhibits the model from achieving comparable performances: we find it is only a matter of rounds, i.e. with a much larger round budget -10 times larger in our case -the model reaches convergence <ref type="figure" target="#fig_2">(Fig. 3</ref>). So it becomes obvious the training is somehow slowed down and there is room for improvement. This hypothesis is further validated by the convergence points of the models trained in different settings ( <ref type="figure" target="#fig_1">Fig. 2</ref>): when ? = 1k a low-loss region is reached at the end of training, while the same does not happen with lower values of ?, meaning that local minima are still to be found. Moreover, the shift between the train and test surfaces suggests us the model trained in the heterogeneous setting (? = 0) is unable to generalize well to unseen data, finding itself in a high-loss region <ref type="bibr">[33]</ref>. By analyzing the model behavior, we discover that shifts in client data distribution lead to numerous fluctuations in learning, i.e. at each round the model focuses on a subset of the just seen tasks and is unable to generalize to the previously learned ones. This phenomenon is also known as catastrophic interference of neural networks <ref type="bibr">[41]</ref> and is typical of the world of multitask learning <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b53">72]</ref>. <ref type="figure" target="#fig_2">Fig. 3</ref> highlights this by comparing the accuracy of the global model on the clients' data and the test set when ? = 0 and ? = 1k. In the first case, at each round the model achieves very high performances on one class but forgets about the others and this behavior is only slightly attenuated as the training continues. In the homogeneous scenario, on the other hand, the model behaves very similarly on each client and convergence is easily reached, giving way to overfitting as the number of rounds increases. We analyze the clients' local training for further insights from the characteristics of the updated models. By plotting the position of the weights in the loss landscape after training, we find the models easily overfit the local data distribution ( <ref type="figure" target="#fig_1">Fig. 2)</ref>: when tested on the test set, the clients' updates are positioned in very high-error regions and as a result the global model moves away from the minimum, meaning the clients specialize too much on their own data and are not able to generalize to the overall underlying distribution. Moreover, <ref type="figure" target="#fig_1">Fig. 2</ref> highlights another relevant issue: models trained on homogeneous distributions are connected through a path of low error and can therefore be ensambled to obtain a more meaningful representation <ref type="bibr" target="#b21">[22]</ref>, but the same does not hold when ? = 0, where the models are situated in different loss-value regions. Therefore, FedAvg averages models that are too far apart to lead to a meaningful result. Federated Training Converges to Sharp Minima. Many works tried to account for this difficulty arising in federated scenarios by enforcing regularization in local optimization not to lead the local model too far apart from the global one <ref type="bibr" target="#b31">[50,</ref><ref type="bibr">38,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr">48]</ref>, or by using momentum on the server-side <ref type="bibr" target="#b29">[30]</ref>, or learning task-specific parameters keeping distinct models on the server-side <ref type="bibr" target="#b52">[71,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. To the best of our knowledge, this is the first work addressing such behavior by looking at the loss landscape. Inspired by a recent trend in Deep Learning connecting the geometry of the loss and the generalization gap [39, <ref type="bibr" target="#b17">18,</ref><ref type="bibr">46,</ref><ref type="bibr">36,</ref><ref type="bibr">44</ref>,33], we investigate the geometry of the loss surface of models trained in non-i.i.d. scenarios with the intention of understanding whether sharp minima may cause the lack of generalization in FL. Following [46], we plot the loss surfaces obtained with models trained in a heterogeneous and in a homogeneous scenario ( <ref type="figure">Fig. 1)</ref> showing that both converge to sharp regions, providing a plausible explanation for the highlighted lack of generalization. Additionally, [39] characterizes flatness    through the eigenvalues of the Hessian: the dominant eigenvalue ? max evaluates the worst-case landscape curvature, i.e. the larger ? max the greater the change in loss in that direction and the steeper the minimum. Hence, we compute the Hessian eigenspectrum (first 50 eigenvalues) using the power iteration mode and analyze it both from the global and local perspectives ( <ref type="figure" target="#fig_4">Fig. 4,5</ref>). <ref type="table" target="#tab_0">Table 1</ref> reports the values of ? max and the ratio ?max /?5, commonly used as a proxy for sharpness <ref type="bibr">[35]</ref>, as the heterogeneity varies. As expected, ? max is large in all settings when using FedAvg, implying that such method leads the model towards sharp minima regardless of the data distribution, confirming what was noted in the loss landscapes. As for the client-side analysis, we compute the value of ? k max using the locally updated parameters ? t k on the k-th device's data D k ?t ? [T ]. Comparing the i.i.d. and non-i.i.d. settings, we note i) the local values of ? max are much lower if ? = 0, i.e. the clients locally reach wide minima (low Hessian maximum eigenvalue, ? k max ? 14) due to the simplicity of the learned task, i.e. a narrow subset of the classes, but the average of the distinct updates drives the model towards sharper minima (high Hessian eigenvalues of the global model, ? max 94). ii) When ? ? {0.5, 1k}, ? max decreases as the rounds pass, i.e. the global model is moving towards regions with lower curvature, while this is not as evident in the heterogeneous setting. Motivated by these results, we believe that introducing an explicit search for flatter minima can help the model generalize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Seeking Flat Minima in Federated Learning</head><p>Common first-order optimizers (e.g. SGD <ref type="bibr" target="#b47">[66]</ref>, Adam [40]) are usually nonrobust to unseen data distributions <ref type="bibr" target="#b12">[13]</ref>, since they only aim at minimizing the Algorithm 1 SAM/ASAM and SWA applied to FedAvg Require: Initial random model f 0 ? , K clients, T rounds, learning rates ? 1 , ? 2 , neighborhood size ? &gt; 0, ? &gt; 0, batch size |B|, local epochs E, cycle length c 1: for each round t = 0 to T ? 1 do 2:</p><p>if t = 0.75 * T then Apply SWA from 75% of training onwards</p><formula xml:id="formula_1">3: ? SWA ? ? t Initialize SWA model 4: end if 5: if t ? 0.75 * T then 6: ? = ?(t)</formula><p>Compute LR for the round (Eq. 7 in Appendix) 7:</p><p>end if 8:</p><p>Subsample a set C of clients 9:</p><p>for each client k in C in parallel do Iterate over subset C of clients 10: ? t+1 k,0 ? ? t</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>for e = 0 to E ? 1 do 12:</p><p>for i = 0 to N k /|B| do training loss L D , without looking at higher-order information correlating with generalization (e.g. curvature). The federated scenario exacerbates such behavior due to its inherent statistical heterogeneity, resulting in sharp minima and poor generalization. We hypothesize that encouraging the local model to converge towards flatter neighborhoods may help bridging the generalization gap. To this end, we introduce sharpness-aware minimizers, namely SAM <ref type="bibr" target="#b19">[20]</ref> and ASAM [44], on the client-side during local training, and Stochastic Weight Averaging [33] on the server-side after the aggregation, adapting the scenario of [33] to FL. By minimizing the sharpness of the loss surface and the generalization gap, the local models are more robust towards unseen data distributions and, when averaged, build a more solid central model. Defined the sharpness of a training loss L D as max || ||p?? L D (? + ) ? L D (?), with ? being the neighborhood size and p ? [1, ?), SAM aims at minimizing it by solving min ??R d max || ||p?? L D (? + ) + ?||?|| 2 2 . SWA averages weights proposed by SGD, while using a learning rate schedule to explore regions of the weight space corresponding to high performing networks. For a detailed explanation of SAM, ASAM and SWA we refer the reader to Appendix A. Algorithm 1 sums up the details of our approach.</p><formula xml:id="formula_2">13: Compute gradient ? ? L B (? t+1 k,i ) on batch B from D k 14: Compute? ? t+1 k,i = ?? ? L B ? t+1 k,i ? ? L B ? t+1 k,i 2 =:? (?) Solve local maximization (Eq. 3) 15: ? t+1 k,i+1 ? ? t+1 k,i ? ? ? ? L B (? t+1 k,i ) ?+? (?) Local</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this Section, we show the effectiveness of SAM, ASAM and SWA in federated scenarios when addressing tasks of image classification (Sec. 5.1), large-scale classification, SS and DG (Sec. 5.2). Their strength indeed lies in finding flatter minima (Sec. 5.1), which consequently help the model to generalize especially in the heterogeneous scenario. We compare our method with algorithms proper of the FL literature and strong data augmentations (Sec. 5.1), commonly used to improve generalization in DL, further validating the efficacy of our proposal. We refer to App. C for implementation details and App. E for the ablation studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The Effectiveness of the Search for Flat Minima in FL</head><p>In Sec. 3.2, we have shown that, given a fixed number of rounds, FL models trained in heterogeneous settings present a considerable performance gap compared to their homogeneous counterparts. Indeed, the gap between the two scenarios can be significant with a difference of up to 20% points ( <ref type="table" target="#tab_2">Table 2</ref>). We identify the clients' overspecialization on local data as one of the causes of the poor generalization of the global model to the underlying training distribution. We confirm this by showing the model converges to sharp minima, correlated to a poor generalization capacity. In <ref type="table" target="#tab_2">Table 2</ref>, we show that explicitly optimizing for flat minima in both the local training and the server-side aggregation does help improving performances, with evident benefits especially in heterogeneous scenarios. We test SAM, ASAM and their combination with SWA on the federated Cifar10 and Cifar100 [43, <ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref> with several levels of heterogeneity (? ? {0, 0.05, 100} for Cifar10 and ? ? {0, 0.5, 1k} for Cifar100) and clients participation (K ? {5, 10, 20}, i.e. 5%, 10%, 20%). As for Cifar100, we additionally test our approach on the setting proposed by <ref type="bibr" target="#b45">[64]</ref>, later referred to as Cifar100-PAM, where the splits reflect the "coarse" and "fine" label structure proper of the dataset. Since both SAM and ASAM perform a step of gradient ascent and one of gradient descent for each iteration, they should be compared with FedAvg with 2 local epochs. However, the results show FedAvg with E = 2 suffers even more from statistical heterogeneity, so we will compare our baseline with the better-performing FedAvg with E = 1. Our experiments reveal that applying ASAM to FedAvg leads to the best accuracies with a gain of +6% and +8% points respectively on Cifar100 and Cifar10 in the most challenging scenario, i.e. ? = 0 and 5 clients per round. This gain  is further improved by FedASAM + SWA with a corresponding increase of +12% and +11.5%. The stability introduced by SWA especially helps with lower clients participation, where the trend is noisier. Our ablation studies (Appendix E.3) prove the boost given by SWA is mainly related to the average of the stochastic weights, rather than the cycling learning rate. <ref type="table" target="#tab_3">Table 3</ref> shows the results on Cifar100-Pam with ResNet18: here SAM and SAM + SWA help more than ASAM. ASAM and SWA Lead to Flatter Minima in FL. We extend the analysis on the loss landscape and the Hessian eigenspectrum to the models trained with FedSAM, FedASAM and SWA. As expected, both the loss surfaces ( <ref type="figure">Fig. 1</ref>) and the Hessian spectra ( <ref type="figure" target="#fig_5">Fig. 5</ref>) indicate us those methods indeed help converging towards flatter minima. The value of ? max goes from 93.5 with FedAvg to 70.3 with FedSAM to 30.1 with FedASAM in the most heterogeneous setting ( <ref type="table" target="#tab_0">Table 1</ref>). The result is further improved by FedASAM + SWA, obtaining ? max = 24.6. We notice there is a strict correspondence between the best ? max and the best ratio ?max /?5. Even if the maximum eigenvalue resulting with FedAvg + SWA and FedSAM + SWA is higher than the respective one without SWA, the corresponding lower ratio ?max /?5 actually tells us the bulk of the spectrum lies in a lower curvature region <ref type="bibr" target="#b19">[20]</ref>, proving the effectiveness of SWA. Looking at ASAM's behavior from each client's perspective ( <ref type="figure" target="#fig_4">Fig. 4</ref>), flat minima are achieved from the very beginning of the training and that reflects positively on the model's performance. ASAM and SWA Enable Strong Data Augmentations in FL. Data augmentations usually play a key role in the performance of a neural network and its ability to generalize [87, <ref type="bibr" target="#b60">79,</ref><ref type="bibr" target="#b4">5]</ref>, but their design often requires domain expertise and greater computational capabilities, two elements not necessarily present in a federated context. In <ref type="table" target="#tab_3">Table 3</ref> and 4, we distinctly apply Mixup [87] and Cutout <ref type="bibr" target="#b15">[16]</ref> on Cifar100-PAM and Cifar100 (Cifar10 in Appendix F. <ref type="bibr" target="#b1">2)</ref>. Surprisingly, both lead to worse performances across all algorithms, so instead of helping the model to generalize, they further slow down training. When combined with our methods, the performance improves in the heterogeneous scenarios w.r.t. the corresponding baseline (FedAvg + data augmentation) and SWA brings a significant boost, enabling the use of data augmentation techniques in FL. Heterogeneous FL Benefits Even More from Flat Minima.</p><p>Given the marked improvement brought by SAM, ASAM and their combination with SWA, one might wonder if this simply reflects the gains achieved in the centralized scenario. In <ref type="table" target="#tab_5">Table 5</ref>, we prove the positive gap obtained in the heterogeneous federated scenario is larger than the centralized one, showing those approaches are actually helping the training. We also note that while Cutout and Mixup improve the performances in the centralized setting, they do not help in FL, where they achieve a final accuracy worse than FedAvg (Appendix F.1 for ? ? {0.5, 1k}). Comparison with FL SOTA. We compare our method with FedProx [50], SCAFFOLD [38], FedAvgM <ref type="bibr" target="#b29">[30]</ref>, FedDyn <ref type="bibr" target="#b0">[1]</ref> and AdaBest <ref type="bibr" target="#b57">[76]</ref>, both on their own and combined with SAM, ASAM and SWA <ref type="table" target="#tab_6">(Table 6</ref>). FedProx adds a proximal term to the local objective and, as expected <ref type="bibr">[47,</ref><ref type="bibr" target="#b57">76]</ref>, does not bring any notable improvement. SCAFFOLD uses control variates to reduce the client drift, exchanging twice the parameters at each round. While performing on par with FedAvg in the homogeneous scenario (84.5% on Cifar10 and 51.9% on Cifar100), its performance is heavily affected by the data statistical heterogeneity. The same happens for FedAvgM. FedDyn dynamically aligns global and local stationary points and, as highlighted by <ref type="bibr" target="#b57">[76]</ref>, is prone to parameters explosion: while it achieves good results on the simpler Cifar10, it requires heavy gradient clipping and is unable to reach the end of training on Cifar100. As a solution, AdaBest is proposed, exceeding FedAvg by a few points. Our results demonstrate the consistent effectiveness of FedASAM w.r.t. the SOTA baselines, improving the accuracy by ? 6% points on the best SOTA on both datasets. Moreover, by adding ASAM, all FL algorithms notably increase their performance. In particular i) we enable FedAvgM and SCAFFOLD to train in most of the settings with highest heterogeneity, ii) even if limited by the necessary gradient clipping, the results reached by FedDyn on Cifar100 are almost doubled. Lastly, the best results are obtained with ASAM + SWA which stabilizes the noisy learning trends and enables models to converge close to centralized performance with ? = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">ASAM and SWA in Real World Vision Scenarios</head><p>In this Section, we analyze our method in real world scenarios, i.e. large scale classification, Semantic Segmentation (SS) for autonomous driving <ref type="bibr" target="#b18">[19]</ref> and Domain Generalization (DG) applied to both classification and SS. Large-scale Classification. We extend our analysis on visual classification tasks to Landmarks-User-160k <ref type="bibr" target="#b30">[31]</ref> to validate the effectiveness of SAM, ASAM, and SWA in the presence of real-world challenges such as Non-Identical Class Distribution (different distribution of classes per device), and Imbalanced Client Sizes (varying number of training data per device). Results confirm the benefits of applying client-side sharpness-aware optimizers, especially in combination with server-side weight averaging with an improvement in final accuracy of up to 7%. Semantic Segmentation for Autonomous Driving. SS is a fundamental task for applications of autonomous driving. Due to the private nature of the data collected by self-driving cars, it is reasonable to study this task within a federated scenario. We refer to FedDrive [19] -a new benchmark for autonomous driving in FL -for both settings and baselines. The employed datasets are Cityscapes <ref type="bibr" target="#b13">[14]</ref> and IDDA <ref type="bibr" target="#b1">[2]</ref> with both uniform and heterogeneous settings. To test the generalization capabilities of the model when facing both semantic and appearance shift, the test domain of IDDA either contains pictures taken in the countryside, or in rainy conditions. The model is tested on both previously seen and unseen domains. As shown in <ref type="table" target="#tab_8">Table 8</ref>, ASAM performs best both on Cityscapes and heterogeneous IDDA. The best performance is obtained combining ASAM + SWA with SiloBN <ref type="bibr" target="#b2">[3]</ref>, keeping the BatchNorm [32] statistics local to each client <ref type="bibr" target="#b34">[53]</ref> while sharing the learnable parameters across domains.  Domain Generalization. To further show the generalization performance acquired by the model trained with SAM, ASAM and SWA, we test it on the corrupted Cifar datasets <ref type="bibr" target="#b26">[27]</ref>. The test images are altered by 19 corruptions each with 5 levels of severity. <ref type="figure" target="#fig_6">Fig. 6</ref> shows the results on the highest severity and once again validate the efficacy of seeking flat minima in FL (complete results in App. D). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Heterogeneous Federated Learning suffers from degraded performances and slowdown in training due to the poor generalization of the learned global model. Inspired by recent trends in deep learning connecting the loss landscape and the generalization gap, we analyzed the behavior of the model through the lens of the geometry of the loss surface and linked the lack of generalization to convergence towards sharp minima. As a solution, we introduced Sharpness-Aware Minimization, its adaptive version and Stochastic Weight Averaging in FL for encouraging convergence towards flatter minima. We showed the effectiveness of this approach in several vision tasks and datasets.</p><p>32. Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing internal covariate shift. In: International conference on machine learning. pp. 448-456. PMLR (2015) 13, 25 33. Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., Wilson, A.G.: Averaging weights leads to wider optima and better generalization. Uncertainty in Artificial Intelligence (UAI) (2018) 2, 5, 6, 7, 9, 21, 22, 28 34. Jastrzebski, S., Kenton, Z., Ballas, N., Fischer, A., Bengio, Y., Storkey, A.: On the relation between the sharpest directions of dnn loss and the sgd step length. International Conference on Learning Representations (2019) 2 35. Jastrzebski, S., Szymczak, M., Fort, S., Arpit, D., Tabor, J., Cho, K., Geras, K.:</p><p>The </p><formula xml:id="formula_3">L D (? + ) ? L D (?)<label>(1)</label></formula><p>where ? is an hyper-parameter defining the neighborhood size and p ? [1, ?). SAM aims at minimizing the sharpness of the loss solving the following minmax objective:</p><formula xml:id="formula_4">min ??R d max || ||p?? L D (? + ) + ?||?|| 2 2<label>(2)</label></formula><p>where ? is a hyper-parameter weighing the importance of the regularization term.</p><p>In <ref type="bibr" target="#b19">[20]</ref>, it is shown that p = 2 is typically the optimal choice, hence, without loss of generality, we use the 2 -norm in the maximization over and omit the regularization term for simplicity. In order to obtain the exact solution of the inner maximization problem * arg max || ||2?? L(? + ), the authors propose to employ a first-order approximation of L(? + ) around 0: * ? arg max || ||2??</p><formula xml:id="formula_5">L D (?) + T ? ? L D (?) = ? ? ? L D (?) ||? ? L D (?)|| 2 =:? (?)<label>(3)</label></formula><p>Under this computationally efficient approximation,? (?) is nothing more than a scaled gradient of the current parameters ?. The sharpness-aware gradient is then defined as ? ? L D (?)| ?+? (?) and used to update the model as</p><formula xml:id="formula_6">? t+1 ? ? t ? ?? ?t L D (? t )| ?t+? t ,<label>(4)</label></formula><p>where ? is an appropriate learning rate and? t =? (? t ). This two-steps procedure is iteratively applied to solve Eq. 2. Intuitively, SAM performs a first step of gradient ascent to estimate the point (? t +? t ) at which the loss is approximately maximized and then applies gradient descent at ? t using the just computed gradient.</p><p>ASAM In [44], the authors point out that sharpness defined in a rigid region with a fixed radius ? (Eq. 1) is sensitive to parameter re-scaling, negatively affecting the connection between sharpness and generalization gap. If A is a scaling operator acting on the parameters space without changing the loss function, two neural networks with weights ? and A? can have different values of sharpness while maintaining the same generalization gap, i.e. the sharpness is scale-dependent. As a solution, they introduce the concept of adaptive sharpness, defined as max</p><formula xml:id="formula_7">||T ?1 ? ||p?? L D (? + ) ? L D (?)<label>(5)</label></formula><p>where T ?1 ? is the normalization operator of ? such that T ?1 A? A = T ?1 ? . Eq. 2 can be rewritten to define the Adaptive Sharpness-Aware Minimization (ASAM) problem as follows:</p><formula xml:id="formula_8">min ??R d max ||T ?1 ? ||p?? L D (? + ) + ?||?|| 2 2 (6)</formula><p>For improving stability, T ? is substituted by T ? + ?I w , where ? &gt; 0 is a hyperparameter controlling the trade-off between stability and adaptivity, while w is the number of weight parameters of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Stochastic Weight Averaging: Overview</head><p>SWA averages weights proposed by SGD, while using a learning rate schedule to explore regions of the weight space corresponding to high performing networks. At each step i of a cycle of length c, the learning rate is decreased from ? 1 to ? 2 :</p><formula xml:id="formula_9">?(i) = 1 ? t(i) ? 1 + t(i)? 2 , t(i) = 1 c mod(i ? 1, c) + 1<label>(7)</label></formula><p>If c = 1 the learning rate is constant (? 1 ), otherwise for c &gt; 1 the learning schedule is cyclical. Starting from a pre-trained model f?, SWA captures all the updates ? at the end of each cycle and averages them as:</p><p>? SWA ? ? SWA ? n models + ? n models + 1 <ref type="bibr" target="#b7">(8)</ref> obtaining the final model f ?SWA , where n models keeps track of the number of completed cycles. In our method, SWA is applied on the server-side to make the learning process more robust. Adapting the scenario of [33] to FL, from 75% of the training onwards, the server keeps two models, f ? and f ?SWA (f and f SWA to simplify the notation). f follows the standard FedAvg paradigm, while f SWA is updated every c rounds (Eq. 8). At each round, the cycling learning rate is computed (Eq. 7) and used for the clients' local training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Mixup and Cutout: Overview</head><p>Mixup and Cutout are recent methods for data augmentation, aiming to improve the learned models' generalization. We apply one of the two in the client-side training. </p><p>with ? ? Beta(?, ?) for ? ? (0, ?).</p><p>Cutout <ref type="bibr" target="#b15">[16]</ref> regularizes learning by randomly masking out square regions of the input during training. At the implementation level, this corresponds to applying a fixed-size zero-mask to a random location of the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Training in Heterogeneous Scenarios -Additional Material</head><p>In this section, we provide further analysis of the model's behavior in heterogeneous and homogeneous federated scenarios. As explained in Sec. 3.2, the model trained under a condition of statistical heterogeneity is subject to oscillations and loss in performance and generalization. Fluctuations in model predictions can also be noted by looking at its output features, defined as f ? (x) ?x ? X . <ref type="figure" target="#fig_8">Fig.  7</ref> shows the L2-norm of the output features computed using the current global model f t ? ?t ? [T ], given as input the local clients' data D k ?k ? [K], where a higher norm value corresponds to greater attention paid to that class by the network. The uniformity of the features obtained in the homogeneous setting contrasts with the chaotic distribution of the ones resulting when ? = 0, which significantly vary over time without following a constant trend. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Experiments Details</head><p>Here we provide a detailed description of the datasets and models used in the paper, together with information regarding the chosen hyper-parameters and their fine-tuning intervals. All results presented in both the main text and the Appendix are averaged over the last 100 rounds for increased robustness and reliability. Unless otherwise specified, the framework is PyTorch <ref type="bibr" target="#b43">[62]</ref> and experiments were run on one NVIDIA GeForce GTX 1070. <ref type="table" target="#tab_9">Table 9</ref> summarizes the tasks and the statistics of the number of clients and examples for each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Datasets and Models</head><p>CIFAR10 and CIFAR100 We replicate the federated version of the Cifar datasets proposed by <ref type="bibr" target="#b29">[30]</ref>. Each dataset is split among 100 clients, receiving 500 images each according to the latent Dirichlet distribution (LDA) applied to the labels. The client's examples are selected following a multinomial distribution drawn from a symmetric Dirichlet distribution with parameter ?. The higher the value of ? the larger the number of classes locally seen , i.e. the more similar and homogeneous the clients' distributions are. We test ? ? {0, 0.05, 100} on Cifar10 and ? ? {0, 0.5, 1000} on Cifar100. The task is image classification on 10 (Cifar10) and 100 (Cifar100) classes.</p><p>Model: We train a Convolutional Neural Network (CNN) similar to LeNet5 [45] on both datasets, following the setting of <ref type="bibr" target="#b30">[31]</ref>. The network has two 64-channels convolutional layers with kernel of size 5 ? 5, each followed by a 2 ? 2 max-pooling layer, ended by two fully connected layers with 384 and 192 channels respectively and a linear classifier.</p><p>Data pre-processing: The 32 ? 32 input images are pre-processed following the standard pipeline: the training images are randomly cropped applying padding 4 with final size 32 ? 32, randomly horizontally flipped with probability 0.5 and finally the pixel values are normalized with the dataset's mean and standard deviation; normalization is applied to test images as well.</p><p>CIFAR100-PAM We further extend our experiments to a more complex version of Cifar100, i.e. Cifar100-Pam proposed by <ref type="bibr" target="#b45">[64]</ref>, reflecting the "coarse" and "fine" label structure of the dataset for a more realistic partition. The dataset is split among 500 clients -with 100 images each -following the Pachinko Allocation Method (PAM) <ref type="bibr" target="#b32">[51]</ref>, on the result of which LDA is applied.</p><p>Model: We train a modified ResNet18, replacing Batch Normalization [32] layers with group normalization (GN) ones <ref type="bibr" target="#b59">[78]</ref>, as suggested by <ref type="bibr" target="#b28">[29]</ref>. We use two groups for each GN layer. Experiments have been run using FedJAX [65] on a cluster with NVIDIA V100 GPUs.</p><p>Data pre-processing: Cifar100-Pam images are pre-processed as the Cifar LDA versions described above.</p><p>CIFAR10-C and CIFAR100-C are the corrupted versions of the Cifar datasets. They are part of the benchmark proposed by <ref type="bibr" target="#b26">[27]</ref>, used for testing the image classifiers' robustness. The 10k images-test set is modified according to a given corruption and a corresponding level of severity. There are 19 possible corruptions (brightness, contrast, elastic blur, elastic transform, fog, frost, Gaussian blur, Gaussian noise, glass blur, impulse noise, JPEG compression, motion blur, pixelate, saturate, short noise, snow, spatter, speckle noise, zoom blur), while the severity ranges from 1 (low) to 5 (high).</p><p>Model: The same model described for Cifar10 and Cifar100 is used here. To test the generalization ability of our method, we test the model trained with Cifar10/100 on the corresponding corrupted dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Landmarks-User-160k</head><p>Introduced by <ref type="bibr" target="#b30">[31]</ref>, the Landmarks-User-160k dataset comprises 164,172 training images belonging to 2,028 landmarks. The dataset is created according to the authorship information from the large-scale dataset Google Landmarks v2 (GLv2) <ref type="bibr" target="#b58">[77]</ref>. Each author owns at least 30 pictures depicting 5 or more landmarks, while each location is depicted by at least 30 images and was visited by no less than 10 users. The authors in the test set do not overlap with the ones appearing in the training split.</p><p>available here 1 . All large-scale classification experiments have been performed using an NVIDIA DGX A100 40GB. The model trained on ImageNet reaches ? 68% top-1 accuracy on the validation set. In our experience, GroupNorm tends to perform slightly worse than BatchNorm when trained on ImageNet. However, since we did not extensively tune the hyper-parameters, getting better final performance is possible. For the ImageNet training, we used 8 GPUs with a total batch size of 2048 images.</p><p>Data pre-processing: We applied the same data augmentation for training the model on ImageNet and fine-tuning on GLv2: we crop and resize the input images to 224 ? 224 with random scale and aspect ratio as described in <ref type="bibr" target="#b54">[73]</ref>. The data augmentation pipeline used for the experiments can be found here 2 . We also adapted the GLv2 TensorFlow Federated data pipeline 3 to be compatible with FedJAX.</p><p>Cityscapes <ref type="bibr" target="#b13">[14]</ref> is a popular dataset for Semantic Segmentation and contains 2,975 real photos taken in the streets of 50 different cities under good weather conditions. Annotations are provided for 19 semantic classes. We refer to the federated splits proposed in the FedDrive benchmark <ref type="bibr" target="#b18">[19]</ref>. The uniform version of the dataset randomly assigns each image to one of the 146 users. In order to account for the distribution heterogeneity appearing in real-world scenarios, an ulterior version is proposed, referred to as heterogeneous: every client only accesses images from one of the 18 training cities. In both cases, the test set contains pictures of unseen cities. Data pre-processing: The images are randomly scaled in the range (0.5, 1.5) and cropped to a 512 ? 1024 shape.</p><p>IDDA [2] is a synthetic dataset for semantic segmentation, specific for the field of autonomous driving. In addition to the annotations for 16 semantic classes, the driving conditions are further characterized by three axes: a city among the 7 available, ranging from Urban to Rural environments; one of 5 viewpoints, simulating different vehicles; an atmospheric condition among 3 possible choices (Noon, Sunset, Rainy), for a total of 105 domains. As done for Cityscapes, we refer to FedDrive <ref type="bibr" target="#b18">[19]</ref> for the federated splits. In the uniform distribution of IDDA, each client has access to 48 images randomly drawn from the whole dataset. The heterogeneous version is built so that every user only sees a single domain. Two distinct testing scenarios are proposed to assess the generalization abilities of the learned model: one with images belonging to domains likely already seen at training time ("seen" in <ref type="table" target="#tab_8">Table 8</ref> of the main text) and another one containing a never-seen one ("unseen"). The unseen domain either contains images taken in the countryside ("country") to analyze the semantic shift or in rainy conditions ("rainy") for studying the shift in appearance.</p><p>Model: As done for Cityscapes, BiSeNetv2 is the model of choice.</p><p>Data pre-processing: The images are randomly scaled in the range (0.5, 2.0) and cropped to a 512 ? 928 shape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Hyper-parameters Tuning</head><p>We consider a different hyper-parameters setup for each dataset. The final choices of training hyper-parameters are summarized in <ref type="table" target="#tab_0">Table 10</ref>. <ref type="table" target="#tab_0">Table 11</ref> and 12 respectively show the values used for SAM/ASAM and SWA.</p><p>CIFAR10 and CIFAR100 For both datasets, the training hyper-parameters follow the choice of <ref type="bibr" target="#b30">[31]</ref>. The client learning rate is tuned between the values {0.01, 0.1} and set to 0.01, the batch size is 64, E ? {1, 2} is tested for the number of local epochs and the former is chosen. As for the weight decay the value 4 ? 10 ?4 leads to better performances than 0. The local optimizer is SGD with no momentum. No learning rate scheduler is used for simplicity. We optimize the cross-entropy loss. As for the server-side, we compare the behavior of different optimizers (i.e. SGD, Adam, AdaGrad) with learning rates in {0.001, 0.01, 0.1, 1} (results in Appendix E.1), following the setup of <ref type="bibr" target="#b45">[64]</ref>, and find out that FedAvg, i.e. SGD with learning rate 1, is the best choice. When testing FedAvgM, the server-side momentum ? = 0.9. As for the other SOTAs, we choose ? = 0.1 in FedProx and ? = 0.01 in FedDyn from {0.001, 0.01, 0.1}; in AdaBest, we tune ? ? {0.8, 0.9} and ? ? {0.01, 0.02} and pick (0.9, 0.02) for Cifar10 and (0.8, 0.02) for Cifar100. The training proceeds for 10k rounds on Cifar10 and 20k rounds on Cifar100. Mixup/Cutout: Following the setup of [87], we fix ? mixup = 1, resulting in ? uniformly distributed between 0 and 1. As for Cutout instead, we select a cutout size of 16 ? 16 pixels for Cifar10 and 8 ? 8 for Cifar100, as done by <ref type="bibr" target="#b15">[16]</ref>.  <ref type="table" target="#tab_0">Table 11</ref>. There is no distinction of values as clients vary per round.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SWA:</head><p>We test SWA's starting round in {5%, 25%, 50%, 75%} of the rounds budget and as expected [33] the best contribution is given if applied from 75% of the training onwards (see Appendix E). We set the value of the learning rate ? 1 to 0.01 and test ? 2 ? {10 ?5 , 10 ?4 , 10 ?3 }, selecting ? 2 = 10 ?4 . The cycle length c is tested in {5, 10, 20} and set to 10 for Cifar10 and 20 for Cifar100. <ref type="table" target="#tab_0">Table 12</ref> summarizes the choices.</p><p>CIFAR100-PAM The hyper-parameters follow the same choice of <ref type="bibr" target="#b45">[64]</ref> (see <ref type="table" target="#tab_0">Table 10</ref>). We report accuracy at 5K and 10K communication rounds.</p><p>Mixup/Cutout: Same as Cifar100.</p><p>SAM/ASAM: We search hyperpameters in the same values as Cifar100. For ? we found 0.05 and 0.5 to be the best values respectively for SAM and ASAM in all configurations. For ASAM we found that ? = 0.2 is working fine when cutout or no augmentations are applied, while ? = 0 works best in the case of Mixup.</p><p>SWA: Same as Cifar100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Landmarks-User-160k</head><p>We start from the hyper-parameters proposed by <ref type="bibr" target="#b30">[31]</ref>.</p><p>In contrast with the original paper, we found that FedAvgM with momentum ? = 0.9 is unstable with 10 participating clients and requires reducing the server learning rate to 0.1 to train the model. Better performance and faster convergence can be obtained with 50 clients per round and ? = 0.9. However, we use 10 clients per round and FedAvg as the baseline because of our limited resources and to maintain consistency with other experiments. All hyper-parameters are described in <ref type="table" target="#tab_0">Table 10</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SWA:</head><p>We tested both SWA starting at the 75% and 100% of training, i.e. the 3750-th and 5000-th rounds. We tested different combinations of cycle lengths c ? {5, 10, 20} and learning rate ? 2 ? {10 ?2 , 10 ?3 , 10 ?4 }. The best performing learning rates (? 1 , ? 2 ) are respectively (10 ?1 , 10 ?3 ) and the cycle length is 5.</p><p>Cityscapes and IDDA For both Cityscapes and IDDA, we maintain the choice of hyper-parameters of <ref type="bibr" target="#b18">[19]</ref>. The clients' initial learning rate is 0.05 on Cityscapes and 0.1 on IDDA, the weight decay is 5 ? 10 ?4 on Cityscapes, while it is not used on IDDA, 2 local epochs, the client optimizer is SGD with momentum 0.9. Differently from <ref type="bibr" target="#b18">[19]</ref>, we do not use mixed precision, thus the batch size is reduced from 16 to 8. A polynomial learning rate scheduler is applied locally, following <ref type="bibr">[83]</ref>. The optimization is based on the Online Hard-Negative Mining <ref type="bibr" target="#b50">[69]</ref>, which selects the 25% of the pixels having the highest cross-entropy loss. The training is spanned across 1.5k rounds. SWA: Following the setup established for the Cifar datasets, SWA starts at the 75% of training, i.e. the 1125th round. The learning rates (? 1 , ? 2 ) are respectively (10 ?1 , 10 ?3 ) for IDDA and (5 ? 10 ?2 , 5 ? 10 ?4 ) for Cityscapes. The cycle length is 5 for both datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Plotting the Loss Landscapes</head><p>In the main text, we introduced both 2-D ( <ref type="figure" target="#fig_1">Fig. 2</ref> of the main text) and 3-D plots of the loss landscapes ( <ref type="figure">Fig. 1 of the main text)</ref>. Implementation details follow.</p><p>2D Loss Landscape Following the indications of <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b40">59]</ref>:</p><p>1. We choose three weight vectors ? 1 , ? 2 , ? 3 and use them to obtain two basis vectors u = (? 2 ? ? 1 ) and v = (? 3 ? ? 1 ) ? ?3??1,?2??1 ||?2??1|| 2 ? (? 2 ? ? 1 ). 2. Then, the normalized vectors? = u /||u|| andv = v /||v|| form an orthonormal basis in the plain containing ? 1 , ? 2 , ? 3 .</p><p>3. We now define a Cartesian grid of N ? N points in the basis?,v. In our case, N = 21. 4. For each point of the grid, the corresponding weights are computed and the loss is consequently evaluated with the resulting network. For each point P of the grid having coordinates (x, y), the corresponding weights are computed as P = ? 1 + x ?? + y ?v. As a consequence, ? 1 is the reference and can be found in the origin (0, 0).</p><p>We adapted the code of <ref type="bibr" target="#b21">[22]</ref> 4 to our scenario.</p><p>3D Loss Landscape The plots in <ref type="figure">Fig. 1</ref> in the main text are generated using the code of [46] 5 , modified to fit our datasets and models. Given a network architecture and its pre-trained parameters, the loss surface is computed along random directions near the optimal parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Computing Hessian Eigenvalues</head><p>We refer to <ref type="bibr" target="#b41">[60]</ref> for computing both the local and the top 50 Hessian eigenvalues (Figs. 4,5 in the main text) with Stochastic Power Iteration method <ref type="bibr" target="#b61">[80]</ref> with maximum 20 iterations per run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Results on Corrupted CIFAR10 and CIFAR100</head><p>In <ref type="figure" target="#fig_12">Fig. 8</ref>, we compare the performance obtained by FedAvg, FedSAM, FedASAM, FedAvg + SWA, FedSAM + SWA and FedASAM + SWA on Cifar10-C and Cifar100-C as ? varies. All results tell us that ASAM (alone or combined with SWA) is the algorithm with the best generalization capabilities, as already seen in Sec. 5.2 of the main text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Ablation Studies</head><p>In this Section, we present our ablation studies on server-side optimizers, SAM, ASAM and SWA, moved from the main text due to space constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Ablation Study on Server-Side Optimizers</head><p>To choose the best server-side optimizer, we test SGD, Adam and AdaGrad on the heterogeneous (? = 0) and homogeneous (? = 1k) versions of Cifar100 with 5 clients per round. Following <ref type="bibr" target="#b45">[64]</ref>, we set ? 1 = ? 2 = 0 for AdaGrad and ? 1 = 0.9, ? 2 = 0.99 for Adam. As <ref type="table" target="#tab_0">Table 13</ref> shows, SGD with learning rate 1, i.e. FedAvg, is certainly the best choice to have acceptable performances both in the homogeneous scenario and above all in the heterogeneous one. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Ablation Study on SAM and ASAM</head><p>We present here an analysis on the sensitivity of the model to the hyper-parameters ? and ? in ASAM and ? in SAM ( <ref type="figure" target="#fig_13">Fig. 9</ref>), having as a reference the setting with 5% clients participation on Cifar100. Regardless of the distribution, we can see that high values of SAM's ? lead to a fast decline in performance ( <ref type="figure" target="#fig_13">Fig. 9a)</ref>, meaning that the algorithm handles smaller neighborhoods better. On the other hand, ASAM allows us to have more freedom and expand the size of the neighborhood up to the value of ? = 0.5 <ref type="figure" target="#fig_13">(Fig. 9b)</ref>, index of the greater robustness of the method. In <ref type="figure" target="#fig_13">Fig. 9c</ref>, we notice that the performances improve linearly as ? increases, where ? is a hyper-parameter balancing the trade-off between stability and adaptivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Ablation Study on SWA</head><p>SWA adds two new concepts to the standard federated training: the average of stochastic weights collected along the trajectory of SGD (Eq. 8) and the cyclical learning rate (Eq. 7), which decreases from ? 1 to ? 2 according to the cycle length c, transmitted as additional information to the clients of each round. Our ablation  studies aim to understand which of these two components has the greatest impact on the achieved stability and increased model performance. We compare the results obtained by SWA with c &gt; 1 with those reached when the learning rate is kept constant, i.e. c = 1, and when the server-side average of the collected weights is not applied while maintaining c &gt; 1, i.e. changing only the clients' learning rate cyclically <ref type="table" target="#tab_0">(Table 14</ref>). We point out that using c = 1 and not applying the average brings us back to the standard federated setting. We discover that the server-side average gives the major contribution, which helps in stabilizing learning, while the cycle length does not particularly affect the results. Since the best results in the most difficult scenarios (i.e. low value of both ? and number of participating clients on Cifar100) are reached when c &gt; 1, we prefer the cyclical learning rate to the constant one in further experiments.</p><p>In addition, in <ref type="table" target="#tab_0">Table 15</ref> we report the differences in results when applying SWA from {5%, 25%, 50%, 75%} of the training onwards on FedAvg with 5 clients per round, showing that a longer pre-training of the network leads to the greater effectiveness of this algorithm.   <ref type="table" target="#tab_0">Table 16</ref> completes the analysis introduced in Sec. 5.1 regarding the gains obtained in the federated scenario w.r.t. the centralized one. Here we report the results for ? ? {0, 1k}. As noted for ? = 0 ( <ref type="table" target="#tab_5">Table 5</ref> in the main text), data augmentations fail in the federated heterogeneous scenarios (? ? {0, 0.5}), but reasonably work in the homogeneous ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Data Augmentations with CIFAR10</head><p>Here we show the results obtained when applying Mixup and Cutout to Cifar10 as the value of ?, clients participation and algorithm change ( <ref type="table" target="#tab_0">Table 17</ref>). As demonstrated for Cifar100 (Sec. 5.1), data augmentations do not improve generalization in a federated context, but on the contrary they seem to inhibit learning, leading to sometimes even worse results than FedAvg.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Figures Omitted in the Main Text</head><p>All plots are best seen in colors.</p><p>Convergence plots As shown in Sec. 5.1, once combined with FedAvgM-i.e. serverside momentum ? = 0.9 -SAM and ASAM allow to reach convergence even in the most heterogeneous scenarios on both Cifar10 and Cifar100. <ref type="figure" target="#fig_3">Fig. 10</ref> shows the convergence plots of those runs. In addition, <ref type="figure">Fig. 11</ref> compares the behavior of FedAvg, FedSAM, FedASAM and their combination with SWA on the most difficult setting, i.e. ? = 0 and 5 clients per round on both Cifar datasets, highlighting the stability and the positive gap in performance introduced by SWA.</p><p>Loss Surfaces <ref type="figure" target="#fig_1">Fig. 12</ref> shows the convergence points of three local models trained with ? = 0.5 on the corresponding test error surface, while <ref type="figure" target="#fig_2">Fig. 13</ref> displays the train loss surfaces with ? ? {0, 0.5, 1000}. In addition, in <ref type="figure" target="#fig_4">Fig. 14</ref> we compare the convergence points of FedAvg, FedSAM and FedASAM in the heterogeneous scenarios of Cifar100, i.e. ? ? {0, 0.5}, proving that ASAM reaches the best local minimum.</p><p>Hessian Eigenvalues The top 50 eigenvalues of the global model trained with ? = 0.5 are showed in <ref type="figure" target="#fig_5">Fig. 15. Fig. 16</ref> shows the complete comparison of the local Hessian eigenvalues partially shown in Sec. 3.2, introducing the values of ? k max ?k ? [K] resulting with SAM and ? = 0.5.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FedAvg ? = 0 Fig. 1 :</head><label>01</label><figDesc>FedASAM ? = 0 FedAvg ? = 1k FedASAM ? = 1k Cross-entropy loss landscapes of the global model in heterogeneous (? = 0) and homogeneous (? = 1k) federated scenarios on Cifar100. When trained with FedAvg, the global model converges towards sharp minima. The sharpness-aware optimizer ASAM significantly smooths the surfaces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Left: CNN convergence points in distinct federated scenarios with ? ? [0, 0.5, 1k] on Cifar100. Please refer to Appendix C for implementation details. (a) Train loss surface showing the weights obtained at convergence. (b) Test error surface of the same models. Right: Test error surfaces computed on Cifar100 using three distinct local models after training. (c) When ? = 0, the local models are not able to generalize to the overall data distribution, being too specialized on the local data. (d) When ? = 1k, the resulting models are connected through a low-loss region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Cifar100 Accuracy trends. Left: Global model on local distributions with (a) ? = 0 and (b) 1k @ 20k rounds. Each color represents a local distribution (i.e. one class for ? = 0). (c): ? ? {0, 0.5, 1k} with necessary rounds to reach convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FedAvg ? = 0 ASAM ? = 0</head><label>0</label><figDesc>FedAvg ? = 1k ASAM ? = 1k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>? k max for each client k as rounds pass</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Hessian eigenspectra of the global model with ? ? {0, 1k}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 :</head><label>6</label><figDesc>n_ blu r ga us sia n_ no ise gla ss_ blu r im pu lse _n ois e jpe g_ co mp res sio n mo tio n_ blu r n_ blu r ga us sia n_ no ise gla ss_ blu r im pu lse _n ois e jpe g_ co mp res sio n mo tio n_ blu r pix ela te sa tur ate sh ot_ no ise sn ow sp att er sp ec kle _n ois e zo om Domain generalization in FL. Results with ? = 0, 20 clients, severity level 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>break-even point on optimization trajectories of deep neural networks. arXiv preprint arXiv:2002.09572 (2020) 8 36. Jiang, Y., Neyshabur, B., Mobahi, H., Krishnan, D., Bengio, S.: Fantastic generalization measures and where to find them. arXiv preprint arXiv:1912.02178 (2019) 2, 4, 7 37. Kairouz, P., McMahan, H.B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A.N., Bonawitz, K., Charles, Z., Cormode, G., Cummings, R., et al.: Advances and open problems in federated learning. arXiv preprint arXiv:1912.04977 (2019) 3 38. Karimireddy, S.P., Kale, S., Mohri, M., Reddi, S., Stich, S., Suresh, A.T.: Scaffold: Stochastic controlled averaging for federated learning. In: International Conference on Machine Learning. pp. 5132-5143. PMLR (2020) 2, 3, 7, 12 39. Keskar, N.S., Mudigere, D., Nocedal, J., Smelyanskiy, M., Tang, P.T.P.: On largebatch training for deep learning: Generalization gap and sharp minima. International Conference on Learning Representations (2017) 2, 4, 7 40. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. ICLR (2015) 8 41. Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A.A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et al.: Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences 114(13), 3521-3526 (2017) 6 42. Kleinberg, B., Li, Y., Yuan, Y.: An alternative view: When does sgd escape local minima? In: International Conference on Machine Learning. pp. 2698-2707. PMLR (2018) 2 43. Krizhevsky, A., Hinton, G., et al.: Learning multiple layers of features from tiny images (2009) 6, 10 44. Kwon, J., Kim, J., Park, H., Choi, I.K.: Asam: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks. International Conference on Machine Learning (2021) 2, 5, 7, 9, 21, 22 45. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11), 2278-2324 (1998) 24 46. Li, H., Xu, Z., Taylor, G., Studer, C., Goldstein, T.: Visualizing the loss landscape of neural nets. In: Neural Information Processing Systems (2018) 2, 4, 7, 30 47. Li, Q., Diao, Y., Chen, Q., He, B.: Federated learning on non-iid data silos: An experimental study. arXiv preprint arXiv:2102.02079 (2021) 12 48. Li, Q., He, B., Song, D.: Model-contrastive federated learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10713-10722 (2021) 1, 3, 7 49. Li, T., Sahu, A.K., Talwalkar, A., Smith, V.: Federated learning: Challenges, methods, and future directions. IEEE Signal Processing Magazine 37(3), 50-60 (2020) 3 83. Yu, C., Gao, C., Wang, J., Yu, G., Shen, C., Sang, N.: Bisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation. International Journal of Computer Vision 129(11), 3051-3068 (2021) 26, 29 84. Yuan, H., Morningstar, W., Ning, L., Singhal, K.: What do we mean by generalization in federated learning? NeurIPS Workshop (2021) 3, 5 85. Yue, X., Nouiehed, M., Kontar, R.A.: Salr: Sharpness-aware learning rates for improved generalization. arXiv preprint arXiv:2011.05348 (2020) 2 86. Zhang, C., Xie, Y., Bai, H., Yu, B., Li, W., Gao, Y.: A survey on federated learning. Knowledge-Based Systems 216, 106775 (2021) 3 87. Zhang, H., Cisse, M., Dauphin, Y.N., Lopez-Paz, D.: mixup: Beyond empirical risk minimization. International Conference on Learning Representations (2018) 11, 12, 23, 28 88. Zhang, L., Luo, Y., Bai, Y., Du, B., Duan, L.Y.: Federated learning for non-iid data via unified feature learning and optimization objective alignment. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 4420-4428 (October 2021) 1 89. Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., Chandra, V.: Federated learning with non-iid data. arXiv preprint arXiv:1806.00582 (2018) 1, 3 A Background In this section, we briefly review the details of Sharpness-Aware Minimization (SAM) [20], its adaptive version (ASAM) [44] and Stochastic Weight Averaging (SWA) [33]. A.1 SAM and ASAM: Overview SAM aims at finding the solution ? surrounded by a neighborhood having uniform low training loss L D (?), i.e. located in a flat minimum. The sharpness of a training loss function is defined as: max || ||p??</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 :</head><label>7</label><figDesc>Cifar100. L2-norm of global classifier output features as rounds pass, after receiving as input each client's local data. (a) with ? = 0, the model tends to focus on a different client's distribution, i.e. on a single class, at each round. (b) when ? = 1000, the model gives the same attention to each distribution. mixup [87] trains the neural network on convex combinations of images and their labels, exploiting the prior knowledge that linear interpolation of features leads to linear interpolations of their corresponding targets. Given two input images (x i , x j ) and their corresponding one-hot label encodings (y i , y j ) drawn from the k-th client's training data D k , virtual training examples are constructed as follows:x = ?x i + (1 ? ?)x j y = ?y i + (1 ? ?)y j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Model:</head><label></label><figDesc>As proposed by the authors of FedDrive, we employ the lightweight network BiSeNetv2 [83] for training, accounting for possible lower computational capabilities of the edge devices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>SAM/ASAM: The parameter ? of SAM is searched in {0.01, 0.02, 0.05, 0.1, 0.2, 0.5}. As for ASAM, the value of ? is tuned in {0.05, 0.1, 0.2, 0.5, 0.7, 1.0, 2.0} and ? ? {0.0, 0.01, 0.1, 0.2}. The choices made for each dataset and ? are shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>SAM/ASAM: The parameter ? of SAM is searched in {0.01, 0.05, 0.1}. As for ASAM, the value of ? is tuned in the set {0.05, 0.1, 0.5} and ? ? {0.0, 0.1, 0.2}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 8 :</head><label>8</label><figDesc>es s co nt ra st de fo cu s_ blu r ela sti c_ tra ns fo rm fo g fro st ga us sia n_ blu r ga us sia n_ no ise gla ss _b lur im pu lse _n ois e jpe g_ co m pr es sio n m ot ion _b lur pix ela te sa tu ra te sh ot _n ois e sn ow sp at te r sp ec kle _n ois e zo om _b lur ? = 0 cle an br igh tn es s co nt ra st de fo cu s_ blu r ela sti c_ tra ns fo rm fo g fro st ga us sia n_ blu r ga us sia n_ no ise gla ss _b lur im pu lse _n ois e jpe g_ co m pr es sio n m ot ion _b lur pix ela te sa tu ra te sh ot _n ois e sn ow sp at te r sp ec kle _n ois e zo om _b lur es s co nt ra st de fo cu s_ blu r ela sti c_ tra ns fo rm fo g fro st ga us sia n_ blu r ga us sia n_ no ise gla ss _b lur im pu lse _n ois e jpe g_ co m pr es sio n m ot ion _b lur pix ela te sa tu ra te sh ot _n ois e sn ow sp at te r sp ec kle _n ois e zo om _b lur ? = 0.5cle an br igh tn es s co nt ra st de fo cu s_ blu r ela sti c_ tra ns fo rm fo g fro st ga us sia n_ blu r ga us sia n_ no ise gla ss _b lur im pu lse _n ois e jpe g_ co m pr es sio n m ot ion _b lur pix ela te sa tu ra te sh ot _n ois e sn ow sp at te r sp ec kle _n ois e zo om _b lur es s co nt ra st de fo cu s_ blu r ela sti c_ tra ns fo rm fo g fro st ga us sia n_ blu r ga us sia n_ no ise gla ss _b lur im pu lse _n ois e jpe g_ co m pr es sio n m ot ion _b lur pix ela te sa tu ra te sh ot _n ois e es s co nt ra st de fo cu s_ blu r ela sti c_ tra ns fo rm fo g fro st ga us sia n_ blu r ga us sia n_ no ise gla ss _b lur im pu lse _n ois e jpe g_ co m pr es sio n m ot ion _b lur pix ela te sa tu ra te sh ot _n ois e sn ow sp at te r sp ec kle _n ois e zo om _b lur Domain generalization in FL. Results with 20 clients, severity level 5 on Cifar10-C and Cifar100-C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 9 :</head><label>9</label><figDesc>Results on Cifar100, 5% clients participation. (a) Sensitivity to SAM's parameter ?. (b)-(c) Sensitivity to ASAM's parameters ? (with fixed ? = 0.2) and ? (with fixed ? = 0.5) as ? varies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 10 :Fig. 11 :Fig. 12 :Fig. 13 :Fig. 14 :</head><label>1011121314</label><figDesc>Convergence plots with ? = 0, 20 clients. When combining FedAvgM or FedSAM (Cifar100)/FedASAM (Cifar10) with SWA, convergence is reached even in the most heterogeneous scenarios. FedAvgM + SWA applied to Cifar10 fails to learn, while adding momentum to FedASAM significantly speeds up training. Convergence plots with ? = 0, 5 clients, highlighting the positive gap in performance and the stability introduced by SWA (both if applied on FedAvg but especially on FedASAM) in the most difficult setting. Test error surface computed on Cifar100 using three distinct local models trained with ? = 0.5 for 20k rounds. Train cross-entropy loss surfaces computed with three local models after 20k training rounds on Cifar100.(a) ? = 0 (b) ? = 0.5 (c) ? = 1000. Loss surfaces comparing the convergence points of FedAvg, FedSAM and FedASAM after 20k training rounds on Cifar100. The minima reached by SAM and ASAM are found within low-loss neighborhoods. (a) Train loss surface ? = 0. (b) Test error surface ? = 0. (c) Train loss surface ? = 0.5. (d) Test error surface ? = 0.5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 15 :FedAvg ? = 0. 5 Fig. 16 :</head><label>15516</label><figDesc>Top 50 eigenvalues of the global model with ? = 0.5 on Cifar100. FedAvg ? = 0 FedSAM ? = 0 FedASAM ? = 0 FedSAM ? = 0.5 FedASAM ? = 0.5 FedAvg ? = 1k FedSAM ? = 1k FedASAM ? = 1k Maximum Hessian eigenvalue computed for each client as rounds pass.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Cifar100 Hessian eigenvalues.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Algorithm</cell><cell cols="8">?max ? = 0 ? = 1k ? = 0 ? = 1k ?max/? 5</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">FedAvg E=1</cell><cell cols="7">93.46 106.14 2.00</cell><cell>1.31</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">FedAvg E=2</cell><cell cols="7">110.62 118.35 2.32</cell><cell>1.30</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">FedSAM</cell><cell cols="7">70.29 51.28 1.79</cell><cell>1.48</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">FedASAM</cell><cell cols="7">30.11 20.19 1.80</cell><cell>1.27</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="9">FedAvg + SWA 97.24 120.02 1.49</cell><cell>1.39</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="7">FedSAM + SWA 73.16 54.20</cell><cell cols="2">1.56</cell><cell>1.61</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="9">FedASAM + SWA 24.57 20.49 1.51</cell><cell>1.30</cell></row><row><cell>Eigenvalue</cell><cell>40 60 80 100</cell><cell></cell><cell></cell><cell></cell><cell cols="2">FedAvg E=1 FedAvg E=2 ASAM SAM FedAvg+SWA SAM+SWA ASAM+SWA</cell><cell>Eigenvalue</cell><cell>40 60 80 100 120</cell><cell></cell><cell></cell><cell></cell><cell>FedAvg E=1 FedAvg E=2 ASAM SAM FedAvg+SWA SAM+SWA ASAM+SWA</cell></row><row><cell></cell><cell>20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>20</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0</cell><cell>10</cell><cell>20 Eigenvalue Index 30</cell><cell>40</cell><cell>50</cell><cell></cell><cell>0</cell><cell>0</cell><cell>10</cell><cell cols="2">20 Eigenvalue Index 30</cell><cell>40</cell><cell>50</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>FedSAM, FedASAM and SWA on Cifar100 and Cifar10</figDesc><table><row><cell></cell><cell>Algorithm</cell><cell>5cl</cell><cell>? = 0 10cl</cell><cell>20cl</cell><cell>5cl</cell><cell cols="3">? = 0.5/0.05 10cl 20cl</cell><cell>5cl</cell><cell cols="2">? = 1000/100 10cl 20cl</cell></row><row><cell></cell><cell>FedAvg E=1</cell><cell>30.25</cell><cell>36.74</cell><cell>38.59</cell><cell cols="2">40.43</cell><cell>41.27</cell><cell>42.17</cell><cell cols="2">49.92</cell><cell>50.25</cell><cell>50.66</cell></row><row><cell>Cifar100</cell><cell>FedAvg E=2 FedSAM FedASAM FedAvg + SWA FedSAM + SWA</cell><cell>24.94 31.04 36.04 39.34 39.30</cell><cell>31.81 36.93 39.76 39.74 39.51</cell><cell>35.18 38.56 40.81 39.85 39.24</cell><cell cols="2">38.21 44.73 45.61 43.90 47.96</cell><cell>39.59 44.84 46.58 44.02 46.76</cell><cell>40.94 46.05 47.78 42.09 46.47</cell><cell cols="2">48.72 54.01 54.81 50.98 53.90</cell><cell>48.64 53.39 54.97 50.87 53.67</cell><cell>48.45 53.97 54.50 50.92 54.36</cell></row><row><cell></cell><cell>FedASAM + SWA</cell><cell>42.01</cell><cell>42.64</cell><cell>41.62</cell><cell cols="2">49.17</cell><cell>48.72</cell><cell>48.27</cell><cell cols="2">53.86</cell><cell>54.79</cell><cell>54.10</cell></row><row><cell></cell><cell>FedAvg E=1</cell><cell>65.00</cell><cell>65.54</cell><cell>68.52</cell><cell cols="2">69.24</cell><cell>72.50</cell><cell>73.07</cell><cell cols="2">84.46</cell><cell>84.50</cell><cell>84.59</cell></row><row><cell></cell><cell>FedAvg E=2</cell><cell>61.49</cell><cell>62.22</cell><cell>66.36</cell><cell cols="2">69.23</cell><cell>69.77</cell><cell>73.48</cell><cell cols="2">83.93</cell><cell>84.10</cell><cell>84.21</cell></row><row><cell>Cifar10</cell><cell>FedSAM FedASAM FedAvg + SWA</cell><cell>70.16 73.66 69.71</cell><cell>71.09 74.10 69.54</cell><cell>72.90 76.09 70.19</cell><cell cols="2">73.52 75.61 73.48</cell><cell>74.81 76.22 72.80</cell><cell>76.04 76.98 73.81</cell><cell cols="2">84.58 84.77 84.35</cell><cell>84.67 84.72 84.32</cell><cell>84.82 84.75 84.47</cell></row><row><cell></cell><cell>FedSAM + SWA</cell><cell>74.97</cell><cell>73.73</cell><cell>73.06</cell><cell cols="2">76.61</cell><cell>75.84</cell><cell>76.22</cell><cell cols="2">84.23</cell><cell>84.37</cell><cell>84.63</cell></row><row><cell></cell><cell>FedASAM + SWA</cell><cell>76.44</cell><cell>75.51</cell><cell>76.36</cell><cell cols="2">76.12</cell><cell>76.16</cell><cell>76.86</cell><cell cols="2">84.88</cell><cell>84.80</cell><cell>84.79</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Accuracy results on Cifar100-PAM with ResNet18 FedSAM 50.71 53.10 55.44 52.96 53.41 54.67 52.36 52.04</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">E = 1</cell><cell></cell><cell></cell><cell></cell><cell>E = 2</cell></row><row><cell cols="2">Algorithm Aug</cell><cell></cell><cell>10 clients</cell><cell></cell><cell></cell><cell>20 clients</cell><cell></cell><cell></cell><cell>10 clients</cell><cell>20 clients</cell></row><row><cell></cell><cell></cell><cell>@5k</cell><cell cols="2">@10k w/ SWA</cell><cell>@5k</cell><cell cols="2">@10k w/ SWA</cell><cell>@5k</cell><cell>@10k w/ SWA</cell><cell>@5k</cell><cell>@10k w/ SWA</cell></row><row><cell>FedAvg</cell><cell></cell><cell cols="2">46.60 47.03</cell><cell>52.70</cell><cell cols="2">46.51 45.83</cell><cell>50.28</cell><cell cols="2">44.58 43.90</cell><cell>51.10</cell><cell>43.31 42.88</cell><cell>47.95</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>55.23</cell><cell>51.41 51.35</cell><cell>53.41</cell></row><row><cell>FedASAM</cell><cell></cell><cell cols="2">49.31 51.10</cell><cell>54.25</cell><cell cols="3">47.21 53.50 54.29</cell><cell cols="2">49.03 49.33</cell><cell>53.01</cell><cell>53.88 52.94</cell><cell>54.18</cell></row><row><cell>FedAvg FedSAM FedASAM</cell><cell>Mixup</cell><cell cols="3">43.47 49.25 42.83 51.92 53.96 56.71 43.13 51.09 56.31</cell><cell cols="3">50.33 49.89 49.66 55.77 57.70 55.74 50.51 52.62 56.89</cell><cell cols="2">44.76 46.44 42.17 51.04 44.74 50.14 58.31 57.15 56.54</cell><cell>47.10 47.59 53.50 54.75 58.88 54.40 49.87 50.87 55.86</cell></row><row><cell>FedAvg FedSAM FedASAM</cell><cell>Cutout</cell><cell cols="3">48.64 48.59 48.28 53.53 47.52 52.13 57.01 55.40 57.25</cell><cell cols="5">47.00 46.96 52.06 54.37 56.70 49.39 51.88 57.32 52.16 52.37 51.70 45.19 45.46 55.40 44.68 44.25 50.01 50.66 53.54 48.99 50.09 55.77 48.48 48.77</cell><cell>49.39 55.45 52.00</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>FedAvg, SAM, ASAM and SWA w/ strong data augmentations (Mixup, Cutout)</figDesc><table><row><cell></cell><cell>Algorithm</cell><cell>SWA</cell><cell>Aug</cell><cell>5cl</cell><cell>? = 0 10cl</cell><cell>20cl</cell><cell>5cl</cell><cell cols="3">? = 0.5/0.05 10cl 20cl</cell><cell>5cl</cell><cell>? = 1000/100 10cl 20cl</cell></row><row><cell></cell><cell>FedAvg</cell><cell></cell><cell></cell><cell>29.91</cell><cell>33.67</cell><cell>35.67</cell><cell cols="2">35.10</cell><cell>37.80</cell><cell>39.34</cell><cell cols="2">55.34</cell><cell>55.81</cell><cell>55.98</cell></row><row><cell></cell><cell>FedSAM</cell><cell></cell><cell></cell><cell>30.46</cell><cell>34.10</cell><cell>35.89</cell><cell cols="2">38.76</cell><cell>40.31</cell><cell>42.03</cell><cell cols="2">54.21</cell><cell>54.94</cell><cell>55.24</cell></row><row><cell>Cifar100</cell><cell>FedASAM FedAvg FedSAM FedASAM FedAvg FedSAM FedASAM FedAvg FedSAM</cell><cell></cell><cell>Mixup Cutout</cell><cell>34.04 35.56 35.62 40.08 24.24 23.51 30.05 33.65 34.00</cell><cell>36.82 36.07 36.25 38.74 31.55 30.92 33.62 34.40 34.08</cell><cell>36.97 36.08 35.66 37.47 32.44 33.12 34.51 35.03 34.26</cell><cell cols="2">40.71 39.21 42.13 44.53 37.72 40.33 41.86 40.43 43.09</cell><cell>42.24 39.22 41.95 43.97 38.45 40.31 41.84 40.12 42.81</cell><cell>44.45 38.31 42.03 44.22 39.48 42.58 43.33 39.32 42.85</cell><cell cols="2">49.75 55.43 52.9 46.97 53.48 54.27 51.88 53.87 53.78</cell><cell>49.87 55.37 53.14 47.24 53.83 54.75 51.78 54.09 54.28</cell><cell>49.68 55.39 53.48 46.93 52.90 54.76 53.03 52.75 53.93</cell></row><row><cell></cell><cell>FedASAM</cell><cell></cell><cell></cell><cell>39.30</cell><cell>37.46</cell><cell>36.27</cell><cell cols="2">44.76</cell><cell>43.48</cell><cell>43.95</cell><cell cols="2">50.00</cell><cell>49.65</cell><cell>50.81</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Comparison of improvements (%) in centralized and heterogeneous federated scenarios (? = 0, 5 clients) on Cifar100, computed w.r.t. the reference at the bottom</figDesc><table><row><cell>Algorithm</cell><cell cols="2">Accuracy Centr. ? = 0</cell><cell cols="2">Absolute Improvement Centr. ? = 0</cell><cell cols="2">Relative Improvement Centr. ? = 0</cell></row><row><cell>SAM</cell><cell>55.22</cell><cell>31.04</cell><cell>+3.02</cell><cell>+0.79</cell><cell>+5.79</cell><cell>+2.61</cell></row><row><cell>ASAM</cell><cell>55.66</cell><cell>36.04</cell><cell>+3.46</cell><cell>+5.79</cell><cell>+6.63</cell><cell>+19.14</cell></row><row><cell>SWA</cell><cell>52.72</cell><cell>39.34</cell><cell>+0.52</cell><cell>+9.09</cell><cell>+1.00</cell><cell>+30.05</cell></row><row><cell>SAM + SWA</cell><cell>55.75</cell><cell>39.30</cell><cell>+0.55</cell><cell>+9.05</cell><cell>+1.06</cell><cell>+29.92</cell></row><row><cell>ASAM + SWA</cell><cell>55.96</cell><cell>42.01</cell><cell>+3.76</cell><cell>+11.76</cell><cell>+7.20</cell><cell>+38.88</cell></row><row><cell>Mixup</cell><cell>58.01</cell><cell>29.91</cell><cell>+5.81</cell><cell>-0.34</cell><cell>+11.13</cell><cell>-1.12</cell></row><row><cell>Cutout</cell><cell>55.30</cell><cell>24.24</cell><cell>+3.10</cell><cell>-6.01</cell><cell>+5.94</cell><cell>-19.87</cell></row><row><cell cols="3">Centralized: 52.20 -FedAvg: 30.25</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>SOTA comparison on Cifar10 and Cifar100 (centralized performance)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">w/o SWA</cell><cell></cell><cell></cell><cell cols="2">w/ SWA</cell><cell></cell></row><row><cell></cell><cell>Algorithm</cell><cell cols="2">? = 0</cell><cell cols="2">? = 0.05/0.5</cell><cell cols="2">? = 0</cell><cell cols="2">? = 0.05/0.5</cell></row><row><cell></cell><cell></cell><cell>5cl</cell><cell>20cl</cell><cell>5cl</cell><cell>20cl</cell><cell>5cl</cell><cell>20cl</cell><cell>5cl</cell><cell>20cl</cell></row><row><cell>Cifar10</cell><cell>FedAvg FedSAM FedASAM FedAvgM FedProx SCAFFOLD FedDyn AdaBest FedAvgM + ASAM FedProx + ASAM SCAFFOLD + ASAM FedDyn + SAM AdaBest + ASAM</cell><cell>65.00 70.16 73.66 10.00 62.72 32.25 67.69 66.77 77.30 73.74 77.78 77.38 77.48</cell><cell>68.52 72.90 76.09 10.00 68.44 15.56 73.81 72.29 84.89 75.76 77.93 81.00 78.43</cell><cell>69.24 73.52 75.61 10.00 68.38 54.46 71.36 69.84 77.06 75.32 77.59 79.18 78.41</cell><cell>73.07 76.04 76.98 78.51 73.02 44.76 75.20 75.89 84.92 77.03 77.80 81.70 79.72</cell><cell>69.71 74.97 76.44 10.00 70.56 11.98 77.00 78.94 80.88 76.89 75.66 83.81 82.00</cell><cell>70.19 73.06 76.36 10.00 70.08 10.00 74.00 76.12 85.98 75.92 75.30 86.07 80.80</cell><cell>73.48 76.61 76.12 10.00 74.27 33.25 77.99 80.35 78.29 76.65 75.32 83.18 81.87</cell><cell>73.81 76.22 76.86 84.00 73.67 24.11 75.12 79.35 86.03 76.95 75.29 85.57 80.81</cell></row><row><cell>Cifar100</cell><cell>FedAvg FedSAM FedASAM FedAvgM FedProx SCAFFOLD FedDyn AdaBest FedAvgM + ASAM FedProx + ASAM SCAFFOLD + ASAM FedDyn + ASAM AdaBest + ASAM</cell><cell>30.25 31.04 36.04 1.00 31.20 1.00 1.00 29.90 1.00 36.10 43.65 22.16 39.75</cell><cell>38.59 38.56 40.81 40.64 38.59 1.00 1.40 39.11 39.61 40.91 42.61 23.51 45.00</cell><cell>40.43 44.73 45.61 4.60 39.53 33.26 22.03 36.93 4.60 44.81 46.50 38.43 45.25</cell><cell>42.17 46.05 47.78 47.88 42.17 1.00 24.75 43.25 51.65 48.17 46.76 38.60 49.56</cell><cell>39.34 39.30 42.01 1.00 39.06 1.00 1.00 44.48 1.00 43.90 40.63 17.51 51.75</cell><cell>39.85 39.24 41.62 53.50 39.68 1.00 1.40 44.21 51.58 42.06 39.07 19.22 47.42</cell><cell>43.90 47.96 49.17 4.60 43.98 5.76 8.27 48.20 4.60 48.66 44.87 38.60 51.89</cell><cell>42.09 46.47 48.27 53.69 41.84 1.00 35.15 44.51 56.19 48.19 44.28 31.06 51.47</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">Accuracy Results (%) on</cell></row><row><cell cols="2">Landmarks-User-160k</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">@5k rounds w/ SWA 75 w/ SWA 100</cell></row><row><cell>FedAvg FedSAM FedASAM</cell><cell>61.91 63.72 64.23</cell><cell>66.05 67.11 67.17</cell><cell>67.52 68.12 68.32</cell></row><row><cell>Centralized</cell><cell></cell><cell>74.03</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Federated SS on Cityscapes and IDDA. Results in mIoU (%) @ 1.5k rounds</figDesc><table><row><cell>Algorithm Uniform</cell><cell></cell><cell>Country seen unseen seen unseen Rainy</cell><cell></cell><cell>mIoU</cell></row><row><cell>FedAvg</cell><cell></cell><cell>63.31 48.60 65.16 27.38</cell><cell></cell><cell>43.61</cell></row><row><cell>FedSAM</cell><cell></cell><cell>64.22 49.74 64.81 30.00</cell><cell></cell><cell>44.58</cell></row><row><cell>FedASAM</cell><cell></cell><cell>62.74 48.73 64.74 31.32</cell><cell></cell><cell>45.86</cell></row><row><cell>FedAvg + SWA FedSAM + SWA FedASAM + SWA FedAvg FedSAM FedASAM FedAvg + SWA</cell><cell>IDDA</cell><cell>63.91 43.28 63.24 47.72 62.26 46.26 63.69 48.40 60.78 44.23 63.18 51.76 42.06 36.04 39.50 24.59 43.28 37.83 39.65 29.27 43.67 36.11 41.68 30.07 37.16 37.48 37.06 42.33</cell><cell>Cityscapes</cell><cell>45.64 45.29 45.69 38.65 41.22 42.27 42.48</cell></row><row><cell>FedSAM + SWA</cell><cell></cell><cell>44.26 40.45 38.15 45.25</cell><cell></cell><cell>43.42</cell></row><row><cell>FedASAM + SWA</cell><cell></cell><cell>45.23 39.72 42.09 45.40</cell><cell></cell><cell>43.02</cell></row><row><cell>SiloBN</cell><cell></cell><cell>45.86 32.77 48.09 39.67</cell><cell></cell><cell>45.96</cell></row><row><cell>SiloBN + SAM</cell><cell></cell><cell>46.88 33.71 48.22 40.08</cell><cell></cell><cell>49.10</cell></row><row><cell>SiloBN + ASAM</cell><cell></cell><cell>46.57 35.22 48.33 40.76</cell><cell></cell><cell>49.75</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>Datasets statistics</figDesc><table><row><cell>Dataset</cell><cell>Task</cell><cell cols="4">Train clients Size imbalance Train samples Test samples</cell></row><row><cell>Cifar10</cell><cell>Classification</cell><cell>100</cell><cell></cell><cell>50,000</cell><cell>10,000</cell></row><row><cell>Cifar100</cell><cell>Classification</cell><cell>100</cell><cell></cell><cell>50,000</cell><cell>10,000</cell></row><row><cell>Cifar100-Pam Cifar10-C Cifar100-C</cell><cell>Classification DG DG</cell><cell>500 --</cell><cell>--</cell><cell>50,000 --</cell><cell>10,000 10,000 10,000</cell></row><row><cell>Landmarks-User-160k</cell><cell>Classification</cell><cell>1,262</cell><cell></cell><cell>164,172</cell><cell>19,526</cell></row><row><cell>Cityscapes (uniform) Cityscapes (heterogeneous)</cell><cell>SS SS</cell><cell>146 144</cell><cell></cell><cell>2,975</cell><cell>500</cell></row><row><cell>Idda (country)</cell><cell>SS+DG</cell><cell>90</cell><cell></cell><cell>4,320</cell><cell>1,920</cell></row><row><cell>Idda (rainy)</cell><cell>SS+DG</cell><cell>69</cell><cell></cell><cell>3,312</cell><cell>2,928</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Best performing training parameters</figDesc><table><row><cell>Dataset</cell><cell>Client learning rate</cell><cell cols="3">Batch size Weight decay Epochs</cell><cell>Client momentum</cell><cell cols="2">Rounds Clients per round</cell></row><row><cell>Cifar10 Cifar100 Cifar100-Pam Landmarks-User-160k Cityscapes (unif.) Cityscapes (het.)</cell><cell>0.01 0.01 0.01 0.1 0.05 0.05</cell><cell>64 64 20 64 8 8</cell><cell>4 ? 10 ?4 4 ? 10 ?4 4 ? 10 ?4 4 ? 10 ?5 5 ? 10 ?4 5 ? 10 ?4</cell><cell>1 1 1-2 5 2 2</cell><cell>0 0 0.9 0 0.9 0.9</cell><cell cols="2">10k {5, 10, 20} 20k {5, 10, 20} 10k {10, 20} 5k 10 1.5k 5 1.5k 5</cell></row><row><cell>Idda (country)</cell><cell>0.1</cell><cell>8</cell><cell>0</cell><cell>2</cell><cell>0.9</cell><cell>1.5k</cell><cell>5</cell></row><row><cell>Idda (rainy)</cell><cell>0.1</cell><cell>8</cell><cell>0</cell><cell>2</cell><cell>0.9</cell><cell>1.5k</cell><cell>5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 :</head><label>11</label><figDesc>FedSAM and FedASAM hyper-parameters</figDesc><table><row><cell>Dataset</cell><cell>Distribution</cell><cell>SAM ?</cell><cell>?</cell><cell>ASAM</cell><cell>?</cell></row><row><cell></cell><cell>? = 0</cell><cell>0.1</cell><cell>0.7</cell><cell></cell><cell>0.2</cell></row><row><cell>Cifar10</cell><cell>? = 0.05 ? = 100</cell><cell>0.1 0.02</cell><cell>0.7 0.05</cell><cell></cell><cell>0.2 0.2</cell></row><row><cell></cell><cell>? = 0</cell><cell>0.02</cell><cell>0.5</cell><cell></cell><cell>0.2</cell></row><row><cell>Cifar100</cell><cell>? = 0.5 ? = 1000</cell><cell>0.05 0.05</cell><cell>0.5 0.5</cell><cell></cell><cell>0.2 0.2</cell></row><row><cell>Cifar100-Pam</cell><cell>? = 0.1</cell><cell>0.05</cell><cell>0.5</cell><cell cols="2">0/0.2</cell></row><row><cell>Landmarks-User-160k</cell><cell>-</cell><cell>0.05</cell><cell>0.5</cell><cell cols="2">0/0.2</cell></row><row><cell>Cityscapes</cell><cell>het/unif</cell><cell>0.01</cell><cell>0.1</cell><cell></cell><cell>0.2</cell></row><row><cell>Idda</cell><cell>het/unif</cell><cell>0.01</cell><cell>0.5</cell><cell></cell><cell>0.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 :</head><label>12</label><figDesc>SWA hyper-parameters The parameter ? of SAM is searched in {0.01, 0.05, 0.1}. As for ASAM, the value of ? is tuned in {0.1, 0.3, 0.5} and ? ? {0.0, 0.1, 0.2}.</figDesc><table><row><cell>Dataset</cell><cell>c</cell><cell>?1</cell><cell>?2</cell><cell>Start round</cell></row><row><cell>Cifar10 Cifar100 Cifar100-Pam Landmarks-User-160k Cityscapes Idda</cell><cell>10 20 5 5 5 5</cell><cell>10 ?2 10 ?2 10 ?2 10 ?1 5 ? 10 ?2 10 ?1</cell><cell>10 ?4 10 ?4 10 ?4 10 ?3 5 ? 10 ?4 10 ?3</cell><cell>7500 15000 15000 3750/5000 1125 1125</cell></row><row><cell>SAM/ASAM:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 13 :</head><label>13</label><figDesc>Final accuracy (%) using different server-side optimizers with varying learning rate (LR) on Cifar100 @ 20k rounds. 5% clients participation. In bold the best results on both ? = 0 and ? = 1k.</figDesc><table><row><cell></cell><cell cols="2">Optimizer</cell><cell>LR</cell><cell>? = 0</cell><cell>? = 1k</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>30.25</cell><cell>49.92</cell></row><row><cell></cell><cell>SGD</cell><cell></cell><cell>0.1 0.01</cell><cell>14.09 2.67</cell><cell>40.43 11.35</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.001</cell><cell>1.20</cell><cell>1.12</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>1.00</cell><cell>51.73</cell></row><row><cell></cell><cell>Adam</cell><cell></cell><cell>0.1 0.01</cell><cell>29.75 13.72</cell><cell>51.62 40.12</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.001</cell><cell>2.60</cell><cell>11.31</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell cols="2">AdaGrad</cell><cell>0.1 0.01</cell><cell>1.77 26.25</cell><cell>46.74 51.44</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.001</cell><cell>9.70</cell><cell>32.01</cell></row><row><cell>0.00 0.05 0.10</cell><cell>0.20</cell><cell>0.50</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 14 :</head><label>14</label><figDesc>SWA ablation study: comparison between cyclical (c &gt; 1) and constant learning rate (c = 1) and contribution given by averaging stochastic weights. Highlighted in bold the best result for each combination (Algorithm, ?, participating clients).39.74 39.85 43.90 44.02 42.09 50.98 50.87 50.92 FedSAM 39.30 39.51 39.24 47.96 46.76 46.47 53.90 53.67 54.36 FedASAM 42.01 42.64 41.62 49.17 48.72 48.27 53.86 54.79 54.10 FedAvg 1 38.86 39.82 40.19 43.86 43.93 42.67 51.33 51.05 51.11 FedSAM 38.58 39.20 39.37 47.29 46.34 46.40 53.88 53.70 54.36 FedASAM 42.50 42.40 41.76 48.67 48.50 47.95 54.16 55.07 54.19 FedAvg 20 30.68 34.86 37.42 40.34 42.40 41.89 50.06 50.21 50.81 FedSAM 31.51 35.87 37.81 44.08 45.80 46.43 53.76 53.46 54.28 FedASAM 36.85 39.76 41.03 46.34 48.06 48.38 54.21 55.06 54.22 FedAvg 1 30.25 36.74 38.59 40.43 41.27 42.17 49.92 50.25 50.66 FedSAM 31.04 36.93 38.56 44.73 44.84 46.05 54.01 53.39 53.97 FedASAM 36.04 39.76 40.81 45.61 46.58 47.78 54.81 54.97 54.50 Cifar10 FedAvg 10 69.71 69.54 70.19 73.48 72.80 73.81 84.35 84.32 84.47 FedSAM 74.97 73.73 73.06 76.61 75.84 76.22 84.23 84.37 84.63 FedASAM 76.44 75.51 76.36 76.12 76.16 76.86 84.88 84.80 84.79 FedAvg 1 69.88 69.83 70.72 73.91 73.12 73.07 84.90 84.47 84.67 FedSAM 75.17 74.00 73.53 76.93 76.06 76.55 84.53 84.54 84.77 FedASAM 76.80 75.48 76.84 76.87 76.30 77.55 85.09 85.06 84.73 FedAvg 10 61.41 63.96 67.39 67.17 69.88 72.19 84.18 84.15 84.45 FedSAM 70.66 71.14 73.04 73.93 74.96 76.20 84.23 84.40 84.69 FedASAM 75.07 74.87 76.37 75.37 76.17 77.14 84.68 84.72 84.71 FedAvg 1 65.00 65.54 68.52 69.24 72.50 73.07 84.46 84.50 84.59 FedSAM 70.16 71.09 72.90 73.52 74.81 76.04 84.58 84.67 84.82 FedASAM 73.66 74.10 76.09 75.61 76.22 76.98 84.77 84.72 84.75</figDesc><table><row><cell cols="2">Dataset Algorithm WeightsAvg c</cell><cell>5cl</cell><cell>? = 0 10cl</cell><cell>20cl</cell><cell>? = 0.5/0.05 5cl 10cl 20cl</cell><cell>? = 1k/100 5cl 10cl 20cl</cell></row><row><cell>FedAvg</cell><cell>20</cell><cell>39.34</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Cifar100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 15 :</head><label>15</label><figDesc>SWA ablation study: comparison between SWA starting rounds when using FedAvg with 5 clients per round</figDesc><table><row><cell>Dataset</cell><cell>c</cell><cell>Start round</cell><cell>? = 0</cell><cell cols="2">Test Accuracy (%) ? = 0.5/0.05 ? = 1k/100</cell></row><row><cell></cell><cell></cell><cell>1000</cell><cell>24.53</cell><cell>34.52</cell><cell>49.38</cell></row><row><cell>Cifar100</cell><cell>20</cell><cell>5000 10000</cell><cell>30.66 36.21</cell><cell>39.71 42.55</cell><cell>51.52 51.01</cell></row><row><cell></cell><cell></cell><cell>15000</cell><cell>39.34</cell><cell>43.90</cell><cell>50.98</cell></row><row><cell></cell><cell></cell><cell>500</cell><cell>55.57</cell><cell>60.50</cell><cell>79.09</cell></row><row><cell>Cifar10</cell><cell>10</cell><cell>2500 5000</cell><cell>60.34 66.22</cell><cell>65.72 70.55</cell><cell>81.49 83.79</cell></row><row><cell></cell><cell></cell><cell>7500</cell><cell>69.71</cell><cell>73.48</cell><cell>84.35</cell></row><row><cell cols="5">F Tables Omitted in the Main Text</cell><cell></cell></row></table><note>F.1 Heterogeneous FL Benefits Even More from Flat Minima - Additional Material</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 16 :</head><label>16</label><figDesc>Comparison of improvements (%) in centralized and federated scenarios (? ? {0.5, 1k}, 5 clients) on Cifar100, computed w.r.t. the reference at the bottom Centralized: 52.20 -FedAvg ? = 0.5: 40.43, ? = 1k: 49.92</figDesc><table><row><cell>Algorithm</cell><cell>Centr.</cell><cell>Accuracy ? = 0.5</cell><cell>? = 1k</cell><cell cols="3">Absolute Improvement Centr. ? = 0.5 ? = 1k</cell><cell cols="3">Relative Improvement Centr. ? = 0.5 ? = 1k</cell></row><row><cell>SAM</cell><cell>55.22</cell><cell>44.73</cell><cell>54.01</cell><cell>+3.02</cell><cell>+4.30</cell><cell>+4.01</cell><cell>+5.79</cell><cell>+10.64</cell><cell>+8.03</cell></row><row><cell>ASAM</cell><cell>55.66</cell><cell>45.61</cell><cell>54.81</cell><cell>+3.46</cell><cell>+5.18</cell><cell>+4.89</cell><cell>+6.63</cell><cell>+12.81</cell><cell>+9.80</cell></row><row><cell>SWA</cell><cell>52.72</cell><cell>43.90</cell><cell>50.98</cell><cell>+0.52</cell><cell>+3.47</cell><cell>+1.06</cell><cell>+1.00</cell><cell>+8.58</cell><cell>+2.12</cell></row><row><cell>SAM + SWA</cell><cell>55.75</cell><cell>47.96</cell><cell>53.90</cell><cell>+0.55</cell><cell>+7.53</cell><cell>+3.98</cell><cell>+1.06</cell><cell>+18.63</cell><cell>+7.97</cell></row><row><cell>ASAM + SWA</cell><cell>55.96</cell><cell>49.17</cell><cell>53.86</cell><cell>+3.76</cell><cell>+8.74</cell><cell>+3.94</cell><cell>+7.20</cell><cell>+21.62</cell><cell>+7.89</cell></row><row><cell>Mixup</cell><cell>58.01</cell><cell>35.10</cell><cell>55.34</cell><cell>+5.81</cell><cell>-5.33</cell><cell>+5.42</cell><cell>+11.13</cell><cell>-13.18</cell><cell>+10.86</cell></row><row><cell>Cutout</cell><cell>55.30</cell><cell>37.72</cell><cell>53.48</cell><cell>+3.10</cell><cell>-2.71</cell><cell>+3.56</cell><cell>+5.94</cell><cell>-6.70</cell><cell>+7.13</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 17 :</head><label>17</label><figDesc>FedAvg, SAM, ASAM and SWA w/ strong data augmentations (Mixup, Cutout) on Cifar10</figDesc><table><row><cell>Algorithm</cell><cell>SWA</cell><cell>Aug</cell><cell>5cl</cell><cell>? = 0 10cl</cell><cell>20cl</cell><cell>5cl</cell><cell>? = 0.5/0.05 10cl 20cl</cell><cell>5cl</cell><cell>? = 1000/100 10cl 20cl</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/rwightman/efficientnet-jax/tree/ a65811fbf63cb90b9ad0724792040ce93b749303 2 https://github.com/google/flax/blob/571018d16b42ce0a0387515e96ba07130cbf79b9/ examples/imagenet/input_pipeline.py 3 https://www.tensorflow.org/federated/api_docs/python/tff/simulation/ datasets/gldv2/load_data</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/timgaripov/dnn-mode-connectivity 5 https://github.com/tomgoldstein/loss-landscape</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. We thank L. Fantauzzo for her help with the SS experiments. We acknowledge the Cineca HPC infrastructure. Work funded by Cini.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model:</head><p>We follow a setting similar to the one proposed by <ref type="bibr" target="#b30">[31]</ref> and use a MobileNetV2 <ref type="bibr" target="#b48">[67]</ref> network pre-trained on ImageNet <ref type="bibr" target="#b14">[15]</ref> with with GroupNorm layers in place of BatchNorm. Since no details on the model are available, we set the network feature multiplier ? = 1 and use 8 groups for the GN layers. We did not apply a bottleneck layer before the classifier as specified in <ref type="bibr" target="#b30">[31]</ref>. To reduce training time, we use Flax <ref type="bibr" target="#b24">[25]</ref> for both pre-training and centralized baselines, and FedJAX <ref type="bibr" target="#b46">[65]</ref> for the implementation of the federated algorithms. Both libraries are based on JAX <ref type="bibr" target="#b7">[8]</ref> and allow for efficient data parallelization. Implementation of the MobileNetV2 backbone used for all the experiments is</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mattina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Whatmough</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
		<title level="m">Federated learning based on dynamic regularization. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Idda: a large-scale multi-domain dataset for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tavera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Masone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Siloed federated learning for multi-centric histopathology datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andreux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">O D</forename><surname>Terrail</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beguier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Tramel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.08529</idno>
		<title level="m">Sharpness-aware minimization improves language model generalization</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Revisiting resnets: Improved training and scaling strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Feddis: Disentangled federated learning for unsupervised brain pathology segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">I</forename><surname>Bercea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wiestler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Albarqouni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03705</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generalizing from several related classification tasks to a new unlabeled sample</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Necula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wanderman-Milne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="http://github.com/google/jax25" />
		<title level="m">JAX: composable transformations of Python+NumPy programs</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Federated learning with hierarchical clustering of local updates to improve training on non-iid data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Briggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Andras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cluster-driven graph federated learning over multiple domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Caldarola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Galasso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ciccone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodol?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshop</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshop</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">When vision transformers outperform resnets without pre-training or strong data augmentations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<title level="m">Improved regularization of convolutional neural networks with cutout</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Essentially no barriers in neural network energy landscape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Draxler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Veschgini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salmhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hamprecht</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Dziugaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.11008</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Feddrive: Generalizing federated learning to semantic segmentation in autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fantauzzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;apos;</forename><surname>Fani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Caldarola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tavera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cermelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ciccone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (2022) 4, 13</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Sharpness-aware minimization for efficiently improving generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Foret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kleiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
	<note>International Conference on Learning Representations (2021) 2, 4, 5, 9</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia-Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Orts-Escolano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Villena-Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Garcia-Rodriguez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.06857</idno>
		<title level="m">A review on deep learning techniques applied to semantic segmentation</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Loss surfaces, mode connectivity, and fast ensembling of dnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Ensemble attention distillation for privacy-preserving federated learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Innanje</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021-10" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-institutional collaborations for improving deep learning-based magnetic resonance image reconstruction using federated learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Flax: A neural network library and ecosystem for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rondepierre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Zee</surname></persName>
		</author>
		<ptr target="http://github.com/google/flax25" />
	</analytic>
	<monogr>
		<title level="j">JAX</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The many faces of robustness: A critical analysis of out-of-distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dorundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parajuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
		<title level="m">Benchmarking neural network robustness to common corruptions and perturbations. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Flat minima</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The non-iid data quagmire of decentralized machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Phanishayee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gibbons</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Measuring the effects of non-identical data distribution for federated visual classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS Workshop</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Federated visual classification with real-world data distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings, Part X 16</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Federated optimization in heterogeneous networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning and Systems</title>
		<meeting>Machine Learning and Systems</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Pachinko allocation: Dag-structured mixture models of topic correlations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Privacy-preserving federated brain tumour segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Milletar?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rieke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hancox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International workshop on machine learning in medical imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Revisiting batch normalization for practical domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Ensemble distillation for robust model fusion in federated learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">U</forename><surname>Stich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07242</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Feddg: Federated domain generalization on medical image segmentation via episodic learning in continuous frequency space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Communicationefficient learning of deep networks from decentralized data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Arcas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Prototype guided federated learning of visual feature representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Michieli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ozay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.08982</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Linear mode connectivity in multitask and continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Mirzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gorur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ghasemzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">pytorch-hessianeigenthings: efficient pytorch hessian eigendecomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhewei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Joseph</surname></persName>
		</author>
		<ptr target="https://github.com/noahgolmant/pytorch-hessian-eigenthings30" />
		<imprint>
			<date type="published" when="2018-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep learning for real-time semantic segmentation: Application in ultrasound imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ouahabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Taleb-Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generalized federated learning via sharpness aware minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szepesvari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<idno>PMLR (17-23</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Conference on Machine Learning. Proceedings of Machine Learning Research</title>
		<editor>Sabato, S.</editor>
		<meeting>the 39th International Conference on Machine Learning. Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2022-07" />
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kone?n?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<title level="m">Adaptive federated optimization. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Ro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.02117</idno>
		<title level="m">Fedjax: Federated learning simulation with jax</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">An overview of gradient descent optimization algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04747</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
	<note>Mobilenetv2: Inverted residuals and linear bottlenecks</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Multi-institutional deep learning modeling without sharing patient data: A feasibility study on brain tumor segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Sheller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Reina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bakas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International MICCAI Brainlesion Workshop</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Training region-based object detectors with online hard example mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A comparative study of real-time semantic segmentation for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Siam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abdel-Razek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yogamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jagersand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition workshops</title>
		<meeting>the IEEE conference on computer vision and pattern recognition workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A bayesian perspective on generalization and stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Learning Representations</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Federated multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Pixel-by-pixel cross-domain alignment for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tavera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cermelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Masone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Privacy-preserving constrained domain generalization for medical image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.08511</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Minimizing client drift in federated learning via adaptive bias estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Varno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saghayi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rafiee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Havaei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.13170</idno>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Google landmarks dataset v2-a largescale benchmark for instance-level recognition and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Adversarial examples improve image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Accelerated stochastic power iteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>De Sa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Re</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Federated multi-target domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Su-net: an efficient encoderdecoder model of federated learning for brain tumor segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
