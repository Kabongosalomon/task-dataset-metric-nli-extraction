<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Knowledge Tracing via Pre-training Question Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfei</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianyu</forename><surname>Chen</surname></persName>
							<email>xianyujun@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">The Center on Frontiers of Computing Studies</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Knowledge Tracing via Pre-training Question Embeddings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge tracing (KT) defines the task of predicting whether students can correctly answer questions based on their historical response. Although much research has been devoted to exploiting the question information, plentiful advanced information among questions and skills hasn't been well extracted, making it challenging for previous work to perform adequately. In this paper, we demonstrate that large gains on KT can be realized by pre-training embeddings for each question on abundant side information, followed by training deep KT models on the obtained embeddings. To be specific, the side information includes question difficulty and three kinds of relations contained in a bipartite graph between questions and skills. To pre-train the question embeddings, we propose to use product-based neural networks to recover the side information. As a result, adopting the pretrained embeddings in existing deep KT models significantly outperforms state-of-the-art baselines on three common KT datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The computer-aided education (CAE) systems are seeking to use advanced computer-based technology to improve students' learning ability and teachers' teaching efficiency <ref type="bibr" target="#b4">[Cingi, 2013]</ref>. Knowledge tracing (KT) is an essential task in CAE systems, which aims at evaluating students' knowledge state over time based on their learning history. To be specific, the objective of KT is to predict whether a student can answer the next question correctly according to all the previous response records.</p><p>To solve KT problem, various approaches have been proposed including Bayesian Knowledge Tracing (BKT) <ref type="bibr" target="#b5">[Corbett and Anderson, 1994;</ref><ref type="bibr" target="#b11">Zhu et al., 2018]</ref>, the factor analysis models <ref type="bibr" target="#b10">[Wilson et al., 2016;</ref><ref type="bibr" target="#b8">Pavlik Jr et al., 2009</ref>] and deep models <ref type="bibr" target="#b8">[Piech et al., 2015;</ref><ref type="bibr">Zhang et al., 2017]</ref>. In this paper, we mainly focus on the deep KT models, which leverage recent advances in deep learning and have achieved great success in KT. In general, most deep KT models estimate a * Corresponding author. and q2 share the same skill s1 but have different difficulties so that skill-level mastery modeling is insufficient. But the implicit similarity between q1 and q2 can help prediction to tackle the sparsity issue.</p><p>student's mastery of skills instead of directly predicting her capability to answer specific questions correctly. Two representative methods are <ref type="bibr">DKT [Piech et al., 2015]</ref> and <ref type="bibr">DKVMN [Zhang et al., 2017]</ref>. Although skill-level mastery can be well predicted by these deep KT models, there exists a major limitation that the information of specific questions is not taken into consideration <ref type="bibr" target="#b8">[Piech et al., 2015;</ref><ref type="bibr">Zhang et al., 2017;</ref><ref type="bibr" target="#b0">Abdelrahman and Wang, 2019]</ref>. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, the questions sharing the same skill may have different difficulties, and thus skilllevel prediction can not accurately reflect the knowledge state of a student for specific questions. Although it is quite necessary to solve KT at a finer-grained level by exploiting the information of specific questions, there comes a major issue that the interactions between students and questions are extremely sparse, which leads to catastrophic failure if directly using questions as the network input . To tackle the sparsity issue, several works are proposed to use the question information as a supplement <ref type="bibr" target="#b8">[Minn et al., 2019;</ref>. However, these works only consider the question difficulties or question-skill relations.</p><p>In this paper, we take a further step towards maximally extracting and exploiting plentiful underlying information among questions and skills to tackle the sparsity issue. Con-sidering that usually a skill includes many questions and a question is also associated with several skills, we can represent them as a bipartite graph where vertices are skills and questions respectively. Generally, bipartite graphs include two kinds of relations <ref type="bibr" target="#b6">[Gao et al., 2018]</ref>: the explicit relations (i.e., observed links) and the implicit relations (i.e., unobserved but transitive links). In KT scenarios as shown in <ref type="figure" target="#fig_0">Figure 1</ref>, in addition to the explicit question-skill relations, we consider the implicit skill similarity and question similarity, which haven't been well exploited in previous work.</p><p>Taking everything into consideration, in this paper, we propose a pre-training approach, called Pre-training Embeddings via Bipartite Graph (PEBG), to learn a low-dimensional embedding for each question with all the useful side information. To be specific, the side information includes question difficulties together with three kinds of relations: explicit questionskill relations, implicit question similarity and skill similarity. To effectively extract the knowledge contained in the side information, we adopt a product layer to fuse question vertex features, skill vertex features and attribute features to produce our final question embeddings. In this way, the learned question embeddings will preserve question difficulty information and the relations among questions and skills.</p><p>The contributions of this paper are summarized as follows.</p><p>? To the best of ours, we are the first to use the bipartite graph of question-skill relations to obtain question embeddings, which provides plentiful relation information. ? We propose a pre-training approach called PEBG, which introduces a product layer to fuse all the input features, to obtain the final question embeddings. ? The obtained question embeddings by PEBG can be incorporated into existing deep KT models. Experiment results on three real-world datasets show that using PEBG can outperform the state-of-the-art models, improving AUC by 8.6% on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Previous KT methods can be largely categorized into three types: Bayesian Knowledge Tracing (BKT), factor analysis KT models and deep KT models. <ref type="bibr" target="#b5">[Corbett and Anderson, 1994]</ref> proposes the Bayesian Knowledge Tracing (BKT) model, which is a hidden Markov model and assumes students' knowledge state as a set of binary variables. BKT models each skill state separately, making it unable to capture the relations among skills. Another line of KT methods is factor analysis, which considers the factors that affect student state, including the difficulty of questions, students' ability, the ratio of correct answers to a certain question. The factor analysis models include Item Response Theory (IRT) <ref type="bibr" target="#b10">[Wilson et al., 2016]</ref>, Additive Factor Model (AFM) <ref type="bibr" target="#b1">[Cen et al., 2006]</ref>, Performance Factor Analysis (PFA) <ref type="bibr" target="#b8">[Pavlik Jr et al., 2009]</ref>, Knowledge Tracing Machine (KTM) <ref type="bibr" target="#b10">[Vie and Kashima, 2019]</ref>. These models only consider the historical interactions of each question or skill, and also fail to capture the relations between questions and skills.</p><p>With the rise of deep learning, lots of deep models have been proposed to solve KT, among which most preliminary work uses skills as network input. For example, <ref type="bibr" target="#b8">[Piech et al., 2015]</ref> proposes the Deep Knowledge Tracing (DKT) model, which uses a recurrent neural network (RNN) to model the learning process of students. Dynamic Key-Value Memory Network (DKVMN), proposed by <ref type="bibr">[Zhang et al., 2017]</ref>, uses a key-value memory network to automatically discover the relations between exercises and their underlying concepts and traces each concept state. The PDKT-C model <ref type="bibr" target="#b2">[Chen et al., 2018]</ref> manually labels the prerequisite relations among skills, which however is not suitable for large-scale data. The GKT model <ref type="bibr" target="#b8">[Nakagawa et al., 2019]</ref> builds a similarity graph of skills randomly, and automatically learns the edge weights of the graph to help prediction.</p><p>Since the skill-level prediction cannot fully reflect the knowledge state of specific questions, several works propose to use the question information as a supplement. For example, <ref type="bibr" target="#b9">[Su et al., 2018;</ref>] encode text descriptions of questions into question embeddings to capture the question characteristics, but the text descriptions are not easy to acquire in practice. <ref type="bibr" target="#b8">[Minn et al., 2019]</ref> calculates the percentage of incorrect answers as the question difficulty to distinguish different questions. DHKT  uses relations between questions and skills as a constraint to train question embeddings, which are used as the input of DKT together with skill embeddings. In this paper, we mainly focus on how to pre-train a low-dimensional embedding for each question, which can be directly used as the network input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>In knowledge tracing, given a student's past question interactions X = {(q 1 , c 1 ), ..., (q t?1 , c t?1 )} where c i is the correctness of the student's answer to the question q i at the time step i, the goal is to predict the probability that the student will correctly answer a new question, i.e., P (c t = 1|q t , X ).</p><p>Let</p><formula xml:id="formula_0">Q = {q i } |Q| i=1</formula><p>be the set of all distinct |Q| questions and S = {s j } |S| j=1 be the set of all distinct |S| skills. Usually, one skill includes many questions and one question is related to several skills. So the question-skill relations can be naturally represented as a bipartite graph G = (Q, S, R R R) where R R R = [r ij ] ? {0, 1} |Q|?|S| is a binary adjacency matrix. If there is an edge between the question q i and the skill s j , then r ij = 1; otherwise r ij = 0. Here we introduce the information we will use to train embeddings in our model, including the information in the graph and the difficulty information. Definition 1 (explicit question-skill relations). Given the question-skill bipartite graph, relations between skill vertices and question vertices are the explicit question-skill relations, that is, explicit relation between question vertex i and skill vertex j depends on whether r ij =1. Definition 2 (implicit question similarity and skill similarity). Given the question-skill bipartite graph, relations between two skill vertices that have the common neighbor question vertices are defined as skill similarity. Similarly, question similarity refers to the relations between two question vertices that share the common neighbor skill vertices. Definition 3 (question difficulty). The question difficulty d i for one question q i is defined as the ratio of correctly being answered computed from the training dataset. All the question difficulties form a vector</p><formula xml:id="formula_1">d d d = [d i ] ? R |Q| .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>In this section, we will give a detailed introduction of our PEBG framework, of which the overview architecture is given by <ref type="figure" target="#fig_1">Figure 2</ref>. PEBG pre-trains question embeddings using four loss functions respectively designed for the side information: explicit skill-question relations, implicit question similarity and skill similarity, and question difficulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Input Features</head><p>To pre-train the question embeddings, we use three kinds of features as follows. It should be noted that the vertex features are initialized randomly and will be updated in the pretraining stage, which is equivalent to learning linear mappings from one-hot encodings to continuous features.</p><p>Skill vertex features are represented by a feature matrix S S S ? R |S|?dv , where d v is the dimension of the features. For one skill s i , the vertex feature is denoted as s s s i , which is the i-th row of matrix S S S.</p><p>Question vertex features are represented by a feature matrix Q Q Q ? R |Q|?dv , which has the same dimension d v as the skill vertex features. For one question q j , the vertex feature is denoted as q q q j , which is the j-th row of matrix Q Q Q.</p><p>Attribute features are the features related to the difficulty of questions, such as average response time, question type and so on. For question q i , we concatenate the features as</p><formula xml:id="formula_2">f f f i = [f f f i1 ; ..; f f f im ], m is the number of features. f f f ij is a one-hot vector if the j-th feature is categorical (e.g., question type)</formula><p>. f f f ij is a scalar value if the j-th feature is numerical (e.g., average response time).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bipartite Graph Constraints</head><p>The skill and question vertex features are updated via the bipartite graph constraints. As there exist different relations in the graph, we design different types of constraints so that the vertex features can preserve these relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Explicit Question-Skill Relations</head><p>In the question-skill bipartite graph, edges exist between question vertices and skill vertices, presenting an explicit signal. Similarly to the modeling of 1st-order proximity in LINE <ref type="bibr" target="#b9">[Tang et al., 2015]</ref>, we model explicit relations by considering the local proximity between skill and question vertices. In detail, we use inner products to estimate the local proximity between question and skill vertices in the embedding space,</p><formula xml:id="formula_3">r ij = ?(q q q T i s s s j ), i ? [1, ..., |Q|], j ? [1, ..., |S|],<label>(1)</label></formula><p>where ?(x) = 1/(1 + e ?x ) is the sigmoid function, which transforms the relation value to a probability. To preserve the explicit relations, the local proximity is enforced to be close to skill-question relations in the bipartite graph via a cross-entropy loss function:</p><formula xml:id="formula_4">L 1 (Q Q Q, S S S) = |Q| i=1 |S| j=1 ?(r ij logr ij + (1 ? r ij )log(1 ?r ij )).</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implicit Similarities</head><p>The implicit similarities used in PEBG indicate the similarity between neighborhoods in the bipartite graph. Specifically, there exist two kinds of similarities: skill similarity and question similarity. We would like to use implicit similarities to update the vertex features simultaneously.</p><p>We define the neighbor set of question q i as ? Q (i) = {s j |r ij = 1}, and the neighbor set of skill s j as ? S (j) = {q i |r ij = 1}. Then the question similarity matrix R R R Q = [r q ij ] ? {0, 1} |Q|?|Q| can be formally defined as,</p><formula xml:id="formula_5">r q ij = 1 ? Q (i) ? ? Q (j) = ? 0 otherwise , i, j ? [1, ..., |Q|]. (3)</formula><p>Similarly, we define the skill similarity matrix R R R S = [r s ij ] ? {0, 1} |S|?|S| as,</p><formula xml:id="formula_6">r s ij = 1 ? S (i) ? ? S (j) = ? 0 otherwise , i, j ? [1, ..., |S|].<label>(4)</label></formula><p>We also use inner products to estimate the implicit relations among questions and skills in the vertex feature space,</p><formula xml:id="formula_7">r q ij = ?(q q q T i q q q j ), i, j ? [1, ..., |Q|],<label>(5)</label></formula><formula xml:id="formula_8">r s ij = ?(s s s T i s s s j ), i, j ? [1, ..., |S|].</formula><p>(6) We minimize the cross entropy to make vertex features preserve the implicit relations:</p><formula xml:id="formula_9">L 2 (Q Q Q) = |Q| i=1 |Q| j=1 ?(r q ij logr q ij + (1 ? r q ij )log(1 ?r q ij )),<label>(7)</label></formula><formula xml:id="formula_10">L 3 (S S S) = |S| i=1 |S| j=1 ?(r s ij logr s ij + (1 ? r s ij )log(1 ?r s ij )).<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Difficulty Constraint</head><p>Difficulty information of questions is important in KT prediction, which, however, is not contained in the bipartite graph. Thus we hope the final question embeddings can recover the difficulty information. <ref type="bibr" target="#b10">[Vie and Kashima, 2019]</ref> use Factorization Machines <ref type="bibr" target="#b9">[Rendle, 2010]</ref> to encode side information and explore feature interactions for student modeling. In this paper, we use attribute features interacting with vertex features to learn high quality embeddings. Especially, inspired by <ref type="bibr">PNN [Qu et al., 2016]</ref>, a product layer is used to learn high-order feature interactions. For one question q (its subscript is omitted for clarity), we have its question vertex feature q q q and its attribute features f f f . To interact attribute features with the vertex features via a product layer, we first use a linear layer parameterized by w w w a to map the attribute features f f f to a low-dimensional feature representation, which is denoted as a a a ? R dv . Assume the set of skills related to q is C = {s j } We use vertex feature q q q, the average skill feature s s s , and the attribute features a a a to generate the linear information Z Z Z and the quadratic information P P P for the question q. Specifically, Z Z Z = (z z z 1 , z z z 2 , z z z 3 ) (q q q, s s s , a a a),</p><formula xml:id="formula_11">P P P = [p ij ] ? R 3?3 ,<label>(10)</label></formula><p>where p ij = g(z z z i , z z z j ) defines the pairwise feature interaction. There are different implementations for g. In this paper, we define g as vector inner product:</p><formula xml:id="formula_13">g(z z z i , z z z j ) =&lt; z z z i , z z z j &gt;.</formula><p>Then we introduce a product layer, which can transform these two information matrices to signal vectors l l l z and l l l p , as shown in <ref type="figure" target="#fig_1">Figure 2</ref>. The transformation equations are as follows:</p><formula xml:id="formula_14">l (k) z = W W W (k) z Z Z Z = 3 i=1 dv j=1 (w (k) z ) ij z ij ,<label>(12)</label></formula><formula xml:id="formula_15">l (k) p = W W W (k) p P P P = 3 i=1 3 j=1 (w (k) p ) ij p ij .<label>(13)</label></formula><p>k ? [1, ...d]. And denotes operations that firstly elementwise multiplication is applied to two matrices, then the multiplication result is summed up to a scalar. d is the transform dimension of l l l z and l l l p . W W W According to the definition of P P P and the commutative law in vector inner product, P P P and W W W (k) p should be symmetric, so we can use matrix factorization to reduce complexity. By introducing the assumption that W W W (k) p = ? ? ? (k) ? ? ? (k) T and ? ? ? (k) ? R 3 , we can simplify the formulation of l (k) p as,</p><formula xml:id="formula_16">W W W (k) p P P P = 3 i=1 3 j=1 ? (k) i ? (k) j &lt; z z z i , z z z j &gt; .<label>(14)</label></formula><p>Then, we can calculate the embedding of question q, which is denoted as e e e: e e e = ReLU(l l l z + l l l</p><formula xml:id="formula_17">p + b b b),<label>(15)</label></formula><p>where l l l z , l l l p and the bias vector b b b ? R d , and l l l z = (l</p><formula xml:id="formula_18">(1) z , l (2) z , ...l (d) z ), l l l p = (l (1) p , l (2) p , ...l (d) p ).</formula><p>The activation function is rectified linear unit (ReLU), defined as ReLU(x) = max(0, x).</p><p>To preserve the difficulty information effectively, for one question q i , we use a linear layer to map the activation e e e i to a difficulty approximationd i = w w w T d e e e i + b d where w w w d and b d are network parameters. We use the question difficulty d i as the auxiliary target, and design the following loss function L 4 to measure the difficulty approximation error:</p><formula xml:id="formula_19">L 4 (Q Q Q, S S S, ? ? ?) = |Q| i=1 (d i ?d i ) 2 ,<label>(16)</label></formula><p>where ? ? ? denotes all the parameters in the network, i.e., ? ?</p><formula xml:id="formula_20">? = {w w w a , W W W z , W W W p , w w w d , b b b, b d }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Joint Optimization</head><p>To generate question embeddings that preserve explicit relations, implicit similarities, and question difficulty information simultaneously, we combine all the loss functions to form a joint optimization framework, namely, we solve: min Q Q Q,S S S,? ? ? ?(L 1 (Q Q Q, S S S)+L 2 (Q Q Q)+L 3 (S S S))+(1??)L 4 (Q Q Q, S S S, ? ? ?), (17) where ? is a coefficient to control the trade-off between bipartite graph constraints and difficulty constraint.</p><p>Once the joint optimization is finished, we can obtain the question embeddings e e e, which can be used as the input of existing deep KT models, such as DKT and DKVMN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we conduct experiments to evaluate the performance of knowledge tracing models based on the question embeddings pre-trained by our proposed model PEBG 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We use three real-world datasets, and the statistics of the three datasets are shown in <ref type="table" target="#tab_1">Table 1.  ASSIST09 ASSIST12   EdNet  #students  3,841  27,405  5,000  #questions  15,911  47,104  13,169  #skills  123  265  188  #records  190,</ref>  ASSIST09 2 and ASSIST12 3 are both collected from the ASSISTments online tutoring platform <ref type="bibr" target="#b6">[Feng et al., 2009]</ref>. For both datasets, we remove records without skills and scaffolding problems. We also remove users with less than three records. After preprocessing, ASSIST09 dataset consists of 123 skills, 15,911 questions answered by 3,841 students which gives a total number of 190,320 records. ASSIST12 dataset contains 265 skills, 47,104 questions answered by 27,405 students with 1,867,167 records.</p><p>EdNet 4 is collected by <ref type="bibr" target="#b3">[Choi et al., 2019]</ref>. In this experiment, we use EdNet-KT1 dataset which consists of students' question-solving logs, and randomly sample 222,141 records of 5,000 students, with 13,169 questions and 188 skills.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Compared Models</head><p>To illustrate the effectiveness of our model and show the improvement of our model to the existing deep KT models, we compare prediction performance among state-of-the-art deep KT models. We divide the compared models as skill-level models and question-level models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Skill-level Models</head><p>Skill-level models only use skill embeddings as input, and they all trace students' mastery of skills.</p><p>? BKT <ref type="bibr" target="#b5">[Corbett and Anderson, 1994</ref>] is a 2-state dynamic Bayesian network, defined by initial knowledge, learning rate, slip and guess parameters.</p><p>? <ref type="bibr">DKT [Piech et al., 2015]</ref> uses recurrent neural network to model student skill learning.</p><p>? DKVMN [Zhang et al., 2017] uses a key-value memory network to store the skills' underlying concept representations and states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question-level Models</head><p>Besides skill-level models, the following models utilize question information for question-level prediction.</p><p>? KTM <ref type="bibr" target="#b10">[Vie and Kashima, 2019]</ref> utilizes factorization machines to make prediction, which lets student id, skill id, question features interact with each other.</p><p>? DKT-Q is our extension to the DKT model, which directly uses questions as the input of DKT and predicts students' response for each question. ? DKVMN-Q is our extension to the DKVMN model, which directly uses questions as the input of DKVMN and predicts students' response for each question. ? DHKT  is the extension model of DKT, which models skill-question relation and can also predict students' response for each question. We test our model based on skill-level deep learning models. PEBG+DKT and PEBG+DKVMN utilize question embeddings pre-trained by PEBG and make DKT and DKVMN achieve question-level prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Implementation Details</head><p>To evaluate the performance of each dataset, we use the area under the curve (AUC) as an evaluation metric.</p><p>PEBG has only a few hyperparameters. The dimension of vertex features d v is set to 64. The final question embeddings dimension d = 128. ? in Eqn.(17) is 0.5. We use the Adam algorithm to optimize our model, and mini-batch size for three datasets is set to 256, the learning rate is 0.001. We also use dropout with a probability of 0.5 to alleviate overfitting. We divide each dataset into 80% for training and validation, and 20% for testing. For each dataset, the training process is repeated five times, we report the average test AUC.</p><p>For ASSIST09 and ASSIST12 datasets, average response time and question type are used as attribute features. For the EdNet dataset, average response time is used as an attribute feature. <ref type="table" target="#tab_3">Table 2</ref> illustrates prediction performance for all compared models, we find several observations as below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Performance Prediction</head><p>The proposed PEBG+DKT and PEBG+DKVMN models achieve the highest AUC on all three datasets. Particularly, on the ASSIST09 dataset, our PEBG+DKT and PEBG+DKVMN models achieve an AUC of 0.8287 and 0.8299, which represents a significant gain of 9.18% on average in comparison with 0.7356 and 0.7394 achieved by DKT and DKVMN. On the ASSIST12 dataset, the results show an average increase of 8%, AUC 0.7665 in PEBG+DKT and 0.7701 in PEBG+DKVMN compared with AUC 0.7013 in DKT and 0.6752 in DKVMN. On the EdNet dataset, PEBG+DKT and PEBG+DKVMN achieve an average improvement of 8.6% over the original DKT and DKVMN.</p><p>Among all the compared models, BKT has the worst performance. DKT, DKVMN, and KTM have similar performance. By comparing the performance of DKT and DKT-Q, DKVMN and DKVMN-Q, we find DKT-Q and DKVMN-Q show no advantage, which indicates that directly applying existing deep KT models to question-level prediction will suffer from question interactions sparsity issue. And our PEBG model can improve DKT and DKVMN well, even on those sparse datasets. Though DHKT outperforms DKT, it still performs worse than our proposed model, which illustrates the effectiveness of PEBG in leveraging more complex relations among skills and questions.   <ref type="table">Table 3</ref>: Performance comparison of ablation study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Ablation Study</head><p>In this section, we conduct some ablation studies to investigate the effectiveness of three important components of our proposed model: (1) Explicit relations;</p><p>(2) Implicit similarities;</p><p>(3) The product layer. We set four comparative settings, and the performances of them have been shown in <ref type="table">Table 3</ref>. The details of the four settings are listed below:</p><p>? RER (Remove Explicit Relations) does not consider explicit relations between questions and skills, i.e. removes L 1 (Q Q Q, S S S) from Eqn.(17).</p><p>? RIS (Remove Implicit Similarities) does not consider implicit similarities among questions and skills, i.e. removes L 2 (Q Q Q) and L 3 (S S S) from Eqn.(17).</p><p>? RPL (Remove Product Layer) directly concatenates q q q, s s s and a a a as the pre-trained question embedding instead of using product layer.</p><p>? RPF (Replace Product Layer with Fully Connected Layer) concatenates q q q, s s s and a a a as the input of a fully connected layer instead of product layer.</p><p>Except for the changes mentioned above, the other parts of the models and experimental settings remain identical.</p><p>From <ref type="table">Table 3</ref> we can find that (1) PEBG+DKT and PEBG+DKVMN perform best indicates the efficacy of different components of the models. (2) The models show a similar degree of decline when removing explicit relations and implicit similarities, which means these two pieces of information are equally important. (3) Removing the product layer hurts the performance badly, and using a fully connected layer also has a lower performance. By exploration of feature interactions, the product layer is promising to learn high-order latent patterns compared to directly concatenating features. (4) Without the product layer, RPF and RPL are standard graph embedding methods, which use the firstorder and second-order neighbor information of the bipartite graph. And our proposed pre-trained model PEBG can better improve the performance of existing deep KT models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Embedding Comparison</head><p>We use t-SNE <ref type="bibr" target="#b8">[Maaten and Hinton, 2008]</ref> to project the multi-dimensional question embeddings pre-trained by PEBG and question embeddings learned by other questionlevel deep KT models to the 2-D points. <ref type="figure" target="#fig_3">Figure 3</ref> shows the visualization of question embeddings. Question embeddings learned by DKT and DKVMN are randomly mixed, which completely loses the relations among questions and skills. Question embeddings of different skills learned by DHKT are completely separated, which fails to capture implicit similarities.Question embeddings pre-trained by PEBG are well structured. Questions in the same skill are close to each other, and questions that do not relate to common skills are well separated. PEBG+DKT and PEBG+DKVMN fine-tune the question embeddings pretrained by PEBG to make them more suitable for the KT task while retaining the relations among questions and skills.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose a novel pre-training model PEBG, which first formulates the question-skill relations as a bipartite graph and introduce a product layer to learn lowdimensional question embeddings for knowledge tracing. Experiments on real-world datasets show that PEBG significantly improves the performance of existing deep KT models. Besides, visualization study shows the effectiveness of PEBG to capture question embeddings, which provides an intuitive explanation of its high performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of a question-skill bipartite graph. The question-skill relations are the explicit relations, and the skill similarity and question similarity are implicit relations. Questions q1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>|C| j=1 , we use the average representation of all skill vertex features in C as the related skill feature of q, denoted as s s s . Mathematically, The PEBG framework overview.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Comparison of question embeddings learned by questionlevel deep KT models on the ASSIST09 dataset. The questions related to the same skill are labeled in the same color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Dataset statistics.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>The AUC results over three datasets.</figDesc><table><row><cell>Model</cell><cell cols="3">ASSIST09 ASSIST12 EdNet</cell></row><row><cell>RER+DKT</cell><cell>0.8144</cell><cell>0.7584</cell><cell>0.7652</cell></row><row><cell>RER+DKVMN</cell><cell>0.8053</cell><cell>0.7617</cell><cell>0.7663</cell></row><row><cell>RIS+DKT</cell><cell>0.8082</cell><cell>0.7608</cell><cell>0.7622</cell></row><row><cell>RIS+DKVMN</cell><cell>0.8063</cell><cell>0.7603</cell><cell>0.7657</cell></row><row><cell>RPL+DKT</cell><cell>0.7763</cell><cell>0.7355</cell><cell>0.7445</cell></row><row><cell>RPL+DKVMN</cell><cell>0.7623</cell><cell>0.7033</cell><cell>0.7437</cell></row><row><cell>RPF+DKT</cell><cell>0.8151</cell><cell>0.7473</cell><cell>0.7528</cell></row><row><cell>RPF+DKVMN</cell><cell>0.8127</cell><cell>0.7391</cell><cell>0.7533</cell></row><row><cell>PEBG+DKT</cell><cell>0.8287</cell><cell>0.7665</cell><cell>0.7765</cell></row><row><cell>PEBG+DKVMN</cell><cell>0.8299</cell><cell>0.7701</cell><cell>0.7757</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Experiment code: https://github.com/lyf-1/PEBG</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://sites.google.com/site/assistmentsdata/home/ assistment-2009-2010-data/skill-builder-data-2009-2010 3 https://sites.google.com/site/assistmentsdata/home/ 2012-13-school-data-with-affect 4 https://github.com/riiid/ednet</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The corresponding author Yong Yu thanks the support of NSFC (61702327 61772333).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Knowledge tracing with sequential key-value memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghodai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Abdelrahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 42nd International ACM SIGIR Conference</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning factors analysis-a general method for cognitive model evaluation and improvement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Cen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Tutoring Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="164" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Prerequisite-driven deep knowledge tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.03072</idno>
		<title level="m">net: A large-scale hierarchical dataset in education</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cingi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Can Cemal Cingi. Computer aided education. Procedia-Social and Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="220" to="229" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Knowledge tracing: Modeling the acquisition of procedural knowledge. User modeling and useradapted interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anderson ; Albert T</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John R</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="253" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Addressing the assessment challenge with an online system that tutors as it assesses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="715" to="724" />
		</imprint>
	</monogr>
	<note>Bine: Bipartite network embedding</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exerciseaware knowledge tracing for student performance prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Graph-based knowledge tracing: Modeling student proficiency using graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinton ; Laurens</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton ; Minn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific-Asia Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008-11" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1149" to="1154" />
		</imprint>
	</monogr>
	<note>IEEE 16th International Conference on Data Mining (ICDM)</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exercise-enhanced sequential modeling for student performance prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Steffen Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on world wide web</title>
		<meeting>the 24th international conference on world wide web</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
	<note>Thirty-Second AAAI Conference on Artificial Intelligence. International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Back to the basics: Bayesian extensions of irt outperform neural networks for proficiency estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashima ; Jill-J?nn</forename><surname>Vie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisashi</forename><surname>Kashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.02336</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Educational Data Mining, EDM 2019</title>
		<editor>Zhang et al., 2017] Jiani Zhang, Xingjian Shi, Irwin King, and Dit-Yan Yeung</editor>
		<meeting>the 12th International Conference on Educational Data Mining, EDM 2019<address><addrLine>Montr?al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="765" to="774" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>ternational World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Integrating temporal information into knowledge tracing: A temporal difference approach</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="27302" to="27312" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
