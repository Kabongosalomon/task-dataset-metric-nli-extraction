<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MetaCorrection: Domain-aware Meta Loss Correction for Unsupervised Domain Adaptation in Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">City University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">City University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baopu</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<address>
									<settlement>Baidu</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">City University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MetaCorrection: Domain-aware Meta Loss Correction for Unsupervised Domain Adaptation in Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised domain adaptation (UDA) aims to transfer the knowledge from the labeled source domain to the unlabeled target domain. Existing self-training based UDA approaches assign pseudo labels for target data and treat them as ground truth labels to fully leverage unlabeled target data for model adaptation. However, the generated pseudo labels from the model optimized on the source domain inevitably contain noise due to the domain gap. To tackle this issue, we advance a MetaCorrection framework, where a Domain-aware Meta-learning strategy is devised to benefit Loss Correction (DMLC) for UDA semantic segmentation. In particular, we model the noise distribution of pseudo labels in target domain by introducing a noise transition matrix (NTM) and construct meta data set with domain-invariant source data to guide the estimation of NTM. Through the risk minimization on the meta data set, the optimized NTM thus can correct the noisy issues in pseudo labels and enhance the generalization ability of the model on the target data. Considering the capacity gap between shallow and deep features, we further employ the proposed DMLC strategy to provide matched and compatible supervision signals for different level features, thereby ensuring deep adaptation. Extensive experimental results highlight the effectiveness of our method 1 against existing state-of-the-art methods on three benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Unsupervised domain adaptation (UDA) aims to adapt a model for the unlabeled target domain through transferring the knowledge from a labeled source domain with the same label space. UDA for semantic segmentation is a crucial practical problem since it may be beneficial for various real-world applications, such as simulation for robots <ref type="bibr" target="#b17">[18]</ref> and autonomous driving <ref type="bibr" target="#b43">[44]</ref>. The main challenge of UDA * Xiaoqing Guo and Chen Yang contributed equally. ? This work was supported by Shenzhen-Hong Kong Innovation Circle Category D Project SGDX2019081623300177 (CityU 9240008). <ref type="bibr" target="#b0">1</ref>   <ref type="figure">Figure 1</ref>. Sample of the noisy pseudo labels on Cityscapes <ref type="bibr" target="#b9">[10]</ref>. The generated pseudo labels suffer from the data distribution biases in comparison to the ground truth.</p><p>semantic segmentation lies in the divergence of data distribution between two domains <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b47">48]</ref>. Such domain gap often results in significant performance degradation if the model learned on the labeled source data is directly applied to the target samples <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b50">51]</ref>. There exist two major lines of approaches to tackle the domain gap problem. On one hand, adversarial learning based UDA methods as a dominant stream have been devised to bridge the domain gap by aligning the distributions of two domains in the appearance <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b21">22]</ref>, feature <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b44">45]</ref> or output spaces <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref>. Despite the significant progress of domain alignment, these works ignored the domain-specific knowledge and could not guarantee the sufficient discriminative capability of the classifier for the specific task. On the other hand, self-training based methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref> have emerged as promising alternatives towards UDA, which enhanced the discrimination property of target features and implicitly encouraged cross-domain alignment by simultaneously training with pseudo-labeled target data and labeled source data. Specifically, self-training methods assign pixel-wise pseudo labels according to confidence score <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b50">51]</ref> or uncertainty <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b47">48]</ref>, providing extra supervision for target data to optimize the model. However, one issue with self-training based UDA methods is that the generated pseudo labels usually suffer from the noise problem, as illustrated in <ref type="figure">Figure 1 (b)</ref>. The presence of noisy pseudo labels may severely hamper the generalization ability of the adapted models, because deep neural networks (DNN) may overfit due to these noisy labeled data. Although some existing works <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b50">51]</ref> manually define a threshold to eliminate the low-confidence pseudolabeled samples, it is still challenging in several aspects. First, the threshold value is hard to predefine manually. It may depend on many factors such as the stage of training procedure, the degree of discrepancy between two domains, the number of pixels in each class, the location of the pixel, etc. Secondly, those selected training samples may be misclassified with high confidence, leading to accumulated errors. In fact, the noisy pseudo labels tend to appear in underrepresented minor classes or ambiguous classes. For instance, the minor category 'traffic sign' is overwhelmed by major category 'building', and 'road' is usually connected to 'sidewalk', yielding noisy labels, as in <ref type="figure">Figure 1</ref> (c). In this scenario, noisy pseudo labels can be theoretically converted from the ground truth labels via a NTM <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b46">47]</ref>, which encodes the inter-class misclassification relationship.</p><p>To heuristically discover intrinsic inter-class noise transition probabilities underlying target data, we model the noise distribution of pseudo labels by a NTM and devise a domain-aware meta-learning strategy to estimate the NTM in a learning-to-learn fashion. The key idea of domainaware meta-learning is to obtain the meta-knowledge of underlying label distribution of clean data in the target domain, and we introduce a domain predictor to adaptively select domain-invariant source data with ground truth labels as meta data set, so as to guide the derivation of NTM. The domain-aware meta-learning strategy enables the gradient of empirical risk measured on meta data to update the NTM, thereby boosting the generalization capacity. Then the approximated noise distribution can be utilized to explicitly correct the supervision signal for target data, aiming at solving the noisy pseudo label problem in a self-training based UDA method. An alternating optimization approach is further adopted to mutually improve the estimation of NTM and the UDA segmentation model. For simplicity, we refer to the whole Domain-aware Meta-learning strategy for Loss Correction in the above process as DMLC. Moreover, we devise a MetaCorrection framework, which incorporates DMLC to provide matched supervision signals for outputs of different levels, thereby enhancing the deep adaptation of model. In particular, we introduce the learnable NTMs for different layers, and adopt the proposed domain-aware meta-learning to estimate the corresponding noise distributions and benefit the loss correction.</p><p>We summarize our contributions in four aspects.</p><p>? We present a MetaCorrection framework, which incorporates the proposed DMLC strategy for UDA semantic segmentation. To our best knowledge, it represents the first effort to formally model the noise distribution of pseudo labels in target domain by a learnable NTM and further solve it in a meta-learning strategy. ? In the DMLC strategy, we formulate the misclassification probability of inter-classes to model noise distribution in target domain and devise a domain-aware meta-learning algorithm to estimate NTM for loss correction in a data driven manner. ? Our MetaCorrection framework aims to provide matched and compatible supervision signals for different layers with the proposed DMLC strategy, boosting the adaptation performance of model. ? We conduct extensive comparison experiments and ablation studies to thoroughly verify the impact and effect of the proposed MetaCorrection framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">UDA in Semantic Segmentation</head><p>Unsupervised domain adaptation (UDA) aims to bridge the distribution gap between the labeled source domain and unlabeled target domain, thus improving the generalization capability of the learned models on the target data. The general idea of UDA semantic segmentation methods is to perform domain alignment through adversarial learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref> or utilize self-training strategy on target samples to adapt the segmentation models <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>. We briefly review some typical works in the following parts.</p><p>Adversarial Learning based UDA semantic segmentation models usually contain two networks <ref type="bibr" target="#b39">[40]</ref>. One network behaves as a generator to obtain the segmentation maps for source and target inputs, while the other network serves as a discriminator to derive domain predictions. The generator intends to fool the discriminator to ensure the cross-domain alignment of feature <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11]</ref> or output <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref> levels. Other methods tried to narrow down the domain gap at the input level via image style transformation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b21">22]</ref>. However, these domain alignment methods induced by adversarial learning ignored the domainspecific information and could not guarantee the discriminative ability for semantic segmentation <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>Self-training. Another line of work for UDA semantic segmentation leverages the idea of self-training to adapt the segmentation model and learn the domain specific information <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b48">49]</ref>. Previous methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b49">50]</ref> introduced entropy minimization to fully leverage the unlabeled target data for model training and encouraged the model to predict with high confidence score. Recently, increasing researchers investigated the problem of pseudo label noise in target domain by filtering out noisy samples with respect to confidence score or uncertainty <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b50">51]</ref>. Zou et. al. <ref type="bibr" target="#b50">[51]</ref> proposed to threshold the argmax values of predictions and selected high-confidence pseudo-labeled samples. Zheng et. al. <ref type="bibr" target="#b47">[48]</ref> utilized uncertainty estimation and  <ref type="figure">Figure 2</ref>. The proposed MetaCorrection framework contains a segmentation net and a domain predictor. Both source and target images are passed through the segmentation net to perform semantic segmentation. The source data is supervised by the loss between prediction and the corresponding ground truth label, while the supervision signals of noisy pseudo-labeled target data are corrected by the learnable NTMs. Domain predictor is introduced to select domain-invariant source pixels for the guidance of NTM estimation. enabled the dynamic threshold to obtain rectified pseudo labels. However, these methods only involved confident samples for training, which may result in biased prediction in minor classes and cannot distinguish confused categories. Moreover, when the noise ratio is high (at the early stage of training procedure), these models filtered out a large number of target samples, which may lose useful information in omitted samples. In this paper, we model the noise distribution of pseudo labels in target domain with a learnable matrix that encodes inter-class noise transition relationship, and propose a DMLC strategy to adaptively distill knowledge from all samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Deep Learning with Noisy Labels</head><p>Many efforts have been devoted to tackling the noisy label problem in DNN training and can be roughly categorized into three typical strategies: label correction <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b46">47]</ref>, sample reweighting <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b35">36]</ref>, and loss correction <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43]</ref>. Zhang et. al. <ref type="bibr" target="#b46">[47]</ref> introduced the meta-learning algorithm to conducted a dynamic linear combination of noisy label and prediction from DNN, thereby refurbishing noisy labels. Li et. al. <ref type="bibr" target="#b36">[37]</ref> progressively incorporated increasing samples in an easy-to-hard manner to enable a robust model trained with noisy samples. Authors in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b36">37]</ref> utilized multiple layer perception network to automatically assign large weighting factor for easy samples. Goldberger et. al. <ref type="bibr" target="#b12">[13]</ref> estimated the noise pattern through embedding a noise adaptation layer in DNN model. Wang et. al. <ref type="bibr" target="#b42">[43]</ref> leveraged a small set of trusted clean-labeled samples to estimate the NTM for loss correction. Nonetheless, these strategies were designed for fully-supervised whole-image classification, and could not be directly incorporated into UDA semantic segmentation. Our work represents the first effort to exploit the loss correction with an effective metalearning strategy for self-training based UDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminaries</head><p>We focus on the problem of UDA in semantic segmentation. In the source domain, we have access to source images X S = {x s ? R H?W ?3 } s?S and the corresponding pixelwise one-hot labels Y S = {y s ? {0, 1} H?W ?C } s?S , while only target images X T = {x t ? R H?W ?3 } t?T are available in the target domain. Note that H, W , C denote the height, width of images and the number of classes, respectively. The goal is to learn a segmentation net f (?) w that can correctly categorize pixels for target data X T . Selftraining based methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50]</ref> regarded pseudo labels of target data as learnable hidden variables,</p><formula xml:id="formula_0">Y T = { y t } t?T = {arg max f (x t ) w } t?T ,</formula><p>and utilized them as approximate ground truth labels for model training. Then cross-entropy loss over the source and target dataset for self-training can be defined as</p><formula xml:id="formula_1">L ST = L S seg (X S , Y S ) + L T seg (X T , Y T ) = ? s?S y s log f (x s , w) ? t?T y t log f (x t , w) .</formula><p>(1) By minimizing the empirical risk of target data with respect to the estimated pseudo label y t , the optimized model thus can be discriminatively adapted to the target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Self-training with Loss Correction</head><p>Jointly optimizing the model and estimating pseudo labels for target data is difficult as the accuracy of generated pseudo labels cannot be guaranteed. The noise in pseudo labels could deteriorate the performance of existing selftraining based methods, and result in unstable training and biased predictions. A feasible way is to enhance the noise tolerance property of target domain risk minimization via loss correction. To incorporate loss correction, we assume that the generated pseudo labels Y t can be bridged to the ground truth labels Y t via an underlying noise transition matrix (NTM) T ? [0, 1] C?C , which specifies the probability of ground truth label j flipping to noisy label k by</p><formula xml:id="formula_2">T jk = p( y t = k | y t = j).</formula><p>If we directly optimize the segmentation net f (?) w on the noisy pseudo-labeled taget data, we would obtain a class posterior probability for noisy label p( y t = k | x t ). NTM bridges the posterior for noisy label p( y t = k | x t ) and the class probability for ground truth label via:</p><formula xml:id="formula_3">p( y t = k | x t , w) = C j=1 T jk p(y t = j | x t , w), ? p( y t | x t ,w) = p(y t | x t , w)T.<label>(2)</label></formula><p>Given the NTM (T ), we modify and correct the self-training loss L T seg (X T ) in Eq. <ref type="formula">(1)</ref> with respect to noisy pseudolabeled target data as</p><formula xml:id="formula_4">L T LC (X T , Y T ) = ? t?T y t log[f (x t , w) T ].<label>(3)</label></formula><p>This corrected loss function encourages the similarity between noise adapted posterior class probabilities and the noisy pseudo labels. It is obvious that once the NTM is obtained, we can recover the desired estimation of class posterior probability p(y t |x t , w) by the softmax output f (x t , w) even training the segmentation model with noisy data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Domain-aware Meta Loss Correction (DMLC)</head><p>The effectiveness of loss correction methods highly depends on the estimation of NTM (T ). Some previous attempts constructed T with a strong assumption on the noise type <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b30">31]</ref>, which impeded the generalization capability of model to complicated label noise. Other works required a set of clean labeled data to guide the estimation of T <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43]</ref>. For example, Gold Loss Correction <ref type="bibr" target="#b15">[16]</ref> utilizes the mean probability of all samples in the clean set categorized to class i to approximate T . This requirement makes the loss correction algorithm infeasible to be applied to unsupervised learning task directly.</p><p>To heuristically explore the inter-class noise transition probabilities, we devise a Domain-aware Meta-learning strategy to enable Loss Correction (DMLC) for UDA task. DMLC alternatively estimates T by minimizing the empirical risk on the domain-invariant meta data with clean labels and optimizes the segmentation net with supervision signal corrected by previously approximated T on the unlabeled target data. The key idea of DMLC lies in the estimation of T , and we first construct a set of meta data set {X M , M M } = {x m , y m } m?M with clean labels, representing the meta-knowledge of underlying label distribution of clean samples. Due to the lack of annotation in target domain, we attempt to select domain-invariant source data to construct such a meta data set. In particular, an additional pre-trained domain predictor g(?) u and a threshold coefficient ? are introduced to sample target-like source pixels as the meta data, as illustrated in <ref type="figure">Figure 2</ref>. Only those samples with domain predictions g(x s , u) larger than ? are involved in meta-learning procedure. With the constructed meta data set, NTM can be updated to T * via:</p><formula xml:id="formula_5">T * = arg min T ?[0,1] c?c ? m?M ym log f (xm, w(T ) * ), where w(T ) * = arg min w ? t?T yt log[f (xt, w) T ],<label>(4)</label></formula><p>where w(T ) * represents the optimal segmentation net with the minimal corrected loss on the noisy pseudo-labeled target data, and the updated T * should minimize the empirical loss on meta data with the optimal segmentation net <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43]</ref>. Intuitively, during the optimization procedure of segmentation net, it is difficult to distinguish hard samples and noisy samples since both of them can produce large loss values, leading to the overfitting of noise. Guiding the estimation of T via risk minimization on meta data set, our method can avoid the wrong supervision signals and boost the generalization ability of adapted model.</p><p>With the estimated T * , the noisy pseudo-labeled target data can be effectively utilized to optimize the segmentation net. Jointly optimizing the segmentation net on source and target data, the proposed DMLC model can be extended from self-training in Eq. (1) and our objective function for UDA can be formulated as:</p><formula xml:id="formula_6">L DM LC = L S seg (X S , Y S ) + L T DM LC (X T , Y T ) = ? s?S y s log f (x s , w) ? t?T y t log[f (x t , w) T * ]. (5)</formula><p>Jointly optimizing NTM associated with the segmentation net, the proposed DMLC can simultaneously estimate the noise distribution in pseudo labels and perform loss correction to target low segmentation error on target data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Alternating Optimization for DMLC</head><p>To synergically optimize the NTM (T ) and the segmentation net f (?)w, we adopt an alternating optimization strategy, and the training procedure consists of three steps: virtual optimization, meta optimization, actual optimization, as in <ref type="figure" target="#fig_1">Figure 3</ref>. The virtual and meta optimizations aim to optimize T , and the actual optimization is to update parameters in the segmentation net with fixed T .</p><p>During virtual optimization step <ref type="figure" target="#fig_1">(Figure 3 (a)</ref>), a meta net is copied from segmentation net with parameters w i , and a mini-batch of target images is forwarded through the meta net. Then the parameters in the meta net are updated by moving the current w i along the gradient descent direction of corrected loss function with learning rate ? v : Note that this is a 'virtual' step, indicating parameters in segmentation net are not actually updated to? i+1 . Similar to well-known MAML <ref type="bibr" target="#b11">[12]</ref> with second-order back-propagation, in the meta optimization step <ref type="figure" target="#fig_1">(Figure 3</ref> (b)), we update T by minimizing the cross entropy loss on meta data with the feedback from the updated parameter? w i+1 as follows:</p><formula xml:id="formula_7">w i+1 (T i ) = w i + ? v ? w t?T y t log[f x t , w i T i ]. (6) Meta Net ( ! ) " Meta Net ( * !#$ ) %&amp;"' %&amp;"' * !#$ = ! ? ? ? !"#$ * " ? &amp;'( Segmentation Net ( ! ) " ? !"#$ * " ? ! Virtual Optimization Meta Optimization Actual Optimization !#$</formula><formula xml:id="formula_8">T i+1 = T i + ? m ? T m?M y m log f (x m ,? i+1 (T i )),<label>(7)</label></formula><p>where ? m is the learning rate of meta optimization. The intuition behind the meta optimization step is to obtain an optima of T i+1 with a low empirical risk and a high generalization ability. After the back propagation updating parameters, T i+1 may contains negative values. Therefore, we first utilize T i+1 = max T i+1 , 0 to enable the nonnegative matrix and then perform normalization along the row direction T i+1 jk = T i+1 jk / T i+1 j? to ensure transition probabilities of class j are summed to 1.</p><p>In the actual optimization step <ref type="figure" target="#fig_1">(Figure 3 (c)</ref>), the noisy pseudo-labeled target data and the labeled source data are simultaneously used to optimize the segmentation net via:</p><formula xml:id="formula_9">w i+1 = w i + ? a ? w s?S y s log f (x s , w) + ? a ? w t?T y t log[f (x t , w) T i+1 ],<label>(8)</label></formula><p>where ? a is the learning rate. Through the alternating optimization strategy, both the NTM (T ) and the segmentation net f (?) w can be gradually ameliorated based on the optimal solution computed in the last step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">MetaCorrection</head><p>Since low-level layers usually contain detailed features while high-level features often encode task-specific infor-mation, it may be beneficial to transfer the knowledge from the deep layer to guide the adaptation of low-level features. Previous deep supervision approaches <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b39">40]</ref> directly forces the low-level output to mimic the one-hot pseudo label computed from high-level output layer, which may bring about supervision bias and eliminate useful detailed information in low-level layer due to the capacity gap <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>Aiming at solving the above problem, we incorporate the proposed DMLC to generate the matched and compatible supervision signal for the low-level features to enhance the adaptation. In particular, we introduce additional NTM for the loss correction and utilize the domain-aware metalearning method to estimate the specific noise distribution for shallow supervisions, thereby bridging the gap between the low-level outputs and the pseudo label obtained from deep features. The overall training objective of our Meta-Correction framework can be extended from Eq. (5) to be:</p><formula xml:id="formula_10">L M C = L S seg (X S , Y S ) + l ? l L T (l) DM LC (X T , Y T ),<label>(9)</label></formula><p>where l indicates the level used for DMLC and ? l is the weighting factor for supervision signal of l th layer. Note that l = 0 denotes the output layer.</p><p>With the proposed MetaCorrection framework, NTMs embedded in the segmentation net are capable of assessing the individual noise distributions in pseudo labels for different layers. Moreover, our MetaCorrection framework can obtain corrected loss functions in a data-driven manner, and these generated compatible supervision signals for different levels of features can further boost the learning of model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>We evaluate the performance of our methods on two challenging synthetic-to-real UDA semantic segmentation tasks and a medical image segmentation task. Two synthetic datasets, GTA5 <ref type="bibr" target="#b32">[33]</ref> and SYNTHIA <ref type="bibr" target="#b33">[34]</ref>, and a real dataset, CityScapes <ref type="bibr" target="#b9">[10]</ref>, are utilized to perform UDA synthetic-toreal semantic segmentation tasks, including two scenarios: GTA5?CityScapes and SYNTHIA?CityScapes. Moreover, two public prostate MRI datasets are adopted to perform UDA from Decathlon <ref type="bibr" target="#b37">[38]</ref> to NCI-ISBI13 <ref type="bibr" target="#b28">[29]</ref>.</p><p>GTA5 contains 24,966 images captured from a video game. Pixel-wise annotations with 33 classes are provided, but only 19 classes are utilized for compatibility with CityScapes. SYNTHIA consists of 9,400 synthetic images, and annotations with 16 classes are used for adaptation. CityScapes is a real-world semantic segmentation dataset collected in driving scenarios. Training set, including 2,975 unlabeled images, is regarded as the target domain data for training. Evaluations are performed on 500 validation images with manual annotations. Decathlon is a comprehensive medical image segmentation dataset, including </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Network and Training Details</head><p>Segmentation Net We adopt DeepLab-v2 <ref type="bibr" target="#b2">[3]</ref> backbone with pre-trained ResNet-101 <ref type="bibr" target="#b14">[15]</ref> encoder as our segmentation net. Subsequently, Atrous Spatial Pyramid Pooling (ASPP) is employed after the last layer of encoder with dilated rates {6, 12, 18, 24}. Finally, an up-sampling layer along with a softmax operator is applied to obtain the final segmentation result with the matched size of input image.</p><p>We construct the above-mentioned segmentation net and apply the NTM to the output layer as our single DMLC model. For the MetaCorrection framework, we additionally extract low-level feature maps from the conv4 layer of ResNet-101 and introduce an ASPP module as the auxiliary classifier with output f 1 (x t , w). An additional NTM T <ref type="bibr" target="#b0">(1)</ref> is incorporated to generate a compatible supervision signal for low-level output. ? 0 and ? 1 in Eq. (9) are set as 1, 0.1.</p><p>Domain Predictor The feature maps extracted from the encoder in the segmentation net are utilized for the pixellevel domain prediction. We adopt a similar structure with DCGAN <ref type="bibr" target="#b31">[32]</ref>, which is composed of five cascaded 4?4 convolution layers with output channel numbers {64, 128, 256, 512, 1}. Then the domain prediction is obtained with the same resolution of the input image, and the threshold coefficient ? is set as 0.5 to construct the meta data set.</p><p>Implementation Details Our methods are implemented with the PyTorch library on Nvidia Tesla V100. The Stochastic Gradient Descent is utilized as our optimizer, where the momentum is 0.9 and the weight decay is 1e-3. We adopt polynomial learning rate scheduling to optimize the segmentation net with the initial learning rate of ? a = 2.5e ? 4, the power of 0.9 and the maximum iteration number of 150000. For the updating of meta net, ? v = 1e ? 4 and ? m = 0.11 are set in our implementation.</p><p>The performances of our methods in synthetic-to-real scenarios are evaluated by the widely utilized performance metrics, intersection-over-union (IoU) of each class and the mean IoU (mIoU). For the prostate zonal segmentation, Dice scores for PZ, TZ and the whole prostate (WP) are employed to measure the accuracy of segmentation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results on GTA5?CityScapes</head><p>We first verify the effectiveness of our approachs in the GTA5?Cityscapes scenario, and the corresponding comparison results are listed in <ref type="table" target="#tab_1">Table 1</ref> with the first and second best results highlighted in bold and underline. For a fair comparison, all the competed models adopt DeepLab-v2 backbone network with pre-trained ResNet-101 as encoder. Overall, our MetaCorrection framework surpasses all other models with a promising mIoU of 52.1%, outperforming the model trained only on the source data by a significant increment of 15.5% in mIoU. Compared with domain alignment methods <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b19">20]</ref>, the proposed method shows superior performance. For example, PatchAlign <ref type="bibr" target="#b40">[41]</ref> leverages the patch-level information to encourage the domain alignment, yielding 46.5% mIoU, which is inferior to our approach. Our MetaCorrection model, as a self-training based method, also outperforms other related pseudo label learning works <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b45">46]</ref>, demonstrating the effectiveness of the proposed method in alleviating the noise problem. Moreover, the proposed methods also show superior performance in terms of the per class IoU score, especially in the minor categories (e.g., 'motor') and ambiguous (e.g., 'road' and 'sidewalk') categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results on SYNTHIA ? CityScapes</head><p>We then utilize SYNTHIA as the source domain data and display comparison results of our methods and other state-of-the-art methods <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b45">46]</ref> on the validation set of Cityscapes, as listed in the <ref type="table" target="#tab_2">Table 2</ref>. We consider the IoU and mIoU of both the 16 classes and a subset of 13 classes following the standard experimental setting <ref type="bibr" target="#b29">[30]</ref>. Since the domain shift is more evident in this scenario, the performance is slightly worse. Our MetaCor-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Results on Decathlon ? NCI-ISBI13</head><p>Domain discrepancy is common in clinical practice, e.g., MRIs obtained from different scanners and sites. Hence, we further assess the performance of our methods on UDA prostate segmentation, and the quantitative comparison results are listed in <ref type="table" target="#tab_3">Table 3</ref>. It is observed that our methods exhibit superior segmentation performance in comparison to the self-training based methods, CBST <ref type="bibr" target="#b50">[51]</ref>, MRENT <ref type="bibr" target="#b49">[50]</ref>, MaxSquare <ref type="bibr" target="#b3">[4]</ref>. For example, both single DMLC and Meta-Correction methods outperform CBST with increments of 5.07%, 6.56% in WP Dice score. This observation proves the impact of our approaches in medical image analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Ablation Study</head><p>Ablation Experiments. To investigate the effects of individual components of our proposed model, we design ablation studies under three adaptation scenarios ( <ref type="table" target="#tab_1">Table 1</ref>, 2, 3) and with three baseline models <ref type="table" target="#tab_4">(Table 4</ref>). Compared with the 'Source only' lower bound, our baseline network with single DMLC boosts the mIoU to 51.2% with an increment of 14.6% in GTA5 ? CityScapes case. Then we introduce auxiliary supervision signals for low-level layers, which also contributes to the performance gain and increases the mIoU to 52.1%, as in <ref type="table" target="#tab_1">Table 1</ref>. Moreover, incorporating DMLC to different baseline models, the MetaCorrection framework consistently improves the performance over single DMLC in terms of mIoU score, as in <ref type="table" target="#tab_4">Table 4</ref>. Comparison with Self-training based UDA Models. To validate the effectiveness of DMLC, we compare it with three typical self-training based UDA models <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>. As listed in <ref type="table" target="#tab_4">Table 4</ref>, the proposed MetaCorrection framework (row 7) is superior to other self-training methods, including entropy minimization <ref type="bibr" target="#b49">[50]</ref> (row 3), handcrafted threshold <ref type="bibr" target="#b50">[51]</ref> (row 4), uncertainty based rectification <ref type="bibr" target="#b27">[28]</ref> (row 5), yielding increments of 2.2%, 2.9%, 1.2% mIoU. Through entropy minimization, considerable noisy labels inevitably result in unsatisfactory performance. Other selftraining based methods <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref> filtered out noisy samples with respect to the confidence score and uncertainty, but lost useful information in those omitted samples. Therefore, the increments are owing to that our method can preserve all data distribution and distill effective information from all samples with learned NTM for unbiased self-training.</p><p>Robustness to Various Types of Noise. We further explore the robustness of our MetaCorrection framework under different types of noise. Specifically, we adopt Adapt-SegNet <ref type="bibr" target="#b39">[40]</ref>, LTIR <ref type="bibr" target="#b19">[20]</ref>, source only model to generate noisy pseudo labels and apply our MetaCorrection to mitigate the noise problem. As in <ref type="table" target="#tab_4">Table 4</ref>, these three models have significantly improved performance with the proposed MetaCorrection framework. For example, MetaCorrection (row 7) improves the performance of AdaptSegNet (row 2) from 42.4% to 47.3% mIoU. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Visualization Results</head><p>Segmentation Visualization. As illustrated in <ref type="figure">Figure  4</ref>, we provide some typical qualitative segmentation results of target data on all three benchmarks. Obviously, the self-training method <ref type="bibr" target="#b49">[50]</ref> could significantly promote the performance in comparison to the source model. Besides, in contrast to the baseline self-training method with conventional entropy minimization, the proposed MetaCorrection framework has better scalability to confused categories (e.g., 'rider' and 'bike') and small-scale objectives (e.g., 'traffic sgn'). We speculate the reason is that pseudo labels usually contain considerable noises in the minor categories and ambiguous categories. The proposed method rectifies the supervision signals and prevent such mistakes, leading to more reasonable segmentation predictions.</p><p>NTM Visualization. We visualize the learned NTMs of output layer (T 0 ) and shallow layer (T 1 ), as in <ref type="figure">Figure 5</ref>. It is obvious that different layers exhibit variant noise transition probability, indicating the varying noise distributions of deep and shallow layers. The proposed MetaCorrection framework can generate matched supervision signals for individual layers to enhance the deep adaptation.</p><p>Feature Visualization. We use t-SNE <ref type="bibr" target="#b26">[27]</ref> to visualize the feature representations of source only model, selftraining <ref type="bibr" target="#b49">[50]</ref>, our MetaCorrection and oracle model (i.e., fine-tuning the segmentation net with the labeled target data), as illustrated in <ref type="figure">Figure 5</ref>. It is observed that our MetaCorrection model obtains the most matched feature distribution with that of the oracle model in comparison to source only and self-training <ref type="bibr" target="#b49">[50]</ref> models. This observation demonstrates that our method can provide correct supervision signal for target data through the learnable NTM. Moreover, our feature representations exhibit the clearest clusters compared with other baseline methods, revealing the discriminative capability of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have proposed a MetaCorrection framework, where the Domain-aware Meta Loss Correction (DMLC) strategy is advanced for UDA in the context of semantic segmentation, aiming for addressing the noise problem in self-training based UDA methods. The DMLC incorporates a learnable noise transition matrix (NTM) to bridge the noisy pseudo labels and ground truth labels for loss correction of the target domain, and NTM is derived through the proposed domain-aware meta-learning strategy in a data-driven manner. The model-agnostic DMLC can be flexibly applied to other models and datasets. Moreover, we consider the capacity gap between deep and shallow layers, and provide compatible supervisions for different levels to ensure the deep adaptation of the proposed MetaCorrection. The experimental results demonstrate that our methods achieve superior results to state-of-the-art methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Meta data ( ' , ' )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of alternating optimization strategy for DMLC, including three steps: virtual optimization, meta optimization and actual optimization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .Figure 5 .</head><label>45</label><figDesc>Qualitative results of UDA semantic segmentation. (a) Target image, (b) Ground truth, Predictions from (c) source only model, (d) self-training based MRENT model [50], (e) ours (MetaCorrection). Left: Visualization of NMTs T (0) and T (1) . Right: The t-SNE visualization of embedded features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Results of adapting GTA5 to CityScapes. The mechanism 'AL' and 'ST' stand for adversarial learning and self-training. AL 86.<ref type="bibr" target="#b4">5</ref> 36.0 79.9 23.4 23.3 23.9 35.2 14.8 83.4 33.3 75.6 58.5 27.6 73.7 32.5 35.4 3.9 30.1 28.1 ST 92.8 58.1 86.2 39.7 33.1 36.3 42.0 38.6 85.5 37.8 87.6 62.8 31.7 84.8 35.7 50.3 2.0 36.8 48.0</figDesc><table><row><cell>GTA5 ? CityScapes</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Results of adapting SYNTHIA to CityScapes. mIoU* denotes the mean IoU of 13 classes, excluding the classes with * .</figDesc><table><row><cell>SYNTHIA ? CityScapes</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Results of adapting Decathlon to NCI-ISBI13.</figDesc><table><row><cell>Method</cell><cell cols="4">mech. PZ (Dice) TZ (Dice) WP (Dice)</cell></row><row><cell>CBST [51]</cell><cell>ST</cell><cell>38.22</cell><cell>70.14</cell><cell>64.31</cell></row><row><cell>MRENT [50]</cell><cell>ST</cell><cell>40.82</cell><cell>72.39</cell><cell>67.68</cell></row><row><cell>MaxSquare [4]</cell><cell>ST</cell><cell>37.45</cell><cell>69.61</cell><cell>63.34</cell></row><row><cell>Source only</cell><cell>-</cell><cell>28.48</cell><cell>52.57</cell><cell>47.56</cell></row><row><cell>Ours (single DMLC)</cell><cell>ST</cell><cell>42.03</cell><cell>74.09</cell><cell>69.38</cell></row><row><cell>Ours (MetaCorrection)</cell><cell>ST</cell><cell>43.25</cell><cell>74.31</cell><cell>70.87</cell></row><row><cell cols="5">rection framework still achieves promising results in com-</cell></row><row><cell cols="5">parison to other competed methods. Specifically, the pro-</cell></row><row><cell cols="5">posed method achieves 45.1% mIoU of 16 categories and</cell></row><row><cell>52.5% mIoU</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* of 13 categories.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Impact of different pseudo labels. 'Pseudo Label' denotes we employ pseudo labels generated by the corresponding model.</figDesc><table><row><cell>Method</cell><cell>Pseudo Label</cell><cell>GTA5 ? CityScapes</cell><cell>?</cell></row><row><cell>AdaptSegNet [40]</cell><cell>-</cell><cell>42.4</cell><cell>-</cell></row><row><cell>Self-training (MRENT [50])</cell><cell>AdaptSegNet</cell><cell>45.1</cell><cell>2.7</cell></row><row><cell cols="2">Self-training (Threshold [51]) AdaptSegNet</cell><cell>44.4</cell><cell>2.0</cell></row><row><cell cols="2">Self-training (Ucertainty [48]) AdaptSegNet</cell><cell>46.1</cell><cell>3.7</cell></row><row><cell>Ours (single DMLC)</cell><cell>AdaptSegNet</cell><cell>45.9</cell><cell>3.5</cell></row><row><cell>Ours (MetaCorrection)</cell><cell>AdaptSegNet</cell><cell>47.3</cell><cell>4.9</cell></row><row><cell>LTIR [20]</cell><cell>-</cell><cell>50.2</cell><cell>-</cell></row><row><cell>Self-training (MRENT [50])</cell><cell>LTIR</cell><cell>50.6</cell><cell>0.4</cell></row><row><cell>Ours (single DMLC)</cell><cell>LTIR</cell><cell>51.2</cell><cell>1.0</cell></row><row><cell>Ours (MetaCorrection)</cell><cell>LTIR</cell><cell>52.1</cell><cell>1.9</cell></row><row><cell>Source only</cell><cell>-</cell><cell>36.6</cell><cell>-</cell></row><row><cell>Self-training (MRENT [50])</cell><cell>Source</cell><cell>39.6</cell><cell>3.0</cell></row><row><cell>Ours (single DMLC)</cell><cell>Source</cell><cell>43.8</cell><cell>7.2</cell></row><row><cell>Ours (MetaCorrection)</cell><cell>Source</cell><cell>44.5</cell><cell>7.9</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E O&amp;apos;</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Synergistic image and feature adaptation: Towards cross-modality domain adaptation for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="865" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain adaptation for semantic segmentation with maximum squares loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adversarial-learned loss for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="3521" to="3528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning semantic segmentation from synthetic data: A geometrically guided input-output adaptation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1841" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Crdoco: Pixel-level domain transfer with crossdomain consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1791" to="1800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the efficacy of knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4794" to="4802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Selfensembling with gan-based data augmentation for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taekyung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changick</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6830" to="6840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ssf-dan: Separated semantic feature based domain adaptation network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingang</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongye</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="982" to="991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Training deep neural-networks using a noise adaptation layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Ben-Reuven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised wce image classification with adaptive aggregated attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">101733</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duncan</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mlsl: Multi-level selfsupervised learning for domain adaptation with spatially independent and semantically consistent labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javed</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1864" to="1873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sim-to-real via simto-sim: Data-efficient robotic grasping via randomized-tocanonical adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Wohlhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinal</forename><surname>Kalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalashnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Irpan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Ibarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Bousmalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12627" to="12637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning texture invariant representation for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeongjin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeran</forename><surname>Byun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="12975" to="12984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Self-paced convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maoguo</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IJCAI</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2110" to="2116" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6936" to="6945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Constructing self-motivated pyramid curriculums for crossdomain semantic segmentation: A non-adversarial approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengmao</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="6758" to="6767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Exploring uncertainty in pseudo-label guided unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">106996</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Metadistiller: Network self-boosting via metalearned top-down distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benlin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongming</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2507" to="2516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.12197</idno>
		<title level="m">stance adaptive self-training for unsupervised domain adaptation</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Nci-isbi 2013 challenge: Automated segmentation of prostate structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bloch</forename><surname>Nicolas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madabhushi</forename><surname>Anant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huisman</forename><surname>Henkjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Freymann</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirby</forename><surname>Justin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Imaging Arch</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Seokju Lee, and In So Kweon. Unsupervised intra-domain adaptation for semantic segmentation through self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkyu</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Rameau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="3764" to="3773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Stephan R Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="102" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio M</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3234" to="3243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Guided curriculum model adaptation and uncertainty-aware evaluation for semantic nighttime image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="1919" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zengben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.05697</idno>
		<title level="m">Meta transition adaptation for robust deep learning with noisy labels</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">A large annotated medical image dataset for the development and evaluation of segmentation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Amber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michela</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyridon</forename><surname>Antonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Bakas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyvan</forename><surname>Bilello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bram</forename><surname>Farahani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annette</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kopp-Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geert</forename><surname>Bennett A Landman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Menze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09063</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Gotta adapt&apos;em all: Joint pixel and feature-level domain adaptation for recognition in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luan</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2672" to="2681" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="7472" to="7481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Domain adaptation for structured output via discriminative patch representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1456" to="1465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation via structured prediction based selective pseudolabeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toby</forename><forename type="middle">P</forename><surname>Breckon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Training noiserobust deep neural networks via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Differential treatment for stuff and things: A simple unsupervised domain adaptation method for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Mei</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12635" to="12644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Adversarial domain adaptation with domain mixup</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="6502" to="6509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Category anchor-guided unsupervised domain adaptation for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="435" to="445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Distilling effective supervision from severe label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sercan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Arik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.03773</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Improving semantic segmentation via self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongruo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Smola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14960</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Confidence regularized self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="5982" to="5991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Bvk Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="289" to="305" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
