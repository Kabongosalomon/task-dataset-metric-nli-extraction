<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021">2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Hausler</surname></persName>
							<email>s.hausler@qut.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">QUT Centre for Robotics</orgName>
								<orgName type="institution">Queensland University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourav</forename><surname>Garg</surname></persName>
							<email>s.garg@qut.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">QUT Centre for Robotics</orgName>
								<orgName type="institution">Queensland University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">QUT Centre for Robotics</orgName>
								<orgName type="institution">Queensland University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
							<email>michael.milford@qut.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">QUT Centre for Robotics</orgName>
								<orgName type="institution">Queensland University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Fischer</surname></persName>
							<email>tobias.fischer@qut.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">QUT Centre for Robotics</orgName>
								<orgName type="institution">Queensland University of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition</title>
					</analytic>
					<monogr>
						<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
						<imprint>
							<date type="published" when="2021">2021</date>
						</imprint>
					</monogr>
					<note>Preprint version; final version available at Published by: IEEE</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T18:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Visual Place Recognition is a challenging task for robotics and autonomous systems, which must deal with the twin problems of appearance and viewpoint change in an always changing world. This paper introduces Patch-NetVLAD, which provides a novel formulation for combining the advantages of both local and global descriptor methods by deriving patch-level features from NetVLAD residuals. Unlike the fixed spatial neighborhood regime of existing local keypoint features, our method enables aggregation and matching of deep-learned local features defined over the feature-space grid. We further introduce a multi-scale fusion of patch features that have complementary scales (i.e. patch sizes) via an integral feature space and show that the fused features are highly invariant to both condition (season, structure, and illumination) and viewpoint (translation and rotation) changes. Patch-NetVLAD outperforms both global and local feature descriptor-based methods with comparable compute, achieving state-of-the-art visual place recognition results on a range of challenging real-world datasets, including winning the Facebook Mapillary Visual Place Recognition Challenge at ECCV2020. It is also adaptable to user requirements, with a speed-optimised version operating over an order of magnitude faster than the stateof-the-art. By combining superior performance with improved computational efficiency in a configurable framework, Patch-NetVLAD is well suited to enhance both stand-alone place recognition capabilities and the overall performance of SLAM systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Visual Place Recognition (VPR) is a key prerequisite for many robotics and autonomous system applications, both as a stand-alone positioning capability when using a prior map and as a key component of full Simultaneous Localization And Mapping (SLAM) systems. The task can prove challenging because of major changes in appearance, illumination and even viewpoint, and is therefore an area of active re- <ref type="figure">Figure 1</ref>. Patch-NetVLAD is a novel condition and viewpoint invariant visual place recognition system that produces a similarity score between two images through local matching of locally-global descriptors extracted from a set of patches in the feature space of each image. Furthermore, by introducing an integral feature space, we are able to derive a multi-scale approach that fuses multiple patch sizes. This is in contrast with the original NetVLAD paper, which performs an appearance only aggregation of the whole feature space into a single global descriptor. search in both the computer vision <ref type="bibr">[3,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b77">78,</ref><ref type="bibr" target="#b78">79]</ref> and robotics <ref type="bibr">[10,</ref><ref type="bibr">11,</ref><ref type="bibr">12,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b41">42]</ref> communities.</p><p>VPR is typically framed as an image retrieval task <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b72">73]</ref>, where, given a query image, the most similar database image (alongside associated metadata such as the camera pose) is retrieved. There are two common ways to represent the query and reference images: using global descriptors which describe the whole image <ref type="bibr">[3,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr">10,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b78">79]</ref>, or using local descriptors that describe areas of interest <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr">18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr">14]</ref>. Global descriptor matching is typically performed using nearest neighbor search between query and reference images. These global descriptors typically excel in terms of their robustness to appearance and illumination changes, as they are directly optimized for place recognition <ref type="bibr">[3,</ref><ref type="bibr" target="#b55">56]</ref>. Conversely, local descriptors are usually cross-matched, followed by geometric verification. Local descriptor techniques prioritize spatial precision, predominantly on a pixel-scale level, using a fixed-size spatial neighborhood to facilitate highly-accurate 6-DoF pose estimation. Given the complementary strengths of local and global approaches, there has been little research <ref type="bibr">[9,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b72">73]</ref> attempting to combine them. The novel Patch-NetVLAD system proposed here combines the mutual strengths of local and global approaches while minimizing their weaknesses.</p><p>To achieve this goal, we make a number of contributions (see <ref type="figure">Fig. 1</ref>): First, we introduce a novel place recognition system that generates a similarity score between an image pair through a spatial score obtained through exhaustive matching of locally-global descriptors. These descriptors are extracted for densely-sampled local patches within the feature space using a VPR-optimized aggregation technique (in this case NetVLAD <ref type="bibr">[3]</ref>). Second, we propose a multi-scale fusion technique that generates and combines these hybrid descriptors of different sizes to achieve improved performance over a single scale approach. To minimize the computational growth implications of moving to a multi-scale approach, we develop an integral feature space (analogous to integral images) to derive the local features for varying patch sizes. Together these contributions provide users with flexibility based on their task requirements: our final contribution is the demonstration of a range of easily implemented system configurations that achieve different performance and computational balances, including a performance-focused configuration that outperforms the state-of-the-art recall performance while being slightly faster, a balanced configuration that performs as well as the state-of-the-art while being 3? faster and a speed-focused configuration that is an order of magnitude faster than the state-of-the-art.</p><p>We extensively evaluate the versatility of our proposed system on a large number of well-known datasets <ref type="bibr" target="#b67">[68,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b78">79]</ref> that capture all challenges present in VPR. We compare Patch-NetVLAD with several state-of-the-art global feature descriptor methods <ref type="bibr">[3,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b75">76]</ref>, and additionally introduce new SuperPoint <ref type="bibr">[18]</ref> and SuperGlue <ref type="bibr" target="#b58">[59]</ref>-enabled VPR pipelines as competitive local descriptor baselines. Patch-NetVLAD outperforms the global feature descriptor methods by large margins (from 6% to 330% relative increase) across all datasets, and achieves superior performance (up to a relative increase of 54%) when compared to SuperGlue. Patch-NetVLAD won the Facebook Mapillary Long-term Localization Challenge as part of the ECCV 2020 Workshop on Long-Term Visual Localization. To characterise the system's properties in detail, we conduct numerous ablation studies showcasing the role of the individual components comprising Patch-NetVLAD, particularly the robustness of the system to changes in various key parameters. To foster future research, we make our code available for research purposes: https://github.com/QVPR/Patch-NetVLAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Global Image Descriptors: Notable early global image descriptor approaches include aggregation of local keypoint descriptors either through a Bag of Words (BoW) scheme <ref type="bibr" target="#b63">[64,</ref><ref type="bibr">16]</ref>, Fisher Vectors (FV) <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b52">53]</ref> or Vector of Locally Aggregated Descriptors (VLAD) <ref type="bibr" target="#b34">[35,</ref><ref type="bibr">2]</ref>. Aggregation can be based on either sparse keypoint locations <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b34">35]</ref> or dense sampling of an image grid <ref type="bibr" target="#b75">[76]</ref>. Re-formulating these methods through deep learning-based architectures led to NetVLAD <ref type="bibr">[3]</ref>, NetBoW <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b50">51]</ref> and NetFV <ref type="bibr" target="#b44">[45]</ref>. More recent approaches include ranking-loss based learning <ref type="bibr" target="#b55">[56]</ref>, novel pooling <ref type="bibr" target="#b54">[55]</ref>, contextual feature reweighting <ref type="bibr" target="#b36">[37]</ref>, large scale re-training <ref type="bibr" target="#b78">[79]</ref>, semantics-guided feature aggregation <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b71">72]</ref>, use of 3D <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b77">78,</ref><ref type="bibr" target="#b39">40]</ref>, additional sensors <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b21">22]</ref> and image appearance translation <ref type="bibr">[1,</ref><ref type="bibr" target="#b53">54]</ref>. Place matches obtained through global descriptor matching are often re-ranked using sequential information <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b45">46]</ref>, query expansion <ref type="bibr" target="#b27">[28,</ref><ref type="bibr">13]</ref>, geometric verification <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b48">49]</ref> and feature fusion <ref type="bibr" target="#b79">[80,</ref><ref type="bibr" target="#b82">83]</ref>. Distinct from existing approaches, this paper introduces Patch-NetVLAD, which reverses the local-to-global process of image description by deriving multi-scale patch features from a global descriptor, NetVLAD.</p><p>Local Keypoint Descriptors: Local keypoint methods are often used to re-rank initial place match candidate lists produced by a global approach <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b57">58]</ref>. Traditional handcrafted local feature methods such as SIFT <ref type="bibr" target="#b40">[41]</ref>, SURF <ref type="bibr">[6]</ref> and ORB <ref type="bibr" target="#b56">[57]</ref>, and more recent deep-learned local features like LIFT <ref type="bibr" target="#b80">[81]</ref>, DeLF <ref type="bibr" target="#b48">[49]</ref>, SuperPoint <ref type="bibr">[18]</ref> and D2Net <ref type="bibr" target="#b19">[20]</ref>, have been extensively employed for VPR <ref type="bibr" target="#b48">[49,</ref><ref type="bibr">9,</ref><ref type="bibr">17]</ref>, visual SLAM <ref type="bibr" target="#b46">[47]</ref> and 6-DoF localization <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b57">58]</ref>. The two most common approaches of using local features for place recognition are: 1) local aggregation to obtain global image descriptors <ref type="bibr" target="#b48">[49]</ref> and 2) cross-matching of local descriptors between image pairs <ref type="bibr" target="#b70">[71]</ref>.</p><p>Several learning-based techniques have been proposed for spatially-precise keypoint matching. These include a unified framework for detection, description and orientation estimation <ref type="bibr" target="#b80">[81]</ref>; a 'describe-then-detect' strategy <ref type="bibr" target="#b19">[20]</ref>; multi-layer explicit supervision <ref type="bibr" target="#b20">[21]</ref>; scale-aware negative mining <ref type="bibr" target="#b64">[65]</ref>; and contextual similarity-based unsupervised training <ref type="bibr" target="#b65">[66]</ref>. However, the majority of these learning-based methods are optimized for 3D pose estimation, through robust description at a keypoint level to improve nearest neighbor matching performance against other keypoint-level descriptors. Local descriptors can be further improved by utilizing the larger spatial context, especially beyond the CNN's inherent hierarchical feature pyramid, a key motivation for our approach.</p><p>Local Region/Patch Descriptors: <ref type="bibr" target="#b68">[69]</ref> proposed Conv-Net Landmarks for representing and cross-matching large image regions, explicitly derived from Edge Boxes <ref type="bibr" target="#b87">[88]</ref>. <ref type="bibr">[12]</ref> discovered landmarks implicitly from CNN activations using mean activation energy of regions defined as '8-connected' feature locations. <ref type="bibr">[8]</ref> composed region features from CNN activation tensors by concatenating individual spatial elements along the channel dimension. However, these offthe-shelf CNNs or handcrafted region description <ref type="bibr" target="#b83">[84]</ref> approaches are not optimized for place recognition, unlike the use of the VPR-trained network in this work.</p><p>Learning region descriptors has been studied for specific tasks <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b43">44]</ref> as well as independently on image patches <ref type="bibr" target="#b66">[67]</ref>. In the context of VPR, <ref type="bibr" target="#b25">[26]</ref> designed a regions-based selfsupervised learning mechanism to improve global descriptors using image-to-region matching during training. <ref type="bibr" target="#b85">[86]</ref> modeled relations between regions by concatenating local descriptors to learn an improved global image descriptor based on K-Max pooling rather than sum <ref type="bibr">[4]</ref> or max pooling (R-MAC) <ref type="bibr" target="#b74">[75]</ref>. <ref type="bibr">[11]</ref> proposed a 'context-flexible' attention mechanism for variable-size regions. However, the learned attention masks were only employed for viewpoint-assumed place recognition and could potentially be used for region selection in our proposed VPR pipeline. <ref type="bibr" target="#b72">[73]</ref> proposed R-VLAD for describing regions extracted through a trained landmark detector, and combined it with selective match kernels to improve global descriptor matching, thus doing away with cross-region comparisons. <ref type="bibr" target="#b35">[36]</ref> proposed RegionVLAD where region features were defined using average activations of connected components within different layers of CNN feature maps. These region features were then separately aggregated as a VLAD representation. Unlike <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b72">73]</ref>, we remove this separate step by generating region-level VLAD descriptors through NetVLAD, thus reusing the VPR-relevant learned cluster membership of spatial elements.</p><p>Existing techniques for multi-scale approaches typically fuse information at the descriptor level, which can lead to loss of complementary or discriminative cues <ref type="bibr" target="#b79">[80,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr">10,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b86">87]</ref> due to pooling, or increased descriptor sizes due to concatenation <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr">7,</ref><ref type="bibr">8]</ref>. Distinct from these methods, we consider multi-scale fusion at the final scoring stage, which enables parallel processing with associated speed benefits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Patch-NetVLAD ultimately produces a similarity score between a pair of images, measuring the spatial and appearance consistency between these images. Our hierarchical approach first uses the original NetVLAD descriptors to retrieve the top-k (we use k = 100 in our experiments) most likely matches given a query image. We then compute a new type of patch descriptor using an alternative to the VLAD layer used in NetVLAD <ref type="bibr">[3]</ref>, and perform local matching of patch-level descriptors to reorder the initial match list and refine the final image retrievals. This combined approach minimizes the additional overall computation cost incurred by cross matching patch features without sacrificing recall performance at the final image retrieval stage. An overview of the complete pipeline can be found in <ref type="figure" target="#fig_4">Fig. 2</ref>.  <ref type="figure" target="#fig_4">Figure 2</ref>. Proposed Algorithm Schematic. Patch-NetVLAD takes as input an initial list of most likely reference matches to a query image, ranked using NetVLAD descriptor comparisons. For topranked candidate images, we compute new locally-global patchlevel descriptors at multiple scales, perform local cross-matching of these descriptors across query and candidate images with geometric verification, and use these match scores to re-order the initial list, producing the final image retrievals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Original NetVLAD Architecture</head><p>The original NetVLAD <ref type="bibr">[3]</ref> network architecture uses the Vector-of-Locally-Aggregated-Descriptors (VLAD) approach to generate a condition and viewpoint invariant embedding of an image by aggregating the intermediate feature maps extracted from a pre-trained Convolutional Neural Network (CNN) used for image classification <ref type="bibr" target="#b62">[63]</ref>. Specifically, let f ? : I ? R H?W ?D be the base architecture which given an image I, outputs a H ? W ? D dimensional feature map F (e.g. the conv5 layer for VGG). The original NetVLAD architecture aggregates these D-dimensional features into a K ? D-dimensional matrix by summing the residuals between each feature x i ? R D and K learned cluster centers weighted by soft-assignment. Formally, for N ? D-dimensional features, let the VLAD aggregation layer f VLAD : R N ?D ? R K?D be given by</p><formula xml:id="formula_0">f VLAD (F )(j, k) = N i=1? k (x i )(x i (j) ? c k (j))<label>(1)</label></formula><p>where x i (j) is the j th element of the i th descriptor,? k is the soft-assignment function and c k denotes the k th cluster center. After VLAD aggregation, the resultant matrix is then projected down into a dimensionality reduced vector using a projection layer f proj : R K?D ? R Dproj by first applying intra(column)-wise normalization, unrolling into a single vector, L2-normalizing in its entirety and finally applying PCA (learned on a training set) with whitening and L2-normalization. Refer to <ref type="bibr">[3]</ref> for more details.</p><p>We use this feature-map aggregation method to extract descriptors for local patches within the whole feature map (N H ?W ) and perform cross-matching of these patches at multiple scales between a query/reference image pair to generate the final similarity score used for image retrieval. This is in contrast to the original NetVLAD paper, which sets N = H ? W and aggregates all of the descriptors within the feature map to generate a global image descriptor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Patch-level Global Features</head><p>A core component of our system revolves around extracting global descriptors for densely sampled sub-regions (in the form of patches) within the full feature map. We extract a set of</p><formula xml:id="formula_1">d x ? d y patches {P i , x i , y i } np i=1</formula><p>with stride s p from the feature map F ? R H?W ?D , where the total number of patches is given by</p><formula xml:id="formula_2">n p = H ? d y s p + 1 * W ? d x s p + 1 , d y , d x ? H, W</formula><p>(2) and P i ? R (dx?dy)?D and x i , y i are the set of patch features and the coordinate of the center of the patch within the feature map, respectively. While our experiments suggest that square patches yielded the best generalized performance across a wide range of environments, future work could consider different patch shapes, especially in specific circumstances (e.g. environments with different texture frequencies in the vertical and horizontal directions).</p><p>For each patch, we subsequently extract a descriptor yielding the patch descriptor set</p><formula xml:id="formula_3">{f i } np i=1</formula><p>where f i = f proj (f VLAD (P i )) ? R Dproj uses the NetVLAD aggregation and projection layer on the relevant set of patch features. In all experiments we show how varying the degree of dimensionality reduction on the patch features using PCA can be used to achieve a user-preferred balance of computation time and image retrieval performance (see Section 4.5). We can further improve place recognition performance by extracting patches at multiple scales and observe that using a combination of patch sizes which represent larger sub-regions within the original image improves retrieval (see Section 3.5). This multi-scale fusion is made computationally efficient using our IntegralVLAD formulation introduced in Section 3.6.</p><p>Compared to local feature-based matching where features are extracted for comparatively small regions within the image, our patch features implicitly contain semantic information about the scene (e.g., building, window, tree) by covering a larger area. We now introduce the remaining parts of our pipeline, which is comprised of mutual nearest neighbor matching of patch descriptors followed by spatial scoring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Mutual Nearest Neighbours</head><p>Given a set of reference and query features {f</p><formula xml:id="formula_4">r i } np i=1 and {f q i } np i=1</formula><p>, (we assume both images have the same resolu-tion for simplicity), we obtain descriptor pairs from mutual nearest neighbor matches through exhaustive comparison between the two descriptor sets. Formally, let the set of mutual nearest neighbor matches be given by P, where</p><formula xml:id="formula_5">P = (i, j): i = NN r (f q j ), j = NN q (f r i ) (3)</formula><p>and NN q (f ) = argmin j f ? f q j 2 and NN r (f ) = argmin j f ? f r j 2 retrieve the nearest neighbor descriptor match with respect to Euclidean distance within the query and reference image set, respectively. Given a set of matching patches, we can now compute the spatial matching score used for image retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Spatial Scoring</head><p>We now introduce our spatial scoring methods which yield an image similarity score between a query/reference image pair used for image retrieval. We present two alternatives, a RANSAC-based scoring method which requires more computation time for higher retrieval performance and a spatial scoring method which is substantially faster to compute at the slight expense of image retrieval performance.</p><p>RANSAC Scoring: Our spatial consistency score is given by the number of inliers returned when fitting a homography between the two images, using corresponding patches computed using our mutual nearest neighbor matching step for patch features. We assume each patch corresponds to a 2D image point with coordinates in the center of the patch when fitting the homography. We set the error tolerance for the definition of an inlier to be the stride s p . We also normalize our consistency score by the number of patches, which is relevant when combining the spatial score at multiple scales as discussed in Section 3.5.</p><p>Rapid Spatial Scoring: We also propose an alternative to the RANSAC scoring approach which we call rapid spatial scoring. This rapid spatial scoring significantly reduces computation time as we can compute this score directly on the matched feature pairs without requiring sampling.</p><p>To compute the rapid spatial score, let</p><formula xml:id="formula_6">x d = {x r i ? x q j } (i,j)</formula><p>?P be the set of displacements in the horizontal direction between patch locations for the matched patches, and y d be the displacements in the vertical direction. In addition,</p><formula xml:id="formula_7">letx d = 1 |x d | x d,i ?x d x d,i</formula><p>and similarly? d be the mean displacements between matched patch locations. We can then define our spatial score (higher is better) to be</p><formula xml:id="formula_8">s spatial = 1 n p i?P | max j?P x d,j | ? |x d,i ?x d |) 2 + | max j?P y d,j | ? |y d,i ?? d | 2 ,<label>(4)</label></formula><p>where the score comprises the sum of residual displacements from the mean, with respect to the maximum possible spatial offset. The spatial score penalizes large spatial offsets in matched patch locations from the mean offset, in effect measuring the coherency in the overall movement of elements in a scene under viewpoint change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Multiple Patch Sizes</head><p>We can easily extend our scoring formulation to ensemble patches at multiple scales and further improve performance. For n s different patch sizes, we can take a convex combination of the spatial matching scores for each patch size as our final matching score. Specifically,</p><formula xml:id="formula_9">s spatial = ns i=1 w i s i,spatial ,<label>(5)</label></formula><p>where s i,spatial is the spatial score for the i th patch size and</p><formula xml:id="formula_10">i w i = 1, w i ? 0 for all i.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">IntegralVLAD</head><p>To assist the computation of extracting patch descriptors at multiple scales, we propose a novel IntegralVLAD formulation analogous to integral images <ref type="bibr">[15]</ref>. To see this, note that the aggregated VLAD descriptor (before the projection layer) for a patch can be computed as the sum of all 1?1 patch descriptors each corresponding to a single feature within the patch. This allows us to pre-compute an integral patch feature map which can then be used to compute patch descriptors for multi-scale fusion. Let the integral feature map I be given by</p><formula xml:id="formula_11">I(i, j) = i &lt;i,j &lt;j f 1 i ,j ,<label>(6)</label></formula><p>where f 1 i ,j represents the VLAD aggregated patch descriptor (before projection) for a patch size of 1 at spatial index i , j in the feature space. We can now recover the patch features for arbitrary scales using the usual approach involving arithmetic over four references within the integral feature map. This is implemented in practice through 2D depth-wise dilated convolutions with kernel K, where</p><formula xml:id="formula_12">K = 1 ?1 ?1 1<label>(7)</label></formula><p>and the dilation is equal to the required patch size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation</head><p>We implemented Patch-NetVLAD in PyTorch and resize all images to 640 by 480 pixels before extracting our patch features. We train the underlying vanilla NetVLAD feature extractor <ref type="bibr">[3]</ref> on two datasets: Pittsburgh 30k <ref type="bibr" target="#b76">[77]</ref> for urban imagery (Pittsburgh and Tokyo datasets), and Mapillary Street Level Sequences <ref type="bibr" target="#b78">[79]</ref> for all other conditions. All hyperparameters for training are the same as in <ref type="bibr">[3]</ref>, except for the Mapillary trained model for which we reduced the number of clusters from 64 to 16 for faster training due to the large dataset size.</p><p>To find the patch sizes and associated weights, we perform a grid search to find the model configuration that performs best on the RobotCar Seasons v2 training set. This resulted in patch size d x = d y = 5 (which equates to an 228 by 228 pixel area in the original image) with stride sp = 1 when a single patch size is used, and square patch sizes 2, 5 and 8 with associated weights w i = 0.45, 0.15, 0.4 for the multi-scale fusion. We emphasize that this single configuration is used for all experiments across all datasets. While the results will indicate that the proposed system configuration would on average outperform all other methods in a wide range of deployment domains, it is likely that if a highly specialized system was required, further performance increases could be achieved by fine-tuning patch sizes and associated weights for the specific environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Datasets</head><p>To evaluate Patch-NetVLAD, we used six of the key benchmark datasets: Nordland <ref type="bibr" target="#b67">[68]</ref>, Pittsburgh <ref type="bibr" target="#b76">[77]</ref>, Tokyo24/7 <ref type="bibr" target="#b75">[76]</ref>, Mapillary Streets <ref type="bibr" target="#b78">[79]</ref>, RobotCar Seasons v2 <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b73">74]</ref> and Extended CMU Seasons <ref type="bibr">[5,</ref><ref type="bibr" target="#b73">74]</ref>. Full technical details of their usage are provided in the Supplementary Material; here we provide an overview to facilitate an informed appraisal of the results. Datasets were used in their recommended configuration for benchmarking, including standardized curation (e.g. removal of pitch black tunnels and times when the train is stopped for the Nordland dataset <ref type="bibr">[8,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b29">30]</ref>) and use of public validation and withheld test sets where provided (e.g. Mapillary).</p><p>Collectively the datasets encompass a challenging range of viewpoint and appearance change conditions, partly as a result of significant variations in the acquisition method, including train, car, smartphone and general crowdsourcing. Specific appearance changes are caused by different times of day: dawn, dusk, night; by varying weather: sun, overcast, rain, and snow; and by seasonal change: from summer to winter. Nordland, RobotCar, Extended CMU Seasons and Tokyo 24/7 contain varying degrees of appearance change up to very severe day-night and seasonal changes. The Pittsburgh dataset contains both appearance and viewpoint change, while the MSLS dataset <ref type="bibr" target="#b78">[79]</ref> in particular includes simultaneous variations in all of the following: geographical diversity (30 major cities across the globe), season, time of day, date (over 7 years), viewpoint, and weather. In total, we evaluate our systems on ?300,000 images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation</head><p>All datasets except for RobotCar Seasons v2 and Extended CMU Seasons are evaluated using the Recall@N  <ref type="figure">Figure 3</ref>. Comparison with state-of-the-art.</p><p>We show the Recall@N performance of Ours (Multi-RANSAC-Patch-NetVLAD) compared to AP-GEM <ref type="bibr" target="#b55">[56]</ref>, DenseVLAD <ref type="bibr" target="#b75">[76]</ref>, Net-VLAD <ref type="bibr">[3]</ref> and SuperGlue <ref type="bibr" target="#b58">[59]</ref>, on the Mapillary validation set. metric, whereby a query image is correctly localized if at least one of the top N images is within the ground truth tolerance <ref type="bibr">[3,</ref><ref type="bibr" target="#b75">76]</ref>. The recall is then the percentage of correctly localized query images, and plots are created by varying N .</p><p>We deem a query to be correctly localized within the standard ground-truth tolerances for all datasets, i.e. 10 frames for Nordland <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>, 25m translational error for Pittsburgh and Tokyo 24/7 <ref type="bibr">[3]</ref>, and 25m translational and 40 ? orientation error for Mapillary <ref type="bibr" target="#b78">[79]</ref>.</p><p>For RobotCar Seasons v2 and Extended CMU Seasons, we use the default error tolerances <ref type="bibr" target="#b73">[74]</ref>, namely translational errors of .25, .5 and 5.0 meters and corresponding rotational errors of 2, 5 and 10 degrees. Note that our method is a place recognition system and does not perform explicit 6-DOF pose estimation; the pose estimate for a query image is given by inheriting the pose of the best matched reference image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Comparison to State-of-the-art Methods</head><p>We compare against several benchmark localization solutions: AP-GEM <ref type="bibr" target="#b55">[56]</ref>, DenseVLAD <ref type="bibr" target="#b75">[76]</ref>, NetVLAD <ref type="bibr">[3]</ref>, and SuperGlue <ref type="bibr" target="#b58">[59]</ref>. In the recently proposed AP-GEM, the Average Precision is directly optimized via Generalized Mean pooling and a listwise loss. The key idea behind Dense-VLAD is to densely sample SIFT features across the image at four different scales, and then aggregate the SIFT features using intra-normalized VLAD.</p><p>Finally, we propose an optimistic baseline that utilizes Su-perGlue [59] as a VPR system. SuperGlue elegantly matches features extracted with SuperPoint <ref type="bibr">[18]</ref> using a graph neural network that solves an assignment optimization problem. While originally proposed for homography and pose estimation, our proposed SuperGlue VPR baseline achieves what would have been state-of-the-art performance second to Patch-NetVLAD. As in Patch-NetVLAD, we provide Su-perGlue with the same k = 100 candidate images extracted using vanilla NetVLAD, and re-rank the candidates by the number of inlier matches. <ref type="table" target="#tab_0">Table 1</ref> and <ref type="figure">Fig. 3</ref> contain quantitative comparisons of Patch-NetVLAD and the baseline methods. Patch-NetVLAD outperforms the best performing global descriptor methods, NetVLAD, DenseVLAD, and AP-GEM, on average by 17.5%, 14.8%, and 22.3% (all percentages stated are absolute differences for R@1) respectively. The differences are particularly pronounced in datasets with large appearance variations, i.e. Nordland and Extended CMU Seasons (both seasonal changes), Tokyo 24/7 (including images captured at night time) and RobotCar Seasons as well as Mapillary (both seasonal changes and night time imagery). On the Nordland dataset, the difference between Patch-NetVLAD and the original NetVLAD is 34.5%.</p><p>A similar trend can be seen when comparing Patch-NetVLAD with SuperGlue. Patch-NetVLAD performs on average 3.1% better (a relative increase of 6.0%), which demonstrates that Patch-NetVLAD outperforms a system that benefits from both learned local feature descriptors and a learned feature matcher. We hypothesize that Patch-NetVLAD's performance could further benefit from Super-Glue's learned matcher and discuss this opportunity further in Section 5. SuperGlue is a landmark system and our approach does not beat it in every case, with SuperGlue edging slightly ahead on R@1 and R@5 on Tokyo 24/7 and on R@5 and R@10 on Pittsburgh. Patch-NetVLAD's performance edge is particularly significant when large appearance variations are encountered in unseen environments -not typically used for training local feature methods like Super-Glue (or underlying Superpoint). Thus, Patch-NetVLAD achieves superior performance on Nordland with an absolute percentage difference of 15.8%. Interestingly, the perfor-mance difference between Patch-NetVLAD and SuperGlue increases with increasing N -from 1.1% for R@1 to 5.1% for R@25 on the Mapillary dataset ( <ref type="figure">Fig. 3)</ref>.</p><p>Patch-NetVLAD won the Mapillary Challenge at the ECCV2020 workshops (not yet publicly announced to comply with CVPR's double-blind policy), with <ref type="table" target="#tab_0">Table 1</ref> showing that Patch-NetVLAD outperformed the baseline method, NetVLAD, by 13.0% (absolute R@1 increase) on the withheld test dataset. The test set was more challenging than the validation set (48.1% R@1 and 79.% R@1 respectively; note that no fine-tuning was performed on any of the datasets), indicating that the Mapillary test set is a good benchmarking target for further research compared to "near-solved" datasets like Pittsburgh and Tokyo 24/7, where both Patch-NetVLAD and SuperGlue achieve near perfect performance.</p><p>In <ref type="figure" target="#fig_2">Fig. 5</ref> we show a set of examples images, illustrating the matches retrieved with our method compared to Net-VLAD and SuperGlue, along with the patch matches that our algorithm detects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Ablation Studies</head><p>Single-scale and Spatial Scoring: To analyze the effectiveness of Patch-NetVLAD, we compare with the following variations: 1) Single-RANSAC-Patch-NetVLAD uses a single patch size (i.e. 5) instead of multi-scale fusion. 2) Single-Spatial-Patch-NetVLAD employs a simple but rapid spatial verification method applied to a single patch size (see Section 3.4). 3) Multi-Spatial-Patch-NetVLAD uses the same rapid spatial verification method, however applied to three patch sizes rather than a single patch size as in the previous variant.</p><p>The comparison results with these three variations are shown in <ref type="table" target="#tab_3">Table 2</ref>. The following numeric results are based on R@1 (recall@1) -the conclusions generally apply to R@5 and R@10 as well. Our proposed multi-fusion approach (Multi-RANSAC-Patch-NetVLAD) performs on average 2.0% better than Single-RANSAC-Patch-NetVLAD, demonstrating that a fusion of multiple patch sizes significantly improves task performance. Our approach also provides some compelling options for compute-constrained applications; our rapid spatial verification approach is 2.9 times faster on a single patch size (Single-Spatial-Patch-NetVLAD), with only a 0.6% performance reduction. Rapid spatial verification applied to multiple patch sizes (Multi-Spatial-Patch-NetVLAD) is 3.1 times faster, with only a 1.1% performance degradation.</p><p>Patch Descriptor Dimension: In addition to disabling multi-scale fusion and using our rapid spatial scoring method, the descriptor dimension can be arbitrarily reduced using PCA (as with the original NetVLAD). Here, we choose D PCA = {128, 512, 2048, 4096}. <ref type="figure">Fig. 4</ref> shows the number of queries that can be processed per second by various con- Recall @1 (%)</p><p>Single-Spatial-Patch-NetVLAD (dim=128)</p><p>Single-Spatial-Patch-NetVLAD (dim=512)</p><p>Single-Spatial-Patch-NetVLAD (dim=2048)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Single-RANSAC-Patch-NetVLAD (dim=2048)</head><p>Multi-RANSAC-Patch-NetVLAD (dim=2048)</p><p>Multi-RANSAC-Patch-NetVLAD (dim=4096) SuperGlue (dim=256) <ref type="figure">Figure 4</ref>. Computational time requirements. The time taken to process one query image is shown on the x-axis, with the resulting R@1 shown on the y-axis, for the Mapillary dataset. Our pipeline enables a range of system configurations that achieve different performance and computational balances that either outperform or are far faster than current state-of-the-art.</p><p>figurations 1 , and the resulting R@1 on the Mapillary validation set. Our proposed Multi-RANSAC-Patch-NetVLAD in a performance-focused configuration (red star in <ref type="figure">Fig. 4</ref>) achieves 1.1% higher recall than SuperGlue (yellow dot) while being slightly (3%) faster. A balanced configuration (orange triangle) is more than 3 times faster than SuperGlue with comparable performance, while a speed-oriented configuration (blue triangle) is 15 times faster at the expense of just 0.6% and 1.7% recall when compared to SuperGlue and our performance-focused configuration respectively. A storage-focused configuration (D PCA = 128) still largely outperforms NetVLAD while having similar memory requirements as a SIFT-like descriptor. Our speed-oriented and storage-focused configurations provide practical options for applications like time-critical robotics. Our approach can also run on consumer GPUs, with our performance configuration requiring 7GB GPU memory (batch-size of 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Further analysis</head><p>We further study the robustness of our approach to the choice of hyperparameters. In <ref type="figure">Fig. 6</ref> (left) we highlight that Single-Patch-NetVLAD is robust to the choice of the patch size d p : The performance gradually decays from a peak at d p = 4. <ref type="figure">Fig. 6</ref> (right) similarly shows that Patch-NetVLAD is robust to the convex combination of the multi-patch fusion in terms of the patch sizes that are fused. The Supplementary Material provides additional ablation studies, including matching across different patch sizes, complementarity of patch sizes and comparison to other pooling strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion and Conclusion</head><p>In this work we have proposed a novel locally-global feature descriptor, which uses global descriptor techniques to further improve the appearance robustness of local descriptors. Unlike prior keypoint-based local feature descriptors <ref type="bibr" target="#b40">[41,</ref><ref type="bibr">18]</ref>, our approach considers all the visual content Recall @N (%) <ref type="bibr">10 15 20</ref> Sum of patch sizes Total patch size R@1 R@5 R@10 <ref type="figure">Figure 6</ref>. Robustness studies for single patch sizes and combined patch sizes. Left: Recall performance of Single-Patch-NetVLAD with varying patch size, using the Mapillary validation dataset. Performance gradually degrades around a peak at dp = 4. The smallest and largest patch sizes perform most poorly, indicating that both local features and global areas are inferior to intermediate size features. An additional issue with large patch sizes is that there are too few patches for effective spatial verification. Right: Recall performance of Multi-Patch-NetVLAD against an indicative measure of cumulative patch dimensions. Our proposed combination of patch dimensions 2, 5 and 8 corresponds to an x-axis value of 15; data points to the left show a reduction in the cumulative patch dimension (e.g. i dp,i = 14 for patch sizes 1, 5 and 8; sizes 2, 4 and 8; and sizes 2, 5 and 7) and so forth; and similarly for increasing patch size combinations to the right. As for variations on the single patch size, performance gracefully degrades around the peak and remains high over a large range.</p><p>within a larger patch of the image, using techniques that facilitate further performance improvements through an efficient multi-scale fusion of patches. Our proposed Patch-NetVLAD's average performance across key benchmarks is superior by 17.5% over the original NetVLAD, and by 3.1% (absolute recall increase) over the state-of-the-art Su-perPoint and SuperGlue-enabled VPR pipeline. Our experiments reveal an inherent benefit to fusing multiple patch sizes simultaneously, where the fused recall is greater than any single patch size recall, and provide a means by which to do so with minimal computational penalty compared to single scale techniques.</p><p>While this demonstration of Patch-NetVLAD occurred in a place recognition context, further applications and extensions are possible. One avenue for future work is the following: while we match Patch-NetVLAD features using mutual nearest neighbors with subsequent spatial verification using RANSAC, recent deep learned matchers <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b84">85]</ref> could further improve the global re-localization performance of the algorithm. Although our method is by no means biologically inspired, it is worth noting that the brain processes visual information over multiple receptive fields <ref type="bibr" target="#b32">[33]</ref>. As a result, another potentially promising direction for future research is to explore and draw inspiration from how the task of visual place recognition, rather than the more commonly studied object or face recognition tasks, is achieved in the brain. Finally, another line of work could consider the correlation between the learned VLAD clustering and semantic classes (e.g. car, pedestrian, building), in order to identify and remove patches that contain dynamic objects. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview</head><p>The Supplementary Material is structured as follows. In Section 1, we show results obtained on the RobotCar Seasons v2 and Extended CMU Seasons datasets split by query condition. Section 2 contains additional quantitative results on the Pittsburgh 30k and Tokyo 24/7 datasets, as well as additional results on the computation time split across the feature extraction and feature matching processes. Section 3 contains a variety of additional ablation studies, some of them further demonstrating the robustness of our method, while others detail experiments that might logically be expected and were conducted, but that were not fruitful. Section 4 contains various qualitative results, showcasing both challenging success cases of Patch-NetVLAD and some failure cases. This section also contains examples of incorrect dataset annotations, where Patch-NetVLAD actually found the correct match but this match was not within the ground-truth matches due to errors in the ground-truth. Finally, in Section 5 we describe in detail the six key benchmark datasets on which we evaluate Patch-NetVLAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Results Split by Condition on RobotCar Seasons v2 and Extended CMU Seasons</head><p>RobotCar Seasons v2: Suppl. <ref type="table" target="#tab_0">Table 1</ref> contains results obtained on the RobotCar Seasons v2 dataset split by query condition. The results for RobotCar Seasons v2 stated in <ref type="table" target="#tab_0">Tables 1 and 2</ref> of the main paper are summary statistics, where the different conditions are weighted by the number of images contained within each condition.</p><p>Patch-NetVLAD outperforms SuperGlue [11] by 1.3% absolute recall on the tightest error thresholds (.25m translational error and 2 degrees orientation error) when considering the summary statistic. There are some conditions where SuperGlue has a slight performance advantage for the looser error thresholds, in particular the night traverses. As stated in the Conclusions section of the main paper, it would be interesting to train a neural network-based feature matcher similar to SuperGlue that uses our proposed Patch-NetVLAD features instead of the original SuperPoint <ref type="bibr">[5]</ref> features. This approach would likely yield more robust matching than a standard mutual nearest neighbors matching technique, which combined with outlier rejection will likely yield a significant performance improvement.</p><p>Extended CMU Seasons: In Suppl. <ref type="table" target="#tab_3">Table 2</ref> we similarly show detailed results for the Extended CMU Seasons dataset, split by Urban, Suburban and Park environments. Patch-NetVLAD consistently outperforms all comparison methods, including our competitive SuperGlue baseline, on all conditions and all error thresholds by relatively large margins, with a single exception being the park condition where SuperGlue performs slightly better for the largest error threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Additional Quantitative Results</head><p>Additional Recall Plots: <ref type="figure">Fig. 3</ref> in the main paper shows the recall@N performance on the Mapillary validation set. Similarly, Suppl. <ref type="figure">Fig. 1</ref> shows the recall@N performance for the Pittsburgh 30k and Tokyo 24/7 datasets.</p><p>Computational Time Requirements: <ref type="figure">Fig. 4</ref> of the main paper shows the number of seconds required to process each query by a variety of our system configurations, as well as SuperGlue. The processing times presented in <ref type="figure">Fig. 4</ref> of the main paper show the accumulated times of feature extraction and feature matching. In Suppl. <ref type="figure" target="#fig_4">Fig. 2</ref> we show the compute times split into feature extraction time only and feature matching time only; as well as the accumulated time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Further Ablation Studies</head><p>Ablation of Multi-Scale Fusion Weights and Patch Sizes: In <ref type="figure">Fig. 6</ref> of the main paper, we demonstrated that Patch-NetVLAD is robust to the choice of particular </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall@N (%)</head><p>Ours AP-GEM DenseVLAD NetVLAD SuperGlue <ref type="figure">Supplementary Figure 1</ref>. Comparison with state-of-the-art. We show the Recall@N performance of Ours (Multi-RANSAC-Patch-NetVLAD) compared to AP-GEM <ref type="bibr">[10]</ref>, DenseVLAD <ref type="bibr">[16]</ref>, NetVLAD <ref type="bibr">[1]</ref> and SuperGlue <ref type="bibr">[11]</ref>, on the Pittsburgh (left) and Tokyo 24/7 (right) datasets.  patch sizes that are fused in our multi-scale approach. In Suppl. <ref type="table">Table 3</ref>, we further validate that our proposed multiscale fusion of spatial scores across several patch sizes is robust to changes in patch size and weightings by presenting results for the Mapillary dataset. Note that, as stated in the main paper, the set of weights used across all experi-ments and all datasets was determined using a grid-search on the training set of the RobotCar Seasons v2 dataset.</p><p>While we fuse three patch sizes in the main paper, our method is not constrained to fusing any particular number of patch sizes. An investigation regarding this is shown in Suppl. <ref type="table">Table 4</ref> -there all patch sizes are fused with equal weights for simplicity. An interesting observation is that increasing the number of different patch sizes used (from three up to five) does not improve the recall performance beyond the best combination of three patch sizes. We can infer that the span of patch sizes (the difference between the smallest size and the largest size) is more important than the number of patch sizes used.</p><p>Early Match Fusion: In Section 3.5 of the main paper, we describe our multi-scale fusion approach that merges the spatial scores obtained from different patch sizes. An alter- <ref type="table">Supplementary Table 3</ref> native to this post-processing fusion is an early fusion where mutual nearest neighbors (Section 3.3 of the main paper) are found across patches of different scales, and a joint spatial score is calculated from all these mutual nearest neighbors. However, we found that this early fusion approach does not work as well as the proposed post-processing fusion. Specifically, on the Mapillary validation set, we find that the early fusion results in R@1: 77.2%, R@5: 85.3%, and R@10: 87.3%. This compares to R@1: 79.5%, R@5: 86.2% and R@10: 87.7% using our proposed postprocessing fusion.</p><p>Other Pooling Strategies: We use NetVLAD pooling to aggregate patch features into a single patch descriptor in our proposed approach. Instead of NetVLAD pooling, other pooling strategies such as max-pooling <ref type="bibr">[15]</ref> and sumpooling <ref type="bibr">[2]</ref> have been proposed in the literature. Our spatial scoring system based on patch-based matching is in principle applicable with alternative pooling strategies. However, we found that patch-based aggregation does not perform well when applied to these pooling strategies: patchlevel average pooling of VGG's Conv-5 layer (all else being equal) improves performance from 60.8% R@1 (vanilla NetVLAD on Mapillary dataset) to 73.6%, which compares to 79.5% using patch-level VLAD pooling (Patch-NetVLAD). Patch-level max-pooling similarly leads to decreased performance when compared to Patch-NetVLAD (R@1: 74.5%). In summary, our Patch-NetVLAD description significantly outperforms those alternative pooling strategies. Further investigation will be required to gain a deeper understanding of the complementary nature of the underlying pooling strategies and our proposed patch-based aggregation.</p><p>Patch Crops in the Image Space Instead of Feature Space: In Patch-NetVLAD, pooling is performed from a set of patches in the feature space of an image. One could instead perform forward passes on patch-crops in the image space. The main problem with this approach is that processing overlapping patches is prohibitive in terms of compute and storage (as each patch needs to be separately passed through VGG). However, overlapping patches are crucial for achieving high task performance -we found that overlapping patches are key to achieving viewpoint invariance. Therefore, performing forward passes on patch-crops in the image space is not a viable alternative to our proposed pooling of patches in the feature space.</p><p>Matching Across Different Patch Sizes: In the proposed method we match patches with other patches of the same size, but there is the possibility to match between patches of different sizes. For instance, a patch of size 2x2 could find a nearest neighbor match to a patch of size 5x5. Experiments revealed that such a cross-patch-size matching leads to sub-optimal performance: R@1 reduces from 79.5% to 78.1%. In future works, we would like to explore other matching strategies such as a coarse-to-fine matching scheme. We would also note that, conceptually, images of different zoom levels should not be matched, as they could have been taken from different places.</p><p>Complementarity of Patch Sizes: Suppl. <ref type="figure">Fig. 3</ref> shows examples of correspondences split by patch size. We randomly sampled 10 correspondences per patch size and indicate the area covered by each patch. We include examples where small/medium/large patch sizes (i.e. d p = {2, 5, 8}) result in particularly good matches, as well as one example (the bottom row) where all patch sizes work well for the same image pair but in distinct areas of the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Additional Qualitative Results</head><p>Suppl. Figs. 4, 5, 6 and 7 contain additional qualitative results on the Mapillary, Nordland, Pittsburgh and Tokyo 24/7 datasets respectively. For all these results, correct matches are represented with green borders, and incorrect matches with red borders. We show success cases of Patch-NetVLAD where all other methods failed to retrieve a correct match. Besides success cases, we also include failure cases where our proposed competitive SuperGlue baseline finds the correct match, but Patch-NetVLAD does not localize correctly. Many of these matches are challenging to recognize as the same place, even for a human observer.</p><p>These match example visualizations lead to interesting observations. For example, in <ref type="figure">Fig. 6</ref> on the Pittsburgh dataset, we note that a large proportion of cases where Patch-NetVLAD succeeds and Superglue fails are for images containing a large proportion of sky. We notice that SuperGlue is attempting to find correspondences between points corresponding to clouds in these images. Patch-Patch size = 2 Patch size = 5</p><p>Patch size = 8</p><p>Supplementary <ref type="figure">Figure 3</ref>. Complementarity of Patch Sizes. The three columns indicate different patch sizes, from small (i.e. dp = 2) over medium (i.e. dp = 5) to large (i.e. dp = 8). It can be observed that a small patch size is able to find matches where smaller spatial context is more intuitive, for example, near boundaries between sky and buildings (first row, left column) or between sky and power lines (third row, left column). On the other hand, a larger patch size provides complementary cues by spanning over large building surfaces, enabling matching despite significant illumination variations (second row, right column). Note that the size of the squares does not reflect the receptive field sizes of the underlying features; different sizes are used for visualization purposes only.</p><p>NetVLAD, on the other hand, uses larger patch-level features which typically include clouds and a ground level feature. Suppl. Finally, Suppl. <ref type="figure" target="#fig_7">Fig. 9</ref> provides some examples of the Pittsburgh and Mapillary datasets where a manual inspection of Patch-NetVLAD's failure cases has shown that Patch-NetVLAD actually found a correct place match, which indicates that either the error tolerances are too tight, or that some ground-truth locations are incorrectly annotated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Detailed Dataset Description</head><p>In this Section, we further detail the datasets that were introduced in Section 4.2 of the main paper. To recap, we evaluate Patch-NetVLAD on six of the key benchmark datasets: Nordland <ref type="bibr">[12]</ref>, Pittsburgh <ref type="bibr">[17]</ref>, Tokyo24/7 <ref type="bibr">[16]</ref>, Mapillary Streets <ref type="bibr">[18]</ref>, Oxford Seasons v2 <ref type="bibr">[8,</ref><ref type="bibr">14]</ref> and Extended CMU Seasons <ref type="bibr">[3,</ref><ref type="bibr">14]</ref>. Collectively the datasets en-compass a wide and challenging range of viewpoint change, appearance change and acqusition methods.</p><p>Nordland: The Nordland dataset <ref type="bibr">[12]</ref> is recorded from a train traveling 728km through Norway in four different seasons. The four recordings are aligned frame-by-frame using available GPS information. We use the summer and winter traverses as the reference and query sets respectively, as these traverses have the highest appearance dissimilarity and are typically considered in the literature <ref type="bibr">[4,</ref><ref type="bibr">9,</ref><ref type="bibr">7,</ref><ref type="bibr">6]</ref>. As in <ref type="bibr">[12]</ref>, we use the entire 728km traverse and subsample the video at 1 fps. Like previous works using this dataset <ref type="bibr">[4,</ref><ref type="bibr">13,</ref><ref type="bibr">7,</ref><ref type="bibr">6]</ref>, we remove all tunnels and times when the train is stopped, which resulted in 27,592 images for both reference and query sets.</p><p>RobotCar Seasons v2: The RobotCar dataset <ref type="bibr">[8]</ref> is a collection of traverses through Oxford, recorded with an autonomous car across multiple times of day and seasons. RobotCar Seasons v2 <ref type="bibr">[14]</ref> is a standardized benchmark subset of the RobotCar dataset, where the reference images are recorded in overcast conditions, and the query images are captured at a variety of times and conditions: dawn, dusk, sun, rain, overcast summer, overcast winter, snow, night and night-rain. Similarly to Nordland, RobotCar Seasons v2 mainly captures appearance changes, while viewpoint changes are relatively minor. An important detail of the structure of the RobotCar Seasons v2 dataset is that the reference images of the original RobotCar Seasons v2 dataset is split into 49 disjoint submaps which comprise the full traverse. Query images are captured from 17 of these submaps for all conditions and furthermore, for each query image the identity of the corresponding submap is provided. For our evaluation, we merge all 49 submaps for the reference traverse and localize each query image against the whole merged reference traverse without using the given submap identity provided with the dataset. This presents a substantially more challenging image retrieval task which showcases the difference between our proposed method and alternative approaches.</p><p>Extended CMU Seasons: CMU Seasons <ref type="bibr">[3]</ref> is similar to the RobotCar dataset: a car was driven around an 8.8km long route in Pittsburgh covering urban, residential, and park-like settings. Extended CMU Seasons <ref type="bibr">[14]</ref> is a subset of the original CMU Seasons dataset that has been standardized for benchmark purposes. Extended CMU Sea-sons covers a single reference set and multiple query traverses under varying seasonal conditions spanning a oneyear time frame. Unlike the RobotCar Seasons, CMU does not contain images that were captured at nighttime.</p><p>Pittsburgh: The Pittsburgh dataset <ref type="bibr">[17]</ref> contains 250k images collected via Google Street View. The reference and query images are captured at different times of the day and several years apart. For each place, 24 perspective images (two pitch and twelve yaw directions) are generated, which leads to high variations in both viewpoints and appearance. We use the Pitts 30k subset as described in <ref type="bibr">[1]</ref>, which contains 10k reference images and 6816 query images.</p><p>Tokyo 24/7: The Tokyo 24/7 dataset <ref type="bibr">[16]</ref> contains images at 125 distinct locations captured with smartphones at three different viewing directions and at three different times of the day. Contrary to the Nordland and Pittsburgh datasets, Tokyo 24/7 includes nighttime images.</p><p>Mapillary Street Level Sequences (MSLS): The MSLS dataset <ref type="bibr">[18]</ref> has recently been introduced with the aim of facilitating lifelong place recognition research. It contains over 1.6 million images recorded in 30 major cities across the globe in urban and suburban areas over a period of 7 years. Compared to the other datasets, it includes variations in all of the following: geographical diversity, season, time of day, viewpoint, and weather. Similarly to RobotCar Seasons v2 and Extended CMU Seasons, it contains a public validation set and a withheld test set. While the dataset is suited for sequence-based methods, we only evaluate the image-to-image task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>Qualitative Results. In these examples, the proposed Patch-NetVLAD successfully retrieves the matching reference image, while both NetVLAD and SuperGlue produce incorrect place matches. The retrieved image with our approach on the Tokyo 24/7 dataset is a particularly challenging match, with a combination of day vs night-time, severe viewpoint shift and occlusions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 .</head><label>2</label><figDesc>Computational time requirements. The number of seconds required to process each query are shown on the x-axis, with the resulting R@1 shown on the y-axis, for the Mapillary dataset. (a) indicates the times taken for feature extraction only, while (b) shows the feature matching time. In (c) we show the combined time (as in Fig 4 in the main paper). Triangles indicate single-scale Patch-NetVLAD, while stars indicate multi-scale Patch-NetVLAD. Filled symbols are used for RANSAC matching, while hollow symbols are used for the rapid spatial verification. The color indicates varying PCA dimensions. Supplementary</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Fig 3 illustrates this effect by showing the corresponding patch sizes at multiple scales superimposed onto the original image. In Suppl. Fig. 8, we showcase some examples where all methods fail to localize correctly -those examples may guide future research to address these open challenges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Supplementary Figure 4 .Supplementary Figure 5 .Supplementary Figure 6 .Supplementary Figure 7 .Supplementary Figure 8 .</head><label>45678</label><figDesc>Feature correspondences for the Mapillary dataset. Feature correspondences for the Nordland dataset. Feature correspondences for the Pittsburgh dataset. Feature correspondences for the Tokyo 24/7 dataset. Cases where all methods fail. We hope that these cases inform future research in VPR. Failure cases on Nordland (top left block) are mainly due to an unseen environment (for learning-based methods) and significant perceptual aliasing, i.e. different places look very similar. Similarly, on the Mapillary dataset (bottom left block) both SuperGlue and Patch-NetVLAD retrieve places that have a very similar structure to the query -consider for example the second last row where both the query and retrieved image from Patch-NetVLAD have a light pole on the left and sparse trees on right. On the Pittsburgh dataset (top right block), an additional challenge are the extreme viewpoint variations. Failures on Tokyo 24/7 (bottom right block) are mainly due to extreme viewpoint and appearance changes, as the query images are captured at night-time while reference images are captured at day-time. As mentioned in the Conclusions, we think that adding semantic information might aid Patch-NetVLAD in these extremely challenging cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Supplementary Figure 9 .</head><label>9</label><figDesc>Cases where Patch-NetVLAD retrieved a correct match, but this match was deemed outside the error tolerance, suggesting either that the error tolerances are too tight (compared to what a human would consider as the same place), or the possibility of slight ground truth errors. The left columns contain examples from the Mapillary dataset, while the right columns contain examples from the Pittsburgh dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative results R@1 R@5 R@10 R@1 R@5 R@10 .25m/2?.5m/5?5.0m/10?.25m/2?.5m/5?5.0m/10?A</figDesc><table><row><cell cols="9">Nordland R@1 R@5 R@10 R@1 R@5 R@10 Mapillary (Challenge) Mapillary (Val. set) R@1 R@5 R@10 P-GEM [56] Method 5.6 9.1 11.2 ---57.0 70.5 75.3</cell><cell>Pittsburgh 30k 75.3 89.3 92.5</cell><cell>Tokyo 24/7 40.3 55.6 65.4</cell><cell cols="3">RobotCar Seasons v2 4.5 16.9 62.7</cell><cell>Extended CMU Seasons 3.8 11.9 62.9</cell></row><row><cell cols="5">DenseVLAD [76] 10.1 17.1 21.5</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>52.8 65.1 69.6</cell><cell>77.7 88.3 91.6</cell><cell>59.4 67.3 72.1</cell><cell>7.4</cell><cell>28.1</cell><cell>79.8</cell><cell>8.2</cell><cell>25.4</cell><cell>82.5</cell></row><row><cell cols="3">NetVLAD [3]</cell><cell cols="2">10.4 16.3 19.7</cell><cell cols="2">35.1 47.4</cell><cell>51.7</cell><cell>60.8 74.3 79.5</cell><cell>83.5 91.3 94.0</cell><cell>64.8 78.4 81.6</cell><cell>6.5</cell><cell>23.8</cell><cell>77.7</cell><cell>5.8</cell><cell>17.9</cell><cell>78.3</cell></row><row><cell cols="5">SuperGlue [59] 29.1 33.4 35.0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>78.4 82.8 84.2</cell><cell>88.7 95.1 96.4</cell><cell>88.2 90.2 90.2</cell><cell>8.3</cell><cell>32.4</cell><cell>89.9</cell><cell>9.5</cell><cell>30.7</cell><cell>96.7</cell></row><row><cell cols="2">Ours</cell><cell></cell><cell cols="2">44.9 50.2 52.2</cell><cell cols="2">48.1 57.6</cell><cell>60.5</cell><cell>79.5 86.2 87.7</cell><cell>88.7 94.5 95.9</cell><cell>86.0 88.6 90.5</cell><cell>9.6</cell><cell>35.3</cell><cell>90.9</cell><cell>11.8</cell><cell>36.2</cell><cell>96.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Table 2. Ablation study</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Method</cell><cell></cell><cell cols="9">Nordland R@1 R@5 R@10 R@1 R@5 R@10 R@1 R@5 R@10 R@1 R@5 R@10 .25m/2?.5m/5?5.0m/10?.25m/2?.5m/5?5.0m/10?O Mapillary (Val. set) Pittsburgh 30k Tokyo 24/7 RobotCar Seasons v2 Extended CMU Seasons</cell></row><row><cell cols="5">urs (Single-Spatial-Patch-NetVLAD)</cell><cell cols="3">42.9 49.2 51.6</cell><cell>77.2 85.4 87.3</cell><cell>88.0 94.0 95.6</cell><cell>78.1 83.8 87.0</cell><cell>8.7</cell><cell>32.4</cell><cell>88.4</cell><cell>10.0</cell><cell>31.5</cell><cell>95.2</cell></row><row><cell cols="8">Ours (Single-RANSAC-Patch-NetVLAD) 42.4 48.8 51.2</cell><cell>77.8 85.7 87.8</cell><cell>87.3 94.2 95.7</cell><cell>82.2 87.3 89.2</cell><cell>8.7</cell><cell>31.6</cell><cell>88.3</cell><cell>10.0</cell><cell>31.3</cell><cell>94.5</cell></row><row><cell cols="5">Ours (Multi-Spatial-Patch-NetVLAD)</cell><cell cols="3">44.5 50.1 52.0</cell><cell>78.2 85.3 86.9</cell><cell>88.6 94.5 95.8</cell><cell>81.9 85.7 87.9</cell><cell>9.4</cell><cell>33.9</cell><cell>89.3</cell><cell>11.1</cell><cell>34.5</cell><cell>96.3</cell></row><row><cell cols="8">Ours (Multi-RANSAC-Patch-NetVLAD) 44.9 50.2 52.2</cell><cell>79.5 86.2 87.7</cell><cell>88.7 94.5 95.9</cell><cell>86.0 88.6 90.5</cell><cell>9.6</cell><cell>35.3</cell><cell>90.9</cell><cell>11.8</cell><cell>36.2</cell><cell>96.2</cell></row><row><cell></cell><cell>100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Recall@N (%)</cell><cell>60 70 80 90</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ours AP-GEM DenseVLAD NetVLAD SuperGlue</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>50</cell><cell>0</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell>25</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="6">N -Number of top reference candidates</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Preprint version; final version available at http://ieeexplore.ieee.org Queensland University of Technology {s.hausler, s.garg, m22.xu, michael.milford, tobias.fischer}@qut.edu.au</figDesc><table><row><cell cols="2">IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2021) Published by: IEEE</cell><cell></cell><cell></cell></row><row><cell cols="4">Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition</cell></row><row><cell cols="3">&lt;Supplementary Material&gt;</cell><cell></cell></row><row><cell>Stephen Hausler QUT Centre for Robotics, Sourav Garg</cell><cell>Ming Xu</cell><cell>Michael Milford</cell><cell>Tobias Fischer</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Performance comparison RobotCar Seasons v2 / 72.5 / 86.2 13.5 / 72.0 / 89.5 5.3 / 80.9 / 94.5 6.3 / 71.3 / 89.8 5.9 / 79.3 / 92.1 7.8 / 75.9 / 87.9 4.8 / 67.3 / 83.4 0.5 / 12.4 / 24.9 1.0 / 19.0 / 30.8</figDesc><table><row><cell></cell><cell></cell><cell cols="4">Supplementary day conditions</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">night conditions</cell></row><row><cell></cell><cell>dawn</cell><cell>dusk</cell><cell></cell><cell>OC-summer</cell><cell>OC-winter</cell><cell>rain</cell><cell></cell><cell></cell><cell>snow</cell><cell>sun</cell><cell></cell><cell>night</cell><cell>night-rain</cell></row><row><cell>m Ours 75 95 4.8 0 5 80 85 90 Recall@N (%)</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell>25</cell><cell>AP-GEM DenseVLAD NetVLAD SuperGlue Ours</cell><cell>40 60 80</cell><cell>0</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell>25</cell></row><row><cell cols="5">N -Number of top reference candidates</cell><cell></cell><cell></cell><cell cols="6">N -Number of top reference candidates</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Performance comparison Extended CMU Seasons / 48.0 / 97.2 8.2 / 28.8 / 97.0 9.5 / 34.9 / 94.3</figDesc><table><row><cell></cell><cell>Urban</cell><cell>Suburban</cell><cell>Park</cell></row><row><cell>m</cell><cell>.25 / .50 / 5.0</cell><cell>.25 / .50 / 5.0</cell><cell>.25 / .50 / 5.0</cell></row><row><cell>deg</cell><cell>2 / 5 / 10</cell><cell>2 / 5 / 10</cell><cell>2 / 5 / 10</cell></row><row><cell>AP-GEM [10]</cell><cell cols="2">8.1 / 21.5 / 81.3 2.4 / 9.1 / 63.6</cell><cell>1.7 / 6.6 / 45.3</cell></row><row><cell cols="4">DenseVLAD [16] 15.0 / 37.2 / 88.8 5.5 / 20.2 / 84.3 5.5 / 21.3 / 74.6</cell></row><row><cell>NetVLAD [1]</cell><cell cols="3">12.0 / 30.5 / 91.4 3.9 / 14.2 / 79.8 2.7 / 11.2 / 64.6</cell></row><row><cell>SuperGlue [11]</cell><cell cols="3">17.1 / 43.6 / 96.9 5.6 / 21.6 / 96.7 7.5 / 30.5 / 96.5</cell></row><row><cell>Ours</cell><cell>19.2</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">These results include both feature extraction and matching times; the Supplementary Material contains further figures that separate feature extraction and feature matching times.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements:</head><p>We would like to thank Gustavo Carneiro and Niko Suenderhauf for their valuable comments in preparing this paper. This work received funding from the Australian Government, via grant AUSMURIB000001 associated with ONR MURI grant N00014-19-1-2571. The authors acknowledge continued support from the Queensland University of Technology (QUT) through the Centre for Robotics.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Night-to-day image translation for retrieval-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asha</forename><surname>Anoosheh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Robot. Autom</title>
		<imprint>
			<biblScope unit="page" from="5958" to="5964" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">All about VLAD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Relja</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1578" to="1585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">NetVLAD: CNN architecture for weakly supervised place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Relja</forename><surname>Arandjelovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Gronat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1437" to="1451" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Aggregating local deep features for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1269" to="1277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Visual topometric localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hernan</forename><surname>Badino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intell. Veh. Symp</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="794" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Surf: Speeded up robust features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="404" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Spatio-semantic convnetbased visual place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libor</forename><surname>Camara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>P?eu?il</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Mobile Robot</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visual place recognition by spatial matching of high-level CNN features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libor</forename><surname>Camara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>P?eu?il</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot. Auton. Syst</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page">103625</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unifying deep local and global features for image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Sim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep learning features at scale for visual place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zetao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>S?nderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Upcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingqiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Robot. Autom</title>
		<imprint>
			<biblScope unit="page" from="3223" to="3230" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning context flexible attention model for long-term visual place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zetao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingqiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkyu</forename><surname>Sa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongyuan</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margarita</forename><surname>Chli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="4015" to="4022" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Only look once, mining distinctive landmarks from ConvNet for visual place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zetao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabiola</forename><surname>Maffra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkyu</forename><surname>Sa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margarita</forename><surname>Chli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ Int. Conf. Intell. Robot. Syst</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Total recall II: Query expansion revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond?ej</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Perdoch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji??</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="889" to="896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">SIPs: succinct interest points from unsupervised inlierness probability learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Titus</forename><surname>Cieslewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scaramuzza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="604" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Summed-area tables for texture mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Crow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conf</title>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visual categorization with bags of keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriella</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jutta</forename><surname>Willamowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C?dric</forename><surname>Bray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis. Worksh</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fab-map: Probabilistic localization and mapping in the space of appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Cummins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="647" to="665" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Superpoint: Self-supervised interest point detection and description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Detone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog. Worksh</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="224" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scalable place recognition under appearance change for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh-Dzung</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasir</forename><surname>Latif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Jun</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh-Toan</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9319" to="9328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">D2-net: A trainable CNN for joint description and detection of local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Dusmanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Rocco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8092" to="8101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hierarchical metric learning and matching for 2D and 3D geometric correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc-Huy</forename><surname>Mohammed E Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeeshan</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Zia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="803" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Event-based visual place recognition with ensembles of temporal windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="6924" to="6931" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Look no deeper: Recognizing places from opposing viewpoints under varying scene appearance using single-view depth estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourav</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanuja</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Dharmasiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>Hausler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swagat</forename><surname>Suenderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Drummond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. Robot. Autom</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4916" to="4923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Delta descriptors: Change-based place representation for robust visual localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourav</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurangi</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="5120" to="5127" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semantic-geometric visual place recognition: A new perspective for reconciling opposing views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourav</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>Suenderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Self-supervising fine-grained region similarities for largescale image localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixiao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis</title>
		<editor>Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm</editor>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="369" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-scale orderless pooling of deep convolutional activation features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="392" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Attentionbased query expansion learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Radenovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. Conf. Comput. Vis</title>
		<imprint>
			<biblScope unit="page" from="172" to="188" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Local descriptor for robust place recognition using lidar intensity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiadong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">K</forename><surname>Paulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chanoh</forename><surname>Borges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abel</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gawel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1470" to="1477" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-process fusion: Visual place recognition using multiple image processing methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Hausler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Hierarchical multiprocess fusion for visual place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Hausler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Robot. Autom</title>
		<imprint>
			<biblScope unit="page" from="3327" to="3333" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Textplace: Visual place recognition and topological localization through reading scene texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvan</forename><surname>Petillot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishu</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2861" to="2870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Functional architecture of macaque monkey visual-cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D H</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T N</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Royal Soc. B</title>
		<imprint>
			<biblScope unit="volume">198</biblScope>
			<biblScope unit="page" from="1" to="59" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Exploiting generative models in discriminative classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Haussler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<biblScope unit="page" from="487" to="493" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Aggregating local descriptors into a compact image representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3304" to="3311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A holistic visual place recognition approach using lightweight CNNs for significant viewpoint and appearance changes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmad</forename><surname>Khaliq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoaib</forename><surname>Ehsan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zetao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Mcdonald-Maier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="561" to="569" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learned contextual feature reweighting for image geo-localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyo</forename><forename type="middle">Jin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Michael</forename><surname>Frahm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3251" to="3260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Geometric image correspondence verification by dense pixel matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zakaria</forename><surname>Laskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iaroslav</forename><surname>Melekhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juha</forename><surname>Hamed Rezazadegan Tavakoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Ylioinas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kannala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conf. Appl. Comput. Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2521" to="2530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">City-scale visual place recognition with deep local features based on multi-scale ordered VLAD pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canh</forename><surname>Duc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyun Youn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09255</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">LPD-Net: 3D point cloud learning for large-scale place recognition and environment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunbo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanzhe</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hesheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Hui</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2831" to="2840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Object recognition from local scale-invariant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Visual place recognition: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Lowry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>Sunderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Corke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">1 year, 1000 km: The Oxford RobotCar dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Pascoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Linegar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dgc-net: Dense geometric correspondence network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iaroslav</forename><surname>Melekhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksei</forename><surname>Tiulpin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esa</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Kannala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conf. Appl. Comput. Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1034" to="1042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learnable pooling with context gating for video classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Miech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog. Worksh</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Milford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Wyeth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Robot. Autom</title>
		<imprint>
			<biblScope unit="page" from="1643" to="1649" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Orb-slam: a versatile and accurate monocular slam system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raul</forename><surname>Mur-Artal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose Maria Martinez</forename><surname>Montiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">D</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1147" to="1163" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Beyond holistic descriptors, keypoints, and fixed patches: Multiscale superpixel grids for place recognition in changing environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peer</forename><surname>Neubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Protzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="484" to="491" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Large-scale image retrieval with attentive deep local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3456" to="3465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Augmenting visual place recognition with structural cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amadeus</forename><surname>Oertel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Titus</forename><surname>Cieslewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Scaramuzza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="5534" to="5541" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep architectures and ensembles for semantic video classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eng-Jon</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Syed Sameed Husain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miroslaw</forename><surname>Bober-Irizar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bober</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3568" to="3582" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Allenvironment visual place recognition with smart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Pepperell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Peter I Corke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Robot. Autom</title>
		<imprint>
			<biblScope unit="page" from="1612" to="1618" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fisher kernels on visual vocabularies for image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Adversarial training for adverse conditions: Robust metric localisation using appearance transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horia</forename><surname>Porav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Robot. Autom</title>
		<imprint>
			<biblScope unit="page" from="1011" to="1018" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Finetuning cnn image retrieval with no human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Radenovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond?ej</forename><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1655" to="1668" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning with average precision: Training image retrieval with a listwise loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Almaz?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cesar Roberto De</forename><surname>Rafael S Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Souza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5107" to="5116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Orb: An efficient alternative to sift or surf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Rublee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Rabaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Bradski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2564" to="2571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">From coarse to fine: Robust hierarchical localization at large scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul-Edouard</forename><surname>Sarlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cesar</forename><surname>Cadena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Siegwart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Dymczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12716" to="12725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">SuperGlue: Learning feature matching with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul-Edouard</forename><surname>Sarlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Detone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4938" to="4947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Benchmarking 6dof outdoor visual localization in changing conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Toft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Hammarstrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Stenborg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Safari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8601" to="8610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Semantic visual localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Johannes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Sch?nberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sattler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6896" to="6906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">SDC-Stacked dilated convolution: A unified descriptor network for dense matching tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren?</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Wasenmuller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didier</forename><surname>Stricker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2556" to="2565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Learn. Represent</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Video Google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Scaleadaptive neural dense features: Learning via hierarchical context aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Spencer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Hadfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6200" to="6209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Same features, different day: Weakly supervised feature learning for seasonal invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Spencer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Hadfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6459" to="6468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">NCC-net: normalized cross correlation based deep matcher with robustness to illumination variations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arulkumar</forename><surname>Subramaniam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashanth</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conf. Appl. Comput. Vision</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1944" to="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Are we there yet? Challenging SeqSLAM on a 3000 km journey across all four seasons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>S?nderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peer</forename><surname>Neubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Protzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Robot. Autom. Workshops</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Place recognition with ConvNet landmarks: Viewpointrobust, condition-robust, training-free</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>S?nderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sareh</forename><surname>Shirazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feras</forename><surname>Dayoub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Pepperell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Upcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot.: Sci. Syst</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">On the performance of ConvNet features for place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>S?nderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sareh</forename><surname>Shirazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feras</forename><surname>Dayoub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Upcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ Int. Conf. Intell. Robot. Syst</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4297" to="4304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Inloc: Indoor visual localization with dense matching and view synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajime</forename><surname>Taira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mircea</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7199" to="7209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Is this the right place? Geometric-semantic pose verification for indoor visual localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajime</forename><surname>Taira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Rocco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Sedlar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4373" to="4383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Detect-to-retrieve: Efficient regional aggregation for image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Teichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Sim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5109" to="5118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Long-term visual localization revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Toft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Hammarstrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Stenborg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Safari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Particular object retrieval with integral max-pooling of CNN activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Sicre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Int. Conf. Learn. Represent</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">24/7 Place Recognition by View Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Relja</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Visual place recognition with repetitive structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2346" to="2359" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">PointNetVLAD: Deep point cloud based retrieval for large-scale place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelina</forename><surname>Mikaela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Uy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4470" to="4479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Mapillary street-level sequences: A dataset for lifelong place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederik</forename><surname>Warburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soren</forename><surname>Hauberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Lopez-Antequera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pau</forename><surname>Gargallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubin</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Civera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2626" to="2635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Real-time visual place recognition based on analyzing distribution of multi-scale cnn landmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqing</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="777" to="792" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">LIFT: Learned invariant feature transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Kwang Moo Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Trulls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="467" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">MRS-VPR: A multi-resolution sampling based global visual place recognition method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peng Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Rangaprasad Arun Srivatsan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongda</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingyun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Robot. Autom</title>
		<imprint>
			<biblScope unit="page" from="7137" to="7142" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Spatial pyramid-enhanced netvlad with weighted triplet loss for place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="661" to="674" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Cohog: A light-weight, compute-efficient, and training-free visual place recognition technique for changing environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubariz</forename><surname>Zaffar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoaib</forename><surname>Ehsan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Mcdonald-Maier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1835" to="1842" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Learning two-view correspondences and geometry using order-aware network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anbang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yurong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongen</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5845" to="5854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Regional relation modeling for visual place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Conf. Res. Develop. Inf. Retrieval</title>
		<imprint>
			<biblScope unit="page" from="821" to="830" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Attention-based pyramid aggregation network for visual place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Multimedia</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="99" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Edge boxes: Locating object proposals from edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="391" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">NetVLAD: CNN architecture for weakly supervised place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Relja</forename><surname>Arandjelovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Gronat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1437" to="1451" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Aggregating local deep features for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1269" to="1277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Visual topometric localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hernan</forename><surname>Badino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intell. Veh. Symp</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="794" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Visual place recognition by spatial matching of high-level CNN features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libor</forename><surname>Camara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>P?eu?il</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot. Auton. Syst</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page">103625</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Superpoint: Self-supervised interest point detection and description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Detone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog. Worksh</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="224" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Multi-process fusion: Visual place recognition using multiple image processing methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Hausler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Hierarchical multiprocess fusion for visual place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Hausler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Robot. Autom</title>
		<imprint>
			<biblScope unit="page" from="3327" to="3333" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">1 year, 1000 km: The Oxford RobotCar dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Pascoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Linegar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Appearance change prediction for long-term navigation across seasons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Neubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>S?nderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Protzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Mobile Robot</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="198" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Learning with average precision: Training image retrieval with a listwise loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Almaz?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cesar Roberto De</forename><surname>Rafael S Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Souza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5107" to="5116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">SuperGlue: Learning feature matching with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul-Edouard</forename><surname>Sarlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Detone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4938" to="4947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Are we there yet? Challenging SeqSLAM on a 3000 km journey across all four seasons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>S?nderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peer</forename><surname>Neubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Protzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Robot. Autom. Workshops</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">On the performance of ConvNet features for place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>S?nderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sareh</forename><surname>Shirazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feras</forename><surname>Dayoub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Upcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ Int. Conf. Intell. Robot. Syst</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4297" to="4304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Long-term visual localization revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Toft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Hammarstrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Stenborg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Safari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Particular object retrieval with integral max-pooling of CNN activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Sicre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Int. Conf. Learn. Represent</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">24/7 Place Recognition by View Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Relja</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Visual place recognition with repetitive structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2346" to="2359" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Mapillary street-level sequences: A dataset for lifelong place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederik</forename><surname>Warburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soren</forename><surname>Hauberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Lopez-Antequera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pau</forename><surname>Gargallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubin</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Civera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2626" to="2635" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
