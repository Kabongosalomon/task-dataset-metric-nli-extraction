<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Break-It-Fix-It: Unsupervised Learning for Program Repair</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
						</author>
						<title level="a" type="main">Break-It-Fix-It: Unsupervised Learning for Program Repair</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider repair tasks: given a critic (e.g., compiler) that assesses the quality of an input, the goal is to train a fixer that converts a bad example (e.g., code with syntax errors) into a good one (e.g., code with no syntax errors). Existing works create training data consisting of (bad, good) pairs by corrupting good examples using heuristics (e.g., dropping tokens). However, fixers trained on this synthetically-generated data do not extrapolate well to the real distribution of bad inputs. To bridge this gap, we propose a new training approach, Break-It-Fix-It (BIFI), which has two key ideas: (i) we use the critic to check a fixer's output on real bad inputs and add good (fixed) outputs to the training data, and (ii) we train a breaker to generate realistic bad code from good code. Based on these ideas, we iteratively update the breaker and the fixer while using them in conjunction to generate more paired data. We evaluate BIFI on two code repair datasets: GitHub-Python, a new dataset we introduce where the goal is to repair Python code with AST parse errors; and DeepFix, where the goal is to repair C code with compiler errors. BIFI outperforms state-of-the-art methods, obtaining 90.5% repair accuracy on GitHub-Python (+28.5%) and 71.7% on DeepFix (+5.6%). Notably, BIFI does not require any labeled data; we hope it will be a strong starting point for unsupervised learning of various repair tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In many domains, one has access to a critic that assesses the quality of an input, but what is desired is a more constructive fixer that actually improves bad inputs. For instance, in programming, while a code analyzer and compiler can tell if a given code has errors, programmers need to repair the errors in the bad code. Development of an automatic code fixer is thus a key to enhancing programming productivity <ref type="bibr" target="#b53">(Seo et al., 2014)</ref> and is an active area of research <ref type="bibr" target="#b41">(Mesbah et al., 2019;</ref><ref type="bibr">Ding et al., 2020;</ref><ref type="bibr">Dinella et al., 2020)</ref>. Other <ref type="figure">Figure 1</ref>. Problem setup. We are given an unlabeled data (code snippets) and a critic (e.g., code analyzer, compiler) that assesses the quality of an input (e.g., bad if the code has errors; good if no error). Our task is to learn a fixer that can actually repair a bad example into a good one (e.g., fixing errors in the bad code).</p><p>instances of this general setting include molecular design <ref type="bibr" target="#b25">(Jin et al., 2019)</ref> which aims to improve the chemical properties (e.g., drug-likeness) of molecules given a property evaluator, and essay editing <ref type="bibr" target="#b57">(Taghipour &amp; Ng, 2016)</ref> which aims to improve a writing given a grade. How to automatically learn a fixer given a critic (we term critic2fixer) remains an important research problem in machine learning.</p><p>In this work, we focus on the domain of code repair. Learning a fixer is challenging because manual labeling of paired data, e.g., broken code, fixed code , is costly. To this end, we consider learning from unlabeled data. Specifically, as illustrated in <ref type="figure">Figure 1</ref>, we are given (a) a critic (code analyzer or compiler) that assesses the quality of an input-bad if the code has errors; good if it has no errors-, and (b) unlabeled dataunpaired set of good code and bad code, e.g., from GitHub. Our goal is to learn a fixer that repairs bad code into good code. Previous works in code repair apply random or heuristic perturbations to good code (e.g., dropping tokens) and prepare synthetic paired data perturbed code, good code to train a fixer <ref type="bibr" target="#b49">(Pu et al., 2016;</ref><ref type="bibr" target="#b16">Gupta et al., 2017;</ref><ref type="bibr" target="#b0">Ahmed et al., 2018;</ref><ref type="bibr" target="#b19">Hajipour et al., 2019;</ref><ref type="bibr">Yasunaga &amp; Liang, 2020)</ref>. However, such synthetically generated bad examples do not match arXiv:2106.06600v2 <ref type="bibr">[cs.</ref>LG] 22 Jun 2021</p><p>Break-It-Fix-It: Unsupervised Learning for Program Repair def validate(type): &lt;IN&gt;if type not in types: &lt;IN&gt;msg = ("invalid type!" "not in %s" % types)a &lt;IN&gt;raise Exception(msg)&lt;DE&gt;&lt;DE&gt; else: pass Real def validate(type): &lt;IN&gt;if type not in types: msg = ("invalid type!" "not in %s" % types) raise Exception(msg)&lt;DE&gt; else: pass Synthetic def validate(type): &lt;IN&gt;if type not in types: &lt;IN&gt;msg = ("invalid type!" "not in %s" % types) raise Exception(msg)&lt;DE&gt; else: pass (Synthetic Errors) (Human Errors) (Synthetic Errors) (Human Errors) &lt;IN&gt;msg = ("invalid type!"</p><p>"not in %s" % types)a &lt;IN&gt;raise Exception(msg)&lt;DE&gt;&lt;DE&gt; else: pass msg = ("invalid type!"</p><p>"not in %s" % types) raise Exception(msg)&lt;DE&gt; else: pass &lt;IN&gt;msg = ("invalid type!"</p><p>"not in %s" % types) raise Exception(msg)&lt;DE&gt; else: pass (Synthetic Error) (Human Error) def validate(type): &lt;I&gt;if type not in types: &lt;I&gt;msg = ("invalid type!" "not in %s" % types)a &lt;I&gt;raise Exception(msg)&lt;D&gt;&lt;D&gt; else: pass Real def validate(type): &lt;I&gt;if type not in types: msg = ("invalid type!" "not in %s" % types) raise Exception(msg)&lt;D&gt; else: pass Synthetic def validate(type): &lt;I&gt;if type not in types: &lt;I&gt;msg = ("invalid type!" "not in %s" % types) raise Exception(msg)&lt;D&gt; else: pass <ref type="figure">Figure 2</ref>. Challenge of learning a fixer from unlabeled data. Existing works randomly perturb good examples into bad examples and learn to recover. However, such synthetically generated bad examples do not match the distribution of real bad examples. For instance, synthetic perturbations may drop parentheses arbitrarily from code (top right), but real human-written bad code misses parentheses more often in a nested context (top center). In a more extreme case at bottom, to generate the human error (center) from the corrected code (left), a pair of indent and dedent tokens need to be inserted accordingly, which random perturbations generate with very small probability. Note that indentation is meaningful in Python: in the tokenized Python code, each I token means indenting the line by one unit, each D means dedenting the next line by one unit. the distribution of real bad examples. For instance, as shown in <ref type="figure">Figure 2</ref>, synthetic perturbations may drop parentheses arbitrarily from code, generating errors that rarely happen in real programming (Figure 2 top right; synthetic errors); in contrast, real human-written code misses parentheses more often in a nested context (Figure 2 top center; human errors). As we will show in ?4, this distribution mismatch between synthetic data and real data results in low performance.</p><p>To bridge this gap, we propose Break-It-Fix-It (BIFI), a new method to learn a fixer from unlabeled data and a critic <ref type="bibr">(Figure 3)</ref>. BIFI is based on two core insights: (i) we can use the critic to check a fixer's output on real bad examples and add good outputs to the training data, and (ii) we train a breaker to generate realistic bad examples from good examples. Specifically, given an initial fixer trained on synthetic paired data synthetic bad, good , BIFI improves the fixer and breaker simultaneously through rounds of data generation and training:</p><p>(1) apply the fixer to real bad examples and keep fixed outputs to obtain real paired data, (2) use the resulting data to train the breaker, (3) use the learned breaker to generate code errors and obtain more paired data, and (4) train the fixer on the newly-generated paired data in (1) and (3). Intuitively, this cycle trains the fixer on increasingly more real or realistically generated bad code, adapting the fixer from the initial synthetic distributions towards real distributions of code errors.</p><p>The BIFI algorithm is related to backtranslation in unsupervised machine translation <ref type="bibr" target="#b33">(Lample et al., 2018a)</ref>, which uses a target-to-source model to generate noisy sources and trains a source-to-target model to reconstruct the targets (e.g., the bad-side and good-side in our repair task can be viewed as the source and target). BIFI differs from backtranslation in two ways: it uses the critic to verify if the generated examples are actually fixed or broken (step 1 and 3), and it trains the fixer on real bad examples in addition to examples generated by the breaker (step 4), which improves the correctness and distributional match of generated paired data.</p><p>We evaluate our proposed approach on two code repair datasets:</p><p>? GitHub-Python: We collected a new dataset of 3M Python code snippets from github.com. The task is to repair errors caught by the Python AST parser. We set the initial fixer to be an encoder-decoder Transformer <ref type="bibr" target="#b61">(Vaswani et al., 2017)</ref> trained on random perturbations. ? DeepFix <ref type="bibr" target="#b16">(Gupta et al., 2017)</ref>: The task is to repair compiler errors in C code submitted by students in an introductory programming course. We set the initial fixer to be the existing best system, DrRepair <ref type="bibr">(Yasunaga &amp; Liang, 2020)</ref>, which was trained on manually-designed heuristic perturbations.</p><p>Our approach (BIFI) outperforms the initial fixers, obtaining 90.5% repair accuracy on GitHub-Python (+28.5% absolute) and 71.7% repair accuracy on DeepFix (+5.6% absolute), attaining a new state-of-the-art. BIFI also improves on backtranslation by 10%. Further, we qualitatively show how the fixer and breaker adapt towards more realistic distributions of code through the BIFI algorithm ( ?4.3). <ref type="figure">Figure 1</ref> illustrates our problem setup, critic2fixer. The system is given unlabeled data D (code snippets) and a critic c (code analyzer or compiler) that returns whether an input is good or bad: e.g., for a code snippet x ? D,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem statement</head><formula xml:id="formula_0">c(x) = 0 if x has errors, 1 if x has no error.<label>(1)</label></formula><p>Using the critic c, examples in D can be classified into bad ones D bad = {x | x ? D, c(x) = 0} and good ones D good = {y | y ? D, c(y) = 1}. Our task is to learn a fixer f that maps a bad example x ? D bad into a good example f (x) such that it is close 1 to x and c(f (x)) = 1. The evaluation metric is the fixer f 's repair accuracy on a held-out set of bad examples, D (test) bad ,</p><formula xml:id="formula_1">RepairAcc = |{x | x ? D (test) bad , c(f (x)) = 1}| |D (test) bad | .</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>The major challenge of learning a fixer is that we need to learn from unpaired data, i.e., D bad and D good do not form broken, for name in listdir(path) if isfile(join(path,name)) i for name in listdir(path) if isfile(join(path,name)))</p><p>Finetune f k for name in listdir(path) if isfile(join(path,name)))i for name in listdir(path) if isfile(join(path,name))) Fixed code</p><formula xml:id="formula_2">Apply f k-1 Keep if fixed (1) Train f k ? 3.4 FixerOnly -Round k (=1,2, ?) ? 3.2 Break-It-Fix-It (BIFI) -Round k (=1,2, ?) ? 3.1 Initialization -Round 0 ? 3.3 ref. Backtranslation -Round k (=1,2, ?) (2) (2)<label>(4)</label></formula><p>(2)</p><p>(2) (4) <ref type="figure">Figure 3</ref>. Overview of our approach. We train the initial fixer on synthetically prepared data as in prior works (top left). In our approach, BIFI (bottom right), we apply the initial fixer to the real bad examples and add fixed outputs (verified by the critic) to our training data (Step 1), train a breaker on the resulting paired data (Step 2), use the breaker to generate (intuitively more realistic) code errors (Step 3), and train the fixer again on the newly-generated paired data (Step 4). We iterate this cycle, improving the fixer and the breaker simultaneously.</p><p>Top right: a version of BIFI without the breaker (FixerOnly). Bottom left: comparison of BIFI to backtranslation. The main difference is that BIFI uses the critic to verify that the fixer produces good code and the breaker produces bad code (annotated with magenta font).</p><p>fixed pairs. Prior works in code repair apply random or heuristic perturbations to good examples (e.g., dropping tokens) and prepare a synthetic paired data perturbed code, good code to train a fixer <ref type="bibr" target="#b16">(Gupta et al., 2017;</ref><ref type="bibr" target="#b0">Ahmed et al., 2018;</ref><ref type="bibr">Yasunaga &amp; Liang, 2020)</ref>. However, such synthetically generated bad examples do not match the distribution of real bad examples. For instance, as <ref type="figure">Figure 2</ref> (top) shows, synthetic perturbations may drop parentheses arbitrarily from code, generating errors that are rare in real programs; in contrast, real human-written code misses parentheses often in a nested context (e.g., 10x more than non-nested in our collected dataset GitHub-Python). In a more extreme case <ref type="figure">(Figure 2</ref> bottom), to make the real human error (center) from the corrected code (left), multiple tokens (in this case, a pair of indent and dedent) need to be inserted or dropped accordingly, which random perturbations would generate with extremely low probability. This distribution mismatch between synthetic data and real data results in low performance ( ?4).</p><p>To address this challenge, we propose Break-It-Fix-It (BIFI), an approach that adapts the fixer automatically towards real distributions of bad examples. Concretely, we first start from the synthetic paired data synthetic bad, good and train an initial fixer as in prior works (see <ref type="figure">Figure 3</ref> top left; initialization). We then perform the following cycle (see <ref type="figure">Figure 3</ref> bottom right): (1) we apply the initial fixer to the real bad examples and use the critic to assess if the fixer's output is good-if good, we keep the pair;</p><p>(2) we train a breaker on the resulting paired data-as this data consists of real code errors, intuitively, the breaker learns to generate realistic code errors;</p><p>(3) we apply the breaker to the good examples; (4) we finally train the fixer on the newly-generated paired data in <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula" target="#formula_3">(3)</ref>. We iterate this cycle to improve the fixer and the breaker simultaneously in the process. The intuition is that a better fixer and breaker will be able to generate more realistic paired data, which in turn helps to train a better fixer and breaker.</p><p>Below, we describe the initialization step in ?3.1, our main algorithm BIFI in ?3.2, and discuss two baselines of BIFI: backtranslation ( ?3.3) and FixerOnly (version of BIFI without the breaker; ?3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Initialization</head><p>Given unlabeled data D = (D bad ,D good ), we first prepare a synthetic paired data P synthetic by perturbing good examples:</p><formula xml:id="formula_3">P synthetic = {(b synthetic (y), y) | y ? D good },<label>(3)</label></formula><p>where b synthetic denotes a pre-defined procedure that corrupts code. For instance, we will experiment with two choices of b synthetic : (i) random noising, which randomly drops/inserts /replaces tokens in code, and (ii) heuristic noising designed in <ref type="bibr">Yasunaga &amp; Liang (2020)</ref>, which aims to generate common programming errors such as typo, punctuation and type errors. More details are described in ?4.1.</p><p>We then train the initial fixer f 0 and breaker b 0 on the </p><formula xml:id="formula_4">synthetic paired data: b 0 = TRAIN good?bad (P synthetic ) (4) f 0 = TRAIN bad?good (P synthetic )<label>(5)</label></formula><p>where TRAIN good?bad (P) denotes training an encoderdecoder model that maps good-side examples to bad-side examples in a paired data P, and TRAIN bad?good (P) does the reverse. Note that f 0 here corresponds to the fixer learned in prior works (e.g., <ref type="bibr" target="#b16">Gupta et al. (2017)</ref>; <ref type="bibr">Yasunaga &amp; Liang (2020)</ref>). We call this initialization step our round 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Break-It-Fix-It (BIFI)</head><p>BIFI aims to improve the fixer and breaker simultaneously through rounds of data generation and training: (1) use a fixer to create data for a breaker, (2) train a breaker, (3) use a breaker to create data for a fixer, and (4) train a fixer. Concretely, after the initialization step, BIFI performs the following in each round k = 1,2,...,K: </p><formula xml:id="formula_5">P (f ) k = {(x, f k?1 (x)) | x ? D bad , c(f k?1 (x)) = 1} (6) b k = TRAIN good?bad (P (f ) k ) (7) P (b) k = {(b k (y), y) | y ? D good , c(b k (y)) = 0} (8) f k = TRAIN bad?good (P (f ) k ? P (b) k ).<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Comparison with Backtranslation</head><p>The BIFI algorithm is related to backtranslation <ref type="bibr" target="#b34">(Lample et al., 2018b)</ref> in unsupervised machine translation. One may view the bad-side and good-side in our setup as two source/target languages in machine translation. Backtranslation uses a target-to-source model to generate noisy sources and trains a source-to-target model to reconstruct the targets. Specifically, in each round k, backtranslation performs the following:</p><formula xml:id="formula_6">P (f ) k = {(x, f k?1 (x)) | x ? D bad } (10) b k = TRAIN good?bad (P (f ) k ) (11) P (b) k = {(b k (y), y) | y ? D good } (12) f k = TRAIN bad?good (P (b) k ).<label>(13)</label></formula><p>BIFI differs in two aspects. First, as our task has a critic, BIFI uses the critic to verify the outputs of the fixer and breaker, and only keep examples whose outputs are actually fixed (Eq 6 red part) and whose outputs are broken (Eq <ref type="formula">8</ref>  in Eq 9) in addition to examples generated by the breaker, which improves the correctness and distributional match of training data. We will show in our ablation study ( ?4.3.3) that both of these two components improve the learning of a fixer and breaker. In essence, BIFI is an augmentation of backtranslation with a critic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Version of BIFI without breaker: FixerOnly</head><p>The benefit of BIFI is to enable training the fixer on real bad examples and bad examples generated by a learned breaker. We consider a version (FixerOnly) that trains the fixer simply on the real bad examples (prepared in Eq 6) but not the bad examples generated by the breaker (Eq 8). Specifically, FixerOnly does the following in each round k:</p><formula xml:id="formula_7">P (f ) k = {(x, f k?1 (x)) | x ? D bad , c(f k?1 (x)) = 1} (14) f k = TRAIN bad?good (P (f ) k ).<label>(15)</label></formula><p>FixerOnly can also be viewed as self-training <ref type="bibr" target="#b35">(Lee, 2013)</ref> with the difference that we only add fixer outputs verified by the critic to the training data. We will show in ?4.3.1 that FixerOnly is especially useful when the amount of available bad examples |D bad | is big, but the gain is smaller compared to BIFI when |D bad | is small, because BIFI can use the breaker to generate additional paired data for training the fixer (Eq 8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We evaluate our approach on two code repair datasets: a common benchmark DeepFix 2 <ref type="bibr" target="#b16">(Gupta et al., 2017)</ref>, and GitHub-Python, a bigger dataset we collect in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset and setup</head><p>We first describe the detail and experimental setup for GitHub-Python and DeepFix. The initial fixer is trained on synthetic bad code. Our proposed method (BIFI) enables the fixer to be fine-tuned on real bad code and bad code generated by the learned breaker. The result shows that BIFI outperforms the initial fixer by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Test accuracy</head><p>DeepFix <ref type="bibr" target="#b16">(Gupta et al., 2017)</ref> 33.4% RLAssist <ref type="bibr" target="#b17">(Gupta et al., 2019)</ref> 26.6% SampleFix <ref type="bibr" target="#b19">(Hajipour et al., 2019)</ref> 45.3% DrRepair <ref type="bibr">(Yasunaga &amp; Liang, 2020)</ref> 66.1%</p><p>Our Initial Round-0 (= DrRepair) 66.1%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our FixerOnly</head><p>Round-1 68.6% Round-2 70.5%</p><p>Our BIFI Round-1 70.8% Round-2 71.7% <ref type="table">Table 2</ref>. Repair accuracy on the DeepFix test set. We define our initial fixer (Round 0) to be the existing best system DrRepair. Note that DrRepair's training procedure coincides with the initialization step of our BIFI algorithm, with heuristic perturbations used in Eq 3. We then apply BIFI on top of it for Round 1, 2. BIFI outperforms DrRepair, achieving a new state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Github-Python</head><p>Dataset. To obtain an unlabeled dataset of code, we collected Python3 files from GitHub public repositories. <ref type="bibr">3</ref> We then tokenize each code file using the builtin Python tokenizer, and keep code snippets of length 10-128 tokens, resulting in 3M code snippets. As the critic c, we use the Python AST parser, 4 which catches unbalanced parentheses, indentation errors, and other syntax errors. Concretely, we define c(x) = 1 (good) if the AST parser returns no errors for input code x, and c(x) = 0 (bad) otherwise. Using this critic, we obtain 38K snippets of bad code and 3M snippets of good code. From the 38K bad examples, we holdout 15K as the final test set, and make the remaining 23K bad examples available for BIFI. Our goal is to learn a fixer that repairs AST parse errors. We define that the fixer's repair is successful if the output code has no AST parse errors and has Levenshtein edit-distance <ref type="bibr" target="#b37">(Levenshtein, 1966)</ref> less than 5 tokens from the input code. The evaluation metric is the fixer's repair accuracy on the test set, i.e., the heldout 15K examples of real bad code.</p><p>BIFI implementation details. For the architecture of the fixer and breaker, we use the encoder-decoder Transformer 3 https:github.com 4 https://docs.python.org/3/library/ast.html <ref type="bibr" target="#b61">(Vaswani et al., 2017)</ref> with 4 layers, 8 attention heads, and hidden states of size 256. The model parameters are optimized by Adam <ref type="bibr" target="#b28">(Kingma &amp; Ba, 2015)</ref>, with batch size of 27,000 tokens, learning rate 0.001, and gradient clipping 1.0 <ref type="bibr" target="#b45">(Pascanu et al., 2013)</ref>, on one GPU (GTX Titan X). For generation, we use beam search with beam size 10, and keep predictions with Levenshtein edit-distance less than 5 tokens from the input.</p><p>To train the initial fixer f 0 , we use random perturbations for the corruption procedure b synthetic (Eq 3), which drops, inserts, or replaces 1-3 tokens in code with uniform distribution. We apply b synthetic 8 times to each of the 2.6M good code snippets to prepare the initial training data P synthetic . We holdout 1% of P synthetic as our dev set, which we use to perform early stopping. We then run the BIFI algorithm for K = 2 rounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">DeepFix</head><p>Dataset. DeepFix <ref type="bibr" target="#b16">(Gupta et al., 2017)</ref> contains C code submitted by students in an introductory programming course, of which 37K snippets are good (no compiler error) and 7K are bad (have compiler errors). Each code snippet has 25 lines on average. Within the 7K bad examples, we take 20% as a heldout test set. We make the remaining 80% available for BIFI. The goal is to learn a fixer that repairs compiler errors. Repair is successful if the output code has no compiler errors. The evaluation metric is the fixer's repair accuracy on the test set.</p><p>BIFI implementation details. We define the initial fixer f 0 as DrRepair <ref type="bibr">(Yasunaga &amp; Liang, 2020)</ref> (the existing best system on DeepFix), which is an encoder-decoder model trained in a procedure that corresponds exactly to the initialization step of BIFI ( ?3.1). Specifically, to train DrRepair, <ref type="bibr">Yasunaga &amp; Liang (2020)</ref> design heuristic perturbations for the corruption procedure b synthetic , which mimics common code errors beginner and experienced programmers make (e.g., typos, punctuation, keyword and type errors). We use the same training / dev data prepared and released by the authors to train the initial fixer. We then run the BIFI algorithm for K = 2 rounds. Our fixer and breaker have the same model architecture as DrRepair. At test time, following the original DrRepair, we repeatedly apply the fixer while the code still has errors, up to a maximum of 5 times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Main results</head><p>We study the fixer's repair accuracy on GitHub-Python and DeepFix. Here "round k accuracy" means the repair accuracy of the fixer learned in round k, i.e., f k . <ref type="table" target="#tab_3">Table 1</ref> shows the test results on GitHub-Python. We show the overall repair accuracy ("Total") as well as the breakdown over the error categories in the Python AST parser <ref type="table">(table right)</ref>. The initial fixer f 0 ("Initial") is trained on randomly perturbed, synthetic bad code. Our proposed method (BIFI) enables the initial fixer to be further trained on real bad code and bad code generated by the learned breaker, which outperforms the initial fixer significantly: +28.5% in overall repair accuracy, and consistently  <ref type="table">Table 4</ref>. Performance comparison with backtranslation on GitHub-Python. Backtranslation is equivalent to removing two components from BIFI: (i) using the critic to verify fix / break attempts ("critic") and (ii) training the fixer on real bad examples in addition to examples generated by the breaker ("real bad"). The result suggests that both of these components improve the learning of a fixer, and consequently BIFI outperforms backtranslation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GitHub-Python.</head><p>across all error categories. This result suggests that even if we start from a very simple initial fixer trained with random perturbations, BIFI can automatically turn it into a usable fixer with high repair accuracy-90.5% accuracy on real bad code. We also experimented with continuing training the initial fixer f 0 with synthetic perturbations only, for the same rounds of BIFI (hence, controlling the amount of training data seen by the fixer); however, this did not provide an improvement, suggesting that there is a performance ceiling if we only train on synthetic data.</p><p>DeepFix. <ref type="table">Table 2</ref> shows the test results on DeepFix, along with prior works. Here we use the existing best system DrRepair as our initial fixer ("Initial"). BIFI outperforms the initial fixer by a substantial margin (+5.6% absolute over DrRepair), attaining a new state-of-the-art accuracy of 71.7%. It is notable that DrRepair was trained with manually-designed heuristic perturbations, where the authors <ref type="bibr">(Yasunaga &amp; Liang, 2020)</ref> mimicked various code errors beginner and experienced programmers make (e.g., typos, punctuation and type errors). Nevertheless, our result suggests that there is still room for improving the adaptation to a more realistic distribution of coding errors, and BIFI  <ref type="figure">Figure 4</ref>. Example of breaker outputs. Given good code on the left, we sampled two outputs made by the breaker learned in BIFI round 1 (right). We observe that the breaker places high probability on errors seen in real bad code (i.e., obsolete usage of raise, unbalanced parentheses in nested context).  <ref type="figure">Figure 5</ref>. Example of fixer outputs. Given the bad code on the left (with an indentation error), the initial fixer (center) attempts to fix it by inserting an indent token ( I ) to line 3, but fails to adjust (delete) the indent token on the next line. The initial fixer commonly makes this mistake due to the distribution mismatch between real errors and synthetic perturbations on which the initial fixer was trained (see ?4.3.4). After one round of BIFI, the fixer in round 1 (right) learns to insert and delete the correct pair of indent tokens, fixing the error.</p><p>boosts repair accuracy without additional manual effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Analysis</head><p>We now analyze the key insights of BIFI. As the main properties of BIFI are to (i) add real bad examples to the training data if the critic accepts the fixer's output (the FixerOnly version), and to (ii) train the breaker to generate realistic bad examples (BIFI), we analyze their effects in ?4.3.1 and ?4.3.2. We also compare with backtranslation in ?4.3.3. We then analyze how our fixer adapts towards real code distributions through quantitative and qualitative studies ( ?4.3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Effect of real bad examples</head><p>FixerOnly enables training the fixer on real bad examples (but does not use the bad examples generated by the breaker).</p><p>As <ref type="table" target="#tab_3">Table 1</ref> and 2 show, FixerOnly outperforms the initial fixer by a large margin, e.g., +27% on GitHub-Python. This result highlights the importance of training on real bad examples.</p><p>We further analyze the effect of varying the amount of real bad examples, shown in <ref type="table">Table 3</ref>. Here, "Bad 100%" is our original setting (with 23K real bad examples available for BIFI and FixerOnly) and "Bad 50%" means only 50% of them (11.5K) are made available. "Synthetic bad only" means keeping training the fixer on synthetic bad examples only. We find that while the repair accuracy drops as we decrease the amount of available real bad examples, a small amount of real bad examples (e.g., "Bad 10%") is still useful,  <ref type="table">Table 5</ref>. Code error categories in GitHub-Python, and repair accuracy. Due to the mismatch between real errors and synthetic perturbations used for training, the initial fixer has lower accuracy on "nested" than "not nested" for "unbalanced parentheses" errors, but it catches up in BIFI round 1, 2. Similarly, the initial fixer's repair accuracy is very low for "redundant parenthesis pair" and "indentation error", but it improves significantly in round 1, 2. This result illustrates the effect of BIFI adapting the fixer towards real errors. See ?4.3.4 for more analysis.</p><p>making FixerOnly perform better than using synthetic data alone (i.e., 78.5% vs 62.7%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Effect of bad examples generated by breaker</head><p>Recall that BIFI trains the fixer on both real bad examples and bad examples generated by the learned breaker. As <ref type="table" target="#tab_3">Table 1</ref> and 2 show, BIFI consistently provides an extra boost over FixerOnly, suggesting that the use of breaker outputs improves the fixer. Moreover, another benefit of the breaker is that one can sample many bad examples from the breaker to augment real bad examples, if their amount is limited.</p><p>In <ref type="table">Table 3</ref> we find that BIFI is especially stronger than FixerOnly when the amount of available real bad examples is small (e.g., "Bad 10%"). <ref type="figure">Figure 4</ref> shows sample outputs made by the learned breaker b 1 given the good code on the left. We observe that the breaker places high probability on errors seen in real bad code, i.e., obsolete usage of raise in Python3 (center) and unbalanced parentheses in nested context (right). Compared to random perturbations that arbitrarily drop/insert tokens, the learned breaker improves the coverage and efficiency of the training data for the fixer. <ref type="table">Table 4</ref> compares our method (BIFI) with backtranslation. As discussed in ?3.3, backtranslation is equivalent to removing two components from BIFI: (i) using the critic to verify fix/break attempts in data generation ("critic" in <ref type="table">Table)</ref> and (ii) training the fixer on real bad examples besides examples generated by the breaker ("real bad"). We find that removing each component from BIFI hurts the performance (e.g., 90%?84%), which suggests that both components are important to improve the quality of training data. With these two innovations, BIFI outperforms backtranslation by a large margin (+10% absolute on GitHub-Python).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">Comparison with backtranslation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4.">How does the fixer adapt?</head><p>We take a closer look at how our fixer performs and adapts towards the real distribution of bad code. <ref type="table">Table 5</ref> shows fine-grained categories of code errors seen in GitHub-Python, and their repair accuracy.</p><p>In this categorization, we observe two examples of distribution mismatch between the real errors and synthetic perturbations: (i) random perturbations can generate this category of errors with high probability but with a wrong "sub-distribution" within it (e.g., can generate "unbalanced parentheses" or "missing comma" errors but do not match the low-level distribution of real bad code, such as errors occurring more often in nested parentheses or in a multi-line list/tuple/dict; recall the Figure 2 top example); (ii) random perturbations can only generate this category of errors with very small probability (e.g., "redundant parenthesis pair" and "indentation error", for which an exact pair of parentheses or indents/dedents need to be dropped or inserted; recall the <ref type="figure">Figure 2</ref> bottom example). For (i), the result shows that the initial fixer trained with random perturbations has lower accuracy on "nested" than "not nested" for "unbalanced parentheses" errors, and on "multi-line" than "single-line" for "missing comma" errors; but the performance catches up in round 1, 2, suggesting the effect of BIFI for addressing the low-level distribution mismatch. For (ii), the result shows that the initial fixer's repair accuracy is very low for "redundant parenthesis pair" and "indentation error", but it achieves significantly higher performance in round 1, 2 (e.g., 39%?85% for indentation errors). A possible explanation is that as BIFI iteratively adds the successfully repaired cases to training, the fixer adapts to up-weight this category of error fixing, leading to improved accuracy. <ref type="figure">Figure 5</ref> provides examples of fixer outputs. Given the bad code on the left (with an indentation error), the initial fixer (center) attempts to fix it by inserting an indent token ( I ) to line 3 but fails to adjust (delete) the indent token on the following line. The initial fixer commonly makes this mistake for indentation errors, due to the mismatch between real errors and synthetic perturbations discussed above.</p><p>After one round of BIFI, the fixer <ref type="figure">(Figure 5</ref> right) learns to insert and delete the correct pair of indents, fixing the error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related work and discussion</head><p>Learning to repair code. Several works learn to repair code from labeled datasets of source code edits made by programmers, e.g., error resolution records <ref type="bibr" target="#b26">(Just et al., 2014;</ref><ref type="bibr" target="#b9">Chen et al., 2019;</ref><ref type="bibr" target="#b41">Mesbah et al., 2019;</ref><ref type="bibr" target="#b4">Bader et al., 2019;</ref><ref type="bibr" target="#b58">Tarlow et al., 2020;</ref><ref type="bibr">Ding et al., 2020)</ref>. As labeled data is costly to prepare, various works study learning code fixers from unlabeled or synthetic data <ref type="bibr" target="#b49">(Pu et al., 2016;</ref><ref type="bibr">Parihar et al., 2017;</ref><ref type="bibr" target="#b0">Ahmed et al., 2018;</ref><ref type="bibr" target="#b48">Pradel &amp; Sen, 2018;</ref><ref type="bibr" target="#b64">Wang et al., 2018;</ref><ref type="bibr" target="#b60">Vasic et al., 2019;</ref><ref type="bibr" target="#b17">Gupta et al., 2019;</ref><ref type="bibr" target="#b19">Hajipour et al., 2019;</ref><ref type="bibr">Hellendoorn et al., 2020)</ref>. In particular, <ref type="bibr" target="#b16">Gupta et al. (2017)</ref> is an early work that randomly perturbs good code to prepare a synthetic paired data and trains a seq2seq neural network model as a fixer. <ref type="bibr">Yasunaga &amp; Liang (2020)</ref> improve on it by designing heuristic perturbations that mimic common errors made by programmers. Different from the above work, our method (BIFI) adapts a naive fixer trained with synthetic errors towards real errors without manual, domain-specific effort. For a more comprehensive review of automatic code repair, we refer readers to <ref type="bibr" target="#b43">Monperrus (2020)</ref>.</p><p>Denoising autoencoding. Denoising autoencoding <ref type="bibr" target="#b63">(Vincent et al., 2008)</ref> trains a model that recovers original data from randomly corrupted versions, and is widely used as an effective self-supervised representation learning and pretraining strategy, e.g., in computer vision <ref type="bibr" target="#b13">(Erhan et al., 2010)</ref> and natural language processing (NLP) <ref type="bibr">(Lewis et al. (2020)</ref>, which randomly drops / replaces tokens in a sentence and learns to recover). Our initial fixer trained with random perturbations is a denoising autoencoder. Crucially, instead of using it purely for representation learning, we show that through the BIFI algorithm, one can turn the vanilla denoising autoencoder into a usable fixer that repairs real-world bad examples with high accuracy. On a related note, <ref type="bibr" target="#b36">Lee et al. (2019)</ref> adapt a denoising autoencoder into an autocomplete system.</p><p>Domain adaptation. Domain adaptation aims to address the mismatch in data distribution between training and test domains <ref type="bibr" target="#b10">(Daume III &amp; Marcu, 2006;</ref><ref type="bibr" target="#b50">Quionero-Candela et al., 2009;</ref><ref type="bibr">Koh et al., 2021)</ref>. Such domain shifts typically occur across related but different datasets <ref type="bibr" target="#b59">(Torralba &amp; Efros, 2011;</ref><ref type="bibr" target="#b14">Fang et al., 2013;</ref><ref type="bibr" target="#b62">Venkateswara et al., 2017;</ref><ref type="bibr" target="#b74">Yu et al., 2018b;</ref><ref type="bibr" target="#b47">Peng et al., 2019;</ref><ref type="bibr">Kamath et al., 2020)</ref>, as well as from synthetic data to real data (including sim2real) <ref type="bibr" target="#b65">(Wang et al., 2015;</ref><ref type="bibr" target="#b15">Ganin &amp; Lempitsky, 2015;</ref><ref type="bibr" target="#b51">Richter et al., 2016;</ref><ref type="bibr" target="#b46">Peng et al., 2018;</ref><ref type="bibr" target="#b21">Hellendoorn et al., 2019;</ref><ref type="bibr">Xu et al., 2020;</ref><ref type="bibr" target="#b5">Bellemare et al., 2020)</ref>, as synthetic data can be easier to obtain than real data. In our repair task, unpaired real data (code snippets on GitHub) is available but paired real data is costly to obtain. Hence we considered adaptation from synthetic paired data to real paired data. Within domain adaptation, our task is also related to the setting where unlabeled data in the test domain is available <ref type="bibr" target="#b55">(Sun &amp; Saenko, 2016;</ref><ref type="bibr" target="#b23">Hoffman et al., 2018;</ref><ref type="bibr">Sun et al., 2020)</ref> (in our case, real bad code). The difference is that as our outputs are structured, we have a critic to check if the fixer's output on the unlabeled data is correct. Leveraging this property, BIFI takes the correct outputs to create training data in the test domain (Eq 6); and trains a breaker to generate more data that simulates the test domain (Eq 8).</p><p>Data augmentation. Data augmentation aims to generate extra training data. A common approach is to increase the source side data, for instance by adding modifications or sampling from generative models <ref type="bibr" target="#b20">(Hannun et al., 2014;</ref><ref type="bibr" target="#b24">Jia &amp; Liang, 2016;</ref><ref type="bibr" target="#b30">Krizhevsky et al., 2017;</ref><ref type="bibr" target="#b1">Antoniou et al., 2017;</ref><ref type="bibr" target="#b72">Yasunaga et al., 2018;</ref><ref type="bibr" target="#b73">Yu et al., 2018a;</ref><ref type="bibr" target="#b36">Lee et al., 2019;</ref><ref type="bibr" target="#b7">Berthelot et al., 2019;</ref><ref type="bibr">Xie et al., 2020)</ref>. Several works also study target side augmentation, which keeps multiple (valid) target predictions made by a model and adds to training. This is commonly used in structured generation problems such as semantic parsing, program synthesis and molecule generation <ref type="bibr" target="#b6">Berant et al., 2013;</ref><ref type="bibr">Guu et al., 2017;</ref><ref type="bibr" target="#b42">Min et al., 2019;</ref><ref type="bibr">Zhong et al., 2020;</ref><ref type="bibr">Yang et al., 2020)</ref>. While our method also augments training data, it differs in two aspects: 1) we use the fixer and breaker to augment both the source and target sides; 2) our goal is not only to increase the amount of training data, but also to adapt to the distribution of interest (real bad examples).</p><p>Self-training. Self-training <ref type="bibr" target="#b35">(Lee, 2013;</ref><ref type="bibr" target="#b40">McClosky et al., 2006;</ref><ref type="bibr">Kumar et al., 2020;</ref><ref type="bibr">Xie et al., 2021</ref>) applies a trained model to unlabeled data, obtains predicted targets (pseudolabels), and uses them as extra training examples. Similarly, co-training <ref type="bibr" target="#b8">(Blum &amp; Mitchell, 1998)</ref> and tri-training <ref type="bibr" target="#b78">(Zhou &amp; Li, 2005)</ref> train multiple models and add predicted targets on which these models agree. Our method also applies trained models (breaker and fixer) to unlabeled data to generate targets, with a difference that we use the critic to verify the predictions and only keep correct ones.</p><p>Unsupervised machine translation (MT). Unsupervised MT learns translators from unpaired corpora <ref type="bibr" target="#b2">(Artetxe et al., 2018a;</ref><ref type="bibr">Lachaux et al., 2020)</ref>. Backtranslation <ref type="bibr" target="#b52">(Sennrich et al., 2016;</ref><ref type="bibr" target="#b33">Lample et al., 2018a;</ref> is a common approach that uses the target-to-source model to generate noisy sources and then trains the source-to-target model to reconstruct the targets (also related to cycle-consistency <ref type="bibr" target="#b79">(Zhu et al., 2017;</ref><ref type="bibr" target="#b23">Hoffman et al., 2018)</ref> and style transfer <ref type="bibr" target="#b54">(Shen et al., 2017;</ref><ref type="bibr">Yang et al., 2018;</ref><ref type="bibr" target="#b76">Zhang et al., 2019)</ref>). One may view the "bad-side" and "good-side" in our repair task as two source/ target languages in MT and apply backtranslation. The main difference is that the repair task has a critic, which motivated our BIFI algorithm: BIFI (i) uses the critic to verify if the generated examples are actually fixed or broken (Eq 6, 8), and (ii) trains the fixer on real bad examples besides examples generated by the breaker (Eq 9). We found these techniques improve the correctness of the generated training data ( ?4.3.3). While we focused on code repair in this work, we hope that BIFI can be applied to unsupervised MT and style transfer by introducing a human-based or learned critic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We considered the problem of learning a fixer from unpaired data and a critic (code analyzer or compiler), and proposed a new approach, Break-It-Fix-It (BIFI). The idea of BIFI is to train a breaker and use the critic to amass more realistic and correct paired data for training the fixer. Using two code repair datasets (GitHub-Python and DeepFix), we showed how BIFI adapts baseline fixers towards realistic distributions of code errors, achieving improved repair performance. We note that BIFI is not about simply collecting more training data, but rather turning raw unlabeled data into usable paired data with the help of a critic. This is a potentially powerful and general framework applicable to many areas such as molecular design, text editing, and machine translation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>For convenience, we call the original examples in D bad real bad examples. Here Eq 6 applies the current fixer f k?1 to the real bad examples in D bad , and keeps outputs that are actually fixed (verified by the critic c; red part). This way, we can obtain new paired data P (f ) k that is based on real bad examples. Eq 7 then trains the breaker b k (fine-tunes from the previous breaker b k?1 ) on this new paired data P (f ) k so that intuitively it can learn to generate realistic bad examples. Next, Eq 8 applies the breaker b k to the good examples in D good , and keeps outputs that are actually broken (verified by the critic c; red part). This provides an extra paired data P (b) k that is based on bad examples generated by the learned breaker. Finally, Eq 9 trains the fixer f k (fine-tunes from the previous fixer f k?1 ) on both P (f ) k and P (b) k , so that the fixer sees real and breakergenerated bad examples. Over time, this cycle adapts the fixer and breaker towards the distribution of real examples. Figure 3 (bottom right) provides an illustration of BIFI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Repair accuracy on the GitHub-Python test set.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Test accuracy</cell><cell></cell></row><row><cell>Method</cell><cell></cell><cell cols="2">Total Unbalanced Parentheses</cell><cell>Indentation Error</cell><cell>Invalid Syntax</cell></row><row><cell>Initial</cell><cell>Round-0</cell><cell>62.0%</cell><cell>87.7%</cell><cell>39.4%</cell><cell>70.5%</cell></row><row><cell>FixerOnly</cell><cell>Round-1 Round-2</cell><cell>86.8% 88.6%</cell><cell>93.3% 92.4%</cell><cell>79.5% 83.7%</cell><cell>90.9% 92.0%</cell></row><row><cell>BIFI</cell><cell>Round-1 Round-2</cell><cell cols="2">88.0% 90.5% 94.2% 94.1%</cell><cell>81.3% 85.9%</cell><cell>91.6% 93.5%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Acc. Round-2 Acc. Round-1 Acc. Round-2 Acc.</figDesc><table><row><cell cols="6">Break-It-Fix-It: Unsupervised Learning for Program Repair</cell><cell></cell></row><row><cell cols="4">Code error category Round-1 Total Initial #Examples Round-0 Acc. 15055 62.0% 86.8%</cell><cell>FixerOnly</cell><cell>92.4%</cell><cell>88.0%</cell><cell>BIFI</cell><cell>90.5%</cell></row><row><cell>Unbalanced Parentheses</cell><cell>3999</cell><cell>87.7%</cell><cell>93.3%</cell><cell></cell><cell>92.4%</cell><cell>94.1%</cell><cell>94.2%</cell></row><row><cell>Unclosed left parenthesis (not nested)</cell><cell>226</cell><cell>92.5%</cell><cell>94.6%</cell><cell></cell><cell>94.6%</cell><cell>94.7%</cell><cell>94.4%</cell></row><row><cell>Unclosed left parenthesis (nested)</cell><cell>3014</cell><cell>85.8%</cell><cell>92.8%</cell><cell></cell><cell>91.7%</cell><cell>93.8%</cell><cell>93.8%</cell></row><row><cell>Redundant right parenthesis</cell><cell>759</cell><cell>93.8%</cell><cell>95.3%</cell><cell></cell><cell>94.7%</cell><cell>95.4%</cell><cell>95.7%</cell></row><row><cell>Indentation Error</cell><cell>6307</cell><cell>39.4%</cell><cell>79.5%</cell><cell></cell><cell>83.7%</cell><cell>81.3%</cell><cell>85.9%</cell></row><row><cell>Expected indent</cell><cell>4311</cell><cell>46.4%</cell><cell>81.2%</cell><cell></cell><cell>84.1%</cell><cell>82.0%</cell><cell>85.3%</cell></row><row><cell>Unexpected indent</cell><cell>1966</cell><cell>24.6%</cell><cell>76.8%</cell><cell></cell><cell>83.8%</cell><cell>80.9%</cell><cell>88.4%</cell></row><row><cell>Invalid Syntax</cell><cell>4749</cell><cell>70.5%</cell><cell>90.9%</cell><cell></cell><cell>92.0%</cell><cell>91.6%</cell><cell>93.5%</cell></row><row><cell>Missing colon</cell><cell>663</cell><cell>98.3%</cell><cell>97.3%</cell><cell></cell><cell>97.4%</cell><cell>98.2%</cell><cell>98.0%</cell></row><row><cell>Missing comma (single-line list/tuple/dict)</cell><cell>694</cell><cell>95.4%</cell><cell>98.1%</cell><cell></cell><cell>97.4%</cell><cell>98.4%</cell><cell>98.3%</cell></row><row><cell>Missing comma (multi-line list/tuple/dict)</cell><cell>451</cell><cell>88.9%</cell><cell>92.5%</cell><cell></cell><cell>92.0%</cell><cell>94.5%</cell><cell>94.9%</cell></row><row><cell>Missing newline</cell><cell>52</cell><cell>84.6%</cell><cell>86.5%</cell><cell></cell><cell>88.5%</cell><cell>86.5%</cell><cell>88.5%</cell></row><row><cell>Missing parenthesis pair</cell><cell>634</cell><cell>82.5%</cell><cell>85.0%</cell><cell></cell><cell>86.4%</cell><cell>87.1%</cell><cell>88.3%</cell></row><row><cell>Redundant comma</cell><cell>152</cell><cell>73.7%</cell><cell>84.2%</cell><cell></cell><cell>91.4%</cell><cell>84.9%</cell><cell>92.1%</cell></row><row><cell>Redundant parenthesis pair</cell><cell>698</cell><cell>13.8%</cell><cell>80.7%</cell><cell></cell><cell>86.1%</cell><cell>80.1%</cell><cell>89.4%</cell></row><row><cell>Invalid use of comma (e.g., "raise OSError, "msg"" ? "raise OSError("msg")")</cell><cell>1138</cell><cell>61.3%</cell><cell>98.8%</cell><cell></cell><cell>99.1%</cell><cell>98.7%</cell><cell>99.4%</cell></row><row><cell>Other</cell><cell>267</cell><cell>60.7%</cell><cell>66.3%</cell><cell></cell><cell>64.4%</cell><cell>67.4%</cell><cell>66.7%</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Stanford University, Stanford, CA. Correspondence to: Michihiro Yasunaga &lt;myasu@cs.stanford.edu&gt;.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We constrain the edit distance as described in ?4.1. We acknowledge that while we want f (x) to be semantics-preserving, it is nontrivial to ensure this automatically, so we rely on the edit distance.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://bitbucket.org/iiscseal/deepfix</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Michael Xie, members of the Stanford P-Lambda, SNAP and NLP groups, as well as our anonymous reviewers for valuable feedback. This work was supported in part by Funai Foundation Fellowship and NSF CAREER Award IIS-1552635.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility</head><p>Code and data are available at https://github.com/ michiyasunaga/bifi. Experiments are available at https://worksheets.codalab.org/worksheets/ 0xfddb2ef01a9f4dc0b5d974a5a97174be.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Compilation error repair: for the student programs, from the student programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">Z</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karkare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="78" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04340</idno>
		<title level="m">Data augmentation generative adversarial networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Unsupervised statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agirre</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1809.01272</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to fix bugs automatically</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pradel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Getafix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Programming Languages</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Autonomous navigation of stratospheric balloons using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Candido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Ponda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">588</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mixmatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Combining labeled and unlabeled data with co-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on computational learning theory</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sequencer: Sequence-to-sequence learning for end-to-end program repair</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Kommrusch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tufano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-N</forename><surname>Pouchet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Poshyvanyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Domain adaptation for statistical classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial Intelligence research</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning graph transformations to detect and fix bugs in programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoppity</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Patching as translation: the data and the metaphor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Devanbu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J</forename><surname>Hellendoorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Software Engineering (ASE)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics (AISTATS)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="201" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Rockmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deepfix: Fixing common C language errors by deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Shevade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for programming language correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shevade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">From language to programs: Bridging reinforcement learning and maximum marginal likelihood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Break-It-Fix-It: Unsupervised Learning for Program Repair Guu</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics (ACL)</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Samplefix</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.10502</idno>
		<title level="m">Learning to correct programs by sampling diverse fixes</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Deep speech: Scaling up end-to-end speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Case</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Prenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.5567</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">When code completion fails: A case study on real-world completions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J</forename><surname>Hellendoorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Proksch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bacchelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Global relational models of source code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J</forename><surname>Hellendoorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Maniatis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cycada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Data recombination for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning multimodal graph-to-graph translation for molecular optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Defects4j: A database of existing faults to enable controlled testing studies for java programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Just</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 International Symposium on Software Testing and Analysis</title>
		<meeting>the 2014 International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="437" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Selective question answering under domain shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Wilds: A benchmark of in-the-wild distribution shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Balsubramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Beery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Understanding selftraining for gradual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Unsupervised translation of programming languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roziere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unsupervised machine translation using monolingual corpora only</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Phrase-based &amp; neural unsupervised machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semisupervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning autocomplete systems as a communication game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS) Workshop on Emergent Communication</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Binary codes capable of correcting deletions, insertions, and reversals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Soviet physics doklady</title>
		<imprint>
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning dependencybased compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Effective self-training for parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deepdelta: learning to repair compilation errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mesbah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Glorioso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aftandilian</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</title>
		<meeting>the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="925" to="936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A discrete hard em approach for weakly supervised question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The living review on automated program repair</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
		<idno>hal-01956501. HAL/archives- ouvertes.fr.</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Automatic grading and feedback using program repair for introductory programming courses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dadachanji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Praveen Kumar Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Karkare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Innovation and Technology in Computer Science Education</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Break-It-Fix-It: Unsupervised Learning for Program Repair Parihar,</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Visda: A synthetic-to-real benchmark for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Usman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Moment matching for multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deepbugs: A learning approach to name-based bug detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pradel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Programming Languages</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">OOPSLA</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">sk p: a neural program corrector for moocs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the 2016 ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="39" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Dataset shift in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quionero-Candela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schwaighofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Programmers&apos; build errors: A case study at google</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sadowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Elbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Aftandilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bowdidge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Style transfer from non-parallel text by cross-alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Test-time training for out-of-distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A neural approach to automated essay scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Taghipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning to fix build errors with graph2diff neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aftandilian</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops</title>
		<meeting>the IEEE/ACM 42nd International Conference on Software Engineering Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="19" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Unbiased look at dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Neural program repair by jointly learning to localize and repair</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Maniatis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5018" to="5027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Dynamic neural program embeddings for program repair</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Building a semantic parser overnight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">In-n-out: Pre-training and self-training using auxiliary information for out-of-distribution robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Khani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">From databases to qa semantic parsers with only synthetic training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Semnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Campagna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autoqa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Improving molecular design by stochastic iterative target augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Unsupervised text style transfer using language models as discriminators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Break-It-Fix-It: Unsupervised Learning for Program Repair Yang</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems (NeurIPS)</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Graph-based, self-supervised program repair from diagnostic feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Robust multilingual part-of-speech tagging via adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Syntaxsqlnet: Syntax tree networks for complex and cross-domaintext-to-sql task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Cross-domain semantic parsing in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">V</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Er</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Style transfer as unsupervised machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Grounded adaptation for zero-shot executable semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Tri-training: Exploiting unlabeled data using three classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
