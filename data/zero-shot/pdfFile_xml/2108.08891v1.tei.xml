<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural TMDlayer: Modeling Instantaneous flow of features via SDE Generators</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Meng</surname></persName>
							<email>zihangm@cs.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Singh</surname></persName>
							<email>vsingh@biostat.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sathya</forename><forename type="middle">N</forename><surname>Ravi</surname></persName>
							<email>sathya@uic.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neural TMDlayer: Modeling Instantaneous flow of features via SDE Generators</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study how stochastic differential equation (SDE) based ideas can inspire new modifications to existing algorithms for a set of problems in computer vision. Loosely speaking, our formulation is related to both explicit and implicit strategies for data augmentation and group equivariance, but is derived from new results in the SDE literature on estimating infinitesimal generators of a class of stochastic processes. If and when there is nominal agreement between the needs of an application/task and the inherent properties and behavior of the types of processes that we can efficiently handle, we obtain a very simple and efficient plug-in layer that can be incorporated within any existing network architecture, with minimal modification and only a few additional parameters. We show promising experiments on a number of vision tasks including few shot learning, point cloud transformers and deep variational segmentation obtaining efficiency or performance improvements.</p><p>What does z(t) actually represent? There are two interpretations of z(t): (i) it formalizes on-the-fly or instan-arXiv:2108.08891v1 [cs.CV]  </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Consider a deep neural network model with parameters W which we train using the following update rule,</p><formula xml:id="formula_0">W ? W ? ?? W E z R (W, z)<label>(1)</label></formula><p>where z is a random variable representing data and R(?) represents the loss function. Now, consider a slightly general form of the same update formula,</p><formula xml:id="formula_1">W ? W ? ?? W E z R (W, T z) .<label>(2)</label></formula><p>The only change here is the introduction of T which can be assumed to be some data transformation matrix. If T = I, we see that Stochastic Gradient Descent (SGD) is a special case of <ref type="bibr" target="#b1">(2)</ref> under the assumption that we approximate the expectation in <ref type="bibr" target="#b1">(2)</ref> with finite iid samples (or a mini-batch). Let us unpack the data transformation notation a bit to check what it offers. If a set of transformations T are chosen beforehand, and applied to the data samples before training commences, T z simply represents data samples derived via data augmentation. On the other hand, T z may not necessarily be explicitly instantiated as above. For example, spherical CNN <ref type="bibr" target="#b15">[16]</ref> shows that when point cloud type data are embedded on the sphere with spherical convolutional operators, then it is possible to learn representations of data that are equivariant to the group action of rotations with no explicit data augmentation procedure. In particular, these approaches register each data point on a standard template (like the sphere) on which efficient convolutions can be defined based on differential geometric constructions -in other words, utilizing the properties of the transformations T of interest and how they relate the data points, such a treatment enables the updates to implicitly take into account the loss on T z. Conceptually, many results <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b48">48,</ref><ref type="bibr" target="#b42">42]</ref> on equivariance show that by considering the entire orbit of each sample (a 3D point cloud) during training, for special types of T , it is possible to avoid explicit data augmentation.</p><p>We can take a more expanded view of the above idea. Repeated application of a transformation T on data point z produces a discrete sequence {z(t)} ? t=0 where z(0) = z, z(t) = T t?1 z. In general, the transformation matrix at the t-th step, denoted by T (t), need not even be generated from a fixed matrix. Indeed, in practice T (t) is selected from a set of appropriate transformations such as rotation, blur and so on, with some ordering, which could even be stochastic. At a high level, approaches such as <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b11">12]</ref> can be seen as a special case of <ref type="bibr" target="#b1">(2)</ref>. Making this argument precise needs adding an appropriate number of auxiliary variables and by averaging over all possible realizable T 's -the specific steps are not particularly relevant since apart from helping set up the intuition we just described, algorithms for equivariance to specific group actions do not directly inform our development. For the sake of convenience, we will primarily focus on the continuous time system since under the same initial conditions, the trajectories of both (continuous and discrete) systems coincide at all integers t. cloud learning and segmentation. "EGNN" refers to edge-labeling graph neural network <ref type="bibr" target="#b24">[25]</ref>; "FF" refers to feed-forward layer (10) and "CV" refers to our proposed deep Chan Vese model <ref type="bibr" target="#b11">(12)</ref>. The manifold (top) describes the meaning of L and Lm: L captures the structure of the manifold. Lm is an approximation of L constructed from samples. taneous (smooth) data augmentation which are often used to accelerate training by exploiting symmetries in the landscape of R, and (ii) a data dependent T can be designed for invariance-like requirements, useful for downstream applications. In fact, learning data dependent transformations has also been explored by <ref type="bibr" target="#b13">[14]</ref>. The starting point of this work is to exploit the view that the data sample provided to us is merely a snapshot of an underlying process which we will discuss shortly. Nonetheless, the key hypothesis is that specifying this process to our deep neural network model will be beneficial and provide a fresh perspective on some strategies that are already in use in the literature.</p><p>Main ideas. The foregoing use of "process" to describe the data sample hints at the potential use of an ordinary differential equations (ODE). While ODE type constructions can be used to characterize simple processes, it will be insufficient to model more complex processes that will better reflect practical considerations. The key challenge in directly instantiating the "z(t)" idea for SDEs is that it is clearly infeasible since there are infinite possible tra-jectories for the same initial conditions. Our main insight is that recent results in the SDE literature show that (under some technical conditions), the dynamics z(t) can be completely characterized by (functions of) the infinitesimal generator L of the process z(t) which can be efficiently estimated using finite data. We exploit this result via a simple modification to the estimation procedure -one that can be directly used within any backpropagation based training scheme. Specifically, we exploit the result from <ref type="bibr" target="#b1">[2]</ref> where the authors call the generator Target Measure Diffusion map (TMDmap). This leads to our TMDlayer that can be conveniently dropped into a network, and be used as a plug-and-play module with just a few additional parameters. When utilized within standard deep learning pipelines, our layer allows incorporating much richer domain information if available, or as a regularizer or an augmentation scheme, or as a substitute to an existing layer. We find this is beneficial to the overall performance of the model.</p><p>Our contributions. Models such as a Neural ODE <ref type="bibr" target="#b9">[10]</ref> and Neural SDE <ref type="bibr" target="#b34">[34]</ref> usually parameterize the dynamical system as a stand-alone model, and show how gradients can be efficiently backpropagated through this module. We take a different line of approach: we propose a stochastic process inspired layer which, in its most rudimentary form, can be thought of as an augmentation scheme that can work with existing layers in deep neural networks. But different from explicit data augmentation (rotation, flipping) that happens in the input image space, our layer can be utilized in the feature space and is fully adaptive to the input. But it is more than another augmentation scheme. Our layer allows modeling the time varying/stochastic property of the data/features, and controls them by a proper parameterization which is highly parameter efficient. We show that this stochasticity is not only mathematically interesting, but can be exploited in applications including point cloud transformers, object segmentation and few-shot recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related Work.</head><p>Early work in vision has made extensive use of differential equations <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b5">6]</ref>, especially for segmentation. In machine learning, differential equations are useful for manifold learning <ref type="bibr" target="#b2">[3]</ref> and semi-supervised learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b38">38]</ref> among others. Recently, a number of strategies combine differential equations with deep neural networks (DNNs) for solving vision problems. For example, <ref type="bibr" target="#b8">[9]</ref> utilizes a conditional random field after the CNN encoder to refine the semantic segmentation results whose update rules can be viewed as a differential equation and <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b21">22]</ref> uses a CNN to extract visual features before feeding them to an active contour model which iteratively refines the contour according to the differential equation. Separately, the literature includes strategies for solving differential equations with DNNs <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b31">32]</ref>. Over the last few years, a num-ber of formulations including neural ODE <ref type="bibr" target="#b9">[10]</ref>, neural SDE <ref type="bibr" target="#b34">[34]</ref> and augmented neural ODE <ref type="bibr" target="#b14">[15]</ref> have been proposed, motivated by the need to solve differential equation modules within DNNs. Note that <ref type="bibr" target="#b34">[34]</ref> proposes to stabilize the neural ODE network with stochastic noise, which leads to a neural SDE, a setting quite different from the one studied here. Finally, we note that SDEs as a tool have also been used for stochastic analysis of DNNs <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>Background. Partial differential equation (PDE) is a functional equation in which the solution satisfies given relations between its various partial derivatives interpreted as multivariable functions. Consider a commonly used PDE model for segmentation -the heat equation, ?u ?t = ?u, where u depends on both X and t. By the celebrated Feynman-Kac formula, we know that the solution u can be equivalently written as a conditional expectation with respect to a continuous time stochastic process X t . This means that the solution (segmentation) u can be obtained by averaging a sequence of stochastic integration problems. For prediction, we need an algebraic concept called the "generator" of a function (like a neural network) since we are more interested in the pushforward mappings f (X t ).</p><p>Given a time invariant stochastic process X t , the (infinitesimal) generator L of a function f is defined as,</p><formula xml:id="formula_2">Lf (X) := lim t?0 E [f (X t )] ? f (X 0 ) t .<label>(3)</label></formula><p>If the process X t is deterministic, the expectation operator E becomes identity, and so the generator L simply measures the instantaneous rate of change in f with respect to X. In addition, say that X t can also be expressed as a (It?) Stochastic Differential Equation (SDE), i.e., X t satisfies:</p><formula xml:id="formula_3">dX t = b(X t )dt + ?(X t )dW t ,<label>(4)</label></formula><p>where W t is a (multidimensional) Brownian motion with covariance C, and b, ? represent drift and diffusion functions. Then, it turns out that L can be written in closed form (without limit) as,</p><formula xml:id="formula_4">Lf = b ? ?f + ?C? T ? ? 2 f,<label>(5)</label></formula><p>where L acts as a linear operator on functions f , see <ref type="bibr" target="#b28">[29]</ref>. We will shortly explain how to estimate and utilize L.</p><p>Setup. Consider the setting where X represents our input features (say, an image as a 3D array for the RGB channels) and f is a network with L layers. Let the data be in the form of points D (m) := x 1 , x 2 , ..., x m ? R N with N &gt; 0, which lie on a compact d-dimensional differentiable submanifold M ? R N which is assumed to be unknown. We assume that f in our case is defined implicitly using samples x i ? M, and so it is impossible to obtain closed form expressions for the operators ?, ? 2 in (5). In such cases, recall that, when ? ? 0, Diffusion maps <ref type="bibr" target="#b12">[13]</ref> uncovers the geometric structure M by using D (m) to construct an m?m matrix L m as an approximation of the linear operator L.</p><p>Interpreting SDE. Recall that when L is used on the input space, it can model stochastic transformations to the input image (rotation and clipping are special cases). When L is used on the feature space (e.g., in an intermediate layer of a DNN), it can then model stochastic transformations of the features where it is hard to hand design augmentation methods. Moreover, it enables us to parameterize and learn the underlying stochastic changes/SDE of the features.</p><p>Roadmap. In the next section, we describe the estimation of differential operator L within deep network training pipelines. Based on this estimate, we define TMDlayer as a approximation to f (X ?t ) := f (X, ?t) for a small time interval ?t using Taylor's theorem. In ?4, we discuss four different applications of TMDlayer, where the pushforward measure f (X, ?t) under the flow of features (interpreted as a vector field) f (X, 0) may be a reasonable choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approximating L in Feedforward Networks</head><p>We now discuss a recently proposed nonparametric procedure to estimate L m given finite samples x when ? ? 0. This is an important ingredient because in our setup, we often do not have a meaningful model of minibatch samples, especially in the high dimensional setting (e.g., images).</p><p>Constructing L m in DNN training. The definition in (3) while intuitive, is not immediately useful for computational purposes. Under some technical conditions such as smoothness of b, ?, f , and the rank of C, <ref type="bibr" target="#b1">[2]</ref> recently showed that for processes that satisfy (4), it is indeed possible to construct finite sample estimators L m of L. In <ref type="bibr" target="#b1">[2]</ref>, the approach is called Target Measure Diffusion (TMD) so we call our proposed layer, a TMDlayer.</p><p>To construct the differential operator, we first need to compute a kernel matrix K ? R m?m from the data. For problems involving a graph or a set of points as input, we can simply use the given data points (m would be the number of nodes in the graph, or the number of points in the set), while for problems with a single input (e.g., standard image classification), we may not have access to m data points directly. In this case, we can construct the kernel matrix by sampling a batch from the dataset and processing them together because we can often assume that the entire dataset is, in fact, sampled from some underlying distribution.</p><p>After getting the set of data samples, we first project the data into a latent space R h with a suitable h using a learnable linear layer, before evaluating them with an appropriate kernel function such as,</p><formula xml:id="formula_5">k (x, y) = exp(?(4 ) ?1 x ? y 2 ).<label>(6)</label></formula><p>We then follow <ref type="bibr" target="#b1">[2]</ref> to construct the differential operator L as </p><formula xml:id="formula_6">x i ) = m j=1 (K ) ij 4 Parameterize target distribution by (7) 5 Form the diagonal matrix D ,? with components (D ,? ) ii = ? 1/2 (x i )q ?1 (x i ) 6 Use D ,? to right-normalize K : K ,? = K D ? 7 Construct Lm by (8) using (D ,? ) ii := m j=1 (K ,? ) ij 8 Return: f (X) + ?t ? Lmf (X) follows: we compute the kernel density estimate q (x i ) = m j=1 (K ) ij . Then, we form the diagonal matrix D ,? with components (D ,? ) ii = ? (1/2) (x i )q ?1 (x i ).</formula><p>Here, we allow the network to learn ? by</p><formula xml:id="formula_7">? 1/2 (x i ) = g(x i ),<label>(7)</label></formula><p>where g can be a linear layer or a MLP depending on the specific application. Next we use D ,? to right-normalize the kernel matrix K ,? = K D ,? and useD ,? which is the diagonal matrix of row sums of K ,? to left-normalize K ,? . Then we can build the TMDmap operator as</p><formula xml:id="formula_8">L m = ?1 (D ?1 ,? K ,? ? I).<label>(8)</label></formula><p>We will use (8) to form our TMDlayer as described next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">TMDlayer: A Transductive Correction via L m</head><p>Observe that (4) is very general and can represent many computer vision tasks where the density ? could be defined using a problem specific energy function, and W t is the source of noise. In other words, we aim to capture the underlying structure of the so-called image manifold <ref type="bibr" target="#b61">[61]</ref> by using its corresponding differential operator <ref type="bibr" target="#b4">(5)</ref>. Intuitively, this means that if we are provided a network f W with parameters W , then by Taylor's theorem, the infinitesimal generator estimate L m can be used to approximate the change of f W as follows:</p><formula xml:id="formula_9">E x f W (x, ?t) ? f W (x, 0) + ?t ? L m [f W ],<label>(9)</label></formula><p>where</p><formula xml:id="formula_10">[f W ] ? R m such that the i?th coordinate [f W ] i = f W (x i )</formula><p>, and ?t is interpreted as a hyperparameter in our use cases, see Algorithm 1. Inference using L m . In the ERM framework, typically, each test sample is used independently, and identically i.e., network (at optimal parameters) is used in a sequential manner for predictive purposes. Our framework allows us to further use relationships between the test samples for prediction. In particular, we can design custom choices of b, ? tailored for downstream applications. For example, in applications that require robustness to small and structured perturbations, it may be natural to consider low bias diffusion processes i.e., we can prescribe the magnitude using b p ? ? almost everywhere for some small constant ? &gt; 0 (akin to radius of perturbation) and structure using diffusion functions ?, C. Inference can then be performed using generators L derived using the corresponding process.</p><p>Layerwise L for improved estimation of L m . While (9) allows us to use L m for any network with no modifications, using it naively can be unsatisfactory in practice. For example, often we find that features from input layers might not be too informative for the task and may hinder training, especially in the early stages. We suggest a simple adjustment: instead of applying approximation in (9) on the entire network, we do it layerwise -this could be every intermediate layer or several layers of interest. It means that f can in principle be any layer (e.g., a layer in graph neural networks or a layer in Resnet), as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>Justification. Recall that most feed-forward neural networks can be completely defined by a finite sequence of linear transformations followed by activation functions (along with intermediate normalization layers). One option is to estimate L m by directly applying the Taylor series-like expansion in <ref type="formula" target="#formula_9">(9)</ref> on f = f l ? f l?1 ? ? ? ? f 1 where l represents the number of layers. However, from <ref type="bibr" target="#b8">(9)</ref> we can see that the variance of such an estimate of the value L m [f W ] will be high due to the well-known propagation of uncertainty phenomenon (across f i 's). To avoid this, we can estimate</p><formula xml:id="formula_11">L m [f W ] in a sequential manner i.e., use L m [f i?1 W ] to es- timate L m [f i W ] ? i ? [l]</formula><p>. We will show in ?4 that this parameterization can be useful in various applications.</p><p>Synopsis. We briefly summarize the benefits of our TMDlayer next: (i) Our TMDlayer can parameterize the underlying stochastic transformations of features, providing a way to augment features at any layer. (ii) The stochasticity/randomness in our TMDlayer is a stability inducing operation for robust predictive purposes <ref type="bibr" target="#b19">[20]</ref>. (iii) Our TMDlayer is parameter efficient. All we need is a projection linear layer h and a linear layer g parameterizing the density ? and a scalar parameter ?t. In practice, we can work with a small latent dimension (e.g., h = 16) when constructing L m , thus the total number of parameters in TMDlayer is very small when compared with the layer function f in most deep learning applications. But the reader will see that a mild limitation of the SDE perspective in practice is that, in principle, the dynamics may eventually get stuck in a metastable state. This means that in this case, the estimate L m will not be very informative in the forward pass, and so the gradient estimates might be biased. In such cases, it may be useful to add points by sampling on the orbit if needed. We will now describe four different vision settings where our TMDlayer can be instantiated in a plug-and-play manner.</p><p>In this section, we evaluate our TMDlayer in the context of different applications. As a warm-up, in ?4.1, we demonstrate the use of TMDlayer on a simple image classification task. We study its properties in both inductive and transductive settings. Then, in ?4.2, we move to learning with point cloud datasets. Here, we see that the data type naturally offers a suitable object for leveraging the features of TMDlayer. In this case, we conduct experiments in an inductive setting. Next, in ?4.3, we explore the use of TMDlayer on a segmentation task (also in an inductive setting). We propose a novel deep active contour model which can be viewed as a dynamical process within a neural network. We demonstrate the use of our TMDlayer on top of such a dynamical process. Finally, in ?4.4, we investigate few-shot learning.</p><p>Here, the problem setup natively provides the graph needed for computing our L m and allows transductive inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">A Simple Sanity check on Resnet</head><p>We start with a simple example of image classification on CIFAR10 <ref type="bibr" target="#b27">[28]</ref> using Resnet <ref type="bibr" target="#b22">[23]</ref>, to demonstrate applicability of our TMDlayer and evaluate its behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Role of TMDlayer: Finetuning/Robustify Resnet</head><p>We choose Resnet-18 as the backbone network and simply treat each of its three residual blocks Res as f (see <ref type="bibr" target="#b22">[23]</ref> for details of a residual block) in TMDlayer as follows,</p><formula xml:id="formula_12">f (x l?1 ) = Res(x l?1 ) =? x l = f (x l?1 )+?t?L m f (x l?1 ),</formula><p>where x l is the feature at the l-th layer and L m is constructed from a mini-batch of samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Experimental results</head><p>During training, we first sample m data points in a batch and use it as the input so that we can construct L m . During test time, an input batch also contains m samples (similar to training time), where m increases from 1 to 200. We can see from <ref type="table" target="#tab_0">Table 1</ref> that m does have an influence on the test accuracy where a larger m performs better than a smaller m. A key reason is that L m using a larger m can better capture the geometric structure of the data.</p><p>We also test whether our TMDlayer can help improve the robustness of the network. We can assess this property by adding random noise to the input image and evaluating the test accuracy (see <ref type="table" target="#tab_2">Table 2</ref>). With our TMDlayer, the network is more noise resilient. This can be partly attributed to the use of our parameterized ?t, which allows the network to control the stochastic process in the TMDlayer adaptively and dependent on the input. In summary, the performance profile is similar (Tab. 1) with small improvements in robustness (Tab. 2).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Point cloud transformer</head><p>Tasks involving learning with point cloud data is important within 3D vision. The input here is usually a 3D point cloud represented by a set of points, each associated with its own feature descriptor. These points can be naturally thought of as samples from the underlying distribution which captures the geometric structure of the object. The problem provides an ideal sandbox to study the effect of our TMDlayer. But before we do so, we provide some context for where and how the TMDlayer will be instantiated. Recently, <ref type="bibr" target="#b18">[19]</ref> proposed a transformer based model for point cloud learning which achieves state-of-the-art performance on this task -and corresponds to an effective and creative use of transformers in this setting. Nonetheless, Transformer models are known to be parameter costly (e.g., see <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b56">56,</ref><ref type="bibr" target="#b59">59]</ref> for cheaper approximations effective in NLP settings) and it is sensible to check to what extent our TMDlayer operating on a simple linear layer can be competitive with the transformer layer proposed in <ref type="bibr" target="#b18">[19]</ref>. Our goal will be to check if significant parameter efficiency is possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Problem formulation</head><p>Denote an input point cloud P ? R N ?d with N points, each with a d-dimensional feature descriptor. The classification task is to predict a class or label for the entire point cloud.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Role of TMDlayer: Replace transformer layer</head><p>The point cloud transformer layer in <ref type="bibr" target="#b18">[19]</ref> is constructed as,</p><formula xml:id="formula_13">F out = F F (F in ? F sa ) + F in ,<label>(10)</label></formula><p>where FF refers to their feed-forward layer (a combination of Linear, BatchNorm and ReLU layer), and F sa is the output of self-attention module which takes F in as an input (we refer the reader to <ref type="bibr" target="#b18">[19]</ref> for more details of their network design, also included in our appendix). A Transformer layer is effective for point cloud because it simultaneously captures the relation between features of all points. Since our TMDlayer can be viewed as a diffusion operator which captures the structure of the underlying data manifold from the data, we can check to what extent its ability suffices. We use the TMDlayer on a single feedforward layer to replace the Transformer layer in <ref type="bibr" target="#b9">(10)</ref>.</p><formula xml:id="formula_14">F out = F F (F in ) + ?t ? L m F F (F in ).<label>(11)</label></formula><p>Surprisingly, it turns out that this simple layer can perform comparably with the carefully designed Transformer layer in (10) while offering a much more favorable parameter efficiency profile. Here, L m is constructed using points of the same point cloud (setting is identical to baselines).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Experimental results</head><p>Dataset. We follow <ref type="bibr" target="#b18">[19]</ref> to conduct a point cloud classification experiment on ModelNet40 <ref type="bibr" target="#b54">[54]</ref>. The dataset contains 12311 CAD models in 40 object categories, widely used in benchmarking point cloud shape classification methods. We use the official splits for training/evaluation.</p><p>Network architecture and training details. We use the same network as <ref type="bibr" target="#b18">[19]</ref> except that we replace each point cloud transformer layer with a TMDlayer built on a single feed forward layer. We follow <ref type="bibr" target="#b18">[19]</ref> to use the same sampling strategy to uniformly sample each object via 1024 points and the same data augmentation strategy during training. The mini-batch size is 32 and we train 250 epochs using SGD (momentum 0.9, initial learning rate 0.01, cosine annealing schedule). The hidden dimension is 256 for the whole network and 16 for constructing L m (in TMDlayer).</p><p>Results. We see from <ref type="table" target="#tab_4">Table 3</ref> that our approach achieves comparable performance with <ref type="bibr" target="#b18">[19]</ref>. In terms of the number of parameters, using hidden dimension 256 (used in this experiment) as an example, one self-attention layer contains 148k parameters; one linear layer contains 65.5k parameters; and the TMDlayer module only needs 4k parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Object segmentation</head><p>Here, we show that our TMDlayer (a dynamical system) can also be built on top of another dynamical system. We do so by demonstrating experiments on object segmentation.</p><p>Recall that active contour models are a family of effective segmentation models which evolve the contour iteratively until a final result is obtained. Among many options available in the literature (e.g., <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b57">57]</ref>), the widely used  Chan-Vese <ref type="bibr" target="#b6">[7]</ref> model evolves the contour based on a variational functional. Here, we propose to combine the Chan-Vese functional with a deep network by parameterizing the iterative evolution steps and build our TMDlayer on top of it. We see that this simple idea leads to improved results. The appendix includes more details of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Problem formulation</head><p>Let ? be a bounded open subset of R 2 , where ?? is its boundary. Let I :? ? R be an image, object segmentation involves predicting a dense map in? ? 0/1 where 1 (and 0) indicates the object (and background). In our formulation, we parameterize the object contour by a level set function ? : ? ? R and evolve it within the DNN. We note that hybrid approaches using level sets together with DNNs is not unique to our work, see <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b58">58]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Role of TMDlayer: in deep active contour model</head><p>Our proposed deep active contour model evolves the contour in the form of a level set function within the network, and the update scheme is,</p><formula xml:id="formula_15">? l = ? l?1 + ?? ?t ?t ,<label>(12)</label></formula><p>where ? l?1 is the level set function at layer l ? 1 and ?? ?t is derived from our proposed deep variational functional. The appendix includes more details of our model, the variational functional, and the derivation of update equation.</p><p>Denote the update function in <ref type="bibr" target="#b11">(12)</ref> as ? l = f (? l?1 ). Then, our TMDlayer forward pass can be written as,</p><formula xml:id="formula_16">? l = f (? l?1 ) + ?t ? L m f (? l?1 ).<label>(13)</label></formula><p>Remark 1 Note that ?t in <ref type="bibr" target="#b11">(12)</ref> and the ?t in (13) correspond to two different dynamical systems. The first one Remark 2 Note that our proposed segmentation model is different from <ref type="bibr" target="#b58">[58]</ref> which uses the variational energy function directly as the final loss, whereas we are parameterizing the updating steps within our network so that the final output will already satisfy low variational energy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Experimental results</head><p>Dataset. The Vaihingen buildings dataset consists of 168 building images extracted from the training set of ISPRS "2D semantic labeling contest" with a resolution of 9cm. We use only 100 images to train the model and the remaining 68 serve as the test set. Network Architecture and Experiment Setup. We use an encoder CNN with an architecture similar to <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b37">[37]</ref>. The input is the original image. The network is trained with a learning rate of 10 ?4 for 300 epochs using a batch size of 10. We setup our baseline using the same CNN architecture to predict the segmentation mask without our Chan-Vese update module. Previous works combining active contour model and deep learning <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b33">33]</ref> often can only be used to provide segmentations of a single building based on manual initialization or another initialization (based on a separate algorithm) whereas our model can be used to segment multiple buildings in the image without any initialization. So, the results cannot be meaningfully compared. See our appendix for more details about the setup.</p><p>Results and Discussion. We use the average Intersection over Union (IoU) to evaluate the performance on Vaihingen dataset: the baseline yields 68.9 while our model without TMDlayer achieves 73.5 and our complete model with TMDlayer achieves 74.6, which is a significant improvement in terms of IoU. This experiment shows that our TMDlayer can be built on top of another dynamical system and can provide additional benefits. Qualitative results of the baseline and our model are shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. Our method tends to predict a more precise shape/boundary, and also fixes some flaws/errors relative to the baseline results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Few-shot learning</head><p>In N -way B-shot few-shot learning, the input is a set of N ? B samples which naturally forms a fully connected graph. This serves to construct the differential operator L m . To provide context for where and how our TMDlayer will be instantiated, we note that <ref type="bibr" target="#b24">[25]</ref> proposed a GNN approach (EGNN) for few-shot learning and this model achieves state-of-the-art performance. We show that by adding our TMDlayer, the performance increases by a clear margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Problem formulation</head><p>Few-shot learning classification seeks to learn a classifier given only a few training samples for every class. Each fewshot classification task T contains a support set S which is a set of labeled input-label pairs and a query set Q (an unlabeled set where the learned classifier is evaluated). Given B labeled samples for each of N classes in the support set S, the problem is a N -way B-shot classification problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Role of TMDlayer: Use in graph neural network</head><p>Let G be the graph formed by samples from the task T , with nodes denoted as V := {V i } i=1,...,|T | . The node feature update equation is designed as (we refer readers to <ref type="bibr" target="#b24">[25]</ref> or our appendix for more details about the network)</p><formula xml:id="formula_17">v l i = NodeUpdate({v l?1 i }, {e l?1 ij }; ? l v ),<label>(14)</label></formula><p>where v l i is the feature of node i at l-th layer, e ij is the edge feature between node i and node j, and ? refers to the parameters in the update function. We abstract <ref type="bibr" target="#b13">(14)</ref> as</p><formula xml:id="formula_18">v l i = f (v l?1 i</formula><p>) and use our TMDlayer as,</p><formula xml:id="formula_19">v l i = f (v l?1 i ) + ?t ? L m f (v l?1 i ).<label>(15)</label></formula><p>Remark 3 In <ref type="formula" target="#formula_0">(15)</ref>, the L m is constructed using samples from the same episode, and f is a GNN module updating the node features using all node features and edge features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Experimental results</head><p>Dataset.</p><p>We follow <ref type="bibr" target="#b24">[25]</ref> to conduct experiments on miniImageNet, proposed by <ref type="bibr" target="#b51">[51]</ref> and derived from ILSVRC-12 dataset <ref type="bibr" target="#b46">[46]</ref>. Images are sampled from 100 different classes with 600 samples per class (size 84 ? 84 pixels). We use the same splits as in <ref type="bibr" target="#b43">[43,</ref><ref type="bibr" target="#b24">25]</ref>: 64, 16 and 20 classes for training, validation and testing respectively.</p><p>Network architecture and training details. We use the same graph neural network architecture and follow the training strategy as in <ref type="bibr" target="#b24">[25]</ref> by utilizing the code provided by the authors. We add our TMDlayer as shown in <ref type="bibr" target="#b14">(15)</ref> to each node update layer in the graph neural network, with a latent dimension of 16 for constructing L m . We follow <ref type="bibr" target="#b24">[25]</ref> to conduct experiments for 5-way 5-shot learning, in both transductive and non-transductive settings, as well as for both supervised and semi-supervised settings. The network is trained with Adam optimizer with an initial learning rate of 5 ? 10 ?4 and weight decay of 10 ?6 . The learning rate is cut in half every 15000 episodes. For evaluation, each test episode was formed by randomly sampling 15 queries for each of 5 classes, and the performance is averaged over 600 randomly generated episodes from the test set. Note that the feature embedding module is a convolutional neural network which consists of four blocks (following <ref type="bibr" target="#b24">[25]</ref>) and used in most few-shot learning models without any skip connections. Thus, Resnet-based models are excluded from the table for a fair comparison. We refer the reader to <ref type="bibr" target="#b24">[25]</ref> or the appendix for more training and evaluation details.</p><p>Results. The performance of supervised and semisupervised 5-way 5-shot learning is given in Tables 4-5 respectively. Our TMDlayer leads to consistent and clear improvements in both supervised and semi-supervised settings (also for transductive/non-transductive settings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Trans. Accuracy(%) Matching Networks <ref type="bibr" target="#b51">[51]</ref> No 55.30 Reptile <ref type="bibr" target="#b40">[40]</ref> No 62.74 Prototypical Net <ref type="bibr" target="#b47">[47]</ref> No 65.77 GNN <ref type="bibr" target="#b17">[18]</ref> No 66.41 EGNN <ref type="bibr" target="#b24">[25]</ref> No   <ref type="table">Table 5</ref>: Accuracy of semi-supervised few-shot classification.</p><p>"Ours" means EGNN plus our TMDlayer.</p><p>tation and TMDLayer are complementary, not mutually exclusive. In all our experiments, the baselines use data augmentations (e.g., random rotation or cropping). Our TMD-Layer offers benefits, above and beyond augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion and Conclusions</head><p>We proposed an SDE based framework that allows a unified view of several different learning tasks in vision. Our framework is beneficial where data generation (or the data itself) can be described using stochastic processes, or more specifically diffusion operators. This is particularly useful in settings where obtaining a deterministic model of the image manifold or learning density functions are impossible or challenging due to high sample complexity requirements. Our TMDlayer does not require explicit generation of diffused samples, especially during training, making it computationally efficient. The "process" of which the provided data sample is a snapshot and whose characterization is enabled by our TMDlayer, also appears to have implications for robust learning. Indeed, if the parameters that define the process are explicitly optimized, we should be able to establish an analogy between the resultant model as a stochastic/simpler version of recent results for certified margin radius maximization <ref type="bibr" target="#b60">[60]</ref> which often require access to Monte Carlo sampling oracles <ref type="bibr" target="#b10">[11]</ref>. We believe that periodicity in SDEs for data augmentation is an important missing ingredient -for instance -this may help model seasonal patterns in disease progression studies for predictions, automatically. For this purpose, tools from Floquet theory may allow us to consider transformed versions of the process, potentially with simplified generators. Our code is available at https://github.com/zihangm/neural-tmd-layer .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Overview of TMDlayer use in few-shot recognition, point</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Qualitative results on Vaihingen dataset. Our model performs well despite the small sample size. pertains to the update function of the deep active contour model and the second one refers to the TMDlayer. L m in (13) is constructed using samples from the same mini-batch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 :</head><label>1</label><figDesc>Operational steps in TMDlayer 1 Input: Function f , a batch of data samples X = {x 1 , ..., xm}, coefficient , parameterized time interval ?t 2 Construct distance matrix K by (6) 3 Compute kernel density estimate: q (</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Accuracy on CIFAR10 when adding random noise (mean = 0, std = ?) to the input. "Ours" refers to Resnet-18 plus the TMDlayer.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell>Classification results on ModelNet40. Accuracy means</cell></row><row><cell>overall accuracy. P = points, N = normals. "Ours" means replacing</cell></row><row><cell>transformer layers in PCT with TMDlayer.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Results of 5-way 5-shot learning on miniImageNet, averaged over 600 test episodes. "Ours" means EGNN plus our TMDlayer."BN" means that the query batch statistics are used instead of global batch normalization parameters.4.5. Runtime overhead/Relation with augmentationRuntime overhead. Our construction does involve some training time overhead because of computing the kernel matrix, and varies depending on the use case. For reference, the overhead is 10% in ?4.2, 11% in ?4.<ref type="bibr" target="#b2">3</ref> and 1% in ?4.4. Relationship with data augmentation. Data augmen-EGNN-semi [25] 61.88 62.52 63.53 66.85 Ours 63.14 64.32 64.83 68.35 EGNN-semi(T) [25] 63.62 64.32 66.37 76.37</figDesc><table><row><cell></cell><cell cols="4">Labeled Ratio (5-way 5-shot)</cell></row><row><cell>Training method</cell><cell>20%</cell><cell>40%</cell><cell>60%</cell><cell>1000%</cell></row><row><cell>GNN-semi [18]</cell><cell cols="2">52.45 58.76</cell><cell>-</cell><cell>66.41</cell></row><row><cell>Ours(T)</cell><cell cols="3">64.84 66.43 68.62</cell><cell>77.78</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by NIH grants RF1 AG059312 and RF1 AG062336. SNR was supported by UIC startup funds. We thank Baba Vemuri for providing many important suggestions on formulating the Chan-Vese model within deep networks.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Point convolutional neural networks by extension operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haggai</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.10091</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diffusion maps tailored to arbitrary non-degenerate it? processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Banisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zofia</forename><surname>Trstanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Bittracher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Klus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P?ter</forename><surname>Koltai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied and Computational Harmonic Analysis</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="242" to="265" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Manifold regularization: A geometric framework for learning from labeled and unlabeled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Longformer: The long-document transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Geodesic active contours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicent</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="79" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Active contours without edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Luminita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="266" to="277" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 Information Theory and Applications Workshop (ITA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="834" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duvenaud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.07366</idno>
		<title level="m">Neural ordinary differential equations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Certified adversarial robustness via randomized smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elan</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1310" to="1320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Taco S Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>K?hler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.10130</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Spherical cnns. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Diffusion maps. Applied and computational harmonic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Ronald R Coifman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lafon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="5" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilien</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.01681</idno>
		<title level="m">Augmented neural odes</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning so(3) equivariant representations with spherical cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Esteves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Allen-Blanchette</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Ameesh Makadia, and Kostas Daniilidis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04043</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Xiong</forename><surname>Meng-Hao Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Ning</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tai-Jiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi-Min</forename><surname>Ralph R Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.09688</idno>
		<title level="m">Pct: Point cloud transformer</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Train faster, generalize better: Stability of stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1225" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hypercolumns for object segmentation and fine-grained localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Arbel?ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">End-to-end deep convolutional active contours for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Hatamizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debleena</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demetri</forename><surname>Terzopoulos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.13359</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Kharazmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">Em</forename><surname>Karniadakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00873</idno>
		<title level="m">Variational physics-informed neural networks for solving partial differential equations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Edge-labeling graph neural network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwoong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Escape from cells: Deep kd-networks for the recognition of 3d point cloud models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Klokov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="863" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A-cnn: Annularly convolutional neural networks on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Komarichev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7421" to="7430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Stochastic flows and stochastic differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Kunita</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Cambridge university press</publisher>
			<biblScope unit="volume">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Pointgrid: A deep network for 3d shape understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Truc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9204" to="9214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">So-net: Selforganizing network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9397" to="9406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Kovachki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamyar</forename><surname>Azizzadenesheli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burigede</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaushik</forename><surname>Bhattacharya</surname></persName>
		</author>
		<imprint>
			<pubPlace>Andrew Stuart, and</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Fourier neural operator for parametric partial differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.08895</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fast interactive object annotation with curve-gcn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amlan</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5257" to="5266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02355</idno>
		<title level="m">Neural sde: Stabilizing neural ode networks with stochastic noise</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Shape modeling with front propagation: A level set approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Malladi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sethian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="158" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning deep structured active contours end-to-end</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devis</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Kellenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8877" to="8885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The Geometry of Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Melas-Kyriazi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
		<respStmt>
			<orgName>Harvard University Cambridge</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Solving differential equations using deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Michoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milo?</forename><surname>Milosavljevi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David R</forename><surname>Hatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">399</biblScope>
			<biblScope unit="page" from="193" to="212" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="652" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning generalized transformation equivariant representations via autoencoding transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Guo-Jun Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Region-based strategies for active contour models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Ronfard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="229" to="251" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Total variation based image restoration with free local constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Leonid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1st International Conference on Image Processing</title>
		<meeting>1st International Conference on Image Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1994" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.05175</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning an effective equivariant 3d descriptor without supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Spezialetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuele</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><forename type="middle">Di</forename><surname>Stefano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6401" to="6410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A quaternion framework for color image smoothing and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>?zlem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Subakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="250" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04080</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Transactions On Graphics (tog)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Pointconv: Deep convolutional networks on 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fuxin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9621" to="9630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1912" to="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Attentional shapecontextnet for point cloud recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4606" to="4615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Nystr?mformer: A nystr?m-based algorithm for approximating self-attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyang</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanpeng</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudrasis</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glenn</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.03902</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Image segmentation using deformable models. Handbook of medical imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dzung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><forename type="middle">L</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Prince</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">0</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Deep variational instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fuxin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">You only sample (almost) once: Linear cost self-attention via bernoulli sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanpeng</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyang</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sathya</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shailesh</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Glenn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="12321" to="12332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Simpler certified radius maximization by propagating covariances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjian</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudrasis</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7292" to="7301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Generative visual manipulation on the natural image manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
