<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EFFICIENT DEBIASING WITH CONTRASTIVE WEIGHT PRUNING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geon</forename><forename type="middle">Yeong</forename><surname>Park</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematical Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangmin</forename><surname>Lee</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Kim Jaechul Graduate School of AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang</forename><forename type="middle">Wan</forename><surname>Lee</surname></persName>
							<email>leeleesang@kaist.ac.kr</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematical Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">Chul</forename><surname>Ye</surname></persName>
							<email>jong.ye@kaist.ac.kr</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematical Sciences</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Kim Jaechul Graduate School of AI</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">KAIST</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Bio and Brain Engineering</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">EFFICIENT DEBIASING WITH CONTRASTIVE WEIGHT PRUNING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Preprint</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural networks are often biased to spuriously correlated features that provide misleading statistical evidence that does not generalize. This raises a fundamental question: "Does an optimal unbiased functional subnetwork exist in a severely biased network? If so, how to extract such subnetwork?" While few studies have revealed the existence of such optimal subnetworks with the guidance of groundtruth unbiased samples, the way to discover the optimal subnetworks with biased training dataset is still unexplored in practice. To address this, here we first present our theoretical insight that alerts potential limitations of existing algorithms in exploring unbiased subnetworks in the presence of strong spurious correlations. We then further elucidate the importance of bias-conflicting samples on structure learning. Motivated by these observations, we propose a Debiased Contrastive Weight Pruning (DCWP) algorithm, which probes unbiased subnetworks without expensive group annotations. Experimental results demonstrate that our approach significantly outperforms state-of-the-art debiasing methods despite its considerable reduction in the number of parameters. * Co-corresponding authors. 1  The bias-aligned samples refer to data with a strong correlation between (potentially latent) spurious features and target labels (e.g., cat in the house). The bias-conflicting samples refer to the opposite cases where spurious correlations do not exist (e.g., cat in the desert).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>While deep neural networks have made substantial progress in solving challenging tasks, they often undesirably rely on spuriously correlated features or dataset bias, if present, which is considered one of the major hurdles in deploying models in real-world applications. For example, consider recognizing desert foxes and cats from natural images. If the background scene (e.g., a desert) is spuriously correlated to the type of animal, the neural networks might use the background information as a shortcut to classification, resulting in performance degradation in different backgrounds (e.g., a desert fox in the house).</p><p>We consider this shortcut as an inherent design issue of subnetworks. If any available information channels in deep networks' structure could transmit the information of spurious features, networks would exploit those features as long as they are sufficiently predictive. It naturally follows that pruning weights on spurious features can purify the biased latent representations, leading to improved performances on bias-conflicting samples 1 . Accordingly, we hypothesize that such unbiased subnetworks may exist in the pretrained biased network.  has empirically demonstrated the existence of subnetworks that are less susceptible to spurious features by using sufficient number of ground-truth bias-conflicting samples. Based on the modular property of neural networks <ref type="bibr" target="#b4">(Csord?s et al., 2020)</ref>, they prune out weights that are irrelevant to the subtask, which is classification of the ground-truth bias-conflicting samples. Nonetheless, it is still unclear how to discover such optimal subnetworks when the dataset is highly biased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preprint</head><p>To formulate this idea, we present a simple theoretical example in which, in the presence of strong spurious correlations, there exists an inevitable generalization gap of subnetworks obtained by standard pruning algorithms. Our example highlights the limitations of existing substructure probing method combining the cross entropy loss and sparsity regularization .</p><p>In addition, our example provides insight that sampling more bias-conflicting data makes it possible to identify spurious weights. Specifically, bias-conflicting samples require that the weights associated with spurious features should be removed because the spurious features are not helpful in predicting the corresponding class of bias-conflicting samples. It leads to the exclusive preservation of non-spurious or invariant weights, resulting in minimizing the upper bounds of the generalization error. Our theoretical observations suggest that balancing the ratio between the number of bias-aligned and bias-conflicting samples is crucial in finding the optimal unbiased subnetworks. However, due to the potential pitfalls in data collection protocols or human prejudice, the dataset may severely lack diversity for bias-conflicting samples. Since it is often highly laborious to supplement enough bias-conflicting samples, it would be better to fully exploit a small set of given bias-conflicting samples in the training data.</p><p>To this end, we propose a novel debiasing scheme, called Debiased Contrastive Weight Pruning (DCWP), that uses the oversampled bias-conflicting data as a probe to search unbiased subnetworks. The proposed method comprises two stages: (1) identifying the bias-conflicting samples without expensive annotations on spuriously correlated attributes and (2) training the pruning parameters to obtain weight pruning masks with debiased loss function and the sparsity constraint. More specifically, our debiased loss includes (1) a weighted cross-entropy loss that upweights the identified bias-conflicting samples and (2) an alignment loss that further reduces the geometrical alignment gap between bias-aligned samples and bias-conflicting samples within each class.</p><p>We demonstrate that DCWP consistently outperforms state-of-the-art debiasing methods across various biased datasets, including the Color-MNIST <ref type="bibr" target="#b21">(Li &amp; Vasconcelos, 2019;</ref>, Corrupted CIFAR-10 <ref type="bibr" target="#b12">(Hendrycks &amp; Dietterich, 2019)</ref> and Biased FFHQ , even without direct supervision on the bias type. Our approach improves the accuracy on the unbiased evaluation dataset by 86.74% ? 93.41%, 27.86% ? 35.90% on Colored-MNIST and Corrupted CIFAR-10 compared to the second best model, respectively, even when 99.5% of samples are bias-aligned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p>Spurious correlations. A series of empirical works have shown that the deep networks often find shortcut solutions relying on spuriously correlated attributes, such as the texture of image <ref type="bibr" target="#b9">(Geirhos et al., 2018)</ref>, language biases <ref type="bibr" target="#b11">(Gururangan et al., 2018)</ref> or sensitive variables such as ethnicity or gender <ref type="bibr" target="#b25">(Narayanan, 2018;</ref><ref type="bibr" target="#b6">Feldman et al., 2015)</ref>. Such behavior is of practical concern because it deteriorates the reliability of deep networks in sensitive applications like healthcare, finance, and legal services <ref type="bibr" target="#b3">(Corbett-Davies &amp; Goel, 2018)</ref>.</p><p>Debiasing frameworks. Recent studies have attempted to train a debiased network robust to spurious correlations, which can be roughly categorized into approaches (1) leveraging annotations of spurious attributes, i.e., bias label <ref type="bibr" target="#b26">(Sagawa et al., 2019;</ref>, (2) presuming certain type of bias, e.g., texture <ref type="bibr" target="#b8">Ge et al., 2021)</ref> or (3) without using explicit kinds of supervisions on dataset bias . <ref type="bibr" target="#b26">Sagawa et al. (2019)</ref>; <ref type="bibr" target="#b14">Hu et al. (2018)</ref> optimize the worst-group error by using training group information. For the practical implementation, reweighting or subsampling protocols are often used with increased model regularization <ref type="bibr" target="#b27">(Sagawa et al., 2020)</ref>. <ref type="bibr" target="#b41">Liu et al. (2021)</ref>; <ref type="bibr" target="#b29">Sohoni et al. (2020)</ref> extend these approaches to the settings without expensive group annotations. <ref type="bibr" target="#b10">Goel et al. (2020)</ref>;  provide bias-tailored augmentations to synthetically balance the majority and minority groups. In particular, these approaches have mainly focused on better approximation and regularization of worst-group error combined with advanced data sampling, augmentation, or retraining strategies.</p><p>Studying impacts of neural architectures. In contrast to the approaches mentioned above, the effects of deep neural network architecture on generalization performance are relatively less explored. <ref type="bibr" target="#b5">Diffenderfer et al. (2021)</ref> employ recently advanced lottery-ticket-style pruning algorithms <ref type="bibr" target="#b7">(Frankle &amp; Carbin, 2018)</ref> to design the compact and robust network architecture. <ref type="bibr" target="#b1">Bai et al. (2021)</ref> directly optimize the neural architecture in terms of accuracy on OOD samples, but it cannot fundamentally eliminate the connections to the spurious input attributes.  demonstrate the effectiveness of pruning weights on spurious attributes, but the solution for discriminating such spurious weights lacks robust theoretical justifications, resulting in marginal performance gains. To fully resolve the above issues, we carry out a theoretical case study, based on which we build a novel pruning algorithm that distills the representations to be independent of the spurious attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THEORETICAL INSIGHTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PROBLEM SETUP</head><p>We consider a supervised setting of predicting labels Y ? Y from input samples X ? X by a classifier f ? : X ? Y parameterized by ? ? ?. Following , let (X e , Y e ) ? P e , where X e ? X and Y e ? Y refer to the input random variable and the corresponding label, respectively, and e ? E = {1, 2, . . . E} denotes the index of environment, P e is the corresponding distribution, and the set E corresponds to every possible environments. We further assume that E is divided into training environmments E train and unseen test environments</p><formula xml:id="formula_0">E test , i.e. E = E train ? E test .</formula><p>For a given a loss function : X ? Y ? ? ? R + , the standard training protocol for ERM is to minimize the expected loss with a training environment e ? E train :</p><formula xml:id="formula_1">? ERM = arg min ? E (X e ,Y e )?P e (X e , Y e ; ?) ,<label>(1)</label></formula><p>whereP e is the empirical distribution over the training data. Our goal is to learn a model with good performance on OOD samples of e ? E test .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">MOTIVATING EXAMPLE</head><p>We assume that neural networks trained by ERM indiscriminately rely on predictive features, including those spurious correlated ones <ref type="bibr" target="#b31">(Tsipras et al., 2018)</ref>. Specifically, ERM models may be sensitive to every strongly-correlated feature regardless of whether it is causally related.</p><p>To examine this issue, we present a simple binary-classification example (X e , Y e ) ? P e , where Y e ? Y = {?1, 1} represents the corresponding target label, and a sample X e ? X = {?1, 1} D+1 ? R D+1 is constituted with both the invariant feature Z e inv ? {?1, 1} and spurious features Z e sp ? {?1, 1} D , i.e. X e = (Z e inv , Z e sp ). Suppose, furthermore, Z e sp,i denote the i-th spurious feature component of Z e sp . Note that we assume D 1 to simulate the model heavily relies on spurious features Z e sp <ref type="bibr" target="#b23">(Nagarajan et al., 2020;</ref>. We consider the setting where the training environment e ? E train is highly biased. In other words, we suppose that Z e inv = Y e , and each of the i-th spurious feature component Z e sp,i is independent and identically distributed (i.i.d) Bernoulli variable: i.e. Z e sp,i independently takes a value equal to Y e with a probability p e and ?Y e with a probability 1 ? p e , where p e ? (0.5, 1], ?e ? E train . Note that p e ? 1 as the environment is severely biased. A test environment e ? E test is assumed to have p e = 0.5, which implies that the spurious feature is totally independent with Y e . Then we introduce a linear classifier f parameterized by a weight vector w = (w inv , w sp ) ? R D+1 , where w inv ? R and w sp ? R D . In this example, we consider a class of pretrained classifiers parameterized byw(t) = w inv (t),w sp,1 (t), . . . ,w sp,D (t) , where t &lt; T is a finite pretraining time for some sufficiently large T . Time t will be often omitted in notations for simplicity.</p><p>Our goal is to obtain the optimal sparse classifier with a highly biased training dataset. To achieve this, we introduce a binary weight pruning mask m as m = (m inv , m sp ) ? {0, 1} D+1 for the pretrained weights, which is a significant departure from the theoretical setting in . Specifically, let m inv ? Bern(? inv ), where ? inv and 1 ? ? inv represents the probability of preserving (i.e. m inv = 1) and pruning out (i.e. m inv = 0), respectively. Similarly, let m sp,i ? Bern(? sp,i ), ?i. Then, our optimization goal is to estimate the pruning probability parameter ? = (? 1 , . . . , ? D+1 ) = (? inv , ? sp,1 , . . . , ? sp,D ), where m ? P (?) is a mask sampled with probability parameters ?. Accordingly, our main loss function for the pruning parameters given the environment e can be defined as follows:</p><formula xml:id="formula_2">e (?) = 1 2 E X e ,Y e ,m [1 ? Y e? e ] = 1 2 E X e ,Y e ,m 1 ? Y e ? sgn w T (X e m) ,<label>(2)</label></formula><p>where? e is the prediction of binary classifier,w is the pretrained weight vector, sgn(?) represents the sign function, and represents element-wise product. The distribution function of each variable is omitted in expectations for notational simplicity. In practice, we apply strong sparsity constraint as 1 penalization in terms of ? along with e (?) to obtain a sparse solution.</p><p>We first derive the upper-bound of the training loss e (?) to illustrate the difficulty of learning optimal pruning parameters in a biased data setting.</p><p>Theorem 1. (Training and test bound) Assume that p e &gt; 1/2 in the biased training environment e ? E train . Definew(t) as weights pretrained for a finite time t &lt; T . Then the upper bound of the error of training environment w.r.t. pruning parameters ? is given as:</p><formula xml:id="formula_3">e (?) ? 2 exp ? 2 ? inv + (2p e ? 1) D i=1 ? i (t)? sp,i 2 4 D i=1 ? i (t) 2 + 1 ,<label>(3)</label></formula><p>where the weight ratio ? i (t) =w sp,i (t)/w inv (t) is bounded below some positive constant. Given a test environment e ? E test with p e = 1 2 , the upper bound of the error of test environment w.r.t. ? is given as:</p><formula xml:id="formula_4">e (?) ? 2 exp ? 2? 2 inv 4 D i=1 ? i (t) 2 + 1 ,<label>(4)</label></formula><p>which implies that there is an unavoidable gap between training bound and test bound.</p><p>The detailed proof of Theorem 1 is provided in the supplementary material. The gap between (3) and (4) severely deteriorates the reliability of subnetworks obtained by training ?. This mismatch of the bounds is attributed to the contribution of ? sp,i on the training bound (3). Intuitively, the networks prefer to preserve bothw inv andw sp,i in the presence of strong spurious correlations due to the inherent sensitivity of ERM to all kinds of predictive features <ref type="bibr" target="#b15">(Ilyas et al., 2019;</ref><ref type="bibr" target="#b31">Tsipras et al., 2018)</ref>. This behavior is directly reflected in the training bound, where increasing either ? inv or ? sp,i , i.e., the probability of preserving weights, decreases the training bound. This inertia of spurious weights may prevent themselves from being primarily pruned against the sparsity constraint.</p><p>Remarkably, we observe some intriguing properties of weight ratio ? i (t): if infinitely many data and sufficient training time is provided, the gradient flow converges to the optimal solution which is invariant to Z e sp , i.e., ? i (t) ? 0. In this ideal situation, the gap between training and test bound is closed, thereby guaranteeing generalizations of obtained subnetworks. However, given a finite time t &lt; T with a strongly biased dataset in practice, ? i (t) is bounded below by some positive constant, resulting in an inevitable generalization gap. We provide details about the dynamics of ? i (t) in the appendix.</p><p>Then, how can we prioritize spurious weights to be pruned out? The above discussion illustrates the risk of reliance on spurious features. In this regard, Theorem 1 implies that the classifier may preserve pretrained spurious weights due to the lack of bias-conflicting samples, which serve as counterexamples that spurious features themselves fail to explain. It motivates us to analyze the training bound in another environment ? where we can systematically augment bias-conflicting samples. Specifically, consider X ? = (Z ? inv , Z ? sp ), where Z ? inv = Y ? and mixture distribution of Z ? sp given Y ? = y is defined in an element wise as follows:</p><formula xml:id="formula_5">P ? mix (Z ? sp,i | Y ? = y) = ?P ? debias (Z ? sp,i | Y ? = y) + (1 ? ?)P ? bias (Z ? sp,i | Y ? = y),<label>(5)</label></formula><p>where ? is a scalar mixture weight,</p><formula xml:id="formula_6">P ? debias (Z ? sp,i | Y ? = y) = 1, if Z ? sp,i = ?y 0, if Z ? sp,i = y<label>(6)</label></formula><p>is a debiasing distribution to weaken the correlation between Y ? and Z ? sp,i by setting the value of Z ? sp,i as ?Y ? , and</p><formula xml:id="formula_7">P ? bias (Z ? sp,i | Y ? = y) = p ? , if Z ? sp,i = y 1 ? p ? , if Z ? sp,i = ?y (7)</formula><p>is a biased distribution similarly defined in the previous environment e ? E train . Given this new environment ?, the degree of spurious correlations can be controlled by ?. This leads to a training bound as follow: Theorem 2. (Training bound with the mixture distribution) Assume that the defined mixture distribution P ? mix is biased, i.e.,</p><formula xml:id="formula_8">P ? mix (Z ? sp,i = ?y | Y e = y) ? P ? mix (Z ? sp,i = y | Y ? = y), ? i (8) Then, ? satisfies 0 ? ? ? 1 ? 1 2p ? .</formula><p>Then the upper bound of the error of training environment ? w.r.t. the pruning parameters is given by</p><formula xml:id="formula_9">? (?) ? 2 exp ? 2(? inv + (2p ? (1 ? ?) ? 1) D i=1 ? i (t)? sp,i ) 2 4 D i=1 ? i (t) 2 + 1 .<label>(9)</label></formula><p>Furthermore, when ? = 1 ? 1 2p ? , the mixture distribution is perfectly debiased, and we have</p><formula xml:id="formula_10">? (?) ? 2 exp ? 2? 2 inv 4 D i=1 ? i (t) 2 + 1 ,<label>(10)</label></formula><p>which is equivalent to the test bound in (4).</p><p>The detailed proof is provided in the supplementary material. Our new training bound (9) suggests that the significance of ? sp,i on training bound decreases as ? progressively increases, and at the extreme end with ? = 1 ? 1 2p ? , it can be easily shown that P ? mix (Z ? sp,i | Y ? = y) = 1 2 for both y = 1 and y = ?1 so that Z ? sp,i turns out to be random. In other words, by plugging ? = 1 ? 1 2p ? into (9), we can minimize the the gap between training and test error bound, which guarantees the improved OOD generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DEBIASED CONTRASTIVE WEIGHT PRUNING (DCWP)</head><p>Our theoretical example elucidates the importance of balancing between the bias-aligned and biasconflicting samples in discovering the optimal unbiased subnetworks structure. While the true analytical form of the debiasing distribution is unknown in practice, we aim to approximate such unknown distribution with existing bias-conflicting samples and simulate the mixture distribution P ? mix with modifying sampling strategy. To this end, we propose a Debiased Contrastive Weight Pruning (DCWP) algorithms that learn the unbiased subnetworks structure from the original fullsize network by identifying and exploiting a small set of existing bias-conflicting training samples.</p><p>Consider a L layer neural networks as a function f W : X ? R C parameterized by weights W = {W 1 , . . . , W L }, where C = |Y| is the number of classes. Analogous to the earlier works on pruning, we introduce binary weight pruning masks m = {m 1 , . . . , m L } to model the subnetworks as f (?; m 1 W 1 , . . . , m L W L ). We denote such subnetworks as f m W for the notational simplicity. We treat each entry of m l as an independent Bernoulli variable, and model their logits as our new pruning parameters ? = {? 1 , . . . , ? L } where ? l ? R n l and n l represents the dimensionality of the l-th layer weights W l . Then ? l,i = ?(? l,i ) denotes the probability of preserving the i-th weight of l-th layer W l,i where ? refers to a sigmoid function. To enable the end-to-end training, the Gumbel-softmax trick <ref type="bibr" target="#b16">(Jang et al., 2016)</ref> for sampling masks together with 1 regularization term of ? is adopted as a sparsity constraint. With a slight abuse of notations, m ? G(?) denotes a set of masks sampled with logits ? by applying Gumbel-softmax trick.</p><p>Then our main optimization problem is defined as follows:</p><formula xml:id="formula_11">min ? debias {(x i , y i )} |S| i=1 ;W , ? + ? 1 l,i |? l,i |,<label>(11)</label></formula><p>where S denotes the index set of whole training samples, ? 1 &gt; 0 is a Lagrangian multiplier,W represents the pretrained weights and debias is our main objective which will be illustrated later. Note that we freeze the pretrained weightsW during training pruning parameters ?. We interchangeably</p><formula xml:id="formula_12">use debias {(x i , y i )} |S| i=1</formula><p>; ? and debias S; ? in the rest of the paper. For comparison with our formulation, we recast the optimization problem of  with our notations as follows:</p><formula xml:id="formula_13">min ? {(x i , y i )} |S| i=1 ;W , ? + ? 1 l,i |? l,i |,<label>(12)</label></formula><p>where  uses the cross entropy (CE) loss function for .</p><p>Bias-conflicting sample mining In the first stage, we identify bias-conflicting training samples which empower functional modular probing. Specifically, we train a bias-capturing model and treat an error set S bc of the index of misclassified training samples as bias-conflicting sample proxies. Our framework is broadly compatible with various bias-capturing models, where we mainly leverage the ERM model trained with generalized cross entropy (GCE) loss <ref type="bibr" target="#b35">(Zhang &amp; Sabuncu, 2018)</ref>:</p><formula xml:id="formula_14">GCE (x i , y i ; W B ) = 1 ? p yi (x i ; W B ) q q ,<label>(13)</label></formula><p>where q ? (0, 1] is a hyperparameter controlling the degree of bias amplification, W B is the parameters of the bias-capturing model, and p yi (x i ; W B ) is a softmax output value of the bias-capturing model assigned to the target label y i . Compared to the CE loss, the gradient of the GCE loss upweights the samples with a high probability of predicting the correct target, amplifying the network bias by putting more emphasis on easy-to-predict samples .</p><p>To preclude the possibility that the generalization performance of DCWP is highly dependent on the behavior of the bias-capturing model, we demonstrate in Section 5 that DCWP is reasonably robust to the degradation of accuracy on capturing bias-conflicting samples. Details about the biascapturing model and simulation settings are presented in the supplementary material.</p><p>Upweighting Bias-conflicting samples After mining the index set of bias-conflicting sample proxies S bc , we treat S ba = S \ S bc as the index set of majority bias-aligned samples. Then we calculate the weighted cross entropy (WCE) loss W CE {x i , y i } |S| i=1 ;W , ? as follows:</p><formula xml:id="formula_15">W CE S;W , ? := E m?G(?) ? up |S bc | i?S bc CE (x i , y i ; m W )+ 1 |S ba | i?S ba CE (x i , y i ; m W ) ,<label>(14)</label></formula><p>where ? up ? 1 is an upweighting hyperparameter, and CE denotes the cross entropy loss. The expectation is approximated with Monte Carlo estimates, where the number of mask m sampled per iteration is set to 1 in practice. To implement <ref type="formula" target="#formula_1">(14)</ref>, we oversample the samples in S bc for ? up times more than the samples in S ba . This sampling strategy is aimed at increasing the mixture weight ? of the proposed mixture distribution P ? mix in <ref type="formula" target="#formula_5">(5)</ref>, while we empirically approximate the unknown bias-conflicting group distribution with the sample set S bc .</p><p>Note that although simple oversampling of bias-conflicting samples may not lead to the OOD generalization due to the inductive bias towards memorizing a few counterexamples in overparameterized neural networks <ref type="bibr" target="#b27">Sagawa et al. (2020)</ref>, such failure is unlikely reproduced in learning pruning parameters under the strong sparsity constraint. We sample new weight masks m for each training iteration in a stochastic manner, effectively precluding the overparameterized networks from potentially memorizing the minority samples. As a result, DCWP exhibits reasonable performance even with few bias-conflicting samples.</p><p>Bridging the alignment gap by pruning To fully utilize the bias-conflicting samples, we consider the sample-wise relation between bias-conflicting samples and majority bias-aligned samples. <ref type="bibr" target="#b34">Zhang et al. (2022)</ref> demonstrates that the deteriorated OOD generalization is potentially attributed to the distance gap between same-class representations; bias-aligned representations are more closely aligned than bias-conflicting representations, although they are generated from the same-class samples. We hypothesized that well-designed pruning masks could alleviate such geometrical misalignment. Specifically, ideal weight sparsification may guide each latent dimension to be independent of spurious attributes, thereby preventing representations from being misaligned with spuriously correlated latent dimensions. This motivates us to explore pruning masks by contrastive learning.</p><p>Following the conventional notations of contrastive learning, we denote f enc W : X ? R n L?1 as an encoder parameterized by W = (W 1 , . . . , W L?1 ) which maps samples into the representations at penultimate layer. Let f cls</p><formula xml:id="formula_16">W L : R n L ? R C be the classification layer parameterized by W L . Then f W (x) = f cls W L (f enc W (x)), ?x ? X . We similarly define f enc m W and f cls m L W L . For the i-th sample x i , let z i (W ) = norm(f enc W (x i ))</formula><p>be the normalized representations lies on the unit hypersphere, and similarly define z i (m W ). We did not consider projection networks <ref type="bibr" target="#b18">Khosla et al., 2020)</ref> for architectural simplicity. Given index subsets of training samples V, V + , the supervised contrastive loss <ref type="bibr" target="#b18">(Khosla et al., 2020)</ref> function is defined as follows:</p><formula xml:id="formula_17">con (V, V + ; W) = i?V ?1 |V + (y i )| j?V + (yi) log exp z i (W) ? z j (W)/? a?V\{i} exp z i (W) ? z a (W)/? ,<label>(15)</label></formula><p>where ? &gt; 0 is a temperature hyperparameter, and V + (y i ) = {k ? V + : y k = y i , k = i} indicates the index set of samples with target label y i . Then, we define the debiased alignment loss as follows:</p><formula xml:id="formula_18">align {x i , y i } |S| i=1 ;W , ? = E m?G(?) con (S bc , S; m W ) + con (S ba , S bc ; m W ) ,<label>(16)</label></formula><p>where the expectation is approximated with Monte Carlo estimates as in <ref type="formula" target="#formula_1">(14)</ref>. Intuitively, (16) reduces the gap between bias-conflicting samples and others (first term), while preventing bias-aligned samples from being aligned too close each other (second term, more discussions in appendix).</p><p>Finally, our debiased loss in (11) is defined as follows:</p><formula xml:id="formula_19">debias S;W , ? = W CE S;W , ? + ? align align S;W , ? ,<label>(17)</label></formula><p>where ? align &gt; 0 is a balancing hyperparameter.</p><p>Fine-tuning after pruning After solving (11) by gradient-descent optimization, we can obtain the pruning parameters ? * . This allows us to uncover the structure of unbiased subnetworks with binary weight masks m * = {m * 1 , . . . , m * L }, where m * l = {1(?(? * l,i ) &gt; 1/2) | 1 ? i ? n l }, ?l ? {1, . . . , L}, and n l is a dimensionality of the l-th weight. After pruning, we finetune the survived weights? = m * W using W CE in (14) and ? align align in (16). Interestingly, we empirically found that the proposed approach works well without the reset <ref type="bibr" target="#b7">(Frankle &amp; Carbin, 2018)</ref> (Related experiments in Section 5). Accordingly, we resume the training while fixing the unpruned pretrained weights. The pseudo-code of DCWP is provided in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>To show the effectiveness of the proposed pruning algorithms, we evaluate the generalization performance of several debiasing approaches on Colored MNIST (CMNIST), Corrupted CIFAR-10 (CIFAR10-C), and Biased FFHQ (BFFHQ) with varying ratio of bias-conflicting samples, i.e., bias ratio. We report unbiased accuracy  on the test set, which includes a balanced number of samples from each data group. We also report bias-conflict accuracy for some experiments, which is the average accuracy on bias-conflicting samples included in an unbiased test set. Specifically, we report the bias-conflict accuracy on BFFHQ in which half of the unbiased test samples are bias-aligned, while the model with the best-unbiased accuracy is selected. We also compare the unbiased accuracy on BFFHQ in <ref type="table" target="#tab_2">Table 3</ref>.</p><p>Baselines We compare DCWP with vanilla network trained by ERM, and the following state-of-theart debiasing approaches: EnD , Rebias , MRM , LfF  and DisEnt . EnD relies on the annotations on the spurious attribute of training samples, i.e., bias labels. Rebias rely on prior knowledge about the type of dataset bias (e.g., texture). MRM, LfF, and DisEnt do not presume such bias labels or prior knowledge about dataset bias. Notably, MRM is closely related to DCWP where it probes the unbiased functional subnetwork with standard cross entropy. Details about other simulation settings, datasets, and baselines are provided in the supplementary material.  <ref type="table" target="#tab_0">Table 1</ref>, we found that DCWP outperforms other state-of-the-art debiasing methods by a large margin. Moreover, the catastrophic pitfalls of the existing pruning method become evident, where MRM fails to search for unbiased subnetworks. It underlines that the proposed approach for utilizing bias-conflicting samples plays a pivotal role in discovering unbiased subnetworks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>As shown in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">QUANTITATIVE ANALYSES</head><p>Ablation studies To quantify the extent of performance improvement achieved by each introduced module, we analyzed the dependency of model performance on: (a) oversampling identified biasconflicting samples when learning ? and W , (b) pruning out spurious weights following the trained parameters, and using alignment loss for (c) training ?, or for (d) finetuning W , and (e) using GCE loss for training bias-capturing model. For those cases where GCE loss is not used, we replace it with a CE loss. To emphasize the contribution of each module, we intentionally use a SGD optimizer which results in lower baseline accuracy (and for other CMNIST experiments in this subsection as well). <ref type="table" target="#tab_1">Table 2</ref> shows that every module plays an important role in OOD generalization, while (b) pruning contributes significantly when comparing indices 3 and 8. Dependency on bias-capturing models To evaluate the reliability of DCWP, we compare different version of DCWP which does not rely on the dataset-tailored mining algorithms. We posit that early stopping  is an easy plug-and-play method to train the bias-capturing model in general. Thus we newly train DCWP ERM which collects bias-conflicting samples by using the early-stopped ERM model. <ref type="table" target="#tab_2">Table 3</ref> shows that DCWP ERM outperforms other baselines even though the precision, the fraction of samples in S bc that are indeed bias-conflicting, or recall, the fraction of the bias-conflicting samples that are included in S bc , were significantly dropped. Do we need to reset weights? While it becomes widespread wisdom that remaining weights should be reset to their initial ones from the original network after pruning <ref type="bibr" target="#b7">(Frankle &amp; Carbin, 2018)</ref>, we analyze whether such reset is also required for the proposed pruning framework. We compared the training dynamics of different models such as: (1) ERM model, (2) MRM debias which solves (11) instead of (12) to obtain the weight pruning masks, (3) DCWP f ine which skip training ? and only conduct finetuning (index 7 in <ref type="table" target="#tab_1">Table 2</ref>), and (4) DCWP. Note that MRM debias reset the unpruned weights to its initialization after pruning. <ref type="figure">Figure 1a</ref> shows that although MRM debias makes a considerable advance, weight reset inevitably limits the performance gain. Moreover, finetuning the biased model significantly improves the generalization performance within only a few iterations, while pruning further boosts the accuracy by about 9%. It implies that the proposed framework does not require parameter reset, which allows debiasing large-scale pretrained models without retraining by simple pruning and finetuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sensitivity analysis on training iterations</head><p>We also analyzed hyperparameter sensitivity to the amount of training iteration ?. The unbiased test accuracy is evaluated with weight pruning masks generated by ? trained for {500, 1000, 1500, 2000} iterations on every dataset. <ref type="figure">Figure 1b</ref> shows that the accuracy increases as more (potentially biased) weights are pruned out. It implies that the proposed method can compress the networks to a substantial extent while significantly improving the OOD generalization performance.  <ref type="figure">Figure 1</ref>: (a) Comparison study on finetuning and weight resetting (CMNIST, bias ratio=1%). For DCWP and DCW P F ine , after pretraining weights for 2000 iterations, we pause and start training pruning parameters (vertical dotted line in the <ref type="figure">figure)</ref>. After convergence, we mask out and finetune weights for another 1000 iterations. For MRM debias , we reset the unpruned weight to its initialization and retrain for 3000 iterations. (b) Sensitivity analysis on the training iterations for ?. Bias ratio=1% for both CMNIST and CIFAR10-C. Bias-conflict accuracy is reported for BFFHQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>This paper presents a novel functional subnetwork probing method for OOD generalization. We provided theoretical insights and empirical evidence to show that the bias-conflicting samples provide an important clue for probing the optimal unbiased subnetworks. The proposed method is computationally efficient while fully compatible with many other debiasing methods.</p><p>The supplementary material is organized as follows. We begin with providing the algorithm of DCWP. Then we present the proof for Theorem 1 and 2. In section C, we extend the presented theoretical example in the main paper to illustrate the risks of geometrical misalignment of embeddings arising from strong spurious correlations. Section D presents additional experimental results and analyses. Optimization setting, hyperparameter configuration, and other experimental details are provided in section E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PSEUDOCODE</head><p>Algorithm 1 Debiased Contrastive Weight Pruning (DCWP) Update ? with debias S;W , ? + ? 1 l,i |? l,i | as in (11). 12: end for 13: Prune out weight as? =W 1(? * &gt; 0). 14: Update? with W CE and ? align align on D for T 3 iterations.</p><formula xml:id="formula_20">1: Input: Dataset D = {(x i , y i ) |S| i=1 },</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B PROOFS</head><p>In this section, we present the detailed proofs for Theorems 1 and 2 explained in the main paper, followed by an illustration about the dynamics of weight ratio ? i (t) =w sp,i (t)/w inv (t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 PROOF OF THEOREM 1</head><p>Theorem 1. (Training and test bound) Assume that p e &gt; 1/2 in the biased training environment e ? E train . Definew(t) as weights pretrained for a finite time t &lt; T . Then the upper bound of the error of training environment w.r.t. pruning parameters ? is derived as:</p><formula xml:id="formula_21">e (?) ? 2 exp ? 2 ? inv + (2p e ? 1) D i=1 ? i (t)? sp,i 2 4 D i=1 ? i (t) 2 + 1 ,<label>(18)</label></formula><p>where the weight ratio ? i (t) =w sp,i (t)/w inv (t) is bounded below some positive constant. Given a test environment e ? E test with p e = 1 2 , the upper bound of the error of test environment w.r.t. ? is derived as:</p><formula xml:id="formula_22">e (?) ? 2 exp ? 2? 2 inv 4 D i=1 ? i (t) 2 + 1 ,<label>(19)</label></formula><p>which implies that there is a unavoidable gap between training bound and test bound.</p><p>Proof. We omit time t inw(t) and ? i (t) for notational simplicity throughout the proof of Theorem 1 and 2.</p><p>The prediction from the classifier? e is defined in <ref type="formula" target="#formula_2">(2)</ref> a?</p><formula xml:id="formula_23">Y e = sgn w T (X e m) = sgn O e ,<label>(20)</label></formula><p>where</p><formula xml:id="formula_24">O e :=w inv m inv Z e inv + D i=1w</formula><p>sp,i m sp,i Z e sp,i .</p><p>Assume that Y e is uniformly distributed binary random variable. Then,</p><formula xml:id="formula_26">E X e ,Y e ,m [Y e? e ] = 1 2 E X e ,m ? e |Y e = 1 ? 1 2 E X e ,m ? e |Y e = ?1 ,<label>(22)</label></formula><p>where</p><formula xml:id="formula_27">E X e ,m ? e |Y e = 1 = E X e ,m sgn O e Y e = 1 = P O e &gt; 0 Y e = 1 ? P O e &lt; 0 Y e = 1 = 1 ? 2P O e &lt; 0 Y e = 1 ,<label>(23)</label></formula><p>and</p><formula xml:id="formula_28">E X e ,m ? e |Y e = ?1 = P O e &gt; 0 Y e = ?1 ? P O e &lt; 0 Y e = ?1 = ?E X e ,m ? e |Y e = 1 ,<label>(24)</label></formula><p>where we use P O e &lt; 0 Y e = 1 = P O e &gt; 0 Y e = ?1 and P O e &gt; 0 Y e = 1 = P O e &lt; 0 Y e = ?1 thanks to the symmetry. Therefore, we have</p><formula xml:id="formula_29">e (?) = 1 2 E X e ,Y e ,m [1 ? Y e? e ] = 1 2 ? 1 2 E X e ,m ? e |Y e = 1 = P O e &lt; 0 Y e = 1 .<label>(25)</label></formula><p>In order to derive a concentration inequality of e (?), we compute a conditional expectation as follows:</p><formula xml:id="formula_30">E X e ,m O e Y e = 1 = E X e ,m w inv m inv Z e inv + D i=1w sp,i m sp,i Z e sp,i Y e = 1 = E X e ,m w inv m inv + D i=1w sp,i m sp,i Z e sp,i Y e = 1 =w inv ? inv + E X e ,m D i=1w sp,i m sp,i Z e sp,i Y e = 1 =w inv ? inv + D i=1 (2p e ? 1)w sp,i ? sp,i ,<label>(26)</label></formula><p>where the last equality follows from the independence of Z sp,? and m sp,? as assumed in the main paper. Then,</p><formula xml:id="formula_31">P O e &lt; 0 Y e = 1 = P O e ? E X e ,m O e &lt; ?E X e ,m O e Y e = 1 ? P O e ? E X e ,m O e &gt; E X e ,m O e Y e = 1 ? 2 exp ? 2E X e ,m O e Y e = 1 2 w 2 inv + D i=1 4w 2 sp,i ? 2 exp ? 2 w inv ? inv + D i=1 (2p e ? 1)w sp,i ? sp,i 2 w 2 inv + D i=1 4w 2 sp,i ? 2 exp ? 2 ? inv + D i=1 (2p e ? 1)? i ? sp,i 2 1 + D i=1 4? 2 i ,<label>(27)</label></formula><p>where the second inequality is obtained using Hoeffding's inequality, third inequality is from (26), and last inequality is obtained by dividing both denominator and numerator withw 2 inv . We use the definition of weight ratio ? i =w sp,i /w inv . For the second inequality, we use thatw inv m inv Z e inv ? {0,w inv } andw sp,i m sp,i Z e sp,i ? {?w sp,i , 0,w sp,i } ?i in (21) to obtain the denominator. Finally, the proof for the positivity of ? i (t) comes from Proposition 1 in B.3 in this appendix. This concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 PROOF OF THEOREM 2</head><p>Theorem 2. (Training bound with the mixture distribution) Assume that the defined mixture distribution P ? mix is biased, i.e.,</p><formula xml:id="formula_32">P ? mix (Z ? sp,i = ?y | Y e = y) ? P ? mix (Z ? sp,i = y | Y ? = y), ? i<label>(28)</label></formula><p>Then, ? satisfies 0 ? ? ? 1 ? 1 2p ? . Then the upper bound of the error of training environment ? w.r.t. the pruning parameters is given by</p><formula xml:id="formula_33">? (?) ? 2 exp ? 2(? inv + (2p ? (1 ? ?) ? 1) D i=1 ? i (t)? sp,i ) 2 4 D i=1 ? i (t) 2 + 1 .<label>(29)</label></formula><p>Furthermore, when ? = 1 ? 1 2p ? , the mixture distribution is perfectly debiased, and we have</p><formula xml:id="formula_34">? (?) ? 2 exp ? 2? 2 inv 4 D i=1 ? i (t) 2 + 1 ,<label>(30)</label></formula><p>which is equivalent to the test bound in (4).</p><p>Proof. Recall that Z ? sp,i follows the mixture distribution P ? mix :</p><formula xml:id="formula_35">P ? mix (Z ? sp,i | Y ? = y) = ?P ? debias (Z ? sp,i | Y ? = y) + (1 ? ?)P ? bias (Z ? sp,i | Y ? = y).<label>(31)</label></formula><p>Then, with definition in (6) and <ref type="formula">(7)</ref>,</p><formula xml:id="formula_36">P mix (Z ? sp,i = ?y|Y ? = y) = ? + (1 ? ?)(1 ? p ? ) P mix (Z ? sp,i = y|Y ? = y) = (1 ? ?)p ? ,<label>(32)</label></formula><p>for y ? {?1, 1}. Then, based on the assumption, ?</p><formula xml:id="formula_37">+ (1 ? ?)(1 ? p ? ) ? (1 ? ?)p ? , which gives ? ? 1 ? 1 2p ? . Specifically, if ? = 1 ? 1 2p ? , it turns out that P mix (Z ? sp,i = ?y|Y ? = y) = P mix (Z ?</formula><p>sp,i = y|Y ? = y) = 1 2 , which implies that spurious features turns out to be random and the mixture distribution becomes perfectly debiased. If ? = 0, the mixture distribution boils down into a biased distribution as similarly defined in the environment e ? E train .</p><p>The prediction from the classifier O ? is defined as similar to O e in (21). Then in order to derive a concentration inequality of ? (?), we derive a conditional expectation of O ? as done in <ref type="formula" target="#formula_2">(26)</ref>:</p><formula xml:id="formula_38">E X ? ,m O ? Y ? = 1 = E X ? ,m w inv m inv Z ? inv + D i=1w sp,i m sp,i Z ? sp,i Y ? = 1 = E X ? ,m w inv m inv + D i=1w sp,i m sp,i Z ? sp,i Y ? = 1 .<label>(33)</label></formula><p>Then, with the definition in (31), the second term in the above conditional expectation of (33) is defined as follows:</p><formula xml:id="formula_39">E X ? ,m D i=1w sp,i m sp,i Z ? sp,i | Y ? = 1 = D i=1w sp,i ? sp,i ?E debias [Z ? sp,i | Y ? = 1] + (1 ? ?)E bias [Z ? sp,i | Y ? = 1] = D i=1w sp,i ? sp,i ? ? (?1) + (1 ? ?)(2p ? ? 1) = D i=1w sp,i ? sp,i 2p ? (1 ? ?) ? 1 ,<label>(34)</label></formula><p>where E debias and E bias in the first equality denote the conditional expectation with respect to distribution P ? debias and P ? bias in <ref type="formula" target="#formula_6">(6)</ref> and <ref type="formula">(7)</ref>, respectively. Plugging (34) into (33), we get</p><formula xml:id="formula_40">E X ? ,m O ? Y ? = 1 =w inv ? inv + D i=1 2p ? (1 ? ?) ? 1 w sp,i ? sp,i .<label>(35)</label></formula><p>Then we can derive the upper bound of ? (?) = P (O ? &lt; 0 | Y ? = 1) similarly to <ref type="formula" target="#formula_2">(27)</ref>:</p><formula xml:id="formula_41">P O ? &lt; 0 Y ? = 1 ? P O ? ? E X ? ,m O ? &gt; E X ? ,m O ? Y ? = 1 ? 2 exp ? 2E X ? ,m O ? Y ? = 1 2 w 2 inv + 4 D i=1w 2 sp,i ? 2 exp ? 2 w inv ? inv + D i=1 2p ? (1 ? ?) ? 1 w sp,i ? sp,i 2 w 2 inv + 4 D i=1w 2 sp,i ? 2 exp ? 2 ? inv + D i=1 (2p ? (1 ? ?) ? 1)? i ? sp,i 2 1 + D i=1 4? 2 i ,<label>(36)</label></formula><p>where the first inequality is obtained by Hoeffding's inequality, and second inequality is from (35). The denominator is obtained as same as in <ref type="formula" target="#formula_2">(27)</ref>, sincew inv m inv Z ? inv ? {0,w inv } and w sp,i m sp,i Z ? sp,i ? {?w sp,i , 0,w sp,i } ?i as-is. If we plug-in the upper bound value of ? = 1 ? 1 2p ? obtained from (32) into (36), it boils down into the test bound in (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 DYNAMICS OF THE WEIGHT RATIO</head><p>We omit an index of environment e in the proposition below for notational simplicity. Proposition 1. Consider a binary classification problem of linear classifier f w under exponential loss. Let (X, Y ) ? P , where each input random variable X and the corresponding label Y is generated by</p><formula xml:id="formula_42">X = Z inv Z sp , Y = Z inv ,</formula><p>where Z sp = (2z ? 1)Z inv for a random variable z ? {0, 1} D which is chosen from multivariate Bernoulli distribution (z i ? Bern(p)) with p &gt; 1 2 , i.e., p denotes p e in the main paper. Let w = w inv w sp ? R D+1 be the weight of the linear classifier f w (x) = w T x. Assume that 0 &lt; w inv (0),</p><p>i.e., w inv is initialized with a positive value, and 0 &lt; w sp,i (0) &lt; 1 2 log p 1?p . Then, after sufficient time of training, w inv diverges to +? and w sp,i converges to 1 2 log p 1?p , which means ? i := wsp,i winv converges to 0 for all i ? {1, 2, ? ? ? , D}. More precisely,</p><formula xml:id="formula_43">log e winv(0) + [4p(1 ? p)] D 2 t ? w inv (t) ? log e winv(0) + t D i=1</formula><p>pe ?wsp,i(0) + p(1 ? p) .</p><p>However, for a fixed t &lt; T , each ? i is positive and its lower bound converges to some positive value.</p><p>Proof. In this proof, w inv (t) denotes the invariant weight at time t, while we often omit the time t and interchangeably use w inv for notational simplicity, and likewise for w sp,i (t).</p><p>Note that the network output is given by</p><formula xml:id="formula_44">f w (x) = w T x = Z inv w inv + Z T sp w sp = Z inv w inv + D i=1 Z sp,i w sp,i .</formula><p>The exponential loss is defined by</p><formula xml:id="formula_45">L(w) = E (X,Y ) [e ?fw(X)Y ] = E z exp ?(Z inv w inv + D i=1 Z sp,i w sp,i )Z inv = E z exp(?w inv ? (2z 1 ? 1)w sp,1 ? ? ? ? ? (2z D ? 1)w sp,D ) = e ?winv D i=1 E z [e ?(2zi?1)wsp,i ] = e ?winv D i=1 (pe ?wsp,i + (1 ? p)e wsp,i ).</formula><p>Then, thanks to symmetry of w sp , it is enough to consider ? := wsp,1 winv . We first compute the gradient:</p><formula xml:id="formula_46">?L ?w inv = ?e ?winv D i=1 (pe ?wsp,i + (1 ? p)e wsp,i ) ?L ?w sp,1 = ?e ?winv (pe ?wsp,1 ? (1 ? p)e wsp,1 ) D i=2</formula><p>(pe ?wsp,i + (1 ? p)e wsp,i ).</p><p>Since d dt w inv = ? ?L ?winv , the dynamics is given by the following differnetial equations.</p><formula xml:id="formula_47">d dt w inv = e ?winv D i=1 (pe ?wsp,i + (1 ? p)e wsp,i ) d dt w sp,1 = e ?winv (pe ?wsp,1 ? (1 ? p)e wsp,1 ) D i=2 (pe ?wsp,i + (1 ? p)e wsp,i ).</formula><p>First we show that w inv (t) diverges to +? as t goes ?. We show this by computing its lower bound.</p><formula xml:id="formula_48">d dt w inv = e ?winv D i=1 (pe ?wsp,i + (1 ? p)e wsp,i ) ? e ?winv D i=1 (2 p(1 ? p)) = e ?winv [4p(1 ? p)] D 2 ,</formula><p>where the inequality is obtained by AM-GM inequality. This implies e winv dw inv ? [4p(1?p)] D 2 dt. Integrating both sides from 0 to t, we get</p><formula xml:id="formula_49">e winv(t) ? e winv(0) ? [4p(1 ? p)] D 2 t or w inv (t) ? log e winv(0) + [4p(1 ? p)] D 2 t ,<label>(37)</label></formula><p>which shows that w inv (t) diverges to +? as t ? ?. Note also that w inv strictly increases since d dt w inv &gt; 0.</p><p>For w sp,i , d dt w sp,i = 0 implies w sp,i converges to w * sp,i such that</p><formula xml:id="formula_50">pe ?w * sp,i ? (1 ? p)e w * sp,i = 0, namely, w * sp,i = 1 2 log p 1?p .</formula><p>As similar to w inv , w sp,1 strictly increases if and only if w sp,1 &lt; 1 2 log p 1?p . Based on the assumptions that 0 &lt; w sp,i (0) &lt; 1 2 log p 1?p , we conclude that w sp,1 monotonically converges to 1 2 log p 1?p . As p goes to 1, 1 2 log p 1?p is sufficiently large and we can assume w sp,i (0) &lt; 1 2 log p 1?p . Now, we fix 0 &lt; t &lt; T for given T and compute an upper bound of w inv . Using w sp,i (t) &lt; 1 2 log p 1?p , we get</p><formula xml:id="formula_51">d dt w inv = e ?winv D i=1 (pe ?wsp,i + (1 ? p)e wsp,i ) &lt; e ?winv D i=1 pe ?wsp,i(0) + (1 ? p) p 1 ? p = e ?winv D i=1 pe ?wsp,i(0) + p(1 ? p) which implies e winv dw inv &lt; D i=1 pe ?wsp,i(0) + p(1 ? p) dt.</formula><p>Integrating both sides from 0 to t, we get</p><formula xml:id="formula_52">w inv (t) &lt; log e winv(0) + D i=1 pe ?wsp,i(0) + p(1 ? p) t .<label>(38)</label></formula><p>Similarly, we compute a lower bound of w sp,1 on 0 &lt; t &lt; T . Before we start, note that w inv (t) &lt; w inv (T ) =: M from monotonicity.</p><formula xml:id="formula_53">d dt w sp,1 = e ?winv (pe ?wsp,1 ? (1 ? p)e wsp,1 ) D i=2 (pe ?wsp,i + (1 ? p)e wsp,i ) &gt; e ?M (pe ?wsp,1 ? (1 ? p)e wsp,1 ) D i=2 (2 p(1 ? p)) = e ?M [4p(1 ? p)] D?1 2 (pe ?wsp,1 ? (1 ? p)e wsp,1 ) induces 1 pe ?wsp,1 ? (1 ? p)e wsp,1 dw sp,1 &gt; e ?M [4p(1 ? p)] D?1 2 dt.</formula><p>Integrating both sides from 0 to t &lt; T , we get </p><formula xml:id="formula_54">V e inv,j = Z e inv , if j = 1 0, otherwise ,<label>(45)</label></formula><p>V e sp,j = Z e sp,j , if j = 2, . . . , D + 1 0, otherwise .</p><p>Thus, V e inv and V e sp are orthogonal. Given Y b = y and Y d = y for some y ? {?1, 1}, the cosine similarity between h b i and h d is expressed as follows:</p><formula xml:id="formula_56">E h b i , h d h b i h d Y b = y, Y d = y = E X b i , W T W X d h b i h d Y b = y, Y d = y = E X b i , X d D + 1 Y b = y, Y d = y = E V b i,inv + V b i,sp , V d inv + V d sp D + 1 Y b = y, Y d = y = 1 D + 1 ,<label>(47)</label></formula><p>where V b i,inv and V b i,sp represent the invariant and spurious component vector of X b i , respectively, and the second equality comes from the semi-orthogonality of W . The last equality comes from the orthogonality of spurious component vector from different environment b ? E train and d ? E test .</p><p>On the other hand, the expected cosine similarity between two arbitrary embeddings h b i and h b j from the biased environment b is expressed as follows:</p><formula xml:id="formula_57">E h b i , h b j h b i h b j Y b = y = E V b i,inv + V b i,sp , V b j,inv + V b j,sp D + 1 Y e = y = 1 + D(2p b ? 1) 2 D + 1 ,<label>(48)</label></formula><p>where the last equality comes from the expectation of product of independent Bernoulli variables.</p><p>The gap between <ref type="formula" target="#formula_3">(43)</ref> and <ref type="formula" target="#formula_4">(44)</ref> unveils the imbalance of distance between same-class embeddings from different environments on the unit hypersphere; embeddings from the training environment are more closely aligned to other embeddings from the same environment than embeddings from test environment at initial even when all samples are generated within the same class. While the Lemma 1 is only applicable to the initialized W before training, such imbalance may be worsened if W learns to project the samples on the high-dimensional subspace where most of its basis are independent to the invariant features. This sparks interests in designing weight pruning masks to aggregate the representations from same-class samples all together. Indeed, in this simple example, we can address this misalignment by masking out every weight in W except the first column, which is associated with the invariant feature.</p><p>From this point of view, we revisit the proposed alignment loss in main paper:</p><formula xml:id="formula_58">align {x i , y i } |S| i=1</formula><p>;W , ? = E m?G(?) con (S bc , S; m W ) + con (S ba , S bc ; m W ) , (49) where the first term reduces the gap between bias-conflicting samples and others, while the second term prevents bias-aligned samples from being aligned too close each other. In other words, the first term is aimed at increasing the cosine similarity between representations of same-class samples with different spurious attributes, as h b i and h d in this example. The second term serves as a regularizer that pulls apart same-class bias-aligned representations, as h b i and h b j in this example. Thus we can leverage abundant bias-aligned samples as negatives regardless of their class in second term, while <ref type="bibr" target="#b34">Zhang et al. (2022)</ref> limits the negatives to samples with different target label but same bias label, which are often highly scarce in a biased dataset. D ADDITIONAL RESULTS <ref type="figure">Figure 3</ref>: t-SNE visualization of representations encoded from unbiased test samples after (a) pretraining, (b) pruning and (c) finetuning (CMNIST, bias ratio=0.5%). Each point is painted following its label (i.e., bias label in first row, and target label in second row).</p><p>Visualization of learned latent representations. We visualized latent representations of unbiased test samples in CMNIST after (a) pretraining, (b) pruning and (c) finetuning. Note that we did not reset or finetune the weights in (b). As reported in <ref type="figure">Figure 3</ref>, biased representations in (a) are misaligned along with bias label as discussed in section 4 and C. However, after pruning, the representations were well-aligned with respect to the class of digits even without modifying the values of pretrained weights. It implies that the geometrical misalignment of representations can be addressed by pruning spurious weights, while finetuning with debias can further improve the generalizations. E EXPERIMENTAL SETUP <ref type="figure">Figure 4</ref>: Example images of datasets. The images above the dotted line denote the bias-aligned samples, while the ones below the dotted line are the bias-conflicting samples. For CMNIST and CIFAR10-C, each column indicates each class. For BFFHQ, the group of three columns indicates each class.</p><p>lowing . The exact number of (bias-aligned, bias-conflicting) samples is set to: (44,832, 228)-0.5%, (44,527, 442)-1%, (44,145, 887)-2%, and (42,820, 2,242)-5%.</p><p>BFFHQ. Each sample in this biased dataset are selected from Flickr-Faces-HQ (FFHQ) Dataset <ref type="bibr" target="#b17">(Karras et al., 2019)</ref>, where we conduct binary classifications with considering (Age, Gender) as target and spuriously correlated attribute pair following ; . Specifically, majority of training images correspond to either young women (i.e., aged 10-29) or old men (i.e., aged 40-59). This dataset consists of 19,104 number of such bias-aligned samples and 96 number of bias-conflicting samples, i.e., old women and young men.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 SIMULATION SETTINGS</head><p>Architecture details. We use a simple convolutional network with three convolution layers for CMNIST, with feature map dimensions of 64, 128 and 256, each followed by a ReLU activation and a batch normalization layer following . For CIFAR10-C and BFFHQ, we use ResNet-18 with pretrained weights provided in PyTorch torchvision implementations. Each convolutional network and ResNet-18 includes 1.3 ? 10 6 and 2.2 ? 10 7 number of parameters, respectively. We assign a pruning parameter for each weight parameter except bias in deep networks. Each of pruning parameter is initialized with value 1.5 so that the initial probability of preserving the corresponding weight is set to ?(1.5) ? 0.8 in default.</p><p>Training details. We first train bias-capturing networks using GCE loss (q=0.7) for CMNIST and BFFHQ, with 2000 and 10000 iterations, respectively. For CIFAR10-C, we use epoch-ensemble based mining algorithms presented in <ref type="bibr" target="#b36">Zhao et al. (2021)</ref>, which selects samples cooperated with ensemble of predictions at each epoch to prevent overfitting. We use b-c score threshold ? = 0.8 and confidence threshold ? = 0.05 as suggested in the original paper.</p><p>Then, main networks are pretrained for 10000 iterations using an Adam optimizer with learning rate 0.01 and 0.001 for CMNIST and others, respectively.</p><p>We train pruning parameters for 2000 iterations using a learning rate 0.01, upweighting hyperparameter ? up = 80 and a balancing hyperparameter ? align = 0.05 for each dataset. We use a Lagrangian multiplier ? 1 = 10 ?8 for CMNIST, and ? 1 = 10 ?9 for CIFAR10-C and BFFHQ. Specifically, we set ? 1 by considering the size of deep networks, where we found that the value within range O(0.1 * n ?1 ) serves as a good starting point where n is the number of parameters.</p><p>After pruning, we finetune the networks with decaying learning rate to 0.001 for CMNIST and 0.0005 for others. We use ? align = 0.05 and ? up = 80 for BFFHQ, and ? up = {10, 30, 50, 80} for CMNIST and CIFAR10-C with {0.5%, 1.0%, 2.0%, 5.0%} of bias ratio, respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Unbiased test accuracy evaluated on CMNIST, CIFAR10-C and bias-conflict test accuracy evaluated on BFFHQ. Models requiring supervisions on dataset bias are denoted with , while others are denoted with . Results are averaged on 4 different random seeds.</figDesc><table><row><cell>Dataset</cell><cell>Ratio (%)</cell><cell cols="2">ERM EnD Rebias MRM</cell><cell>LfF</cell><cell>DisEnt DCWP</cell></row><row><cell></cell><cell>0.5</cell><cell>62.36 84.32 69.12</cell><cell cols="3">60.98 83.73 86.74</cell><cell>93.41</cell></row><row><cell>CMNIST</cell><cell>1.0 2.0</cell><cell>81.73 94.98 84.65 89.33 97.01 91.96</cell><cell cols="3">80.42 88.44 93.15 89.31 92.67 95.15</cell><cell>95.98 97.16</cell></row><row><cell></cell><cell>5.0</cell><cell>95.22 98.00 96.74</cell><cell cols="3">95.23 94.90 96.76</cell><cell>98.02</cell></row><row><cell></cell><cell>0.5</cell><cell>22.02 23.93 21.73</cell><cell cols="3">23.92 27.02 27.86</cell><cell>35.90</cell></row><row><cell>CIFAR10-C</cell><cell>1.0 2.0</cell><cell>28.00 27.61 28.09 34.63 36.62 35.57</cell><cell cols="3">27.77 31.44 34.62 33.53 38.49 41.95</cell><cell>41.56 49.01</cell></row><row><cell></cell><cell>5.0</cell><cell>45.66 43.67 48.22</cell><cell cols="3">47.00 46.16 49.15</cell><cell>56.17</cell></row><row><cell>BFFHQ</cell><cell>0.5</cell><cell>52.25 59.80 54.90</cell><cell cols="3">54.75 56.50 55.50</cell><cell>60.35</cell></row><row><cell cols="2">5.2 EVALUATION RESULTS</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Ablation study on CMNIST (Bias ratio=1%). Unbiased accuracy is reported.</figDesc><table><row><cell cols="4">Index (a) Oversampling (b) Pruning (c) ? align</cell><cell>(d) W align</cell><cell cols="2">(e) GCE Accuracy (%)</cell></row><row><cell>1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>43.10</cell></row><row><cell>2</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>69.78</cell></row><row><cell>3</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>73.20</cell></row><row><cell>4</cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>74.80</cell></row><row><cell>5</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell>-</cell><cell>75.15</cell></row><row><cell>6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-</cell><cell>76.49</cell></row><row><cell>7</cell><cell></cell><cell>-</cell><cell>-</cell><cell></cell><cell></cell><cell>79.28</cell></row><row><cell>8</cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell><cell></cell><cell>84.79</cell></row><row><cell>9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>87.96</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Robustness dependency of DCWP on the performance of bias-capturing models. We set bias ratio as 1% for CIFAR10-C. Results are averaged on 4 different random seeds.</figDesc><table><row><cell>Dataset</cell><cell>Model</cell><cell></cell><cell>Accuracy</cell><cell></cell><cell cols="2">Mining metrics</cell></row><row><cell></cell><cell></cell><cell cols="5">bias-align bias-conflict unbiased precision recall</cell></row><row><cell></cell><cell>DisEnt</cell><cell>80.04</cell><cell>26.51</cell><cell>34.62</cell><cell>-</cell><cell>-</cell></row><row><cell>CIFAR10-C</cell><cell>DCWP ERM</cell><cell>94.33</cell><cell>29.75</cell><cell>36.21</cell><cell>19.71</cell><cell>79.53</cell></row><row><cell></cell><cell>DCWP</cell><cell>91.68</cell><cell>35.99</cell><cell>41.56</cell><cell>85.97</cell><cell>74.89</cell></row><row><cell></cell><cell>DisEnt</cell><cell>89.80</cell><cell>55.55</cell><cell>72.68</cell><cell>-</cell><cell>-</cell></row><row><cell>BFFHQ</cell><cell>LfF DCWP ERM</cell><cell>96.05 99.45</cell><cell>56.50 56.90</cell><cell>76.30 78.20</cell><cell>-20.18</cell><cell>-28.39</cell></row><row><cell></cell><cell>DCWP</cell><cell>98.85</cell><cell>60.35</cell><cell>79.60</cell><cell>30.61</cell><cell>31.25</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>pruning parameters ?, Training iterations T 1 , T 2 , T 3 . 2: Output: Trained pruning parameters ? * and finetuned weights W * Update the weights of bias-capturing network W b on D for T 1 iterations. 6: Identify S bc and S ba . Pretrain the main network on D. Denote the pretrained weights asW . 10: for t = 1 to T 2 do</figDesc><table><row><cell>3:</cell></row><row><cell>4: Stage 1. Mining debiased samples</cell></row><row><cell>5: 7:</cell></row><row><cell>8: Stage 2. Debiased Contrastive Weight Pruning</cell></row><row><cell>9: 11:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Proof. Let X e = V e inv + V e sp for the sample from an arbitrary environment e in general, where v e inv , v e sp ? {?1, 1} D+1 are invariant and spurious component vector, respectively:</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>t</cell><cell></cell><cell></cell></row><row><cell>1 p(1 ? p)</cell><cell>tanh ?1</cell><cell>1 ? p p</cell><cell>e wsp,1</cell><cell>0</cell><cell>&gt; e ?M [4p(1 ? p)]</cell><cell>D?1 2 t</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix or w sp,1 (t) &gt; 1 2 log p 1 ? p + log tanh tanh ?1 ( 1 ? p p e wsp,1(0) ) + e ?M 2 D?1 [p(1 ? p)] D 2 t .</p><p>(39)</p><p>Combining <ref type="formula">(38)</ref> and <ref type="formula">(39)</ref>, we conclude that</p><p>&gt; 1 2 log p 1?p + log tanh tanh ?1 ( 1?p p e wsp,1(0) ) + e ?M 2 D?1 [p(1 ? p)]</p><p>for 0 &lt; t &lt; T . Note that ? p (t) is positive in 0 &lt; t &lt; T , since both w sp,1 (t) and w inv (t) is monotonically increasing in 0 &lt; t &lt; T , and 0 &lt; w sp,1 (0), w inv (0) by assumptions.</p><p>The numerator becomes</p><p>for some c such that</p><p>We use f (x + y) = f (x) + yf (c) by the Mean Value Theorem (MVT) at the last line.</p><p>Notably, if we take a limit p ? 1, the numerator becomes</p><p>Similarly, the denominator becomes</p><p>Therefore, for a fixed 0 &lt; t &lt; T , we conclude that</p><p>where we use the inequality log(x + y) ? log x + y x in the last line.</p><p>The key insights from Proposition 1 can be summarized as follows:</p><p>(1) Weight ratio ? i (t) converges to 0 as t ? ?.</p><p>(2) However, for a fixed t &lt; T , ? i (t) &gt; 0.</p><p>(3) When t &lt; T and p ? 1, i.e., the environment is almost perfectly biased, the convergence rate of (1) is remarkably slow as in <ref type="formula">(42)</ref>. In other words, there exists c &gt; 0 such that</p><p>This results afford us intriguing perspective on the fundamental factors behind the biased classifiers. If we situate the presented theoretical example in an ideal scenario in which infinitely many data and sufficient training time is provided, our result (1) shows that the pretrained classifier becomes fully invariant to the spurious correlations. However, in practical setting with finite training time and number of samples, our result <ref type="formula">(2)</ref> shows that the pretrained model inevitably rely on the spuriously correlated features. Beyond theoretical results, we empirically observe that the weight ratio ? i of pretrained classifiers in Section 3 indeed increases as p e ? 1. We simulate the example presented in section 3, where the dimensionality D is set to 15, and probability p e varies from 0.6 (weakly biased) to 0.99 (severely biased). We train a linear classifier for 500 epochs with batch size of 1024, and measure the unbiased accuracy on test samples generated from environment e ? E test . We also measure weight ratio mean(w sp )/w inv , where mean(w sp ) denotes the average of pretrained spurious weights {w sp,i } D i=1 . To enable the end-to-end training, we use binary cross entropy loss instead of exponential loss, with setting Y = {0, 1} instead of Y = {?1, 1}. We do not consider pruning process in this implementation. <ref type="figure">Figure 2</ref> shows that the weight ratio increases to 1 in average as p e ? 1. It implies that the spurious features Z e sp participate almost equally to the invariant feature Z e inv in the presence of strong spurious correlations. In this worst case, it is frustratingly difficult to discriminate weights necessary for OOD generalization in biased environment, resulting in the failure of learning optimal pruning parameters. Simulation results are averaged on 15 different random seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C EXAMPLE OF GEOMETRICAL MISALIGNMENT</head><p>In this section, we present a simple example illustrating the potential adverse effect of spurious correlations on latent representations. Consider independent arbitrary samples within the same class</p><p>be a weight matrix representation of a linear mapping T : {?1, 1} D+1 ? R Q which encodes the embedding vector of a given sample. We denote such embedding as h e = W X e for some e ? E. We assume that W is initialized as to be semi-orthogonal <ref type="bibr" target="#b28">(Saxe et al., 2013;</ref><ref type="bibr" target="#b13">Hu et al., 2020)</ref> for simplicity. Then the following lemma reveals the geometrical misalignment of embeddings in the presence of strong spurious correlations:</p><p>Then, the expected cosine similarity between h b i and h d is derived as:</p><p>while the expected cosine similarity between h b i and h b j is derived as:</p><p>where p b is a probability parameter of Bernoulli distribution of i.i.d variable Z b sp,i , similar to p e in the main paper.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning de-biased representations with biased representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyojin</forename><surname>Bahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seong Joon</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="528" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Nasood: Neural architecture search for out-of-distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyue</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanqing</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S-H Gary</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8320" to="8329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The measure and mismeasure of fairness: A critical review of fair machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharad</forename><surname>Goel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.00023</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?bert</forename><surname>Csord?s</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Sjoerd Van Steenkiste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02066</idno>
		<title level="m">Are neural nets modular? inspecting functional modularity through differentiable weight masks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A winning hand: Compressing deep networks can improve out-of-distribution robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Diffenderfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Bartoldson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreya</forename><surname>Chaganti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jize</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhavya</forename><surname>Kailkhura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="664" to="676" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Certifying and removing disparate impact</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sorelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Friedler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Moeller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Venkatasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 21th ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Carbin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03635</idno>
		<title level="m">The lottery ticket hypothesis: Finding sparse, trainable neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Robust contrastive learning using negative samples with diminished semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shlok</forename><surname>Songwei Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="27356" to="27368" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Felix A Wichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brendel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.12231</idno>
		<title level="m">Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Model patching: Closing the subgroup performance gap with data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.06775</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Suchin Gururangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02324</idno>
		<title level="m">Annotation artifacts in natural language inference data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.12261</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Provable benefit of orthogonal initialization in optimizing deep linear networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lechao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.05992</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Does distributionally robust supervised learning give robust classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2029" to="2037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adversarial examples are not bugs, they are features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Categorical reparameterization with gumbel-softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="18661" to="18673" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Biaswap: Removing dataset bias with bias-tailored swapping augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eungyeup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihyeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="14992" to="15001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning debiased representation via disentangled feature augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungsoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eungyeup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihyeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="25123" to="25133" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Repair: Removing representation bias by dataset resampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9572" to="9581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Just train twice: Improving group robustness without training group information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Evan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behzad</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><forename type="middle">S</forename><surname>Haghgoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6781" to="6792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Understanding the failure modes of out-of-distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Vaishnavh Nagarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnam</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neyshabur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.15775</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning from failure: De-biasing classifier from biased classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhyun</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyuntak</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungsoo</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaeho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="20673" to="20684" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Translation tutorial: 21 fairness definitions and their politics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Fairness Accountability Transp</title>
		<meeting>Conf. Fairness Accountability Transp<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1170</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tatsunori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.08731</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An investigation of why overparameterization exacerbates spurious correlations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditi</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8346" to="8356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">L</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ganguli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6120</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">No subclass left behind: Fine-grained robustness in coarse-grained classification problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nimit</forename><surname>Sohoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Dunnmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Angus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">End: Entangling and disentangling deep representations for bias correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enzo</forename><surname>Tartaglione</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><forename type="middle">Alberto</forename><surname>Barbano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Grangetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13508" to="13517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.12152</idno>
		<title level="m">Robustness may be at odds with accuracy</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Towards fairness in visual recognition: Effective strategies for bias mitigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klint</forename><surname>Qinami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Karakozis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prem</forename><surname>Genova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Russakovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8919" to="8928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Can subnetwork structure be the key to out-of-distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinghuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="12356" to="12367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Correct-ncontrast: A contrastive approach for improving robustness to spurious correlations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nimit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sohoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hongyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.01517</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mert</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning debiased models with dynamic gradient alignment and bias-conflicting sample mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shutao</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.13108</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">DATASETS We mainly follow Nam et</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">2021) to evaluate our framework on Color-MNIST (CMNIST), Corrupted CIFAR-10 (CIFAR10-C) and Biased FFHQ (BFFHQ) as presented in Figure 4</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Each digit is colored with certain type of color, following</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bahng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CMNIST. We first consider the prediction task of digit class which is spuriously correlated to the pre-assigned color, following the existing works</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>The ratio of bias-conflicting samples, i.e., bias ratio. is varied in range of {0.5%, 1.0%, 2.0%, 5.0%}, where the exact number of (bias-aligned, bias-conflicting) samples is set to: (54,751, 249)-0.5%, (54,509, 491)-1%, (54,014, 986)-2%, and (52,551, 2,449)-5%</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Each of these corruption is spuriously correlated to the object classes of CIFAR-10, which are Plane, Car, Bird, Cat, Deer, Dog, Frog, Horse, Ship, and Truck. We use the samples corrupted in most severe level among five different severity, fol-Considering the pruning as a strong regularization, we did not use additional capacity control techniques such as early stopping or strong 2 regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pixelate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIFAR10-C. Each sample in this dataset is generated by corrupting original samples in CIFAR-10 with certain types of corruption</title>
		<editor>Sagawa et al.</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Among 15 different corruptions introduced in the original paper (Hendrycks &amp; Dietterich, 2019), we select 10 types which are Brightness, Contrast, Gaussian Noise, Frost, Elastic Transform, Gaussian Blur, Defocus Blur, Impulse Noise, Saturate, and</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">We did not use any kinds of data augmentations which may implicitly enforce networks to encode invariances. For the BFFHQ dataset, we only apply random horizontal flip. For the CIFAR10-C dataset, we take 32 ? 32 random crops from image padded by 4 pixels followed by random horizontal flip, following Nam et</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Al</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>We do not use any kinds of augmentations in CMNIST</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">DisEnt released by authors, and reproduce EnD and MRM by ourselves. For DisEnt, we use the official hyperparameter configurations provided in the original paper. We use q = 0.7 for LfF as suggested by authors on every experiment. For Rebias, we use the official hyperparameter configurations for CMNIST, and train for 200 epochs using Adam optimizer with learning rate 0.001 and RBF kernel radius of 1 for other datasets. For MRM, we use ? 1 of 10 ?8 for CMNIST following the original paper, and 10 ?9 for the others. For EnD, we set the multipliers ? for disentangling and ? for entangling to 1</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baselines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">We use the official implementations of Rebias, LfF</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
