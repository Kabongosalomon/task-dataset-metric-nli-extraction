<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation of Teacher Ensembles for Spoken Command Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao-Han</forename><surname>Huck</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabato</forename><forename type="middle">Marco</forename><surname>Siniscalchi</surname></persName>
							<email>marco.siniscalchi@unikore.it</email>
							<affiliation key="aff0">
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Computer and Telecommunication Engineering</orgName>
								<orgName type="institution">University of Enna</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Electronic Systems</orgName>
								<orgName type="institution">NTNU</orgName>
								<address>
									<settlement>Trondheim</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation of Teacher Ensembles for Spoken Command Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T12:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms: Privacy-preserving speech processing</term>
					<term>differen- tial privacy</term>
					<term>generative modeling</term>
					<term>ensemble learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose using an adversarial autoencoder (AAE) to replace generative adversarial network (GAN) in private aggregation of teacher ensembles (PATE), a solution for ensuring differential privacy in speech applications. The AAE architecture allows us to obtain good synthetic speech leveraging upon a discriminative training of latent vectors. Such synthetic speech is used to build a privacy-preserving classifier when non-sensitive data is not sufficiently available in the public domain. This classifier follows the PATE scheme that uses an ensemble of noisy outputs to label the synthetic samples and guarantee ?-differential privacy (DP) on its derived classifiers. Our proposed framework thus consists of an AAE-based generator and a PATE-based classifier (PATE-AAE). Evaluated on the Google Speech Commands Dataset Version II, the proposed PATE-AAE improves the average classification accuracy by +2.11% and +6.60%, respectively, when compared with alternative privacy-preserving solutions, namely PATE-GAN and DP-GAN, while maintaining a strong level of privacy target at ?=0.01 with a fixed ?=10 ?5 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The speech signal contains a rich set of information <ref type="bibr" target="#b0">[1]</ref> that encompasses gender, accent, speaking environment, and other speaker characteristics; therefore, protecting data privacy becomes a raising concern when speech data is used to deploy commercial speech applications. In recent years, public regulations, e.g., GDPR <ref type="bibr" target="#b1">[2]</ref> and CCPA <ref type="bibr" target="#b2">[3]</ref>, have been proposed to establish new guidelines related to data privacy measurement and identity protection in end-user applications. Recent works on model inversion attacks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> indeed highlighted the importance of data privacy when the original data profile (e.g., facial images <ref type="bibr" target="#b3">[4]</ref>) could be recovered from a machine learning model by using query-free optimization techniques.</p><p>Differential privacy <ref type="bibr" target="#b5">[6]</ref> (DP) is an effective mechanism for ensuring individual data protection, and it has been deployed in several industrial systems <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>  <ref type="bibr" target="#b0">1</ref> to protect customer's sensitive information by exploiting a sophisticated noisy perturbation scheme. The ?-DP mechanism <ref type="bibr" target="#b5">[6]</ref> provides a way to quantify a privacy loss and set up a privacy budget (e.g., a minimum ? value) for a given dataset. However, ?-differential private models <ref type="bibr" target="#b6">[7]</ref> need to be refined in order to improve a degraded prediction accuracy <ref type="bibr" target="#b8">[9]</ref> caused by the DP noise. The private aggre- <ref type="bibr" target="#b0">1</ref> Apple has also applied differential privacy with a privacy budget (?=8) based on an official document in https: //www.apple.com/privacy/docs/Differential_ Privacy_Overview.pdf. gation of teacher ensembles <ref type="bibr" target="#b9">[10]</ref> (PATE) is a recently proposed solution that aims to combat the accuracy loss of the machine learning models while ensuring privacy requirements. PATE follows a teacher-student architecture <ref type="bibr" target="#b10">[11]</ref>, where the teacher is an ensemble model. The underpinning idea in PATE is to leverage upon noisy outputs of aggregated teacher models to (re)label non-sensitive public data with DP guarantees. The PATE method and its improved version <ref type="bibr" target="#b11">[12]</ref> were proven useful in reducing the model accuracy drop through a voting process during the noisy ensemble. Nonetheless, the teacher-student learning process highly depends on a hypothesis <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref> that there exists a sufficient amount of public (non-sensitive) data to train the model. PATE-GAN <ref type="bibr" target="#b12">[13]</ref> tries to overcome this issue by incorporating a generative block jointly trained with the PATE block; the goal is providing enough synthetic data to train deep models effectively. Unfortunately, PATE-GAN does not work well for high dimensional data synthesis (e.g., images), as demonstrated in recent studies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>. Moreover, generating speech samples is a challenging task, as shown in recent studies about neural vocoders <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>.  <ref type="figure">Figure 1</ref>: Private aggregation of teachers ensemble (PATE) learning process <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>: (a) the teacher prediction models training from sensitive data; (b) a joint generative model (e.g., adversarial autoencoder <ref type="bibr" target="#b17">[18]</ref> for audio synthesis in this study); (c) student prediction model training from non-sensitive data.</p><p>In this study, we introduce an adversarial autoencoder <ref type="bibr" target="#b17">[18]</ref> (AAE) based model into PATE to improve the generative process for privacy-preserving speech classification. PATE-AAE first adapts an autoencoder to minimize a reconstruction loss, training on sensitive data. As shown in <ref type="figure">Fig. 1(a)</ref>, the generative model produces synthetic data as non-sensitive samples. Meanwhile, the training data are divided into I isolated subsets to train individual teacher classifiers. For instance, I is equal to 3 in <ref type="figure">Fig. 1(b)</ref>. The teacher classifiers then undergo an output aggregation process to generate noisy labels, which ensures the ?-differentially private protection. Finally, a student classifier uses the labeled synthetic samples (non-sensitive data) for training its model. The proposed PATE-AAE framework is assessed with the Google Speech Commands Dataset Version II <ref type="bibr" target="#b18">[19]</ref>. Our experimental evidence demonstrates competitive results in terms of synthetic sample quality and classification accuracy with a strong ?-DP guarantee (? &lt; 1) considering established privacy-preserving learning (PPL) works <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20]</ref>. To the best of the authors' knowledge, this is the first attempt to introduce the PATE architecture into a speech classification task. Moreover, the proposed solution is benefited from adversarial autoencoder block, with advantages over existing GAN solutions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13]</ref> of having a better test-likelihood estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Much of research effort to preserve data privacy in a machine learning model can be categorized into one of the two main groups: (i) systemic, such as federated learning <ref type="bibr" target="#b20">[21]</ref>, data isolation <ref type="bibr" target="#b21">[22]</ref>, and data encryption <ref type="bibr" target="#b22">[23]</ref>, and (ii) algorithmic, mainly differential private machine learning <ref type="bibr" target="#b6">[7]</ref>. In the following sections, we first briefly discuss some of the privacy-preserving solutions proposed for speech applications. Next, we describe the substratum of differential privacy devised for machine learning applications and discuss the difference with our proposed approach while highlighting its key contributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Privacy-Preserving Speech Processing</head><p>Federated architectures <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b21">22]</ref> have been studied in the speech processing community to increase privacy protection. For example, the average gradient method <ref type="bibr" target="#b23">[24]</ref> was used to update the learning model for decentralized training <ref type="bibr" target="#b24">[25]</ref>. Heterogeneous computing architectures <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b26">26]</ref> shows advantages on acoustic feature extraction for vertical federate learning. However, those approaches at a system-level usually make some assumptions on the limited accessibility of the malicious attackers and provide less universal measures about the privacy guarantees. There exist also some algorithmic efforts on investigating privacy-preserving speech processing by using cryptographic encryption <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b27">27]</ref>, and computation protocols <ref type="bibr" target="#b28">[28]</ref>. Meanwhile, these encryption algorithms and protocols barely cover the training sample-level privacy protection, which plays a major role in deploying large-scale machine learning models.</p><p>However, differentially private algorithms <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b29">29]</ref> is with a different focus from the aforementioned frameworks, aiming to provide quantitative guarantees and further prevent identity (e.g., accent) inference. We define a mathematical formation of differential privacy and investigate potential impacts on speech processing in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Differential Privacy Fundamentals</head><p>The differential privacy mechanism <ref type="bibr" target="#b5">[6]</ref> is an established standard to deploy algorithms with a target privacy guarantee. Definition 1. A randomized algorithm M with domain D and range R is (?, ?)-differentially private if for any two neighboring inputs (e.g., acoustic data) d, d ? D and for any subset of outputs (e.g., labels) S ? R, the following holds:</p><formula xml:id="formula_0">Pr[M(d) ? S] ? e ? Pr M d ? S + ?.<label>(1)</label></formula><p>The above definition provides a notion of privacy that can be interpreted as a measure of the probabilistic difference of a specific outcome by a multiplicative factor, e ? , and an additive amount, ?. Both ? and ? should be positive or equal to zero. Considering ? ? 0 with only minor relaxation, a smaller value of ? indicates a stronger (?, 0)-differentially private guarantee. In other words, nearly equal probabilities in Eq. 1 would be given from the neighboring inputs d and d , which makes data identity much hard to be inference. Moreover, learning from post-processing features (e.g., mel-frequency cepstral coefficients (MFCC)) from the data could also be differentially private, which have been proofed by the theorem given in <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Differential Privacy for Machine Learning</head><p>More recently, Abadi et al. <ref type="bibr" target="#b6">[7]</ref> introduced the composition theorem <ref type="bibr" target="#b29">[29]</ref>, which guarantees the validity of DP protection when batch-wise training is used to learn deep neural network (DNN) parameters with non-convex objective functions. DP-GAN <ref type="bibr" target="#b19">[20]</ref> incorporated noisy perturbations into a generative model during gradient updates to satisfy ?-DP but shows degraded prediction accuracy. Recent advances in teacher-student ensembles methods, such as PATE <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>, have further shown state-of-the-art performance on large-scale image classification tasks with sufficient non-sensitive data. Jordon et al. <ref type="bibr" target="#b12">[13]</ref> instigated a GAN-based <ref type="bibr" target="#b30">[30]</ref> generator into PATE to extend using scenarios with sufficient synthetic data (as non-sensitive), which is called PATE-GAN <ref type="bibr" target="#b12">[13]</ref>. PATE-GAN is aligned with our motivation, but it only shows a stable performance for a small amount and low dimensional data. Meanwhile, application of PATE to large-scale speech processing, such as spokenterm classification, is practically absent despite the sensitive nature of the speech signals. In this study, we propose an autoencoder based approach incorporating PATE into speech processing, which considers non-sensitive acoustic data is not accessible. We will introduce an adversarial autoencoder with PATE to ensure ?-DP for the acoustic modeling in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PATE-AAE Framework</head><p>The proposed method consists of AAE and PATE models with feature encoders <ref type="bibr" target="#b31">[31]</ref>. We focus on the application of PATE for speech processing, which is often in shortage of nonsensitive human voice data and more severe than in the original PATE <ref type="bibr" target="#b9">[10]</ref>. It should be noted that PATE-GAN has succeeded in synthesizing low dimensional data (e.g., short sequences of EEG) but has failed when dealing with high-dimension data (e.g., images). This could be due to its difficulties of using a random noise generator to match input data distribution from sample discriminator in standard GAN <ref type="bibr" target="#b30">[30]</ref> training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Private Aggregation of Teacher Ensembles</head><p>We describe the foundation <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref> of PATE to empower privacy-preserving speech classification. First, an ensemble of teacher models is built by partitioning the training dataset of images into n disjoint subsets: D1, ..., DI . Next, each subset is used to train I classifier independently: T1, ..., TI , that is, the teacher models. For each input data x, we aggregate prediction outputs from the teacher models to a single prediction. The number, cj(x), of teachers, that output class j for the given input x with m possible classes is set to be:</p><p>cj(x) = |{Ti : Ti(x) = j}| for j = 1, . . . , m.</p><p>A random perturbation was introduced into the vote count, cj, in Eq. (2) to obtain a noisy final prediction:</p><formula xml:id="formula_2">FPATE(x, ?) = arg max j?[m] (cj(x) + Yj(?)) ,<label>(3)</label></formula><p>where Y1, ..., Ym are i.i.d. Lap(?) random variables with location 0 and scale ? ?1 . ? refers to a privacy parameter that influences ( , ?)-differentially private guarantees and has been proven its bounded properties under composition theorems applying for model aggregation in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>. As shown in <ref type="figure">Figure 1</ref>, the next step in the PATE mechanism is based on a knowledge transfer process, where the noisy ensemble output is used to relabel a non-sensitive dataset, having a total sample number equal to K, which in turn is used to train a student model, S. Both prediction outputs and the trained student model's internal parameters are free from querying requests, which allows the privacy cost only associated with acquiring the training data for the student model. Under the aforementioned data setup, the student model is (?, 10 ?5 )-differentially private guarantee using ? = K 2? from the analysis in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>. According to Eq. (3), a large ? refers to a smaller ? providing a strong privacy guarantee but degrade the accuracy of the labels from the noisy maximum prediction output of the PATE function. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">PATE with Adversarial Autoencoder (PATE-AAE)</head><p>We introduce AAE training as follows. Instead of training the noisy generator as in GAN, AAE leverages upon an autoencoder-based regression model to minimize a reconstruction loss between input data (x) and decoded output (x ). The bottleneck vector (latent space z) is modeling as variational autoencoder <ref type="bibr" target="#b32">[32]</ref> but uses a discriminator to refine z closing to a real vector (?) sampling from a fixed Gaussian distribution as shown in <ref type="figure" target="#fig_0">Fig. 2(a)</ref>. This discriminative training resulted in a better test-likelihood on synthetic samples <ref type="bibr" target="#b17">[18]</ref>. The recent success <ref type="bibr" target="#b31">[31]</ref> of probabilistic autoencoder for audio synthesis motivates our solution that combines PATE with AAE for spoken command classification. Let x and z be the input and the bottleneck latent vector of an encoder-decoder model, respectively. The universal approximator posterior q(z) introduced <ref type="bibr" target="#b17">[18]</ref> is:</p><formula xml:id="formula_3">q(z | x) = ? q(z | x, ?)p?(?)d? (4) ? q(z) = x ? q(z | x, ?)p d (x)p?(?)d?dx,<label>(5)</label></formula><p>where the stochasticity in q(z) comes from both the datadistribution x and the random noise ? with a fixed Gaussian distribution at the input of the encoder. The adversarial training procedure can match q(z) to p(z) by back-propagation through the encoder network directly. The encoder encodes an input data x into latent vector, z i ? N (?i(x), ?i(x)), by variational inference used in <ref type="bibr" target="#b32">[32]</ref>. Therefore, a training objective for reconstructing input x is computed by minimizing the following upper-bound on the negative log-likelihood of x:</p><formula xml:id="formula_4">Ex E q(z|x) [? log(p(x | z)]] + Ex[KL(q(z | x) p(z))]. (6)</formula><p>Makhzani et al. <ref type="bibr" target="#b17">[18]</ref> further introduce a discriminative update into the second terms of Eq. (6) that makes q(z) to match to the distribution of p(z) to train an AAE. The discriminative training objective between the latent vector z (denoted as a fake sample as 0) and the sampling noise ? (denoted as a real sample as 1) is computed by BCE loss and back-propagated gradients to input data (x) for updating encoder's parameters <ref type="figure" target="#fig_0">(Fig. 2 (a)</ref>).</p><p>Next, for training teacher models, we partition the sensitive dataset into n subsets, D1, . . . , DI , with |Di| = |D| I for ?q. Each teacher model (Ti) is training with discriminator loss:</p><formula xml:id="formula_5">LT i = ?( log Ti (q(z))+ I j=1 log 1 ? Ti q z j ) (7)</formula><p>To generate synthetic samples for training student model, we take I samples of Gaussian distribution, ?1, ..., ?I using the trained AAE decoder network (G) to synthesize sample?j = G (?j) for each class. Following the PATE mechanism for knowledge transfer, the aggregated noisy output from the teachers models in Eq. (7) labels the synthetic data for training a differentially private student model, where noisy label refers rj = PATE (?j, ?) from Eq. <ref type="formula" target="#formula_2">(3)</ref>. Finally, we train the student model to maximize the standard cross-entropy loss on this teacher-labeled data:</p><formula xml:id="formula_6">LS = I j=1 rj log S (?j) + (1 ? rj) log (1 ? S (?j)) (8)</formula><p>We train G, T1, ..., TI and S iteratively, with each iteration of G consisting of first performing gradient updates on all teachers, then performing gradient updates of the student. The major difference between proposed PATE-AAE and PATE-GAN <ref type="bibr" target="#b12">[13]</ref> is on the generative process. Proposed AAE method uses a regression autoencoder architecture to reconstruct the input samples and use a random variable for the refined latent space as the decoder (generator) input for generating new synthetic samples. Instead, PATE-GAN adapts discriminator on the sample generator directly to refine the learning process from random noise to synthetic data, which produces worse test-likelihood on high dimensional data from previous studies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b33">33]</ref> related to the convergence properties <ref type="bibr" target="#b34">[34]</ref> of GAN. To conduct privacy-preserving speech processing frameworks, we select PATE-GAN <ref type="bibr" target="#b12">[13]</ref>, and DP-GAN <ref type="bibr" target="#b19">[20]</ref> as baselines in our studies motivated by the condition of without any available nonsensitive audio dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>(1) Dataset and Classifier Model: A large-scale dataset (?100k training samples) for the partition process is needed in our experiments. Therefore, we have chosen the Google Speech Commands V2 <ref type="bibr" target="#b18">[19]</ref> task, which contains 105,829 utterances of 35 words from 2,618 speakers with a sampling rate of 16 kHz. The audio length per sample clip is 1 second for a total amount of 55.5 hours. We split the dataset into I=200 <ref type="bibr" target="#b12">[13]</ref> disjoint subsets to train individual teacher classifiers following the procedure indicated in Eq. <ref type="bibr" target="#b6">(7)</ref>. We use the mel-spectrogram feature with an 80-band mel-scale and 1024 points of discrete Fourier transform as inputs to the classifiers. For a fair comparison, both teacher and student classifiers use an identical selfattention <ref type="bibr" target="#b35">[35]</ref> and U-Net <ref type="bibr" target="#b36">[36]</ref> based neural network proposed in the recent work <ref type="bibr" target="#b21">[22]</ref>, which has shown benchmark prediction accuracy on the selected speech commands dataset.</p><p>(2) Encoder-Decoder Model: For encoder-decoder inputs, we use standard 13 MFCC at a sampling rate of 100 Hz from 80 log-mel filter-bank features on training (x) and synthetic (u) data. We carefully build our encoder-decoder upon a WaveNetbased autoencoder presented in <ref type="bibr" target="#b31">[31]</ref>, which has shown competitive performance for unsupervised speech synthesis tasks. As shown in <ref type="figure" target="#fig_1">Fig 3(a)</ref>, our encoder has four network blocks associated 768 input units, which include the first ResNet layer, a convolution layer with a stride scale = 2, the second ResNet layer, and a Dense layer with ReLU activation. The latent representation z is computed by outputs (?, ?) from two linear layers with 128 units. As shown in <ref type="figure" target="#fig_1">Fig 3(b)</ref>, our decoder applied a randomized dropout layer from an output of the discriminator, which is selected from a latent vector (z) or a random vector (?). The output vector is then upsampled 320 times to fit the 16 kHz sampling rate for WaveNet decoding. Finally, we follow the same setting with <ref type="bibr" target="#b31">[31]</ref> for running two cycles of WaveNet with 20 convolution layers followed by a 256-ReLU layer. We follow ?-law companding transformation <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b16">17]</ref> with 256 quantization levels to generate raw 16k Hz audio. (3) Synthesis and Classification Evaluation Metrics: For the speech synthesis task, the Frechet Inception Distance (FID) <ref type="bibr" target="#b38">[38]</ref> is selected to evaluate the sample quality that computes the Frechet Distance <ref type="bibr" target="#b39">[39]</ref> between two multivariate Gaussian distributions for the synthetic and real samples. We follow a standard FID setup in <ref type="bibr" target="#b14">[15]</ref> to evaluate the quality of over 10,000 synthetic speech samples generated from random noise. For the speech command classification task, classification accuracy is used to evaluate the student model. We train each privacy-preserving model 20 times and report its average prediction accuracy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results and Performance Analysis</head><p>We have developed two baseline systems, namely PATE-GAN <ref type="bibr" target="#b12">[13]</ref> and DP-GAN <ref type="bibr" target="#b19">[20]</ref>, whose models are using the same encoder-decoder architecture introduced in Sec. 4.1.</p><p>(2). First, as shown in Tab. 1, PATE-AAE performs best (lowest) FID scores compared with PATE-GAN and DP-GAN, which indicates a good capability of privacy-preserving speech synthesis. According to a visualization presented in <ref type="figure">Fig. 4 (a)</ref>, PATE-AAE demonstrates many detailed acoustic features on its mel-spectrogram, where PATE-GAN's mel-spectrogram at most preserves intensity information. Next, we have investigated the prediction accuracy in terms of different target privacy budgets with the constraint of guaranteeing (?, 10 ?5 )differential privacy. The classification results are averaged over 20 trials to reduce the effect of random parameters initialization. <ref type="figure">Fig. 5</ref> summarises our results. As a fair comparison, a visual inspection of <ref type="figure">Fig. 5</ref> reveals that the two baseline systems and the proposed PATE-AAE system attain a similar average classification accuracy with an extremely weak privacy budget (?=100). As the constraints on the privacy increases, that is, is reduced (the noisy level, ? = K 2? , is increased). Simultaneously, the proposed PATE-AAE approach exemplifies its advantage over both the DP-GAN and PATE-GAN solutions. In particular, PATE-AAE boosts the average accuracy by 2.11% (?=0.01) and 1.11% (?=0.1) compared with PATE-GAN; 6.60% (?=0.01) and 5.32% (?=0.1) compared with DP-GAN. With a large ? value, the noise level (?) becomes too small; nonetheless, PATE-AAE still attains a slightly better average accuracy (92.37%) than PATE-GAN (92.19%) and DP-GAN (92.02%) baselines. This phenomenon could be due to the aggregation in PATEs ameliorating the negative impact of ?-DP noise and echoing theoretical studies in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we incorporate an adversarial autoencoder into the PATE scheme. We further investigate different privacypreserving solutions to speech command classification by combining the WaveNet based encoder-decoder structures and classification models together. The proposed PATE-AAE approach shows the best performances in terms of synthetic speech quality scores and classification accuracy. Our future work includes exploring different ?-DP distributed training strategies, such as average gradient aggregation <ref type="bibr" target="#b13">[14]</ref> and adversarial training <ref type="bibr" target="#b40">[40]</ref>, for large vocabulary continuous speech recognition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>The proposed PATE-AAE framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>PATE-AAE encoder-decoder architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Mel-spectrogram of (a) PATE-GAN; (b) PATE-AAE with a privacy target (?=0.1), where output command is "right." Performance of different privacy-preserving models under four levels of privacy target (?, with a fixed ?=10 ?5 ), which refers to the Laplace noise level at scale of ? = K 2? .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>FID scores (lower is better) for speech synthesis quality by generative models with ?-DP (a fixed ?=10 ?5 ) settings. 2?0.5 32.2?0.<ref type="bibr" target="#b5">6</ref> 28.8?0.4 26.7?0.3 24.9?0.3 PATE-GAN [13] 33.4?0.5 30.1?0.4 27.9?0.3 26.0?0.3 24.3?0.1 PATE-AAE 30.2?0.4 28.6?0.3 26.3?0.2 24.7?0.2 24.0?0.1</figDesc><table><row><cell cols="2">privacy target (?)</cell><cell>0.01</cell><cell>0.1</cell><cell>1</cell><cell>10</cell><cell>100</cell></row><row><cell>DP-GAN [20] 0 512 1024 2048 4096 8192 Hz</cell><cell cols="2">35.Time</cell><cell>-30 dB -25 dB -20 dB -15 dB -10 dB -5 dB</cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Privacypreserving speech processing: cryptographic and string-matching frameworks show promise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Rane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE signal processing magazine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="62" to="74" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The eu general data protection regulation (gdpr)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Voigt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Von</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bussche</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">3152676</biblScope>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
	<note>A Practical Guide. 1st Ed</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The california consumer privacy act of 2018: A sea change in the protection of california consumers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Chylik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Business Lawyer</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model inversion attacks that exploit confidence information and basic countermeasures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 22nd ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1322" to="1333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Extracting training data from large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Erlingsson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.07805</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Differential privacy: A survey of results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on theory and applications of models of computation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2016 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Guidelines for implementing and auditing differentially private systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Messing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.04049</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A differentially private stochastic gradient descent algorithm for multiparty classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="933" to="941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Semi-supervised knowledge transfer for deep learning from private training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Relational teacher student learning with neural label embedding for device adaptation in acoustic scene classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Siniscalchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech 2020</title>
		<meeting>Interspeech 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1196" to="1200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Scalable private learning with pate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Erlingsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pate-gan: Generating synthetic data with differential privacy guarantees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gs-wgan: A gradientsanitized approach for learning differentially private generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Orekondy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">High-fidelity audio generation and representation learning with guided adversarial autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Schuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="223" to="509" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A wavenet for speech denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rethage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Serra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5069" to="5073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03499</idno>
		<title level="m">Wavenet: A generative model for raw audio</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Adversarial autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Frey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05644</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Speech commands: A dataset for limited-vocabulary speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03209</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Differentially private generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.06739</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Federated learning for keyword spotting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gisselbrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dureau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6341" to="6345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Decentralizing feature extraction with quantum convolutional neural network for automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Siniscalchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.13309</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Privacy preserving encrypted phonetic search of speech data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Glackin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dugan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cannings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tahir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">G</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rajarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6414" to="6418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A federated approach in training acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dimitriadis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kumatani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gmyr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gaur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Eskimez</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Submodular rank aggregation on score-based permutations for distributed automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tejedor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint/>
	</monogr>
	<note>ICASSP</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="3517" to="3521" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Federated quantum machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yoo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12010</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Voiceguard: Secure and private speech processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Brasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Frassetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Riedhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-R</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weinert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in Interspeech</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1303" to="1307" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Privacy-preserving speaker verification and identification using gaussian mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="397" to="406" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Boosting and differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">N</forename><surname>Rothblum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE 51st Annual Symposium on Foundations of Computer Science</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Unsupervised speech representation learning using wavenet autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">speech, and language processing</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2041" to="2053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Gan-leaks: A taxonomy of membership inference attacks against generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2020 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="343" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">On convergence and stability of gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kodali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Abernethy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07215</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Attention is all you need,&quot; in NIPS</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Pulse code modulation (pcm) of voice frequencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Recommendation</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<pubPlace>ITU</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">How good is my gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shmelkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Alahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The fr?chet distance between multivariate normal distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dowson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Landau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of multivariate analysis</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="450" to="455" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Characterizing speech adversarial examples using self-attention u-net enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint/>
	</monogr>
	<note>ICASSP</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="3107" to="3111" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
