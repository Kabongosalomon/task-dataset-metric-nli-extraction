<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Published as a conference paper at ICLR 2021 DOMAIN GENERALIZATION WITH MIXSTYLE</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Surrey</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
							<email>yongxin.yang@surrey.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
							<email>yu.qiao@siat.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Surrey</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shenzhen Institutes of Advanced Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
							<email>t.xiang@surrey.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Surrey</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Published as a conference paper at ICLR 2021 DOMAIN GENERALIZATION WITH MIXSTYLE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Though convolutional neural networks (CNNs) have demonstrated remarkable ability in learning discriminative features, they often generalize poorly to unseen domains. Domain generalization aims to address this problem by learning from a set of source domains a model that is generalizable to any unseen domain. In this paper, a novel approach is proposed based on probabilistically mixing instancelevel feature statistics of training samples across source domains. Our method, termed MixStyle, is motivated by the observation that visual domain is closely related to image style (e.g., photo vs. sketch images). Such style information is captured by the bottom layers of a CNN where our proposed style-mixing takes place. Mixing styles of training instances results in novel domains being synthesized implicitly, which increase the domain diversity of the source domains, and hence the generalizability of the trained model. MixStyle fits into mini-batch training perfectly and is extremely easy to implement. The effectiveness of MixStyle is demonstrated on a wide range of tasks including category classification, instance retrieval and reinforcement learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Key to automated understanding of digital images is to compute a compact and informative feature representation. Deep convolutional neural networks (CNNs) have demonstrated remarkable ability in representation learning, proven to be effective in many visual recognition tasks, such as classifying photo images into 1,000 categories from ImageNet <ref type="bibr" target="#b20">(Krizhevsky et al., 2012)</ref> and playing Atari games with reinforcement learning <ref type="bibr" target="#b31">(Mnih et al., 2013)</ref>. However, it has long been discovered that the success of CNNs heavily relies on the i.i.d. assumption, i.e. training and test data should be drawn from the same distribution; when such an assumption is violated even just slightly, as in most realworld application scenarios, severe performance degradation is expected <ref type="bibr" target="#b14">(Hendrycks &amp; Dietterich, 2019;</ref><ref type="bibr" target="#b35">Recht et al., 2019)</ref>.</p><p>Domain generalization (DG) aims to address such a problem <ref type="bibr" target="#b58">(Zhou et al., 2021;</ref><ref type="bibr" target="#b1">Blanchard et al., 2011;</ref><ref type="bibr" target="#b33">Muandet et al., 2013;</ref><ref type="bibr" target="#b25">Li et al., 2018a;</ref><ref type="bibr" target="#b56">Zhou et al., 2020b;</ref><ref type="bibr" target="#b0">Balaji et al., 2018;</ref><ref type="bibr" target="#b5">Dou et al., 2019;</ref><ref type="bibr" target="#b2">Carlucci et al., 2019)</ref>. In particular, assuming that multiple source domains containing the same visual classes are available for model training, the goal of DG is to learn models that are robust against data distribution changes across domains, known as domain shift, so that the trained model can generalize well to any unseen domains. Compared to the closely related and more widely studied domain adaptation (DA) problem, DG is much harder in that no target domain data is available for the model to analyze the distribution shift in order to overcome the negative effects. Instead, a DG model must rely on the source domains and focus on learning domain-invariant feature representation in the hope that it would remain discriminative given target domain data.</p><p>A straightforward solution to DG is to expose a model with a large variety of source domains. Specifically, the task of learning domain-invariant and thus generalizable feature representation becomes easier when data from more diverse source domains are available for the model. This would reduce the burden on designing special models or learning algorithms for DG. Indeed, model training with large-scale data of diverse domains is behind the success of existing commercial face recognition or vision-based autonomous driving systems. A recent work by <ref type="bibr">Xu et al. (2021)</ref> also emphasizes the Visualization of style statistics <ref type="figure">Figure 1</ref>: 2-D t-SNE <ref type="bibr" target="#b30">(Maaten &amp; Hinton, 2008)</ref> visualization of the style statistics (concatenation of mean and standard deviation) computed from the first residual block's feature maps of a ResNet-18 <ref type="bibr" target="#b13">(He et al., 2016)</ref> trained on four distinct domains <ref type="bibr" target="#b24">(Li et al., 2017)</ref>. It is clear that different domains are well separated.</p><p>importance of diverse training distributions for out-of-distribution generalization. However, collecting data of a large variety of domains is often costly or even impossible. It thus cannot be a general solution to DG.</p><p>In this paper, a novel approach is proposed based on probabilistically mixing instance-level feature statistics of training samples across source domains. Our model, termed MixStyle, is motivated by the observation that visual domain is closely related to image style. An example is shown in <ref type="figure">Fig. 1</ref>: the four images from four different domains depict the same semantic concept, i.e. dog, but with distinctive styles (e.g., characteristics in color and texture). When these images are fed into a deep CNN, which maps the raw pixel values into category labels, such style information is removed at the output. However, recent style transfer studies <ref type="bibr" target="#b15">(Huang &amp; Belongie, 2017;</ref><ref type="bibr" target="#b6">Dumoulin et al., 2017)</ref> suggest that such style information is preserved at the bottom layers of the CNN through the instance-level feature statistics, as shown clearly in <ref type="figure" target="#fig_1">Fig. 4</ref>. Importantly, since replacing such statistics would lead to replaced style while preserving the semantic content of the image, it is reasonable to assume that mixing styles from images of different domains would result in images of (mixed) new styles. That is, more diverse domains/styles can be made available for training a more domain-generalizable model.</p><p>Concretely, our MixStyle randomly selects two instances of different domains and adopts a probabilistic convex combination between instance-level feature statistics of bottom CNN layers. In contrast to style transfer work <ref type="bibr" target="#b15">(Huang &amp; Belongie, 2017;</ref><ref type="bibr" target="#b6">Dumoulin et al., 2017)</ref>, no explicit image synthesis is necessary meaning much simpler model design. Moreover, MixStyle perfectly fits into modern mini-batch training. Overall, it is very easy to implement with only few lines of code. To evaluate the effectiveness as well as the general applicability of MixStyle, we conduct extensive experiments on a wide spectrum of datasets covering category classification (Sec. 3.1), instance retrieval (Sec. 3.2), and reinforcement learning (Sec. 3.3). The results demonstrate that MixStyle can significantly improve CNNs' cross-domain generalization performance. 1 2 METHODOLOGY 2.1 BACKGROUND Normalizing feature tensors with instance-specific mean and standard deviation has been found effective for removing image style in style transfer models <ref type="bibr" target="#b43">(Ulyanov et al., 2016;</ref><ref type="bibr" target="#b15">Huang &amp; Belongie, 2017;</ref><ref type="bibr" target="#b6">Dumoulin et al., 2017)</ref>. Such an operation is widely known as instance normalization <ref type="bibr" target="#b43">(IN, Ulyanov et al. (2016)</ref>). Let x ? R B?C?H?W be a batch of tensors, with B, C, H and W denoting the dimension of batch, channel, height and width, respectively, IN is formulated as</p><formula xml:id="formula_0">IN(x) = ? x ? ?(x) ?(x) + ?,<label>(1)</label></formula><p>where ?, ? ? R C are learnable affine transformation parameters, and ?(x), ?(x) ? R B?C are mean and standard deviation computed across the spatial dimension within each channel of each instance (tensor), i.e.</p><formula xml:id="formula_1">?(x) b,c = 1 HW H h=1 W w=1 x b,c,h,w ,<label>(2)</label></formula><p>and</p><formula xml:id="formula_2">?(x) b,c = 1 HW H h=1 W w=1 (x b,c,h,w ? ?(x) b,c ) 2 .<label>(3)</label></formula><p>Huang &amp; Belongie (2017) introduced adaptive instance normalization (AdaIN), which simply replaces the scale and shift parameters in Eq.</p><p>(1) with the feature statistics of style input y to achieve arbitrary style transfer:</p><formula xml:id="formula_3">AdaIN(x) = ?(y) x ? ?(x) ?(x) + ?(y).<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MIXSTYLE</head><p>Our method, MixStyle, draws inspiration from AdaIN. However, rather than attaching a decoder for image generation, MixStyle is designed for the purpose of regularizing CNN training by perturbing the style information of source domain training instances. It can be implemented as a plug-andplay module inserted between CNN layers of, e.g., a supervised CNN classifier, without the need to explicitly generate an image of new style.</p><formula xml:id="formula_4">x 1 x 2 x 3 x 4 x 5 x 6 x = [ ] ] x = [ x 4 x 5 x 6 x 1 x 2 x 3 x 1 x 2 x 3 x 4 x 5 x 6 x = [ ] ] x = [ x 1 x 2 x 3</formula><p>x 4 x 5 x 6 (a) Shuffling batch w/ domain label (b) Shuffling batch w/ random shuffle <ref type="figure">Figure 2</ref>: A graphical illustration of how a reference batch is generated. Domain label is denoted by color.</p><p>More specifically, MixStyle mixes the feature statistics of two instances with a random convex weight to simulate new styles. In terms of implementation, MixStyle can be easily integrated into mini-batch training. Given an input batch x, MixStyle first generates a reference batchx from x. When domain labels are given, x is sampled from two different domains i and j, e.g., x = [x i , x j ] (x i and x j have the same batch size). Then,x is obtained by swapping the position of x i and x j , followed by a shuffling operation along the batch dimension applied to each batch, i.e.x = [Shuffle(x j ), Shuffle(x i )]. See <ref type="figure">Fig. 2(a)</ref> for an illustration. In cases where domain labels are unknown, x is randomly sampled from the training data, andx is simply obtained byx = Shuffle(x) (see <ref type="figure">Fig. 2(b)</ref>). <ref type="figure" target="#fig_1">Fig. 4</ref> shows that sub-domains exist within each domain, so even if two instances of the same domain are sampled, new domain could be synthesized. After shuffling, MixStyle computes the mixed feature statistics by</p><formula xml:id="formula_5">? mix = ??(x) + (1 ? ?)?(x), (5) ? mix = ??(x) + (1 ? ?)?(x),<label>(6)</label></formula><p>where ? ? R B are instance-wise weights sampled from the Beta distribution, ? ? Beta(?, ?) with ? ? (0, ?) being a hyper-parameter. Unless specified otherwise, we set ? to 0.1 throughout this paper. Finally, the mixed feature statistics are applied to the style-normalized x,</p><formula xml:id="formula_6">MixStyle(x) = ? mix x ? ?(x) ?(x) + ? mix .<label>(7)</label></formula><p>In practice, we use a probability of 0.5 to decide if MixStyle is activated or not in the forward pass. At test time, no MixStyle is applied. Note that gradients are blocked in the computational graph of ?(?) and ?(?). MixStyle can be implemented with only few lines of code. See Algorithm 1 in Appendix A.1 for the PyTorch-like pseudo-code. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">GENERALIZATION IN CATEGORY CLASSIFICATION</head><p>Dataset and implementation details. We choose the PACS dataset <ref type="bibr" target="#b24">(Li et al., 2017)</ref>, a commonly used domain generalization (DG) benchmark concerned with domain shift in image classification. PACS consists of four domains, i.e. Art Painting, Cartoon, Photo and Sketch, with totally 9,991 images of 7 classes. As shown in <ref type="figure">Fig. 1</ref>, the domain shift mainly corresponds to image style changes.</p><p>For evaluation, a model is trained on three domains and tested on the remaining one. Following prior work <ref type="bibr" target="#b55">Zhou et al., 2020a)</ref>, we use ResNet-18 <ref type="bibr" target="#b13">(He et al., 2016)</ref> as the classifier where MixStyle is inserted after the 1st, 2nd and 3rd residual blocks. Our code is based on Dassl.pytorch <ref type="bibr">(Zhou et al., 2020c). 2</ref> Baselines. Our main baselines are general-purpose regularization methods including Mixup <ref type="bibr" target="#b49">(Zhang et al., 2018b)</ref>, Manifold Mixup <ref type="bibr" target="#b45">(Verma et al., 2019)</ref>, DropBlock <ref type="bibr" target="#b11">(Ghiasi et al., 2018)</ref>, CutMix <ref type="bibr" target="#b47">(Yun et al., 2019)</ref> and Cutout <ref type="bibr" target="#b4">(DeVries &amp; Taylor, 2017)</ref>, which are trained using the same training parameters as MixStyle and the optimal hyper-parameter setup as reported in their papers. We also compare with the existing DG methods which reported state-of-the-art performance on PACS. These include domain alignment-based CCSA <ref type="bibr" target="#b32">(Motiian et al., 2017)</ref> and MMD-AAE <ref type="bibr" target="#b27">(Li et al., 2018b)</ref>, Jigsaw puzzle-based JiGen <ref type="bibr" target="#b2">(Carlucci et al., 2019)</ref>, adversarial gradient-based CrossGrad <ref type="bibr" target="#b39">(Shankar et al., 2018)</ref>, meta-learning-based Metareg <ref type="bibr" target="#b0">(Balaji et al., 2018)</ref> and Epi-FCR , and data augmentation-based L2A-OT <ref type="bibr" target="#b55">(Zhou et al., 2020a)</ref>.</p><p>Comparison with general-purpose regularization methods. The results are shown in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>Overall, we observe that the general-purpose regularization methods do not offer any clear advantage over the vanilla    <ref type="figure" target="#fig_1">Fig. 4</ref>(a-c)), which allow random shuffling to produce more diverse "new" domains that lead to a more domain-generalizable model.</p><p>Comparison with state-of-the-art DG methods. Overall, MixStyle outperforms most DG methods by a clear margin, despite being a much simpler method. The performance of MixStyle w/ domain label is nearly 1% better on average than the recently introduced L2A-OT. From a data augmentation perspective, MixStyle and L2A-OT share a similar goal-to synthesize data from pseudo-novel domains. MixStyle accomplishes this goal through mixing style statistics at the feature level. Whereas L2A-OT works at the pixel level: it trains an image generator by maximizing the domain difference (measured by optimal transport) between the original and the generated images, which introduces much heavier computational overhead than MixStyle in terms of GPU memory and training time. It is worth noting that MixStyle's domain label-free version is highly competitive: its 82.8% accuracy is on par with L2A-OT's.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">GENERALIZATION IN INSTANCE RETRIEVAL</head><p>Dataset and implementation details. We evaluate MixStyle on the person re-identification (re-ID) problem, which aims to match people across disjoint camera views. As each camera view is itself a distinct domain, person re-ID is essentially a cross-domain image matching problem. Instead of using the standard protocol where training and test data come from the same camera views, we adopt the cross-dataset setting so test camera views are never seen during training. Specifically, we train a model on one dataset and then test its performance on the other dataset. Two commonly used re-ID datasets are adopted: Market1501 <ref type="bibr" target="#b50">(Zheng et al., 2015)</ref> and Duke <ref type="bibr" target="#b36">(Ristani et al., 2016;</ref><ref type="bibr" target="#b51">Zheng et al., 2017)</ref>. Ranking accuracy and mean average precision (mAP) are used as the performance measures (displayed in percentage). We test MixStyle on two CNN architectures: ResNet-50 <ref type="bibr" target="#b13">(He et al., 2016)</ref> and OSNet . The latter was designed specifically for re-ID. In both architectures, MixStyle is inserted after the 1st and 2nd residual blocks. Our code is based on Torchreid . 3</p><p>Baselines. We compare with three baseline methods: 1) The vanilla model, which serves as a strong baseline; 2) DropBlock, which was the top-performing competitor in <ref type="table" target="#tab_0">Table 1</ref>; 3) Ran-domErase <ref type="bibr" target="#b52">(Zhong et al., 2020)</ref>, a widely used regularization method in the re-ID literature (similar to Cutout).</p><p>Results. The results are reported in <ref type="table" target="#tab_2">Table 2</ref>. It is clear that only MixStyle consistently outperforms the strong vanilla model under both settings with considerable margins, while DropBlock and Ran-domErase are unable to show any benefit. Notably, RandomErase, which simulates occlusion by erasing pixels in random rectangular regions with random values, has been used as a default trick when training re-ID CNNs. However, RandomErase shows a detrimental effect in the cross-dataset re-ID setting. Indeed, similar to DropBlock, randomly erasing pixels offers no guarantee to improve the robustness when it comes to domain shift.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">GENERALIZATION IN REINFORCEMENT LEARNING</head><p>Though RL has been greatly advanced by using CNNs for feature learning in raw pixels <ref type="bibr" target="#b31">(Mnih et al., 2013)</ref>, it has been widely acknowledged that RL agents often overfit training environments while generalize poorly to unseen environments <ref type="bibr" target="#b3">(Cobbe et al., 2019;</ref><ref type="bibr" target="#b16">Igl et al., 2019)</ref>.</p><p>Dataset and implementation details. We conduct experiments on Coinrun <ref type="bibr" target="#b3">(Cobbe et al., 2019)</ref>, a recently introduced RL benchmark for evaluating the generalization performance of RL agents. As shown in <ref type="figure" target="#fig_0">Fig. 3(a)</ref>, the goal in Coinrun is to control a character to collect golden coins while avoiding both stationary and non-stationary obstacles. We follow <ref type="bibr" target="#b16">Igl et al. (2019)</ref> to construct and train our RL agent: the CNN architecture used in IMPALA <ref type="bibr" target="#b7">(Espeholt et al., 2018</ref>) is adopted as the policy network, and is trained by the Proximal Policy Optimization (PPO) algorithm <ref type="bibr" target="#b37">(Schulman et al., 2017)</ref>. Please refer to <ref type="bibr" target="#b16">Igl et al. (2019)</ref> for further implementation details. MixStyle is inserted after the 1st and 2nd convolutional sequences. Training data are sampled from 500 levels while test  Baselines. Following <ref type="bibr" target="#b16">Igl et al. (2019)</ref>, we train strong baseline models and add MixStyle on top of them to see whether MixStyle can bring further improvements. To this end, we train two baseline models: 1) Baseline, which combines weight decay and data augmentation; 5 2) IBAC-SNI (the ? = 0.5 version), the best-performing model in <ref type="bibr" target="#b16">Igl et al. (2019)</ref> which is based on selective noise injection.</p><p>Results. The test performance is shown in <ref type="figure" target="#fig_0">Fig. 3(b)</ref>. Comparing Baseline (blue) with Base-line+MixStyle (orange), we can see that MixStyle brings a significant improvement. Interestingly, the variance is also significantly reduced by using MixStyle, as indicated by the smaller shaded areas (for both orange and red lines). These results strongly demonstrate the effectiveness of MixStyle in enhancing generalization for RL agents. When it comes to the stronger baseline IBAC-SNI (green), MixStyle (red) is able to bring further performance gain, suggesting that MixStyle is complementary to IBAC-SNI. This result also shows the potential of MixStyle as a plug-and-play component to be combined with other advanced RL methods. It is worth noting that Baseline+MixStyle itself is already highly competitive with IBAC-SNI. <ref type="figure" target="#fig_0">Fig. 3(c)</ref> shows the generalization gap from which it can been seen that the models trained with MixStyle (orange &amp; red) clearly generalize faster and better than those without using MixStyle (blue &amp; green). . res1-4 denote the four residual blocks in order in a ResNet architecture. We observe that res1 to res3 contain domain-related information while res4 encodes label-related information. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">ANALYSIS</head><p>Where to apply MixStyle? We repeat the experiments on PACS (category classification) and the re-ID datasets (instance retrieval) using the ResNet architecture. Given that a standard ResNet model has four residual blocks denoted by res1-4, we train different models with MixStyle applied to different layers. For notation, res1 means MixStyle is applied after the first residual block; res12 means MixStyle is applied after both the first and second residual blocks; and so forth. The results are shown in <ref type="table" target="#tab_3">Table 3</ref>. We have the following observations. 1) Applying MixStyle to multiple lowerlevel layers generally achieves a better performance-for instance, res12 is better than res1 on both tasks. 2) Different tasks favor different combinations-res123 achieves the best performance on PACS, while on the re-ID datasets res12 is the best. 3) On both tasks, the performance plunges when applying MixStyle to the last residual block. This makes sense because res4 is the closest to the prediction layer and tends to capture semantic content (i.e. label-sensitive) information rather than style. In particular, res4 is followed by an average-pooling layer, which essentially forwards the mean vector to the prediction layer and thus forces the mean vector to capture label-related information. As a consequence, mixing the statistics at res4 breaks the inherent label space. This is clearer in <ref type="figure" target="#fig_1">Fig. 4</ref>: the features and style statistics in res1-3 exhibit clustering patterns based on domains while those in res4 have a high correlation with class labels.  Mixing vs. replacing. Unlike the AdaIN formulation, which completely replaces one style with the other, MixStyle mixes two styles via a convex combination. <ref type="table" target="#tab_4">Table 4</ref> shows that mixing is better than replacing. This is easy to understand: mixing diversifies the styles (imagine an interpolation between two data points). Random vs. fixed shuffle at multiple layers. Applying MixStyle to multiple layers, which has been shown advantageous in <ref type="table" target="#tab_3">Table 3</ref>, raises another question of whether to shuffle the mini-batch at different layers or use the same shuffled order for all layers. <ref type="table" target="#tab_5">Table 5</ref> suggests that using random shuffle at different layers gives a better performance, which may be attributed to the increased noise level that gives a better regularization effect.</p><p>Sensitivity of hyper-parameter. Recall that ? is used to control the shape of Beta distribution, which has a direct effect on how the convex weights ? are sampled. The smaller ? is, the more likely the value in ? is close to the extreme value of 0 or 1. In other words, a smaller ? favors the style statistics in Eqs. (5) &amp; (6) to be dominated by one side. We first evaluate ? on PACS. <ref type="figure" target="#fig_2">Fig. 5(a)</ref> shows that with ? increasing from 0.1 to 0.4, the accuracy slides from 82.8% to 81.7%. However, further increasing ? does not impact on the accuracy. Therefore, the results suggest that the performance is not too sensitive to ?; and selecting ? from {0.1, 0.2, 0.3} seems to be a good starting point. We further experiment with ? ? {0.1, 0.2, 0.3} on the re-ID datasets and the Coinrun benchmark. Figs. 5(b) &amp; (c) show that in general the variance for the results of different values is small. Therefore, we suggest practitioners to choose ? from {0.1, 0.2, 0.3}, with ? = 0.1 being a good default setting.</p><p>For more analyses and discussions, please see Appendix A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head><p>Domain generalization, or DG, studies out-of-distribution (OOD) generalization given only source data typically composed of multiple related but distinct domains. We refer readers to <ref type="bibr" target="#b58">Zhou et al. (2021)</ref> for a comprehensive survey in this topic. Many DG methods are based on the idea of aligning features between different sources, with a hope that the model can be invariant to domain shift given unseen data. For instance, <ref type="bibr" target="#b27">Li et al. (2018b)</ref> achieved distribution alignment in the hidden representation of an autoencoder using maximum mean discrepancy; <ref type="bibr" target="#b28">Li et al. (2018c)</ref> resorted to adversarial learning with auxiliary domain classifiers to learn features that are domain-agnostic. Some works explored domain-specific parameterization, such as domain-specific weight matrices <ref type="bibr" target="#b24">(Li et al., 2017)</ref> and domain-specific BN <ref type="bibr" target="#b38">(Seo et al., 2020)</ref>. Recently, meta-learning has drawn increasing attention from the DG community <ref type="bibr" target="#b25">(Li et al., 2018a;</ref><ref type="bibr" target="#b0">Balaji et al., 2018;</ref><ref type="bibr" target="#b5">Dou et al., 2019)</ref>. The main idea is to expose a model to domain shift during training by using pseudo-train and pseudo-test domains, both drawn from source domains. Data augmentation has also been investigated for learning domain-invariant models. <ref type="bibr" target="#b39">Shankar et al. (2018)</ref> introduced a cross-gradient training method (Cross-Grad) where source data are augmented by adversarial gradients obtained from a domain classifier. <ref type="bibr" target="#b12">Gong et al. (2019)</ref> proposed DLOW (for the DA problem), which models intermediate domains between source and target via a domainness factor and learns an image translation model to generate intermediate-domain images. Very recently, <ref type="bibr" target="#b55">Zhou et al. (2020a)</ref> introduced L2A-OT to learn a neural network to map source data to pseudo-novel domains by maximizing an optimal transport-based distance measure. Our MixStyle is related to DLOW and L2A-OT in its efforts to synthesizing novel domains. However, MixStyle differs in the fact that it is done implicitly with a much simpler formulation leveraging the feature-level style statistics and only few lines of extra code on top of a standard supervised classifier while being more effective. Essentially, MixStyle can be seen as feature-level augmentation, which is clearly different from the image-level augmentation-based DLOW and L2A-OT.</p><p>Generalization in deep RL has been a challenging problem where RL agents often overfit training environments, and as a result, perform poorly in unseen environments with different visual patterns or levels <ref type="bibr" target="#b48">(Zhang et al., 2018a)</ref>. A natural way to improve generalization, which has been shown effective in <ref type="bibr" target="#b3">(Cobbe et al., 2019;</ref><ref type="bibr" target="#b8">Farebrother et al., 2018)</ref>, is to use regularization, e.g., weight decay. However, <ref type="bibr" target="#b16">Igl et al. (2019)</ref> suggested that stochastic regularization methods like dropout and batch normalization (which uses estimated population statistics) have adverse effect as the training data in RL are essentially model-dependent. As such, they proposed selective noise injection (SNI), which basically combines a stochastic regularization technique with its deterministic counterpart. They further integrated SNI with information bottleneck actor critic (IBAC-SNI) to reduce the variance in gradients. Curriculum learning has been investigated in <ref type="bibr" target="#b18">(Justesen et al., 2018)</ref> where the level of training episodes progresses from easy to difficult over the course of training. <ref type="bibr" target="#b9">Gamrian &amp; Goldberg (2019)</ref> leveraged the advances in GAN-based image-to-image translation <ref type="bibr" target="#b29">(Liu et al., 2017)</ref> to map target data to the source domain which the agent was trained on. <ref type="bibr" target="#b42">Tobin et al. (2017)</ref> introduced domain randomization, which diversifies training data by rendering images with different visual effects via a programmable simulator. With a similar goal of data augmentation,  pre-processed input images with a randomly initialized network. Very recent studies <ref type="bibr" target="#b21">(Laskin et al., 2020;</ref><ref type="bibr" target="#b19">Kostrikov et al., 2020)</ref> have shown that it is useful to combine a diverse set of label-preserving transformations, such as rotation, shifting and Cutout. Different from the aforementioned methods, our MixStyle works at the feature level and is orthogonal to most existing methods. For instance, we have shown in Sec. 3.3 that MixStyle significantly improves upon IBAC-SNI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We presented a simple yet effective domain generalization method, termed MixStyle. MixStyle mixes the feature statistics of two instances to synthesize novel domains, which is inspired by the observation in style transfer work that the feature statistics encode style/domain-related information. Extensive experiments covering a wide range of tasks were conducted to demonstrate that MixStyle yields new state-of-the-art on three different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX</head><p>A.1 PSEUDO-CODE OF MIXSTYLE Algorithm 1 provides a PyTorch-like pseudo-code.</p><p>Algorithm 1 PyTorch-like pseudo-code for MixStyle.    MixStyle between same-domain instances.</p><p>We are interested in knowing if mixing styles between same-domain instances helps performance. To this end, we sample each mini-batch from a single domain during training when using MixStyle. The results are shown in <ref type="table" target="#tab_9">Table 6</ref> where we observe that mixing styles between same-domain instances is about 1% better than the baseline model. This suggests that instancespecific style exists. Nonetheless, the performance is clearly worse than mixing styles between instances of different domains.</p><p>Performance on source domains. To prove that MixStyle does not sacrifice the performance on seen domains in exchange for gains on unseen domains, we report the test accuracy on the held-out validation set of the source domains on PACS in <ref type="table" target="#tab_7">Table 7</ref>.</p><p>Results on Digits-DG and Office-Home. In addition to the experiments on PACS (in Sec. 3.1), we further evaluate MixStyle's effectiveness on two DG datasets, namely Digits-DG <ref type="bibr" target="#b55">(Zhou et al., 2020a)</ref> and Office-Home <ref type="bibr" target="#b44">(Venkateswara et al., 2017)</ref>. Digits-DG contains four digit datasets (domains) including <ref type="bibr">MNIST (LeCun et al., 1998)</ref>, MNIST-M <ref type="bibr" target="#b10">(Ganin &amp; Lempitsky, 2015)</ref>, SVHN <ref type="bibr" target="#b34">(Netzer et al., 2011)</ref> and SYN <ref type="bibr" target="#b10">(Ganin &amp; Lempitsky, 2015)</ref>. Images from different digit datasets differ drastically in font style, stroke color and background. Office-Home is composed of four domains (Artistic, Clipart, Product and Real World) with around 15,500 images of 65 classes for home and office object recognition. The results are shown in <ref type="table" target="#tab_8">Tables 8 and 9</ref> where no domain labels are used in MixStyle. Similar to the results on PACS, here we observe that MixStyle also brings clear improvements to the baseline CNN model and outperforms all general-purpose regularization methods on both Digits-DG and Office-Home. Compared with more sophisticated DG methods like L2A-OT, MixStyle's performance is comparable, despite being much simpler to train and consuming much less computing resources. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>(a) Coinrun benchmark. (b) Test performance in unseen environments. (c) Difference between training and test performance.data are drawn from new levels of only the highest difficulty. As domain labels are difficult to define, we use the random shuffle version of MixStyle. Our code is built on top of<ref type="bibr" target="#b16">Igl et al. (2019)</ref>. 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4</head><label>4</label><figDesc>: 2-D visualization of flattened feature maps (top) and the corresponding style statistics (bottom)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Evaluation on the hyper-parameter ? on (a) PACS, (b) person re-ID datasets and (c) Coinrun. In (b), M and D denote Market1501 and Duke respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Leave-one-domain-out generalization results on PACS.</figDesc><table><row><cell>Method</cell><cell>Art</cell><cell>Cartoon</cell><cell>Photo</cell><cell>Sketch</cell><cell>Avg</cell></row><row><cell>MMD-AAE</cell><cell>75.2</cell><cell>72.7</cell><cell>96.0</cell><cell>64.2</cell><cell>77.0</cell></row><row><cell>CCSA</cell><cell>80.5</cell><cell>76.9</cell><cell>93.6</cell><cell>66.8</cell><cell>79.4</cell></row><row><cell>JiGen</cell><cell>79.4</cell><cell>75.3</cell><cell>96.0</cell><cell>71.6</cell><cell>80.5</cell></row><row><cell>CrossGrad</cell><cell>79.8</cell><cell>76.8</cell><cell>96.0</cell><cell>70.2</cell><cell>80.7</cell></row><row><cell>Epi-FCR</cell><cell>82.1</cell><cell>77.0</cell><cell>93.9</cell><cell>73.0</cell><cell>81.5</cell></row><row><cell>Metareg</cell><cell>83.7</cell><cell>77.2</cell><cell>95.5</cell><cell>70.3</cell><cell>81.7</cell></row><row><cell>L2A-OT</cell><cell>83.3</cell><cell>78.2</cell><cell>96.2</cell><cell>73.6</cell><cell>82.8</cell></row><row><cell>ResNet-18</cell><cell cols="5">77.0?0.6 75.9?0.6 96.0?0.1 69.2?0.6 79.5</cell></row><row><cell>+ Manifold Mixup</cell><cell cols="5">75.6?0.7 70.1?0.9 93.5?0.7 65.4?0.6 76.2</cell></row><row><cell>+ Cutout</cell><cell cols="5">74.9?0.4 74.9?0.6 95.9?0.3 67.7?0.9 78.3</cell></row><row><cell>+ CutMix</cell><cell cols="5">74.6?0.7 71.8?0.6 95.6?0.4 65.3?0.8 76.8</cell></row><row><cell cols="6">+ Mixup (w/o label interpolation) 74.7?1.0 72.3?0.9 93.0?0.4 69.2?0.2 77.3</cell></row><row><cell>+ Mixup</cell><cell cols="5">76.8?0.7 74.9?0.7 95.8?0.3 66.6?0.7 78.5</cell></row><row><cell>+ DropBlock</cell><cell cols="5">76.4?0.7 75.4?0.7 95.9?0.3 69.0?0.3 79.2</cell></row><row><cell>+ MixStyle w/ random shuffle</cell><cell cols="5">82.3?0.2 79.0?0.3 96.3?0.3 73.8?0.9 82.8</cell></row><row><cell>+ MixStyle w/ domain label</cell><cell cols="5">84.1?0.4 78.8?0.4 96.1?0.3 75.9?0.9 83.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>in this DG task, while MixStyle improves upon the vanilla ResNet-18 with a significant margin. Compared with Mixup, MixStyle is 5.2% better on average. Recall that Mixup also interpolates the output space, we further compare with a variant of Mixup in order to demonstrate the advantage of mixing style statistics at the feature level over mixing images at the pixel level for DG-following<ref type="bibr" target="#b40">Sohn et al. (2020)</ref>, we remove the label interpolation in Mixup and sample the mixing weights from a uniform distribution of [0, 1]. Still, MixStyle outperforms this new baseline with a large margin, which justifies our claim. MixStyle and DropBlock share some commonalities in that they are both applied to feature maps at multiple layers, but MixStyle significantly outperforms DropBlock in all test domains. The reason why DropBlock is ineffective here is because dropping out activations mainly encourages a network to mine discriminative patterns, but does not reinforce the ability to cope with unseen styles, which is exactly what MixStyle aims to achieve: by synthesizing "new" styles (domains) MixStyle regularizes the network to become more robust to domain shift. In addition, it is interesting to see that on Cartoon and Photo, MixStyle w/ random shuffle obtains slightly better results. The reason might be because there exist sub-domains in a source domain (see</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Generalization results on the cross-dataset person re-ID task.</figDesc><table><row><cell>Model</cell><cell cols="2">Market1501?Duke mAP R1 R5 R10 mAP R1 Duke?Market1501 R5 R10</cell></row><row><cell>ResNet-50</cell><cell cols="2">19.3 35.4 50.3 56.4 20.4 45.2 63.6 70.9</cell></row><row><cell>+ RandomErase</cell><cell cols="2">14.3 27.8 42.6 49.1 16.1 38.5 56.8 64.5</cell></row><row><cell>+ DropBlock</cell><cell cols="2">18.2 33.2 49.1 56.3 19.7 45.3 62.1 69.1</cell></row><row><cell cols="3">+ MixStyle w/ random shuffle 23.8 42.2 58.8 64.8 24.1 51.5 69.4 76.2</cell></row><row><cell>+ MixStyle w/ domain label</cell><cell cols="2">23.4 43.3 58.9 64.7 24.7 53.0 70.9 77.8</cell></row><row><cell>OSNet</cell><cell cols="2">25.9 44.7 59.6 65.4 24.0 52.2 67.5 74.7</cell></row><row><cell>+ RandomErase</cell><cell cols="2">20.5 36.2 52.3 59.3 22.4 49.1 66.1 73.0</cell></row><row><cell>+ DropBlock</cell><cell cols="2">23.1 41.5 56.5 62.5 21.7 48.2 65.4 71.3</cell></row><row><cell cols="3">+ MixStyle w/ random shuffle 27.2 48.2 62.7 68.4 27.8 58.1 74.0 81.0</cell></row><row><cell>+ MixStyle w/ domain label</cell><cell cols="2">27.3 47.5 62.0 67.1 29.0 58.2 74.9 80.9</cell></row><row><cell>Seen</cell><cell></cell><cell></cell></row><row><cell>Unseen</cell><cell></cell><cell></cell></row><row><cell>(a)</cell><cell>(b)</cell><cell>(c)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Ablation study on where to apply MixStyle in the ResNet architecture.</figDesc><table><row><cell cols="2">(a) Category classification on PACS.</cell><cell cols="2">(b) Cross-dataset person re-ID.</cell></row><row><cell>Model</cell><cell>Accuracy</cell><cell>Model</cell><cell>mAP</cell></row><row><cell>ResNet-18</cell><cell>79.5</cell><cell>ResNet-50</cell><cell>19.3</cell></row><row><cell>+ MixStyle (res1)</cell><cell>80.1</cell><cell>+ MixStyle (res1)</cell><cell>22.6</cell></row><row><cell>+ MixStyle (res12)</cell><cell>81.6</cell><cell>+ MixStyle (res12)</cell><cell>23.8</cell></row><row><cell>+ MixStyle (res123)</cell><cell>82.8</cell><cell>+ MixStyle (res123)</cell><cell>22.0</cell></row><row><cell>+ MixStyle (res1234)</cell><cell>75.6</cell><cell cols="2">+ MixStyle (res1234) 10.2</cell></row><row><cell>+ MixStyle (res14)</cell><cell>76.3</cell><cell>+ MixStyle (res14)</cell><cell>11.1</cell></row><row><cell>+ MixStyle (res23)</cell><cell>81.7</cell><cell>+ MixStyle (res23)</cell><cell>20.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Mixing vs. replacing.</figDesc><table><row><cell></cell><cell>Accuracy (%)</cell></row><row><cell>Mixing</cell><cell>82.8?0.4</cell></row><row><cell>Replacing</cell><cell>82.1?0.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell cols="2">: Random vs. fixed</cell></row><row><cell cols="2">shuffle at multiple layers.</cell></row><row><cell></cell><cell>Accuracy (%)</cell></row><row><cell>Random</cell><cell>82.8?0.4</cell></row><row><cell>Fixed</cell><cell>82.4?0.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Test results on the source domains on PACS. A: Art. C: Cartoon. P: Photo. S: Sketch. 49?0.03 99.47?0.04 99.38?0.02 99.65?0.03 99.50 MixStyle 99.55?0.02 99.54?0.01 99.47?0.03 99.68?0.03 99.56</figDesc><table><row><cell>Method</cell><cell>C,P,S</cell><cell>A,P,S</cell><cell>A,C,S</cell><cell>A,C,P</cell><cell>Avg</cell></row><row><cell>Vanilla</cell><cell>99.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Leave-one-domain-out generalization results on Digits-DG.</figDesc><table><row><cell>Method</cell><cell>MNIST</cell><cell>MNIST-M</cell><cell>SVHN</cell><cell>SYN</cell><cell>Avg</cell></row><row><cell>JiGen</cell><cell>96.5</cell><cell>61.4</cell><cell>63.7</cell><cell>74.0</cell><cell>73.9</cell></row><row><cell>CCSA</cell><cell>95.2</cell><cell>58.2</cell><cell>65.5</cell><cell>79.1</cell><cell>74.5</cell></row><row><cell>MMD-AAE</cell><cell>96.5</cell><cell>58.4</cell><cell>65.0</cell><cell>78.4</cell><cell>74.6</cell></row><row><cell>CrossGrad</cell><cell>96.7</cell><cell>61.1</cell><cell>65.3</cell><cell>80.2</cell><cell>75.8</cell></row><row><cell>L2A-OT</cell><cell>96.7</cell><cell>63.9</cell><cell>68.6</cell><cell>83.2</cell><cell>78.1</cell></row><row><cell>CNN</cell><cell cols="5">95.8?0.3 58.8?0.5 61.7?0.5 78.6?0.6 73.7</cell></row><row><cell cols="6">+ Mixup w/o label interpolation 93.7?0.6 55.2?1.0 61.6?0.9 74.4?0.8 71.2</cell></row><row><cell>+ Manifold Mixup</cell><cell cols="5">92.7?0.4 53.1?0.8 64.4?0.2 76.8?0.5 71.7</cell></row><row><cell>+ CutMix</cell><cell cols="5">94.9?0.2 50.1?0.5 64.1?0.9 78.1?0.7 71.8</cell></row><row><cell>+ Mixup</cell><cell cols="5">94.2?0.5 56.5?0.8 63.3?0.7 76.7?0.6 72.7</cell></row><row><cell>+ Cutout</cell><cell cols="5">95.8?0.4 58.4?0.6 61.9?0.9 80.6?0.5 74.1</cell></row><row><cell>+ DropBlock</cell><cell cols="5">96.2?0.1 60.5?0.6 64.1?0.8 80.2?0.6 75.3</cell></row><row><cell>+ MixStyle (ours)</cell><cell cols="5">96.5?0.3 63.5?0.8 64.7?0.7 81.2?0.8 76.5</cell></row><row><cell>A.2 FURTHER ANALYSIS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Investigation on the effect of mixing styles between same-domain instances.</figDesc><table><row><cell></cell><cell>Accuracy (%)</cell></row><row><cell>ResNet18</cell><cell>79.5</cell></row><row><cell>+ MixStyle w/ same-domain</cell><cell>80.4</cell></row><row><cell>+ MixStyle w/ random shuffle</cell><cell>82.8</cell></row><row><cell>+ MixStyle w/ domain label</cell><cell>83.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Leave-one-domain-out generalization results on Office-Home.</figDesc><table><row><cell>Method</cell><cell>Artistic</cell><cell>Clipart</cell><cell>Product</cell><cell cols="2">Real World Avg</cell></row><row><cell>JiGen</cell><cell>53.0</cell><cell>47.5</cell><cell>71.5</cell><cell>72.8</cell><cell>61.2</cell></row><row><cell>CCSA</cell><cell>59.9</cell><cell>49.9</cell><cell>74.1</cell><cell>75.7</cell><cell>64.9</cell></row><row><cell>MMD-AAE</cell><cell>56.5</cell><cell>47.3</cell><cell>72.1</cell><cell>74.8</cell><cell>62.7</cell></row><row><cell>CrossGrad</cell><cell>58.4</cell><cell>49.4</cell><cell>73.9</cell><cell>75.8</cell><cell>64.4</cell></row><row><cell>L2A-OT</cell><cell>60.6</cell><cell>50.1</cell><cell>74.8</cell><cell>77.0</cell><cell>65.6</cell></row><row><cell>ResNet18</cell><cell cols="3">58.9?0.3 49.4?0.1 74.3?0.1</cell><cell>76.2?0.2</cell><cell>64.7</cell></row><row><cell>+ Manifold Mixup</cell><cell cols="3">56.2?0.4 46.3?0.3 73.6?0.1</cell><cell>75.2?0.2</cell><cell>62.8</cell></row><row><cell cols="4">+ Mixup w/o label interpolation 57.0?0.2 48.7?0.2 71.4?0.6</cell><cell>74.5?0.4</cell><cell>62.9</cell></row><row><cell>+ Cutout</cell><cell cols="3">57.8?0.2 48.1?0.3 73.9?0.2</cell><cell>75.8?0.3</cell><cell>63.9</cell></row><row><cell>+ CutMix</cell><cell cols="3">57.9?0.1 48.3?0.3 74.5?0.1</cell><cell>75.6?0.4</cell><cell>64.1</cell></row><row><cell>+ DropBlock</cell><cell cols="3">58.0?0.1 48.1?0.1 74.3?0.3</cell><cell>75.9?0.4</cell><cell>64.1</cell></row><row><cell>+ Mixup</cell><cell cols="3">58.2?0.1 49.3?0.2 74.7?0.1</cell><cell>76.1?0.1</cell><cell>64.6</cell></row><row><cell>+ MixStyle (ours)</cell><cell cols="3">58.7?0.3 53.4?0.2 74.2?0.1</cell><cell>75.9?0.1</cell><cell>65.5</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Source code can be found at https://github.com/KaiyangZhou/mixstyle-release.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/KaiyangZhou/Dassl.pytorch.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/KaiyangZhou/deep-person-reid.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/microsoft/IBAC-SNI.5  We do not use batch normalization<ref type="bibr" target="#b17">(Ioffe &amp; Szegedy, 2015)</ref> or dropout<ref type="bibr" target="#b41">(Srivastava et al., 2014)</ref> because they are detrimental to the performance, as shown by<ref type="bibr" target="#b16">Igl et al. (2019)</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Metareg: Towards domain generalization using meta-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Generalizing from several related classification tasks to a new unlabeled sample</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyemin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Scott</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Antonio D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Quantifying generalization in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taehoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<title level="m">Improved regularization of convolutional neural networks with cutout</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Domain generalization via model-agnostic learning of semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glocker</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A learned representation for artistic style</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Vincent Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kudlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymir</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yotam</forename><surname>Doron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Firoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Dunning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Generalization and regularization in dqn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Farebrother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Marlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bowling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00123</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Transfer learning for related reinforcement learning tasks via image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shani</forename><surname>Gamrian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">S</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dropblock: A regularization method for convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dlow: Domain flow for adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Arbitrary style transfer in real-time with adaptive instance normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Generalization in reinforcement learning with selective noise injection and information bottleneck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Igl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamil</forename><surname>Ciosek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingzhen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Tschiatschek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Hofmann</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Illuminating generalization in deep reinforcement learning through procedural level generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niels</forename><surname>Justesen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruben</forename><forename type="middle">Rodriguez</forename><surname>Torrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bontrager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Khalifa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Risi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.10729</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Image augmentation is all you need: Regularizing deep reinforcement learning from pixels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Kostrikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13649</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Laskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Stooke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lerrel</forename><surname>Pinto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14990</idno>
		<title level="m">Pieter Abbeel, and Aravind Srinivas. Reinforcement learning with augmented data</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Network randomization: A simple technique for generalization in deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to generalize: Metalearning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Episodic training for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tiana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised image-to-image translation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Playing atari with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5602</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krikamol</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<editor>NeurIPS-W</editor>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<title level="m">Do imagenet classifiers generalize to imagenet? In ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Performance measures and a data set for multi-target, multi-camera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ergys</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning to optimize domain specific normalization for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonguk</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yumin</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongwoo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Domain randomization for transferring deep neural networks from simulation to the real world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tobin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Instance normalization: The missing ingredient for fast stylization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08022</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hemanth</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shayok</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sethuraman</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Manifold mixup: Better representations by interpolating hidden states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">How neural networks extrapolate: From feedforward to graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mozhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><forename type="middle">Shaolei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken-Ichi</forename><surname>Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.06893</idno>
		<title level="m">Remi Munos, and Samy Bengio. A study on overfitting in deep reinforcement learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Scalable person re-identification: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyue</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengjin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unlabeled samples generated by gan improve the person re-identification baseline in vitro</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Random erasing data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Torchreid: A library for deep learning person re-identification in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10093</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Omni-scale feature learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning to generate novel domains for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deep domain-adversarial image generation for domain generalisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Domain adaptive ensemble learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.07325</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.02503</idno>
		<title level="m">Domain generalization: A survey</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
