<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rethinking the compositionality of point clouds through regularization in the hyperbolic space</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Montanaro</surname></persName>
							<email>antonio.montanaro@polito.it</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Valsesia</surname></persName>
							<email>diego.valsesia@polito.it</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Magli</surname></persName>
							<email>enrico.magli@polito.it</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Politecnico di Torino</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Politecnico di Torino</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Politecnico di Torino</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rethinking the compositionality of point clouds through regularization in the hyperbolic space</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Point clouds of 3D objects exhibit an inherent compositional nature where simple parts can be assembled into progressively more complex shapes to form whole objects. Explicitly capturing such part-whole hierarchy is a long-sought objective in order to build effective models, but its tree-like nature has made the task elusive. In this paper, we propose to embed the features of a point cloud classifier into the hyperbolic space and explicitly regularize the space to account for the part-whole hierarchy. The hyperbolic space is the only space that can successfully embed the tree-like nature of the hierarchy. This leads to substantial improvements in the performance of state-of-art supervised models for point cloud classification. * Code of the project: https://github.com/diegovalsesia/HyCoRe Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Is the whole more than the sum of its parts? While philosophers have been debating such deep question since the time of Aristotle, we can certainly say that understanding and capturing the relationship between parts as constituents of whole complex structures is of paramount importance in building models of reality. In this paper, we turn our attention to the compositional nature of 3D objects, represented as point clouds, where simple parts can be assembled to form progressively more complex shapes. Indeed, the complex geometry of an object can be better understood by unraveling the implicit hierarchy of its parts. Such hierarchy can be intuitively captured by a tree where nodes close to the root represent basic universal shapes, which become progressively more complex as we approach the whole-object leaves. Transforming an object into another requires swapping parts by traversing the tree up to a common ancestor part. It is thus clear that a model extracting features, that claim to capture the nature of 3D objects, needs to incorporate such hierarchy.</p><p>In the last years, point cloud processing methods have tried to devise methods to extract complex geometric information from points and neighborhoods. Architectures like graph neural networks <ref type="bibr" target="#b0">[1]</ref> compose the features extracted by local receptive fields, with sophisticated geometric priors <ref type="bibr" target="#b1">[2]</ref> exploiting locality and self-similarity, while a different school of thought argues that simple architectures, such as PointMLP <ref type="bibr" target="#b2">[3]</ref> and SimpleView <ref type="bibr" target="#b3">[4]</ref>, with limited geometric priors are nevertherless very effective. It thus raises a question whether prior knowledge about the data is being exploited effectively.</p><p>In this sense, works such as PointGLR <ref type="bibr" target="#b4">[5]</ref>, Info3D <ref type="bibr" target="#b5">[6]</ref> and DCGLR <ref type="bibr" target="#b6">[7]</ref> recognized the need to reason about local and global interactions in the feature extraction process. In particular, their claim is that maximizing the mutual information between parts and whole objects leads to understanding of local and global relations. Although these methods present compelling results for unsupervised feature extraction, they still fall short of providing significant improvements when finetuned with supervision.</p><p>In our work, we argue that those methods do not fulfill their promise of capturing the part-whole relationship because they are unable to represent the tree-like nature of the compositional hierarchy. Indeed, their fundamental weakness lies in the use of spaces that are either flat (Euclidean) or with positive curvature (spherical). However, it is known that only spaces with negative curvature (hyperbolic) are able to embed tree structures with low distortion <ref type="bibr" target="#b7">[8]</ref>. This is due to the fact that the volume of the Euclidean space grows only as a power of its radius rather than exponentially, limiting the representation capacity of tree-like data with an exponential number of leaves. This unique characteristic has inspired many researchers to represent hierarchical relations in many domains, from natural language processing <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> to computer vision <ref type="bibr" target="#b10">[11]</ref> , <ref type="bibr" target="#b11">[12]</ref>. However, the use of such principles for point clouds and 3D data is still unexplored.</p><p>The main contributions of this paper lie in the following aspects:</p><p>? we propose a novel regularizer to supervised training of point cloud classification models that promotes the part-whole hierarchy of compositionality in the hyperbolic space;</p><p>? this regularizer can be applied to any state-of-art architecture with a simple modification of its head to perform classification with hyperbolic layers in the regularized space, coupled with Riemannian optimization <ref type="bibr" target="#b12">[13]</ref>;</p><p>? we observe a significant improvement in the performance of a number of popular architectures, including state-of-the-art techniques, surpassing the currently known best results on two different datasets;</p><p>? we are the first to experimentally observe the desired part-whole hierarchy, by noticing that the geodesics in hyperbolic space between whole objects pass though common part ancestors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Point Cloud Analysis Point cloud data are sets of multiple points and, in recent years, several deep neural networks have been studied to process them. Early works adapted models for images through 2D projections <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. Later, PointNet <ref type="bibr" target="#b15">[16]</ref> established new models working directly on the raw set of 3D coordinates by exploiting shared architectures invariant to points permutation. Originally, PointNet independently processed individual points through a shared MLP. To improve performance, PointNet++ <ref type="bibr" target="#b16">[17]</ref> exploited spatial correlation by using a hierarchical feature learning paradigm. Other methods <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, treat point clouds as a graph and exploit operators defined over irregular sets to capture relations among points and their neighbors at different resolutions. This is the case of DGCNN <ref type="bibr" target="#b20">[21]</ref>, where the EdgeConv graph convolution operation aggregates features supported on neighborhoods as defined by a nearest neighbor graph dynamically computed in the feature space. Recently, PointMLP <ref type="bibr" target="#b2">[3]</ref> revisits PointNet++ to include the concept of residual connections. Through this simple model, the authors show that sophisticated geometric models are not essential to obtain state-of-the-art performance.</p><p>Part Compositionality Successfully capturing the semantics of 3D objects represented as point clouds requires to learn interactions between local and global information, and, in particular, the compositional nature of 3D objects as constructed from local parts. Indeed, some works have focused on capturing global-local reasoning in point cloud processing. One of the first and most representative works is PointGLR <ref type="bibr" target="#b4">[5]</ref>. In this work, the authors map local features at different levels within the network to a common hypersphere where the global features embedding is made close to such local embeddings. This is the first approach towards modeling the similarities of parts (local features) and whole objects (global features). The use of a hypersphere as embedding space for similarity promotion traces its roots in metric learning works for face recognition <ref type="bibr" target="#b21">[22]</ref>. In addition to the global-local embedding, PointGLR added two other pretext tasks, namely normal estimation and self-reconstruction, to further promote learning of highly discriminative features. Our work significantly differs from PointGLR in multiple ways: i) a positive curvature manifold such as the hypersphere is unable to accurately embed hierarchies (tree-like structures), hence our adoption of the hyperbolic space; ii) we actively promote a continuous embedding of part-whole hierarchies by penalizing the hyperbolic norm of parts proportionally to their number of points (a proxy for part complexity); iii) we move the classification head of the model to the hyperbolic space to exploit our regularized geometry. A further limitation of PointGLR is the implicit assumption of a model generating progressive hierarchies (e.g. via expanding receptive fields) in the intermediate layers. In contrast, our work can be readily adopted by any state-of-the-art model with just a replacement of the final layers. Other works revisit the global-local relations using maximization of mutual information between different views <ref type="bibr" target="#b5">[6]</ref>, clustering and contrastive learning <ref type="bibr" target="#b22">[23]</ref>, distillation with constrast <ref type="bibr" target="#b6">[7]</ref>, self-similarity and contrastive learning with hard negative samples <ref type="bibr" target="#b23">[24]</ref>. Although most of these works include the contrastive strategy, they differ in the way they contrast the positive and negative samples and in the details of the self-supervision procedures, e.g., contrastive loss and point cloud augmentations. We also notice that most these works focus on unsupervised learning, and, while they show that the features learned in this manner are highly discriminative, they are also mostly unable to improve upon state-of-the-art supervised methods when finetuned with full supervision. These approaches differ from the one followed in this paper, where we focus on regularization of a fully supervised method, and we show improvements upon the supervised baselines that do not adopt our regularizer.</p><p>Hyperbolic Learning The intuition that the hyperbolic space is crucial to embed hierarchical structures comes from the work of Sarkar <ref type="bibr" target="#b7">[8]</ref> who proved that trees can be embedded in the hyperbolic space with arbitrarily low distortion. This inspired several works which investigated how various frameworks of representation learning can be reformulated in non-Euclidean manifolds. In particular, <ref type="bibr" target="#b8">[9]</ref> [13] and <ref type="bibr" target="#b9">[10]</ref> were some of the first works to explore hyperbolic representation learning by introducing Riemannian adaptive optimization, Poincar? embeddings and hyperbolic neural networks for natural language processing. The new mathematical formalism introduced by Ganea et al. <ref type="bibr" target="#b9">[10]</ref> was decisive to demonstrate the effectiveness of hyperbolic variants of neural network layers compared to the Euclidean counterparts. Generalizations to other data, such as images <ref type="bibr" target="#b24">[25]</ref> and graphs <ref type="bibr" target="#b25">[26]</ref> with the corresponding hyperbolic variants of the main operations like graph convolution <ref type="bibr" target="#b25">[26]</ref> and gyroplane convolution <ref type="bibr" target="#b11">[12]</ref> have also been studied. In the context of unsupervised learning, new objectives in the hyperbolic space force the models to include the implicit hierarchical structure of the data leading to a better clustering in the embedding space <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b10">[11]</ref>. To the best of our knowledge, no work has yet focused on hyperbolic representations for point clouds. Indeed, 3D objects present an intrinsic hierarchy where whole objects are made by parts of different size. While the smallest parts may be shared across different object classes, the larger the parts the more class-specific they become. This consistently fits with the structure of a tree where simple fundamental parts are shared ancestors of complex objects and hence we show how the hyperbolic space can fruitfully capture this data prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In this section we present our proposed method, named HyCoRe (Hyperbolic Compositional Regularizer). An overview is presented in <ref type="figure" target="#fig_0">Fig. 1</ref>. At a high level, HyCoRe enhances any state-of-the-art neural network model for point cloud classification by 1) replacing its last layers with layers performing transformations in the hyperbolic space (see Sec. 3.2), and 2) regularizing the classification loss to induce a desirable configuration of the hyperbolic feature space where embeddings of parts both follow a hierarchy and cluster according to class labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Compositional Hierarchy in 3D Point Clouds</head><p>The objective of HyCoRe is to regularize the feature space produced by a neural network so that it captures the compositional structure of the 3D point cloud at different levels. In particular, we notice that there exists a hierarchy where small parts (e.g., simple structures like disks, squares, triangles) composed of few points are universal ancestors to more complex shapes included in many different objects. As these structures are composed into more complex parts with more points, they progressively become more specific to an object or class. This hierarchy can be mathematically represented by a tree, as depicted in <ref type="figure" target="#fig_1">Fig.2</ref> where a simple cylinder can be the ancestor of both pieces of a chair or a table. While the leaves in the tree are whole objects, thus belonging to a specific class, their ancestors are progressively more universal the higher up in the hierarchy they sit.  At this point, it is important noting that the graph distance between leaves is determined by the shortest path passing through the first common ancestor for objects in the same or similar classes, while objects from significantly dissimilar classes have the shortest path passing through the root of the hierarchy. In order to ensure that we can embed this tree structure in a feature space, we need a space that preserves the geometrical properties of trees and especially the graph distance. In particular, the embedding space must be able to accommodate the exponential volume growth of a tree along its radius. A classic result by Sarkar <ref type="bibr" target="#b7">[8]</ref> showed that flat Euclidean space does not provide this, leading to high errors when embedding trees, even in high dimensions. On the contrary, the hyperbolic space, a Riemannian manifold with negative curvature, does support exponentially increasing volumes and can embed trees with arbitrarily low distortion. Indeed, the geodesic (shortest path) between two points in this space does pass through points closer to the origin, mimicking the behavior of distance defined over a tree.</p><p>In particular, we will focus on the Poincar? ball model of hyperbolic space. Since hyperbolic space is a non-Euclidean manifold, it cannot benefit from conventional vector representations and linear algebra. As a consequence, classical neural networks cannot operate in such a space. However, we will use extensions <ref type="bibr" target="#b9">[10]</ref> of classic layers defined through the concept of gyrovector spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Hyperbolic Space and Neural Networks</head><p>The hyperbolic space is a Riemannian manifold with constant negative curvature. The curvature determines the metric of a space by the following formula:</p><formula xml:id="formula_0">g R = (? c x ) 2 g E = 2 1 + c x 2 g E<label>(1)</label></formula><p>where g R is the metric tensor of a generic Riemannian manifold, ? c x is the conformal factor that depends on the curvature c and on the point x on which is calculated, and g E is the metric tensor of the Euclidean space R n , i.e., the identity tensor I n . Note how the metric depends on the coordinates (through x ) for c = 0, and how c = 0 yields g R = 2g E , i.e., the Euclidean space is a flat Riemannian manifold with zero curvature. Spaces with c &gt; 0 are spherical, and with c &lt; 0 hyperbolic.</p><p>The Poincar? Ball in n dimensions D n is a hyperbolic space with c = ?1, and it is isometric to other models such as the Lorentz model. The distance and norm are defined as: </p><formula xml:id="formula_1">d D (x, y) = cosh ?1 1 + 2 x ? y 2 (1 ? x 2 )(1 ? y 2 )</formula><p>) ,</p><formula xml:id="formula_2">x D = 2 tanh ?1 ( x )<label>(2)</label></formula><p>Since the Poincar? Ball is a Riemannian manifold, for each point x ? D n we can define a logarithmic map log x : D n ? T x D n that maps points from the Poincar? Ball to the corresponding tangent space T x D n ? R n , and an exponential map exp x : T x D n ? D n that does the opposite. These operations <ref type="bibr" target="#b9">[10]</ref> are fundamental to move from one space to the other and viceversa.</p><p>The formalism to generalize tensor operations in the hyperbolic space is called the gyrovector space, where addition, scalar multiplication, vector-matrix multiplication and other operations are redefined as M?bius operations and work in Riemannian manifolds with curvature c. These become the basic blocks of the hyperbolic neural networks. In particular, we will use the hyperbolic feed forward (FF) layer (also known as M?bius layer). Considering the Euclidean case, for a FF layer, we need a matrix M : R n ? R m to linearly project the input x ? R n to the feature space R m , and, additionally, a translation made by a bias addition, i.e., y + b with y, b ? R m and, finally, a pointwise non-linearity ? : R m ? R m .</p><p>Matrix multiplication, bias and pointwise non-linearity are replaced by M?bius operations in the gyrovector space and become:</p><formula xml:id="formula_3">y = M ?c (x) = 1 ? c tanh Mx x tanh ?1 ( ? c x ) Mx x (3) z = y ? c b = exp c y ? c 0 ? c y log c 0 (b) , ? ?c (z) = exp c z (?(log c 0 (z)))<label>(4)</label></formula><p>where M and b are the same matrix and vector defined above, c is the magnitude of the curvature. Note that when c ? 0 we recover the Euclidean feed-forward layer. An interesting property of the M?bius layer is that it is highly nonlinear; indeed the bias addition in hyperbolic space becomes a nonlinear mapping since geodesics are curved paths in non-flat manifolds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Hyperbolic Compositional Regularization</head><p>Armed with the formalism introduced in the previous section, we are ready to formulate our HyCoRe framework, anticipated in <ref type="figure" target="#fig_0">Fig. 1</ref>. Consider a point cloud P N as a set of 3D points p ? R 3 with N elements. We use any state-of-the-art point cloud processing network as a feature extraction backbone E : R N ?3 ? R m to encode P N in the corresponding feature space. At this point we apply an exponential map exp c x : R m ? D m to map the Euclidean feature vector into the hyperbolic space and then a M?bius layer H : D m ? D f to project the hyperbolic vector in an f -dimensional Poincar? ball. This is the hyperbolic embedding of the whole point cloud P N , i.e., z whole = H(exp(E(P N ))) ? D f . We repeat the same procedure for a sub-part of P N , which we call P N with a number of points N &lt; N , to create the part embedding z part = H(exp(E(P N ))) ? D f in the same feature space as before.</p><p>We now want to regularize the feature space to induce the previously mentioned properties, namely the part-whole hierarchy and clustering according to the class labels. This is performed by defining the following triplet regularizers:</p><formula xml:id="formula_4">R hier (z + whole , z + part ) = max(0, ? z + whole D + z + part D + ?/N )<label>(5)</label></formula><formula xml:id="formula_5">R contr (z + whole , z + part , z ? part ) = max 0, d D (z + whole , z + part ) ? d D (z + whole , z ? part ) + ?<label>(6)</label></formula><p>where z + whole and z + part are the hyperbolic representation of the whole and a part from the same point cloud, while z ? part is the embedding of a part of a different point cloud from a different class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Object A Object B</head><p>Common part ancestor Geodesic path <ref type="figure">Figure 3</ref>: Geodesic path.</p><p>The R hier regularizer in Eq. (5) induces the compositional part-whole hierarchy by promoting part embeddings to lie closer to the center of the Poincar? ball and whole embeddings to be closer to the edge. In particular, we use a variable margin ?/N that depends on the number of points N of the part P N . This means that shapes composed by few points (hence simple universal shapes) will be far from the whole object representation and with lower hyperbolic norm (near the centre). On the other hand, embeddings of larger parts will be progressively closer to the edge of the Poincar? ball, depending on the part size. Since geodesics between two points pass closer to the ball center ( <ref type="figure">Fig. 3)</ref>, this structure we impose to the space allows to visit common part ancestors while traversing a geodesic between two whole objects. This regularization thus mimics a continuous version of a part-whole tree embedded in the Poincar? ball.</p><p>The R contr regularizer in Eq. (6) promotes correct clustering of objects and parts in the hyperbolic space. In particular, parts and whole of the same point cloud are promoted to be close while a part from a different class is mapped far apart with respect to the other whole. It ensures that the parts of a point cloud of a different class are far in terms of geodesic distance. ? is a margin hyperparameter to control the degree of separation between positive and negative samples.</p><p>The two regularizations are included in the final loss in this way: L = L CE + ?R contr + ?R hier <ref type="bibr" target="#b6">(7)</ref> where L CE is the conventional classification loss (e.g., cross-entropy) evaluated on the whole objects. The classification head is a hyperbolic M?bius layer followed by softmax. In principle, one could argue that L CE could already promote correct clustering according to class labels, rendering R contr redundant. However, several works <ref type="bibr" target="#b9">[10]</ref> have noticed that the M?bius-softmax hyperbolic head is weaker than its Euclidean counterpart. We thus found it more effective to evaluate L CE on the whole objects only, and use R contr as a metric penalty that explicitly considers geodesic distances to ensure correct clustering of both parts and whole objects.</p><p>At each iteration of training with HyCoRe we sample shapes with a random N varying within a predefined range. A part is defined as the N nearest neighbors of a random point. In future work, it would be interesting to explore alternative definitions for parts, e.g., using part labels if available but, at the moment, we only address definition via spatial neighbors to avoid extra labeling requirements.  We study the performance of our regularizer HyCoRe on the synthetic dataset ModelNet40 <ref type="bibr" target="#b26">[27]</ref> (12,331 objects with 1024 points, 40 classes) and on the real dataset ScanObjectNN <ref type="bibr" target="#b27">[28]</ref> (15,000 objects with 1024 points, 15 classes). We apply our method over multiple classification architectures, namely the widely popular DGCNN and PointNet++ baselines, as well as the recent state-of-the-art PointMLP model. We substitute the standard classifier with its hyperbolic version (M?bius+softmax), as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. We use f = 256 features to be comparable to the official implementations in the Euclidean space, then we test the model over different embedding dimensions in the ablation study. Moreover, we set ? = ? = 0.01, ? = 1000 and ? = 4. For the number of points of each part N , we select a random number between 200 and 600, and for the whole object a random number between 800 and 1024 to ensure better flexibility of the learned to model to part sizes. We train the models using Riemannian SGD optimization. Our implementation is on Pytorch and we use geoopt <ref type="bibr" target="#b28">[29]</ref> for the hyperbolic operations. Models are trained on an Nvidia A6000 GPU. <ref type="table" target="#tab_1">Table 1</ref> shows the results for ModelNet40 classification. In the first part we report well-known and state-of-the-art supervised models. We retrained PointNet++, DGCNN and the state-of-theart PointMLP as baselines, noting some documented difficulty <ref type="bibr" target="#b37">[38]</ref> with exactly reproducing the <ref type="figure">Figure 4</ref>: Embeddings produced by the hyperbolic encoder, projected to 2 dimensions with hyperbolic UMAP. Each color represents a class; small points correspond to parts; large points correspond to whole objects. Parts are closer to the center, sitting higher in the hierarchy (whole objects at the border may share a common part ancestor reachable via the geodesic connecting the objects).  official results. In addition, the second part of the table reports the performance of methods <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b6">[7]</ref> proposing self-supervised pretraining techniques, after supervised finetuning. Concerning PointGLR <ref type="bibr" target="#b4">[5]</ref>, the most similar method to HyCoRe, we ensure a fair comparison by using only the L2G embedding loss and not the pretext tasks of normal estimation and reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Main Results</head><p>Finally, the last part of the table presents the results with HyCoRe applied to the selected baselines. We can see that the proposed method achieves substantial gains not only compared to the randomly initialized models, but also compared to the finetuned models. When applied to the PointMLP, HyCoRe exceed the state-of-the-art performance on ModelNet40. Moreover, it is interesting to notice that the embedding framework of PointGLR is not particularly effective without the pretext tasks. This is due to the unsuitability of the spherical space to embed hierarchical information, as explained in Sec. 2, and it is indeed not far from results we obtain with our method in Euclidean space. <ref type="table">Table 2</ref> reports the classification results on the ScanObjectNN dataset. Also in this case, HyCoRe significantly improves the baseline DGCNN leading it to be comparable with the state-of-the-art methods such as SimpleView <ref type="bibr" target="#b3">[4]</ref>, PRANet <ref type="bibr" target="#b34">[35]</ref> and MVTN <ref type="bibr" target="#b35">[36]</ref>. In addition, PointMLP that holds the state of the art for this dataset, is further improved by our method and reaches an impressive overall accuracy of 87.2 %, substantially outperforming all the previous approaches. Although the authors in <ref type="bibr" target="#b2">[3]</ref> claim that classification performance has reached a saturation point, we show that including novel regularizers in the training process can still lead to significant gains. This demonstrates that the proposed method leverages novel ideas, complementary to what is exploited by existing architectures, and it is thus able to boost the performance even of state-of-the-art methods. It is also remarkable that an older, yet still popular, architecture like DGCNN is able to outperform complex and sophisticated models such as the Point Transformer, when regularized by HyCoRe. In addition, to further prove that enforcing the hierarchy between parts is useful to build better clusters, we show in <ref type="figure">Fig. 4</ref> a 2D visualization with UMAP of the hyperbolic representations for the ModelNet40 data. Colors denote classes, big points whole objects and small points parts. Besides the clear clustering according to class labels, it is fascinating to notice the emergence of the part-whole hierarchy with part objects closer to the center of the disk. Importantly, some parts bridge multiple classes, such as the ones in the bottom right zoom, i.e., they are found along a geodesic connecting two class clusters, serving as common ancestors. This can happen due to the fact that some simple parts having roughly the same shape appear with multiple class labels during training, and the net effect of R contr is to position them midway across the classes.</p><p>The tree-likeness of the hyperbolic space can be also be seen in the visualization in <ref type="figure" target="#fig_1">Fig. 2 (right)</ref>. There we embed shapes with gradually large number of points up to the whole object made by 1024 points. We can notice that the parts are moved towards the disk edge as more points are added. Furthermore, a quantitative analysis of the part-whole hierarchy is shown in <ref type="table" target="#tab_5">Table 6</ref>. Here we calculated the hyperbolic norms of compositions of labeled parts. We can see that, as the parts are assembled with other parts, their hyperbolic norms grow, up to the whole object that is pushed close to the ball edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation study</head><p>In the following we show an ablation study focusing on the DGCNN backbone and the ScanObjectNN dataset. The dataset selection is motivated by the fact that it is a real dataset, able to provide more stable and representative results compared to ModelNet40.</p><p>We first compare HyCoRe with its Euclidean version (EuCoRe) to investigate the effectiveness of the hyperbolic space. The basic principles and losses are the same, but in EuCoRe distances and network layers are defined in the Euclidean space. <ref type="table" target="#tab_2">Table 3</ref> shows the results. With Hype-DGCNN we indicate the hyperbolic version of DGCNN, as represented in <ref type="figure" target="#fig_0">Fig. 1</ref>, but without any regularization, serving as a baseline to assess the individual effect of the regularizer. We also test the models over a different number of embedding dimensions. We can see that EuCoRe only provides a modest improvement, underlining the importance of the hyperbolic space. We also notice that the hyperbolic baseline struggles to be on par with its Euclidean counterpart, as observed by many recent works <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b9">[10]</ref>. However, when regularized with HyCoRe, we can observe significant gains, even in low dimensions. This also leaves an open research question, about whether better hyperbolic baselines could be built so that HyCoRe starts from a less disadvantaged point.</p><p>In <ref type="table" target="#tab_3">Table 4</ref> we ablate HyCoRe by removing one of the two regularizers. We can see that the combination of the two provides the overall best gain.</p><p>In order to study the effect of different space curvatures c, <ref type="table" target="#tab_4">Table 5</ref> evaluates HyCoRe from the standard curvature 1 down to 0.01. We remark that some works <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b38">[39]</ref>, report significant improvements when c is very low (e.g., 0.001), but this is counter-intuitive since the hyperbolic space then resembles an almost flat manifold. On the contrary, we do see improved results at higher curvatures.</p><p>Since HyCoRe constrains the network to learn the relations between parts and whole object, we claim that, at the end of the training process, the model should be better able to classify coarser objects. In <ref type="figure" target="#fig_2">Figs. 5a and 5b</ref> we show the test accuracy of DGCNN on ModelNet40, when presented with a uniformly subsampled point cloud and with a small randomly chosen and spatially-contiguous part, respectively. Indeed, we can notice that HyCoRe provides a gain up to 20 percentage points for very sparse point clouds, and is also able to successfully detect the object from smaller parts. For a fair comparison, we also report the baseline DGCNN with training augmented by random crops  of parts. Even though the augmentation is useful to improve accuracy, HyCoRe is more effective demonstrating the importance of compositional reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Although deep learning in the hyperbolic space is in its infancy, in this paper we showed how it can successfully capture the hierarchical nature of 3D point clouds, boosting the performance of state-of-the-art models for classification. Reasoning about the relations between objects and the parts that compose them leads not only to better results but also more robust and explainable models. In the future, it would be interesting to explore different ways of defining parts, not based on spatial nearest neighbors but rather on more semantic constructions. One important extension is to adapt HyCoRe to segmentation. Since segmentation aims to classify single points and the corresponding parts, contrary to classification, the parts embeddings should be placed on the boundary of the Poincar? Ball, where there is more space to correctly cluster them, and the whole objects (made by composition of parts) near the origin. We could exploit the label of the parts to this end or investigate unsupervised settings where the part hierarchy emerges naturally.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>HyCoRe overview. A point cloud classification model is regularized by promoting the feature space to include compositional information. Hierarchy regularizer: simple parts should be mapped closer to the center of the Poincar? disk (common ancestors of whole objects). Contrastive regularizer: parts of the same class should be embedded closer than parts of other classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>3D objects possess inherent hierarchies due to their nature as compositions of small parts. The hyperbolic space can embed trees and hierarchical structures with lower distortions than the Euclidean space. The number of points in the embedded part point cloud is highlighted in figure. Embeddings shown are experimental results projected to 2D Poincar? disk with hyperbolic UMAP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Test inference of DGCNN on ModelNet40.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Classification results on ModelNet40. *: re-implemented. **: re-implemented but did not exactly reproduce the reference result.</figDesc><table><row><cell>Method</cell><cell></cell><cell></cell><cell>AA(%) OA(%) Training</cell></row><row><cell cols="2">*PointNet++[17]</cell><cell></cell><cell>-</cell><cell>90.5 supervised</cell></row><row><cell cols="2">*DGCNN[21]</cell><cell></cell><cell>90.2</cell><cell>92.9 supervised</cell></row><row><cell cols="3">Point Transformer [30]</cell><cell>90.6</cell><cell>93.7 supervised</cell></row><row><cell cols="2">PA-DGC [31]</cell><cell></cell><cell>-</cell><cell>93.6 supervised</cell></row><row><cell cols="2">CurveNet [32]</cell><cell></cell><cell>-</cell><cell>93.8 supervised</cell></row><row><cell cols="2">**PointMLP[3]</cell><cell></cell><cell>91.2</cell><cell>93.4 supervised</cell></row><row><cell cols="3">**PointMLP (voting)</cell><cell>91.4</cell><cell>93.7 supervised</cell></row><row><cell cols="3">DGCNN+Self-Recon. [33]</cell><cell>-</cell><cell>92.4 finetuned</cell></row><row><cell cols="3">DGCNN+STRL [34]</cell><cell>-</cell><cell>93.1 finetuned</cell></row><row><cell cols="3">DGCNN+DCGLR [7]</cell><cell>-</cell><cell>93.2 finetuned</cell></row><row><cell cols="3">*PointNet++ +PointGLR [5]</cell><cell>-</cell><cell>90.6 finetuned</cell></row><row><cell cols="3">PointNet++ +HyCoRe</cell><cell>-</cell><cell>91.1 regularized</cell></row><row><cell cols="3">DGCNN +HyCoRe</cell><cell>91.0</cell><cell>93.7 regularized</cell></row><row><cell cols="3">PointMLP +HyCoRe</cell><cell>91.7</cell><cell>94.3 regularized</cell></row><row><cell cols="4">PointMLP +HyCoRe (voting) 91.9</cell><cell>94.5 regularized</cell></row><row><cell cols="3">Table 2: Classification results on ScanObjectNN.</cell></row><row><cell>Method</cell><cell cols="2">AA(%) OA(%)</cell></row><row><cell>DGCNN[21]</cell><cell>77.8</cell><cell>80.3</cell></row><row><cell>SimpleView[4]</cell><cell>-</cell><cell>80.8</cell></row><row><cell>PRANet[35]</cell><cell>79.1</cell><cell>82.1</cell></row><row><cell>MVTN[36]</cell><cell>-</cell><cell>82.8</cell></row><row><cell>PointMLP[3]</cell><cell>84.4</cell><cell>86.1</cell></row><row><cell>**PointNeXt[37]</cell><cell>86.4</cell><cell>88.0</cell></row><row><cell cols="2">DGCNN+HyCoRe 80.2</cell><cell>82.1</cell></row><row><cell cols="2">PointMLP+HyCoRe 85.9</cell><cell>87.2</cell></row><row><cell cols="2">PointNeXt+HyCoRe 87.0</cell><cell>88.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Effectiveness of hyperbolic space.</figDesc><table><row><cell cols="2">Average Accuracy (%)</cell></row><row><cell>Dim</cell><cell>16 64 256 512 1024</cell></row><row><cell>DGCNN</cell><cell>76.6 77.5 77.8 76.6 76.3</cell></row><row><cell cols="2">DGCNN+EuCoRe 78.2 78.9 79.0 78.8 79.0</cell></row><row><cell>Hype-DGCNN</cell><cell>76.8 75.9 76.5 76.0 77.5</cell></row><row><cell cols="2">DGCNN+HyCoRe 79.1 80.0 80.2 80.2 79.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Classification results when one of the two regularizations is omitted.</figDesc><table><row><cell></cell><cell cols="2">AA(%) OA(%)</cell></row><row><cell>DGCNN</cell><cell>77.8</cell><cell>80.3</cell></row><row><cell>DGCNN+R hier</cell><cell>77.9</cell><cell>80.5</cell></row><row><cell>DGCNN+R contr</cell><cell>79.2</cell><cell>81.6</cell></row><row><cell cols="2">DGCNN+HyCoRe 80.2</cell><cell>82.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Performance vs. curvature of the</figDesc><table><row><cell>Poincar? Ball</cell><cell></cell><cell></cell></row><row><cell cols="3">Average Accuracy (%)</cell></row><row><cell>Curvature c</cell><cell>1</cell><cell>0.5 0.1 0.01</cell></row><row><cell>Hype-DGCNN</cell><cell cols="2">76.5 76.9 76.6 76.9</cell></row><row><cell cols="3">DGCNN+HyCoRe 80.2 79.4 78.7 78.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Hyperbolic Norms of labeled parts from the whole object up to the single parts.</figDesc><table><row><cell>Table</cell><cell>Plane+uprights</cell><cell cols="2">Legs+uprights Plane</cell><cell>Legs</cell><cell>Uprights</cell></row><row><cell>5.32</cell><cell>4.56</cell><cell>2.08</cell><cell>4.07</cell><cell>2.05</cell><cell>1.99</cell></row><row><cell cols="2">Aircraft Wings+tail+engines</cell><cell>Wings+tail</cell><cell cols="2">Wings Fuselage</cell><cell>Tail</cell></row><row><cell>4.98</cell><cell>4.56</cell><cell>4.45</cell><cell>4.22</cell><cell>3.37</cell><cell>2.94</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Point-gnn: Graph neural network for 3d object detection in a point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rajkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1711" to="1719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Equivariant point network for 3d point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="14" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Rethinking network design and local geometry in point cloud: A simple residual mlp framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.07123</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Revisiting point cloud shape classification with a simple and effective baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR, 2021</title>
		<imprint>
			<biblScope unit="page" from="3809" to="3820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Global-local bidirectional reasoning for unsupervised representation learning of 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5376" to="5385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Info3d: Representation learning on 3d objects using mutual information maximization and contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanghi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="626" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Distillation with contrast is all you need for self-supervised point cloud representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.04241</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Low distortion delaunay embedding of trees in hyperbolic plane</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Graph Drawing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="355" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Poincar? embeddings for learning hierarchical representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hyperbolic neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>B?cigneul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unsupervised discovery of the long-tail in instance segmentation using hierarchical self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Ogut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Limonchik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2603" to="2612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Capturing implicit hierarchical structure in 3D biomedical images with self-supervised hyperbolic representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Riemannian Adaptive Optimization Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Becigneul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O.-E</forename><surname>Ganea</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=r1eiqi09K7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">PVNet: A joint convolutional network of point cloud and multi-view for 3D shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM international conference on Multimedia</title>
		<meeting>the 26th ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">End-to-end learning local multi-view descriptors for 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1919" to="1928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="652" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Relation-shape convolutional neural network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8895" to="8904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pointconv: Deep convolutional networks on 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fuxin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9621" to="9630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">PointCNN: Convolution on X-transformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">146</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4690" to="4699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Unsupervised learning on 3d point clouds by clustering and contrasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.02543</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Self-contrastive learning with hard negative sampling for self-supervised point cloud learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Multimedia</title>
		<meeting>the 29th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3133" to="3142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hyperbolic image embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Khrulkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mirvakhabova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Oseledets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6418" to="6428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining</title>
		<meeting>the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1912" to="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Uy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-K</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1588" to="1597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Geoopt: Riemannian optimization in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kochurov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Karimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kozlukov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Point transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="16" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Paconv: Position adaptive convolution with dynamic kernel assembling on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3173" to="3182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Walk in the cloud: Learning curves for point clouds shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="915" to="924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Self-supervised deep learning on point clouds by reconstructing space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sauder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sievers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Spatio-temporal self-supervised representation learning for 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6535" to="6545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pra-net: Point relation-aware network for 3d point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="4436" to="4448" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Mvtn: Multi-view transformation network for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Giancola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A A K</forename><surname>Hammoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.04670</idno>
		<title level="m">Pointnext: Revisiting pointnet++ with improved training and scaling strategies</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Reproducing PointMLP on ModelNet40</title>
		<ptr target="https://github.com/ma-xu/pointMLP-pytorch/issues/1" />
		<imprint>
			<biblScope unit="page" from="2022" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Hyperbolic Vision Transformers: Combining Improvements in Metric Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ermolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mirvakhabova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Khrulkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Oseledets</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.10833</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
