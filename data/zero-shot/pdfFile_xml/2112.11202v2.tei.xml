<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contrast and Generation Make BART a Good Dialogue Emotion Recognizer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimin</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
							<email>xpqiu@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<region>Guangdong</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Contrast and Generation Make BART a Good Dialogue Emotion Recognizer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In dialogue systems, utterances with similar semantics may have distinctive emotions under different contexts. Therefore, modeling long-range contextual emotional relationships with speaker dependency plays a crucial part in dialogue emotion recognition. Meanwhile, distinguishing the different emotion categories is non-trivial since they usually have semantically similar sentiments. To this end, we adopt supervised contrastive learning to make different emotions mutually exclusive to identify similar emotions better. Meanwhile, we utilize an auxiliary response generation task to enhance the model's ability of handling context information, thereby forcing the model to recognize emotions with similar semantics in diverse contexts. To achieve these objectives, we use the pretrained encoder-decoder model BART as our backbone model since it is very suitable for both understanding and generation tasks. The experiments on four datasets demonstrate that our proposed model obtains significantly more favorable results than the state-of-the-art model in dialogue emotion recognition. The ablation study further demonstrates the effectiveness of supervised contrastive loss and generative loss 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>With the development and popularization of personal intelligent terminal technology and social networks, the importance of constructing a dialogue system that can comprehend user emotions and intentions and conduct effective dialogue interactions has increased significantly. A critical module in the dialogue system is the natural language understanding module that analyzes user behaviors like intents or emotions. Analyzing user sentiments with contextual relationships is an advanced step for simple sentiment classification tasks and is more suitable for usage scenarios in the real world with more research value. The task of emotion recognition in conversation (ERC) is to assign emotion labels to all the utterances in a historical dialogue with a contextual relationship. At the same time, each historical dialogue contains interactions between multiple different speakers, as illustrated in <ref type="figure">Figure 1</ref>.</p><p>There are three challenges for ERC. (1) The first challenge is that the emotion of each utterance may be affected <ref type="bibr">[Jade]</ref>: Oh, Bob, he was nothing compared to you. I had to bite my lip to keep from screaming your name.</p><p>[Chandler]: Well, that makes me feel so good.</p><p>[Jade]: It was just so awkward and bumpy <ref type="bibr">[Ross]</ref>: Bumpy?</p><p>[Chandler]: Well, maybe he had some kind of, uh, new, cool style, that you're not familiar with.</p><p>[Jade]: Well, there really wasn't much time to get used to it, you know what I mean? <ref type="figure">Figure 1</ref>: The conversation flow chart in multi-person dialogue emotion recognition. The solid line indicates that the previous utterance directly influences the current speaker's emotion. The dashed line signifies that the same speaker is influenced by other utterances and expresses different emotions. by contextual information. For example, specific emotions will depend on certain utterances of the context. Meanwhile, utterances with the same expression may have completely different emotions in various contexts. Therefore, effectively modeling the context dependency and the speaker dependency is the main factor distinguishing this task from traditional sentiment classification. (2) The second challenge is that each speaker's emotion is influenced by the utterance of other speakers in the conversation, so there may exist a sudden change in a speaker's emotion. (3) The third challenge lies in semantically similar but different categories of emotions, such as "frustrated" to "sad", "happy" to "excited", etc. It is difficult to distinguish these semantically similar sentiment categories.</p><p>Recent related work addressed contextual dependencies and speaker relations using various graph networks <ref type="bibr" target="#b23">(Shen et al. 2021b;</ref><ref type="bibr" target="#b8">Ghosal et al. 2019;</ref><ref type="bibr" target="#b13">Ishiwatari et al. 2020;</ref><ref type="bibr" target="#b24">Sheng et al. 2020)</ref>. However, as the number of layers deepens, the phenomenon of over-smoothing <ref type="bibr" target="#b2">(Chen et al. 2020a</ref>) starts to appear, resulting in the representation of similar sentiments tending to be indistinguishable. This work deals with the above challenges by better modeling the context and speaker information and auxiliary generation task.</p><p>Firstly, we introduce a dialogue-level Transformer <ref type="bibr" target="#b26">(Vaswani et al. 2017)</ref> layer to model the long-range context dependencies between utterances. A pre-trained language model captures the representation of each utterance. Compared to previous approaches that only adopt pre-trained models as a feature extractor <ref type="bibr" target="#b19">(Liu et al. 2019</ref>) and employ the extracted features as the node representation of downstream graph networks, a pure Transformer structure makes fewer prior structural assumptions <ref type="bibr" target="#b18">(Lin et al. 2021)</ref>.</p><p>Secondly, we adopt supervised contrastive learning (SCL) <ref type="bibr" target="#b14">(Khosla et al. 2020)</ref> to alleviate the difficulty in categorizing similar emotions, which makes samples with same sentiments cohesive and different sentiments mutually exclusive under the fully utilization of label information. Compared with the cross-entropy loss for noisy labels, the supervised contrastive loss can increase the stability of training and improve the generalization of the model <ref type="bibr" target="#b9">(Gunel et al. 2021)</ref>. Unlike the regular SCL, we copy the hidden state of all samples in a batch and detach off its gradient as its multiview representation. The reason is that the categories in existing ERC datasets are highly unbalanced, and some categories may exist in a batch with only one sample. If only the original SCL is used, it will lead to incorrect loss calculation.</p><p>Thirdly, we introduce an auxiliary response generation task to enhance the ability of capturing the context information for ERC. The prediction of the following utterance makes the model fully consider contextual dependencies, thus forcing the model to consider the information in the context and rely on the current utterance itself when recognizing the sentiment in the conversation. Moreover, by splicing the speaker directly before utterance as a hint for speaker information, the dependency between speakers and utterances is modeled adequately without additional parameters.</p><p>Finally, we utilize BART (Lewis et al. 2020), a pre-trained Transformer with an encoder-decoder structure, as our backbone model and enhance it by contrastive and generative loss. Our proposed COnstrastive-and-Generation-enhanced BART (CoG-BART) obtains state-of-the-art results on four ERC datasets compared to the baseline models. Additionally, ablation experiments and case studies prove the effectiveness of the contrastive and generative losses in the ERC task.</p><p>To summarize, our main contributions can be concluded as follows:</p><p>? To the best of our knowledge, we utilize supervised contrastive learning for the first time in ERC and significantly improve the model's ability to distinguish different sentiments. ? By incorporating response generation as an auxiliary task, the performance of ERC is improved when certain contextual information is involved. ? Our model is easy-to-implemented since it does not depend on external resources, like graph-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>This section will introduce related works in ERC. Due to context-dependency and speaker dependency properties, it is natural for researchers to employ graph neural networks. Therefore, many works have constructed various task-specific graph structures. Meanwhile, with the excellent performance of the pre-trained model in diverse downstream tasks, an increasing number of works adopt the pretrained model as the feature extractor for the input of the downstream model or directly fine-tune it with downstream datasets. Therefore, this section divides the related work into two categories: graph-based models and pre-train-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialog Emotion Recognition</head><p>Graph-based model Considering the unidirectionality of information interaction, DAG <ref type="bibr" target="#b23">(Shen et al. 2021b</ref>) utilizes directed acyclic graphs to model the information interaction between utterance and speaker. DialogGCN <ref type="bibr" target="#b8">(Ghosal et al. 2019</ref>) adopts the basic graph neural network to model the relationship between contexts. SumAggGIN <ref type="bibr" target="#b24">(Sheng et al. 2020)</ref> adds an aggregation module based on DialogGCN to additionally consider phrase-level information other than utterance-level. By simulating the process of human reasoning, DialogCRN <ref type="bibr" target="#b11">(Hu, Wei, and Huai 2021)</ref> proposes to apply several reasoning modules to extract and integrate clues of emotional reasoning. To make the model better understand the additional general information involved in the dialogue process, KET <ref type="bibr" target="#b31">(Zhong, Wang, and Miao 2019)</ref> combines external knowledge with a hierarchical Transformer. By appending sequence information into the graph network, RGAT <ref type="bibr" target="#b13">(Ishiwatari et al. 2020</ref>) uses relational position encoding to combine position information into the graph network structure to consider the dependency between speakers. TODKAT <ref type="bibr" target="#b32">(Zhu et al. 2021)</ref> integrates topic detection into the pre-training model and fuses commonsense knowledge into Transformer <ref type="bibr" target="#b26">(Vaswani et al. 2017</ref>).</p><p>Pre-train-based model Suppose each utterance is regarded as an independent sentence, regardless of its contextdependence and speaker information. In that case, the problem can be transformed into a simple sentence classification so that pre-trained models <ref type="bibr" target="#b21">(Qiu et al. 2020</ref> </p><formula xml:id="formula_0">BART BART BART BART BART BART Dialogue-level Transformer BART BART BART BART BART L CE L CE L CE L CE L CE L CE L GEN L GEN L GEN L GEN L GEN BART-Encoder L SCL L SCL</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max-Pooling</head><p>Auxiliary Response Generation:</p><p>Emotion Recognition:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BART-Decoder</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BART-Encoder BART-Decoder</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Push closer Mutually repel</head><p>Max-Pooling Max-Pooling Max-Pooling Max-Pooling Max-Pooling <ref type="figure">Figure 2</ref>: The overall framework of CoG-BART. The utterance is fed into BART for N utterances in a batch to get its hidden state. The representation of the utterance obtained after max-pooling the hidden state of each utterance is fed to the upper-level dialogue-level Transformer for modeling context dependencies. The obtained context-dependent utterance representations are utilized to compute the cross-entropy loss and supervised contrastive loss. In addition, the two adjacent utterance pairs are used for the auxiliary response generation.</p><p>pays attention to different aspects of dialogue information. <ref type="bibr" target="#b12">Ide and Kawahara (2021)</ref> trained BART with both generation and classification in a multi-task format, though their method focused on response generation, treating emotion recognition as an auxiliary task. However, we focus on ERC and apply supervised contrastive loss as an additional optimization goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contrastive Learning</head><p>Unsupervised contrastive learning In the field of computer vision, SimCLR <ref type="bibr" target="#b3">(Chen et al. 2020b</ref>) takes pictures obtained from the same image through randomly different data augmentation methods as positive samples and other pictures as negative samples, thereby optimizing contrastive loss. The naive sentence representation obtained by BERT has poor performance in semantic text similarity tasks. Therefore, ConSERT <ref type="bibr" target="#b28">(Yan et al. 2021</ref>) introduces selfsupervised contrast loss in the fine-tuning stage of BERT. MBERT (Kim, Yoo, and Lee 2021) does not use data augmentation to construct positive samples but uses BERT with frozen parameters and fine-tunable parameters as a special siamese model to construct positive samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supervised contrastive learning</head><p>To make full use of label information, <ref type="bibr" target="#b14">Khosla et al. (2020)</ref> extends it to supervised contrastive learning based on self-supervised training so that samples belonging to the same label are gathered in the embedding space while pushing samples of different categories away. Given that cross-entropy loss may cause model training instability and converge to a local optimum, SCL <ref type="bibr" target="#b9">(Gunel et al. 2021)</ref> introduces supervised contrastive loss in the finetuning stage, which greatly improves the model's perfor-mance in few-shot learning scenarios. SimCSE <ref type="bibr" target="#b6">(Gao, Yao, and Chen 2021)</ref> uses entailment pair in the annotated NLI dataset as the positive sample and the contradict pair as the negative sample in supervised contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology Problem Definition</head><p>In dialogue emotion recognition, the data is composed of multiple conversations {c 1 , c 2 , ? ? ? , c N }, with each conversation composed of several utterances c i = [u 1 , u 2 , ? ? ? , u m ] and emotion labels Y ci = {y 1 , y 2 , ? ? ? , y m } ? S, where S indicates the categories of emotions. For an utterance, it is comprised of several tokens u t = [w t,1 , w t,2 , ? ? ? , w t,n ]. Every utterance in a conversation c i is uttered by one speaker which can be represented as p(c i ) = [p(u 1 ), ? ? ? , p(u i ), ? ? ? , p(u m )] and p(u i ) ? P , where P indicates the categories or names of the speakers. Accordingly, the whole problem can be expressed as getting the emotional label of each utterance based on the context and speaker information in a piece of conversation:</p><formula xml:id="formula_1">Y ci = f (c i , p(c i )).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supervised Contrastive Learning for ERC</head><p>Utterance Encoding To model the dependencies between speaker and utterance, for a certain utterance u t in a conversation, we splice the speaker's name or category before the utterance. After tokenizing the utterance prepended with the speaker information, we get:</p><formula xml:id="formula_2">u t = s , w t,1 , ? ? ? , w t,i , ? ? ? , w t,|nt| , /s ,<label>(1)</label></formula><p>where s and /s are treated as special tokens to indicate the beginning and end of an utterance. Then the token se-quence after tokenization is fed to the shared embedding layer of BART to acquire the hidden state of each token in utterance before sending it to the encoder and decoder of BART. After sending H t to BART, the representation of the current utterance H t is acquired:</p><formula xml:id="formula_3">H t = EmbeddingLayer(? t ),<label>(2)</label></formula><formula xml:id="formula_4">H t = BART-Model(H t ),<label>(3)</label></formula><p>where H t , H t ? R s?d , and s, d indicates the length of the sequence and hidden dimension respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialogue Modeling</head><p>The representation H t obtained by the BART-Model is max-pooled to obtain the aggregated representation of the utterances as follows:</p><formula xml:id="formula_5">h t = max-pooling( H t ).<label>(4)</label></formula><p>To model the historical context information of the dialogue, we exploit a dialogue-level Transformer <ref type="bibr" target="#b26">(Vaswani et al. 2017</ref>) layer as the context encoder. The multi-head attention mechanism can capture the interaction between different dialogues in multiple rounds of dialogue and aggregate different features to obtain the final implicit representation, thereby fully modeling the complex dependence between different utterances and context relations. For all utterances in a context, the multi-head attention score of the hidden state between two different utterances in a conversation? j ,? k can be calculated by the following formulas:</p><formula xml:id="formula_6">Atten(Q, K, V ) = softmax( QK T ? d k )V,<label>(5)</label></formula><formula xml:id="formula_7">head i = Atten(? j W Q i ,? k W K i ,? k W V i ),<label>(6)</label></formula><p>MultiHead(Q, K, V ) = [head 1 ; ? ? ? ; head n ]W O , <ref type="formula">(7)</ref> where</p><formula xml:id="formula_8">W Q i ? R d?dq , W K i ? R d?d k , W V i ? R d?dv and W O ? R d?d</formula><p>are parameters that can be optimized, d q , d k and d v are dimensions of query, key and value vectors, n indicates the number of heads.</p><p>Therefore, the utterance representation that models the context-dependence can be obtained through the abovementioned dialogue-level Transformer:</p><formula xml:id="formula_9">H win = [? t ,? t+1 , ? ? ? ,? t+bs?1 ],<label>(8)</label></formula><formula xml:id="formula_10">H d-win = Dialogue-Transformer(H win ),<label>(9)</label></formula><p>where H win ? R bs?d indicates utterances in a conversation within the window size bs and H d-win ? R bs?d denotes the utterances after context modeling.</p><p>Supervised Contrastive Learning Supervised contrastive learning assumes that some crucial aspects get attention and allows few-shot learning to be more stable when fine-tuned on pre-trained models <ref type="bibr" target="#b9">(Gunel et al. 2021)</ref>. For ERC, the number of samples in each category in some datasets <ref type="bibr" target="#b17">(Li et al. 2017</ref>) is highly unbalanced, while the supervised contrastive learning will mask itself when calculating the loss. If only one sample exists for a category in the batch, it cannot be directly applied to calculate the loss. Therefore, a copy of the hidden state of the utterance H d-win is made to obtain H d-win , and its gradient is detached. Hence the parameter optimization is maintained stable.</p><p>For a batch with N training samples, each sample is operated by the above mechanism to obtain multiview 2N samples, then the supervised contrastive loss of all samples in a batch can be expressed by the following equation:</p><formula xml:id="formula_11">X = [H d-win , H d-win ],<label>(10)</label></formula><formula xml:id="formula_12">L SCL = i?I ?1 |P (i)| p?P (i) SIM(p, i),<label>(11)</label></formula><formula xml:id="formula_13">SIM(p, i) = log exp((X i ? X p )/? ) a?A(i) exp(X i ? X a /? ) ,<label>(12)</label></formula><p>where X ? R 2N ?d , i ? I = {1, 2, ? ? ? , 2N } indicate the index of the samples in a multiview batch, ? ? R + denotes the temperature coefficient used to control the distance between instances, P (i) = I j=i ? {i} represents samples with the same category as i while excluding itself, A(i) = I ? {i, N + i} indicates samples in the multiview batch except itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Auxiliary Response Generation</head><p>To facilitate the model to consider richer contextual information when determining utterance sentiment, the model is required to generate its following utterance u t+1 given the current utterance u t . The output hidden state of each token in u t+1 is generated by the BART decoder sequentially.</p><formula xml:id="formula_14">H t = BART-Encoder(H t ),<label>(13)</label></formula><formula xml:id="formula_15">h d j = BART-Decoder(H t ;h d &lt;j ),<label>(14)</label></formula><formula xml:id="formula_16">u t+1,j = Softmax(h d j ),<label>(15)</label></formula><formula xml:id="formula_17">L Gen = ? N i=1 log p(u t+1 |u t , ?),<label>(16)</label></formula><p>where ? is the parameters of BART need to be optimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Training</head><p>The loss of model training consists of three parts: the hidden state H d-win obtained after context modeling passes through a multilayer perceptron to obtain logits for calculating crossentropy loss. The other part is the supervised contrastive loss and the loss of response generation. The loss is a weighted sum of the three components, and the sum of their weights equals one. The overall framework of CoG-BART is illustrated in <ref type="figure">Figure 2</ref>. <ref type="table" target="#tab_3">Dataset   DD  MELD ENLP IEMOCAP   #Dial  Train 11118  1038  713  120  Dev  1000  114  99  120  Test  1000  280  85  31  #Utter Train 87170  9989  9934  5810  Dev  8069  1109  1344  5810  Test  7740  2610  1328  1623   #CLS  7  7  7  6   Table 1</ref>: Statistics of four benchmark datasets.</p><formula xml:id="formula_18">P i = Softmax(W s H d-win,i + b s ),<label>(17)</label></formula><formula xml:id="formula_19">y i = argmax(P i ),<label>(18)</label></formula><formula xml:id="formula_20">L CE = ? 1 N N i=1 C c=1 y i,c ? log? i,c ,<label>(19)</label></formula><formula xml:id="formula_21">L = (1 ? ? ? ?)L CE + ?L SCL + ?L Gen ,<label>(20)</label></formula><p>where y i,c represents the label of a certain utterance,? i,c indicates the probability distribution of category c output by the dense layer, ? denotes the weight for supervised contrastive loss and ? is the weight for loss of response generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Settings</head><p>This section will elaborate on the datasets, baseline models, experimental conditions, and parameter settings adopt in the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Setup</head><p>The code framework and initial weight of BART come from Huggingface's Transformers <ref type="bibr" target="#b27">(Wolf et al. 2020)</ref>. The optimizer applied for model training is AdamW with a linearscheduled warm-up strategy. The parameters adjusted in this experiment include batch size, learning rate, warm-up ratio, ?, and ?. We conducted a hyperparameter search for model training through the reserved validation set. The results on the test set come from the best checkpoint in the validation set, and we average the scores from five different random seeds. All experiments are performed on GeForce RTX 3090 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>This section will introduce four benchmark datasets: MELD , EmoryNLP (Zahiri and Choi 2018), Dai-lyDialog <ref type="bibr" target="#b17">(Li et al. 2017)</ref>, and IEMOCAP <ref type="bibr" target="#b1">(Busso et al. 2008)</ref> for comparison with the baseline models.</p><p>MELD This dataset comes from the dialogue content of the characters in the American drama Friends. MELD originally contained multi-modal data, but we used only the text data for the experiments.</p><p>EmoryNLP (ENLP) This dataset also comes from Friends, and the difference from MELD is the annotation of utterance's emotional label category. The emotional tags contained in this dataset are: joyful, neutral, powerful, mad, sad, scared, and peaceful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DailyDialog (DD)</head><p>Manually compiled data sets about daily communication. The annotation method used in this data set is Ekman's emotion type <ref type="bibr" target="#b5">(Ekman 1993)</ref>, which includes six basic emotion tags, including happiness, surprise, anger, disgust, fear, and sadness.</p><p>IEMOCAP Like MELD, it is a multi-modal dataset. The content is derived from the lines in the scripts of the two actors, and the emotional tags included are excited, neutral, frustrated, sad, happy, and angry.</p><p>The detailed statistics of the four datasets are shown in <ref type="table">Table 1</ref>, where "#Dial" indicates the number of dialogue in train/dev/test, "#Utter" represents the number of all utterances in dialogue, and "#CLS" denotes the number of categories of each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics</head><p>For MELD, EmoryNLP and IEMOCAP, we adopt weighted average F1 as the evaluation metrics. In that "neutral" occupies the majority in DailyDialog, micro-F1 is employed as the evaluation metric for this data set, and we ignore the label "neutral" when calculating the results as in the previous works <ref type="bibr" target="#b32">(Zhu et al. 2021;</ref><ref type="bibr" target="#b23">Shen et al. 2021b</ref>).  For graph-based models, KET <ref type="bibr" target="#b31">(Zhong, Wang, and Miao 2019)</ref>, RGAT <ref type="bibr" target="#b13">(Ishiwatari et al. 2020)</ref>, DialogGCN <ref type="bibr" target="#b8">(Ghosal et al. 2019)</ref>, DialogCRN <ref type="bibr" target="#b11">(Hu, Wei, and Huai 2021)</ref>, COS-MIC <ref type="bibr" target="#b7">(Ghosal et al. 2020)</ref>, and DAG-ERC <ref type="bibr" target="#b23">(Shen et al. 2021b)</ref> are listed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Analysis Main Results</head><p>Compared to the graph-based model, CoG-BART improves 0.53 points over COSMIC <ref type="bibr" target="#b7">(Ghosal et al. 2020)</ref>. It is worth noting that RoBERTa-large is used as the feature extractor in COSMIC, while CoG-BART only adopts BARTlarge as the backbone structure to obtain competitive results, indicating that adequate knowledge transfer of pre-trained models which effectively model the dependencies between contexts can also yield promising results in MELD.</p><p>We can observe from the results in EmoryNLP (Zahiri and Choi 2018) that the graph-based model using the pre-trained model as the feature extractor works better overall than the model applying only the pre-trained model as the backbone network. Meanwhile, CoG-BART still achieves results with significant improvement. Also, the graph-based model can obtain higher F1 overall on IEMOCAP <ref type="bibr" target="#b1">(Busso et al. 2008)</ref> compared to the pre-trained based models. The reason is that    the number of utterances contained in one context of IEMO-CAP is much larger than the other three datasets, so pretrained models are usually incapable of handling excessively long contexts. However, graph network models can better model context dependencies. In comparison, CoG-BART also achieves results similar to those of graph-based models, demonstrating the capability of CoG-BART to model the context-dependence. The micro-F1 values of CoG-BART in DailyDialog are lower compared to the results of some graph neural network models. Still, it can achieve similar results to some pre-trainbased models such as BERT <ref type="bibr" target="#b4">(Devlin et al. 2019)</ref>, RoBERTa <ref type="bibr" target="#b19">(Liu et al. 2019)</ref> and DialogXL <ref type="bibr" target="#b22">(Shen et al. 2021a</ref>). Therefore, the graph-based model may have the advantage over pre-train-based models by more adequately modeling context dependencies on this dataset.  Qualitative Analysis of SCL To conduct a qualitative analysis of supervised contrastive learning, we utilize t-SNE <ref type="bibr" target="#b10">(Hinton and Roweis 2002)</ref> to visualize the distribution of high-dimensional hidden states obtained by the model trained with supervised contrastive loss. By controlling different sizes of ?, the ratio of supervised contrastive loss is controlled to 0% and 80%, respectively, to obtain the hidden state output by the model under different levels of supervised contrastive learning.</p><formula xml:id="formula_22">Dataset MELD EmoryNLP IEMOCAP DailyDialog Model Weighted Micro-F1 Weighted Micro-F1 Weighted Micro-F1 Weighted Micro -Avg-F1 -Avg-F1 -Avg-F1 -F1-neural -F1-</formula><p>As illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>, when the supervised contrastive loss is not exploited, that is, when the cross-entropy loss function is completely adopted, the overlap rate of samples between different labels is particularly high, especially for some samples with similar emotions, which increase the difficulty of learning the decision boundaries. As the proportion of supervised contrastive loss increases, it can be distinctly observed that the degree of coupling between different classes is gradually enlarged, and the same classes begin to cohesive. It is worth mentioning that although the distance within the class has been reduced, the uniformity  between samples has been well maintained, indicating that the information has been well preserved and no representation collapse has occurred.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantitative Analysis of SCL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Response Generation</head><p>Response generation has a facilitating effect on modeling context dependence to some extent. As the two cases in <ref type="figure">Figure 4</ref> illustrate, if only the current utterance itself is considered, the expression may cause the model to misjudge the sentiment of the current utterance, while generating responses leads the model to pay more attention to contextual information, thus making correct predictions which consistent with the scenario. As for the impact of different weights of response generation loss, <ref type="table" target="#tab_6">Table 4</ref> illustrates that when fixing ? and adjusting ?, there is also a slight impact on the model's overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Analysis</head><p>To investigate the impacts of individual modules and combinations of several components on the overall effect of the model, this section conducts an ablation study on three modules in CoG-BART. As illustrated in <ref type="table" target="#tab_8">Table 5</ref>, the selected datasets are MELD and IEMOCAP, where "-" indicates the removal of the single method or several methods, "Gen" denotes the auxiliary task of response generation, "SCL loss" means supervised contrastive loss, and "Speaker" indicates the splicing of speaker label before utterance. From the results of MELD, removing any of the three modules makes the overall performance worse, while dis-carding the supervised contrastive loss and response generation has the greatest impact on the performance of CoG-BART in MELD. These indicate that supervised contrastive loss leverage label information better compared to crossentropy loss, thus effectively distinguishing different sentiments.</p><p>Consistent results are also obtained in IEMOCAP, indicating that the improvement in model performance from these three modules transfers well across these datasets. However, the more unexpected finding was that removing the speaker's information made CoG-BART most degraded in IEMOCAP. By analyzing this dataset, we found that it involved 302 speakers, so it may be crucial to fully model the speaker information for this dataset. It also proves the effectiveness of the simple method of splicing the speaker information directly in front of the utterance. Furthermore, removing the supervised contrastive loss alone degrades the performance by 1.95 points on IEMOCAP, indicating that supervised contrastive learning significantly impacts CoG-BART on this dataset. The results after removing Dialoglevel Transformer suggest that this module improves overall performance by modelling longer contextual dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We propose supervised contrastive learning with response generation as an auxiliary task for BART, namely CoG-BART, for emotion recognition in conversation (ERC). First, supervised contrastive learning is introduced into the training process to distinguish similar emotions, reducing intraclass distance and increasing inter-class variance. Meanwhile, the response generation is adopted as an auxiliary task; hence, the model categorizes utterances with similar semantics but different emotions by considering the context. The results obtained on four datasets compared with the current state-of-the-art baseline methods demonstrate the proposed method's effectiveness. Furthermore, ablation studies demonstrate that supervised contrastive learning can effectively improve the model's efficacy in recognizing emotions, thus improving the overall performance. Also, response generation as an auxiliary task helps the model fully consider the context to discern the emotions of semantically similar utterances in varying contexts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>The typical contrastive learning uses only one pair of positive examples, while all other samples are treated as negative examples. Supervised contrastive learning treats all examples with the same label in the batch as positive examples by making full use of label information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>2 and 3 record the results of comparing CoG-BART with the baseline models on four datasets. Among the pre-train-based models and their variants, the selected baseline models are BERT (Devlin et al. 2019), RoBERTa (Liu et al. 2019), HiTrans (Li et al. 2020), Di-alogXL (Shen et al. 2021a) and XLNet (Yang et al. 2019). In MELD (Poria et al. 2019), CoG-BART has an approximate absolute 1.24% improvement over the previous state-of-theart BART-large (Lewis et al. 2020).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The t-SNE visualization results of the model output when ? is 0 and 0.8, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>BART 64.81 (?0.19) 65.95 (?0.44) 39.04 (?0.10) 42.58 (?0.94) 66.18 (?0.45) 66.71 (?0.49) 56.09 (?0.01) 56.29 (?0.17)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>neutral</cell></row><row><cell>BERT</cell><cell>62.28</cell><cell>63.49</cell><cell>34.87</cell><cell>41.11</cell><cell>60.98</cell><cell>-</cell><cell>53.41</cell><cell>54.85</cell></row><row><cell>RoBERTa</cell><cell>62.51</cell><cell>63.75</cell><cell>35.90</cell><cell>40.81</cell><cell>63.38</cell><cell>-</cell><cell>52.84</cell><cell>54.33</cell></row><row><cell>HiTrans</cell><cell>61.94</cell><cell>-</cell><cell>36.75</cell><cell>-</cell><cell>64.50</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DialogXL</cell><cell>62.41</cell><cell>-</cell><cell>34.73</cell><cell>-</cell><cell>65.94</cell><cell>-</cell><cell>-</cell><cell>54.93</cell></row><row><cell>XLNet</cell><cell>61.65</cell><cell>-</cell><cell>34.13</cell><cell>-</cell><cell>61.33</cell><cell>-</cell><cell>-</cell><cell>53.62</cell></row><row><cell>BART-large</cell><cell>63.57</cell><cell>64.41</cell><cell>35.98</cell><cell>38.93</cell><cell>56.14</cell><cell>56.67</cell><cell>54.83</cell><cell>55.34</cell></row><row><cell>CoG-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>The overall results of CoG-BART with pre-train-based baseline models on four datasets.</figDesc><table><row><cell>Dataset</cell><cell>MELD</cell><cell cols="3">EmoryNLP IEMOCAP DailyDialog</cell></row><row><cell>Model</cell><cell>Weighted</cell><cell>Weighted</cell><cell>Weighted</cell><cell>Micro</cell></row><row><cell></cell><cell>-Avg-F1</cell><cell>-Avg-F1</cell><cell>-Avg-F1</cell><cell>-F1-neutral</cell></row><row><cell>KET</cell><cell>58.18</cell><cell>34.39</cell><cell>59.56</cell><cell>53.37</cell></row><row><cell>RGAT</cell><cell>60.91</cell><cell>34.42</cell><cell>65.22</cell><cell>54.31</cell></row><row><cell>RGAT+RoBERTa</cell><cell>62.80</cell><cell>37.89</cell><cell>66.36</cell><cell>59.02</cell></row><row><cell>DialogGCN</cell><cell>58.10</cell><cell>-</cell><cell>64.18</cell><cell>-</cell></row><row><cell>DialogCRN</cell><cell>58.39</cell><cell>-</cell><cell>66.20</cell><cell>-</cell></row><row><cell>COSMIC</cell><cell>64.28</cell><cell>37.10</cell><cell>63.05</cell><cell>56.16</cell></row><row><cell>DAG-ERC</cell><cell>63.65</cell><cell>39.02</cell><cell>68.03</cell><cell>59.33</cell></row><row><cell>CoG-BART</cell><cell cols="4">64.81 (?0.19) 39.04 (?0.10) 66.18 (?0.45) 56.29 (?0.17)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparison with graph-based models.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>The F1 scores for different values of ? and ?</figDesc><table><row><cell>The Potency of Supervised Contrastive Learning</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>The effects of different proportions of supervised contrastive learning on CoG-BART are illustrated inTable 4, where the weighted average F1 of CoG-BART with different proportions of SCL loss is recorded. Different ? have a large impact on the outcomes, e.g., there exists a 2.8 points difference in F1 values between ? equals 0.4 and 0.8 for IEMOCAP, reflecting the significant positive effect of supervised contrastive learning for this dataset. Meanwhile, different datasets have different values of ? in obtaining the relatively best gain effect. For instance, So that's two boxes of the Holiday Macaroons. On behalf of the Brown Birds of America, I salute you. Case studies show that response generation enables the model to correctly predict the emotion based on context.</figDesc><table><row><cell cols="2">Utterance for Prediction</cell><cell>Generated Response</cell><cell>Predict w/o RG</cell><cell>Predict with RG</cell><cell>Golden label</cell></row><row><cell cols="2">Joey : Thursday's clearly not good for ya, pick a day!</cell><cell cols="2">Sarah : anger</cell><cell>joy</cell><cell>joy</cell></row><row><cell cols="2">Joey: Man, that was great! Huh? Can you believe how long we threw that ball around?</cell><cell>Rachel : Yeah, it is amazing it lasted that long.</cell><cell>surprise</cell><cell>joy</cell><cell>joy</cell></row><row><cell>Figure 4: Dataset</cell><cell>MELD</cell><cell>IEMOCAP</cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell cols="2">Weight-Avg-F1</cell><cell></cell><cell></cell></row><row><cell>CoG-BART</cell><cell>64.81</cell><cell>66.18</cell><cell></cell><cell></cell></row><row><cell>-Gen</cell><cell cols="2">64.26 (?0.55) 64.74 (?1.44)</cell><cell></cell><cell></cell></row><row><cell>-SCL loss</cell><cell cols="2">64.28 (?0.53) 64.23 (?1.95)</cell><cell></cell><cell></cell></row><row><cell>-Speaker</cell><cell cols="2">64.14 (?0.67) 55.41 (?10.77)</cell><cell></cell><cell></cell></row><row><cell>-Gen, SCL loss</cell><cell cols="2">63.57 (?1.24) 62.90 (?3.28)</cell><cell></cell><cell></cell></row><row><cell cols="3">-SCL loss, Speaker 63.72 (?1.09) 54.83 (?11.35)</cell><cell></cell><cell></cell></row><row><cell>-Gen, Speaker</cell><cell cols="2">64.02 (?0.79) 54.95 (?11.23)</cell><cell></cell><cell></cell></row><row><cell>-Dialog-Trans</cell><cell cols="2">64.40 (?0.41) 64.19 (?1.99)</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Ablation study to evaluate the impact of different components on the overall performance of the model on MELD and EmoryNLP CoG-BART performs best when ? = 0.2 in MELD, while achieving the best result when ? = 0.4 in IEMOCAP.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are very grateful to the reviewers for their diligent and rigorous attitude towards our work and their valuable suggestions for improvement during the whole review process. This work was supported by the National Key Research and Development Program of China (No. 2020AAA0108702) and the National Natural Science Foundation of China (NO. 62022027).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">COMET: Commonsense Transformers for Automatic Knowledge Graph Construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<editor>Korhonen, A.</editor>
		<editor>Traum, D. R.</editor>
		<editor>and M?rquez, L.</editor>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07-28" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4762" to="4779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">IEMOCAP: Interactive emotional dyadic motion capture database. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Busso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bulut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Narayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="335" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Measuring and Relieving the Over-Smoothing Problem for Graph Neural Networks from the Topological View</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020-02-07" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="3438" to="3445" />
		</imprint>
	</monogr>
	<note>The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Simple Framework for Contrastive Learning of Visual Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>: Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Facial expression and emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American psychologist</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">384</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">SimCSE: Simple Contrastive Learning of Sentence Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<idno>abs/2104.08821</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">COSMIC: COmmonSense knowledge for eMotion Identification in Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2470" to="2481" />
		</imprint>
	</monogr>
	<note>Online: Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chhaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="154" to="164" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gunel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<imprint>
			<date type="published" when="2021-05-03" />
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stochastic Neighbor Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 15 [Neural Information Processing Systems, NIPS 2002, December 9-14</title>
		<editor>Becker, S.</editor>
		<editor>Thrun, S.</editor>
		<editor>and Obermayer, K.</editor>
		<meeting><address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="833" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">; C</forename><surname>Huai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/I-JCNLP 2021</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/I-JCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7042" to="7052" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-Task Learning of Generation and Classification for Emotion-Aware Dialogue Response Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop, NAACL-HLT 2021</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop, NAACL-HLT 2021</meeting>
		<imprint>
			<date type="published" when="2021-06-06" />
			<biblScope unit="page" from="119" to="125" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Relation-aware Graph Attention Networks with Relational Position Encodings for Emotion Recognition in Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ishiwatari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yasuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>Webber, B.</editor>
		<editor>Cohn, T.</editor>
		<editor>He, Y.</editor>
		<editor>and Liu, Y.</editor>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-11-16" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="7360" to="7370" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.11362</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Supervised contrastive learning</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021<address><addrLine>Lewis, M</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
	<note>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Online</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">HiTrans: A Transformer-Based Context-and Speaker-Sensitive Model for Emotion Detection in Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4190" to="4200" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="986" to="995" />
		</imprint>
	</monogr>
	<note>: Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.04554</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">A Survey of Transformers. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>abs/1907.11692</idno>
	</analytic>
	<monogr>
		<title level="j">RoBERTa: A Robustly Optimized BERT Pretraining Approach. CoRR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pre-trained Models for Natural Language Processing: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SCIENCE CHINA Technological Sciences</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1872" to="1897" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021-02-02" />
			<biblScope unit="page" from="13789" to="13797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Directed Acyclic Graph Network for Conversational Emotion Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">; C</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/I-JCNLP 2021</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/I-JCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1551" to="1560" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Summarize before Aggregate: A Global-to-local Heterogeneous Graph Inference Network for Conversational Emotion Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">4153</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spain</forename><surname>Barcelona</surname></persName>
		</author>
		<title level="m">International Committee on Computational Linguistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Von Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pmlr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Proceedings of the 37th International Conference on Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<editor>Zong, C.</editor>
		<editor>Xia, F.</editor>
		<editor>Li, W.</editor>
		<editor>and Navigli, R.</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5065" to="5075" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">XLNet: Generalized Autoregressive Pretraining for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>Wallach, H. M.</editor>
		<editor>Larochelle, H.</editor>
		<editor>Beygelzimer, A.</editor>
		<editor>d&apos;Alch?-Buc, F.</editor>
		<editor>Fox, E. B.</editor>
		<editor>and Garnett, R.</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="5754" to="5764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Emotion Detection on TV Show Transcripts with Sequence-Based Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Zahiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Workshops of the The Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<meeting><address><addrLine>Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018-02-02" />
			<biblScope unit="page" from="44" to="52" />
		</imprint>
	</monogr>
	<note>WS-18 of AAAI Workshops</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Knowledge-Enriched Transformer for Emotion Detection in Textual Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
		<idno>abs/1909.10681</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pergola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<editor>Zong, C.</editor>
		<editor>Xia, F.</editor>
		<editor>Li, W.</editor>
		<editor>and Navigli, R.</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1571" to="1582" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
