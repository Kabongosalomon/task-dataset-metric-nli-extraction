<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
							<email>?xuezhiw@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Zhou</surname></persName>
							<email>?dennyzhou@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Research</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brain</forename><surname>Team</surname></persName>
						</author>
						<title level="a" type="main">SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T14:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and ARC-challenge (+3.9%).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Although language models have demonstrated remarkable success across a range of NLP tasks, their ability to demonstrate reasoning is often seen as a limitation, which cannot be overcome solely by increasing model scale <ref type="bibr" target="#b51">(Rae et al., 2021;</ref><ref type="bibr">BIG-bench collaboration, 2021, inter alia)</ref>. In an effort to address this shortcoming,  have proposed chain-of-thought prompting, where a language model is prompted to generate a series of short sentences that mimic the reasoning process a person might employ in solving a task. For example, given the question "If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?", instead of directly responding with "5", a language model would be prompted to respond with the entire chain-of-thought: "There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.". It has been observed that chain-of-thought prompting significantly improves model performance across a variety of multi-step reasoning tasks .</p><p>In this paper, we introduce a novel decoding strategy called self-consistency to replace the greedy decoding strategy used in chain-of-thought prompting , that further improves language models' reasoning performance by a significant margin. Self-consistency leverages the intuition that complex reasoning tasks typically admit multiple reasoning paths that reach a correct answer <ref type="bibr" target="#b55">(Stanovich &amp; West, 2000)</ref>. The more that deliberate thinking and analysis is required for a problem <ref type="bibr" target="#b23">(Evans, 2010)</ref>, the greater the diversity of reasoning paths that can recover the answer. <ref type="figure">Figure 1</ref> illustrates the self-consistency method with an example. We first prompt the language model with chain-of-thought prompting, then instead of greedily decoding the optimal reasoning path, we propose a "sample-and-marginalize" decoding procedure: we first sample from the language model's decoder to generate a diverse set of reasoning paths; each reasoning path might lead to a different final answer, so we determine the optimal answer by marginalizing out the sampled reasoning paths to find the most consistent answer in the final answer set. Such an approach is analogous to the human experience that if multiple different ways of thinking lead to the same answer, one has greater confidence that the final answer is correct. Compared to other decoding methods, self-consistency avoids the repetitiveness and local-optimality that plague greedy decoding, while mitigating the stochasticity of a single sampled generation. <ref type="figure">Figure 1</ref>: The self-consistency method contains three steps: (1) prompt a language model using chain-of-thought (CoT) prompting; (2) replace the "greedy decode" in CoT prompting by sampling from the language model's decoder to generate a diverse set of reasoning paths; and (3) marginalize out the reasoning paths and aggregate by choosing the most consistent answer in the final answer set.</p><p>Self-consistency is far simpler than prior approaches that either train an additional verifier <ref type="bibr" target="#b19">(Cobbe et al., 2021)</ref> or train a re-ranker given additional human annotations to improve generation quality <ref type="bibr" target="#b58">(Thoppilan et al., 2022)</ref>. Instead, self-consistency is entirely unsupervised, works off-the-shelf with pre-trained language models, requires no additional human annotation, and avoids any additional training, auxiliary models or fine-tuning. Self-consistency also differs from a typical ensemble approach where multiple models are trained and the outputs from each model are aggregated, it acts more like a "self-ensemble" that works on top of a single language model. We evaluate self-consistency on a wide range of arithmetic and commonsense reasoning tasks over four language models with varying scales: the public UL2-20B <ref type="bibr" target="#b57">(Tay et al., 2022)</ref> and GPT-3-175B <ref type="bibr" target="#b10">(Brown et al., 2020)</ref>, and two densely-activated decoder-only language models: LaMDA-137B <ref type="bibr" target="#b58">(Thoppilan et al., 2022)</ref> and PaLM-540B <ref type="bibr">(Chowdhery et al., 2022)</ref>. On all four language models, self-consistency improves over chain-of-thought prompting  by a striking margin across all tasks. In particular, when used with PaLM-540B or GPT-3, self-consistency achieves new state-of-the-art levels of performance across arithmetic reasoning tasks, including GSM8K <ref type="bibr" target="#b19">(Cobbe et al., 2021</ref>) (+17.9% absolute accuracy gains), SVAMP <ref type="bibr" target="#b46">(Patel et al., 2021</ref>) (+11.0%), AQuA <ref type="bibr">(Ling et al., 2017</ref>) (+12.2%), and across commonsense reasoning tasks such as StrategyQA <ref type="bibr" target="#b28">(Geva et al., 2021</ref>) (+6.4%) and ARC-challenge <ref type="bibr" target="#b18">(Clark et al., 2018</ref>) (+3.9%). In additional experiments, we show self-consistency can robustly boost performance on NLP tasks where adding a chain-of-thought might hurt performance compared to standard prompting <ref type="bibr" target="#b66">(Ye &amp; Durrett, 2022)</ref>. We also show selfconsistency significantly outperforms sample-and-rank, beam search, ensemble-based approaches, and is robust to sampling strategies and imperfect prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SELF-CONSISTENCY OVER DIVERSE REASONING PATHS</head><p>A salient aspect of humanity is that people think differently. It is natural to suppose that in tasks requiring deliberate thinking, there are likely several ways to attack the problem. We propose that such a process can be simulated in language models via sampling from the language model's decoder. For instance, as shown in <ref type="figure">Figure 1</ref>, a model can generate several plausible responses to a math question that all arrive at the same correct answer (Outputs 1 and 3). Since language models are not perfect reasoners, the model might also produce an incorrect reasoning path or make a mistake in one of the reasoning steps (e.g., in Output 2), but such solutions are less likely to arrive at the same answer. That is, we hypothesize that correct reasoning processes, even if they are diverse, tend to have greater agreement in their final answer than incorrect processes.</p><p>We leverage this intuition by proposing the following self-consistency method. First, a language model is prompted with a set of manually written chain-of-thought exemplars   <ref type="table">Table 1</ref>: Accuracy comparison of different answer aggregation strategies.</p><p>we sample a set of candidate outputs from the language model's decoder, generating a diverse set of candidate reasoning paths. Self-consistency is compatible with most existing sampling algorithms, including temperature sampling <ref type="bibr" target="#b0">(Ackley et al., 1985;</ref><ref type="bibr" target="#b25">Ficler &amp; Goldberg, 2017)</ref>, top-k sampling <ref type="bibr" target="#b24">(Fan et al., 2018;</ref><ref type="bibr" target="#b30">Holtzman et al., 2018;</ref><ref type="bibr" target="#b50">Radford et al., 2019)</ref>, and nucleus sampling <ref type="bibr" target="#b31">(Holtzman et al., 2020)</ref>. Finally, we aggregate the answers by marginalizing out the sampled reasoning paths and choosing the answer that is the most consistent among the generated answers.</p><p>In more detail, assume the generated answers a i are from a fixed answer set, a i ? A, where i = 1, . . . , m indexes the m candidate outputs sampled from the decoder. Given a prompt and a question, self-consistency introduces an additional latent variable r i , which is a sequence of tokens representing the reasoning path in the i-th output, then couples the generation of (r i , a i ) where r i ? a i , i.e., generating a reasoning path r i is optional and only used to reach the final answer a i . As an example, consider Output 3 from <ref type="figure">Figure 1</ref>: the first few sentences "She eats 3 for breakfast ... So she has 9 eggs * $2 = $18." constitutes r i , while the answer 18 from the last sentence, "The answer is $18", is parsed as a i . 1 Now given a certain answer a, self-consistency applies a marginalization over r i after sampling a diverse set of (r i , a i ) from the language model's decoder, so the probability of a given by the above generation process is (we omit the normalization factor since it is a constant):</p><formula xml:id="formula_0">P (a | prompt, question) = m i=1 1(a i = a)P (r i , a i | prompt, question).</formula><p>(1)</p><p>To compute P (r i , a i | prompt, question), we can either take the unnormalized probability of the language model generating (r i , a i ) given (prompt, question), or we can normalize the conditional probability by the output length <ref type="bibr" target="#b10">(Brown et al., 2020)</ref>, i.e.,</p><formula xml:id="formula_1">P (r i , a i | prompt, question) = exp 1 K K k=1 log P (t k |prompt,question,t1,...,t k?1 ) ,<label>(2)</label></formula><p>where log P (t k | prompt, question, t 1 , . . . , t k?1 ) is the log probability of generating the k-th token t k in (r i , a i ) conditioned on the previous tokens, and K is the total number of tokens in (r i , a i ).</p><p>As the last step, we choose the optimal answer by picking a with the maximum P (a | prompt, question), or as we defined as the most "consistent" answer among the final answer set.</p><p>In <ref type="table">Table 1</ref>, we show the accuracy over a set of reasoning tasks by using different answer aggregation strategies. First, Equation 1 corresponds to a "weighted sum" over a i with weights P (r i , a i | prompt, question), and results in <ref type="table">Table 1</ref> show that the "normalized" weighted sum (i.e., Equation 2) gives a much higher accuracy compared to its unnormalized counterpart. In addition, perhaps surprisingly, we found that taking the "unweighted sum", i.e., taking a majority vote directly over a i (i.e., m i=1 1(a i = a)) gives a very similar accuracy as calculating the exact normalized weighted sum. We took a closer look at the model's output probabilities and found that for each (r i , a i ), the normalized conditional probabilities P (r i , a i | prompt, question) are quite close to each other, i.e., the language model regards those generations as "equally likely". 2 Hence for self-consistency in practice, one can either calculate the exact normalized weighted sum (Equation 1 and 2) or take a majority vote over a i directly as an approximation, where the latter has a strictly lower computational cost. In our experiments, for simplicity we use majority vote to report all results. For completeness,</p><p>in <ref type="table">Table 1</ref> we also report the results by taking a "weighted average", i.e., each a gets a score of its weighted sum divided by m i=1 1(a i = a), which results in a much worse performance.</p><p>Self-consistency explores an interesting space between open-ended text generation and optimal text generation with a fixed answer. Reasoning tasks typically have fixed answers, which is why researchers have generally considered greedy decoding approaches <ref type="bibr" target="#b50">(Radford et al., 2019;</ref><ref type="bibr">Chowdhery et al., 2022)</ref>. However, we have found that even when the desired answer is fixed, introducing diversity in the reasoning processes can be highly beneficial; therefore we leverage sampling, as commonly used for open-ended text generation <ref type="bibr" target="#b50">(Radford et al., 2019;</ref><ref type="bibr" target="#b10">Brown et al., 2020;</ref><ref type="bibr" target="#b58">Thoppilan et al., 2022)</ref>, to achieve this goal. One should note that self-consistency can be applied only to problems where the final answer is from a fixed answer set, but in principle this approach can be extended to open-text generation problems if a good metric of consistency can be defined between multiple generations, e.g., whether two answers agree or contradict each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>We conducted a series of experiments to compare the proposed self-consistency method with existing approaches on a range of reasoning benchmarks. We find that self-consistency robustly improves reasoning accuracy for every language model considered, spanning a wide range of model scales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">EXPERIMENT SETUP</head><p>Tasks and datasets. We evaluate self-consistency on the following reasoning benchmarks. 3</p><p>? Arithmetic reasoning. For these tasks, we used the Math Word Problem Repository <ref type="bibr" target="#b36">(Koncel-Kedziorski et al., 2016)</ref>, including AddSub <ref type="bibr" target="#b32">(Hosseini et al., 2014)</ref>, MultiArith <ref type="bibr" target="#b53">(Roy &amp; Roth, 2015)</ref>, and ASDiv <ref type="bibr" target="#b43">(Miao et al., 2020)</ref>. We also included AQUA-RAT <ref type="bibr">(Ling et al., 2017)</ref>, a recently published benchmark of grade-school-math problems (GSM8K; <ref type="bibr" target="#b19">Cobbe et al., 2021)</ref>, and a challenge dataset over math word problems (SVAMP; <ref type="bibr" target="#b46">Patel et al., 2021)</ref>. ? Commonsense reasoning. For these tasks, we used CommonsenseQA <ref type="bibr" target="#b56">(Talmor et al., 2019)</ref>,</p><p>StrategyQA <ref type="bibr" target="#b28">(Geva et al., 2021)</ref>, and the AI2 Reasoning Challenge (ARC) <ref type="bibr" target="#b18">(Clark et al., 2018)</ref>. ? Symbolic Reasoning. We evaluate two symbolic reasoning tasks: last letter concatenation (e.g., the input is "Elon Musk" and the output should be "nk"), and Coinflip (e.g., a coin is heads-up, after a few flips is the coin still heads-up?) from .</p><p>Language models and prompts. We evaluate self-consistency over four transformer-based language models with varying scales: ? UL2 <ref type="bibr" target="#b57">(Tay et al., 2022)</ref> is an encoder-decoder model trained on a mixture of denoisers with 20billion parameters. UL2 is completely open-sourced 4 and has similar or better performance than GPT-3 on zero-shot SuperGLUE, with only 20B parameters and thus is more compute-friendly; ? GPT-3 <ref type="bibr" target="#b10">(Brown et al., 2020)</ref> with 175-billion parameters. We use two public engines code-davinci-001 and code-davinci-002 from the Codex series  to aid reproducibility; 5</p><p>? LaMDA-137B <ref type="bibr" target="#b58">(Thoppilan et al., 2022</ref>) is a dense left-to-right, decoder-only language model with 137-billion parameters, pre-trained on a mixture of web documents, dialog data and Wikipedia; ? PaLM-540B <ref type="bibr">(Chowdhery et al., 2022)</ref> is a dense left-to-right, decoder-only language model with 540-billion parameters, pre-trained on a high quality corpus of 780 billion tokens with filtered webpages, books, Wikipedia, news articles, source code, and social media conversations. We perform all experiments in the few-shot setting, without training or fine-tuning the language models. For a fair comparison we use the same prompts as in : for all arithmetic reasoning tasks we use the same set of 8 manually written exemplars; for each commonsense reasoning task, 4-7 exemplars are randomly chosen from the training set with manually composed chain-of-thought prompts. 6 Full details on the prompts used are given in Appendix A.2.</p><p>Sampling scheme. To sample diverse reasoning paths, we followed similar settings to those suggested in <ref type="bibr" target="#b50">Radford et al. (2019)</ref>; <ref type="bibr" target="#b31">Holtzman et al. (2020)</ref> for open-text generation. In particular, for UL2-20B and LaMDA-137B we applied temperature sampling with T = 0.5 and truncated at the top-k (k = 40) tokens with the highest probability, for PaLM-540B we applied T = 0.7, k = 40, and for GPT-3 we use T = 0.7 without top-k truncation. We provide an ablation study in Section 3.5 to show that self-consistency is generally robust to sampling strategies and parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">MAIN RESULTS</head><p>We report the results of self-consistency averaged over 10 runs, where we sampled 40 outputs independently from the decoder in each run. The baseline we compare to is chain-of-thought prompting with greedy decoding , referred to as CoT-prompting, which has been previously used for decoding in large language models <ref type="bibr">(Chowdhery et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Arithmetic Reasoning</head><p>The results are shown in <ref type="table">Table 2</ref>. 7 Self-consistency improves the arithmetic reasoning performance over all four language models significantly over chain-of-thought prompting. More surprisingly, the gains become more significant when the language model's scale increases, e.g., we see +3%-6% absolute accuracy improvement over UL2-20B but +9%-23% improvement for LaMDA-137B and GPT-3. For larger models that already achieve high accuracy on most tasks (e.g., GPT-3 and PaLM-540B), self-consistency still contributes significant additional gains with +12%-18% absolute accuracy on tasks like AQuA and GSM8K, and +7%-11% on SVAMP and ASDiv. With self-consistency, we achieve new state-of-the-art results on almost all tasks: despite the fact that self-consistency is unsupervised and task-agnostic, these results compare favorably to existing approaches that require task-specific training, or fine-tuning with thousands of examples (e.g., on GSM8K). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LaMDA-137B</head><p>CoT-prompting 52.9 51.8 49.0 17.7 38.9 17.1 Self-consistency 63.5 (+10.6) 75.7 (+23.9) 58.2 (+9.2) 26.8 (+9.1) 53.3 (+14.4) 27.7 (+10.6)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PaLM-540B</head><p>CoT-prompting 91.9 94.7 74.0 35.8 79.0 56.5 Self-consistency 93.7 (+1.8) 99.3 (+4.6) 81.9 (+7.9) 48.3 (+12.5) 86.6 (+7.6) 74.4 (+17.9)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPT-3</head><p>Code-davinci-001</p><p>CoT-prompting 57.2 59.5 52.7 18.9 39.8 14.6 Self-consistency 67.8 (+10.6) 82.7 (+23.2) 61.9 (+9.2) 25.6 (+6.7) 54.5 (+14.7) 23.4 (+8.8)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPT-3</head><p>Code-davinci-002</p><p>CoT-prompting 89.4 96.2 80.1 39.8 75.8 60.1 Self-consistency 91.6 (+2.2) 100.0 (+3.8) 87.8 (+7.6) 52.0 (+12.2) 86.8 (+11.0) 78.0 (+17.9) <ref type="table">Table 2</ref>: Arithmetic reasoning accuracy by self-consistency compared to chain-of-thought prompting . The previous SoTA baselines are obtained from: a: Relevance and LCA operation classifier <ref type="bibr" target="#b53">(Roy &amp; Roth, 2015)</ref>  <ref type="bibr" target="#b19">(Cobbe et al., 2021)</ref>, g: GPT-3 175B finetuned plus an additional 175B verifier <ref type="bibr" target="#b19">(Cobbe et al., 2021)</ref>. The best performance for each task is shown in bold. <ref type="table">Table 3</ref> shows the results on commonsense and symbolic reasoning tasks. Similarly, self-consistency yields large gains across all four language models, and obtained SoTA results on 5 out of 6 tasks. For symbolic reasoning, we test the out-of-distribution (OOD) setting where the input prompt contains examples of 2-letters or 2-flips but we test examples of 4-letters and 4-flips (this setting is more challenging as PaLM-540B or GPT-3 can already achieve perfect in-distribution accuracy). In this challenging OOD setting, the gain of self-consistency is still quite significant compared to CoT-prompting with sufficient model sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Commonsense and Symbolic Reasoning</head><p>To show the effect of the number of sampled reasoning paths, we plot the accuracy (mean and standard deviation over 10 runs) with respect to varying numbers of sampled paths <ref type="bibr">(1,</ref><ref type="bibr">5,</ref><ref type="bibr">10,</ref><ref type="bibr">20,</ref><ref type="bibr">40)</ref> in <ref type="figure" target="#fig_1">Figure 2</ref>. The results show that sampling a higher number (e.g., 40) of reasoning paths leads to a  <ref type="table">Table 3</ref>: Commonsense and symbolic reasoning accuracy by self-consistency compared to chainof-thought prompting . The previous SoTA baselines are obtained from: a: DeBERTaV3-large + KEAR <ref type="bibr" target="#b64">(Xu et al., 2021b)</ref>, b: <ref type="bibr">Chowdhery et al. (2022)</ref>, c: UnifiedQA-FT <ref type="bibr">(Khashabi et al., 2020)</ref>. The best performance for each task is shown in bold.</p><p>consistently better performance, further emphasizing the importance of introducing diversity in the reasoning paths. In <ref type="table" target="#tab_3">Table 4</ref>, we show self-consistency yields a richer set of reasoning paths compared to greedy decoding with a few example questions from two tasks. Question Henry made two stops during his 60-mile bike trip. He first stopped after 20 miles. His second stop was 15 miles before the end of the trip. How many miles did he travel between his first and second stops?</p><p>Yes or no: Is Albany, Georgia the most populous US Albany?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Greedy Decode</head><p>He traveled 60 miles in total. He stopped after 20 miles, so he traveled 60 -20 = 40 miles between the first and second stops. The answer is 40.</p><p>Albany, Georgia is the most populous US Albany. Thus, the answer is yes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sampled</head><p>Path <ref type="formula">1</ref> Henry travelled a total of 60 miles. His first stop was 20 miles in, and his second stop was 15 miles before the end. So between his first and second stops he travelled 60 -20 -15 = 25 miles. The answer is 25.</p><p>The most populous US Albany is Albany, New York. Thus, Albany, Georgia is not the most populous US Albany. So the answer is no.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sampled Path 2</head><p>He made two stops during a 60-mile trip. The first was 20 miles into the trip. The second was 15 miles before the end of the trip. This means the second stop was 60 -15 = 45 miles into the trip. Since he made the stops in order, the second stop must have been 45 -20 = 25 miles after the first stop. The answer is 25.</p><p>Albany, Georgia has a population of about 88,000. Albany, New York has a population of about 95,000. Thus, Albany, Georgia is not the most populous US Albany. So the answer is no.  <ref type="formula" target="#formula_1">(2022)</ref> show that sometimes chain-of-thought prompting might hurt performance compared to standard prompting in few-shot in-context learning. Here we perform a study using self-consistency to see if it can help fill in the gap, over a set of common NLP tasks, including <ref type="formula">(1)</ref> Closed-Book Question Answering: BoolQ <ref type="bibr" target="#b17">(Clark et al., 2019)</ref>, HotpotQA <ref type="bibr" target="#b65">(Yang et al., 2018)</ref>, and (2) Natural Language Inference: e-SNLI <ref type="bibr">(Camburu et al., 2018)</ref>, ANLI <ref type="bibr" target="#b44">(Nie et al., 2020)</ref> and <ref type="bibr">RTE (Dagan et al., 2005;</ref><ref type="bibr" target="#b5">Bar-Haim et al., 2006;</ref><ref type="bibr" target="#b29">Giampiccolo et al., 2007;</ref><ref type="bibr" target="#b7">Bentivogli et al., 2009)</ref>.</p><p>The results over PaLM-540B are shown in <ref type="table" target="#tab_5">Table 5</ref>. For some tasks (e.g., ANLI-R1, e-SNLI, RTE), adding chain-of-thought does hurt performance compared to standard prompting <ref type="bibr" target="#b10">(Brown et al., 2020)</ref>, but self-consistency is able to robustly boost the performance and outperform standard prompting, making it a reliable way to add rationales in few-shot in-context learning for common NLP tasks.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">COMPARE TO OTHER EXISTING APPROACHES</head><p>We conduct a set of additional studies and show that self-consistency significantly outperforms existing methods including sample-and-rank, beam search, and ensemble-based approaches.</p><p>Comparison to Sample-and-Rank One commonly used approach to improve generation quality is sample-and-rank, where multiple sequences are sampled from the decoder and then ranked according to each sequence's log probability <ref type="bibr" target="#b1">(Adiwardana et al., 2020)</ref>. We compare self-consistency with sample-and-rank on GPT-3 code-davinci-001, by sampling the same number of sequences from the decoder as self-consistency and taking the final answer from the top-ranked sequence. The results are shown in <ref type="figure" target="#fig_2">Figure 3</ref>. While sample-and-rank does improve the accuracy with additionally sampled sequences and ranking, the gain is much smaller compared to self-consistency.  <ref type="table">Table 6</ref>, we compare self-consistency with beam search decoding on the UL2-20B model. For a fair comparison we report the accuracy under the same number of beams and reasoning paths. On both tasks self-consistency outperforms beam search significantly. Note self-consistency can also adopt beam search to decode each reasoning path (results are shown as "Self-consistency using beam search"), but its performance is worse compared to self-consistency with sampling. The reason is that beam search yields a lower diversity in the outputs , while in self-consistency the diversity of the reasoning paths is the key to a better performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MultiArith</head><p>Beam search decoding (top beam) 10.7 12.0 11.3 11.0 10.5 Self-consistency using beam search 10.7 11.8 ? 0.0 11.4 ? 0.1 12.3 ? 0.1 10.8 ? 0.1 Self-consistency using sampling 9.5 ? 1.2 11.3 ? 1.2 12.3 ? 0.8 13.7 ? 0.9 14.7 ? 0.3 <ref type="table">Table 6</ref>: Compare self-consistency with beam search decoding on the UL2-20B model. Comparison to Ensemble-based Approaches We further compare self-consistency to ensemblebased methods for few-shot learning. In particular, we consider ensembling by: (1) prompt order permutation: we randomly permute the exemplars in the prompt 40 times to mitigate model's sensitivity to prompt order <ref type="bibr" target="#b68">(Zhao et al., 2021;</ref><ref type="bibr" target="#b41">Lu et al., 2021)</ref>; and (2) multiple sets of prompts <ref type="bibr" target="#b26">(Gao et al., 2021)</ref>: we manually write 3 different sets of prompts. We took majority vote of the answers from greedy decoding in both approaches as an ensemble. <ref type="table">Table 7</ref> shows that compared to self-consistency, existing ensemble-based approaches achieve a much smaller gain. 8 In addition, note that self-consistency is different from a typical model-ensemble approach, where multiple models are trained and their outputs are aggregated. Self-consistency acts more like a "self-ensemble" on top of a single language model. We additionally show the results of ensembling multiple models in Appendix A.1.3 where the model-ensembles perform much worse compared to self-consistency. <ref type="bibr">GSM8K</ref> MultiArith SVAMP ARC-e ARC-c</p><p>CoT <ref type="formula">(</ref>  <ref type="table">Table 7</ref>: Self-consistency outperforms prompt-order and multiple-prompt ensembles on LaMDA-137B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">ADDITIONAL STUDIES</head><p>We conducted a number of additional experiments to analyze different aspects of the self-consistency method, including its robustness to sampling strategies and parameters, and how it works with imperfect prompts and non-natural-language reasoning paths.</p><p>Self-Consistency is Robust to Sampling Strategies/Parameters and Scaling We show selfconsistency is robust to sampling strategies and parameters, by varying T in temperature sampling <ref type="bibr" target="#b0">(Ackley et al., 1985;</ref><ref type="bibr" target="#b25">Ficler &amp; Goldberg, 2017)</ref>, k in top-k sampling <ref type="bibr" target="#b24">(Fan et al., 2018;</ref><ref type="bibr" target="#b30">Holtzman et al., 2018;</ref><ref type="bibr" target="#b50">Radford et al., 2019)</ref>, and p in nucleus sampling <ref type="bibr" target="#b31">(Holtzman et al., 2020)</ref>, over PaLM-540B in <ref type="figure" target="#fig_3">Figure 4</ref> (left). <ref type="figure" target="#fig_3">Figure 4 (right)</ref> shows that self-consistency robustly improves performance across all scales for the LaMDA-137B model series. The gain is relatively lower for smaller models due to certain abilities (e.g., arithmetic) only emerge when the model reaches a sufficient scale <ref type="bibr" target="#b10">(Brown et al., 2020)</ref>. Self-Consistency Improves Robustness to Imperfect Prompts For few-shot learning with manually constructed prompts, human annotators sometimes make minor mistakes when creating the prompts. We further study if self-consistency can help improve a language model's robustness to imperfect prompts. <ref type="bibr">9</ref> We show the results in <ref type="table" target="#tab_8">Table 8</ref>: while imperfect prompts decrease accuracy with greedy decoding (17.1 ? 14.9), self-consistency can fill in the gaps and robustly improve the results.</p><p>Additionally, we found that the consistency (in terms of % of decodes agreeing with the final aggregated answer) is highly correlated with accuracy ( <ref type="figure" target="#fig_4">Figure 5, over GSM8K)</ref>. This suggests that one can use self-consistency to provide an uncertainty estimate of the model in its generated solutions.</p><p>In other words, one can use low consistency as an indicator that the model has low confidence; i.e., self-consistency confers some ability for the model to "know when it doesn't know".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Self-Consistency Works for Non-Natural-Language Reasoning Paths and Zero-shot CoT</head><p>We also tested the generality of the self-consistency concept to alternative forms of intermediate reasoning like equations (e.g., from "There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars." to "3 + 2 = 5"). The results are shown in Prompt with equations 5.0 + Self-consistency (40 paths) 6.5</p><p>PaLM-540B Zero-shot CoT <ref type="bibr" target="#b35">(Kojima et al., 2022)</ref> 43.0 + Self-consistency (40 paths) 69.2 <ref type="table" target="#tab_8">Table 8</ref>: Self-consistency works under imperfect prompts, equation prompts and zero-shot chain-of-thought for GSM8K. and less opportunity remains for generating diversity in the decoding process. In addition, we tested self-consistency with zero-shot chain-of-thought <ref type="bibr" target="#b35">(Kojima et al., 2022)</ref> and show that self-consistency works for zero-shot CoT as well and improves the results significantly (+26.2%) in <ref type="table" target="#tab_8">Table 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head><p>Reasoning in language models. Language models are known to struggle in Type 2 tasks, such as arithmetic, logical and commonsense reasoning <ref type="bibr" target="#b23">(Evans, 2010)</ref>. Previous work has primarily focused on specialized approaches for improving reasoning <ref type="bibr" target="#b3">(Andor et al., 2019;</ref><ref type="bibr" target="#b52">Ran et al., 2019;</ref><ref type="bibr" target="#b27">Geva et al., 2020;</ref><ref type="bibr">Pi?kos et al., 2021)</ref>. Compared to prior work, self-consistency is applicable to a wide range of reasoning tasks without any additional supervision or fine-tuning, while still substantially improving the performance of the chain-of-thought prompting approach proposed in .</p><p>Sampling and re-ranking in language models. Multiple decoding strategies for language models have been proposed in the literature, e.g., temperature sampling <ref type="bibr" target="#b0">(Ackley et al., 1985;</ref><ref type="bibr" target="#b25">Ficler &amp; Goldberg, 2017)</ref>, top-k sampling <ref type="bibr" target="#b24">(Fan et al., 2018;</ref><ref type="bibr" target="#b30">Holtzman et al., 2018;</ref><ref type="bibr" target="#b50">Radford et al., 2019)</ref>, nucleus sampling <ref type="bibr" target="#b31">(Holtzman et al., 2020)</ref>, minimum Bayes risk decoding <ref type="bibr" target="#b21">(Eikema &amp; Aziz, 2020)</ref>, and typical decoding <ref type="bibr" target="#b42">(Meister et al., 2022)</ref>. Other work has sought to explicitly promote diversity in the decoding process <ref type="bibr" target="#b6">(Batra et al., 2012;</ref><ref type="bibr" target="#b59">Vijayakumar et al., 2018)</ref>.</p><p>Re-ranking is another common approach to improve generation quality in language models (Adiwardana et al., 2020; <ref type="bibr" target="#b54">Shen et al., 2021)</ref>. <ref type="bibr" target="#b58">Thoppilan et al. (2022)</ref> collect additional human annotations to train a re-ranker for response filtering. <ref type="bibr" target="#b19">Cobbe et al. (2021)</ref> train a "verifier" to re-rank generated solutions, which substantially improves the solve rate on math tasks compared to just fine-tuning the language model. <ref type="bibr" target="#b22">Elazar et al. (2021)</ref> improve the consistency of factual knowledge extraction by extending pre-training with an additional consistency loss. All these methods require either training an additional re-ranker or collecting additional human annotation, while self-consistency requires no additional training, fine-tuning, nor extra data collection.</p><p>Extract reasoning paths. Some previous work has considered task-specific approaches for identifying reasoning paths, such as constructing semantic graphs <ref type="bibr" target="#b62">(Xu et al., 2021a)</ref>, learning an RNN to retrieve reasoning paths over the Wikipedia graph <ref type="bibr" target="#b4">(Asai et al., 2020)</ref>, fine-tuning with human annotated reasoning paths on math problems <ref type="bibr" target="#b19">(Cobbe et al., 2021)</ref>, or training an extractor with heuristic-based pseudo reasoning paths <ref type="bibr" target="#b13">(Chen et al., 2019)</ref>. More recently, the importance of diversity in the reasoning processes has been noticed, but only leveraged via task-specific training, either through an additional QA model over extracted reasoning paths <ref type="bibr" target="#b13">(Chen et al., 2019)</ref>, or by the introduction of latent variables in a commonsense knowledge graph <ref type="bibr" target="#b58">(Yu et al., 2022)</ref>. Compared to these approaches, self-consistency is far simpler and requires no additional training. The approach we propose simply couples the generation of reasoning paths and a final answer by sampling from the decoder, using aggregation to recover the most consistent answer without additional modules.</p><p>Consistency in language models. Some prior work has shown that language models can suffer from inconsistency in conversation <ref type="bibr" target="#b1">(Adiwardana et al., 2020)</ref>, explanation generation <ref type="bibr" target="#b12">(Camburu et al., 2020)</ref>, and factual knowledge extraction <ref type="bibr" target="#b22">(Elazar et al., 2021)</ref>. <ref type="bibr" target="#b61">Welleck et al. (2020)</ref> use "consistency" to refer to generating an infinite-length sequence in recurrent language models. <ref type="bibr" target="#b45">Nye et al. (2021)</ref> improve the logical consistency of samples from a System 1 model by adding a System 2-inspired logical reasoning module. In this paper we focus on a slightly different notion of "consistency", i.e., utilizing answer consistency among diverse reasoning paths to improve accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND DISCUSSION</head><p>We introduced a simple yet effective method called self-consistency, and observed that it significantly improves accuracy in a range of arithmetic and commonsense reasoning tasks, across four large language models with varying scales. Beyond accuracy gains, self-consistency is also useful for collecting rationales when performing reasoning tasks with language models, and for providing uncertainty estimates and improved calibration of language model outputs.</p><p>One limitation of self-consistency is that it incurs more computation cost. In practice people can try a small number of paths (e.g., 5 or 10) as a starting point to realize most of the gains while not incurring too much cost, as in most cases the performance saturates quickly <ref type="figure" target="#fig_1">(Figure 2</ref>). As part of future work, one could use self-consistency to generate better supervised data to fine-tune the model, such that the model can give more accurate predictions in a single inference run after fine-tuning. In addition, we observed that language models can sometimes generate incorrect or nonsensical reasoning paths (e.g., the strategy QA example in <ref type="table" target="#tab_3">Table 4</ref>, the two population numbers are not exactly correct), and further work is needed to better ground models' rationale generations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX</head><p>A.1 ADDITIONAL EXPERIMENT RESULTS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.1 ROBUSTNESS TO SAMPLING STRATEGIES AND PARAMETERS</head><p>In <ref type="figure" target="#fig_5">Figure 6</ref> we ablate the results with respect to different sampling strategies and parameters by varying T in temperature sampling and k in Top-k sampling, on LaMDA-137B. Self-consistency is quite robust to various sampling strategies and parameters. In <ref type="figure" target="#fig_6">Figure 7</ref> and <ref type="figure" target="#fig_7">Figure 8</ref>, we show the results of self-consistency compared with greedy decoding a single path over LaMDA-137B and PaLM-540B, respectively. Self-consistency improves over greedy decode by a quite significant margin on both models, on top of high accuracy already achieved by scaling up model sizes. We further show additional sampled reasoning paths from the LaMDA-137B model in <ref type="table">Table 12</ref>, and sampled reasoning paths from the PaLM-540B model in <ref type="table">Table 13</ref>. We see that the diversity in the additionally sampled reasoning paths indeed helps the model arrive at a more correct final answer after aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.2 ROBUSTNESS TO DIFFERENT SETS OF PROMPTS</head><p>In <ref type="table">Table 9</ref>, we further show that self-consistency is quite robust to different sets of input prompts. We manually wrote 3 different sets of chains of thought as prompts to the model. Across all sets of prompts, self-consistency yields consistent gains over the original CoT approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.3 COMPARED TO MODEL ENSEMBLES</head><p>Additionally, we provide results of directly ensembling the outputs from multiple language models. The results are shown in <ref type="table">Table 10</ref>, by greedily decoding sequences from 3 language models and CoT  56.5 54.6 54.0 Self-consistency 74.4 (+17.9) 72.1 (+17.5) 70.4 (+16.4) <ref type="table">Table 9</ref>: GSM8K accuracy over PaLM-540B. The results show robustness of self-consistency with respect to different prompts in the input.</p><p>taking the majority vote (averaged over 10 runs). Note this is a typical ensemble approach (averaging over the predictions over multiple models) and it achieves a performance significantly worse than self-consistency (self-consistency over PaLM-540B gets an accuracy of 74.4%), as lower-capacity models drag down the performance of higher-capacity models. In addition, this approach is limited in two ways: 1) It requires multiple models for an ensemble which might not always be available, while self-consistency only requires one single model to "self-ensemble"; 2) If one of the models is much weaker, it can actually hurt the final performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method GSM8K accuracy</head><p>Single model PaLM-540B, greedy / self-consistency 56.5 / 74.4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ensemble of models</head><p>LaMDA-137B + PaLM-540B 36.9 ? 0.5 PaLM-540B + GPT-3 (code-davinci-001, 175B) 36.6 ? 0.4 LaMDA-137B + GPT-3 (code-davinci-001, 175B)</p><p>16.0 ? 0.8 LaMDA-137B + PaLM-540B + GPT-3 (code-davinci-001, 175B)</p><p>33.3 ? 0.7 <ref type="table">Table 10</ref>: Comparison of GSM8K accuracy over multiple-model ensembles.</p><p>A.1.4 COMBINING SELF-CONSISTENCY WITH OTHER ENSEMBLING STRATEGIES Self-consistency is completely compatible with other ensemble strategies, although the gains achieved by self-consistency are significantly higher than other ensemble strategies (and can "override" the performance gains achieved by other ensemble strategies). We further performed experiments and include the results in  The number of boys is the difference between 697 and 228. This is 697 -228 = 469. The answer is 469.</p><p>In the beginning there are 697 girls and the rest are boys. So, the number of boys must be 697 -228 = 469 boys. The answer is 469.</p><p>[AQuA] There are 10 oranges in a basket. Find the no. of ways in which 2 oranges are chosen from the basket? (a) 45 (b) 90 (c) 120 (d) 150 (e) 180</p><p>There are 10 oranges in a basket. So there are 10 ways in which 2 oranges are chosen from the basket.</p><p>There are 10 oranges in a basket. We need to choose 2 oranges from the basket. So the number of ways are 10C2. So the answer is (a).</p><p>There are 10 oranges in the basket. If you choose 2 oranges, you have 10C2 = 45 ways of choosing 2 oranges. So the answer is (a).</p><p>[CommonsenseQA] The man laid on the soft moss and looked up at the trees, where was the man? (a) niagra falls (b) forest (c) waterfall (d) ground (e) tree</p><p>The answer must be something that is soft and mossy. Of the above choices, only ground is soft and mossy. So the answer is (d).</p><p>The answer must be somewhere where moss is found. Of the above choices, only forests are known for having moss. So the answer is (b).</p><p>The answer must be a place where the man is laying down and looking up at trees. Of the above choices, only forest is a place where people lay down and look at trees. So the answer is (b).</p><p>[ARC] Which of these will most likely harm a habitat? Planting trees will not harm a habitat. So the answer is (a).</p><p>The answer is (b), water pollution, because it will most likely harm the habitat. The other answers are not likely to harm the habitat.</p><p>The answer is (b), water pollution. Trees are good for a habitat, rainfall is necessary for a habitat, and sunlight is necessary for a habitat. So the answer is (b). The process of photosynthesis in plants takes the longest to complete. So the answer is (c).</p><p>The formation of fossil fuels takes the longest time to complete. So the answer is (d).</p><p>The process that takes the longest time to complete is the formation of fossil fuels, which happens over millions of years. So the answer is (d). <ref type="table">Table 12</ref>: Additional examples where self-consistency helps repair the errors over greedy decode on LaMDA-137B. Two sampled reasoning paths that are consistent with the ground truth are shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 FULL SETS OF PROMPTS</head><p>We list the full details of the prompts used for two newly-introduced datasets, AQUA-RAT <ref type="bibr">(Ling et al., 2017)</ref> and AI2 Reasoning Challenge (ARC) <ref type="bibr" target="#b18">(Clark et al., 2018)</ref>, where we manually composed the example chains of thought in this paper, in <ref type="table" target="#tab_3">Table 14 and Table 15</ref>, respectively.</p><p>As additional information, we also list the exact set of prompts used for all arithmetic reasoning tasks in <ref type="table" target="#tab_16">Table 17</ref>, since there are multiple sets of prompts introduced in . The prompts for CommonsenseQA and StrategyQA are the same as used in .</p><p>We provide the exact prompts used for common NLP tasks in the following tables as well, including NLI and Closed-Book Question-Answering tasks. The volume of the tank is 8 m * 6 m * 2.5 m = 120 m 3 . So the capacity of the tank is 120 m 3 . So the answer is (c).</p><p>The volume of the tank is 8m * 6m* 2.5m = 120m 3 . This is equal to 120000 litres. So the answer is (d)</p><p>The volume of the tank is 8 m * 6 m * 2.5 m = 120 m3. One cubic meter contains 1000 litres, so the tank contains 120 m3 * 1000 liters/m3 = 120,000 liters. So the answer is (d).</p><p>[StrategyQA] Yes or no: Can the Great Depression be treated with Prozac?</p><p>The Great Depression was an economic depression. Prozac is a drug used to treat depression. Thus, the Great Depression could be treated with Prozac. So the answer is yes.</p><p>Prozac is an anti-depressant medication. A nonrenewable source of energy is one in which the source is not replenished in a short amount of time. Thus, the only option that is nonrenewable is coal. So the answer is (a).</p><p>Coal is a fossil fuel and is formed from dead organisms from the past. Coal cannot be produced in a short period of time, so it is considered a nonrenewable source of energy. So the answer is (a). The Earth is closest to the Sun in December, hence Florida will have the most sunlight energy available in December. So the answer is (d).</p><p>Earth is closest to the Sun on June 21, the summer solstice. So the answer is (b).</p><p>Florida is closer to the sun during June, so it will have the most sunlight energy during that month. So the answer is (b). <ref type="table">Table 13</ref>: Additional examples where self-consistency helps repair the errors over greedy decode on PaLM-540B. Two sampled reasoning paths that are consistent with the ground truth are shown. Q: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64</p><p>A: If 10 is added to each number, then the mean of the numbers also increases by 10. So the new mean would be 50. The answer is (a). Q: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then find the distance? Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km A: The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. The answer is (e).</p><p>Q: How many keystrokes are needed to type the numbers from 1 to 500? Answer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788</p><p>A: There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401 three-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b).  A: Dry surfaces will more likely cause more friction via rubbing than other smoother surfaces, hence dry palms will produce the most heat. The answer is (a). Q: Which factor will most likely cause a person to develop a fever? (a) a leg muscle relaxing after exercise.     .</p><p>Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?</p><p>A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted. So, they must have planted 21 -15 = 6 trees. The answer is 6.</p><p>Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?</p><p>A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.</p><p>Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?</p><p>A: Leah had 32 chocolates and Leah's sister had 42. That means there were originally 32 + 42 = 74 chocolates. 35 have been eaten. So in total they still have 74 -35 = 39 chocolates. The answer is 39.</p><p>Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?</p><p>A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of lollipops he has given to Denny must have been 20 -12 = 8 lollipops. The answer is 8.</p><p>Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?</p><p>A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in total he has 7 + 2 = 9 toys. The answer is 9.</p><p>Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?</p><p>A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 = 20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers. The answer is 29. Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?</p><p>A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 -23 = 35 balls. On Wednesday he lost 2 more so now he has 35 -2 = 33 balls. The answer is 33.</p><p>Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?</p><p>A: She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in beginning, so now she has $23 -$15 = $8. The answer is 8.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>, b: Lan et al. (2021), c: Amini et al. (2019), d: Pi et al. (2022), e: GPT-3 175B finetuned with 7.5k examples</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Self-consistency (blue) significantly improves accuracy over CoT-prompting with greedy decoding (orange) across arithmetic and commonsense reasoning tasks, over LaMDA-137B. Sampling a higher number of diverse reasoning paths consistently improves reasoning accuracy.GSM8KStrategy QA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Self-consistency significantly outperforms sample-and-rank with the same # of samples. Comparison to Beam Search In</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>GSM8K accuracy. (Left) Self-consistency is robust to various sampling strategies and parameters. (Right) Self-consistency improves performance across language model scales.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>The consistency is correlated with model's accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>GSM8K accuracy over LaMDA-137B. Self-consistency works under various sampling strategies and sampling parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Self-consistency (blue) significantly improves accuracy across various arithmetic and commonsense reasoning tasks, over LaMDA-137B. Sampling a higher number of diverse reasoning paths consistently improves reasoning accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Self-consistency (blue) significantly improves accuracy across various arithmetic and commonsense reasoning tasks, over PaLM-540B. Sampling a higher number of diverse reasoning paths consistently helps reasoning accuracy.Prompt set 1 (used in the main text) Prompt set 2 Prompt set 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(a) planting trees. (b) water pollution. (c) rainfall. (d) sunlight.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>[</head><label></label><figDesc>ARC-challenge] Which process in the carbon cycle takes the longest to complete? (a) emission of waste. (b) respiration in animals. (c) photosynthesis in plants. (d) formation of fossil fuels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>[</head><label></label><figDesc>ARC-challenge] Students studied the revolution of Earth around the Sun. During which month will Florida have the most sunlight energy available? (a) March. (b) June. (c) September. (d) December.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Q:</head><label></label><figDesc>If a / b = 3/4 and 8a + 5b = 22,then find the value of a. Answer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e) 7/2 A: If a / b = 3/4, then b = 4a / 3. So 8a + 5(4a / 3) = 22. This simplifies to 8a + 20a / 3 = 22, which means 44a / 3 = 22. So a is equal to 3/2. The answer is (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Q:</head><label></label><figDesc>George wants to warm his hands quickly by rubbing them. Which skin surface will produce the most heat? (a) dry palms. (b) wet palms. (c) palms covered with oil. (d) palms covered with lotion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>(b) a bacterial population in the bloodstream. (c) several viral particles on the skin. (d) carbohydrates being digested in the stomach. A: Option (b), bacterial population is the most likely cause for a person developing fever. The answer is (b). Q: Which change in the state of water particles causes the particles to become arranged in a fixed position? (a) boiling. (b) melting. (c) freezing. (d) evaporating. A: When water is freezed, the particles are arranged in a fixed position; the particles are still moving for all other options. The answer is (c). Q: When a switch is used in an electrical circuit, the switch can (a) cause the charge to build. (b) increase and decrease the voltage. (c) cause the current to change direction. (d) stop and start the flow of current.A: The function of a switch is to start and stop the flow of a current. The answer is (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Q:</head><label></label><figDesc>Which magazine was started first Arthur's Magazine or First for Women? A: Arthur's Magazine started in 1844. First for Women started in 1989. So Arthur's Magazine was started first. The answer is Arthur's Magazine. Q: The Oberoi family is part of a hotel company that has a head office in what city? A: The Oberoi family is part of the hotel company called The Oberoi Group. The Oberoi Group has its head office in Delhi. The answer is Delhi. Q: What nationality was James Henry Miller's wife? A: James Henry Miller's wife is June Miller. June Miller is an American. The answer is American. Q: The Dutch-Belgian television series that "House of Anubis" was based on first aired in what year? A: "House of Anubis" is based on the Dutch-Belgian television series Het Huis Anubis. Het Huis Anubis is first aired in September 2006. The answer is 2006.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Weighted avg (unnormalized) 56.3 ? 0.0 90.5 ? 0.0 35.8 ? 0.0 73.0 ? 0.0 74.8 ? 0.0 82.3 ? 0.0Weighted avg (normalized) 22.1 ? 0.0 59.7 ? 0.0 15.7 ? 0.0 40.5 ? 0.0 52.1 ? 0.0 51.7 ? 0.0</figDesc><table><row><cell></cell><cell cols="2">GSM8K MultiArith</cell><cell>AQuA</cell><cell>SVAMP</cell><cell>CSQA</cell><cell>ARC-c</cell></row><row><cell>Greedy decode</cell><cell>56.5</cell><cell>94.7</cell><cell>35.8</cell><cell>79.0</cell><cell>79.0</cell><cell>85.2</cell></row><row><cell cols="7">Weighted sum (unnormalized) 59.9 ? 0.0 92.2 ? 0.0 38.2 ? 0.0 76.2 ? 0.0 76.2 ? 0.0 83.5 ? 0.0</cell></row><row><cell>Weighted sum (normalized)</cell><cell cols="6">74.1 ? 0.0 99.3 ? 0.0 48.0 ? 0.0 86.8 ? 0.0 80.7 ? 0.0 88.7 ? 0.0</cell></row><row><cell cols="7">Unweighted sum (majority vote) 74.4 ? 0.1 99.3 ? 0.0 48.3 ? 0.5 86.6 ? 0.1 80.7 ? 0.1 88.7 ? 0.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>. Next,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Self-consistency 55.7 (+4.3) 54.9 (+1.6) 69.8 (+8.2) 49.5 (+6.8) 0.0 (+0.0) 50.5 (+0.1) Self-consistency 80.7 (+1.7) 81.6 (+6.3) 96.4 (+1.1) 88.7 (+3.5) 70.8 (+5.0) 91.2 (+3.0)</figDesc><table><row><cell></cell><cell>Method</cell><cell>CSQA</cell><cell cols="2">StrategyQA ARC-e</cell><cell>ARC-c</cell><cell cols="2">Letter (4) Coinflip (4)</cell></row><row><cell></cell><cell cols="2">Previous SoTA 91.2 a</cell><cell>73.9 b</cell><cell>86.4 c</cell><cell>75.0 c</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>UL2-20B</cell><cell cols="2">CoT-prompting 51.4</cell><cell>53.3</cell><cell>61.6</cell><cell>42.9</cell><cell>0.0</cell><cell>50.4</cell></row><row><cell>LaMDA-137B</cell><cell cols="7">CoT-prompting 57.9 Self-consistency 63.1 (+5.2) 67.8 (+2.4) 79.3 (+4.0) 59.8 (+4.7) 8.2 (+0.0) 73.5 (+1.1) 65.4 75.3 55.1 8.2 72.4</cell></row><row><cell>PaLM-540B</cell><cell cols="2">CoT-prompting 79.0</cell><cell>75.3</cell><cell>95.3</cell><cell>85.2</cell><cell>65.8</cell><cell>88.2</cell></row><row><cell>GPT-3</cell><cell cols="2">CoT-prompting 46.6</cell><cell>56.7</cell><cell>63.1</cell><cell>43.1</cell><cell>7.8</cell><cell>71.4</cell></row><row><cell>Code-davinci-001</cell><cell cols="7">Self-consistency 54.9 (+8.3) 61.7 (+5.0) 72.1 (+9.0) 53.7 (+10.6) 10.0 (+2.2) 75.9 (+4.5)</cell></row><row><cell>GPT-3</cell><cell cols="2">CoT-prompting 79.0</cell><cell>73.4</cell><cell>94.0</cell><cell>83.6</cell><cell>70.4</cell><cell>99.0</cell></row><row><cell>Code-davinci-002</cell><cell cols="7">Self-consistency 81.5 (+2.5) 79.8 (+6.4) 96.0 (+2.0) 87.5 (+3.9) 73.4 (+3.0) 99.5 (+0.5)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Examples where self-consistency helps repair the errors over greedy decode, on PaLM-540B. Two sampled reasoning paths that are consistent with the ground truth are shown.</figDesc><table><row><cell>3.3 SELF-CONSISTENCY HELPS WHEN CHAIN-OF-THOUGHT HURTS PERFORMANCE</cell></row><row><cell>Ye &amp; Durrett</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Compare Standard/CoT prompting with self-consistency on common NLP tasks (PaLM-540B).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>? 0.3 21.2 ? 0.7 24.6 ? 0.4 24.2 ? 0.5 Self-consistency using sampling 19.7 ? 2.5 24.9 ? 2.6 25.3 ? 1.8 26.7 ? 1.0 26.9 ? 0.5</figDesc><table><row><cell></cell><cell>Beam size / Self-consistency paths</cell><cell>1</cell><cell>5</cell><cell>10</cell><cell>20</cell><cell>40</cell></row><row><cell></cell><cell>Beam search decoding (top beam)</cell><cell>23.6</cell><cell>19.3</cell><cell>16.1</cell><cell>15.0</cell><cell>10.2</cell></row><row><cell>AQuA</cell><cell>Self-consistency using beam search</cell><cell>23.6</cell><cell>19.8</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell></cell><cell>Prompt with correct chain-of-thought</cell><cell>17.1</cell></row><row><cell>LaMDA-137B</cell><cell cols="2">Prompt with imperfect chain-of-thought 14.9 + Self-consistency (40 paths) 23.4</cell></row></table><note>("Prompt with equations"): self-consistency still improves accuracy by generating intermediate equations; however, compared to generating natural language reasoning paths, the gain is smaller since the equations are much shorter</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 11</head><label>11</label><figDesc></figDesc><table><row><cell>(for a fair comparison, we use 40 sets of prompts, or 40 prompt</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 11 :</head><label>11</label><figDesc>Combining self-consistency with other ensembling strategies.</figDesc><table><row><cell cols="4">permutations to compare with self-consistency with 40 paths, all experiments are based on PaLM-</cell></row><row><cell>540B).</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Question</cell><cell>Greedy Decode</cell><cell>Sampled Path 1</cell><cell>Sampled Path 2</cell></row><row><cell>[MultiArith] Sam had 10 socks.</cell><cell>Sam had 10 socks. He threw</cell><cell>Sam had 10 socks. He</cell><cell>He had 10 socks. He threw away</cell></row><row><cell>If he threw away 3 old ones</cell><cell>away 3 old ones that didn't fit.</cell><cell>threw away 3 old ones. So</cell><cell>3 old ones that didn't fit. He</cell></row><row><cell>that didn't fit and bought 36 new</cell><cell>He bought 36 new ones. That</cell><cell>now he has 7 left. Then he</cell><cell>bought 36 new ones. So in total</cell></row><row><cell>ones, how many socks would he</cell><cell>means he has 10 + 36 -3 = 41</cell><cell>bought 36 new ones. So</cell><cell>he has 10 -3 + 36 = 43 socks. The</cell></row><row><cell>have?</cell><cell>socks. The answer is 41.</cell><cell>now he has 7 + 36 = 43</cell><cell>answer is 43.</cell></row><row><cell></cell><cell></cell><cell>socks. The answer is 43.</cell><cell></cell></row><row><cell>[SVAMP] In a school there are</cell><cell>There are 697 girls and the rest</cell><cell></cell><cell></cell></row><row><cell>697 girls and the rest are boys.</cell><cell>are boys. That means there are</cell><cell></cell><cell></cell></row><row><cell>If there are 228 more girls than</cell><cell>697 + 228 = 925 girls. The</cell><cell></cell><cell></cell></row><row><cell>boys. How many boys are there</cell><cell>rest are boys. So the number of</cell><cell></cell><cell></cell></row><row><cell>in that school?</cell><cell>boys is 925 -697 = 228. The</cell><cell></cell><cell></cell></row><row><cell></cell><cell>answer is 228.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 14 :</head><label>14</label><figDesc>Few-shot exemplars for AQUA-RAT.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 15 :</head><label>15</label><figDesc>Few-shot exemplars for ARC easy/challenge.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 16 :</head><label>16</label><figDesc>Few-shot exemplars for HotpotQA (closed-book setting).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 17 :</head><label>17</label><figDesc>Few-shot exemplars for all arithmetic reasoning tasks, from</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The parser is task dependent. For arithmetic reasoning, we parse the first numerical part as the final answer after the model generates "The answer is ". For commonsense reasoning, we parse the full string answer as the final answer after the model generates "The answer is ". Most generated outputs have a consistent format of "{Reasoning paths}. The answer is X." if we prompt the language model in this format.2  This also means that the language model is not well calibrated and thus cannot distinguish well between correct solutions and wrong solutions, which also explains why additional re-rankers were trained to better judge the quality of the solutions in previous work<ref type="bibr" target="#b19">(Cobbe et al., 2021;</ref><ref type="bibr" target="#b58">Thoppilan et al., 2022)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">By default we use the test split for all datasets if the labels are available for evaluation. For CommonsenseQA we use the dev split; for StrategyQA we use the question-only set from BIG-bench collaboration(2021):https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/strategyqa.4  Model checkpoints at https://github.com/google-research/google-research/tree/master/ul2. 5 Public API available at https://openai.com/api/. 6 Self-consistency is robust to different sets of prompts and we provide a study in Appendix A.1.2.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">The standard deviation of self-consistency is ? 0.5 for all tasks and is thus omitted in the table. Please refer toFigure 2, Figure 7and 8 for the standard deviations under varying numbers of sampled paths.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Self-consistency is compatible with both ensemble approaches and we show the results in Appendix A.1.4.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">We use the same prompts as before, but swap all the numbers in the reasoning paths with random numbers except the final answer, e.g., from "There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars." to "There are 7 cars in the parking lot already. 6 more arrive. Now there are 7 + 6 = 5 cars.".</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Premise: "Conceptually cream skimming has two basic dimensions -product and geography." Based on this premise, can we conclude the hypothesis "Product and geography are what make cream skimming work." is true? OPTIONS: -yes -no -it is not possible to tell A: Based on "cream skimming has two basic dimensions" we can't infer that these two dimensions are what make cream skimming work. The answer is it is not possible to tell.</p><p>Premise: "One of our member will carry out your instructions minutely." Based on this premise, can we conclude the hypothesis "A member of my team will execute your orders with immense precision." is true? OPTIONS: -yes -no -it is not possible to tell A: "one of" means the same as "a member of", "carry out" means the same as "execute", and "minutely" means the same as "immense precision". The answer is yes.</p><p>Premise: "Fun for adults and children." Based on this premise, can we conclude the hypothesis "Fun for only children." is true? OPTIONS: -yes -no -it is not possible to tell A: "adults and children" contradicts "only children". The answer is no.</p><p>Premise: "He turned and smiled at Vrenna." Based on this premise, can we conclude the hypothesis "He smiled at Vrenna who was walking slowly behind him with her mother." is true? OPTIONS: -yes -no -it is not possible to tell A: the premise does not say anything about "Vrenna was walking". The answer is it is not possible to tell.</p><p>Premise: "well you see that on television also" Based on this premise, can we conclude the hypothesis "You can see that on television, as well." is true? OPTIONS: -yes -no -it is not possible to tell A: "also" and "as well" mean the same thing. The answer is yes.</p><p>Premise: "Vrenna and I both fought him and he nearly took us." Based on this premise, can we conclude the hypothesis "Neither Vrenna nor myself have ever fought him." is true? OPTIONS: -yes -no -it is not possible to tell A: "Vrenna and I both" contradicts "neither Vrenna nor myself". The answer is no.</p><p>Self-Consistency Improves Chain of Thought Reasoning in Language Models <ref type="table">Table 19</ref>: Few-shot exemplars for e-SNLI (the rationales are crowd-sourced annotations from the original dataset).</p><p>Premise: "A person on a horse jumps over a broken down airplane." Based on this premise, can we conclude the hypothesis "A person is training his horse for a competition." is true? OPTIONS: -yes -no -it is not possible to tell A: The person is not necessarily training his horse. The answer is it is not possible to tell.</p><p>Premise: "A person on a horse jumps over a broken down airplane." Based on this premise, can we conclude the hypothesis "A person is at a diner, ordering an omelette." is true? OPTIONS: -yes -no -it is not possible to tell A: One jumping horse cannot be in a diner ordering food. The answer is no.</p><p>Premise: "A person on a horse jumps over a broken down airplane." Based on this premise, can we conclude the hypothesis "A person is outdoors, on a horse." is true? OPTIONS: -yes -no -it is not possible to tell A: A broken down airplane is outdoors. The answer is yes.</p><p>Premise: "Children smiling and waving at camera." Based on this premise, can we conclude the hypothesis "They are smiling at their parents." is true? OPTIONS: -yes -no -it is not possible to tell A: Just because they are smiling and waving at a camera does not imply their parents or anyone is anyone behind it. The answer is it is not possible to tell.</p><p>Premise: "Children smiling and waving at camera." Based on this premise, can we conclude the hypothesis "The kids are frowning." is true? OPTIONS: -yes -no -it is not possible to tell A: One cannot be smiling and frowning at the same time. The answer is no.</p><p>Premise: "Children smiling and waving at camera." Based on this premise, can we conclude the hypothesis "There are children present." is true? OPTIONS: -yes -no -it is not possible to tell A:The children must be present to see them smiling and waving. The answer is yes.</p><p>A: "Herceptin was approved to treat breast cancer" implies that "Herceptin can be used to treat breast cancer". The answer is yes. A: Iran and Afghanistan both speak the Indo-European language Persian. The answer is yes.</p><p>Q: is a cello and a bass the same thing?</p><p>A: The cello is played sitting down with the instrument between the knees, whereas the double bass is played standing or sitting on a stool. The answer is no.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q: can you use oyster card at epsom station?</head><p>A: Epsom railway station serves the town of Epsom in Surrey and is not in the London Oyster card zone. The answer is no.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A learning algorithm for boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Ackley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrence</forename><forename type="middle">J</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sejnowski</surname></persName>
		</author>
		<idno>0364-0213</idno>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S0364021385800124" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="169" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Towards a human-like open-domain chatbot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Adiwardana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">R</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romal</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Nemade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">MathQA: Towards interpretable math word problem solving with operation-based formalisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aida</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saadia</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanchuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/N19-1245" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2357" to="2367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Giving BERT a calculator: Finding operations and arguments with reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Andor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Pitler</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/D19-1609" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to retrieve reasoning paths over wikipedia graph for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SJgVHkrYDH" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The second pascal recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Bar-Haim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second PASCAL challenges workshop on recognising textual entailment</title>
		<meeting>the second PASCAL challenges workshop on recognising textual entailment</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Diverse m-best solutions in markov random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Payman</forename><surname>Yadollahpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abner</forename><surname>Guzman-Rivera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-33715-4_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-33715-4_1" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th European Conference on Computer Vision -Volume Part V, ECCV&apos;12</title>
		<meeting>the 12th European Conference on Computer Vision -Volume Part V, ECCV&apos;12<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The fifth pascal recognizing textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<editor>TAC</editor>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Beyond the imitation game: Measuring and extrapolating the capabilities of language models</title>
		<ptr target="https://github.com/google/BIG-bench/" />
		<imprint/>
	</monogr>
	<note>BIG-bench collaboration</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Self-Consistency Improves Chain of Thought Reasoning in Language Models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ilya Sutskever, and Dario Amodei. Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">esnli: Natural language inference with natural language explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oana-Maria</forename><surname>Camburu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="9539" to="9549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Make up your mind! adversarial generation of inconsistent natural language explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oana-Maria</forename><surname>Camburu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Shillingford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.382</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.382" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="4157" to="4165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Multi-hop question answering via reasoning chains. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Ting</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1910.02610" />
		<imprint>
			<date type="published" when="1910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>et al. Evaluating large language models trained on code</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parker</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kensen</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parker</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinodkumar</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reif ; Denny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anselm Levskaya</title>
		<editor>Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus,</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Palm: Scaling language modeling with pathways</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanumalayan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Sankaranarayana Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Pellat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erica</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongwei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brennan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Saeta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathy</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fiedel</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2204.02311" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Boolq: Exploring the surprising difficulty of natural yes/no questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Think you have solved question answering? try arc, the ai2 reasoning challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carissa</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<idno>abs/1803.05457</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Training verifiers to solve math word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Challenges Workshop</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">International Committee on Self-Consistency Improves Chain of Thought Reasoning in Language Models Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Eikema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilker</forename><surname>Aziz</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.coling-main" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12" />
			<biblScope unit="page" from="4506" to="4520" />
		</imprint>
	</monogr>
	<note>Is MAP decoding all you need? the inadequacy of the mode in neural machine translation</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Measuring and improving consistency in pretrained language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanai</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nora</forename><surname>Kassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shauli</forename><surname>Ravfogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhilasha</forename><surname>Ravichander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00410</idno>
		<ptr target="https://aclanthology.org/2021.tacl-1.60" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1012" to="1031" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Intuition and reasoning: A dual-process perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Inquiry</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="313" to="326" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hierarchical neural story generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1082</idno>
		<ptr target="https://aclanthology.org/P18-1082" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="889" to="898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Controlling linguistic style aspects in neural language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Ficler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-4912</idno>
		<ptr target="https://aclanthology.org/W17-4912" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Stylistic Variation</title>
		<meeting>the Workshop on Stylistic Variation<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09" />
			<biblScope unit="page" from="94" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.295</idno>
		<ptr target="https://aclanthology.org/2021.acl-long" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3816" to="3830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Injecting numerical reasoning skills into language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.89</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.89" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.tacl-1.21" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The third pascal recognizing textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing</title>
		<meeting>the ACL-PASCAL workshop on textual entailment and paraphrasing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to write with cooperative discriminators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1152</idno>
		<ptr target="https://aclanthology.org/P18-1152" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The curious case of neural text degeneration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rygGQyrFvH" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to solve arithmetic word problems with verb categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad Javad</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1058</idno>
		<ptr target="https://aclanthology.org/D14-1058" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">UNIFIEDQA: Crossing format boundaries with a single QA system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.171</idno>
		<ptr target="https://aclanthology.org/2020.findings-emnlp.171" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1896" to="1907" />
		</imprint>
	</monogr>
	<note>Online, November 2020</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Self-Consistency Improves Chain of Thought Reasoning in Language Models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iwasawa</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2205.11916</idno>
		<ptr target="https://arxiv.org/abs/2205.11916" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">MAWPS: A math word problem repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aida</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1136</idno>
		<ptr target="https://aclanthology.org/N16-1136" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">MWPToolkit: An open-source framework for deep learning-based math word problem solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihuai</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunshi</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><forename type="middle">Tian</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ee-Peng</forename><surname>Lim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.00799</idno>
		<ptr target="https://arxiv.org/abs/2109.00799" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Mutual information and diverse decoding improve neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1601.00372" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A simple, fast diverse decoding algorithm for neural generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno>abs/1611.08562</idno>
		<ptr target="http://arxiv.org/abs/1611.08562" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Program induction by rationale generation: Learning to solve and explain algebraic word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1015</idno>
		<ptr target="https://aclanthology.org/P17-1015" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alastair</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<idno>abs/2104.08786</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Typical decoding for natural language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Meister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Pimentel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gian</forename><surname>Wiher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.00666</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A diverse corpus for evaluating and developing English math word problem solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shen Yun Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keh Yih</forename><surname>Chao Chun Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Su</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.acl-main.92" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Adversarial NLI: A new benchmark for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Henry</forename><surname>Tessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brenden</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=uyKk_avJ-p4" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Are NLP models really able to solve simple math word problems?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkil</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satwik</forename><surname>Bhattamishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navin</forename><surname>Goyal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.168</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.168" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06" />
			<biblScope unit="page" from="2080" to="2094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morteza</forename><surname>Ziyadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeqi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>Reasoning like program executors</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Measuring and improving BERT&apos;s mathematical abilities by predicting the order of reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Pi?kos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-short.49</idno>
		<ptr target="https://aclanthology.org/2021.acl-short.49" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Self-Consistency Improves Chain of Thought Reasoning in Language Models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Scaling language models: Methods, analysis &amp; insights from training gopher</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Jack W Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susannah</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.11446</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">NumNet: Machine reading comprehension with numerical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Qiu Ran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1251</idno>
		<ptr target="https://aclanthology.org/D19-1251" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Solving general arithmetic word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1202</idno>
		<ptr target="https://aclanthology.org/D15-1202" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Generate &amp; rank: A multi-task framework for math word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.findings-emnlp.195" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<meeting><address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11" />
			<biblScope unit="page" from="2269" to="2279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Individual differences in reasoning: Implications for the rationality debate?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard F</forename><surname>Stanovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>West</surname></persName>
		</author>
		<ptr target="https://pubmed.ncbi.nlm.nih.gov/11301544/" />
	</analytic>
	<monogr>
		<title level="j">Behavioral and brain sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="645" to="665" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">CommonsenseQA: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/N19-1421" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Unifying language learning paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Vinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dara</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaixiu</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Steven Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Metzler</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2205.05131" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romal</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heng-Tze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08239</idno>
		<ptr target="https://arxiv.org/abs/2201.08239" />
		<title level="m">Language models for dialog applications</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Diverse beam search for improved description of complex scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Vijayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramprasaath</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<ptr target="https://ojs.aaai.org/index.php/AAAI/article/view/12340" />
		<imprint>
			<date type="published" when="2018-04" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://arxiv.org/pdf/2201.11903" />
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Consistency of a recurrent language model with respect to incomplete decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilia</forename><surname>Kulikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaedeok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">Yuanzhe</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.448</idno>
		<ptr target="https://aclanthology.org/2020.emnlp-main.448" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="5553" to="5568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Exploiting reasoning chains for multi-hop science question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.findings-emnlp.99" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<meeting><address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11" />
			<biblScope unit="page" from="1143" to="1156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Self-Consistency Improves Chain of Thought Reasoning in Language Models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Human parity on commonsenseqa: Augmenting self-attention with external attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2112.03254" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">HotpotQA: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1259</idno>
		<ptr target="https://aclanthology.org/D18-1259" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11" />
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">The unreliability of explanations in few-shot in-context learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Diversifying content generation for commonsense reasoning with mixture of knowledge graph experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianhui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A man is due in court later charged with the murder 26 years ago of a teenager whose case was the first to be featured on BBC One&apos;s Crimewatch. Colette Aram, 16, was walking to her boyfriend&apos;s house in Keyworth, Nottinghamshire, on 30 October 1983 when she disappeared. Her body was later found in a field close to her home. Paul Stewart Hutchinson, 50, has been charged with murder and is due before Nottingham magistrates later</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v139/zhao21c.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<editor>Marina Meila and Tong Zhang</editor>
		<meeting>the 38th International Conference on Machine Learning<address><addrLine>Monday</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">139</biblScope>
		</imprint>
	</monogr>
	<note>Based on this premise, can we conclude the hypothesis &quot;Paul Stewart Hutchinson is accused of having stabbed a girl. is true? A: The premise does not say Paul Stewart Hutchinson &quot;stabbed&quot; this girl. The answer is no. Premise: &quot;Herceptin was already approved to treat the sickest breast cancer patients, and the company said. it will discuss with federal regulators the possibility of prescribing the drug for more breast cancer patients.&quot; Based on this premise, can we conclude the hypothesis &quot;Herceptin can be used to treat breast cancer. is true</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
