<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Nearest Neighbors Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Pl?tz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<address>
									<settlement>Darmstadt</settlement>
									<country>TU</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<address>
									<settlement>Darmstadt</settlement>
									<country>TU</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Nearest Neighbors Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Non-local methods exploiting the self-similarity of natural signals have been well studied, for example in image analysis and restoration. Existing approaches, however, rely on k-nearest neighbors (KNN) matching in a fixed feature space. The main hurdle in optimizing this feature space w. r. t. application performance is the non-differentiability of the KNN selection rule. To overcome this, we propose a continuous deterministic relaxation of KNN selection that maintains differentiability w. r. t. pairwise distances, but retains the original KNN as the limit of a temperature parameter approaching zero. To exploit our relaxation, we propose the neural nearest neighbors block (N 3 block), a novel non-local processing layer that leverages the principle of self-similarity and can be used as building block in modern neural network architectures. <ref type="bibr" target="#b0">1</ref> We show its effectiveness for the set reasoning task of correspondence classification as well as for image restoration, including image denoising and single image super-resolution, where we outperform strong convolutional neural network (CNN) baselines and recent non-local models that rely on KNN selection in hand-chosen features spaces.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ongoing surge of convolutional neural networks (CNNs) has revolutionized many areas of machine learning and its applications by enabling unprecedented predictive accuracy. Most network architectures focus on local processing by combining convolutional layers and element-wise operations. In order to draw upon information from a sufficiently broad context, several strategies, including dilated convolutions <ref type="bibr" target="#b49">[50]</ref> or hourglass-shaped architectures <ref type="bibr" target="#b26">[27]</ref>, have been explored to increase the receptive field size. Yet, they trade off context size for localization accuracy. Hence, for many dense prediction tasks, e. g. in image analysis and restoration, stacking ever more convolutional blocks has remained the prevailing choice to obtain bigger receptive fields <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b50">51]</ref>.</p><p>In contrast, traditional algorithms in image restoration increase the receptive field size via non-local processing, leveraging the self-similarity of natural signals. They exploit that image structures tend to re-occur within the same image <ref type="bibr" target="#b53">[54]</ref>, giving rise to a strong prior for image restoration <ref type="bibr" target="#b27">[28]</ref>. Hence, methods like non-local means <ref type="bibr" target="#b5">[6]</ref> or BM3D <ref type="bibr" target="#b8">[9]</ref> aggregate information across the whole image to restore a local patch. Here, matching patches are usually selected based on some hand-crafted notion of similarity, e. g. the Euclidean distance between patches of input intensities. Incorporating this kind of non-local processing into neural network architectures for image restoration has only very recently been considered <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b46">47]</ref>. These methods replace the filtering of matched patches with a trainable network, while the feature space on which k-nearest neighbors selection is carried out is taken to be fixed. But why should we rely on a predefined matching space in an otherwise end-to-end trainable neural network architecture? In this paper, we demonstrate that we can improve non-local processing considerably by also optimizing the feature space for matching.</p><p>The main technical challenge is imposed by the non-differentiability of the KNN selection rule. To overcome this, we make three contributions. First, we propose a continuous deterministic relaxation (1,0,0) (0,1,0) (0,0,1) (d) Continuous NN (Eqs. 8 to 11) <ref type="figure">Figure 1</ref>. Illustration of nearest neighbors selection as paths on the simplex. The traditional KNN rule (b) selects corners of the simplex deterministically based on the distance of the database items xi to the query item q (a). Stochastic neighbors selection (c) performs a random walk on the corners, while our proposed continuous nearest neighbors selection (d) relaxes the weights of the database items into the interior of the simplex and computes a deterministic path. Depending on the temperature parameter this path can interpolate between a more uniform weighting (red) and the original KNN selection (blue).</p><p>of the KNN rule, which allows differentiating the output w. r. t. pairwise distances in the input space, such as between image patches. The strength of the novel relaxation can be controlled by a temperature parameter whose gradients can be obtained as well. Second, from our relaxation we develop a novel neural network layer, called neural nearest neighbors block (N 3 block), which enables end-to-end trainable non-local processing based on the principle of self-similarity. Third, we demonstrate that the accuracy of image denoising and single image super-resolution (SISR) can be improved significantly by augmenting strong local CNN architectures with our novel N 3 block, also outperforming strong non-local baselines. Moreover, for the task of correspondence classification, we obtain significant improvements by simply augmenting a recent neural network baseline with our N 3 block, showing its effectiveness on set-valued data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>An important branch of image restoration techniques is comprised of non-local methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b54">55]</ref>, driven by the concept of self-similarity. They rely on similar structures being more likely to encounter within an image than across images <ref type="bibr" target="#b53">[54]</ref>. For denoising, the non-local means algorithm <ref type="bibr" target="#b5">[6]</ref> averages noisy pixels weighted by the similarity of local neighborhoods. The popular BM3D method <ref type="bibr" target="#b8">[9]</ref> goes beyond simple averaging by transforming the 3D stack of matching patches and employing a shrinkage function on the resulting coefficients. Such transform domain filtering is also used in other image restoration tasks, e. g. single image super-resolution <ref type="bibr" target="#b7">[8]</ref>. More recently, Yang and Sun <ref type="bibr" target="#b46">[47]</ref> propose to learn the domain transform and activation functions. Lefkimmiatis <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref> goes further by chaining multiple stages of trained non-local modules. All of these methods, however, keep the standard KNN matching in fixed feature spaces. In contrast, we propose to relax the non-differentiable KNN selection rule in order to obtain a fully end-to-end trainable non-local network.</p><p>Recently, non-local neural networks have been proposed for higher-level vision tasks such as object detection or pose estimation <ref type="bibr" target="#b41">[42]</ref> and, with a recurrent architecture, for low-level vision tasks <ref type="bibr" target="#b25">[26]</ref>. While also learning a feature space for distance calculation, their aggregation is restricted to a single weighted average of features, a strategy also known as (soft) attention. Our differentiable nearest neighbors selection generalizes this; our method can recover a single weighted average by setting k=1. As such, our novel N 3 block can potentially benefit other methods employing weighted averages, e. g. for visual question answering <ref type="bibr" target="#b44">[45]</ref> and more general learning tasks like modeling memory access <ref type="bibr" target="#b13">[14]</ref> or sequence modeling <ref type="bibr" target="#b39">[40]</ref>. Weighted averages have also been used for building differentiable relaxations of the k-nearest neighbors classifier <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b40">41]</ref>. Note that the crucial difference to our work is that we propose a differentiable relaxation of the KNN selection rule where the output is a set of neighbors, instead of a single aggregation of the labels of the neighbors. Without using relaxations, Weinberger and Saul <ref type="bibr" target="#b43">[44]</ref> learn the distance metric underlying KNN classification using a max-margin approach. They rely on predefined target neighbors for each query item, a restriction that we avoid.</p><p>Image denoising. Besides improving the visual quality of noisy images, the importance of image denoising also stems from the fact that image noise severely degrades the accuracy of downstream computer vision tasks, e. g. detection <ref type="bibr" target="#b9">[10]</ref>. Moreover, denoising has been recognized as a core module for density estimation <ref type="bibr" target="#b1">[2]</ref> and serves as a sub-routine for more general image restoration tasks in a flurry of recent work, e. g. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b51">52]</ref>. Besides classical approaches <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b36">37]</ref>, CNN-based methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b50">51]</ref> have shown strong denoising accuracy over the past years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Differentiable k-Nearest Neighbors</head><p>We first detail our continuous and differentiable relaxation of the k-nearest neighbors (KNN) selection rule. Here, we will make few assumptions on the data to derive a very general result that can be used with many kinds of data, including text or sets. In the next section, we will then define a non-local neural network layer based on our relaxation. Let us start by precisely defining KNN selection. Assume that we are given a query item q, a database of candidate items (x i ) i?I with indices I = {1, . . . , M } for matching, and a distance metric d(?, ?) between pairs of items. Assuming that q is not in the database, d yields a ranking of the database items according to the distance to the query. Let ? q : I ? I be a permutation that sorts the database items by increasing distance to q:</p><formula xml:id="formula_0">? q (i) &lt; ? q (i ) ? d(q, x i ) ? d(q, x i ), ?i, i ? I.<label>(1)</label></formula><p>The KNN of q are then given by the set of the first k items w. r. t. the permutation ? q</p><formula xml:id="formula_1">KNN(q) ? {x i | ? q (i) ? k}.<label>(2)</label></formula><p>The KNN selection rule is deterministic but not differentiable. This effectively hinders to derive gradients w. r. t. the distances d(?, ?). We will alleviate this problem in two steps. First, we interpret the deterministic KNN rule as a limit of a parametric family of discrete stochastic sampling processes. Second, we derive continuous relaxations for the discrete variables, thus allowing to backpropagate gradients through the neighborhood selection while still preserving the KNN rule as a limit case.</p><p>KNN rule as limit distribution. We proceed by interpreting the KNN selection rule as the limit distribution of k categorical distributions that are constructed as follows. As in Neighborhood Component Analysis <ref type="bibr" target="#b12">[13]</ref>, let Cat(w 1 | ? 1 , t) be a categorical distribution over the indices I of the database items, obtained by deriving logits ? 1 i from the negative distances to the query item d(q, x i ), scaled with a temperature parameter t. The probability of w 1 taking a value i ? I is given by:</p><formula xml:id="formula_2">P w 1 = i | ? 1 , t ? Cat(? 1 , t) = exp ? 1 i/t i ?I exp ? 1 i /t<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">? 1 i ? ?d(q, x i ).<label>(4)</label></formula><p>Here, we treat w 1 as a one-hot coded vector and denote with w 1 = i that the i-th entry is set to one while the others are zero. In the limit of t ? 0, Cat(w 1 | ? 1 , t) will converge to a deterministic ("Dirac delta") distribution centered at the index of the database item with smallest distance to q. Thus we can regard sampling from Cat(w 1 | ? 1 , t) as a stochastic relaxation of 1-NN <ref type="bibr" target="#b12">[13]</ref>. We now generalize this to arbitrary k by proposing an iterative scheme to construct further conditional distributions Cat(w j+1 | ? j+1 , t). Specifically, we compute ? j+1 by setting the w j -th entry of ? j to negative infinity, thus ensuring that this index cannot be sampled again:</p><formula xml:id="formula_4">? j+1 i ? ? j i + log(1 ? w j i ) = ? j i , if w j = i ??, if w j = i.<label>(5)</label></formula><p>The updated logits are used to define a new categorical distribution for the next index to be sampled:</p><formula xml:id="formula_5">P w j+1 = i | ? j+1 , t ? Cat(? j+1 , t) = exp ? j+1 i /t i ?I exp ? j+1 i /t .<label>(6)</label></formula><p>From the index vectors w j , we can define the stochastic nearest neighbors {X 1 , . . . , X k } of q using</p><formula xml:id="formula_6">X j ? i?I w j i x i .<label>(7)</label></formula><p>When the temperature parameter t approaches zero, the distribution over the {X 1 , . . . , X k } will be a deterministic distribution centered on the k nearest neighbors of q. Using these stochastic nearest neighbors directly within a deep neural network is problematic, since gradient estimators for expectations over discrete variables are known to suffer from high variance <ref type="bibr" target="#b32">[33]</ref>. Hence, in the following we consider a continuous deterministic relaxation of the discrete random variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Continuous deterministic relaxation.</head><p>Our basic idea is to replace the one-hot coded weight vectors with their continuous expectations. This will yield a deterministic and continuous relaxation of the stochastic nearest neighbors that still converges to the hard KNN selection rule in the limit case of t ? 0. Concretely, the expectationw 1 of the first index vector w 1 is given b?</p><formula xml:id="formula_7">w 1 i ? E w 1 i | ? 1 , t = P w 1 = i | ? 1 , t .<label>(8)</label></formula><p>We can now relax the update of the logits (Eq. 5) by using the expected weight vector instead of the discrete sample as?</p><formula xml:id="formula_8">j+1 i ?? j i + log(1 ?w j i ) with? 1 i ? ? 1 i .<label>(9)</label></formula><p>The updated logits are then used in turn to calculate the expectation over the next index vector:</p><formula xml:id="formula_9">w j+1 i ? E w j+1 i |? j+1 , t = P w j+1 = i |? j+1 , t .<label>(10)</label></formula><p>Analogously to Eq. <ref type="formula" target="#formula_6">(7)</ref>, we define continuous nearest neighbors {X 1 , . . . ,X k } of q using thew j as</p><formula xml:id="formula_10">X j ? i?Iw j i x i .<label>(11)</label></formula><p>In the limit of t ? 0, the expectationw 1 of the first sampled index vector will approach a one-hot encoding of the index of the closest neighbor. As a consequence, the logit update in Eq. (9) will also converge to the hard update from Eq. (5). By induction it follows that the otherw j will converge to a one-hot encoding of the closest indices of the j-th nearest neighbor. In summary, this means that our continuous deterministic relaxation still contains the hard KNN selection rule as a limit case.</p><p>Discussion. <ref type="figure">Figure 1</ref> shows the relation between the deterministic KNN selection, stochastic nearest neighbors, and our proposed continuous nearest neighbors. Note that the continuous nearest neighbors are differentiable w. r. t. the pairwise distances as well as the temperature t. This allows making the temperature a trainable parameter. Moreover, the temperature can depend on the query item q, thus allowing to learn for which query items it is beneficial to average more uniformly across the database items, i. e. by choosing a high temperature, and for which query items the continuous nearest neighbors should be close to the discrete nearest neighbors, i. e. by choosing a low temperature. Both cases have their justification. A more uniform averaging effectively allows to aggregate information from many neighbors at once. On the other hand, the more distinct neighbors obtained with a low temperature allow to first non-linearly process the information before eventually fusing it.</p><p>From Eq. (11) it becomes apparent that the continuous nearest neighbors effectively take k weighted averages over the database items. Thus, prior work such as non-local networks <ref type="bibr" target="#b41">[42]</ref>, differentiable relaxations of the KNN classifier <ref type="bibr" target="#b40">[41]</ref>, or soft attention-based architectures <ref type="bibr" target="#b13">[14]</ref> can be realized as a special case of our architecture with k = 1. We also experimented with a continuous relaxation of the stochastic nearest neighbors based on approximating the discrete distributions with Concrete distributions <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b29">30]</ref>. This results in a stochastic sampling of weighted averages as opposed to our deterministic nearest neighbors. For the dense prediction tasks considered in our experiments, we found the deterministic variant to give significantly better results, see Sec. 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Neural Nearest Neighbors Block</head><p>In the previous section we made no assumptions about the source of query and database items. Here, we propose a new network block, called neural nearest neighbors block (N 3 block, <ref type="figure">Fig. 2a</ref>), which integrates our continuous and differentiable nearest neighbors selection into feed-forward neural networks based on the concept of self-similarity, i. e. query set and database are derived from the same features (e. g., feature patches of an intermediate layer within a CNN). An N 3 block consists of two important parts. First, an embedding network takes the input and produces a feature embedding as well as temperature parameters. These are used in a second step to compute continuous nearest neighbors feature volumes that are aggregated with the input. We interleave N 3 blocks with existing local processing networks to form neural nearest neighbors networks (N 3 Net) as shown in <ref type="figure">Fig. 2b</ref>. In the following, we take a closer look at the components of an N 3 block and their design choices. Y <ref type="figure">Figure 2</ref>. (a) In a neural nearest neighbors (N 3 ) block (shaded box), an embedding network takes the output Y of a previous layer and calculates a pairwise distance matrix D between elements in Y as well as a temperature parameter (T , red feature layer) for each element. These are used to produce a stack of continuous nearest neighbors volumes N1, . . . , N k (green), which are then concatenated with Y . We build an N 3 Net (b) by interleaving common local processing networks (e. g., DnCNN <ref type="bibr" target="#b50">[51]</ref> or VDSR <ref type="bibr" target="#b19">[20]</ref>) with N 3 blocks.</p><p>Embedding network. A first branch of the embedding network calculates a feature embedding</p><formula xml:id="formula_11">E = f E (Y ).</formula><p>For image data, we use CNNs to parameterize f E ; for set input we use multi-layer perceptrons. The pairwise distance matrix D can now be obtained by</p><formula xml:id="formula_12">D ij = d(E i , E j )</formula><p>, where E i denotes the embedding of the i-th item and d is a differentiable distance function. We found that the Euclidean distance works well for the tasks that we consider. In practice, for each query item, we confine the set of potential neighbors to a subset of all items, e. g. all image patches in a certain local region. This allows our N 3 block to scale linearly in the number of items instead of quadratically.</p><p>Another network branch computes a tensor T = f T (Y ) containing the temperature t for each item. Note that f E and f T can potentially share weights to some degree. We opted for treating them as separate networks as this allows for an easier implementation.</p><p>Continuous nearest neighbors selection. From the distance matrix D and the temperature tensor T , we compute k continuous nearest neighbors feature volumes N 1 , . . . , N k from the input features Y by applying Eqs. <ref type="bibr" target="#b7">(8)</ref> to <ref type="bibr" target="#b10">(11)</ref> to each item. Since Y and each N i have equal dimensionality, we could use any element-wise operation to aggregate the original features Y and the neighbors. However, a reduction at this stage would mean a very early fusion of features. Hence, we instead simply concatenate Y and the N i along the feature dimension, which allows further network layers to learn how to fuse the information effectively in a non-linear way.</p><p>N 3 block for image data. The N 3 block described above is very generic and not limited to a certain input domain. We now describe minor technical modifications when applying the N 3 block to image data. Traditionally, non-local methods in image processing have been applied at the patch-level, i. e. the items to be matched consist of image patches instead of pixels. This has the advantage of using a broader local context for matching and aggregation. We follow this reasoning and first apply a strided im2col operation on E before calculating pairwise distances. The temperature parameter for each patch is obtained by taking the corresponding center pixel in T . Each nearest neighbor volume N i is converted from the patch domain to the image domain by applying a col2im operation, where we average contributions of different patches to the same pixel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We now analyze the properties of our novel N 3 Net and show its benefits over state-of-the-art baselines. We use image denoising as our main test bed as non-local methods have been well studied there. Moreover, we evaluate on single image super-resolution and correspondence classification.</p><p>Gaussian image denoising. We consider the task of denoising a noisy image D, which arises by corrupting a clean image C with additive white Gaussian noise of standard deviation ?:</p><formula xml:id="formula_13">D = C + N with N ? N (0, ? 2 ).<label>(12)</label></formula><p>Our baseline architecture is the DnCNN model of Zhang et al. <ref type="bibr" target="#b50">[51]</ref>, consisting of 16 blocks, each with a sequence of a 3 ? 3 convolutional layer with 64 feature maps, batch normalization <ref type="bibr" target="#b16">[17]</ref>, and a ReLU activation function. In the end, a final 3 ? 3 convolution is applied, the output of which is added back to the input through a global skip connection.</p><p>We use the DnCNN architecture to create our N 3 Net for image denoising. Specifically, we use three DnCNNs with six blocks each, cf. <ref type="figure">Fig. 2b</ref>. The first two blocks output 8 feature maps, which are  <ref type="bibr" target="#b20">[21]</ref> with default parameters ? 1 = 0.9, ? 2 = 0.999 to minimize the squared error. The learning rate is initially set to 10 ?3 and exponentially decreased to 10 ?8 over the course of training. Following the publicly available implementation of DnCNN <ref type="bibr" target="#b50">[51]</ref>, we apply a weight decay with strength 10 ?4 to the weights of the convolution layers and the scaling of batch normalization layers.</p><p>We evaluate our full model on three different datasets: (i) a set of twelve commonly used benchmark images (Set12), (ii) the 68 images subset <ref type="bibr" target="#b36">[37]</ref> of the BSD500 validation set <ref type="bibr" target="#b31">[32]</ref>, and (iii) the Urban100 <ref type="bibr" target="#b15">[16]</ref> dataset, which contains images of urban scenes where repetitive patterns are abundant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Ablation study</head><p>We begin by discerning the effectiveness of the individual components. We compare our full N 3 Net against several baselines: (i,ii) The baseline DnCNN network with depths 17 (default) and 18 (matching the depth of N 3 Net). (iii) A baseline where we replace the N 3 blocks with KNN selection (k = 7) to obtain neighbors for each patch. Distance calculation is done on the noisy input patches.</p><p>(iv) The same baseline as (iii) but where distances are calculated on denoised patches. Here we use the pretrained 17-layer DnCNN as strong denoiser. The task specific hand-chosen distance embedding for this baseline should intuitively yield more sensible nearest neighbors matches than when matching noisy input patches. (v) A baseline where we use Concrete distributions <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b29">30]</ref> to approximately reparameterize the stochastic nearest neighbors sampling. The resulting Concrete block has an additional network for estimating the annealing parameter of the Concrete distribution.  distributions (baseline (v)) performs worse than our continuous nearest neighbors. This is probably due to the Concrete distribution introducing stochasticity into the forward pass, leading to a less stable training. Additional ablations are given in the the supplemental material.</p><p>Next, we compare N 3 Nets with a varying number of selected neighbors. <ref type="table">Table 2</ref> shows the results on Urban100 with ? ? {25, 50}. We can observe that, as expected, more neighbors improve denoising results. However, the effect diminishes after roughly four neighbors and accuracy starts to deteriorate again. As we refrain from selecting optimal hyper-parameters on the test set, we will stick to the architecture with k = 7 for the remaining experiments on image denoising and SISR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Comparison to the state of the art</head><p>We compare our full N 3 Net against state-of-the-art local denoising methods, i. e. the DnCNN baseline <ref type="bibr" target="#b50">[51]</ref>, the very deep and wide (30 layers, 128 feature channels) RED30 model <ref type="bibr" target="#b30">[31]</ref>, and the recent FFDNet <ref type="bibr" target="#b52">[53]</ref>. Moreover, we compare against competing non-local denoisers. These include the classical BM3D <ref type="bibr" target="#b8">[9]</ref>, which uses a hand-crafted denoising pipeline, and the state-of-the-art trainable non-local models NLNet <ref type="bibr" target="#b22">[23]</ref> and UNLNet <ref type="bibr" target="#b23">[24]</ref>, both learning to process non-locally aggregated patches. We also compare against NN3D <ref type="bibr" target="#b6">[7]</ref>, which applies a non-local step on top of a pretrained network. For fair comparison, we apply a single denoising step for NN3D using our 17-layer baseline DnCNN. As a crucial difference to our proposed N 3 Net, all of the compared non-local methods use KNN selection on a fixed feature space, thus not being able to learn an embedding for matching. <ref type="table" target="#tab_2">Table 3</ref> shows the results for three different noise levels. We make three important observations: First, our N 3 Net significantly outperforms the baseline DnCNN network on all tested noise levels and all datasets. Especially for higher noise levels the margin is dramatic, e. g. +0.54dB (? = 50) or +0.79dB (? = 70) on Urban100. Even the deeper and wider RED30 model does not reach the accuracy of N 3 Net. Second, our method is the only trainable non-local model that is able to outperform the local models DnCNN, RED30, and FFDNet. The competing models NLNet and UNLNet do not reach the accuracy of DnCNN even on Urban100, whereas our N 3 Net even fares better than the strongest local denoiser FFDNet. Third, the post-hoc non-local step applied by NN3D is very effective on Urban100 where self-similarity can intuitively shine. However, on Set12 the gains are noticeably smaller whilst on BDS68 the non-local step can even result in degraded accuracy, e. g. NN3D achieves ?0.04dB compared to DnCNN while N 3 Net achieves +0.16dB for ? = 50. This highlights the importance of integrating non-local processing into an end-to-end trainable pipeline. <ref type="figure" target="#fig_1">Figure 3</ref> shows denoising results for an image from the Urban100 dataset. BM3D and UNLNet can exploit the recurrence of image structures to produce good results albeit introducing artifacts in the windows. DnCNN and FFDNet yield even more artifacts due to the limited receptive field and NN3D, as a post-processing method, cannot recover from the errors of DnCNN. In contrast, our N 3 Net produces a significantly cleaner image where most of the facade structure is correctly restored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Real image denoising</head><p>To further demonstrate the merits of our approach, we applied the same N 3 Net architecture as before to the task of denoising real-world images with realistic noise. To this end, we evaluate on the recent Darmstadt Noise Dataset <ref type="bibr" target="#b33">[34]</ref>, consisting of 50 noisy images shot with four different cameras at varying ISO levels. Realistic noise can be well explained by a Poisson-Gaussian distribution which, in turn, can be well approximated by a Gaussian distribution where the variance depends on the image intensity via a linear noise level function <ref type="bibr" target="#b11">[12]</ref>. We use this heteroscedastic Gaussian distribution to generate synthetic noise for training. Specifically, we use a broad range of noise level functions covering those that occur on the test images. For training, we use the 400 images of the BSDS training and test splits, 800 images of the DIV2K training set <ref type="bibr" target="#b0">[1]</ref>, and a training split of 3793 images from the Waterloo database <ref type="bibr" target="#b28">[29]</ref>. Before adding synthetic noise, we transform the clean RGB images Y RGB to Y RAW such that they more closely resemble images with raw intensity values:</p><formula xml:id="formula_14">Y RAW = f c ? Y (Y RGB ) fe , with f c ? U(0.25, 1) and f e ? U(1.25, 10),<label>(13)</label></formula><p>where Y (?) computes luminance values from RGB, the exponentiation with f e aims at undoing compression of high image intensities, and scaling with f c aims at undoing the effect of white balancing. Further training details can be found in the supplemental material. We train both the DnCNN baseline as well as our N 3 Net with the same training protocol and evaluate them on the benchmark website. Results are shown in <ref type="table" target="#tab_3">Table 4</ref>. N 3 Net sets a new state of the art for denoising raw images, outperforming DnCNN and BM3D by a significant margin. Moreover, the PSNR values, when evaluated on developed sRGB images, surpass those of the currently top performing methods in sRGB denoising, TWSC <ref type="bibr" target="#b45">[46]</ref> and CBDNet <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Single image super-resolution</head><p>We now show that we can also augment recent strong CNN models for SISR with our N 3 block. We particularly consider the common task <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b19">20]</ref> of upsampling a low-resolution image that was obtained from a high-resolution image by bicubic downscaling. We chose the VDSR model <ref type="bibr" target="#b19">[20]</ref> as our baseline architecture, since it is conceptually very close to the DnCNN model for image denoising. The only notable difference is that it has 20 layers instead of 17. We derive our N 3 Net for SISR from the VDSR model by stacking three VDSR networks with depth 7 and inserting two N 3 blocks (k = 7) after the first two VDSR networks, cf. <ref type="figure">Fig. 2b</ref>. Following <ref type="bibr" target="#b19">[20]</ref>, the input to our network is the  bicubicly upsampled low-resolution image and we train a single model for super-resolving images with factors 2, 3, and 4. Further details on the architecture and training protocol can be found in the supplemental material. Note that we refrain from building our N 3 Net for SISR from more recent networks, e. g. MemNet <ref type="bibr" target="#b37">[38]</ref>, MDSR <ref type="bibr" target="#b24">[25]</ref>, or WDnCNN <ref type="bibr" target="#b2">[3]</ref>, since they are too costly to train.</p><p>We compare our N 3 Net against VDSR and MemNet as well as two non-local models: SelfEx <ref type="bibr" target="#b15">[16]</ref> and the recent WSD-SR <ref type="bibr" target="#b7">[8]</ref>. <ref type="table" target="#tab_4">Table 5</ref> shows results on Set5 <ref type="bibr" target="#b3">[4]</ref>. Again, we can observe a consistent gain of N 3 Net compared to the strong baseline VDSR for all super-resolution factors, e. g. +0.15dB for ?4 super-resolution. More importantly, the other non-local methods perform inferior compared to our N 3 Net (e. g. +0.36dB compared to WSD-SR for ?2 super-resolution), showing that learning the matching feature space is superior to relying on a hand-defined feature space. Further quantitative and visual results demonstrating the same benefits of N 3 Net can be found in the supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Correspondence classification</head><p>As a third application, we look at classifying correspondences between image features from two images as either correct or incorrect. Again, we augment a baseline network with our non-local block. Specifically, we build upon the context normalization network <ref type="bibr" target="#b48">[49]</ref>, which we call CNNet in the following. The input to this network is a set of pairs of image coordinates of putative correspondences and the output is a probability for each of the correspondences to be correct. CNNet consists of 12 blocks, each comprised of a local fully connected layer with 128 feature channels that processes each point individually, and a context normalization and batch normalization layer that pool information across the whole point set. We augment CNNet by introducing a N 3 block after the sixth original block. As opposed to the N 3 block for the previous two tasks, where neighbors are searched only in the vicinity of a query patch, here we search for nearest neighbors among all correspondences. We want to emphasize that this is a pure set reasoning task. Image features are used only to determine putative correspondences while the network itself is agnostic of any image content.</p><p>For training we use the publicly available code of <ref type="bibr" target="#b48">[49]</ref>. We consider two settings: First, we train on the training set of the outdoor sequence St. Peter and evaluate on the test set of St. Peter and another outdoor sequence called Reichstag to test generalization. Second, we train and test on the respective sets of the indoor sequence Brown. <ref type="table" target="#tab_5">Table 6</ref> shows the resulting mean average precision (MAP) values at different error thresholds (for details on this metric, see <ref type="bibr" target="#b48">[49]</ref>). We compare our N 3 Net to the original CNNet and a baseline that just uses all putative correspondences for pose estimation. As can be seen, by simply inserting our N 3 block we achieve a consistent and significant gain in all considered settings, increasing MAP scores by 10% to 30%. This suggests that our N 3 block can enhance local processing networks in a wide range of applications and data domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Non-local methods have been well studied, e. g., in image restoration. Existing approaches, however, apply KNN selection on a hand-defined feature space, which may be suboptimal for the task at hand. To overcome this limitation, we introduced the first continuous relaxation of the KNN selection rule that maintains differentiability w. r. t. the pairwise distances used for neighbor selection. We integrated continuous nearest neighbors selection into a novel network block, called N 3 block, which can be used as a general building block in neural networks. We exemplified its benefit in the context of image denoising, SISR, and correspondence classification, where we outperform state-of-the-art CNN-based methods and non-local approaches. We expect the N 3 block to also benefit end-to-end trainable architectures for other input domains, such as text or other sequence-valued data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Architectures and Training Details</head><p>A detailed summary of the used architectures can be found in the following tables: 2</p><p>? <ref type="table" target="#tab_7">Tables 7 and 8</ref> show the architecture of embedding network and the temperature network within an N 3 block, respectively. ? <ref type="table" target="#tab_9">Table 9</ref> shows the architecture of a DnCNN block used as local processing network in our N 3 Net for denoising. The architecture of the whole N 3 Net can be found in <ref type="table" target="#tab_0">Table 10</ref>. ? <ref type="table" target="#tab_0">Table 11</ref> shows the architecture of a VDSR block used as local processing network in our N 3 Net for single image super-resolution. The architecture of the whole N 3 Net can be found in <ref type="table" target="#tab_0">Table 12</ref>.</p><p>Analogously to image denoising, the N 3 blocks for super-resolution extract 10 ? 10 patches with a stride of 5 and patches are matched to other patches in a 80 ? 80 region.</p><p>Training details for super-resolution. We follow the training protocol of <ref type="bibr" target="#b19">[20]</ref>. Our training set consists of 291 images: The 200 images of the BSD500 training set and 91 images from <ref type="bibr" target="#b47">[48]</ref>. In each of the 80 training epochs, we randomly crop 3833 patches of size 80 ? 80 from each image and apply data augmentation by flipping and using a rotation ? {0 ? , 90 ? , 180 ? , 270 ? }. Our batchsize is 32. As in <ref type="bibr" target="#b19">[20]</ref>, we use the SGD optimizer with momentum of 0.9 and a weight decay of 10 ?4 . The initial learning rate is set to 0.1 and decayed by a factor of 10 every 20 epochs. Like <ref type="bibr" target="#b19">[20]</ref>, we apply gradient clipping to stabilize training.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Further Analyses on Gaussian Denoising</head><p>Extended ablation study. We first conduct further ablation studies on the task of removing additive white Gaussian noise, extending the results of Sec. 5.1 of the main paper. We basically want to discern the effect of adding a single KNN or N 3 block, respectively, and the effect of training the baseline    model on bigger patch sizes. <ref type="table" target="#tab_0">Table 13</ref> shows these results. We make the following observations: First, for d = 6 our N 3 block outperforms simple stacking of DnCNN networks as well as using a KNN block by a significant margin, for both ? = 25 and 70. Second, for d = 17 stacking two full networks performs poorly as training becomes more difficult with the increased depth. Interestingly, N 3 can remedy some of the ill effects. Third, increasing the receptive field for the baseline DnCNN using more layers does not always help (cf. 2 ? DnCNN, d = 17 in <ref type="table" target="#tab_0">Table 13</ref>). This is in contrast to our approach that allows increasing the receptive field without having many layers or parameters. Fourth, training on larger patch sizes does not benefit the baseline DnCNN model, cf. baseline (i) in <ref type="table" target="#tab_0">Table 1</ref> of the main paper.</p><p>Runtime overhead. For denoising, the runtime of our full model with N 3 increases by 3.5? compared to the baseline DnCNN model (d = 17). For KNN this overhead is 2.5?.</p><p>Learned strength of the continuous relaxation. To look into what the network has learned, we consider the maximum weightw j = max iw j i (cf. Eq. 11) for the j th neighbors volume. For the first N 3 block of our full network for denoising (? = 25), we havew 1 ? 0.21 andw 7 ? 0.11 on average, while for the 2 nd blockw 1 ? 0.04 andw 7 ? 0.03. Thus the network learned that at a lower level a "harder" N 3 selection is beneficial while for higher level features the network tends to learn a more uniform weighting. A completely uniform weighting would correspond tow = 1 /224 ? 0.004. <ref type="table" target="#tab_0">Table 14</ref> shows results for single image super-resolution on two further datasets: The full BSD500 validation set consisting of 100 images (BSD100), and Urban100. We observe a consistent gain of N 3 Net compared to the very strong baseline VDSR on both datasets and all super-resolution factors. Moreover, the performance of the other non-local methods falls short compared to both the baseline and our N 3 Net. <ref type="figure" target="#fig_2">Figure 4</ref> shows visual results for our method and VDSR. We can see that N 3 Net produces sharper details than VDSR, leading to perceptually more pleasing images despite the PSNR values being relatively close.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Super-Resolution Results</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Stochastic NN (Eqs. 4 to 7)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Denoising results (cropped for better display) and PSNR values on an image from Urban100 (? = 50).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Super-resolution results (cropped for better display) and PSNR values on four images from Urban100 with a super-resolution factor of 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>PSNR and SSIM<ref type="bibr" target="#b42">[43]</ref> on Urban100 for different architectures on gray-scale image denoising (?=25). block that computes 7 neighbor volumes. The concatenated output again has a depth of 64 feature channels, matching the depth of the other intermediate blocks. The N 3 blocks extract 10 ? 10 patches with a stride of 5. Patches are matched to other patches in a 80 ? 80 region, yielding a total of 224 candidate patches for matching each query patch. More details on the architecture can be found in the supplemental material.</figDesc><table><row><cell></cell><cell>Model</cell><cell>Matching on</cell><cell cols="2">PSNR [dB] SSIM</cell></row><row><cell>(i)</cell><cell>1 ? DnCNN (d=17)</cell><cell>-</cell><cell>29.97</cell><cell>0.879</cell></row><row><cell>(ii)</cell><cell>1 ? DnCNN (d=18)</cell><cell>-</cell><cell>29.92</cell><cell>0.885</cell></row><row><cell>(iii)</cell><cell>3 ? DnCNN (d=6), KNN block (k=7)</cell><cell>noisy input</cell><cell>30.07</cell><cell>0.891</cell></row><row><cell>(iv)</cell><cell>3 ? DnCNN (d=6), KNN block (k=7)</cell><cell>DnCNN output (d=17)</cell><cell>30.08</cell><cell>0.890</cell></row><row><cell>(v)</cell><cell>3 ? DnCNN (d=6), Concrete block (k=7)</cell><cell>learned embedding</cell><cell>29.97</cell><cell>0.889</cell></row><row><cell cols="2">(ours light) 2 ? DnCNN (d=6), N 3 block (k=7)</cell><cell>learned embedding</cell><cell>29.99</cell><cell>0.888</cell></row><row><cell>(ours full)</cell><cell>3 ? DnCNN (d=6), N 3 block (k=7)</cell><cell>learned embedding</cell><cell>30.19</cell><cell>0.892</cell></row><row><cell cols="2">fed into a subsequent N 3</cell><cell></cell><cell></cell><cell></cell></row></table><note>Training details. We follow the protocol of Zhang et al. [51] and use the 400 images in the train and test split of the BSD500 dataset for training. Note that these images are strictly separate from the validation images. For each epoch, we randomly crop 512 patches of size 80 ? 80 from each training image. We use horizontal and vertical flipping as well as random rotations ? {0 ? , 90 ? , 180 ? , 270 ? } as further data augmentation. In total, we train for 50 epochs with a batch size of 32, using the Adam optimizer</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 shows</head><label>1</label><figDesc>Third, learning a patch embedding with our novel N 3 block shows a clear improvement over all baselines. We, moreover, evaluate a smaller version of N 3 Net with only two DnCNN blocks of depth 6 (ours light). This model already outperforms the baseline DnCNN with depth 17 despite having fewer layers (12 vs. 17) and fewer parameters (427k vs. 556k). Fourth, reparameterization with Concrete</figDesc><table><row><cell></cell><cell>k = 1</cell><cell>k = 2</cell><cell>k = 3</cell><cell>k = 4</cell><cell>k = 5</cell><cell>k = 6</cell><cell>k = 7</cell></row><row><cell>? = 25</cell><cell>30.17</cell><cell>30.21</cell><cell>30.15</cell><cell>30.27</cell><cell>30.27</cell><cell>30.22</cell><cell>30.19</cell></row><row><cell>? = 50</cell><cell>26.76</cell><cell>26.81</cell><cell>26.78</cell><cell>26.86</cell><cell>26.83</cell><cell>26.80</cell><cell>26.82</cell></row></table><note>the results on the Urban100 test set (? = 25) from which we can infer four insights: First, the KNN baselines (iii) and (iv) improve upon the plain DnCNN model, showing that allowing the network to access non-local information is beneficial. Second, matching denoised patches (baseline (iv)) does not improve significantly over matching noisy patches (baseline (iii)).Table 2. PSNR (dB) on Urban100 for gray-scale image denoising for varying k.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>PSNR (dB) for gray-scale image denoising on different datasets. NLNet does not provide a model for ? = 70 and the publicly available UNLNet model was not trained for ? = 70. RED30 does not provide a model for ? = 25 and BSD68 is part of the RED30 training set. Hence, we omit these results.</figDesc><table><row><cell>Dataset</cell><cell>?</cell><cell cols="8">DnCNN BM3D NLNet UNLNet NN3D RED30 FFDNet N 3 Net (ours)</cell></row><row><cell></cell><cell>25</cell><cell>30.44</cell><cell>29.96</cell><cell>30.31</cell><cell>30.27</cell><cell>30.45</cell><cell>-</cell><cell>30.43</cell><cell>30.55</cell></row><row><cell>Set12</cell><cell>50</cell><cell>27.19</cell><cell>26.70</cell><cell>27.04</cell><cell>27.07</cell><cell>27.24</cell><cell>27.24</cell><cell>27.31</cell><cell>27.43</cell></row><row><cell></cell><cell>70</cell><cell>25.56</cell><cell>25.21</cell><cell>-</cell><cell>-</cell><cell>25.61</cell><cell>25.71</cell><cell>25.81</cell><cell>25.90</cell></row><row><cell></cell><cell>25</cell><cell>29.23</cell><cell>28.56</cell><cell>29.03</cell><cell>28.99</cell><cell>29.19</cell><cell>-</cell><cell>29.19</cell><cell>29.30</cell></row><row><cell>BSD68</cell><cell>50</cell><cell>26.23</cell><cell>25.63</cell><cell>26.07</cell><cell>26.07</cell><cell>26.19</cell><cell>-</cell><cell>26.29</cell><cell>26.39</cell></row><row><cell></cell><cell>70</cell><cell>24.85</cell><cell>24.46</cell><cell>-</cell><cell>-</cell><cell>24.89</cell><cell>-</cell><cell>25.04</cell><cell>25.14</cell></row><row><cell></cell><cell>25</cell><cell>29.97</cell><cell>29.71</cell><cell>29.92</cell><cell>29.80</cell><cell>30.09</cell><cell>-</cell><cell>29.92</cell><cell>30.19</cell></row><row><cell>Urban100</cell><cell>50</cell><cell>26.28</cell><cell>25.95</cell><cell>26.15</cell><cell>26.14</cell><cell>26.47</cell><cell>26.32</cell><cell>26.52</cell><cell>26.82</cell></row><row><cell></cell><cell>70</cell><cell>24.36</cell><cell>24.27</cell><cell>-</cell><cell>-</cell><cell>24.53</cell><cell>24.63</cell><cell>24.87</cell><cell>25.15</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Results on the Darmstadt Noise Dataset<ref type="bibr" target="#b33">[34]</ref>.</figDesc><table><row><cell></cell><cell cols="2">Raw</cell><cell cols="2">sRGB</cell></row><row><cell></cell><cell>PSNR</cell><cell>SSIM</cell><cell>PSNR</cell><cell>SSIM</cell></row><row><cell>BM3D</cell><cell cols="4">46.64 0.9724 37.78 0.9308</cell></row><row><cell>DnCNN</cell><cell cols="4">47.37 0.9760 38.08 0.9357</cell></row><row><cell>N 3 Net</cell><cell cols="4">47.56 0.9767 38.32 0.9384</cell></row><row><cell>TWSC</cell><cell>-</cell><cell>-</cell><cell cols="2">37.94 0.9403</cell></row><row><cell>CBDNet</cell><cell>-</cell><cell>-</cell><cell cols="2">38.06 0.9421</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>PSNR (dB) for single image super-resolution on Set5.</figDesc><table><row><cell></cell><cell>Bicubic</cell><cell>SelfEx</cell><cell>WSD-SR</cell><cell>MemNet</cell><cell>MDSR</cell><cell>VDSR</cell><cell>N 3 Net</cell></row><row><cell>?2</cell><cell>33.68</cell><cell>36.49</cell><cell>37.21</cell><cell>37.78</cell><cell>38.11</cell><cell>37.53</cell><cell>37.57</cell></row><row><cell>?3</cell><cell>30.41</cell><cell>32.58</cell><cell>33.50</cell><cell>34.09</cell><cell>34.66</cell><cell>33.66</cell><cell>33.84</cell></row><row><cell>?4</cell><cell>28.43</cell><cell>30.31</cell><cell>31.39</cell><cell>31.74</cell><cell>32.50</cell><cell>31.35</cell><cell>31.50</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>MAP scores for correspondence estimation for different error thresholds and combinations of training and testing set. Higher MAP scores are better.</figDesc><table><row><cell></cell><cell cols="3">St. Peter / St. Peter</cell><cell cols="3">St. Peter / Reichstag</cell><cell cols="3">Brown / Brown</cell></row><row><cell>Threshold</cell><cell cols="3">No Net CNNet N 3 Net</cell><cell cols="3">No Net CNNet N 3 Net</cell><cell cols="3">No Net CNNet N 3 Net</cell></row><row><cell>5 ?</cell><cell>0.014</cell><cell>0.271</cell><cell>0.316</cell><cell>0.0</cell><cell>0.173</cell><cell>0.231</cell><cell>0.054</cell><cell>0.236</cell><cell>0.293</cell></row><row><cell>10 ?</cell><cell>0.030</cell><cell>0.379</cell><cell>0.431</cell><cell>0.038</cell><cell>0.337</cell><cell>0.442</cell><cell>0.110</cell><cell>0.333</cell><cell>0.391</cell></row><row><cell>20 ?</cell><cell>0.071</cell><cell>0.522</cell><cell>0.574</cell><cell>0.111</cell><cell>0.500</cell><cell>0.601</cell><cell>0.232</cell><cell>0.463</cell><cell>0.510</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Acknowledgments. The research leading to these results has received funding from the European Research Council under the European Union's Seventh Framework Programme (FP/2007-2013)/ERC Grant agreement No. 307942. We would like to thank reviewers for their fruitful comments.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 .</head><label>7</label><figDesc>Architecture of the embedding block.</figDesc><table><row><cell>Type</cell><cell>Ker., Str., Pad.</cell><cell>Feat.</cell></row><row><cell>Input</cell><cell></cell><cell>8</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv</cell><cell>3 ? 3, 1, 1</cell><cell>8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 .</head><label>8</label><figDesc>Architecture of the block for predicting the temperature parameter.</figDesc><table><row><cell>Type</cell><cell>Ker., Str., Pad.</cell><cell>Feat.</cell></row><row><cell>Input</cell><cell></cell><cell>8</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv</cell><cell>3 ? 3, 1, 1</cell><cell>1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 .</head><label>9</label><figDesc>Architecture of the 6 layer DnCNN blocks used for N 3 Net for image denoising.</figDesc><table><row><cell>Type</cell><cell>Ker., Str., Pad.</cell><cell>Feat.</cell></row><row><cell>Input</cell><cell></cell><cell>1 if first block / 64 else</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv</cell><cell>3 ? 3, 1, 1</cell><cell>1 if last block / 8 else</cell></row><row><cell>Skip</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 .</head><label>10</label><figDesc>Architecture of N 3 Net for image denoising.</figDesc><table><row><cell>Type</cell><cell>k</cell><cell>Feat.</cell></row><row><cell>Input</cell><cell></cell><cell>1</cell></row><row><cell>DnCNN block</cell><cell></cell><cell>8</cell></row><row><cell>N 3 block</cell><cell>7</cell><cell>64</cell></row><row><cell>DnCNN block</cell><cell></cell><cell>8</cell></row><row><cell>N 3 block</cell><cell>7</cell><cell>64</cell></row><row><cell>DnCNN block</cell><cell></cell><cell>1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 .</head><label>11</label><figDesc>Architecture of the 7 layer VDSR blocks used for N 3 Net for super resolution.</figDesc><table><row><cell>Type</cell><cell>Ker., Str., Pad.</cell><cell>Feat.</cell></row><row><cell>Input</cell><cell></cell><cell>1 if first block / 64 else</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv/BN/ReLU</cell><cell>3 ? 3, 1, 1</cell><cell>64</cell></row><row><cell>Conv</cell><cell>3 ? 3, 1, 1</cell><cell>1 if last block / 8 else</cell></row><row><cell>Skip</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 .Table 13 .</head><label>1213</label><figDesc>Architecture of N 3 Net for super resolution. PSNR (dB) on Urban100 for different architectures on gray-scale image denoising. Models are trained on 80 ? 80 patches.</figDesc><table><row><cell>Type</cell><cell>k</cell><cell>Feat.</cell></row><row><cell>Input</cell><cell></cell><cell>1</cell></row><row><cell>VDSR block</cell><cell></cell><cell>8</cell></row><row><cell>N 3 block</cell><cell>7</cell><cell>64</cell></row><row><cell>VDSR block</cell><cell></cell><cell>8</cell></row><row><cell>N 3 block</cell><cell>7</cell><cell>64</cell></row><row><cell>VDSR block</cell><cell></cell><cell>1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 14 .</head><label>14</label><figDesc>PSNR (dB) values for single image super-resolution on Urban100 and BSD100. WSD-SR does not provide results for BSD100.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>Bicubic</cell><cell>SelfEx</cell><cell>WSD-SR</cell><cell>MemNet</cell><cell>MDSR</cell><cell>VDSR</cell><cell>N 3 Net</cell></row><row><cell></cell><cell>?2</cell><cell>26.88</cell><cell>29.54</cell><cell>30.29</cell><cell>31.31</cell><cell>32.84</cell><cell>30.76</cell><cell>30.80</cell></row><row><cell>Urban100</cell><cell>?3</cell><cell>24.46</cell><cell>26.44</cell><cell>26.95</cell><cell>27.56</cell><cell>28.79</cell><cell>27.14</cell><cell>27.19</cell></row><row><cell></cell><cell>?4</cell><cell>23.14</cell><cell>24.79</cell><cell>25.16</cell><cell>25.50</cell><cell>26.67</cell><cell>25.18</cell><cell>25.23</cell></row><row><cell></cell><cell>?2</cell><cell>29.56</cell><cell>31.18</cell><cell>-</cell><cell>32.05</cell><cell>32.29</cell><cell>31.90</cell><cell>31.98</cell></row><row><cell>BSD100</cell><cell>?3</cell><cell>27.21</cell><cell>28.29</cell><cell>-</cell><cell>28.95</cell><cell>29.25</cell><cell>28.82</cell><cell>28.91</cell></row><row><cell></cell><cell>?4</cell><cell>25.96</cell><cell>26.84</cell><cell>-</cell><cell>27.38</cell><cell>27.72</cell><cell>27.29</cell><cell>27.34</cell></row><row><cell></cell><cell>Clean</cell><cell></cell><cell>Bicubic (19.75 dB)</cell><cell></cell><cell>VDSR (20.86 dB)</cell><cell></cell><cell>NN3D (20.99 dB)</cell><cell></cell></row><row><cell></cell><cell>Clean</cell><cell></cell><cell>Bicubic (22.53 dB)</cell><cell></cell><cell>VDSR (23.44 dB)</cell><cell></cell><cell>NN3D (23.47 dB)</cell><cell></cell></row><row><cell></cell><cell>Clean</cell><cell></cell><cell>Bicubic (27.65 dB)</cell><cell></cell><cell>VDSR (29.01 dB)</cell><cell></cell><cell>NN3D (29.10 dB)</cell><cell></cell></row><row><cell></cell><cell>Clean</cell><cell></cell><cell>Bicubic (20.03 dB)</cell><cell></cell><cell>VDSR (21.23 dB)</cell><cell></cell><cell>NN3D (21.43 dB)</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Code and pretrained models are available at https://github.com/visinf/n3net/.Preprint. Work in progress.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">"Ker.", "Str.", "Pad.", and "Feat." refer to the kernel size, stride, padding and number of feature channels, respectively.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">NTIRE 2017 challenge on single image super-resolution: Dataset and study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="126" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">What regularized auto-encoders learn from the data-generating distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3563" to="3593" />
			<date type="published" when="2014-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Beyond deep residual learning for image restoration: Persistent homology-guided manifold simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woong</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><forename type="middle">Jun</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong Chul</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="145" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Low-complexity single-image super-resolution based on nonnegative neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Bevilacqua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aline</forename><surname>Roumy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Guillemot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie Line Alberi-Morel</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="135" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep mean-shift priors for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Siavash Arjomand Bigdeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Zwicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meiguang</forename><surname>Favaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS*2017</title>
		<imprint>
			<biblScope unit="page" from="763" to="772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartomeu</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Michel</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nonlocality-reinforced convolutional neural networks for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Crist?v?o</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><forename type="middle">O</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Sig. Proc. Letters</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1216" to="1220" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Single image superresolution based on Wiener filter in similarity domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Crist?v?o</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakesh</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><forename type="middle">O</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Image Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1376" to="1389" />
			<date type="published" when="2018-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Image denoising with block-matching and 3D filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Electronic Imaging &apos;06, Proc. SPIE</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6064</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Dirty pixels: Optimizing image classification architectures for raw sensor data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Diamond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Sitzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Wetzstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Heide</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06487</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs.CV</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Denoising by soft-thresholding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Info. Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="627" />
			<date type="published" when="1995-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Practical Poissonian-Gaussian noise modeling and fitting for single-image raw-data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mejdi</forename><surname>Trimeche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1737" to="1754" />
			<date type="published" when="2008-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neighbourhood components analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS*2005</title>
		<imprint>
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<title level="m">Neural Turing machines</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>cs.NE</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifei</forename><surname>Shi Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.04686[cs.CV]</idno>
		<title level="m">Toward convolutional blind denoising of real photographs</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Single image super-resolution from transformed self-exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narendra</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5197" to="5206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Natural image denoising with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viren</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Sebastian</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS*2008</title>
		<imprint>
			<biblScope unit="page" from="769" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Categorical reparameterization with Gumbel-softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Accurate image super-resolution using very deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1646" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">P</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Non-local color image denoising with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Lefkimmiatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5882" to="5891" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Universal denoising networks: A novel CNN-based network architecture for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Lefkimmiatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3204" to="3213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Enhanced deep residual networks for single image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bee</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyun</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungjun</forename><surname>Nah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Non-local recurrent network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bihan</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Needle-match: Reliable patch matching under high uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Lotan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="439" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Waterloo Exploration Database: New challenges for image quality assessment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kede</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengfang</forename><surname>Duanmu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingbo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-02" />
			<publisher>IEEE T. Image Process</publisher>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1004" to="1016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The Concrete distribution: A continuous relaxation of discrete random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Image restoration using very deep convolutional encoderdecoder networks with symmetric skip connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiao</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Bin</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS*2016</title>
		<imprint>
			<biblScope unit="page" from="2802" to="2810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doron</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Variational inference for Monte Carlo objectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2188" to="2196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Benchmarking denoising algorithms with real photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Pl?tz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1586" to="1595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning convolutional nonlinear features for k nearest neighbor image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiqiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junge</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4358" to="4363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The little engine that could: Regularization by denoising (RED)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1804" to="1844" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fields of experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="229" />
			<date type="published" when="2009-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">MemNet: A persistent memory network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4539" to="4547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">NTIRE 2017 challenge on single image super-resolution: Methods and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="114" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS*2017</title>
		<imprint>
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS*2016</title>
		<imprint>
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multi-scale structural similarity for image quality assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">C</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Asilomar Conference on Signals, Systems and Computers</title>
		<meeting><address><addrLine>Pacific Grove, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-11" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1398" to="1402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="207" to="244" />
			<date type="published" when="2009-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Ask, attend and answer: Exploring question-guided spatial attention for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="451" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A trilateral weighted sparse coding scheme for real-world image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="21" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">BM3D-Net: A convolutional neural network for transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Signal Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="59" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Image super-resolution via sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2861" to="2873" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning to find good correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Kwang Moo Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><surname>Trulls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2666" to="2674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Beyond a Gaussian denoiser: Residual learning of deep CNN for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Image Process</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning deep CNN denoiser prior for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2808" to="2817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">FFDNet: Toward a fast and flexible solution for CNN based image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Image Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4608" to="4622" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Internal statistics of a single natural image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Zontak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="977" to="984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Separating signal from noise using patch recurrence across scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Zontak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inbar</forename><surname>Mosseri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1195" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
