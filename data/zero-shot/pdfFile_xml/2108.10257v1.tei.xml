<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SwinIR: Image Restoration Using Swin Transformer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyun</forename><surname>Liang</surname></persName>
							<email>jinliang@vision.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiezhang</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
							<email>guosun@vision.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
							<email>kai.zhang@vision.ee.ethz.ch</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
							<email>vangool@vision.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
							<email>timofter@vision.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyunliang</forename><forename type="middle">/</forename><surname>Com/</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swinir</surname></persName>
						</author>
						<title level="a" type="main">SwinIR: Image Restoration Using Swin Transformer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Image restoration is a long-standing low-level vision problem that aims to restore high-quality images from lowquality images (e.g., downscaled, noisy and compressed images). While state-of-the-art image restoration methods are based on convolutional neural networks, few attempts have been made with Transformers which show impressive performance on high-level vision tasks. In this paper, we propose a strong baseline model SwinIR for image restoration based on the Swin Transformer. SwinIR consists of three parts: shallow feature extraction, deep feature extraction and high-quality image reconstruction. In particular, the deep feature extraction module is composed of several residual Swin Transformer blocks (RSTB), each of which has several Swin Transformer layers together with a residual connection. We conduct experiments on three representative tasks: image super-resolution (including classical, lightweight and real-world image super-resolution), image denoising (including grayscale and color image denoising) and JPEG compression artifact reduction. Experimental results demonstrate that SwinIR outperforms state-of-the-art methods on different tasks by up to 0.14?0.45dB, while the total number of parameters can be reduced by up to 67%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image restoration, such as image super-resolution (SR), image denoising and JPEG compression artifact reduction, aims to reconstruct the high-quality clean image from its low-quality degraded counterpart. Since several revolutionary work <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b89">90,</ref><ref type="bibr" target="#b90">91]</ref>, convolutional neural networks (CNN) have become the primary workhorse for image restoration <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b91">92,</ref><ref type="bibr" target="#b94">95,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b92">93,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b88">89,</ref><ref type="bibr" target="#b87">88]</ref>.</p><p>Most CNN-based methods focus on elaborate architecture designs such as residual learning <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b50">51]</ref> and dense connections <ref type="bibr" target="#b96">[97,</ref><ref type="bibr" target="#b80">81]</ref>. Although the performance is significantly improved compared with traditional model-based * Corresponding author.  <ref type="figure">Figure 1</ref>: PSNR results v.s the total number of parameters of different methods for image SR (?4) on Set5 <ref type="bibr" target="#b2">[3]</ref>.</p><p>methods <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b27">28]</ref>, they generally suffer from two basic problems that stem from the basic convolution layer. First, the interactions between images and convolution kernels are content-independent. Using the same convolution kernel to restore different image regions may not be the best choice. Second, under the principle of local processing, convolution is not effective for long-range dependency modelling.</p><p>As an alternative to CNN, Transformer <ref type="bibr" target="#b75">[76]</ref> designs a self-attention mechanism to capture global interactions between contexts and has shown promising performance in several vision problems <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b55">56]</ref>. However, vision Transformers for image restoration <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b4">5]</ref> usually divide the input image into patches with fixed size (e.g., 48?48) and process each patch independently. Such a strategy inevitably gives rise to two drawbacks. First, border pixels cannot utilize neighbouring pixels that are out of the patch for image restoration. Second, the restored image may introduce border artifacts around each patch. While this problem can be alleviated by patch overlapping, it would introduce extra computational burden.</p><p>Recently, Swin Transformer <ref type="bibr" target="#b55">[56]</ref> has shown great promise as it integrates the advantages of both CNN and Transformer. On the one hand, it has the advantage of CNN to process image with large size due to the local attention mechanism. On the other hand, it has the advantage of Transformer to model long-range dependency with the shifted window scheme.</p><p>In this paper, we propose an image restoration model, namely SwinIR, based on Swin Transformer. More specifically, SwinIR consists of three modules: shallow feature extraction, deep feature extraction and high-quality image reconstruction modules. Shallow feature extraction module uses a convolution layer to extract shallow feature, which is directly transmitted to the reconstruction module so as to preserve low-frequency information. Deep feature extraction module is mainly composed of residual Swin Transformer blocks (RSTB), each of which utilizes several Swin Transformer layers for local attention and cross-window interaction. In addition, we add a convolution layer at the end of the block for feature enhancement and use a residual connection to provide a shortcut for feature aggregation. Finally, both shallow and deep features are fused in the reconstruction module for high-quality image reconstruction.</p><p>Compared with prevalent CNN-based image restoration models, Transformer-based SwinIR has several benefits: <ref type="bibr" target="#b0">(1)</ref> content-based interactions between image content and attention weights, which can be interpreted as spatially varying convolution <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b74">75]</ref>. (2) long-range dependency modelling are enabled by the shifted window mechanism.</p><p>(3) better performance with less parameters. For example, as shown in <ref type="figure">Fig. 1</ref>, SwinIR achieves better PSNR with less parameters compared with existing image SR methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Image Restoration</head><p>Compared to traditional image restoration methods <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b31">32]</ref> which are generally model-based, learningbased methods, especially CNN-based methods, have become more popular due to their impressive performance. They often learn mappings between low-quality and highquality images from large-scale paired datasets. Since pioneering work SRCNN <ref type="bibr" target="#b17">[18]</ref> (for image SR), DnCNN <ref type="bibr" target="#b89">[90]</ref> (for image denoising) and ARCNN <ref type="bibr" target="#b16">[17]</ref> (for JPEG compression artifact reduction), a flurry of CNN-based models have been proposed to improve model representation ability by using more elaborate neural network architecture designs, such as residual block <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b87">88]</ref>, dense block <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b96">97,</ref><ref type="bibr" target="#b97">98]</ref> and others <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b92">93,</ref><ref type="bibr" target="#b77">78,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b91">92,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b95">96,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b24">25]</ref>. Some of them have exploited the attention mechanism inside the CNN framework, such as channel attention <ref type="bibr" target="#b94">[95,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b62">63]</ref>, non-local attention <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b60">61]</ref> and adaptive patch aggregation [100].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Vision Transformer</head><p>Recently, natural language processing model Transformer <ref type="bibr" target="#b75">[76]</ref> has gained much popularity in the computer vision community. When used in vision problems such as image classification <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b83">84,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b74">75]</ref>, ob-ject detection <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b55">56]</ref>, segmentation <ref type="bibr" target="#b83">[84,</ref><ref type="bibr" target="#b98">99,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b3">4]</ref> and crowd counting <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b68">69]</ref>, it learns to attend to important image regions by exploring the global interactions between different regions. Due to its impressive performance, Transformer has also been introduced for image restoration <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b81">82]</ref>. Chen et al. <ref type="bibr" target="#b8">[9]</ref> proposed a backbone model IPT for various restoration problems based on the standard Transformer. However, IPT relies on large number of parameters (over 115.5M parameters), large-scale datasets (over 1.1M images) and multi-task learning for good performance. Cao et al. <ref type="bibr" target="#b4">[5]</ref> proposed VSR-Transformer that uses the self-attention mechanism for better feature fusion in video SR, but image features are still extracted from CNN. Besides, both IPT and VSR-Transformer are patch-wise attention, which may be improper for image restoration. In addition, a concurrent work <ref type="bibr" target="#b81">[82]</ref> proposed a U-shaped architecture based on the Swin Transformer <ref type="bibr" target="#b55">[56]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Network Architecture</head><p>As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, SwinIR consists of three modules: shallow feature extraction, deep feature extraction and highquality (HQ) image reconstruction modules. We employ the same feature extraction modules for all restoration tasks, but use different reconstruction modules for different tasks. Shallow and deep feature extraction. Given a lowquality (LQ) input I LQ ? R H?W ?Cin (H, W and C in are the image height, width and input channel number, respectively), we use a 3 ? 3 convolutional layer H SF (?) to extract shallow feature F 0 ? R H?W ?C as</p><formula xml:id="formula_0">F 0 = H SF (I LQ ),<label>(1)</label></formula><p>where C is the feature channel number. The convolution layer is good at early visual processing, leading to more stable optimization and better results <ref type="bibr" target="#b85">[86]</ref>. It also provides a simple way to map the input image space to a higher dimensional feature space. Then, we extract deep feature F DF ? R H?W ?C from F 0 as</p><formula xml:id="formula_1">F DF = H DF (F 0 ),<label>(2)</label></formula><p>where H DF (?) is the deep feature extraction module and it contains K residual Swin Transformer blocks (RSTB) and a 3 ? 3 convolutional layer. More specifically, intermediate features F 1 , F 2 , . . . , F K and the output deep feature F DF are extracted block by block as</p><formula xml:id="formula_2">F i = H RSTBi (F i?1 ), i = 1, 2, . . . , K, F DF = H CONV (F K ),<label>(3)</label></formula><p>where H RSTBi (?) denotes the i-th RSTB and H CONV is the last convolutional layer. Using a convolutional layer at the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shallow Feature Extraction</head><p>Deep Feature Extraction  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HQ Image Reconstruction</head><formula xml:id="formula_3">I RHQ = H REC (F 0 + F DF ),<label>(4)</label></formula><p>where H REC (?) is the function of the reconstruction module. Shallow feature mainly contain low-frequencies, while deep feature focus on recovering lost high-frequencies.</p><p>With a long skip connection, SwinIR can transmit the lowfrequency information directly to the reconstruction module, which can help deep feature extraction module focus on high-frequency information and stabilize training. For the implementation of reconstruction module, we use the sub-pixel convolution layer <ref type="bibr" target="#b67">[68]</ref> to upsample the feature. For tasks that do not need upsampling, such as image denoising and JPEG compression artifact reduction, a single convolution layer is used for reconstruction. Besides, we use residual learning to reconstruct the residual between the LQ and the HQ image instead of the HQ image. This is formulated as</p><formula xml:id="formula_4">I RHQ = H SwinIR (I LQ ) + I LQ ,<label>(5)</label></formula><p>where H SwinIR (?) denotes the function of SwinIR. Loss function. For image SR, we optimize the parameters of SwinIR by minimizing the L 1 pixel loss</p><formula xml:id="formula_5">L = I RHQ ? I HQ 1 ,<label>(6)</label></formula><p>where I RHQ is obtained by taking I LQ as the input of SwinIR, and I HQ is the corresponding ground-truth HQ image. For classical and lightweight image SR, we only use the naive L 1 pixel loss as same as previous work to show the effectiveness of the proposed network. For real-world image SR, we use a combination of pixel loss, GAN loss and perceptual loss <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b88">89,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b80">81]</ref> to improve visual quality. For image denoising and JPEG compression artifact reduction, we use the Charbonnier loss [8]</p><formula xml:id="formula_6">L = I RHQ ? I HQ 2 + 2 ,<label>(7)</label></formula><p>where is a constant that is empirically set to 10 ?3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Residual Swin Transformer Block</head><p>As shown in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>, the residual Swin Transformer block (RSTB) is a residual block with Swin Transformer layers (STL) and convolutional layers. Given the input feature F i,0 of the i-th RSTB, we first extract intermediate fea-</p><formula xml:id="formula_7">tures F i,1 , F i,2 , . . . , F i,L by L Swin Transformer layers as F i,j = H STLi,j (F i,j?1 ), j = 1, 2, . . . , L,<label>(8)</label></formula><p>where H STLi,j (?) is the j-th Swin Transformer layer in the i-th RSTB. Then, we add a convolutional layer before the residual connection. The output of RSTB is formulated as</p><formula xml:id="formula_8">F i,out = H CONVi (F i,L ) + F i,0 ,<label>(9)</label></formula><p>where H CONVi (?) is the convolutional layer in the i-th RSTB. This design has two benefits. First, although Transformer can be viewed as a specific instantiation of spatially varying convolution <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b74">75]</ref>, covolutional layers with spatially invariant filters can enhance the translational equivariance of SwinIR. Second, the residual connection provides a identity-based connection from different blocks to the reconstruction module, allowing the aggregation of different levels of features.</p><p>Swin Transformer layer. Swin Transformer layer (STL) <ref type="bibr" target="#b55">[56]</ref> is based on the standard multi-head selfattention of the original Transformer layer <ref type="bibr" target="#b75">[76]</ref>. The main differences lie in local attention and the shifted window mechanism. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>(b), given an input of size H ? W ? C, Swin Transformer first reshapes the input to a HW M 2 ? M 2 ? C feature by partitioning the input into non-overlapping M ? M local windows, where HW M 2 is the total number of windows. Then, it computes the standard self-attention separately for each window (i.e., local attention). For a local window feature X ? R M 2 ?C , the query, key and value matrices Q, K and V are computed as</p><formula xml:id="formula_9">Q = XP Q , K = XP K , V = XP V ,<label>(10)</label></formula><p>where P Q , P K and P V are projection matrices that are shared across different windows. Generally, we have Q, K, V ? R M 2 ?d . The attention matrix is thus computed by the self-attention mechanism in a local window as</p><formula xml:id="formula_10">Attention(Q, K, V ) = SoftMax(QK T / ? d + B)V,<label>(11)</label></formula><p>where B is the learnable relative positional encoding. In practice, following <ref type="bibr" target="#b75">[76]</ref>, we perform the attention function for h times in parallel and concatenate the results for multihead self-attention (MSA). Next, a multi-layer perceptron (MLP) that has two fullyconnected layers with GELU non-linearity between them is used for further feature transformations. The LayerNorm (LN) layer is added before both MSA and MLP, and the residual connection is employed for both modules. The whole process is formulated as</p><formula xml:id="formula_11">X = MSA(LN(X)) + X, X = MLP(LN(X)) + X.<label>(12)</label></formula><p>However, when the partition is fixed for different layers, there is no connection across local windows. Therefore, regular and shifted window partitioning are used alternately to enable cross-window connections <ref type="bibr" target="#b55">[56]</ref>, where shifted window partitioning means shifting the feature by ( M 2 , M 2 ) pixels before partitioning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>For classical image SR, real-world image SR, image denoising and JPEG compression artifact reduction, the RSTB number, STL number, window size, channel number and attention head number are generally set to 6, 6, 8, 180 and 6, respectively. One exception is that the window size is set to 7 for JPEG compression artifact reduction, as we observe significant performance drop when using 8, possibly because JPEG encoding uses 8 ? 8 image partions. For lightweight image SR, we decrease RSTB number and channel number to 4 and 60, respectively. Following <ref type="bibr" target="#b94">[95,</ref><ref type="bibr" target="#b62">63]</ref>, when self-ensemble strategy <ref type="bibr" target="#b50">[51]</ref> is used in testing, we mark the model with a symbol "+", e.g., SwinIR+. Due to page limit, training and evaluation details are provided in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Study and Discussion</head><p>For ablation study, we train SwinIR on DIV2K <ref type="bibr" target="#b0">[1]</ref> for classical image SR (?2) and test it on Manga109 <ref type="bibr" target="#b59">[60]</ref>. Impact of channel number, RSTB number and STL number. We show the effects of channel number, RSTB number and STL number in a RSTB on model performance in Figs. 3(a), 3(b) and 3(c), respectively. It is observed that the PSNR is positively correlated with these three hyperparameters. For channel number, although the performance keeps increasing, the total number of parameters grows quadratically. To balance the performance and model size, we choose 180 as the channel number in rest experiments. As for RSTB number and layer number, the performance gain becomes saturated gradually. We choose 6 for both of them to obtain a relatively small model. Impact of patch size and training image number; model convergence comparison. We compare the proposed SwinIR with a representative CNN-based model RCAN to compare the difference of Transformer-based and CNNbased models. From <ref type="figure" target="#fig_2">Fig. 3(d)</ref>, one can see that SwinIR performs better than RCAN on different patch sizes, and the PSNR gain becomes larger when the patch size is larger. <ref type="figure" target="#fig_2">Fig. 3(e)</ref> shows the impact of the number of training images. Extra images from Flickr2K are used in training when the percentage is larger than 100% (800 images). There are two observations. First, as expected, the performance of SwinIR rises with the training image number. Second, different from the observation in IPT that Transformer-based models are heavily relied on large amount of training data, SwinIR achieves better results than CNN-based models using the same training data, even when the dataset is small (i.e., 25%, 200 images). We also plot the PSNR during training for both SwinIR and RCAN in <ref type="figure" target="#fig_2">Fig. 3(f)</ref>. It is clear that SwinIR converges faster and better than RCAN, which is contradictory to previous observations that Transformerbased models often suffer from slow model convergence. Impact of residual connection and convolution layer in RSTB. <ref type="table" target="#tab_2">Table 1</ref> shows four residual connection variants in RSTB: no residual connection, using 1 ? 1 convolution layer, using 3 ? 3 convolution layer and using three 3 ? 3 convolution layers (channel number of the intermediate layer is set to one fourth of network channel number). From the table, we can have following observations. First, the residual connection in RSTB is important as it improves the PSNR by 0.16dB. Second, using 1 ? 1 convolution brings little improvement maybe because it cannot <ref type="bibr" target="#b59">60</ref>     <ref type="bibr" target="#b56">[57]</ref>. In addition to PSNR and SSIM, we also report the total numbers of parameters and multiply-accumulate operations (evaluated on a 1280 ? 720 HQ image) to compare the model size and computational complexity of different models. As shown in <ref type="table" target="#tab_4">Table 3</ref>, SwinIR outperforms competitive methods by a PSNR margin of up to 0.53dB on different benchmark datasets, with similar total numbers of parameters and multiplyaccumulate operations. This indicates that the SwinIR architecture is highly efficient for image restoration.</p><p>Real-world image SR. The ultimate goal of image SR is for real-world applications. Recently, Zhang et al. <ref type="bibr" target="#b88">[89]</ref> proposed a practical degradation model BSRGAN for realworld image SR and achieved surprising results in real scenarios 1 . To test the performance of SwinIR for realworld SR, we re-train SwinIR by using the same degradation model as BSRGAN for low-quality image synthesis. Since there is no ground-truth high-quality images, we only provide visual comparison with representative bicubic model ESRGAN <ref type="bibr" target="#b80">[81]</ref> and state-of-the-art realworld image SR models RealSR <ref type="bibr" target="#b36">[37]</ref>, BSRGAN <ref type="bibr" target="#b88">[89]</ref> and Real-ESRGAN <ref type="bibr" target="#b79">[80]</ref>. As shown in <ref type="figure" target="#fig_3">Fig. 5</ref>, SwinIR produces visually pleasing images with clear and sharp edges, whereas other compared methods may suffer from unsatisfactory artifacts. In addition, to exploit the full potential of SwinIR for real applications, we further propose a  <ref type="figure">Figure 4</ref>: Visual comparison of bicubic image SR (?4) methods. Compared images are derived from <ref type="bibr" target="#b8">[9]</ref>. Best viewed by zooming.   large model and train it on much larger datasets. Experiments show that it can deal with more complex corruptions and achieves even better performance on real-world images than the current model. Due to page limit, the details are given in our project page https://github.com/ JingyunLiang/SwinIR. <ref type="table" target="#tab_5">Table 4</ref> shows the comparison of SwinIR with stateof-the-art JPEG compression artifact reduction methods: ARCNN <ref type="bibr" target="#b16">[17]</ref>, DnCNN-3 <ref type="bibr" target="#b89">[90]</ref>, QGAC <ref type="bibr" target="#b19">[20]</ref>, RNAN <ref type="bibr" target="#b95">[96]</ref>, RDN <ref type="bibr" target="#b97">[98]</ref> and DRUNet <ref type="bibr" target="#b87">[88]</ref>. All of compared methods are CNN-based models. Following <ref type="bibr" target="#b97">[98,</ref><ref type="bibr" target="#b87">88]</ref>, we test different methods on two benchmark datasets (Classic5 <ref type="bibr" target="#b21">[22]</ref> and LIVE1 <ref type="bibr" target="#b66">[67]</ref>) for JPEG quality factors 10, 20, 30 and 40. As we can see, the proposed SwinIR has average PSNR gains of at least 0.11dB and 0.07dB on two testing datasets for different quality factors. Besides, compared with the previous best model DRUNet, SwinIR only has 11.5M parameters, while DRUNet is a large model that has 32.7M parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results on JPEG Compression Artifact Reduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Results on Image Denoising</head><p>We show grayscale and color image denoising results in <ref type="table" target="#tab_7">Table 5</ref> and <ref type="table" target="#tab_8">Table 6</ref>, respectively.</p><p>Com-pared methods include traditional models BM3D <ref type="bibr" target="#b13">[14]</ref> and WNNM <ref type="bibr" target="#b28">[29]</ref>, CNN-based models DnCNN <ref type="bibr" target="#b89">[90]</ref>, IR-CNN <ref type="bibr" target="#b90">[91]</ref>, FFDNet <ref type="bibr" target="#b91">[92]</ref>, N3Net <ref type="bibr" target="#b64">[65]</ref>, NLRN <ref type="bibr" target="#b51">[52]</ref>, FOC-Net <ref type="bibr" target="#b37">[38]</ref>, RNAN <ref type="bibr" target="#b95">[96]</ref>, MWCNN <ref type="bibr" target="#b53">[54]</ref> and DRUNet <ref type="bibr" target="#b87">[88]</ref>. Following <ref type="bibr" target="#b89">[90,</ref><ref type="bibr" target="#b87">88]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose a Swin Transformer-based image restoration model SwinIR. The model is composed of three parts: shallow feature extraction, deep feature extrac-  Noisy BM3D <ref type="bibr" target="#b13">[14]</ref> DnCNN <ref type="bibr" target="#b89">[90]</ref> FFDNet <ref type="bibr" target="#b91">[92]</ref> DRUNet <ref type="bibr" target="#b87">[88]</ref> SwinIR (ours) <ref type="figure">Figure 6</ref>: Visual comparison of grayscale image denoising (noise level 50) methods on image "Monarch" from Set12 <ref type="bibr" target="#b89">[90]</ref>. Compared images are derived from <ref type="bibr" target="#b87">[88]</ref>.</p><p>Noisy DnCNN <ref type="bibr" target="#b89">[90]</ref> FFDNet <ref type="bibr" target="#b91">[92]</ref> IPT <ref type="bibr" target="#b8">[9]</ref> DRUNet <ref type="bibr" target="#b87">[88]</ref> SwinIR (ours) <ref type="figure">Figure 7</ref>: Visual comparison of color image denoising (noise level 50) methods on image "163085" from CBSD68 <ref type="bibr" target="#b58">[59]</ref>. Compared images are derived from <ref type="bibr" target="#b87">[88]</ref>.</p><p>tion and HR reconstruction modules. In particular, we use a stack of residual Swin Transformer blocks (RSTB) for deep feature extraction, and each RSTB is composed of Swin Transformer layers, convolution layer and a residual connection. Extensive experiments show that SwinIR achieves state-of-the-art performance on three representative image restoration tasks and six different settings: classic image SR, lightweight image SR, real-world image SR, grayscale image denoising, color image denoising and JPEG com-pression artifact reduction, which demonstrates the effectiveness and generalizability of the proposed SwinIR. In the future, we will extend the model to other restoration tasks such as image deblurring and deraining.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>STLFigure 2 :</head><label>2</label><figDesc>The architecture of the proposed SwinIR for image restoration. end of feature extraction can bring the inductive bias of the convolution operation into the Transformer-based network, and lay a better foundation for the later aggregation of shallow and deep features. Image reconstruction. Taking image SR as an example, we reconstruct the high-quality image I RHQ by aggregating shallow and deep features as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Ablation study on different settings of SwinIR. Results are tested on Manga109<ref type="bibr" target="#b59">[60]</ref> for image SR (?2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Visual comparison of real-world image SR (?4) methods on real-world images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Ablation study on RSTB design.</figDesc><table><row><cell>Design</cell><cell>No residual</cell><cell>1 ? 1 conv</cell><cell>3 ? 3 conv</cell><cell>Three 3 ? 3 conv</cell></row><row><cell>PSNR</cell><cell>39.42</cell><cell>39.45</cell><cell>39.58</cell><cell>39.56</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>com-</cell></row><row><cell cols="5">parisons between SwinIR (middle size) and state-of-the-art</cell></row><row><cell cols="5">methods: DBPN [31], RCAN [95], RRDB [81], SAN [15],</cell></row><row><cell cols="5">IGNN [100], HAN [63], NLSA [61] and IPT [9]. As one</cell></row><row><cell cols="5">can see, when trained on DIV2K, SwinIR achieves best</cell></row><row><cell cols="5">performance on almost all five benchmark datasets for all</cell></row><row><cell cols="5">scale factors. The maximum PSNR gain reaches 0.26dB</cell></row><row><cell cols="5">on Manga109 for scale factor 4. Note that RCAN and</cell></row><row><cell cols="5">HAN introduce channel and spatial attention, IGNN pro-</cell></row><row><cell cols="5">poses adaptive patch feature aggregation, and NLSA is</cell></row><row><cell cols="5">based on the non-local attention mechanism. However, all</cell></row><row><cell cols="5">these CNN-based attention mechanisms perform worse than</cell></row><row><cell cols="5">the proposed Transformer-based SwinIR, which indicates</cell></row><row><cell cols="5">the effectiveness of the proposed model. When we train</cell></row><row><cell cols="5">SwinIR on a larger dataset (DIV2K+Flickr2K), the perfor-</cell></row><row><cell cols="5">mance further increases by a large margin (up to 0.47dB),</cell></row><row><cell cols="5">achieving better accuracy than the same Transformer-based</cell></row><row><cell cols="5">model IPT, even though IPT utilizes ImageNet (more than</cell></row><row><cell cols="5">1.3M images) in training and has huge number of param-</cell></row><row><cell cols="5">eters (115.5M). In contrast, SwinIR has a small number</cell></row><row><cell cols="5">of parameters (11.8M) even compared with state-of-the-art</cell></row><row><cell cols="5">CNN-based models (15.4?44.3M). As for runtime, repre-</cell></row></table><note>extract local neighbouring information as 3 ? 3 convolution does. Third, although using three 3 ? 3 convolution lay- ers can reduce the number of parameters, the performance drops slightly.4.3. Results on Image SR Classical image SR. Table 2 shows the quantitativesentative CNN-based model RCAN, IPT and SwinIR take about 0.2, 4.5s and 1.1s to test on a 1, 024 ? 1, 024 im- age, respectively. Visual comparisons are show in Fig. 4. SwinIR can restore high-frequency details and alleviate the blurring artifacts, resulting in sharp and natural edges. In contrast, most CNN-based methods produces blurry images or even incorrect textures. IPT generates better images com- pared with CNN-based methods, but it suffers from image distortions and border artifact. Lightweight image SR. We also provide comparison of SwinIR (small size) with state-of-the-art lightweight im- age SR methods: CARN [2], FALSR-A [12], IMDN [35], LAPAR-A [44] and LatticeNet</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Quantitative comparison (average PSNR/SSIM) with state-of-the-art methods for classical image SR on benchmark datasets. Best and second best performance are in red and blue colors, respectively. Results on ?8 are provided in supplementary.</figDesc><table><row><cell>Method</cell><cell>Scale</cell><cell>Training Dataset</cell><cell cols="2">Set5 [3] PSNR SSIM</cell><cell cols="2">Set14 [87] PSNR SSIM</cell><cell cols="2">BSD100 [58] PSNR SSIM</cell><cell cols="2">Urban100 [34] PSNR SSIM</cell><cell cols="2">Manga109 [60] PSNR SSIM</cell></row><row><cell>RCAN [95]</cell><cell>?2</cell><cell>DIV2K</cell><cell>38.27</cell><cell>0.9614</cell><cell>34.12</cell><cell>0.9216</cell><cell>32.41</cell><cell>0.9027</cell><cell>33.34</cell><cell>0.9384</cell><cell>39.44</cell><cell>0.9786</cell></row><row><cell>SAN [15]</cell><cell>?2</cell><cell>DIV2K</cell><cell>38.31</cell><cell>0.9620</cell><cell>34.07</cell><cell>0.9213</cell><cell>32.42</cell><cell>0.9028</cell><cell>33.10</cell><cell>0.9370</cell><cell>39.32</cell><cell>0.9792</cell></row><row><cell>IGNN [100]</cell><cell>?2</cell><cell>DIV2K</cell><cell>38.24</cell><cell>0.9613</cell><cell>34.07</cell><cell>0.9217</cell><cell>32.41</cell><cell>0.9025</cell><cell>33.23</cell><cell>0.9383</cell><cell>39.35</cell><cell>0.9786</cell></row><row><cell>HAN [63]</cell><cell>?2</cell><cell>DIV2K</cell><cell>38.27</cell><cell>0.9614</cell><cell>34.16</cell><cell>0.9217</cell><cell>32.41</cell><cell>0.9027</cell><cell>33.35</cell><cell>0.9385</cell><cell>39.46</cell><cell>0.9785</cell></row><row><cell>NLSA [61]</cell><cell>?2</cell><cell>DIV2K</cell><cell>38.34</cell><cell>0.9618</cell><cell>34.08</cell><cell>0.9231</cell><cell>32.43</cell><cell>0.9027</cell><cell>33.42</cell><cell>0.9394</cell><cell>39.59</cell><cell>0.9789</cell></row><row><cell>SwinIR (Ours)</cell><cell>?2</cell><cell>DIV2K</cell><cell>38.35</cell><cell>0.9620</cell><cell>34.14</cell><cell>0.9227</cell><cell>32.44</cell><cell>0.9030</cell><cell>33.40</cell><cell>0.9393</cell><cell>39.60</cell><cell>0.9792</cell></row><row><cell>SwinIR+ (Ours)</cell><cell>?2</cell><cell>DIV2K</cell><cell>38.38</cell><cell>0.9621</cell><cell>34.24</cell><cell>0.9233</cell><cell>32.47</cell><cell>0.9032</cell><cell>33.51</cell><cell>0.9401</cell><cell>39.70</cell><cell>0.9794</cell></row><row><cell>DBPN [31]</cell><cell>?2</cell><cell>DIV2K+Flickr2K</cell><cell>38.09</cell><cell>0.9600</cell><cell>33.85</cell><cell>0.9190</cell><cell>32.27</cell><cell>0.9000</cell><cell>32.55</cell><cell>0.9324</cell><cell>38.89</cell><cell>0.9775</cell></row><row><cell>IPT [9]</cell><cell>?2</cell><cell>ImageNet</cell><cell>38.37</cell><cell>-</cell><cell>34.43</cell><cell>-</cell><cell>32.48</cell><cell>-</cell><cell>33.76</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>SwinIR (Ours)</cell><cell>?2</cell><cell>DIV2K+Flickr2K</cell><cell>38.42</cell><cell>0.9623</cell><cell>34.46</cell><cell>0.9250</cell><cell>32.53</cell><cell>0.9041</cell><cell>33.81</cell><cell>0.9427</cell><cell>39.92</cell><cell>0.9797</cell></row><row><cell>SwinIR+ (Ours)</cell><cell>?2</cell><cell>DIV2K+Flickr2K</cell><cell>38.46</cell><cell>0.9624</cell><cell>34.61</cell><cell>0.9260</cell><cell>32.55</cell><cell>0.9043</cell><cell>33.95</cell><cell>0.9433</cell><cell>40.02</cell><cell>0.9800</cell></row><row><cell>RCAN [95]</cell><cell>?3</cell><cell>DIV2K</cell><cell>34.74</cell><cell>0.9299</cell><cell>30.65</cell><cell>0.8482</cell><cell>29.32</cell><cell>0.8111</cell><cell>29.09</cell><cell>0.8702</cell><cell>34.44</cell><cell>0.9499</cell></row><row><cell>SAN [15]</cell><cell>?3</cell><cell>DIV2K</cell><cell>34.75</cell><cell>0.9300</cell><cell>30.59</cell><cell>0.8476</cell><cell>29.33</cell><cell>0.8112</cell><cell>28.93</cell><cell>0.8671</cell><cell>34.30</cell><cell>0.9494</cell></row><row><cell>IGNN [100]</cell><cell>?3</cell><cell>DIV2K</cell><cell>34.72</cell><cell>0.9298</cell><cell>30.66</cell><cell>0.8484</cell><cell>29.31</cell><cell>0.8105</cell><cell>29.03</cell><cell>0.8696</cell><cell>34.39</cell><cell>0.9496</cell></row><row><cell>HAN [63]</cell><cell>?3</cell><cell>DIV2K</cell><cell>34.75</cell><cell>0.9299</cell><cell>30.67</cell><cell>0.8483</cell><cell>29.32</cell><cell>0.8110</cell><cell>29.10</cell><cell>0.8705</cell><cell>34.48</cell><cell>0.9500</cell></row><row><cell>NLSA [61]</cell><cell>?3</cell><cell>DIV2K</cell><cell>34.85</cell><cell>0.9306</cell><cell>30.70</cell><cell>0.8485</cell><cell>29.34</cell><cell>0.8117</cell><cell>29.25</cell><cell>0.8726</cell><cell>34.57</cell><cell>0.9508</cell></row><row><cell>SwinIR (Ours)</cell><cell>?3</cell><cell>DIV2K</cell><cell>34.89</cell><cell>0.9312</cell><cell>30.77</cell><cell>0.8503</cell><cell>29.37</cell><cell>0.8124</cell><cell>29.29</cell><cell>0.8744</cell><cell>34.74</cell><cell>0.9518</cell></row><row><cell>SwinIR+ (Ours)</cell><cell>?3</cell><cell>DIV2K</cell><cell>34.95</cell><cell>0.9316</cell><cell>30.83</cell><cell>0.8511</cell><cell>29.41</cell><cell>0.8130</cell><cell>29.42</cell><cell>0.8761</cell><cell>34.92</cell><cell>0.9526</cell></row><row><cell>IPT [9]</cell><cell>?3</cell><cell>ImageNet</cell><cell>34.81</cell><cell>-</cell><cell>30.85</cell><cell>-</cell><cell>29.38</cell><cell>-</cell><cell>29.49</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>SwinIR (Ours)</cell><cell>?3</cell><cell>DIV2K+Flickr2K</cell><cell>34.97</cell><cell>0.9318</cell><cell>30.93</cell><cell>0.8534</cell><cell>29.46</cell><cell>0.8145</cell><cell>29.75</cell><cell>0.8826</cell><cell>35.12</cell><cell>0.9537</cell></row><row><cell>SwinIR+ (Ours)</cell><cell>?3</cell><cell>DIV2K+Flickr2K</cell><cell>35.04</cell><cell>0.9322</cell><cell>31.00</cell><cell>0.8542</cell><cell>29.49</cell><cell>0.8150</cell><cell>29.90</cell><cell>0.8841</cell><cell>35.28</cell><cell>0.9543</cell></row><row><cell>RCAN [95]</cell><cell>?4</cell><cell>DIV2K</cell><cell>32.63</cell><cell>0.9002</cell><cell>28.87</cell><cell>0.7889</cell><cell>27.77</cell><cell>0.7436</cell><cell>26.82</cell><cell>0.8087</cell><cell>31.22</cell><cell>0.9173</cell></row><row><cell>SAN [15]</cell><cell>?4</cell><cell>DIV2K</cell><cell>32.64</cell><cell>0.9003</cell><cell>28.92</cell><cell>0.7888</cell><cell>27.78</cell><cell>0.7436</cell><cell>26.79</cell><cell>0.8068</cell><cell>31.18</cell><cell>0.9169</cell></row><row><cell>IGNN [100]</cell><cell>?4</cell><cell>DIV2K</cell><cell>32.57</cell><cell>0.8998</cell><cell>28.85</cell><cell>0.7891</cell><cell>27.77</cell><cell>0.7434</cell><cell>26.84</cell><cell>0.8090</cell><cell>31.28</cell><cell>0.9182</cell></row><row><cell>HAN [63]</cell><cell>?4</cell><cell>DIV2K</cell><cell>32.64</cell><cell>0.9002</cell><cell>28.90</cell><cell>0.7890</cell><cell>27.80</cell><cell>0.7442</cell><cell>26.85</cell><cell>0.8094</cell><cell>31.42</cell><cell>0.9177</cell></row><row><cell>NLSA [61]</cell><cell>?4</cell><cell>DIV2K</cell><cell>32.59</cell><cell>0.9000</cell><cell>28.87</cell><cell>0.7891</cell><cell>27.78</cell><cell>0.7444</cell><cell>26.96</cell><cell>0.8109</cell><cell>31.27</cell><cell>0.9184</cell></row><row><cell>SwinIR (Ours)</cell><cell>?4</cell><cell>DIV2K</cell><cell>32.72</cell><cell>0.9021</cell><cell>28.94</cell><cell>0.7914</cell><cell>27.83</cell><cell>0.7459</cell><cell>27.07</cell><cell>0.8164</cell><cell>31.67</cell><cell>0.9226</cell></row><row><cell>SwinIR+ (Ours)</cell><cell>?4</cell><cell>DIV2K</cell><cell>32.81</cell><cell>0.9029</cell><cell>29.02</cell><cell>0.7928</cell><cell>27.87</cell><cell>0.7466</cell><cell>27.21</cell><cell>0.8187</cell><cell>31.88</cell><cell>0.9423</cell></row><row><cell>DBPN [31]</cell><cell>?4</cell><cell>DIV2K+Flickr2K</cell><cell>32.47</cell><cell>0.8980</cell><cell>28.82</cell><cell>0.7860</cell><cell>27.72</cell><cell>0.7400</cell><cell>26.38</cell><cell>0.7946</cell><cell>30.91</cell><cell>0.9137</cell></row><row><cell>IPT [9]</cell><cell>?4</cell><cell>ImageNet</cell><cell>32.64</cell><cell>-</cell><cell>29.01</cell><cell>-</cell><cell>27.82</cell><cell>-</cell><cell>27.26</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>RRDB [81]</cell><cell>?4</cell><cell>DIV2K+Flickr2K</cell><cell>32.73</cell><cell>0.9011</cell><cell>28.99</cell><cell>0.7917</cell><cell>27.85</cell><cell>0.7455</cell><cell>27.03</cell><cell>0.8153</cell><cell>31.66</cell><cell>0.9196</cell></row><row><cell>SwinIR (Ours)</cell><cell>?4</cell><cell>DIV2K+Flickr2K</cell><cell>32.92</cell><cell>0.9044</cell><cell>29.09</cell><cell>0.7950</cell><cell>27.92</cell><cell>0.7489</cell><cell>27.45</cell><cell>0.8254</cell><cell>32.03</cell><cell>0.9260</cell></row><row><cell>SwinIR+ (Ours)</cell><cell>?4</cell><cell>DIV2K+Flickr2K</cell><cell>32.93</cell><cell>0.9043</cell><cell>29.15</cell><cell>0.7958</cell><cell>27.95</cell><cell>0.7494</cell><cell>27.56</cell><cell>0.8273</cell><cell>32.22</cell><cell>0.9273</cell></row><row><cell></cell><cell></cell><cell></cell><cell>HR</cell><cell></cell><cell>VDSR [40]</cell><cell></cell><cell>EDSR [51]</cell><cell></cell><cell>RDN [97]</cell><cell></cell><cell cols="2">OISR [33]</cell></row><row><cell cols="2">Urban100 (4?):img 012</cell><cell cols="2">SAN [15]</cell><cell></cell><cell>RNAN [96]</cell><cell></cell><cell>IGNN [100]</cell><cell></cell><cell>IPT [9]</cell><cell></cell><cell cols="2">SwinIR (ours)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Quantitative comparison (average PSNR/SSIM) with state-of-the-art methods for lightweight image SR on benchmark datasets. Best and second best performance are in red and blue colors, respectively.</figDesc><table><row><cell>Method</cell><cell>Scale</cell><cell>#Params</cell><cell>#Mult-Adds</cell><cell cols="2">Set5 [3] PSNR SSIM</cell><cell cols="2">Set14 [87] PSNR SSIM</cell><cell cols="2">BSD100 [58] PSNR SSIM</cell><cell cols="2">Urban100 [34] PSNR SSIM</cell><cell cols="2">Manga109 [60] PSNR SSIM</cell></row><row><cell>CARN [2]</cell><cell>?2</cell><cell>1,592K</cell><cell>222.8G</cell><cell>37.76</cell><cell>0.9590</cell><cell>33.52</cell><cell>0.9166</cell><cell>32.09</cell><cell>0.8978</cell><cell>31.92</cell><cell>0.9256</cell><cell>38.36</cell><cell>0.9765</cell></row><row><cell>FALSR-A [12]</cell><cell>?2</cell><cell>1,021K</cell><cell>234.7G</cell><cell>37.82</cell><cell>0.959</cell><cell>33.55</cell><cell>0.9168</cell><cell>32.1</cell><cell>0.8987</cell><cell>31.93</cell><cell>0.9256</cell><cell>-</cell><cell>-</cell></row><row><cell>IMDN [35]</cell><cell>?2</cell><cell>694K</cell><cell>158.8G</cell><cell>38.00</cell><cell>0.9605</cell><cell>33.63</cell><cell>0.9177</cell><cell>32.19</cell><cell>0.8996</cell><cell>32.17</cell><cell>0.9283</cell><cell>38.88</cell><cell>0.9774</cell></row><row><cell>LAPAR-A [44]</cell><cell>?2</cell><cell>548K</cell><cell>171.0G</cell><cell>38.01</cell><cell>0.9605</cell><cell>33.62</cell><cell>0.9183</cell><cell>32.19</cell><cell>0.8999</cell><cell>32.10</cell><cell>0.9283</cell><cell>38.67</cell><cell>0.9772</cell></row><row><cell>LatticeNet [57]</cell><cell>?2</cell><cell>756K</cell><cell>169.5G</cell><cell>38.15</cell><cell>0.9610</cell><cell>33.78</cell><cell>0.9193</cell><cell>32.25</cell><cell>0.9005</cell><cell>32.43</cell><cell>0.9302</cell><cell>-</cell><cell>-</cell></row><row><cell>SwinIR (Ours)</cell><cell>?2</cell><cell>878K</cell><cell>195.6G</cell><cell>38.14</cell><cell>0.9611</cell><cell>33.86</cell><cell>0.9206</cell><cell>32.31</cell><cell>0.9012</cell><cell>32.76</cell><cell>0.9340</cell><cell>39.12</cell><cell>0.9783</cell></row><row><cell>CARN [2]</cell><cell>?3</cell><cell>1,592K</cell><cell>118.8G</cell><cell>34.29</cell><cell>0.9255</cell><cell>30.29</cell><cell>0.8407</cell><cell>29.06</cell><cell>0.8034</cell><cell>28.06</cell><cell>0.8493</cell><cell>33.50</cell><cell>0.9440</cell></row><row><cell>IMDN [35]</cell><cell>?3</cell><cell>703K</cell><cell>71.5G</cell><cell>34.36</cell><cell>0.9270</cell><cell>30.32</cell><cell>0.8417</cell><cell>29.09</cell><cell>0.8046</cell><cell>28.17</cell><cell>0.8519</cell><cell>33.61</cell><cell>0.9445</cell></row><row><cell>LAPAR-A [44]</cell><cell>?3</cell><cell>544K</cell><cell>114.0G</cell><cell>34.36</cell><cell>0.9267</cell><cell>30.34</cell><cell>0.8421</cell><cell>29.11</cell><cell>0.8054</cell><cell>28.15</cell><cell>0.8523</cell><cell>33.51</cell><cell>0.9441</cell></row><row><cell>LatticeNet [57]</cell><cell>?3</cell><cell>765K</cell><cell>76.3G</cell><cell>34.53</cell><cell>0.9281</cell><cell>30.39</cell><cell>0.8424</cell><cell>29.15</cell><cell>0.8059</cell><cell>28.33</cell><cell>0.8538</cell><cell>-</cell><cell>-</cell></row><row><cell>SwinIR (Ours)</cell><cell>?3</cell><cell>886K</cell><cell>87.2G</cell><cell>34.62</cell><cell>0.9289</cell><cell>30.54</cell><cell>0.8463</cell><cell>29.20</cell><cell>0.8082</cell><cell>28.66</cell><cell>0.8624</cell><cell>33.98</cell><cell>0.9478</cell></row><row><cell>CARN [2]</cell><cell>?4</cell><cell>1,592K</cell><cell>90.9G</cell><cell>32.13</cell><cell>0.8937</cell><cell>28.60</cell><cell>0.7806</cell><cell>27.58</cell><cell>0.7349</cell><cell>26.07</cell><cell>0.7837</cell><cell>30.47</cell><cell>0.9084</cell></row><row><cell>IMDN [35]</cell><cell>?4</cell><cell>715K</cell><cell>40.9G</cell><cell>32.21</cell><cell>0.8948</cell><cell>28.58</cell><cell>0.7811</cell><cell>27.56</cell><cell>0.7353</cell><cell>26.04</cell><cell>0.7838</cell><cell>30.45</cell><cell>0.9075</cell></row><row><cell>LAPAR-A [44]</cell><cell>?4</cell><cell>659K</cell><cell>94.0G</cell><cell>32.15</cell><cell>0.8944</cell><cell>28.61</cell><cell>0.7818</cell><cell>27.61</cell><cell>0.7366</cell><cell>26.14</cell><cell>0.7871</cell><cell>30.42</cell><cell>0.9074</cell></row><row><cell>LatticeNet [57]</cell><cell>?4</cell><cell>777K</cell><cell>43.6G</cell><cell>32.30</cell><cell>0.8962</cell><cell>28.68</cell><cell>0.7830</cell><cell>27.62</cell><cell>0.7367</cell><cell>26.25</cell><cell>0.7873</cell><cell>-</cell><cell>-</cell></row><row><cell>SwinIR (Ours)</cell><cell>?4</cell><cell>897K</cell><cell>49.6G</cell><cell>32.44</cell><cell>0.8976</cell><cell>28.77</cell><cell>0.7858</cell><cell>27.69</cell><cell>0.7406</cell><cell>26.47</cell><cell>0.7980</cell><cell>30.92</cell><cell>0.9151</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Quantitative comparison (average PSNR/SSIM/PSNR-B) with state-of-the-art methods for JPEG compression artifact reduction on benchmark datasets. Best and second best performance are in red and blue colors, respectively.</figDesc><table><row><cell>Dataset</cell><cell>q</cell><cell>ARCNN [17]</cell><cell>DnCNN-3 [90]</cell><cell>QGAC [20]</cell><cell>RNAN [96]</cell><cell>RDN [98]</cell><cell>DRUNet [88]</cell><cell>SwinIR (ours)</cell></row><row><cell></cell><cell>10</cell><cell cols="5">29.03/0.7929/28.76 29.40/0.8026/29.13 29.84/0.8370/29.43 29.96/0.8178/29.62 30.00/0.8188/-</cell><cell cols="2">30.16/0.8234/29.81 30.27/0.8249/29.95</cell></row><row><cell>Classic5</cell><cell>20</cell><cell cols="5">31.15/0.8517/30.59 31.63/0.8610/31.19 31.98/0.8850/31.37 32.11/0.8693/31.57 32.15/0.8699/-</cell><cell cols="2">32.39/0.8734/31.80 32.52/0.8748/31.99</cell></row><row><cell>[22]</cell><cell>30</cell><cell cols="5">32.51/0.8806/31.98 32.91/0.8861/32.38 33.22/0.9070/32.42 33.38/0.8924/32.68 33.43/0.8930/-</cell><cell cols="2">33.59/0.8949/32.82 33.73/0.8961/33.03</cell></row><row><cell></cell><cell>40</cell><cell cols="2">33.32/0.8953/32.79 33.77/0.9003/33.20</cell><cell>-</cell><cell>34.27/0.9061/33.4</cell><cell>34.27/0.9061/-</cell><cell cols="2">34.41/0.9075/33.51 34.52/0.9082/33.66</cell></row><row><cell></cell><cell>10</cell><cell cols="5">28.96/0.8076/28.77 29.19/0.8123/28.90 29.53/0.8400/29.15 29.63/0.8239/29.25 29.67/0.8247/-</cell><cell cols="2">29.79/0.8278/29.48 29.86/0.8287/29.50</cell></row><row><cell>LIVE1</cell><cell>20</cell><cell cols="5">31.29/0.8733/30.79 31.59/0.8802/31.07 31.86/0.9010/31.27 32.03/0.8877/31.44 32.07/0.8882/-</cell><cell cols="2">32.17/0.8899/31.69 32.25/0.8909/31.70</cell></row><row><cell>[67]</cell><cell>30</cell><cell cols="5">32.67/0.9043/32.22 32.98/0.9090/32.34 33.23/0.9250/32.50 33.45/0.9149/32.71 33.51/0.9153/-</cell><cell cols="2">33.59/0.9166/32.99 33.69/0.9174/33.01</cell></row><row><cell></cell><cell>40</cell><cell cols="2">33.63/0.9198/33.14 33.96/0.9247/33.28</cell><cell>-</cell><cell cols="2">34.47/0.9299/33.66 34.51/0.9302/-</cell><cell cols="2">34.58/0.9312/33.93 34.67/0.9317/33.88</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>, the compared noise levels include 15, 25 and 50. As one can see, our model achieves better performance than all compared methods. In particular, it surpasses the state-of-the-art model DRUNet by up to 0.3dB on the large Urban100 dataset that has 100 high-resolution testing images. It is worth pointing out that SwinIR only has 12.0M parameters, whereas DRUNet has 32.7M parameters. This indicates that the SwinIR architecture is highly efficient in learning feature representations for restoration. The visual comparison for grayscale and color image denoising of different methods are shown in Figs. 6 and 7. As we can see, our method can remove heavy noise corruption and preserve high-frequency image details, resulting in sharper edges and more natural textures. By contrast, other methods suffer from either over-smoothness or oversharpness, and cannot recover rich textures.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Quantitative comparison (average PSNR) with state-of-the-art methods for grayscale image denoising on benchmark datasets. Best and second best performance are in red and blue colors, respectively.</figDesc><table><row><cell>Dataset</cell><cell>?</cell><cell>BM3D [14]</cell><cell>WNNM [29]</cell><cell>DnCNN [90]</cell><cell>IRCNN [91]</cell><cell>FFDNet [92]</cell><cell>N3Net [65]</cell><cell>NLRN [52]</cell><cell>FOCNet [38]</cell><cell>RNAN [96]</cell><cell>MWCNN [54]</cell><cell>DRUNet [88]</cell><cell>SwinIR (ours)</cell></row><row><cell>Set12 [90]</cell><cell>15 25 50</cell><cell>32.37 29.97 26.72</cell><cell>32.70 30.28 27.05</cell><cell>32.86 30.44 27.18</cell><cell>32.76 30.37 27.12</cell><cell>32.75 30.43 27.32</cell><cell>-30.55 27.43</cell><cell>33.16 30.80 27.64</cell><cell>33.07 30.73 27.68</cell><cell>--27.70</cell><cell>33.15 30.79 27.74</cell><cell>33.25 30.94 27.90</cell><cell>33.36 31.01 27.91</cell></row><row><cell>BSD68 [59]</cell><cell>15 25 50</cell><cell>31.08 28.57 25.60</cell><cell>31.37 28.83 25.87</cell><cell>31.73 29.23 26.23</cell><cell>31.63 29.15 26.19</cell><cell>31.63 29.19 26.29</cell><cell>-29.30 26.39</cell><cell>31.88 29.41 26.47</cell><cell>31.83 29.38 26.50</cell><cell>--26.48</cell><cell>31.86 29.41 26.53</cell><cell>31.91 29.48 26.59</cell><cell>31.97 29.50 26.58</cell></row><row><cell>Urban100 [34]</cell><cell>15 25 50</cell><cell>32.35 29.70 25.95</cell><cell>32.97 30.39 26.83</cell><cell>32.64 29.95 26.26</cell><cell>32.46 29.80 26.22</cell><cell>32.40 29.90 26.50</cell><cell>-30.19 26.82</cell><cell>33.45 30.94 27.49</cell><cell>33.15 30.64 27.40</cell><cell>--27.65</cell><cell>33.17 30.66 27.42</cell><cell>33.44 31.11 27.96</cell><cell>33.70 31.30 27.98</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Quantitative comparison (average PSNR) with state-of-the-art methods for color image denoising on benchmark datasets. Best and second best performance are in red and blue colors, respectively.</figDesc><table><row><cell>Dataset</cell><cell>?</cell><cell>BM3D [14]</cell><cell>DnCNN [90]</cell><cell>IRCNN [91]</cell><cell>FFDNet [92]</cell><cell>DSNet [64]</cell><cell>RPCNN [85]</cell><cell>BRDNet [71]</cell><cell>RNAN [96]</cell><cell>RDN [98]</cell><cell>IPT [9]</cell><cell>DRUNet [88]</cell><cell>SwinIR (ours)</cell></row><row><cell>CBSD68 [59]</cell><cell>15 25 50</cell><cell>33.52 30.71 27.38</cell><cell>33.90 31.24 27.95</cell><cell>33.86 31.16 27.86</cell><cell>33.87 31.21 27.96</cell><cell>33.91 31.28 28.05</cell><cell>-31.24 28.06</cell><cell>34.10 31.43 28.16</cell><cell>--28.27</cell><cell>--28.31</cell><cell>--28.39</cell><cell>34.30 31.69 28.51</cell><cell>34.42 31.78 28.56</cell></row><row><cell>Kodak24 [23]</cell><cell>15 25 50</cell><cell>34.28 32.15 28.46</cell><cell>34.60 32.14 28.95</cell><cell>34.69 32.18 28.93</cell><cell>34.63 32.13 28.98</cell><cell>34.63 32.16 29.05</cell><cell>-32.34 29.25</cell><cell>34.88 32.41 29.22</cell><cell>--29.58</cell><cell>--29.66</cell><cell>--29.64</cell><cell>35.31 32.89 29.86</cell><cell>35.34 32.89 29.79</cell></row><row><cell>McMaster [94]</cell><cell>15 25 50</cell><cell>34.06 31.66 28.51</cell><cell>33.45 31.52 28.62</cell><cell>34.58 32.18 28.91</cell><cell>34.66 32.35 29.18</cell><cell>34.67 32.40 29.28</cell><cell>-32.33 29.33</cell><cell>35.08 32.75 29.52</cell><cell>--29.72</cell><cell>---</cell><cell>--29.98</cell><cell>35.40 33.14 30.08</cell><cell>35.61 33.20 30.22</cell></row><row><cell>Urban100 [34]</cell><cell>15 25 50</cell><cell>33.93 31.36 27.93</cell><cell>32.98 30.81 27.59</cell><cell>33.78 31.20 27.70</cell><cell>33.83 31.40 28.05</cell><cell>---</cell><cell>-31.81 28.62</cell><cell>34.42 31.99 28.56</cell><cell>--29.08</cell><cell>--29.38</cell><cell>--29.71</cell><cell>34.81 32.60 29.61</cell><cell>35.13 32.90 29.82</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/cszn/BSRGAN</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements This paper was partially supported by the ETH Zurich Fund (OK), a Huawei Technologies Oy (Finland) project, the China Scholarship Council and an Amazon AWS grant. Special thanks goes to Yijue Chen.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ntire 2017 challenge on single image super-resolution: Dataset and study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="126" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast, accurate, and lightweight super-resolution with cascading residual network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namhyuk</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byungkon</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyung-Ah</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Low-complexity single-image super-resolution based on nonnegative neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Bevilacqua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aline</forename><surname>Roumy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Guillemot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberi</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Swin-unet: Unet-like pure transformer for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueyue</forename><surname>Hu Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joy</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manning</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.05537</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiezhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.06847</idno>
		<title level="m">Video super-resolution transformer</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">End-to-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cas-cnn: A deep convolutional neural network for image compression artifact suppression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Cavigelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="752" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Two deterministic half-quadratic regularization algorithms for computed imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Charbonnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laure</forename><surname>Blanc-Feraud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Barlaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1994" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="168" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pre-trained image processing transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="12299" to="12310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1256" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Mfagan: A compression framework for memoryefficient on-device super-resolution gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenlong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiling</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.12679</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast, accurate and lightweight superresolution with neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyuan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">On the relationship between self-attention and convolutional layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Baptiste</forename><surname>Cordonnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Loukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03584</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-d transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Second-order attention network for single image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianrui</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu-Tao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep coupled feedback network for joint exposure fusion and image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3098" to="3112" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Compression artifacts reduction by a deep convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubin</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning a deep convolutional network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="184" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<title level="m">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Quantization guided jpeg artifact correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Ehrlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="293" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Revisiting spatial invariance with low-rank local connectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gamaleldin</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pointwise shape-adaptive dct for high-quality denoising and deblocking of grayscale and color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1395" to="1411" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Kodak lossless true color image suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Franzen</surname></persName>
		</author>
		<ptr target="http://r0k.us/graphics/kodak" />
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Frequency separation for real-world super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Fritsche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on International Conference on Computer Vision Workshops</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3599" to="3608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A model-driven deep unfolding method for jpeg artifacts removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Jpeg artifacts reduction via deep convolutional sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2501" to="2510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fast image super resolution via local regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nong</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on International Conference on Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3128" to="3131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weighted nuclear norm minimization with application to image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangchu</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2862" to="2869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Closedloop matters: Dual regression networks for single image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiezhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeshuai</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5407" to="5416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep back-projection networks for superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Haris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norimichi</forename><surname>Ukita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Single image haze removal using dark channel prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2341" to="2353" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Ode-inspired network design for single image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zitao</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peisong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1732" to="1741" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Single image super-resolution from transformed selfexemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narendra</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="5197" to="5206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Lightweight image super-resolution with information multi-distillation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinbo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiumei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Multimedia</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Video super-resolution with recurrent structure-detail network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Isobe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songjiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengjin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="645" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Real-world super-resolution via kernel estimation and noise injection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jilin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Focnet: A fractional optimal control network for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xixi</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangchu</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6054" to="6063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Perceptual losses for real-time style transfer and super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="694" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Accurate image super-resolution using very deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1646" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A pseudo-blind convolutional neural network for the reduction of compression artifacts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonsik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><forename type="middle">Woong</forename><surname>Soh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byeongyong</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun-Seung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Su</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">Ik</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1121" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep laplacian pyramid networks for fast and accurate super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Sheng</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narendra</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="624" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianjuan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangbo</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.10422</idno>
		<title level="m">Lapar: Linearly-assembled pixel-adaptive regression network for single image super-resolution and beyond</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiezhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.05707</idno>
		<title level="m">Localvit: Bringing locality to vision transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Feedback network for image superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinglei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaomin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gwanggil</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3867" to="3876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Transcrowd: Weakly-supervised crowd counting with transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingkang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiwu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.09116</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Hierarchical conditional flow: A unified framework for image superresolution and image rescaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyun</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Lugmayr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Mutual affine network for spatially variant kernel estimation in blind image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyun</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Flow-based kernel prior with application to blind super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyun</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10601" to="10610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Enhanced deep residual networks for single image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bee</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyun</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungjun</forename><surname>Nah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Non-local recurrent network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bihan</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02919</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep learning for generic object detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Fieguth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matti</forename><surname>Pietik?inen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="261" to="318" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multi-level wavelet-cnn for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengju</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on computer vision and pattern recognition workshops</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="773" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajad</forename><surname>Chhatkuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03180</idno>
		<title level="m">Transformer in convolutional neural networks</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14030</idno>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Latticenet: Towards lightweight image super-resolution with lattice block</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyun</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuihua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doron</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doron</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Sketch-based manga retrieval using manga109 dataset. Multimedia Tools and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Matsui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kota</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Aramaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azuma</forename><surname>Fujimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toru</forename><surname>Ogawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoharu</forename><surname>Aizawa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Image superresolution with non-local sparse attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqian</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Nonparametric blind super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Michaeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="945" to="952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Single image super-resolution via a holistic attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilei</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangde</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianping</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuzhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaihao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Dilated residual networks with symmetric skip connection for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yali</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shigang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xili</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">345</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="67" to="76" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Pl?tz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.12575</idno>
		<title level="m">Neural nearest neighbors networks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Standalone self-attention in vision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwan</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05909</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheikh</surname></persName>
		</author>
		<ptr target="http://live.ece.utexas.edu/research/quality" />
		<title level="m">Live image quality assessment database release 2</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Real-time single image and video superresolution using an efficient sub-pixel convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1874" to="1883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Probst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Danda Pani Paudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.10926</idno>
		<title level="m">Boosting crowd counting with transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Memnet: A persistent memory network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4539" to="4547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Image denoising using deep cnn with batch renormalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunwei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="461" to="473" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Anchored neighborhood regression for fast example-based super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">De</forename><surname>Smet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1920" to="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">A+: Adjusted anchored neighborhood regression for fast superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">De</forename><surname>Smet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="111" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.12877</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Scaling local self-attention for parameter efficient visual backbones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blake</forename><surname>Hechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12731</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Unsupervised degradation representation learning for blind superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingqian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10581" to="10590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Learning parallax attention for stereo image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingqian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengfa</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaiping</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12250" to="12259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Learning a single network for scale-arbitrary super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingqian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaiping</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10581" to="10590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Real-esrgan: Training real-world blind super-resolution with pure synthetic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangbin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Shan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.10833</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Esrgan: Enhanced super-resolution generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision Workshops</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Uformer: A general u-shaped transformer for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhendong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Cun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhuang</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03106</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Unsupervised real-world image super resolution via domain-distance aware training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunxuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longcun</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengjie</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13385" to="13394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Visual transformers: Token-based image representation and processing for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.03677</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Identifying recurring patterns with deep neural networks for natural image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayan</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2426" to="2434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mannat</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Mintun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.14881</idno>
		<title level="m">Piotr Doll?r, and Ross Girshick. Early convolutions help transformers see better</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">On single image scale-up using sparse-representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Zeyde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Protter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Curves and Surfaces</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="711" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Plug-and-play image restoration with deep denoiser prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Designing a practical degradation model for deep blind image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyun</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Learning deep cnn denoiser prior for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3929" to="3938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Ffdnet: Toward a fast and flexible solution for cnn-based image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4608" to="4622" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Learning a single convolutional super-resolution network for multiple degradations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3262" to="3271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Color demosaicking by local directional interpolation and nonlocal adaptive thresholding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Electronic imaging</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">23016</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Image super-resolution using very deep residual channel attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="286" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Residual non-local attention networks for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10082</idno>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Residual dense network for image superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yapeng</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="2472" to="2481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Residual dense network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yapeng</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2480" to="2495" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sixiao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zekun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yabiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6881" to="6890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Cross-scale internal graph neural network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shangchen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16673</idno>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
