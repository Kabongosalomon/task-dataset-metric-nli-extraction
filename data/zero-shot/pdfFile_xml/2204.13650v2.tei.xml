<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unlocking High-Accuracy Differentially Private Image Classification through Scale</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soham</forename><surname>De</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Berrada</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Hayes</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Balle</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepmind</forename></persName>
						</author>
						<title level="a" type="main">Unlocking High-Accuracy Differentially Private Image Classification through Scale</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differential Privacy (DP) provides a formal privacy guarantee preventing adversaries with access to a machine learning model from extracting information about individual training points. Differentially Private Stochastic Gradient Descent (DP-SGD), the most popular DP training method for deep learning, realizes this protection by injecting noise during training. However previous works have found that DP-SGD often leads to a significant degradation in performance on standard image classification benchmarks. Furthermore, some authors have postulated that DP-SGD inherently performs poorly on large models, since the norm of the noise required to preserve privacy is proportional to the model dimension.</p><p>In contrast, we demonstrate that DP-SGD on over-parameterized models can perform significantly better than previously thought. Combining careful hyper-parameter tuning with simple techniques to ensure signal propagation and improve the convergence rate, we obtain a new SOTA without extra data on CIFAR-10 of 81.4% under (8, 10 ?5 )-DP using a 40-layer Wide-ResNet, improving over the previous SOTA of 71.7%. When fine-tuning a pre-trained NFNet-F3, we achieve a remarkable 83.8% top-1 accuracy on ImageNet under (0.5, 8 ? 10 ?7 )-DP. Additionally, we achieve 86.7% top-1 accuracy under (8, 8 ? 10 ?7 )-DP, only 4.3% below the current non-private SOTA for this task. We believe our results are a significant step towards closing the accuracy gap between private and non-private image classification. Corresponding author(s): {sohamde | lberrada | slsmith | bballe}@deepmind.com arXiv:2204.13650v2 [cs.LG] 16 Jun 2022</p><p>Unlocking High-Accuracy Differentially Private Image Classification through Scale Paper outline. We provide a brief introduction to Differential Privacy and DP-SGD in Section 2, where we also discuss the challenges that arise when applying DP-SGD to deep networks. In Section 3, we describe a range of techniques that enhance the performance of networks trained with DP-SGD, achieving SOTA performance on CIFAR-10 and ImageNet when training without additional data. In Section 4, we show that privately fine-tuning strong pre-trained models dramatically improves the performance of private image classification. Finally, we provide additional insights into how the hyper-parameters of DP-SGD influence performance in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility.</head><p>To help researchers reproduce and verify our results, we are releasing the implementation of DP-SGD used in our experiments at https://github.com/deepmind/jax_privacy. We also provide the configuration scripts and pre-trained checkpoints necessary to reproduce all of our results on CIFAR-10 and CIFAR-100, as well as our results on ImageNet without extra data. We provide further details about our DP-SGD implementation in Appendix A, together with a description of the steps we undertook to audit its correctness. 1 Shortly after our paper was released, Klause et al. (2022) updated their paper to combine our techniques with their suggested ScaleNorm, achieving a new SOTA test accuracy of 82.5% on CIFAR-10 without extra data at = 8. Additionally, Bu et al. (2022) also published their work showing the benefits of large models when fine-tuning with differential privacy by achieving a new SOTA test accuracy with extra data of 96.7% on CIFAR-10 and 83.0% on CIFAR-100 under (1, 10 ?5 )-DP using a large ViT model pre-trained on ImageNet.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Machine learning models trained with standard pipelines can be attacked by an adversary that seeks to reveal the data on which the model was trained. For example, <ref type="bibr">Carlini et al. (2021b)</ref> showed that adversaries can generate and detect text sequences from the training set of a large transformer language model, while <ref type="bibr">Balle et al. (2022)</ref> showed that powerful adversaries can reconstruct images in the training set of a classifier trained on CIFAR-10. Alongside other results <ref type="bibr">(Carlini et al., 2021a;</ref><ref type="bibr">Choquette-Choo et al., 2021;</ref><ref type="bibr" target="#b35">Liu et al., 2021)</ref>, these studies demonstrate that models trained on sensitive datasets present a significant privacy risk. Differential Privacy (DP) <ref type="bibr" target="#b8">(Dwork et al., 2006)</ref> is the gold standard technique for mitigating privacy attacks aimed at leaking individual training examples, and it has already been adopted in practice by a range of public and private organizations <ref type="bibr" target="#b1">(Abowd, 2018;</ref><ref type="bibr">Apple Differential Privacy Team, 2017;</ref><ref type="bibr">Bird, 2020;</ref><ref type="bibr" target="#b10">Erlingsson, 2014;</ref><ref type="bibr" target="#b40">McMahan and Thakurta, 2022;</ref><ref type="bibr" target="#b46">Nayak, 2020)</ref>. A differentially private algorithm is a randomized algorithm providing a formal guarantee that any single example in the training set can only influence the output distribution of the algorithm by a small, pre-specified amount. This privacy guarantee, denoted ( , )-DP, is defined by two parameters ( , ), which we refer to as the privacy budget. The smaller these two parameters are, the closer the output distributions between training sets that differ by a single example, and therefore the more difficult it is for an adversary to infer whether any single data point was included during training.</p><p>The most popular method for training neural networks with DP is Differentially Private Stochastic Gradient Descent (DP-SGD) <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref>. DP-SGD replaces the usual mini-batch gradient estimate of SGD with a privatized version, in which the gradient of each training example is clipped to a maximum norm. In addition, Gaussian noise proportional to the clipping norm is added to the sum of the clipped gradients, which is sufficient to mask the contribution of any single example to the sum. Each evaluation of a (privatized) mini-batch gradient incurs a privacy cost, and a privacy accountant <ref type="bibr" target="#b0">(Abadi et al., 2016;</ref><ref type="bibr" target="#b44">Mironov et al., 2019)</ref> is used to track the total privacy budget spent throughout training. These parameters increase with every mini-batch seen during training, and decrease with the scale of the noise added, thus limiting the number of training iterations we can perform at a fixed privacy budget while keeping the variance in the gradient estimate under control. Test Accuracy (%) <ref type="bibr" target="#b82">Yu et al., 2021c</ref><ref type="bibr" target="#b71">Tram?r and Boneh, 2021</ref><ref type="bibr" target="#b28">Klause et al., 2022</ref><ref type="bibr">D?rmann et al, 2021</ref> Ours Top-1 Accuracy (%) <ref type="bibr">77.6 83.8 84.4 85.6 86.0 86.7</ref> Non-private SOTA: <ref type="bibr">Yu et al., 2022 Ours (b)</ref> ImageNet with extra data <ref type="figure">Figure 1</ref> | (a) When training on CIFAR-10 without additional data, we improve on previously published results under ( , 10 ?5 )-DP whenever ? 3. At = 8, we improve on the previous SOTA of <ref type="bibr" target="#b28">Klause et al. (2022)</ref> by 9.7%. Note we report the mean and standard error across 5 independent runs. (b) When fine-tuning a pre-trained NFNet-F3 <ref type="bibr">(Brock et al., 2021b)</ref> on ImageNet under (8, 8 ? 10 ?7 )-DP, we achieve 86.7% top-1 accuracy, only 4.3% below the current non-private SOTA of 91.0% <ref type="bibr" target="#b83">(Yu et al., 2022)</ref>. We also obtain 83.8% top-1 accuracy under a much tighter (0.5, 8 ? 10 ?7 )-DP guarantee, which exceeds the performance of many popular non-private models (e.g., .</p><p>Training with DP-SGD involves a delicate balancing act between different hyper-parameters such as the amount of added noise, the batch size, and the number of training iterations, in order to reach optimal performance within a specified privacy budget. In particular, the noise added to the gradient is a significant barrier to optimization, typically resulting in a significant degradation in performance compared to standard non-private training <ref type="bibr">(D?rmann et al., 2021;</ref><ref type="bibr" target="#b28">Klause et al., 2022;</ref>. Furthermore, several authors have postulated that highly over-parameterized models, which perform well in non-private settings, do not work well when used with DP-SGD, because the norm of the added noise increases with the dimension of the gradient <ref type="bibr" target="#b56">Shen et al., 2021;</ref><ref type="bibr" target="#b71">Tram?r and Boneh, 2021;</ref><ref type="bibr" target="#b81">Yu et al., 2021b)</ref>, leading to a "curse of dimensionality". Consequently, many works have focused either on developing specialized architectures for private training <ref type="bibr" target="#b71">Tram?r and Boneh, 2021)</ref>, or on reducing the dimensionality of the model during training <ref type="bibr" target="#b16">(Golatkar et al., 2022;</ref><ref type="bibr" target="#b81">Yu et al., 2021b;</ref><ref type="bibr" target="#b90">Zhou et al., 2021)</ref>.</p><p>On the contrary, we show that standard over-parameterized architectures, which achieve close to state-of-the-art performance in non-private training, can also perform very well when trained using DP-SGD if properly tuned. To achieve this, we introduce a number of techniques which help convergence and ensure trainability at initialization, and we explore the benefits of using pre-trained models. Our main contributions are listed below:</p><p>? We describe a set of simple techniques which, when combined, significantly improve the performance of DP-SGD. First, we revisit ideas that have previously been identified as useful for private training, including using large batch sizes <ref type="bibr" target="#b42">(McMahan et al., 2018b)</ref>, and replacing batch normalization layers with alternatives that ensure good signal propagation at initialization (van der <ref type="bibr">Maaten and Hannun, 2020)</ref>. In addition, we propose further modifications that improve the convergence rate of DP-SGD, and that have not previously been used for private training. Specifically, we suggest using weight standardization in convolutional layers <ref type="bibr">(Qiao et al., 2019)</ref>, leveraging the benefits of data augmentation by averaging per-example gradients across multiple augmentations of the same image before the clipping operation <ref type="bibr" target="#b21">(Hoffer et al., 2019)</ref> and applying parameter averaging techniques <ref type="bibr" target="#b52">(Polyak and Juditsky, 1992</ref>).</p><p>? Applying the techniques above, we significantly improve the performance of DP-SGD when training randomly initialized over-parameterized models. Training Wide-ResNets <ref type="bibr" target="#b84">(Zagoruyko and Komodakis, 2016)</ref> on CIFAR-10 without extra data, we achieve a new SOTA of 81.4% under (8, 10 ?5 )-DP. This is a substantial improvement on the previous SOTA of 71.7% achieved under (7.5, 10 ?5 )-DP (Klause et al., JFT-300M ---55.1 5 ? 10 ?7 4.3 2022). As shown in <ref type="figure">Figure 1</ref>(a), we achieve SOTA results on this task across a range of values between 3 and 8. We also achieve a new SOTA top-1 accuracy on ImageNet of 32.4% under (8, 8 ? 10 ?7 )-DP when training a Normalizer-Free ResNet-50 (NF-ResNet-50) <ref type="bibr">(Brock et al., 2021a;</ref><ref type="bibr" target="#b20">He et al., 2016)</ref>.</p><p>? We show that non-private pre-training on public/non-sensitive data, followed by fine-tuning with DP-SGD on the private dataset, yields remarkable performance benefits on image classification benchmarks. For example, when privately fine-tuning an NF-ResNet-200 pre-trained on JFT-300M <ref type="bibr" target="#b64">(Sun et al., 2017)</ref>, we achieve 81.3% top-1 accuracy on ImageNet under (8, 8 ? 10 ?7 )-DP. We observe further improvements in performance from increasing both the size of the model and the size of the pre-training dataset, achieving 86.7% top-1 accuracy under (8, 8 ? 10 ?7 )-DP with an NFNet-F3 <ref type="bibr">(Brock et al., 2021b)</ref> pre-trained on JFT-4B. This network also obtains 83.8% top-1 accuracy under a much tighter privacy budget of (0.5, 8 ? 10 ?7 )-DP.</p><p>For comparison, fine-tuning the same pre-trained network on ImageNet without privacy reaches 88.5%.</p><p>? We provide novel insights into how optimal hyper-parameters relate to each other when training with DP. We empirically observe that (1) there is an optimal budget of training iterations given a fixed batch-size, (2) larger batch sizes improve validation accuracy but require more training epochs after the batch size exceeds a certain threshold, and (3) the optimal choice of learning-rate for DP-SGD is proportional to the batch size when the batch size is small but constant for large batch sizes, similar to non-private training.</p><p>We summarize our key results in <ref type="table" target="#tab_0">Table 1</ref>, with our SOTA results shown in bold. <ref type="bibr">1</ref> We emphasize that all our results use standard vision architectures which have been shown to work well for non-private training. We believe these results are a significant step towards practically useful differentially private image classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Differential Privacy (DP)</head><p>Differential privacy (DP) is a formal privacy guarantee that applies to randomized data analysis algorithms. By construction, differentially private algorithms prevent an adversary that observes the output of a computation from inferring any property pertaining to individual data points in the input data used during the computation. The strength of this guarantee is controlled by two parameters: &gt; 0 and ? [0, 1]. Roughly speaking, bounds the log-likelihood ratio of any particular output that can be obtained when running the algorithm on two datasets differing in a single data point, and is a small probability which bounds the occurrence of infrequent outputs that violate this bound. The privacy guarantee becomes stronger as both parameters get smaller. A standard rule of thumb states that, to obtain meaningful privacy, should be a small constant while should be smaller than 1/ , where is the size of the input dataset. More formally, we have the following.</p><p>Definition 2.1 (Differential Privacy <ref type="bibr" target="#b8">(Dwork et al., 2006)</ref>). Let : D ? S be a randomized algorithm, and let &gt; 0, ? [0, 1]. We say that is ( , )-DP if for any two neighboring datasets , ? D differing by a single element, we have that</p><formula xml:id="formula_0">? ? S, ?[ ( ) ? ] ? exp( )?[ ( ) ? ] + .<label>(1)</label></formula><p>The privacy protection afforded by DP holds under an exceedingly strong threat model: inferences about individuals are protected even in the face of an adversary that has full knowledge of the DP algorithm, unbounded computational power, and arbitrary side knowledge about the input data. Furthermore, DP satisfies a number of appealing properties from the algorithm design standpoint, including preservation under post-processing and a smooth degradation with multiple accesses to the same data. These properties are exploited in the construction of complex DP algorithms based on the combination of small building blocks that inject carefully calibrated noise into operations that access the data. The magnitude of the noise required to satisfy the privacy guarantee increases with the strength of the privacy parameters, leading to an unavoidable trade-off between utility and privacy, as illustrated by the Fundamental Law of Information Recovery <ref type="bibr" target="#b7">(Dwork and Roth, 2014)</ref>.</p><p>Together, the strength of the formal guarantee it provides and the variety of tools available for the construction of DP algorithms, have led to the growing adoption of DP as a gold standard for privacy-preserving machine learning. For convex learning problems there exists a variety of methods for obtaining differentially private algorithms, including output perturbation <ref type="bibr">(Chaudhuri et al., 2011;</ref><ref type="bibr" target="#b76">Wu et al., 2017)</ref>, objective perturbation <ref type="bibr">(Chaudhuri et al., 2011;</ref><ref type="bibr" target="#b27">Kifer et al., 2012)</ref> and gradient perturbation <ref type="bibr">(Bassily et al., 2014;</ref><ref type="bibr" target="#b62">Song et al., 2013)</ref>. The nature of convex problems enables the formal analysis of the privacy-utility offered by these algorithms, and by now there are large classes of problems for which algorithms achieving (nearly) optimal privacy-utility trade-offs are known <ref type="bibr" target="#b5">(Asi et al., 2021;</ref><ref type="bibr">Bassily et al., 2014;</ref><ref type="bibr" target="#b12">Feldman et al., 2020;</ref><ref type="bibr" target="#b66">Talwar et al., 2015)</ref>. For non-convex learning problems, the range of available algorithms is more limited and privacy-utility trade-offs are harder to analyze theoretically. Nonetheless, for such problems there exist two families of algorithms that have been shown to achieve reasonable privacy-utility-computation trade-offs in practice: gradient perturbation applied to standard optimizers like SGD <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref>, and private aggregation of teacher ensembles <ref type="bibr" target="#b50">(Papernot et al., 2018)</ref>. In this work we focus on the former, which is most commonly used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Differentially Private Stochastic Gradient Descent (DP-SGD)</head><p>In this work, we assume that the differentially private algorithm (see Equation <ref type="formula" target="#formula_0">(1)</ref>) is a learning algorithm that maps a training dataset = {( , )} 1? ? to a vector of learned neural network parameters ? S = ? . Let L ( , , ) denote the learning objective (e.g., the cross-entropy loss), given the model parameters , input example and label . For convenience, we use the shorthand notation ( ) = L ( , , ).</p><p>In the non-private setting, a parameter update using Stochastic Gradient Descent (SGD) at iteration draws examples at random from the dataset, and performs an update of the form:</p><formula xml:id="formula_1">( +1) = ( ) ? 1 ?? ?B ? ( ( ) ) ,</formula><p>where is the step-size for the ? update, ? denotes the gradient operator, and B represents the set of examples sampled at iteration with |B | = . In order to make this algorithm differentially private, we apply the following modifications. First, the gradient for each example in the mini-batch is clipped to a maximal norm , and second, Gaussian noise with standard deviation proportional to is added to the mean of the clipped gradients. Let clip : ? ? ? ? min 1, 2 ? ? ? denote the clipping function which re-scales its input so that the output has a maximal 2 norm of . The new update step is:</p><formula xml:id="formula_2">( +1) = ( ) ? 1 ?? ?B clip ? ( ( ) ) + ,<label>(2)</label></formula><p>where ? N (0, ) is a standard -dimensional Gaussian random variable and specifies the standard deviation of the added noise. The resulting algorithm is called Differentially Private-Stochastic Gradient Descent (DP-SGD) <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref>. Intuitively, performing a model update using Equation (2) provides differential privacy because adding Gaussian noise with standard deviation proportional to is sufficient to mask the contribution of any single example whose clipped gradient has norm less than or equal to . While we use privatized SGD as our optimizer throughout this work, a similar privatization method can also be used in combination with other first-order optimization algorithms, such as SGD with momentum or Adam <ref type="bibr" target="#b41">(McMahan et al., 2018a)</ref>.</p><p>Throughout this paper we use a modified version of DP-SGD where the privatized gradient is normalized by :</p><formula xml:id="formula_3">( +1) = ( ) ? 1 ?? ?B 1 clip ? ( ( ) ) + .<label>(3)</label></formula><p>This is a re-parameterization of Equation <ref type="formula" target="#formula_2">(2)</ref> in which the learning rate absorbs a factor of . This has no effect on the privacy guarantees, but ensures the clipping norm does not influence the scale of the update, which simplifies hyper-parameter tuning (See Appendix B.1). Note that to preserve the DP guarantees, we must divide by after the clipping operation. Appendix A.1 provides further details about our DP-SGD implementation, including a description of our approach to virtual batching to enable training with large batch sizes.</p><p>Privacy accounting. The privacy guarantee of DP-SGD is determined by three parameters: the standard deviation , the sampling ratio = / and the number of training iterations . In practice, the privacy budget ( , ) is usually fixed, and these three hyper-parameters are chosen to provide the best possible performance within this budget. There may also be additional practical constraints (e.g., the maximum compute budget available). The privacy calibration process is performed using a privacy accountant: a numerical algorithm providing tight upper bounds for the privacy budget as a function of the hyper-parameters <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref>, which in turn can be combined with numerical optimization routines to optimize one hyper-parameter given the privacy budget and the other two hyper-parameters. In this work we use the accounting method for DP-SGD proposed by <ref type="bibr" target="#b44">Mironov et al. (2019)</ref> and implemented in TensorFlow Privacy <ref type="bibr" target="#b17">(Google, 2018)</ref>. This privacy accountant relies on a "composition" analysis across iterations, which allows us to release not only the final model, but also every intermediate model obtained during training (under the same privacy budget).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Challenges of DP-SGD</head><p>As described above, there are three key differences between DP-SGD and non-private SGD: (1) the per-example gradients are clipped to a maximal 2 norm before they are averaged, (2) Gaussian noise is added to the average of the clipped gradients, and (3) the maximum number of updates allowed within the privacy budget is bounded, and depends on the batch size/added noise. These differences introduce a number of challenges:</p><p>Hyper-parameter tuning and regularization. The noise added to the gradient estimate in the DP-SGD update (Equation <ref type="formula" target="#formula_3">(3)</ref>) is a significant barrier to efficient optimization, and if we reduce the scale of this noise, the number of training iterations allowed within the privacy budget decreases. This constraint alters the optimal values of key hyper-parameters like the batch size/learning rate, and defaults from non-private training can be highly sub-optimal . Consequently, DP-SGD requires careful hyper-parameter tuning. <ref type="bibr">2</ref> We also found in our experiments that, when training with DP-SGD, improvements in training accuracy usually translate directly to improved generalization, without requiring strong regularization. Inspired by this observation, our philosophy is that methods that reduce the number of training iterations required to reach high training accuracy in non-private training are likely to improve the test accuracy achieved in private training. Consistent with this approach, it is usually beneficial to remove explicit regularization methods.</p><p>Bias and variance of the DP-SGD update. The gradient estimator used by DP-SGD is biased because of the use of per-example gradient clipping, and in general it does not correspond to the gradient of any differentiable function . More importantly, the clipping norm introduces a bias-variance trade-off <ref type="bibr">(Chen et al., 2020;</ref>. This can be viewed from the DP-SGD update shown in Equation <ref type="formula" target="#formula_3">(3)</ref>.</p><p>When is very large, clip is the identity function, so the privatized gradient is an unbiased estimator of the true gradient, but the clipped gradient 1 clip ? ( ( ) ) is very small compared to the noise (which is independent of ) -overall the privatized gradient estimate has low bias and high variance. Conversely, if is small, the clipping operation introduces bias, but the clipped gradient 1 clip ? ( ( ) ) is larger, and thus is not necessarily small compared to the noise -overall the privatized gradient estimate has high bias and low variance. Note that when is very small (smaller than the smallest per-example gradient norm), further lowering does not change 1 clip ? ( ( ) ) , which indicates that the bias and variance in the update both approach a constant as ? 0. Intriguingly, previous work has observed that wide ranges of the clipping norm can provide near optimal performance provided that (i) the clipping norm is small enough, and (ii) the learning-rate is re-scaled accordingly <ref type="bibr" target="#b34">Li et al., 2021)</ref>. This suggests that reducing the variance introduced by noise may be more important than reducing the bias introduced by clipping.</p><p>Making standard models work. Differentially private training has recently obtained promising results with standard architectures in NLP, both when training a BERT model <ref type="bibr">(Devlin et al., 2018)</ref> from random initialization <ref type="bibr" target="#b3">(Anil et al., 2021)</ref>, and when fine-tuning a large Transformer language model <ref type="bibr" target="#b74">(Vaswani et al., 2017</ref>) from a pre-trained set of parameters <ref type="bibr" target="#b34">(Li et al., 2021;</ref><ref type="bibr" target="#b80">Yu et al., 2021a)</ref>. However, similar results have not been obtained in computer vision, and the literature does not provide clear recommendations on which model architectures perform well. For instance, surveying recent research on private training for CIFAR-10, , <ref type="bibr">D?rmann et al. (2021)</ref> use variants of shallow VGG models <ref type="bibr" target="#b58">(Simonyan and Zisserman, 2015)</ref>, while <ref type="bibr" target="#b71">Tram?r and Boneh (2021)</ref> use ScatterNets <ref type="bibr" target="#b48">(Oyallon and Mallat, 2015)</ref> to train linear models on handcrafted features, achieving an impressive 69.3% test accuracy under a tight privacy budget of (3, 10 ?5 )-DP. Finally, <ref type="bibr" target="#b28">Klause et al. (2022)</ref> achieve the SOTA test accuracy for ? 8 without extra data of 71.7% when training a shallow 9-layer residual network <ref type="bibr" target="#b20">(He et al., 2016</ref>) under (7.5, 10 ?5 )-DP.</p><p>The 2 norm of the noise added in the DP-SGD update scales proportional to the dimension of the gradient (the number of parameters). This observation has led many researchers to believe that standard over-parameterized models will perform poorly with DP-SGD, and instead focus on reducing the explicit or implicit dimension of the update, either through the use of small models/hand-crafted features <ref type="bibr" target="#b71">(Tram?r and Boneh, 2021)</ref> or through dimensionality reduction techniques <ref type="bibr">(Yu et al., 2021b,c)</ref>. Another key obstacle to the use of standard models for private training in computer vision has been that in order to provide tight DP guarantees, DP-SGD requires that the gradients evaluated on different training examples are independent. This excludes the use of any method that enables communication between training examples, such as batch normalization <ref type="bibr" target="#b24">(Ioffe and Szegedy, 2015)</ref>, which until recently has been almost ubiquitous in standard vision architectures <ref type="bibr">(Brock et al., 2021b;</ref><ref type="bibr">Dosovitskiy et al., 2020;</ref><ref type="bibr" target="#b20">He et al., 2016;</ref><ref type="bibr" target="#b67">Tan and Le, 2019;</ref><ref type="bibr" target="#b84">Zagoruyko and Komodakis, 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Improving the Privacy-Utility Trade-off of DP-SGD in Image Classification</head><p>In this section, we describe the key techniques we use to enhance the performance of models trained with DP-SGD on standard image classification benchmarks. In all the experiments in this section we train randomly initialized models without using any extra data. In Section 3.1 we provide an empirical ablation of these techniques on CIFAR-10, while in Sections 3.2 and 3.3 we evaluate the performance of our best models on CIFAR-10 and ImageNet. We focus on standard architectures popular in the computer vision community, since we believe that these models represent the most promising avenue for achieving long-term progress. <ref type="table">Table 2</ref> | An ablation study on the effect of a range of architectural modifications and changes to the training pipeline for models trained on CIFAR-10 under (8, 10 ?5 )-DP. We report median and standard deviation values over 5 runs. The baseline is a WRN-40-4 without batch normalization trained with DP-SGD using batch-size 256 without data augmentation. We report accuracy on our own validation set, not the official test set. 78.4 (0.9) 79.4 (0.9) + Parameter averaging (exponential moving average) 79.7 (0.2) 81.5 (0.2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Training on CIFAR-10 Without Additional Data -An Ablation Study</head><p>In <ref type="table">Table 2</ref> we provide an ablation study of a range of techniques, which collectively significantly enhance the performance of DP-SGD when training from random initialization on CIFAR-10 ( <ref type="bibr" target="#b31">Krizhevsky et al., 2009</ref>). These techniques include replacing batch normalization with group normalization <ref type="bibr" target="#b77">(Wu and He, 2020)</ref>, using large batch sizes, weight standardization <ref type="bibr">(Qiao et al., 2019)</ref>, a modification to DP-SGD which we call augmentation multiplicity <ref type="bibr" target="#b14">(Fort et al., 2021;</ref><ref type="bibr" target="#b21">Hoffer et al., 2019;</ref><ref type="bibr" target="#b69">Touvron et al., 2021a)</ref> and parameter averaging <ref type="bibr" target="#b52">(Polyak and Juditsky, 1992)</ref>. Prior research has already identified group normalization and large batch sizes as beneficial for training with DP-SGD <ref type="bibr" target="#b3">(Anil et al., 2021;</ref><ref type="bibr">D?rmann et al., 2021;</ref><ref type="bibr" target="#b34">Li et al., 2021;</ref><ref type="bibr" target="#b36">Luo et al., 2021;</ref><ref type="bibr">van der Maaten and Hannun, 2020;</ref><ref type="bibr" target="#b82">Yu et al., 2021c)</ref>, while to our knowledge the other techniques have not previously been used for private training. We first define our baseline model/training pipeline, and then discuss each modification in turn. For all experiments in this section, we split the official CIFAR-10 training dataset of 50K examples into a training set of 45K examples and a validation set of 5K examples. We train with DP-SGD on this reduced training set under (8, 10 ?5 )-DP. In order to avoid tuning on the official held-out test set, throughout this subsection we report accuracies obtained on the training and validation set only.</p><p>Baseline model and private training pipeline for CIFAR-10. As our baseline for CIFAR-10, we study the Wide-ResNet (WRN) model family <ref type="bibr" target="#b84">(Zagoruyko and Komodakis, 2016)</ref>. We note that WRN models obtain high accuracies on CIFAR-10 when trained non-privately: the 16 layer network with width factor 4 (denoted as WRN-16-4) achieves &gt;94% test accuracy, while the WRN-40-4 achieves &gt;95% <ref type="bibr" target="#b84">(Zagoruyko and Komodakis, 2016)</ref>. The model parameters are initialized using Gaussian random variables following <ref type="bibr" target="#b15">Glorot and Bengio (2010)</ref>. We train using DP-SGD without Momentum (Equation <ref type="formula" target="#formula_3">(3)</ref>). We observed no benefit from decaying the learning rate during training, and therefore use a constant learning rate in all experiments reported in this paper. We also do not use weight decay or dropout which we found to reduce both training and validation accuracies for private training. This is similar to observations made in <ref type="bibr" target="#b71">Tram?r and Boneh (2021)</ref>, although <ref type="bibr" target="#b3">Anil et al. (2021)</ref> reported improved performance when using weight decay with DP-Adam on BERT models. Unless otherwise specified, we train without data augmentation. For all experiments in this subsection, we tune the learning rate and the noise parameter on the validation set. We fix the clipping norm = 1 for all experiments in this paper. Given a target privacy guarantee ( , )-DP and specific hyper-parameter settings for and = / , we compute the maximum number of training iterations using the privacy accountant discussed in Section 2.2. We provide additional details for each of our experiments in Appendix C.</p><p>Training deep networks without batch normalization. As mentioned previously, most computer vision architectures, including the WRN model family, contain batch normalization layers, which are not compatible with DP-SGD. Therefore, for our experiments on WRNs, we replace all batch normalization layers by group normalization layers <ref type="bibr" target="#b77">(Wu and He, 2020)</ref>, as has been previously done by several authors <ref type="bibr" target="#b36">Luo et al., 2021;</ref><ref type="bibr">van der Maaten and Hannun, 2020;</ref><ref type="bibr" target="#b82">Yu et al., 2021c)</ref>. Group normalization splits the channels 2 8 2 9 2 10 2 11 2 12 2 13 2 14</p><p>Batch size B of the hidden activations of a single image into groups and normalizes the hidden activations within each group. It therefore does not break the independence between gradients evaluated on different examples. Note however that it is crucial to place the group normalization layers on the residual branch of the network to recover the benefits of batch normalization for training deep networks (De and . We fix the number of groups of the group normalization layers to 16 in all our experiments. In <ref type="table">Table 2</ref>, we show that this simple change significantly improves the performance of deep WRNs when training with DP-SGD.</p><p>A range of other alternatives to batch normalization have recently been identified in non-private deep learning <ref type="bibr">(Brock et al., 2021a;</ref><ref type="bibr" target="#b29">Kolesnikov et al., 2020;</ref>. These alternatives can train very deep networks (De and  and some even achieve superior train and test accuracies on standard benchmarks such as ImageNet classification <ref type="bibr">(Brock et al., 2021a,b)</ref>. We will provide additional results when training Normalizer-Free ResNets (Brock et al., 2021a) in later sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Large batch sizes.</head><p>As observed in several recent papers <ref type="bibr" target="#b3">(Anil et al., 2021;</ref><ref type="bibr">D?rmann et al., 2021;</ref><ref type="bibr" target="#b22">Hoory et al., 2021;</ref><ref type="bibr" target="#b34">Li et al., 2021;</ref><ref type="bibr" target="#b36">Luo et al., 2021)</ref>, increasing the batch size can significantly improve the privacy-utility trade-off of DP-SGD. In <ref type="table">Table 2</ref> we show that increasing the batch size from 256 to 4096 significantly increases both training and validation accuracy. Additionally in <ref type="figure">Figure 2</ref>, we evaluate the effect of the batch size on a WRN-16-4 where we sweep the batch size from 2 8 = 256 to 2 14 = 16384. We find that performance consistently improves as the batch size rises. The effect of increasing the batch size is discussed further in Section 5.</p><p>We note that the gap between the training and validation accuracy in <ref type="figure">Figure 2</ref> also increases with the batch size. As discussed by <ref type="bibr" target="#b78">Yeom et al. (2018)</ref>, increased overfitting can be an indication of a rise in privacy leakage, and training under DP implies generalization bounds that prevent overfitting when is small <ref type="bibr">(Bassily et al., 2016;</ref><ref type="bibr" target="#b9">Dwork et al., 2015)</ref>. However these bounds degrade rapidly with increasing , and even the best bounds we are aware of are vacuous in our setting <ref type="bibr" target="#b11">(Feldman and Steinke, 2017;</ref><ref type="bibr" target="#b26">Jung et al., 2020)</ref>. In Appendix A.2 we audit our implementation using membership inference attacks exploiting the generalization gap to assess privacy leakage, and find that the observed gaps are within the theoretical predictions for all values of considered.</p><p>Weight standardization. Next, we apply Weight Standardization <ref type="bibr">(Qiao et al., 2019)</ref> to all convolutional layers, which normalizes the rows of the weight matrix of each convolution over the fan-in of each output unit (See Appendix C.1 for implementation details). Several authors have shown that using weight standardization combined with group normalization can be an effective replacement for batch normalization in non-private training, especially when training with large batch size <ref type="bibr" target="#b29">(Kolesnikov et al., 2020;</ref><ref type="bibr">Qiao et al., 2019;</ref><ref type="bibr" target="#b53">Richemond et al., 2020</ref><ref type="bibr">), while Brock et al. (2021a</ref> found Weight Standardization improves the performance of NF-ResNets. We found that weight standardization also improves the performance of DP-SGD, particularly for large batch sizes. In <ref type="table">Table 2</ref>, we show the improvement in both the training and validation accuracies when using weight standardization with group normalization and a large batch size of 4096 on the WRN-40-4 model.</p><p>Augmentation multiplicity. Data augmentation is a crucial component of non-private training, which significantly improves the performance of over-parameterized models on vision tasks <ref type="bibr">(Cubuk et al., 2020;</ref><ref type="bibr" target="#b57">Shorten and Khoshgoftaar, 2019;</ref><ref type="bibr" target="#b86">Zhang et al., 2018a)</ref>. However, in our experiments with DP-SGD, we found that data augmentation as it is usually implemented in non-private training (using one augmentation per independent example in the mini-batch) reduced both training and validation accuracies (See <ref type="figure">Figure 3</ref>). We believe this occurs because data augmentation introduces variance into the gradient <ref type="bibr" target="#b14">(Fort et al., 2021)</ref>, which increases the number of training iterations required to minimize the loss. In non-private training, several authors have shown that using multiple augmentations per unique example in a mini-batch can improve performance <ref type="bibr" target="#b14">(Fort et al., 2021;</ref><ref type="bibr" target="#b21">Hoffer et al., 2019;</ref><ref type="bibr" target="#b70">Touvron et al., 2021b)</ref>. We now explore using multiple augmentations per example in the DP-SGD update to see if we can recover the benefits of data augmentation in private training. The naive approach when using multiple augmentations per example with DP-SGD would be to compute one clipped gradient for each augmented image, however this would lead to a privacy cost scaling with the number of augmentations per training example in each mini-batch. To circumvent this issue, we average the gradients of different augmentations of the same training example before clipping the per-example gradients. This approach does not increase the sensitivity of the mini-batch gradient to any single training example, and therefore does not incur any additional privacy cost. The resulting update can be written as follows:</p><formula xml:id="formula_4">( +1) = ( ) ? ? ? ? ? ? ? ? 1 ?? ?B 1 clip 1 ?? ?K ? ( ( ) ) + ? ? ? ? ? ? ? .<label>(4)</label></formula><p>Here K represents the set of randomly sampled augmentations for the ? training example on the ? iteration. We refer to the number of per-example augmentations as the augmentation multiplicity. When training with augmentation multiplicity on CIFAR-10, we use random crops and random horizontal flips of the input images, following <ref type="bibr" target="#b84">Zagoruyko and Komodakis (2016)</ref>. In <ref type="table">Table 2</ref>, we show that augmentation multiplicity, as described in Equation <ref type="formula" target="#formula_4">(4)</ref>, significantly boosts both the training and validation accuracy of the WRN-40-4 model. Additionally, we perform a sweep of augmentation multiplicities ranging from 2 to 32 on the WRN-16-4 model at a batch size of 4096 in <ref type="figure">Figure 3</ref>, and show that performance consistently improves with higher augmentation multiplicities, significantly exceeding the performance achieved without data augmentation.</p><p>Parameter averaging. Since the privacy analysis for DP-SGD assumes that all intermediate parameter values obtained during training can be released, parameter averaging techniques do not incur any additional privacy cost. We found that using an exponential moving average (EMA) of the parameters consistently improved final accuracy on both the training and validation sets <ref type="bibr" target="#b67">(Tan and Le, 2019)</ref>, as shown in <ref type="table">Table 2</ref> (See Appendix C for implementation details). All results in the remainder of this paper use EMA unless specified otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Training on CIFAR-10 Without Additional Data -Official Evaluation</head><p>In Section 3.1, we described a collection of techniques which substantially enhanced the performance of DP-SGD when training Wide-ResNets on CIFAR-10 ( <ref type="bibr" target="#b84">Zagoruyko and Komodakis, 2016</ref> With this setting, we achieve our best test accuracy on CIFAR-10 of 81.4% under (8, 10 ?5 )-DP. This exceeds the previous SOTA on CIFAR-10 for this privacy budget <ref type="bibr" target="#b28">(Klause et al., 2022)</ref> by 9.7%. We also provide the test accuracy across a range of values between 1 and 8. For these experiments, we tune the learning rate and the noise parameter independently for each (on the validation set as described above). As shown in <ref type="figure">Figure 1</ref>(a) and the more detailed comparison in <ref type="table">Table 3</ref>, we improve the current SOTA for all values of ? 3. We note that for small values of , the model used by <ref type="bibr" target="#b71">Tram?r and Boneh (2021)</ref> performs best, likely due to its ability to get good performance with a low number of updates. However, the capacity of this model is limited -only reaching 71% in non-private training <ref type="bibr" target="#b71">(Tram?r and Boneh, 2021)</ref>, and thus the more expressive WRN models outperform it whenever ? 3. We also note that the WRN-16-4 slightly outperforms the deeper WRN-40-4 model at = 1, while the WRN-40-4 performs better at all larger values of . These observations are consistent with our experiments in Appendix B.2, which show that the optimal model depth increases with .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Training on ImageNet Without Additional Data</head><p>To confirm that the insights above can improve the performance of DP-SGD on large datasets, we now train a classifier with DP from random initialization on the ImageNet dataset <ref type="bibr" target="#b54">(Russakovsky et al., 2015)</ref>.</p><p>We use a Normalizer-Free ResNet-50 (NF-ResNet-50) <ref type="bibr">(Brock et al., 2021a)</ref>, which is a modified version of the standard ResNet-50 model, designed to ensure good signal propagation. The model does not contain batch normalization layers and it applies weight standardization to convolutional layers <ref type="bibr">(Qiao et al., 2019)</ref>. We note that this model has been shown to match the performance of the standard batch normalized ResNet-50 for ImageNet classification in non-private training <ref type="bibr">(Brock et al., 2021a)</ref>. We initialize the model parameters using Gaussian random variables as for CIFAR-10 classification <ref type="bibr" target="#b15">(Glorot and Bengio, 2010)</ref>, and we remove all explicit regularization methods such as dropout, stochastic depth, label smoothing and weight decay. We reserve 10K images from the official training set of ImageNet as our validation set to tune hyper-parameters, and train on the remaining 1.27 million training examples. We use the official validation set of 50K examples as our test set. We use a batch size of 16384 and set augmentation multiplicity = 4. See Appendix C for further experimental details. Training on ImageNet is significantly more computationally expensive than on CIFAR-10. We therefore only ran a very limited sweep of the learning rate and the noise parameter for a single random seed.</p><p>As shown in <ref type="table">Table 4</ref>, our NF-ResNet-50 model achieves a top-1 accuracy of 32.4% and a top-5 accuracy of 55.8% under (8, 8 ? 10 ?7 )-DP. We note that this is a significant improvement on the previous SOTA for training on ImageNet with DP without using additional data, which achieves a top-1 accuracy of 6.9% under a larger privacy budget of (13.2, 10 ?6 )-DP using a ResNet-18 model .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">High-Accuracy Differentially Private Image Classification with Fine-Tuning</head><p>We now consider the setting where we have access to a large non-sensitive/public dataset on which we can pre-train our model, using standard non-private training. We then fine-tune this pre-trained model with DP-SGD on the sensitive/private dataset. This approach has been recently used successfully when privately fine-tuning language models <ref type="bibr" target="#b34">(Li et al., 2021;</ref><ref type="bibr" target="#b80">Yu et al., 2021a)</ref>, and it has also been shown to improve the performance of DP-SGD on both CIFAR-10 <ref type="bibr" target="#b0">(Abadi et al., 2016;</ref><ref type="bibr" target="#b71">Tram?r and Boneh, 2021;</ref><ref type="bibr" target="#b81">Yu et al., 2021b)</ref> and ImageNet . However, the best reported performance of DP-SGD on image classification benchmarks is still significantly lower than non-private training, particularly on large challenging datasets like ImageNet.</p><p>Using the techniques described in Section 3, we now show that we can significantly reduce the performance gap between private and non-private models in the fine-tuning regime. In Section 4.1 we provide results when fine-tuning on CIFAR-10 and CIFAR-100 from a model pre-trained on ImageNet. In Section 4.2 we provide results when fine-tuning on ImageNet using models pre-trained on either JFT-300M or JFT-4B <ref type="bibr" target="#b64">(Sun et al., 2017)</ref>, two internal datasets containing 300 million and 4 billion labelled images respectively. Finally, to confirm the versatility of our approach, in Section 4.3 we fine-tune from JFT-300M to Places-365 <ref type="bibr" target="#b89">(Zhou et al., 2017)</ref>, a challenging scene recognition dataset. For all experiments in this section, we explore both fine-tuning the final layer and fine-tuning all layers simultaneously. Except on ImageNet, almost all our best results are obtained by fine-tuning all layers of the model simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Fine-tuning on CIFAR-10 and CIFAR-100</head><p>In this section, we consider differentially-private fine-tuning on the CIFAR-10 and CIFAR-100 datasets, using models that were pre-trained on ImageNet without privacy. We consider WRN-28-10 and WRN-40-4 models, which we pre-train on ImageNet using images down-sampled to 32 ? 32 <ref type="bibr">(Chrabaszcz et al., 2017)</ref>. For pretraining, we use SGD with momentum for 240K iterations with a constant learning rate and a batch size of 1024. We use a weight decay of 5 ? 10 ?5 , and apply data augmentation including random flips and crops of the input images with augmentation multiplicity 1 (See Appendix C for further experimental details).</p><p>We fine-tune the pre-trained model on both the CIFAR-10 and CIFAR-100 datasets using DP-SGD. As in Section 3, we use a constant learning rate without additional regularization techniques, although we do apply data augmentation with augmentation multiplicity = 16. We explore two fine-tuning scenarios, one where we fine-tune all layers of the model simultaneously, and a second where we only train the final classifier layer. We show our results with the WRN-28-10 model in <ref type="table">Table 5</ref>. On CIFAR-10, we achieve a new SOTA test accuracy of 94.7% under (1, 10 ?5 )-DP, exceeding the previous SOTA of 94.3% at the same privacy budget from <ref type="bibr" target="#b81">Yu et al. (2021b)</ref>. We also provide test accuracies at a range of different privacy budgets for both CIFAR-10 and CIFAR-100. Under (8, 10 ?5 )-DP, we reach 96.7% on CIFAR-10 and 81.8% on CIFAR-100. On this task, fine-tuning all the layers of the model simultaneously outperforms fine-tuning only the classifier layer.</p><p>We provide additional results for fine-tuning on CIFAR-10 with the WRN-40-4 model in Appendix B.3. While the 40-4 model also performs well and reaches a test accuracy of 95.6% under (8, 10 ?5 )-DP, the 28-10 model performs better at all values considered. To interpret these results, we note that the WRN-28-10 is a stronger pre-trained model, achieving 62.4% top-1 accuracy on the down-sampled ImageNet validation set, while the WRN-40-4 achieves 57.4% top-1 accuracy. This phenomenon was consistent across all our fine-tuning <ref type="table">Table 5</ref> | CIFAR-10 and CIFAR-100 test accuracies when fine-tuning with DP-SGD a 28-10 Wide-ResNet pretrained on ImageNet (down-sampled to 32 ? 32). We report the median accuracy across 5 runs. experiments: models which achieved stronger performance on the pre-training task consistently achieved higher test accuracies after private fine-tuning. Additionally, in Appendix B.4, we provide results for privately fine-tuning on CIFAR-10 using a 40-4 Wide-ResNet model pre-trained non-privately on CIFAR-100, where we again show consistent improvements over previous baselines <ref type="bibr" target="#b36">(Luo et al., 2021)</ref> at all values of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Fine-tuning on ImageNet</head><p>In this section, we fine-tune image classifiers with DP-SGD on the ImageNet dataset, using models pre-trained either on JFT-300M or JFT-4B. JFT-300M is an internal dataset of 300 million labelled images from 18k classes, while JFT-4B contains 4 billion images from 30k classes <ref type="bibr" target="#b64">(Sun et al., 2017)</ref>. Pre-training on JFT-300M or JFT-4B has been recently used by several authors to achieve SOTA performance when fine-tuning on ImageNet without privacy <ref type="bibr">(Brock et al., 2021b;</ref><ref type="bibr">Dosovitskiy et al., 2020;</ref><ref type="bibr" target="#b85">Zhai et al., 2021)</ref>. To preserve privacy guarantees when fine-tuning on ImageNet, we removed all images from both JFT-300M and JFT-4B that were exact or near-duplicates of ImageNet images across common data augmentations <ref type="bibr" target="#b29">(Kolesnikov et al., 2020)</ref>. <ref type="bibr">3</ref> We first use the NF-ResNet architecture (Brock et al., 2021a) (See Section 3.3), which we pre-train on JFT-300M for 10 epochs with the cross entropy loss, using the training procedure described in <ref type="bibr">Brock et al. (2021b)</ref>. <ref type="bibr">Interestingly, Brock et al. (2021b)</ref> found that NF-ResNets significantly outperformed batch-normalized ResNets when fine-tuning from JFT-300M to ImageNet without privacy. We use the same training, validation and test splits for ImageNet as in Section 3.3. We remove all explicit regularizers from the model such as weight decay or dropout. When fine-tuning on ImageNet, we explore both fine-tuning all layers of the network, as well as fine-tuning only the final classifier layer. Unless otherwise specified, we fine-tune using DP-SGD with a privacy budget of (8, 8 ? 10 ?7 )-DP. Because of our computational constraints, we could only afford to run limited sweeps with a single random seed to identify the best hyper-parameters. We also do not use augmentation multiplicity to avoid a further increase in the computational cost of training, nor do we use any data augmentation.</p><p>We first compare fine-tuning all layers of the model to fine-tuning only the final classifier layer, for a range of NF-ResNet model depths. We use a batch size of 1024 and a fixed noise parameter = 0.6, which corresponds to roughly 136 training epochs. We tune the learning rate independently for each model. Remarkably, we find in <ref type="figure">Figure 4</ref> that an NF-ResNet-50 can reach a top-1 accuracy of 75.4% and top-5 accuracy of 93.0% when fine-tuning only the final classifier layer. This far exceeds the previous best reported accuracy for private fine-tuning on ImageNet of 47.8%, achieved under a privacy budget of (10, 10 ?6 )-DP .  Note that  used Places-365 <ref type="bibr" target="#b89">(Zhou et al., 2017)</ref> as the pre-training dataset, which is a significantly smaller dataset compared to JFT-300M. In <ref type="figure">Figure 4</ref>, we also see consistent benefits from increasing the model depth, both when fine-tuning only the last layer and when fine-tuning all layers simultaneously. For example, the NF-ResNet-200 model achieves a top-1 accuracy of 79.9% when fine-tuning only the final layer.</p><p>We note that, in <ref type="figure">Figure 4</ref>, fine-tuning only the final classifier layer consistently performed slightly better than fine-tuning the whole network. We therefore only report results when fine-tuning the final classifier layer for our remaining experiments on ImageNet. This also considerably reduces the computational cost of these experiments, since the features can be pre-computed only once and stored on disk -assuming that no data augmentation is used as is the case for our experiments in this section. This enables us to use a very large batch-size of = 2 18 = 262144 for the rest of our ImageNet experiments.</p><p>We provide the performance of NF-ResNet-200 at a range of privacy budgets in <ref type="figure" target="#fig_3">Figure 5</ref>, where we compare the effect of pre-training either on JFT-300M or on the larger JFT-4B. We pre-train on JFT-300M for 10 epochs and on JFT-4B for 1 epoch. When privately fine-tuning on ImageNet, we set = 4000 (which corresponds to = 9.1) when = 8. We noticed in Section 3.2 that the optimal number of training iterations scaled approximately linearly with when keeping other hyper-parameters constant. We use this scaling rule for these experiments to reduce the cost of tuning hyper-parameters. For example, at = 4 we use half the number of training iterations as our best run with = 8. The noise parameter was scaled accordingly, while using the same learning rate. From <ref type="figure" target="#fig_3">Figure 5</ref>, we see that using a larger and more diverse pre-training dataset consistently improves the accuracy across all values of . After pre-training on the larger JFT-4B dataset and scaling up the batch size, the NF-ResNet-200 model achieves a top-1 accuracy of 82.2% and top-5 accuracy of 96.1% under (8, 8 ? 10 ?7 )-DP. Note that these experiments required a substantial number of training epochs at = 8 (roughly 800 epochs at = 9.1), significantly larger than is commonly used when fine-tuning in non-private training.</p><p>In all our fine-tuning experiments, we found that a stronger pre-trained model, achieved either through using a larger model or through using a larger pre-training dataset, always improved fine-tuning performance. Indeed, shortly after the first version of our paper was released, <ref type="bibr" target="#b43">Mehta et al. (2022)</ref> published a study on differentially private fine-tuning on ImageNet using a large ViT model pre-trained on JFT-4B, in which they achieve 81.1% top-1 accuracy under (1, 10 ?6 )-DP and 81.7% under (4, 10 ?6 )-DP. Our best results when fine-tuning on ImageNet are achieved with an NFNet-F3 (Brock et al., 2021b) pre-trained for 2 epochs on JFT-4B, which we fine-tune for = 1000 training iterations using a batch size = 2 18 . We show these NFNet-F3 results in <ref type="table" target="#tab_6">Table 6</ref>. We achieve a top-1 accuracy of 86.7% and top-5 accuracy of 98.0% under (8, 8 ? 10 ?7 )-DP. Most remarkably, this network also achieves a top-1 accuracy of 83.8% under a much tighter privacy budget of (0.5, 8 ? 10 ?7 )-DP.</p><p>For comparison, fine-tuning the same pre-trained NFNet-F3 without privacy using SGD with Momentum, AGC, ) achieves 88.5% top-1 accuracy on ImageNet, which is only 1.8% higher than the accuracy we achieve with DP at = 8, and 4.7% higher than the accuracy we obtain at = 0.5. We conclude that our results significantly reduce the gap between private and non-private training on ImageNet when fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Fine-tuning on Places-365</head><p>In this section, we provide results for fine-tuning with DP on the Places-365 dataset <ref type="bibr" target="#b89">(Zhou et al., 2017)</ref>. Places-365 is a dataset for scene recognition containing 1.8 million training images from 365 scene categories. We use the NF-ResNet-50 model <ref type="bibr">(Brock et al., 2021a)</ref> in this section, which is pre-trained on JFT-300M as described in Section 4.2. The current non-private SOTA on this dataset is 60.7%, obtained by a large Vision Transformer (Dosovitskiy et al., 2020) after pre-training on a labelled dataset of 3.6 billion public Instagram images <ref type="bibr" target="#b59">(Singh et al., 2022)</ref>. To the best of our knowledge, there is no established SOTA for training on Places-365 with DP.</p><p>We fine-tune both with and without privacy, in order to illustrate the scale of the privacy-utility trade-off. For both standard and private fine-tuning, no data augmentation is applied and the learning rate is kept constant throughout training. The batch size is set to 1024 for non-private training, and to 4096 for private training. We do not use any weight decay. We tune the learning rate independently for each experiment using a single seed. When using DP-SGD, we set = 5 ? 10 ?7 . We also compare the performance of fine-tuning all layers and fine-tuning only the final classifier layer. When training all layers with DP-SGD, we consider a single noise parameter = 1, while when fine-tuning the classifier layer we select the best result from ? {1, 2, 3}.</p><p>We present our results in <ref type="table">Table 7</ref>, where we provide the validation accuracy when training with DP-SGD under (8, 5 ? 10 ?7 )-DP, and without privacy using SGD without momentum. Training all layers outperforms training the classifier layer for both private and non-private training. Our non-private baseline achieves a top-1 validation accuracy of 57.0%, which is within a few percent of the current non-private SOTA on this dataset, while our best private model achieves a top-1 accuracy of 55.1%, only 1.9% lower than our non-private baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">The Interplay between Noise, Batch Size, Compute Budget and Learning Rate</head><p>Carefully tuning the DP-SGD hyper-parameters can significantly boost performance. However intuitions from tuning non-private models do not always carry over to private training. For example, in <ref type="figure">Figure 2</ref> we observed an improvement of ?8% on the validation accuracy after increasing the batch size and re-tuning the learning rate and noise parameter . By contrast, in non-private training under a constant epoch budget, the test accuracy is usually either constant or monotonically decreasing as the batch size rises <ref type="bibr" target="#b18">(Goyal et al., 2017;</ref><ref type="bibr" target="#b55">Shallue et al., 2018;</ref><ref type="bibr" target="#b61">Smith et al., , 2017</ref>. Below we present some of our findings from an empirical analysis on the impact of different hyper-parameters on the performance of models trained with DP-SGD. Training Accuracy (%) (c) <ref type="figure">Figure 6</ref> | Training WRN-16-4 on CIFAR-10 at batch size 4096 under (8, 10 ?5 )-DP. (a) There is an optimal noise parameter, ? 3.0, which maximizes validation accuracy. Note that we tune the learning rate independently for each . (b) Since the training iteration budget is a function of the batch size and the noise parameter, the optimal noise parameter also implies an optimal budget of training iterations, ? 2500. (c) The optimal noise parameter/training iteration budget maximizes training accuracy as well as validation accuracy.</p><p>In this section, we only provide experiments on CIFAR-10, using models trained from random initialization without extra data, using the training pipeline described in Section 3.1. On this smaller benchmark, we could perform a rigorous empirical evaluation with thorough hyper-parameter sweeps. By contrast, on large datasets (e.g., ImageNet), we were unable to tune hyper-parameters to maximize performance, and instead tuned the noise parameter to ensure the training iteration budget was feasible within our computational constraints.</p><p>There is an optimal noise parameter at fixed batch size, implying an optimal budget of training iterations. Given a privacy budget ( , ) and a batch size , the noise parameter determines the maximum budget of training iterations . We now investigate whether it is always better to increase the value of and train longer, or if there is an optimal value of the noise parameter beyond which the performance of DP-SGD degrades. In <ref type="figure">Figure 6</ref>(a), we consider a batch size = 4096 on the WRN-16-4 under (8, 10 ?5 )-DP, and we study the validation accuracy achieved across a range of different noise parameters. We do not use data augmentation (or augmentation multiplicity) in these experiments, and we re-tune the learning rate on the validation set for each choice of . We find that there is an optimal value ? 3.0 that achieves the highest validation accuracy.</p><p>The fact there is an optimal value for the noise parameter implies that there also exists an optimal value for the number of training iterations (since and determine , given a privacy budget), which we illustrate in <ref type="figure">Figure 6</ref>(b), where the validation accuracy reaches its maximal value for ? 2500. This observation also holds for the accuracy on the training set, as illustrated in <ref type="figure">Figure 6</ref>(c). By contrast, increasing the number of training iterations almost always achieves higher training accuracy in non-private training .</p><p>The optimal epoch budget increases with the batch size. In <ref type="figure">Figure 2</ref>, we showed that increasing the batch size improves the accuracy of DP-SGD (after re-tuning other hyper-parameters). Meanwhile, in <ref type="figure">Figure 6</ref> we found that, at a fixed batch size, there is an optimal noise parameter which implies a corresponding optimal budget of training iterations . In <ref type="figure" target="#fig_4">Figure 7</ref>(a), we study the same WRN-16-4 model/training pipeline described above, and we plot how the optimal iteration budget (which maximizes validation accuracy after tuning the noise parameter and learning rate) depends on the batch size. We find that the optimal iteration budget falls rapidly when the batch size is small, but is roughly constant when the batch size is large.</p><p>However if the number of training iterations is constant, larger batch sizes will perform more training epochs. Therefore, in <ref type="figure" target="#fig_4">Figure 7</ref>(b), we show how the corresponding optimal epoch budget depends on the batch size. We find that the optimal epoch budget is roughly constant when the batch size is small, but increases proportional to the batch size when the batch size is large. We conclude that, although large batch sizes achieve superior accuracies with DP-SGD, very large batch sizes also require more compute. We recommended that practitioners who are compute constrained choose a moderate batch size in practice (e.g., ? 2048 for this dataset/architecture). Note we provide the train/validation accuracies corresponding to <ref type="figure" target="#fig_4">Figure 7</ref> in <ref type="figure">Figure 2</ref>. The optimal learning rate is proportional to batch size for small batch sizes, but constant for large batch sizes.</p><p>The optimal learning obeys a linear scaling rule for small batch sizes. In <ref type="figure" target="#fig_4">Figure 7</ref>(c), we plot the relationship between the optimal learning rate (after tuning the noise parameter) and the batch size. When the batch size is small, the optimal learning rate is proportional to the batch size, while when the batch size is large, the optimal learning rate is constant. Similar scaling behaviour has previously been observed in non-private training <ref type="bibr" target="#b38">(Ma et al., 2018;</ref><ref type="bibr" target="#b39">McCandlish et al., 2018;</ref>, while linearly scaling the learning rate with the batch size was suggested as a heuristic for private training by <ref type="bibr" target="#b71">Tram?r and Boneh (2021)</ref>, although as we show this scaling law holds only up to a certain batch size. Notice that the optimal epoch budget in <ref type="figure" target="#fig_4">Figure 7</ref>(b) begins to rise at the same batch size where the optimal learning rate ceases to rise in <ref type="figure" target="#fig_4">Figure 7</ref>(c).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>Privacy and fairness considerations. We have developed a methodology which achieves high accuracy on academic image classification datasets with DP, however using this methodology for a real-world application on sensitive data would involve several important additional considerations. Although in this paper we consider a range of privacy budgets with ranging from below 1 to 8, choosing the privacy budget for a real-world application is non-trivial and would depend on the specific privacy and utility requirements <ref type="bibr" target="#b2">(Abowd et al., 2020)</ref>. In addition, our experiments focus on providing record-level privacy at the level of individual images. In scenarios where a single individual can contribute multiple images to the training data, user-level privacy may be preferable <ref type="bibr" target="#b42">(McMahan et al., 2018b)</ref>. Furthermore, several authors have shown that differentially private training can potentially reduce the accuracy of models on under-represented subgroups in the dataset <ref type="bibr">(Bagdasaryan et al., 2019;</ref><ref type="bibr">Carlini et al., 2019;</ref><ref type="bibr" target="#b65">Suriyakumar et al., 2021;</ref><ref type="bibr">Tran et al., 2021)</ref>, and therefore deploying any application with DP would require careful evaluation, particularly when the dataset is imbalanced. Finally, in Section 4 we demonstrate that pre-training our networks on large public/non-sensitive datasets significantly enhances the performance achievable by DP-SGD, however this methodology may introduce additional privacy risks if the dataset used for pre-training contains sensitive data (Prabhu and Birhane, 2020).</p><p>The computational cost of private training. We consistently found that private training requires significantly more compute than non-private training to achieve optimal performance. The computational cost of training with DP-SGD can be broken down into two components: the cost of performing a single parameter update given a batch size, and the number of parameter updates that need to be performed for the model to reach a high accuracy. The cost of a single DP-SGD update is largely dominated by the cost of computing per-example gradients, which is slower than computing the averaged gradient and also requires more memory. While recent deep learning frameworks like JAX <ref type="bibr">(Bradbury et al., 2018)</ref> have significantly reduced these overheads, DP-SGD remains slower than SGD in our experience. For example, we observe that computing a parameter update at batch size 1024 for a NF-ResNet-50 on a TPUv3 is about 9? slower with DP-SGD using our implementation than with standard SGD. Furthermore, we found that DP-SGD also required more training epochs than non-private training to achieve optimal performance. This observation is exacerbated by the use of large batch sizes and/or large augmentation multiplicities, both of which further increase the computational cost of training. We note that this computational cost is significantly reduced on tasks where fine-tuning only the last layer is sufficient to obtain high accuracy. In our experiments however, we typically found fine-tuning the whole model to be optimal when transferring between datasets other than from JFT-300M/4B to ImageNet.</p><p>Correctness. While differentially private algorithms provide strong formal privacy certificates, such guarantees are only realized if the algorithm is correctly implemented, which can be prone to human errors arising from minor variations in the algorithm <ref type="bibr" target="#b37">(Lyu et al., 2017;</ref><ref type="bibr" target="#b72">Tramer et al., 2022)</ref>. By releasing our implementation we aim to make the code used in this paper verifiable by the DP community. Additionally, we document key implementation details in Appendix A.1, and we validate in Appendix A.2 that the claimed privacy guarantees of our implementation are not contradicted by DP lower bounds obtained using membership inference attacks <ref type="bibr" target="#b72">(Tramer et al., 2022)</ref>. Our implementation includes unit-tests, and has undergone two independent internal technical reviews for correctness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We have shown how to unlock high-accuracy image classification with differential privacy by scaling up models, computational budgets, and pre-training data in order to significantly reduce the utility gap between private and non-private image classification on academic datasets. For instance, we achieve 83.8% top-1 accuracy on ImageNet under a (0.5, 8 ? 10 ?7 )-DP guarantee. All of our results are obtained using standard architectures popular in the computer vision community with minimal modification, which should make our methodology easy to re-use in existing pipelines. We hope that our insights will significantly reduce the performance penalty that arises when applying differentially private machine learning in real-world applications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementing and Auditing DP-SGD</head><p>All the experiments reported in this paper use a JAX <ref type="bibr">(Bradbury et al., 2018)</ref> implementation of DP-SGD based on JAXline <ref type="figure">(Babuschkin et al., 2020)</ref>, a re-usable framework for distributed model training and evaluation. Our full implementation, including launch scripts for reproducing experiments that do not depend on models pre-trained on JFT-300M, is available at https://github.com/deepmind/jax_privacy</p><p>Besides enabling reproducibility of our results, another important reason for open sourcing our code is to allow the differential privacy community to verify our implementation of DP-SGD. To help navigate our code base, Appendix A.1 provides an in-depth description of how our code parallelizes the computation of privatized gradients across many devices when using virtual batching and multiple augmentations. Furthermore, Appendix A.2 describes how we used the methodology proposed by <ref type="bibr" target="#b72">Tramer et al. (2022)</ref> to empirically test our implementation against membership inference attacks.</p><p>Our implementation leverages the default R?nyi DP privacy accountant for DP-SGD provided by the TensorFlow Privacy <ref type="bibr" target="#b17">(Google, 2018)</ref> implementation. As a minor technical note, we remark that this accountant assumes that at each iteration mini-batches are sampled with replacement from the entire dataset by including every training example with probability , while in practice we sample mini-batches using a random shuffling scheme, such that each example is sampled once per training epoch. This discrepancy commonly arises in empirical studies of DP-SGD, as well as in popular open-source implementations <ref type="bibr" target="#b17">(Google, 2018;</ref><ref type="bibr" target="#b79">Yousefpour et al., 2021)</ref>. The main driver behind this discrepancy is the pervasiveness of shuffling-based mini-batching in deep learning frameworks. Obtaining tight numerical accounting methods for shuffled DP mechanisms based on Gaussian perturbations remains an open problem <ref type="bibr" target="#b5">(Feldman et al., 2021;</ref><ref type="bibr" target="#b30">Koskela et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Implementation Details</head><p>Algorithm ? , // Synchronize average gradient across devices ? +?? // Numerically stable averaging across accumulation steps return // Each device gets the same gradient Algorithm 1 provides a high-level description of how our DP-SGD implementation computes the privatized gradient used in each model update step. The structure of the code is informed by the way model training pipelines are implemented in JAXline. The implementation is parallelized across devices, where each device runs a copy of Algorithm 1. To extract the maximum possible throughput from the implementation, each device processes training examples in batches of size , where this parameter is adjusted depending on the memory available in each device and the size of model gradients for the present architecture. To accommodate settings where the desired batch size for a single model update is larger than ? , our implementation incorporates gradient accumulation (i.e. virtual batching) where gradient accumulation steps are performed before each model update, giving a total batch size = ? ? .</p><p>As input to the gradient computation step, each device receives the current model parameters (which are identical across devices), the desired clipping norm and noise standard deviation , and their device identifier ? {1, . . . , }. In addition, each device has access to ? training examples {( , , , , , ) : ? [ ], ? [ ]}, and i.i.d. samples from a standard Gaussian distribution 1 , . . . , . Crucially, these samples are shared across devices, meaning that noise is independent across gradient accumulation steps but not across devices. This is enforced in our implementation by broadcasting the same pseudo-random number generator key to all devices -this is preferred over having a different PRNG key per-device because it makes the pipeline more reproducible across training infrastructures with different numbers of devices.</p><p>In the innermost loop of Algorithm 1, client computes the individual contribution , , of a single example , , (where indexes the accumulation step and the local batch-size). As discussed in Section 3.1, in our algorithm this contribution is based on the average parameter gradient with respect to random augmentations of , , .</p><p>These augmentations are returned by independent calls to the augment subroutine. The result of this average is then clipped to a maximal 2 norm of by the clip function and then normalized by (cf. Equation <ref type="formula" target="#formula_3">(3)</ref>).</p><p>This results in a contribution , , to the model update with norm bounded by 1, which is then averaged locally over on device to produce , . We note that although the loop over ? [ ] is presented in Algorithm 1 as a sequential computation for convenience, in reality our implementation uses hardware parallelism offered by modern accelerators -this means that as long as the device can process ? examples in parallel, the cost of computing , is constant in these parameters.</p><p>After computing the average of clipped gradient contributions , , each device adds appropriately calibrated Gaussian noise to obtain?, -we emphasize again that in step each device shares the same random noise sample, so the noise adding process is not independent across devices. At this point devices synchronize their updates by computing the average of?, over ? [ ]. After this step, each device has the same averaged noisy gradient?. Finally, each device updates their local copy of the accumulated gradient by using Welford's incremental averaging algorithm for numerical stability <ref type="bibr" target="#b75">(Welford, 1962)</ref>.</p><p>That Algorithm 1 provides a correct implementation of the privatized gradients required by DP-SGD follows by comparing the following result to Equation (3).</p><p>Lemma A.1. Each device participating in Algorithm 1 obtains the same noisy gradient given by</p><formula xml:id="formula_5">= ? ? ? ? ? ? ? 1 ?? =1 ?? =1 ?? =1 1 clip 1 ?? =1 ?L ( , augment( , , ), , , ) ? ? ? ? ? ? ? + ,<label>(5)</label></formula><p>where ? N (0, ).</p><p>Proof. By construction it is clear that each device gets the same gradient. Now let ( ) be the value of (on an arbitrary device) at the end of iteration of the outermost loop. By induction on we can show that ( ) = 1 =1? : it is clear that (1) =?1, and</p><formula xml:id="formula_6">( +1) = ( ) +?+ 1 ? ( ) + 1 = ( ) +?+ 1 + 1 = 1 + 1 +1 ?? =1? ,</formula><p>where the last identity follows by the inductive hypothesis. Thus, at the end of the algorithm each device gets = ( ) = 1 =1?. Unrolling the computations done at every accumulation step on every device we get:</p><formula xml:id="formula_7">= 1 ?? =1= 1 ? ?? =1 ?? =1?, = 1 ? ?? =1 ?? =1 , + ? ? ? ?? =1 ?? =1 = 1 ? ? ?? =1 ?? =1 ?? =1 , , + ? ? ?? =1</formula><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>24</head><p>Unlocking High-Accuracy Differentially Private Image Classification through Scale</p><p>The result now follows by observing that the first term in the sum above equals the first term in Equation <ref type="formula" target="#formula_5">(5)</ref> and 1 ? =1 ? N (0, ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Privacy Lower Bounds via Membership Inference Attacks</head><p>Inspired by recent work on auditing DP algorithms with privacy attacks <ref type="bibr" target="#b25">(Jagielski et al., 2020;</ref><ref type="bibr">Nasr et al., 2021;</ref><ref type="bibr" target="#b72">Tramer et al., 2022)</ref>, we carry out membership inference attacks on models trained with Algorithm 1. The extent to which these attacks are successful can be used to provide (empirical) lower bounds on the privacy guarantees afforded by our implementation, which can then be compared with the nominal upper bound. Note that this type of test is incomplete; a failure to find a violation of the upper bound does not rule out the possibility that one exists. However, along with independent code reviews and unit testing, it provides another signal that our implementation of DP-SGD is correct.</p><p>DP lower bounds via hypothesis testing. Given two datasets, and = ? { }, that differ by a single data point , a model trained with a DP algorithm reduces an adversary's ability to infer via a simple hypothesis test whether the model was trained on or . More formally, if an algorithm is ( , )-DP then it must satisfy ln ( 1? ? ) ? <ref type="bibr" target="#b19">(Hall et al., 2013)</ref>, where and denote the Type I and Type II errors of the hypothesis testing procedure. If we can construct datasets and such that this bound is violated, we can be sure the algorithm does not provide ( , )-DP; evaluating ln ( 1? ? ) through a membership inference attack will give a valid lower bound of . In practice, the test relies on comparing the loss (distribution) of point under models trained with and .</p><p>Overview of the attack. Note that DP is a worst-case guarantee, and so we are free to design our datasets and in any way we choose. In addition, our algorithm provides the same privacy guarantees for many setting of its hyper-parameters. Our attack operates in two phases: in phase I, we design a learning problem that we expect will maximize the ability to infer membership, while in phase II, we use the procedure set out by <ref type="bibr" target="#b72">Tramer et al. (2022)</ref> to run a membership inference attack to find a (statistically valid) lower bound for . In phase I, we sweep over different hyper-parameter configurations and choices for , to find a choice that is likely to maximize the ratio 1? ? / when the model is trained with Algorithm 1. In phase II, we use the best configuration from phase I and train a large number of models to ensure the lower bound is statistically valid with enough confidence. For completeness, we repeat the same procedure with two dataset sizes (| | ? {100, 60 }) and four settings of the nominal privacy parameters: ? {1, 2, 4, 8}, where we set = 1 /| |.</p><p>Experimental details. Throughout, we will use a simple LeNet classifier <ref type="bibr" target="#b33">(LeCun et al., 1998)</ref> as the trained model and take from the MNIST dataset. The hyper-parameters and choices of we evaluated in phase I are given in <ref type="table" target="#tab_10">Table 8</ref>. Given a choice of ( , ), we find a choice of hyperparameters that maximizes distinguishability between models trained on and as follows: for each hyperparameter configuration, we train 1K models on and 1K models on , where the only randomness originates from the noise added from DP-SGD. In particular, all models are initialized with the same parameters, as prior work has shown random initialization weakens privacy attacks <ref type="bibr">(Balle et al., 2022;</ref><ref type="bibr" target="#b25">Jagielski et al., 2020)</ref>. We then record the loss on for each model trained on and on , and fit two Gaussians over these histograms. After this, we record the total variation distance between these two Gaussians <ref type="bibr" target="#b47">(Nielsen and Sun, 2018)</ref>, and choose the hyperparameter configuration that maximizes this distance. The choice of learning rate, clipping norm, and number of model updates that maximize our ability to infer if was included in training varied for each ? {1, 2, 4, 8} and | | ? {100, 60 }. However, we found that selecting to be a blank image was a consistently better choice than using uniform noise or mislabeling an MNIST test set example.</p><p>In phase II, we repeat the procedure set out by <ref type="bibr" target="#b72">Tramer et al. (2022)</ref> for each choice of privacy parameters, dataset size and best hyper-parameters from phase I. For both and we train 500K models, reserving the first 10K models on each setting as the set from which we find a threshold that maximizes the ratio between 1 ? and , and the remaining models are used to evaluate this chosen threshold and report the lower bound. To gain statistical confidence in our lower bounds we compute the lower bound of the true positive rate, 1 ? , and upper bound of the false positive rate, , over the remaining 980K models using Clopper-Pearson confidence intervals. With an appropriate choice of significance level this gives us a probabilistic lower bound with 99.9% confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results.</head><p>Our results are given in <ref type="table" target="#tab_11">Table 9</ref>; we did not find any violation of our reported ( , )-DP guarantees. Note that our lower bounds when using | | = 100 are substantially tighter than when training with | | = 60for example at nominal &gt; 1 training on a small dataset yields lower bounds which are over 2? stronger. We also provide membership inference AUC and advantage (1 ? ? ) scores for inferring if was or was not included in training over the 980K models, and give upper bounds to the membership advantage that can be derived in closed form from and (c.f. <ref type="bibr" target="#b23">Humphries et al. (2020)</ref>). Throughout our entire experiment we chose to train models without augmentation multiplicity to expedite experimentation, however, we ran an additional experiment for = 1 and | | = 100 where we turned on augmentation multiplicity during training with 16 augmentations per image, and found the lower bound was almost unchanged.  Note, it is unlikely that taking to be the MNIST dataset is the optimal choice for maximizing privacy lower bounds; one could imagine taking to be a pathological dataset with the same pixel value everywhere, and taking to be an image with different pixel values, would improve distinguishability between models trained on or . However, our aim is to verify that the end-to-end implementation of our DP training procedure is correct, including the data pre-processing part of the pipeline. Data pre-processing (including augmentations) may have a null effect on such a pathological dataset, meaning if an error was introduced in this stage of the training pipeline it would not be captured by our membership attack. Therefore, we chose to use the MNIST dataset to increase the likelihood that any errors from data pre-processing pipeline will be reflected and included in our membership attack. We leave the design of datasets to elicit the best lower bounds for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Additional Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Choice of the Clipping Norm under the Modified DP-SGD Update</head><p>In the DP-SGD update as described in Equation <ref type="formula" target="#formula_2">(2)</ref>, the clipping norm determines the norm of the parameter update, and therefore affects the optimal choice of the learning-rate. This results in an undesirable dependency between the clipping norm and the learning rate, which can make the performance of DP-SGD appear to be sensitive to the choice of the clipping norm when the learning rate is not carefully tuned <ref type="bibr" target="#b34">(Li et al., 2021)</ref>. To decouple the effect of the learning rate and the clipping norm, we instead use a slightly modified version of the DP-SGD update as described in Equation <ref type="formula" target="#formula_3">(3)</ref>, where the learning rate absorbs a factor of . Using this update, performance becomes less sensitive to the choice of clipping norm, as we demonstrate in <ref type="figure" target="#fig_5">Figure 8</ref> where we show the accuracy of the WRN-16-4 over a range of clipping norms and learning rates at batch size 4096 and augmentation multiplicity 16. More importantly, the optimal choice of the learning rate does not depend on the clipping norm under this modified DP-SGD update, as long as the clipping norm is lower or equal to 1. Therefore, to reduce the cost of hyper-parameter tuning, for all of our experiments in this paper, we fix = 1.</p><p>2 6 2 4 2 2 2 0 2 2 2 4 2 6</p><p>Clipping Norm C </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. The Optimal Model Depth Depends on the Privacy Budget and Training Setup</head><p>Scaling the depth of neural networks has been crucial in achieving good performance with non-private training <ref type="bibr">(Brock et al., 2021b;</ref><ref type="bibr" target="#b20">He et al., 2016;</ref><ref type="bibr" target="#b67">Tan and Le, 2019)</ref>. In this paper, we were interested in exploring whether we could leverage the same benefits of deep models when training with DP-SGD. However, in our initial experiments on WRN models for CIFAR-10 classification without extra data under (8, 10 ?5 )-DP, we found that both training and validation set performance degraded for networks deeper than the WRN-16-4.</p><p>To understand this, in <ref type="figure">Figure 9</ref>, we train a range of Wide-ResNets at different depths (from 16 to 100 layers) using a fixed noise parameter = 2 and a batch size of 4096 until exhausting a very large privacy budget of (64, 10 ?5 )-DP, and track the performance of these models during training. We emphasize that = 64 is too large to provide a meaningful notion of privacy, but our goal here is to gain an understanding for the training dynamics. In our initial experiment, we train without data augmentation. We find that the deeper models start converging slower than the shallower models, likely due to the added noise in DP-SGD. However, when trained for long enough (i.e., for a sufficiently large privacy budget), the deeper models outperform the shallower models. This is illustrated in <ref type="figure">Figure 9</ref>(a), where we show that at low values (which corresponds to early in training for this experiment), the WRN-16-4 outperforms all deeper models, while at high values (i.e., late in training), some of the deeper models start to outperform the shallower models.</p><p>Interestingly, we find that using data augmentation with large augmentation multiplicities significantly speeds up convergence of the deeper models. Performing the same experiment as before using augmentation multiplicity = 16, we see in <ref type="figure">Figure 9</ref>(c) that even early in training at = 8, the WRN-40-4 significantly outperforms the WRN-16-4. Late in training, at larger values of , a much deeper network is optimal compared to when not using augmentation multiplicity. We note this effect of speeding up convergence of deeper models is not simply due to using data augmentation (See <ref type="figure">Figure 9</ref>(b) using augmentation multiplicity 1).</p><p>We conclude from these results that the optimal network depth depends on the privacy budget, as well as other choices made during training. We notice this in <ref type="table">Table 3</ref>, where at a small privacy budget of (1, 10 ?5 )-DP, the WRN-16-4 slightly outperforms the WRN-40-4. For larger privacy budgets, we find the WRN-40-4 performs better. Additionally, we find the optimal network depth to also depend on whether we train without using any extra data, or if we privately fine-tune a pre-trained network. In the fine-tuning setting, we find larger models to consistently perform better than shallower networks, even at small values, as shown throughout Section 4. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3. Private Fine-Tuning on CIFAR-10 Using a WRN-40-4 Model Pre-trained on ImageNet-32</head><p>In Section 4.1, we provided results for privately fine-tuning a WRN-28-10 on CIFAR-10 and CIFAR-100, which was pre-trained on ImageNet-32. We now provide additional results for this same task using a pre-trained WRN-40-4 model instead, and with the same experimental setup as in Section 4.1. We show results in <ref type="table" target="#tab_0">Table 10</ref>.</p><p>We fine-tuned all layers of the model simultaneously, which we found to perform better than fine-tuning only the last layer for this experiment. We show that we achieve 95.6% test accuracy under (8, 10 ?5 )-DP. As mentioned in Section 4.1, we find that the WRN-28-10 to outperform the WRN-40-4 at all values of considered, likely due to the WRN-28-10 model being a better pre-trained model. In Section 4.1, we provided results for privately fine-tuning WRNs on CIFAR-10 and CIFAR-100 using a model pre-trained on ImageNet-32. We now provide additional results, when fine-tuning with DP-SGD on CIFAR-10, using a model pre-trained without privacy on CIFAR-100. We compare our results with <ref type="bibr" target="#b36">Luo et al. (2021)</ref>, who provide the current SOTA for this task. We use the WRN-40-4 model, which we pre-train on CIFAR-100 using SGD with momentum for 100K iterations with a batch size of 128. We use the same fine-tuning procedure on CIFAR-10 as in Section 4.1 (See Appendix C), and use batch size 4096 and augmentation multiplicity = 16.</p><p>We present our results in <ref type="table" target="#tab_0">Table 11</ref>. We fine-tuned all layers of the model simultaneously, which we found to perform better than fine-tuning just the last layer for this experiment, similar to Section 4.1. As before, we outperform previous SOTA results for this task at all privacy budgets considered. In particular we achieve a test accuracy of 80.4% under (1, 10 ?5 )-DP and a test accuracy of 89.0% under (8, 10 ?5 )-DP. We note however that the accuracies achieved on CIFAR-10 after pre-training on CIFAR-100 are significantly lower than those obtained after pre-training on ImageNet. This emphasizes the importance of using a strong pre-trained model if we wish to achieve performance competitive with non-private training. In <ref type="figure">Figure 6</ref>, we showed that on the WRN-16-4, there is an optimal noise scale, and consequently an optimal compute budget, for a fixed batch size of 4096. To provide additional evidence of this, we show a similar plot in <ref type="figure" target="#fig_6">Figure 10</ref> on a WRN-40-4 trained on CIFAR-10 under (8, 10 ?5 )-DP and using a batch size of 16384 (with all other experimental details the same as in <ref type="figure">Figure 6</ref>). We found this property to hold also at other batch sizes. In <ref type="figure" target="#fig_4">Figure 7</ref>, we showed how the optimal budget of training iterations and epochs and the optimal learning rate varied with the batch size on the WRN-16-4 under (8, 10 ?5 )-DP. To provide additional evidence of the main takeaways from <ref type="figure" target="#fig_4">Figure 7</ref>, we provide additional experiments under the same experimental setup with the WRN-40-4 model in <ref type="figure" target="#fig_7">Figure 11</ref> where we observe qualitatively the same behaviour as in <ref type="figure" target="#fig_4">Figure 7</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Additional Experimental Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Model Details</head><p>Wide-ResNet models. We use the Wide-ResNet model family from <ref type="bibr" target="#b84">Zagoruyko and Komodakis (2016)</ref> for all of our experiments on CIFAR-10 and CIFAR-100, and replace all the batch normalization layers with group normalization layers with the number of groups set to 16. We use Gaussian initialization for all weight parameters with variance (1/fan-in) <ref type="bibr" target="#b15">(Glorot and Bengio, 2010)</ref>. We also use Weight Standardization for each convolutional layer as follows:?,</p><formula xml:id="formula_8">= , ??, ? ,? ? fan-in ,</formula><p>where?, ? and?, ? denote the empirical mean and the standard deviation calculated over the fan-in extent for the convolutional layer . This is similar to the implementation in <ref type="bibr">Brock et al. (2021a)</ref>. We note for clarity that we employ Weight Standardization throughout training as a differentiable operation. We remove explicit regularizers such as dropout from the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NF-ResNet models.</head><p>We use the Normalizer-Free (NF) ResNet family of models from <ref type="bibr">Brock et al. (2021a)</ref> in most of our experiments on ImageNet and Places-365. When training on ImageNet from random initialization (without using any extra data) as described in Section 3.3, we initialize the SkipInit parameter in the NF-ResNets to 1.0, which we found to result in slightly faster convergence when training NF-ResNets with DP-SGD. We remove all explicit regularizers from the model such as dropout and stochastic depth.</p><p>NFNet models. We use the Normalizer-Free F3 Network (NFNet) from Brock et al. (2021b) to achieve our best results when fine-tuning on ImageNet. As before, we remove all explicit regularizers from the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Dataset Details</head><p>Overview. When using data augmentation, we perform random crops and random horizontal flips at training time. We never use data augmentation at evaluation time. When the augmentation multiplicity is set to 0, it means that no data augmentation is used. Our best hyper-parameters are selected on the validation set, and we report the corresponding performance on the test set for our best results, and on the validation set for all other analysis and ablation experiments. The data splits used for each dataset are reported in <ref type="table" target="#tab_0">Table 12</ref>. ImageNet. We construct a validation set from the official training set of the ImageNet dataset, so that we can cross-validate hyper-parameters on it. We report our best results on the official validation set. Each image is centered and standardized per channel. For all our experiments training from random initialization without any extra data (as in Section 3.3), we use an image size of 224 ? 224 both during training and evaluation. When fine-tuning on ImageNet from a pre-trained model (as in Section 4.2), we noticed that using larger image sizes for training and evaluation improved performance, and we use an image size of 320 ? 320 for all our experiments. When using random crops, we first resize the image to have 1.2 times the desired height and width, and then take a random crop of the desired size within this large image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4. Hyper-parameter Sweeps for the Analyses and Ablations</head><p>For our experiments shown in <ref type="table">Table 2</ref> and Figures 2, 3, 6 and 7, we tune the learning rate on a logarithmic grid and the number of training iterations on a linear grid (and calculate the corresponding noise parameter for each combination of and using the privacy accountant) and made sure the optimal values did not lie on the edge of the hyper-parameter grid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5. Optimal Hyper-parameter Values for the Best Results</head><p>In the tables below, we now report the hyper-parameters used to achieve our best results for each image classification task considered in this paper. <ref type="table" target="#tab_0">Table 13</ref> | Hyper-parameters for training without extra data on CIFAR-10 with a WRN-16-4 <ref type="table">(Table 3)</ref>.</p><p>Hyper-parameter Value 1.0 2.0 3.0 4.0 6.0 8.0 10 ?5 10 ?5 10 ?5 10 ?5 10 ?5 10 ?5  <ref type="table">(Table 3)</ref>.</p><p>Hyper-parameter Value 1.0 2.0 3.0 4.0 6.0 8.0 10 ?5 10 ?5 10 ?5 10 ?5 10 ?5 10 ?5    <ref type="table" target="#tab_0">(Table 11)</ref>.</p><p>Hyper-parameter Value 0.5 1.0 1.5 2.0 4.0 6.0 8.0 10 ?5 10 ?5 10 ?5 10 ?5 10 ?5 10 ?5 10 ?5     <ref type="table">Table 22</ref> | Hyper-parameters for JFT-4B ? ImageNet: fine-tuning last layer of NFNet-F3 <ref type="table" target="#tab_6">(Table 6)</ref>.</p><p>Hyper-parameter Value 0.1 0.5 1.0 2.0 4.0 8.0 8 ? 10 ?7 8 ? 10 ?7 8 ? 10 ?7 8 ? 10 ?7 8 ? 10 ?7 8 ? 10 ?7 </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 |Figure 3 |</head><label>23</label><figDesc>Increasing batch sizes on the WRN-16-4 model leads to improved training and validation accuracy under (8, 10 ?5 )-DP. We plot the mean and standard error across 5 independent runs. Increasing augmentation multiplicities on WRN-16-4 leads to improved training and validation accuracy under (8, 10 ?5 )-DP. We plot the mean/standard error across 5 independent runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 |</head><label>5</label><figDesc>Top-1 and top-5 accuracies of NF-ResNet-200 on ImageNet for a range of privacy budgets fine-tuning only the final layer with = 2 18 . We pre-train either on JFT-300M or on JFT-4B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 |</head><label>7</label><figDesc>Training a WRN-16-4 on CIFAR-10 under (8, 10 ?5 )-DP. (a) The optimal training iteration budget falls as the batch size rises for small batch sizes, but is roughly constant for large batch sizes. (b) The optimal epoch budget is roughly constant for small batch sizes, but proportional to batch size for large batch sizes. (c)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 |</head><label>8</label><figDesc>Sensitivity of performance to clipping norm for different learning rates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 |</head><label>10</label><figDesc>Training a WRN-40-4 on CIFAR-10 at batch size 16384 under (8, 10 ?5 )-DP. B.6. Scaling of the Compute Budget with the Batch Size: Experiments on the WRN-40-4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 |</head><label>11</label><figDesc>Optimal compute budgets and optimal learning rates at a range of batch sizes on the WRN-40-4 under (8, 10 ?5 )-DP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>21 | Hyper-parameters for JFT-300M/4B ? ImageNet: fine-tuning last layer of NF-ResNet-200 (Figure 510 ?7 8 ? 10 ?7 8 ? 10 ?7 8 ? 10 ?7 8 ? 10 ?7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 |</head><label>1</label><figDesc>A summary of the best results provided in this paper when training with DP-SGD. All numbers in bold are SOTA. For the CIFAR-10 and CIFAR-100 experiments, we report the median accuracy across 5 independent runs. All experiments on CIFAR use Wide-ResNets with group normalization, while the ImageNet and Places-365 experiments use NF-ResNets or NFNets. See relevant sections for further details.</figDesc><table><row><cell>Dataset</cell><cell>Pre-Training</cell><cell cols="4">Top-1 Accuracy (%)</cell><cell></cell><cell>Section</cell></row><row><cell></cell><cell>Data</cell><cell>= 1</cell><cell>= 2</cell><cell>= 4</cell><cell>= 8</cell><cell></cell></row><row><cell>CIFAR-10</cell><cell>-</cell><cell cols="4">56.8 65.9 73.5 81.4</cell><cell>10 ?5</cell><cell>3.2</cell></row><row><cell>ImageNet</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">32.4 8 ? 10 ?7</cell><cell>3.3</cell></row><row><cell>CIFAR-10</cell><cell>ImageNet</cell><cell cols="4">94.7 95.4 96.1 96.7</cell><cell>10 ?5</cell><cell>4.1</cell></row><row><cell>CIFAR-100</cell><cell>ImageNet</cell><cell cols="4">70.3 74.7 79.2 81.8</cell><cell>10 ?5</cell><cell>4.1</cell></row><row><cell>ImageNet</cell><cell>JFT-4B</cell><cell cols="5">84.4 85.6 86.0 86.7 8 ? 10 ?7</cell><cell>4.2</cell></row><row><cell>Places-365</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>). For those experiments, we split the dataset of 50K examples into a training set of 45K examples and a validation set of 5K examples, and did not evaluate on the held out test set. In this section, we take the insights identified above, re-train our models on the full dataset of 50K examples, and evaluate performance on the official test set of 10K examples. We run experiments on both WRN-16-4 and WRN-40-4, at a range of values. To determine the best hyper-parameters, we first train on the reduced training set of 45K examples, tuning the learning rate and the noise parameter on the validation set. We then expand the training set to 50K examples and re-train without additional tuning. We report the median accuracy of 5 independent training runs on the CIFAR-10 test set. All experiments in this section apply group normalization, weight standardization and parameter averaging as described above.We first consider the WRN-16-4 model. Using a batch size of = 4096 and augmentation multiplicity = 16, this model achieves a held-out test accuracy of 78.7% under (8, 10 ?5 )-DP. Next, we consider the deeper WRN-40-4 model, and scale up the batch size to 2 14 = 16384 and the augmentation multiplicity to 32.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 |Table 4 |</head><label>34</label><figDesc>CIFAR-10 test accuracy of our Wide-ResNet models trained with DP-SGD without additional data. For our results, we report the median computed over five independent runs as well as the standard deviation. Top-1 and top-5 accuracy when training on ImageNet using DP-SGD without additional data.</figDesc><table><row><cell>Test Accuracy (%)</cell></row><row><cell>Median Std. Dev.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 |</head><label>6</label><figDesc>ImageNet top-1 accuracy when fine-tuning the last layer of an NFNet-F3 pre-trained on JFT-4B.</figDesc><table><row><cell>Accuracy (%)</cell></row></table><note>and strong additional regularization including Dropout, Weight Decay and Stochastic Depth (Brock et al., 2021b</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>I. Babuschkin, K. Baumli, A. Bell, S. Bhupatiraju, J. Bruce, P. Buchlovsky, D. Budden, T. Cai, A. Clark, I. Danihelka, V. U. Prabhu and A. Birhane. Large image datasets: A pyrrhic win for computer vision? arXiv, 2020. S. Qiao, H. Wang, C. Liu, W. Shen, and A. Yuille. Micro-batch training with batch-channel normalization and weight standardization. arXiv, 2019.A. Rakhlin, O. Shamir, and K. Sridharan. Making gradient descent optimal for strongly convex stochastic optimization. arXiv, 2011.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 |</head><label>8</label><figDesc>Phase I of the lower bound experiment: Finding the best choice of hyperparameters that distinguish models trained with and without .</figDesc><table><row><cell>Hyperparameter</cell><cell></cell><cell></cell><cell>Values</cell><cell></cell></row><row><cell></cell><cell>Uniform noise:</cell><cell>, Blank:</cell><cell>, Label 7 as 8:</cell><cell>, Label 6 as 7:</cell><cell>, Label 0 as 1:</cell></row><row><cell>Learning rate</cell><cell></cell><cell></cell><cell>0.1, 0.5, 1.0</cell><cell></cell></row><row><cell>Clipping norm</cell><cell></cell><cell></cell><cell cols="2">0.1, 1.0, 10.0</cell></row><row><cell>| |</cell><cell></cell><cell>60K</cell><cell></cell><cell></cell><cell>100</cell></row><row><cell>Batch size</cell><cell cols="4">4096 (accumulated over two steps of batch size 2048)</cell><cell>64</cell></row><row><cell>Number of updates</cell><cell></cell><cell cols="2">500, 1K</cell><cell></cell><cell>50, 100</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 |</head><label>9</label><figDesc>Phase II of the lower bound experiment: Reporting probabilistic lower bounds with 99.9% confidence and the membership inference (inferring if was or was not used in training) AUC and advantage (1 ? ? ).</figDesc><table><row><cell cols="2">| | Nominal</cell><cell cols="4">lower bound Membership AUC Membership advantage Membership advantage upper bound</cell></row><row><cell></cell><cell>1</cell><cell>0.279</cell><cell>0.54</cell><cell>0.06</cell><cell>0.46</cell></row><row><cell>60K</cell><cell>2 4</cell><cell>0.456 1.139</cell><cell>0.57 0.62</cell><cell>0.10 0.17</cell><cell>0.76 0.96</cell></row><row><cell></cell><cell>8</cell><cell>2.153</cell><cell>0.72</cell><cell>0.31</cell><cell>1.00</cell></row><row><cell></cell><cell>1</cell><cell>0.361</cell><cell>0.59</cell><cell>0.13</cell><cell>0.47</cell></row><row><cell>100</cell><cell>2 4</cell><cell>0.837 2.461</cell><cell>0.66 0.79</cell><cell>0.22 0.43</cell><cell>0.76 0.96</cell></row><row><cell></cell><cell>8</cell><cell>4.327</cell><cell>0.91</cell><cell>0.67</cell><cell>1.00</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Validation accuracy at different points in training (corresponding to different values of ) for WRNs at different depths and different augmentation multiplicities , trained with fixed noise parameter = 2.</figDesc><table><row><cell>Validation Error (%)</cell><cell>20 30 40</cell><cell></cell><cell cols="2">WRN-16-4 WRN-28-4 WRN-40-4 WRN-76-4 WRN-100-4</cell><cell>Validation Error (%)</cell><cell>20 30 40</cell><cell></cell><cell cols="2">WRN-16-4 WRN-28-4 WRN-40-4 WRN-76-4 WRN-100-4</cell><cell>Validation Error (%)</cell><cell>12 16 20 24</cell><cell>WRN-16-4 WRN-28-4 WRN-40-4 WRN-76-4 WRN-100-4</cell></row><row><cell></cell><cell>8</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell></cell><cell>8</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell></cell><cell>8</cell><cell>16</cell><cell>32</cell><cell>64</cell></row><row><cell cols="5">(a) = 0 (no augmentation)</cell><cell></cell><cell></cell><cell>(b) = 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(c) = 16</cell></row><row><cell cols="2">Figure 9 |</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 |</head><label>10</label><figDesc>Test accuracy on fine-tuning on CIFAR-10 using a WRN-40-4 pre-trained on ImageNet-32.</figDesc><table><row><cell>Fine-tuning Method</cell><cell></cell><cell>Test Accuracy (%)</cell></row><row><cell></cell><cell>1</cell><cell>93.6</cell></row><row><cell>All layers</cell><cell>2 4</cell><cell>94.3 95.1</cell></row><row><cell></cell><cell>8</cell><cell>95.6</cell></row></table><note>B.4. Private Fine-Tuning on CIFAR-10 Using a WRN-40-4 Model Pre-Trained on CIFAR-100</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 |</head><label>11</label><figDesc>Test accuracy on CIFAR-10 when privately fine-tuning from the WRN-40-4 pre-trained on CIFAR-100. We report the median test accuracy and the standard deviation across 5 independent runs.</figDesc><table><row><cell></cell><cell>Method</cell><cell cols="2">Test Accuracy (%)</cell></row><row><cell></cell><cell></cell><cell cols="2">Median Std. Dev.</cell></row><row><cell>0.5</cell><cell>Luo et al. (2021) Ours</cell><cell>73.3 76.7</cell><cell>-(0.3)</cell></row><row><cell>1.0</cell><cell>Luo et al. (2021) Ours</cell><cell>76.6 80.4</cell><cell>-(0.7)</cell></row><row><cell>1.5</cell><cell>Luo et al. (2021) Ours</cell><cell>81.6 83.8</cell><cell>-(0.3)</cell></row><row><cell>2</cell><cell>Ours</cell><cell>84.9</cell><cell>(0.2)</cell></row><row><cell>4</cell><cell>Ours</cell><cell>87.0</cell><cell>(0.2)</cell></row><row><cell>6</cell><cell>Ours</cell><cell>88.4</cell><cell>(0.2)</cell></row><row><cell>8</cell><cell>Ours</cell><cell>89.0</cell><cell>(0.2)</cell></row></table><note>B.5. Optimal Noise Scale for a Fixed Batch Size: Experiments on the WRN-40-4</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 12 |</head><label>12</label><figDesc>Number of samples in each split per dataset. When results are reported on the validation set, the model is trained on the 45 training images.When results are reported on the test set, the model is trained on the full 50 training + valid images. We ensure that the DP accountant uses the corresponding number of examples to calculate the guarantee. Each image is centered and standardized per channel. When using random crops, every image is padded with 4 pixels on each edge with "mirror" padding.</figDesc><table><row><cell>Dataset</cell><cell>Train</cell><cell>Valid</cell><cell>Train + Valid</cell><cell>Test</cell></row><row><cell>CIFAR-10</cell><cell>45,000</cell><cell>5,000</cell><cell>50,000</cell><cell>10,000</cell></row><row><cell>CIFAR-100</cell><cell>45,000</cell><cell>5,000</cell><cell>50,000</cell><cell>10,000</cell></row><row><cell>ImageNet</cell><cell cols="2">1,271,167 10,000</cell><cell>-</cell><cell>50,000</cell></row><row><cell cols="3">ImageNet-32 1,271,167 10,000</cell><cell>-</cell><cell>50,000</cell></row><row><cell>Places-365</cell><cell>1,803,460</cell><cell>-</cell><cell>-</cell><cell>36,500</cell></row><row><cell>CIFAR.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 14 |</head><label>14</label><figDesc>Hyper-parameters for training without extra data on CIFAR-10 with a WRN-40-4</figDesc><table><row><cell>Augmult</cell><cell>16</cell><cell>16</cell><cell>16</cell><cell>16</cell><cell>16</cell><cell>16</cell></row><row><cell>Batch-size</cell><cell cols="6">4096 4096 4096 4096 4096 4096</cell></row><row><cell>Clipping-norm</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Learning-rate</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>4</cell><cell>4</cell></row><row><cell>Noise multiplier</cell><cell>10.0</cell><cell>6.0</cell><cell>5.0</cell><cell>4.0</cell><cell>3.0</cell><cell>3.0</cell></row><row><cell>Number Updates</cell><cell cols="6">875 1125 1593 1687 1843 2468</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 15 |</head><label>15</label><figDesc>Hyper-parameters for training without extra data on ImageNet with an NF-ResNet-50 (Section 3.3).</figDesc><table><row><cell>Augmult</cell><cell>32</cell><cell>32</cell><cell>32</cell><cell>32</cell><cell>32</cell><cell>32</cell></row><row><cell>Batch-size</cell><cell cols="6">16384 16384 16384 16384 16384 16384</cell></row><row><cell>Clipping-norm</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Learning-rate</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>4</cell><cell>4</cell></row><row><cell>Noise multiplier</cell><cell>40.0</cell><cell>24.0</cell><cell>20.0</cell><cell>16.0</cell><cell>12.0</cell><cell>9.4</cell></row><row><cell>Number Updates</cell><cell>906</cell><cell>1156</cell><cell>1656</cell><cell>1765</cell><cell>2007</cell><cell>2000</cell></row><row><cell></cell><cell cols="2">Hyper-parameter</cell><cell></cell><cell>Value</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>8.0</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>8 ? 10 ?7</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Augmentation multiplicity</cell><cell>4</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Batch-size</cell><cell></cell><cell></cell><cell>16384</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Clipping-norm</cell><cell></cell><cell>1</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Learning-rate</cell><cell></cell><cell>4</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Noise multiplier</cell><cell></cell><cell>2.5</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Number of updates</cell><cell></cell><cell>71589</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 16 |Table 17 |Table 18 |Table 19 |</head><label>16171819</label><figDesc>Hyper-parameters for ImageNet-32 ? CIFAR-10, fine-tuning all layers of WRN-28-10(Table 5). Hyper-parameters for ImageNet-32 ? CIFAR-10, fine-tuning the last layer of WRN-28-10(Table 5). Hyper-parameters for ImageNet-32 ? CIFAR-100, fine-tuning all layers of WRN-28-10(Table 5). Hyper-parameters for ImageNet-32 ? CIFAR-100, fine-tuning the last layer of WRN-28-10(Table 5).</figDesc><table><row><cell>Hyper-parameter</cell><cell></cell><cell cols="2">Value</cell><cell></cell></row><row><cell></cell><cell>1.0</cell><cell>2.0</cell><cell>4.0</cell><cell>8.0</cell></row><row><cell></cell><cell>10 ?5</cell><cell>10 ?5</cell><cell>10 ?5</cell><cell>10 ?5</cell></row><row><cell>Augmentation multiplicity</cell><cell>16</cell><cell>16</cell><cell>16</cell><cell>16</cell></row><row><cell>Batch-size</cell><cell cols="4">16384 16384 16384 16384</cell></row><row><cell>Clipping-norm</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Learning-rate</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Noise multiplier</cell><cell>21.1</cell><cell>15.8</cell><cell>12.0</cell><cell>9.4</cell></row><row><cell>Number of updates</cell><cell>250</cell><cell>500</cell><cell>1000</cell><cell>2000</cell></row><row><cell>Hyper-parameter</cell><cell></cell><cell cols="2">Value</cell><cell></cell></row><row><cell></cell><cell>1.0</cell><cell>2.0</cell><cell>4.0</cell><cell>8.0</cell></row><row><cell></cell><cell>10 ?5</cell><cell>10 ?5</cell><cell>10 ?5</cell><cell>10 ?5</cell></row><row><cell>Augmentation multiplicity</cell><cell>16</cell><cell>16</cell><cell>16</cell><cell>16</cell></row><row><cell>Batch-size</cell><cell cols="4">16384 16384 16384 16384</cell></row><row><cell>Clipping-norm</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Learning-rate</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>4</cell></row><row><cell>Noise multiplier</cell><cell>21.1</cell><cell>15.8</cell><cell>12.0</cell><cell>9.4</cell></row><row><cell>Number of updates</cell><cell>250</cell><cell>500</cell><cell>1000</cell><cell>2000</cell></row><row><cell>Hyper-parameter</cell><cell></cell><cell cols="2">Value</cell><cell></cell></row><row><cell></cell><cell>1.0</cell><cell>2.0</cell><cell>4.0</cell><cell>8.0</cell></row><row><cell></cell><cell>10 ?5</cell><cell>10 ?5</cell><cell>10 ?5</cell><cell>10 ?5</cell></row><row><cell>Augmentation multiplicity</cell><cell>16</cell><cell>16</cell><cell>16</cell><cell>16</cell></row><row><cell>Batch-size</cell><cell cols="4">16384 16384 16384 16384</cell></row><row><cell>Clipping-norm</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Learning-rate</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Noise multiplier</cell><cell>21.1</cell><cell>15.8</cell><cell>12.0</cell><cell>9.4</cell></row><row><cell>Number of updates</cell><cell>250</cell><cell>500</cell><cell>1000</cell><cell>2000</cell></row><row><cell>Hyper-parameter</cell><cell></cell><cell cols="2">Value</cell><cell></cell></row><row><cell></cell><cell>1.0</cell><cell>2.0</cell><cell>4.0</cell><cell>8.0</cell></row><row><cell></cell><cell>10 ?5</cell><cell>10 ?5</cell><cell>10 ?5</cell><cell>10 ?5</cell></row><row><cell>Augmentation multiplicity</cell><cell>16</cell><cell>16</cell><cell>16</cell><cell>16</cell></row><row><cell>Batch-size</cell><cell cols="4">16384 16384 16384 16384</cell></row><row><cell>Clipping-norm</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Learning-rate</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>4</cell></row><row><cell>Noise multiplier</cell><cell>21.1</cell><cell>15.8</cell><cell>12.0</cell><cell>9.4</cell></row><row><cell>Number of updates</cell><cell>250</cell><cell>500</cell><cell>1000</cell><cell>2000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 20 |</head><label>20</label><figDesc>Hyper-parameters for CIFAR-100 ? CIFAR-10, fine-tuning all layers of </figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 23 |</head><label>23</label><figDesc>Hyper-parameters for fine-tuning JFT-300M ? Places-365(Table 7).</figDesc><table><row><cell>Augmult</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Batch-size</cell><cell cols="6">262144 262144 262144 262144 262144 262144</cell></row><row><cell>Clipping-norm</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Learning-rate</cell><cell>30</cell><cell>10</cell><cell>30</cell><cell>30</cell><cell>100</cell><cell>100</cell></row><row><cell>Noise multiplier</cell><cell>82.6</cell><cell>57.2</cell><cell>29.9</cell><cell>15.8</cell><cell>8.4</cell><cell>4.6</cell></row><row><cell>Number Updates</cell><cell>100</cell><cell>1000</cell><cell>1000</cell><cell>1000</cell><cell>1000</cell><cell>1000</cell></row><row><cell>Hyper-parameter</cell><cell></cell><cell></cell><cell cols="2">Value</cell><cell></cell><cell></cell></row><row><cell>Fine-tuning</cell><cell></cell><cell cols="5">Entire Model Last Layer Entire Model Last Layer</cell></row><row><cell></cell><cell></cell><cell>8.0</cell><cell>8.0</cell><cell>?</cell><cell></cell><cell>?</cell></row><row><cell></cell><cell></cell><cell>5 ? 10 ?7</cell><cell>5 ? 10 ?7</cell><cell>1</cell><cell></cell><cell>1</cell></row><row><cell cols="2">Augmentation multiplicity</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell></cell><cell>0</cell></row><row><cell>Batch-size</cell><cell></cell><cell>4096</cell><cell>4096</cell><cell cols="2">1024</cell><cell>1024</cell></row><row><cell>Clipping-norm</cell><cell></cell><cell>1</cell><cell>1</cell><cell>?</cell><cell></cell><cell>?</cell></row><row><cell>Learning-rate</cell><cell></cell><cell>0.1</cell><cell>0.1</cell><cell cols="2">0.3</cell><cell>0.1</cell></row><row><cell>Noise multiplier</cell><cell></cell><cell>1.0</cell><cell>2.0</cell><cell cols="2">0.0</cell><cell>0.0</cell></row><row><cell>Number of updates</cell><cell></cell><cell>223939</cell><cell>1374116</cell><cell cols="2">8250</cell><cell>46500</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In this paper we do not account for the privacy cost of hyper-parameter tuning<ref type="bibr" target="#b49">(Papernot and Steinke, 2021)</ref>, and instead favour thorough sweeps on the same dataset in order to better understand how the hyper-parameters of DP-SGD influence model performance.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">In an earlier version, we mistakenly used a version of JFT-300M de-duplicated with respect to the validation set of ImageNet but not the training set. After repeating our experiments on a new version of JFT-300M fully de-duplicated with respect to both ImageNet and Places-365, a number of our results improved. We believe this arises because the de-duplication process also removes low-quality images.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank: Matthias Bauer and Sven Gowal for insightful comments that helped improve the paper's presentation; Robert Stanforth for engineering support, open-sourcing support and code reviews; Rudy Bunel for code reviews; John Aslanides for code quality reviews and open-sourcing support; Alison Reid for support during the open-sourcing process; Andrew Trask and Thomas Steinke for insightful discussions; Zahra Ahmed and Kitty Stacpoole for project management support; Andrew Brock, Taylan Cemgil, Raia Hadsell, Koray Kavukcuoglu, Pushmeet Kohli, Razvan Pascanu and Yee Whye Teh for advice throughout the project. We would also like to thank Abhradeep Thakurta, Florian Tram?r and Harsh Mehta for discussions on their related works.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ImageNet-32. We construct a validation set from the official training set similar to the ImageNet dataset. In the ImageNet-32 dataset, each image from the ImageNet dataset is down-sampled to 32 ? 32. We follow the same image down-sampling procedure as described in <ref type="bibr">Chrabaszcz et al. (2017)</ref>. Each image is translated and normalized so as to have values between -1 and 1. When using random crops, every image is padded with 4 pixels on each edge with "mirror" padding.</p><p>Places-365. We train on the training set and report results on the test set. Each image is centered and standardized per channel, and we use an image size of 256 ? 256 for both training and evaluation. When using random crops, we first resize the image to have 1.2 times the desired height and width, and then take a crop of the desired size within this large image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. Training Details</head><p>Training with DP-SGD. For all our experiments training with DP-SGD (both when training from random initialization or when fine-tuning a pre-trained model), we use a constant learning rate without any learning rate decay. We also do not use explicit regularizers such as weight decay or label smoothing.</p><p>We found that using parameter averaging helped reduce the oscillations of the iterates during training and improved accuracy. While Polyak averaging schemes <ref type="bibr" target="#b52">(Polyak and Juditsky, 1992)</ref> have good theoretical convergence properties in non-private training <ref type="bibr">(Rakhlin et al., 2011)</ref>, neural network practitioners typically use an exponential moving average (EMA) of the model parameters <ref type="bibr">(Brock et al., 2021b;</ref><ref type="bibr" target="#b67">Tan and Le, 2019)</ref> which is easier to tune. Following <ref type="bibr" target="#b67">Tan and Le (2019)</ref>, we use EMA with a warm-up schedule where the decay on training iteration equals min( _ , 1+ 10+ ). For our experiments on CIFAR-10 and CIFAR-100, we use a decay rate of 0.9999. For our experiments on ImageNet and Places-365, where we train for a larger number of iterations compared to the CIFAR experiments, we use a decay rate of 0.99999.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-training on ImageNet-32.</head><p>For non-private pre-training on ImageNet-32 using the WRN-28-10 and the WRN-40-4 (Section 4.1, we use SGD with a momentum parameter of 0.9. We use a constant learning rate of 0.3 and a weight decay parameter of 5 ? 10 ?5 . We use random crops and random flips of the images with augmentation multiplicity 1. We train for 240K iterations with batch size 1024.</p><p>Pre-training on CIFAR-100. For non-private pre-training on CIFAR-100 using the WRN-40-4 (Appendix B.4), we use SGD with a momentum parameter of 0.9. We use random crops and random flips of the images with augmentation multiplicity 1. We train for 100K iterations with batch size 128. We use an initial learning rate of 0.1, and decay the learning rate by factors of 10 at 50K and 75K iterations. We use a weight decay of 5 ? 10 ?4 .</p><p>Pre-training on JFT-300M. We use the same pre-training procedure on JFT-300M as described in <ref type="bibr">Brock et al. (2021b)</ref>. We use SGD with momentum parameter 0.9. We use a learning rate of 0.4, using a warm-up from 0 over 5K iterations and then use cosine annealing to decay the learning rate to 0 through the rest of training. We use random crops and random flips of the images with augmentation multiplicity 1, and train with an image size of 224 ? 224. We train for 10 epochs using a batch size of 1024. We use a weight decay of 10 ?6 .</p><p>Pre-training on JFT-4B. We use the same procedure for fine-tuning on JFT-4B as described in the previous section on pre-training on JFT-300M, except that we pre-train the NF-ResNet models on JFT-4B for 1 epoch, instead of 10 epochs. We pre-train the NFNet-F3 models on JFT-4B for 2 epochs.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer and Communications Security</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The U.S. census bureau adopts differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Abowd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Discovery &amp; Data Mining</title>
		<editor>Y. Guo and F. Farooq</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The modernization of statistical disclosure limitation at the u.s. census bureau</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Abowd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Benedetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Garfinkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Dajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Hawes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Karwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Leclerc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Machanavajjhala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">M</forename><surname>Schmutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">N</forename><surname>Sexton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vilhuber</surname></persName>
		</author>
		<ptr target="https://www.census.gov/library/working-papers/2020/adrm/modernization-statistical-disclosure-limitation.html" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Manurangsi</surname></persName>
		</author>
		<title level="m">Large-scale differentially private BERT. arXiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Apple Differential Privacy Team</title>
		<ptr target="https://docs-assets.developer.apple.com/ml-research/papers/learning-with-privacy-at-scale.pdf" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Learning with privacy at scale</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Private stochastic convex optimization: Optimal rates in L1 geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Asi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">An image is worth 16x16 words: Transformers for image recognition at scale. arXiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The algorithmic foundations of differential privacy. Foundations and Trends? in Theoretical Computer Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of cryptography conference</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The reusable holdout: Preserving validity in adaptive data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning statistics with privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Erlingsson</surname></persName>
		</author>
		<ptr target="https://ai.googleblog.com/2014/10/learning-statistics-with-privacy-aided.html" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generalization for adaptively-chosen estimators via stable median</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Steinke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Private stochastic convex optimization: optimal rates in linear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Theory of Computing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hiding among the clones: A simple and nearly optimal analysis of privacy amplification by shuffling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Computer Science, FOCS</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Drawing multiple augmentation samples per image during training efficiently decreases test error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mixed differential privacy in computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Golatkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Tensorflow privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Google</surname></persName>
		</author>
		<ptr target="https://github.com/tensorflow/privacy" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<title level="m">Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Differential privacy for functions and functional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rinaldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Wasserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ben-Nun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Giladi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hoefler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Soudry</surname></persName>
		</author>
		<title level="m">Augment your batch: better training with larger batches. arXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning and evaluating a differentially private pre-trained language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tendler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Erell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Peled-Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nakhost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Stemmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hassidim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Humphries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rafuse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hengartner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kerschbaum</surname></persName>
		</author>
		<title level="m">Differentially private learning does not bound membership inference. arXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Auditing differentially private machine learning: How private is private sgd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oprea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A new analysis of differential privacy&apos;s generalization guarantees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ligett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Neel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharifi-Malvajerdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovations in Theoretical Computer Science Conference</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Private convex optimization for empirical risk minimization with applications to high-dimensional regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<editor>S. Mannor, N. Srebro, and R. C. Williamson</editor>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Klause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ziller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kaissis</surname></persName>
		</author>
		<title level="m">Differentially private training of residual networks with scale normalisation. arXiv</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Big transfer (bit): General visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koskela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Heikkil?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Honkela</surname></persName>
		</author>
		<title level="m">Tight accounting in the shuffle model of differential privacy. arXiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Geambasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Terzis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<title level="m">Toward training at imagenet scale with differential privacy. arXiv</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Large language models can be strong differentially private learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tram?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hashimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Ml-doctor: Holistic risk assessment of inference attacks against machine learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Salem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cristofaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">Scalable differential privacy with sparse network finetuning. Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Understanding the sparse vector technique for differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The power of interpolation: Understanding the effectiveness of sgd in modern over-parametrized learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">An empirical model of large-batch training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">D</forename><surname>Team</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Federated learning with formal differential privacy guarantees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<ptr target="https://ai.googleblog.com/2022/02/federated-learning-with-formal.html" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kairouz</surname></persName>
		</author>
		<title level="m">A general approach to adding differential privacy to iterative training procedures. arXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning differentially private recurrent language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Large scale transfer learning for differentially private image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cutkosky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">R?nyi differential privacy of the sampled gaussian mechanism. arXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Adversary instantiation: Lower bounds for differentially private machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Songi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papemoti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Security and Privacy (SP)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">New privacy-protected Facebook data for independent research on social media&apos;s impact on democracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Nayak</surname></persName>
		</author>
		<ptr target="https://research.facebook.com/blog/2020/02/new-privacy-protected-facebook-data-for-independent-research-on-social-medias-impact-on-democracy/" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Guaranteed deterministic bounds on the total variation distance between univariate mixtures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Machine Learning for Signal Processing</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep roto-translation scattering for object classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oyallon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Steinke</surname></persName>
		</author>
		<title level="m">Hyperparameter tuning with renyi differential privacy. arXiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Scalable private learning with PATE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Erlingsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Tempered sigmoid activations for deep learning with differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Erlingsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Acceleration of stochastic approximation by averaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Polyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Juditsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on control and optimization</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Piot</surname></persName>
		</author>
		<title level="m">Byol works even without batch statistics. arXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>ImageNet Large Scale Visual Recognition Challenge. Internation Journal of Computer Vision</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Shallue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Antognini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<title level="m">Measuring the effects of data parallelism on neural network training. arXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<title level="m">Towards understanding the impact of model size on differential private classification. arXiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A survey on image data augmentation for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shorten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Revisiting weakly supervised pre-training of visual perception models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">D F</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gedik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">On the generalization benefit of noise in stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Don&apos;t decay the learning rate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-J</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>increase the batch size. arXiv</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent with differentially private updates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Global Conference on Signal and Information Processing</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Evading the curse of dimensionality in unconstrained private glms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Steinke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Artificial Intelligence and Statistics</title>
		<editor>A. Banerjee and K. Fukumizu</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Revisiting unreasonable effectiveness of data in deep learning era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Chasing your long tails: Differentially private prediction in health care settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Suriyakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Fairness, Accountability, and Transparency</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Nearly optimal private LASSO</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Differentially private learning with adaptive clipping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Going deeper with image transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Differentially private learning needs better features (or much more data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tram?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Debugging differential privacy: A case study for privacy auditing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Terzis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Steinke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Differentially private deep learning under the fairness lens. arXiv, 2021. L. van der Maaten and A. Y. Hannun. The trade-offs of private prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fioretto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<title level="m">Attention is all you need. Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Note on a method for calculating corrected sums of squares and products</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Welford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
		</imprint>
	</monogr>
	<note type="report_type">Technometrics</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Bolt-on differential privacy for scalable stochastic gradient descent-based analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Naughton</surname></persName>
		</author>
		<editor>S. Salihoglu, W. Zhou, R. Chirkova, J. Yang, and D. Suciu</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Group normalization. Internation Journal of Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Privacy risk in machine learning: Analyzing the connection to overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yeom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Giacomelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Security Foundations Symposium</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yousefpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Testuggine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<title level="m">Opacus: User-friendly differential privacy library in PyTorch. arXiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Backurs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Inan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Manoel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wutschitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yekhanin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Differentially private fine-tuning of language models. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Do not let privacy overbill utility: Gradient embedding perturbation for private learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Large scale private learning via low-rank reparametrization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seyedhosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01917</idno>
		<title level="m">Coca: Contrastive captioners are image-text foundation models</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<title level="m">Scaling vision transformers. arXiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Fixup initialization: Residual learning without normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hejazinia</surname></persName>
		</author>
		<title level="m">Wide network learning with differential privacy. arXiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Bypassing the ambient dimension: Private SGD with gradient subspace identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
