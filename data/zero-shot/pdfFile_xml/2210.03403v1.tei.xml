<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TAN WITHOUT A BURN: SCALING LAWS OF DP-SGD</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Sander</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ecole Polytechnique</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Stock</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ecole Polytechnique</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meta</forename><surname>Ai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ecole Polytechnique</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ecole Polytechnique</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meta</forename><surname>Ai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ecole Polytechnique</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">TAN WITHOUT A BURN: SCALING LAWS OF DP-SGD</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differentially Private methods for training Deep Neural Networks (DNNs) have progressed recently, in particular with the use of massive batches and aggregated data augmentations for a large number of steps. These techniques require much more compute than their non-private counterparts, shifting the traditional privacyaccuracy trade-off to a privacy-accuracy-compute trade-off and making hyperparameter search virtually impossible for realistic scenarios. In this work, we decouple privacy analysis and experimental behavior of noisy training to explore the trade-off with minimal computational requirements. We first use the tools of R?nyi Differential Privacy (RDP) to show that the privacy budget, when not overcharged, only depends on the total amount of noise (TAN) injected throughout training. We then derive scaling laws for training models with DP-SGD to optimize hyper-parameters with more than a 100? reduction in computational budget. We apply the proposed method on CIFAR-10 and ImageNet and, in particular, strongly improve the state-of-the-art on ImageNet with a +9 points gain in accuracy for a privacy budget ? = 8. * Work done during an internship at Meta.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep neural networks (DNNs) have become a fundamental tool of modern artificial intelligence, producing cutting-edge performance in many domains such as computer vision <ref type="bibr" target="#b20">(He et al., 2016)</ref>, natural language processing <ref type="bibr" target="#b14">(Devlin et al., 2018)</ref> or speech recognition <ref type="bibr" target="#b1">(Amodei et al., 2016)</ref>. The performance of these models generally increases with their training data size <ref type="bibr">(Brown et al., 2020;</ref><ref type="bibr" target="#b30">Rae et al., 2021;</ref><ref type="bibr" target="#b31">Ramesh et al., 2022)</ref>, which encourages the inclusion of more data in the model's training set. This phenomenon also introduces a potential privacy risk for data that gets incorporated. Indeed, AI models not only learn about general statistics or trends of their training data distribution (such as grammar for language models), but also remember verbatim information about individual points (e.g., credit card numbers), which compromises their privacy <ref type="bibr" target="#b9">(Carlini et al., 2019;</ref>. Access to a trained model thus potentially leaks information about its training data.</p><p>The gold standard of disclosure control for individual information is Differential Privacy (DP) <ref type="bibr" target="#b16">(Dwork et al., 2006)</ref>. Informally, DP ensures that the training algorithm does not produce very different models if a sample is added or removed from the dataset. Motivated by applications in deep learning, DP-SGD <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref> is an adaptation of Stochastic Gradient Descent (SGD) that clips individual gradients and adds Gaussian noise to their sum. Its DP guarantees depend on the privacy parameters: the sampling rate q = B/N (where B is the batch size and N is the number of training examples), the number of gradient steps S, and the noise variance ? 2 .</p><p>Training neural networks with DP-SGD has seen progress recently, due to several factors. The first is the use of pre-trained models, with DP finetuning on downstream tasks <ref type="bibr" target="#b25">(Li et al., 2021b;</ref><ref type="bibr" target="#b12">De et al., 2022)</ref>. This circumvents the traditional problems of DP, because the model learns meaningful features from public data and can adapt to downstream data with minimal information. In the remainder of this paper, we only consider models trained from scratch, as we focus on obtaining information through the DP channel. Another emerging trend among DP practitioners is to use massive batch sizes at a large number of steps to achieve a better tradeoff between privacy and utility: <ref type="bibr" target="#b2">Anil et al. (2021)</ref> have successfully pre-trained BERT with DP-SGD using batch sizes of 2 million. This paradigm makes training models computationally intensive and hyper-parameter (HP) search effectively impractical for realistic datasets and architectures. We perform low compute hyper-parameter (HP) search at batch size 128 and extrapolate our best setup for a single run at large batch size: stars show our reproduction of the previous SOTA from <ref type="bibr" target="#b12">De et al. (2022)</ref> and improved performance obtained under the privacy budget ? = 8 with a +6 points gain in top-1 accuracy. The shaded blue areas denote 2 standard deviations over three runs.</p><p>In this context, we look at DP-SGD through the lens of the Total Amount of Noise (TAN) injected during training, and use it to decouple two aspects: privacy accounting and influence of noisy updates on the training dynamics. We first show that within a wide range of the privacy parameters, the privacy budget ? is a function only of the total amount of noise. Using the tools of RDP accounting, we approximate ? by a closed-form expression. We then analyze the scaling laws of DNNs at constant TAN and show that performance at very large batch sizes (computationally intensive) is (linearly) predictable from performance at small batch sizes as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>In summary, our contributions are as follows:</p><p>? We define the notion of Total Amount of Noise (TAN) and show that when the budget ? is not overcharged, it only depends on TAN; ? We derive scaling laws and showcase the predictive power of TAN to reduce the computational cost of hyper-parameter tuning with DP-SGD, saving a factor of 128 in compute on ImageNet experiments ( <ref type="figure" target="#fig_0">Figure 1</ref>). We then use TAN to find optimal privacy parameters, leading to a gain of +9 points under ? = 8 compared to the previous SOTA; ? We leverage TAN to quantify the impact of the dataset size on the privacy/utility trade-off and demonstrate that doubling dataset size halves ? while providing better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND RELATED WORK</head><p>In this section, we review traditional definitions of DP and RDP. We consider a randomized mechanism M that takes as input a dataset D and outputs a machine learning model ? ? M(D). Definition 1 (Differential Privacy). A randomized mechanism M satisfies (?, ?)-DP <ref type="bibr" target="#b16">(Dwork et al., 2006)</ref> if, for any pair of datasets D and D that differ by one sample and for all subset R ? Im(M),</p><formula xml:id="formula_0">P(M(D) ? R) ? P(M(D ) ? R) exp(?) + ?.<label>(1)</label></formula><p>DP-SGD <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref> is the most popular DP algorithm to train DNNs. It consists in selecting samples uniformly at random with probability q = B/N (Poisson sampling), clipping per-sample gradients, aggregating them and adding (Gaussian) noise:</p><formula xml:id="formula_1">g noisy = 1 B i?B clip C (? ? (?, (x i , y i ))) + N 0, C 2 ? 2 B 2 .<label>(2)</label></formula><p>2</p><p>The traditional privacy analysis of DP-SGD is obtained through R?nyi DP. Definition 2 (R?nyi Divergence). For two probability distributions P and Q defined over R, the R?nyi divergence of order ? &gt; 1 of P given Q is:</p><formula xml:id="formula_2">D ? (P Q) := 1 ? ? 1 log E x?Q P (x) Q(x) ? .</formula><p>Definition 3 (R?nyi DP). A randomized mechanism M : D ? R satisfies (?, d ? )-R?nyi differential privacy (RDP) if, for any D, D ? D that differ by one sample, we have</p><formula xml:id="formula_3">D ? (M(D) M(D )) ? d ? .</formula><p>R?nyi DP is a convenient notion to track privacy because composition is additive: a sequence of two algorithms satisfying (?, d ? ) and (?, d ? ) RDP satisfies (?, d ? + d ? ) RDP. In particular, the succession of S steps of a (?, d ? ) RDP mechanism satisfies (?, Sd ? ) RDP. <ref type="bibr" target="#b28">Mironov et al. (2019)</ref> show that each step of DP-SGD satisfies (?, g ? (?, q))-RDP with</p><formula xml:id="formula_4">g ? (?, q) := D ? ((1 ? q)N (0, ? 2 ) + qN (1, ? 2 ) N (0, ? 2 )).</formula><p>Finally, a mechanism satisfying (?, d ? )-R?nyi-DP also satisfies (?, ?)-DP <ref type="bibr" target="#b27">(Mironov, 2017)</ref> </p><formula xml:id="formula_5">for? = d ? + log(1/?) ??1 .</formula><p>Training for S steps with DP-SGD thus satisfies (? RDP , ?)-DP with</p><formula xml:id="formula_6">? RDP := min ? Sg ? (?, q) + log(1/?) ? ? 1 .<label>(3)</label></formula><p>RDP is the traditional tool used to analyse DP-SGD, but other accounting tools have been proposed to obtain tighter bounds . In this work, we use the accountant due to <ref type="bibr" target="#b4">Balle et al. (2020)</ref>, whose output is referred to as ?, which is slightly smaller than ? RDP .</p><p>Training from Scratch with DP-SGD. Training ML models with DP-SGD typically incurs a loss of model utility, and recent work have shown that using very large batch sizes improves the privacy/utility trade-off <ref type="bibr" target="#b2">(Anil et al., 2021;</ref><ref type="bibr" target="#b24">Li et al., 2021a)</ref>. <ref type="bibr" target="#b12">De et al. (2022)</ref> recently introduced Augmentation Multiplicity (AugMult), which averages the gradients from different augmented versions of every sample before clipping and leads to improved performance on CIFAR-10. Computing per-sample gradients with mega batch sizes (for a large number of steps) and AugMult makes DP-SGD much more computationally intensive than non-private training (typically dozens of times). For instance, reproducing the previous SOTA on ImageNet of <ref type="bibr" target="#b12">De et al. (2022)</ref> under ? = 8 necessitates a 4-day run using 32 A100 GPUs, while the non-private SOTA can be reproduced in a few hours with the same hardware <ref type="bibr" target="#b19">(Goyal et al., 2017)</ref>.</p><p>Finetuning with DP-SGD. <ref type="bibr" target="#b37">Tramer &amp; Boneh (2020)</ref> shows that handcrafted features are very competitive when training from scratch, but fine-tuning deep models outperforms them. <ref type="bibr" target="#b25">Li et al. (2021b)</ref>; <ref type="bibr" target="#b42">Yu et al. (2021)</ref> fine-tune language models to competitive accuracy on several NLP tasks. <ref type="bibr" target="#b12">De et al. (2022)</ref> consider models pre-trained on JFT-300M and transferred to downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE TAN APPROACH</head><p>We introduce the notion of Total Amount of Noise (TAN) and discuss its connections to RDP accounting. We then demonstrate how training with reference privacy parameters (q ref , ? ref , S) can be simulated with much lower computational resources using the same TAN with a smaller batch size. Definition 4. Let the individual signal-to-noise ratio ? (and its inverse ?, the Total Amount of Noise or TAN) be as follows:</p><formula xml:id="formula_7">? 2 = 1 ? 2 := q 2 S 2? 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MOTIVATION</head><p>We begin with a simple case to motivate our definition of TAN. We assume a one-dimensional model, where the gradients of all points are clipped to C. Looking at Equation 2, in one batch, the ). On the right, we use ? = 0.95 (? TAN = 8). We observe a "privacy wall" imposing ? ? 0.5 for meaningful level of privacy budget ?, and ? ? 2 for constant ? ? ? TAN .</p><p>expected signal from each sample is C/B with probability q = B/N and 0 otherwise. Therefore, the expected individual signal of each sample after S steps is SC/N , and its squared norm is S 2 C 2 /N 2 . The noise at each step being drawn independently, the variance across S steps adds to SC 2 ? 2 /B 2 . The ratio between the signal and noise is thus equal to (up to a factor 1/2)</p><formula xml:id="formula_8">S 2 C 2 N 2 2SC 2 ? 2 B 2 = q 2 S 2? 2 = ? 2 .</formula><p>Denoting ? step := q/ ? 2?, we have ? 2 = S? 2 step . The ratio ?/q is noted by <ref type="bibr" target="#b24">Li et al. (2021a)</ref> as the effective noise. The authors found that for a fixed budget ? and fixed S, the effective noise decreases with B. Our analysis goes further by analyzing how RDP accounting explains this dependency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CONNECTION WITH PRIVACY ACCOUNTING</head><p>Intuitively, we expect that the privacy budget ? only depends on the signal-to-noise ratio ?. In <ref type="figure" target="#fig_1">Figure 2</ref>, we plot ? as a function of ? and S, at a fixed ?, and observe that ? is indeed constant, but only when ? &gt; 2. On the contrary, when ? gets smaller, ? increases exponentially, creating a "Privacy Wall". We can shed light on this phenomenon by looking at the underlying RDP values. We observe (see <ref type="figure">Figure 3</ref>) that when ? &gt; 2, g ? (?, q) is close to ?q 2 /(2? 2 ) = ?? 2 step . Replacing that in the definition of ? RDP (Equation 3), we get</p><formula xml:id="formula_9">? RDP ? ? 2 + min ? (? ? 1)? 2 + log (1/?) ? ? 1 = ? 2 + 2? log (1/?) =: ? TAN (?).<label>(4)</label></formula><p>. . <ref type="figure">Figure 3</ref>: Approximation of g ? (?, q). All curves correspond to distinct couples (q, ?) such that ? step = 3.9 ? 10 ?3 (used for ImageNet). The right plot corresponds to an enlargement of the left plot: the ratio is very close to 1 for ? ? 2. The phase transitions on the left plot were also observed by <ref type="bibr" target="#b38">Wang et al. (2018)</ref> and <ref type="bibr" target="#b0">Abadi et al. (2016)</ref>. We verify this relationship empirically, and in particular choose ? to get a desired ? TAN in <ref type="figure" target="#fig_1">Figure 2</ref>. Conversely, we observe that when ? &lt; 2, g ? becomes much larger than ?? 2 step , which explains the blow-up in ? from Figure 2. Having this simple approximation for ? is useful in practice because it allows for simple mental gymnastics: for instance, doubling the sampling rate q while dividing the number of steps S by 4 should leave the privacy budget constant, which we observe empirically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">SCALING AT CONSTANT TAN</head><p>Our RDP analysis in Section 3.2 suggests a simple scaling strategy. Starting from (q, ?, S), while ? &lt; 2, we can double both q and ?. This drastically improves privacy accounting ( <ref type="figure" target="#fig_1">Figure 2</ref>), and the per step signal-to-noise ratio ? step remains constant. However, given that the number of steps S is fixed, each doubling of q doubles the computational cost.</p><p>Batch Scaling Laws. We now analyse how this strategy affects the performance of the network. In <ref type="figure">Figure 4</ref>, we perform this analysis on CIFAR-10 and ImageNet. We find that for triplets (q, ?, S) for which q/? = q ref /? ref (keeping ? step constant), the performance of the network (log) linearly decreases with the batch size. This is consistent with the (non-private) work of Smith et al. <ref type="formula" target="#formula_1">(2020)</ref>, which shows that for a fixed number of steps, small batch sizes perform better in generalisation (i.e., test accuracy) than large batch sizes. The difference with our work is that we consider noisy updates and observe a (log) linear relationship between batch size and performance.</p><p>Choice of ?. Simultaneously doubling the batch size q and the noise ? has a negligible or small impact on accuracy ( <ref type="figure">Figure 4</ref>) but greatly reduces the privacy budget if ? &lt; 2 ( <ref type="figure" target="#fig_1">Figure 2)</ref>. Reciprocally, if ? &gt; 4, dividing it by 2 simultaneously with halving q is likely to improve performance. In addition, it keeps the privacy guarantees almost unchanged and divides the computational cost by 2. This explains why state-of-the-art approaches heuristically find that mega-batches work well: a blind grid search on the batch size and the noise level at constant privacy budget is likely to discover batches large enough to have ? &gt; 2. Our analysis gives a principled explanation for the sweet spot of ? ? [2, 4] used by most state-of-the-art approaches <ref type="bibr" target="#b12">(De et al., 2022;</ref><ref type="bibr" target="#b25">Li et al., 2021b)</ref>.</p><p>Efficient TAN training. We go one step further and study training in the small batch size setting. We choose the optimal hyper-parameters (including architecture, optimizer, type of data augmentation) in this simulated setting, and finally launch one single run at the reference (large) batch size, with desired privacy guarantees. On ImageNet, we target B ref = 16,384 with B = 128. We thus reduce the computational requirements by a factor of 128?. Each hyper-parameter search in the ImageNet setup takes 4 days using 32 A-100 GPUs; we reduce it to less than a day on a single GPU. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We leverage our efficient TAN training strategy and obtain new state-of-the-art results on ImageNet for ? = 8 <ref type="table" target="#tab_1">(Table 1)</ref>. We then study the impact of the dataset size on the pricacy/utility trade-off. We also demonstrate how our low compute simulation framework can be used to detect performance bottlenecks when training with noisy updates: in our case, the importance of the order between activation and normalization in a WideResNet on CIFAR-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">EXPERIMENTAL SETUP</head><p>We use the CIFAR-10 dataset <ref type="bibr" target="#b22">(Krizhevsky et al., 2009</ref>) which contains 50K 32?32 images grouped in 10 classes. The ImageNet dataset <ref type="bibr" target="#b13">(Deng et al., 2009;</ref><ref type="bibr" target="#b32">Russakovsky et al., 2014)</ref> contains 1.2 million images partitioned into 1000 categories. When using data augmentation, we always use Augmentation Multiplicity as detailed in Appendix C. For both datasets, we train models from random initialization. On CIFAR-10, we train 16-4-WideResNets <ref type="bibr" target="#b43">(Zagoruyko &amp; Komodakis, 2016)</ref>. On Imagenet, we compare Vision Transformers (ViTs) <ref type="bibr" target="#b15">(Dosovitskiy et al., 2020)</ref>, Residual Neural Networks (ResNets) <ref type="bibr" target="#b20">(He et al., 2016)</ref> and Normalizer-Free ResNets (NF-ResNets) <ref type="bibr" target="#b6">(Brock et al., 2021b)</ref>. We fix ? = 1/N where N is the number of samples for each experiment and report the corresponding value of ?. We use C = 1 for the clipping factor in Equation 2 as we did not see any improvement using other values. We use the Opacus <ref type="bibr" target="#b41">(Yousefpour et al., 2021)</ref> library in Pytorch <ref type="bibr" target="#b29">(Paszke et al., 2019)</ref>. We open-source the training code at https://github.com/facebookresearch/tan.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">IMAGENET</head><p>In Section 4.2.1, we use our simulated training with constant TAN to find optimal hyperparameters at low compute and improve performance for reference privacy parameters (B ref , ? ref , S) = (16384, 2.5, 72k). In Section 4.2.2, we find optimal privacy parameters at constant TAN by changing the number of steps S, leading to a new state of the art on ImageNet for ? = 8 <ref type="table" target="#tab_1">(Table 1)</ref>.  We try different types of data augmentation, that we referred to as "RRC", "Ours" and "SimCLR", and try for each various multiplicity of augmentations (1, 2, 4, 8, 16) (see Appendix C for details).</p><p>? RRC: a standard random resized crop (crop chosen at random with an area between 8% and 100% of the original image and random aspect ratio in [3/4, 4/3]), ? Ours: random crop around the center with 20 pixels padding with reflect, random horizontal flip and color jitter; ? SimCLR: the augmentation from , including color jitter, grayscale, gaussian blur and random resized crop, horizontal flip.</p><p>We find <ref type="table" target="#tab_2">(Table 2</ref>) that optimal parameters are the same in each scenario of simulation, as predicted in Section 3.3. We perform one run with these optimal parameters at B = 16384 which satisfies a privacy budget of ? = 8. Note that we use multiple batch sizes only to support our hypothesis and batch scaling law, but it is sufficient to simulate only at B = 128. Our experiments indicate that AugMult is the most beneficial when the corresponding image augmentations are rather mild.</p><p>Testing with augmentations. We also test the model using a majority vote on the augmentations of each test image (AugTest column in <ref type="table" target="#tab_2">Table 2</ref>). We use the same type and number of augmentations as in training. It improves the final top-1 test accuracy. This is in line with a recent line of work aiming at reconciling train and test modalities <ref type="bibr" target="#b35">(Touvron et al., 2019)</ref>. To provide a fair comparison with the state of the art, we decide not to include this gain in the final report in <ref type="table" target="#tab_1">Table 1 and Table 4</ref>.</p><p>Choice of architecture and optimizer. We have experimented with different architectures (ViTs, ResNets, NFResnets) and optimizers (DP-Adam, DP-AdamW, DP-SGD) (see Appendix B for details). Our best results are obtained using a NFResnet-50 and DP-SGD with constant learning rate, which differs from standard practice in non-private training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">PRIVACY PARAMETER SEARCH AT CONSTANT TAN</head><p>While we kept S constant in previous experiments, we now explore constant TAN triplets (q, ?, S) by varying S. We keep ? fixed to 2.5 and vary (B, S) starting from the reference (16384, 72K) at constant ? = q 2 S/(2? 2 ). Given that ? &gt; 2, we stay in the almost constant privacy regime (see <ref type="figure" target="#fig_1">Figure 2</ref>): we indeed observe ? ? ? TAN in <ref type="table" target="#tab_4">Table 4</ref>. We scale the learning rate inversely to S to compensate for the decrease of the noisy updates' magnitude (Equation 2). Since performing this privacy parameter search is computationally intensive, we first simulate training using our scaling law at B = 256 (with the same ? step ) and display our results in <ref type="table" target="#tab_3">Table 3</ref>. Our best results are obtained for 18k steps. Finally, we perform one computationally expensive run at S = 18k and B = 32768, with other hyper-parameters from Section 4.2.1, and show the results in <ref type="table" target="#tab_4">Table 4</ref>. We note an improvement over our previous best performance at (B, ?, S) = (16384, 2.5, 72K) referred in <ref type="table" target="#tab_2">Table 2</ref>. Overall, we improved performance by 9% when training from scratch on Im-ageNet with DP-SGD under ? = 8. We compare to our reproduction of the previous SOTA of <ref type="bibr" target="#b12">De et al. (2022)</ref> at 30.2% (compared to the results reported in the original paper (32.4%), we still gain 7% of accuracy). Thus, we have shown how we can use TAN to perform optimal privacy parameter search while simulating each choice of optimal parameters at a much smaller cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">ABLATION</head><p>We now illustrate the benefit of TAN for ablation analysis. We study the importance of the order between activation and the normalization layers when training with DP-SGD. We also discuss how gathering more training data helps improve performance while decreasing the privacy budget. On both experiments, we train a 16-4-WideResnet on CIFAR-10, constant learning rate at 4, and we are studying (B ref , ? ref , S) = (4096, 3, 2.5k) (reference private training).</p><p>Pre-activation vs Post-activation Normalization Normalization techniques such as BatchNorm <ref type="bibr" target="#b21">(Ioffe &amp; Szegedy, 2015)</ref>, GroupNorm (GN) <ref type="bibr" target="#b39">(Wu &amp; He, 2018)</ref> or LayerNorm <ref type="bibr" target="#b3">(Ba et al., 2016)</ref> help training DNNs. Note that BatchNorm is not compatible with DP-SGD because it is not amenable to per-sample gradient computations, we thus resort to GroupNorm. These normalization layers are usually placed between convolutional layers and activations (e.g., CONV-GN-ReLU). <ref type="bibr" target="#b5">Brock et al. (2021a)</ref> suggest that signal propagation improves when the order is reversed (to CONV-ReLU-GN).</p><p>We experiment with DP-SGD training using both orders of layers, and display our results in <ref type="figure" target="#fig_2">Figure 5</ref>. We make two observations. First, the reverse order leads to significantly greater performance, and is  7.3 72.9(?0.1) 50K</p><p>7.1 74.0 (?0.5) more robust. Second, the standard order does not benefit from data augmentation. We observe that the two simulated experiments with B = 512 represented by lighter colors in <ref type="figure" target="#fig_2">Figure 5</ref> (2 standard deviations around the means) have the same properties. However, each simulation is 8 times less computationally expensive. Therefore, using TAN through our scaling law can facilitate studying variants of the network architecture while reducing the computational costs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantity of Data and Privacy Budget</head><p>We now look at how collecting more data affects the tradeoff between privacy and utility. We show that doubling the data (from the same distribution) allows better performance with half the privacy budget. To this end, we train on portions of the CIFAR-10 training set (N = 50k) and always report accuracies on the same test set. If we multiply by ? the quantity of data N 0 and keep the same (B, ?, S), q (and thus ?), is divided by ? as well. We divide ? by ? for the accounting. We show in <ref type="table" target="#tab_5">Table 5</ref> the effects on ? and model accuracy.</p><p>On the one hand, when using ? TAN , we can predict the impact on the privacy budget. On the other hand, since the global signal-to-noise ratio N ? is held constant in all experiments, we expect to extract the same amount of information in each setup; adding more data makes this information richer, which explains the gain in accuracy. We show similar results for ImageNet in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>We argue that the total amount of noise (TAN) is a simple but useful guiding principle to experiment with private training. In particular, we demonstrate that the privacy budget is either a direct function of TAN or can be reduced. We further show that scaling batch size with noise level using TAN allows for ultra-efficient hyper-parameter search and demonstrate the power of this paradigm by establishing a new state of the art for DP training on Imagenet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">LIMITATIONS</head><p>Non-private hyper-parameter search. We follow the standard practice of not counting hyperparameter search towards the privacy budget <ref type="bibr" target="#b25">(Li et al., 2021b;</ref><ref type="bibr" target="#b2">Anil et al., 2021)</ref>. Theoretically, each training run should be charged on the overall budget, but in practice it is commonly assumed that the "bandwidth" of hyper-parameters is too small to incur any observable loss of privacy (see also <ref type="bibr" target="#b26">Liu &amp; Talwar (2019)</ref> for a theoretically sound way of handling this problem). For some private datasets, it is possible to use a similar public dataset (such as Imagenet) to choose hyper-parameters, and then perform only limited runs on the private dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">FURTHER WORK</head><p>Better accounting. We believe that the exponential increase in the privacy budget ? as the noise level ? decreases is a real phenomenon and not an artifact of the analysis. Indeed, DP assumes that the adversary has access to all model updates, as is the case for example in Federated Learning. In such cases, a noise level that is too low is insufficient to hide the presence of individual data points and makes it impossible to obtain reasonable privacy guarantees. In the centralized case however, the adversary does not see intermediate models but only the final result of training. Some works have successfully taken into account this "privacy amplification by iteration" idea <ref type="bibr" target="#b17">(Feldman et al., 2018;</ref><ref type="bibr" target="#b40">Ye &amp; Shokri, 2022)</ref> but results are so far limited to convex models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A MORE DATA: IMAGENET</head><p>We show in <ref type="table">Table 6</ref> that similarly to the experiments in CIFAR-10, doubling the training data on ImageNet improves the accuracy while diving ? by 2. We also demonstrate that our scaling strategy can accurately detect the gain of accuracy. We compare training on half of the ImageNet training set (N = 600k) and the entire training set (N = 1.2M ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B CHOICE OF ARCHITECTURE AND OPTIMIZER</head><p>In this section, we give more details about our choice of architecture and optimizer on ImageNet. In particular, we noticed that DP-SGD without momentum is always optimal, even with ViTs, and that NF-ResNets-50 performed the best.</p><p>Architecture. When training with DP-SGD, the goal is to find the best possible local minimum within a constrained number of steps S, and with noisy gradients. However, architectures and optimizers have been developed to ultimately achieve the best possible final accuracy with normal updates. To illustrate this extremely, we train a Vision Transformer (ViT) <ref type="bibr" target="#b15">(Dosovitskiy et al., 2020)</ref> from scratch on ImageNet using DP-SGD. <ref type="bibr" target="#b36">Touvron et al. (2020)</ref> have succeeded in achieving SOTA performance in the non-private setting, but with a number of training steps higher than convolutionbased architectures. A common explanation is that ViTs have less inductive bias than CNNs: they have to learn them first, and that can be even harder with noisy gradients. And if they are successful, they have lost the budget for gradient steps to learn general properties of images.</p><p>We used our scaling strategy (keeping ? step and S constant) to simulate the DP training with different architectures at low compute, studying noisy training without the burden of DP accounting. The best simulated results were obtained with a NFResNet-50 <ref type="bibr" target="#b6">(Brock et al., 2021b)</ref> designed to be fast learners in terms of number of FLOPS. The worst results were obtained with ViTs, and intermediate results with classical ResNets. In <ref type="figure">Figure 6</ref>, we compare different training trajectories of a ViT and a NF-ResNet.</p><p>Optimizer Using our simulation scheme, we found that DP-SGD with no momentum and a constant learning rate is the best choice for all architectures. We also tried DP-Adam, DP-AdamW with a wide range of parameters. It is surprising to find that this is the case for ViTs, as without noisy, the Adam type optimizers perform better <ref type="bibr" target="#b36">(Touvron et al., 2020)</ref>. This highlights the fact that training with DP-SGD is a different paradigm that requires its own tools.</p><p>Using TAN allowed us to explore and compare different architectures and optimizers, which would have been computationally impossible in the normal DP training setting at B = 16384.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C AUGMENTATION MULTIPLICITY</head><p>Augmentation Multiplicity (AugMult) was introduced by <ref type="bibr" target="#b12">De et al. (2022)</ref> in the context of DP-SGD. The authors average the gradients of different augmentations of the same image before clipping the per-sample gradients, using the following formula (where ? is a standard Gaussian variable): <ref type="table">Table 6</ref>: Impact of adding more data on ImageNet. The "Simulated Gain" column corresponds to the accuracy gain we observe when simulating at lower compute using our scaling strategy for B = 256. The "Gain" column corresponds to the real gain at B = 16384. ViT, AugMult=16 NF-ResNet-50, AugMult=0 <ref type="figure">Figure 6</ref>: Training a ViT from scratch on ImageNet with DP-SGD. We simulate training with our scaling strategy and B = 256. We observe that the accuracies are not as good as for NF-ResNets, and that Augmentation Multiplicity plays a more important role.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Imagenet</head><formula xml:id="formula_10">w t+1 = w t+1 ? ? t ? ? 1 B i?Bt 1 C clip C ? ? 1 K j?Kt ? j (w (t) ) ? ? + N 0, ? 2 B 2 ? ?<label>(5)</label></formula><p>Compute scales linearly with the AugMult order K. Our intuition on the benefits of AugMult is that difficult examples (or examples that fall out of the distribution) become easier when using this augmentation technique. On the other hand, without AugMult, simple examples are learned to be classified early in training, resulting in a gradient close to 0 when used without augmentation. Because we are training for a fixed number of steps, it is a waste of gradient steps (i.e. privacy budget). With AugMult, the network may still be able to learn from these examples. <ref type="figure">Figure 7</ref> shows the histograms of the norms of the average over all augmentations for each image of the per-sample gradients, before clipping and adding noise in equation 5 at different times of training. <ref type="figure">Figure 7</ref>: Histograms of the norms of the average across all augmentations for each image of the per-sample gradients, before clipping and adding noise. On the left, we see that without augmentation, an increasing number of examples have their gradients going to zero during training. On the right, we see that when using a strong augmentation technique (SimCLR, ), the gradients are more concentrated during all the training.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Training with DP-SGD on ImageNet for a constant number of steps S = 72k. All points are obtained at constant ?/B, with ? ref = 2.5 and B ref = 16384. The dashed lines are computed using a linear regression on the crosses, and the dots and stars illustrate the predictive power of TAN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Privacy budget ? as a function of the noise level ? with ? constant. On both figures, each curve corresponds to a different number of steps S, and each point on the curve is computed at a sampling rate q such that ? is constant. On the left, we use ? = 0.13 (resulting in ? TAN = 1 in Equation 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Impact of data augmentation on the test accuracy using pre-activation normalization vs post-activation in a 16-4-WideResnet on CIFAR-10. We compare simulation at (B, ?) = (512, 3 8 ) and reference (B ref , ? ref ) = (4096, 3), both trained for S = 2,500 steps. Confidence intervals are plotted with two standard deviations over 5 runs. Augmentation Multiplicity Order corresponds to the number of augmentations per image, or K in Appendix C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>CIFAR-10 for B ref = 4096 and S ref = 2500 ImageNet for Bref = 16384, ref = 2.5 Figure 4: Test accuracies at constant ? step and S are (log) linearly decreasing with B. Dashed lines are computed using a linear regression on the crosses. Shaded areas correspond to 3 std confidence intervals. (Left) CIFAR-10 with 16-4-WideResNet. Each curve corresponds to a different value of ? step . (Right) ImageNet with NF-ResNet-50 with various numbers of steps. The scaling law holds for various training configurations.</figDesc><table><row><cell>Top 1 Test Accuracy</cell><cell>60 65 70 75 80 85 90</cell><cell>TAN: ref = 0.5 ref = 3 ref = 5 ref = 1</cell><cell>Top 1 Test Accuracy</cell><cell>20 25 30 35 40 45</cell><cell>TAN: S=72k S=50k S=30k Previous SOTA at = 8</cell></row><row><cell></cell><cell>128</cell><cell>256</cell><cell>512 1024 2048 4096 8192 16384 Batch Size</cell><cell></cell><cell>128 256 512 1024 2048 4096 8192 16384 32768 Batch Size</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Top-1 test accuracy when training on ImageNet from scratch using DP-SGD. We train a NF-ResNet-50 with ? = 2.5, hyper-parameters ofTable 2and (B, S) = (32768, 18k)(Table 4).</figDesc><table><row><cell>Method</cell><cell>(?, ?)</cell><cell>Accuracy</cell></row><row><cell>Kurakin et al. (2022)</cell><cell>(13.2, 10 ?6 )</cell><cell>6.2%</cell></row><row><cell>De et al. (2022) (original paper)</cell><cell>(8, 8.10 ?7 )</cell><cell>32.4%</cell></row><row><cell cols="2">De et al. (2022) (our reproduction) (8, 8.10 ?7 )</cell><cell>30.2%</cell></row><row><cell>Ours</cell><cell>(8, 8.10 ?7 )</cell><cell>39.2%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparing optimal hyper-parameters. Keeping ? step and S constant, we compare various changes in the training pipeline. We compare with the baseline of De et al.</figDesc><table><row><cell>(2022) (blue line in Fig-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Low compute simulation of privacy parameter search. We start from B = 256 = 16384/64 and S = 72K. We use ? = 2.5/64 for all runs and no data augmentation.B ref = 256, S ref = 72K</figDesc><table><row><cell>S</cell><cell>B</cell><cell>lr</cell><cell>Gain</cell></row><row><cell>9K</cell><cell cols="3">756 64 -6.22%</cell></row><row><cell cols="4">18K 512 32 +1.32%</cell></row><row><cell cols="3">72K 256 8</cell><cell>/</cell></row><row><cell cols="3">288K 128 2</cell><cell>-1.88%</cell></row><row><cell cols="4">4.2.1 HYPER-PARAMETER TUNING AT CONSTANT TAN</cell></row><row><cell cols="4">Hyper-parameter search. We run a large hyper-parameter search and report the best hyper-</cell></row><row><cell cols="4">parameters in Table 2 as well as the corresponding improvement for various batch sizes (at constant</cell></row><row><cell cols="4">? step and S). Each gain is compared to the optimal hyper-parameters find at the previous column.</cell></row><row><cell cols="4">We search over learning rates lr ? [1, 2, 4, 8, 12, 16], momentum parameters ? ? [0, 0.1, 0.5, 0.9, 1]</cell></row><row><cell cols="4">and dampening factors d ? [0, 0.1, 0.5, 0.9, 1]. We use exponential moving average (EMA) on the</cell></row><row><cell cols="4">weights (Tan &amp; Le, 2019) with a decay parameter in [0.9, 0.99, 0.999, 0.9999, 0.99999].</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Privacy parameter search. We use the optimal parameters described in Section 4.2.1 with ? = 2.5 for one expensive run and compare it with our optimal resultB ref = 16384, S ref = 72K</figDesc><table><row><cell>S</cell><cell>B</cell><cell>?</cell><cell cols="2">lr Test acc</cell></row><row><cell cols="4">18K 32,768 8.00 32</cell><cell>39.2%</cell></row><row><cell cols="4">72K 16,384 7.97 8</cell><cell>36.9%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Impact of the training set size N on the privacy/utility trade-off. We start training on 10% of the data (N 0 = 5K). We use B = 4,096, ? = 3 and S = 2,500, with post-activation normalization, and no augmentation. Standard deviations are computed over 3 runs.</figDesc><table><row><cell cols="3">CIFAR-10: ? = 3, B = 4,096, S = 2,500</cell></row><row><cell>N</cell><cell>?</cell><cell>Test acc (%)</cell></row><row><cell cols="2">5K 150.3</cell><cell>59.9 (?1)</cell></row><row><cell cols="2">25K 13.7</cell><cell>71.1 (?0.4)</cell></row><row><cell>40K</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>: ? ref = 2.5, B ref = 16384, S = 72k</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="4">NF-ResNet VS ViT on Imagenet with DP-SGD</cell></row><row><cell></cell><cell>0.5</cell><cell></cell><cell cols="2">ViT, AugMult=0 ViT, AugMult=4</cell><cell></cell></row><row><cell>Top 1 Test Accuracy</cell><cell>0.1 0.2 0.3 0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0</cell><cell>0</cell><cell>20</cell><cell cols="3">40 Percentage of Training 60</cell><cell>80</cell><cell>100</cell></row><row><cell></cell><cell></cell><cell>N</cell><cell>?</cell><cell>?</cell><cell>? T AN</cell><cell>Gain</cell><cell>Simulated Gain</cell></row><row><cell></cell><cell></cell><cell cols="4">0.6M 16.10 ?7 17.98 18.06</cell><cell>/</cell><cell>/</cell></row><row><cell></cell><cell></cell><cell cols="2">1.2M 8.10 ?7</cell><cell>8.00</cell><cell>8.26</cell><cell>+1.3%</cell><cell>+1.5%</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2016 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep speech 2: End-toend speech recognition in english and mandarin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishita</forename><surname>Sundaram Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingliang</forename><surname>Anubhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Battenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Case</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Large-scale differentially private bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Badih</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasin</forename><surname>Manurangsi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2108.01624" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Layer normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1607.06450" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hypothesis testing interpretations and R?nyi differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Barthe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Gaboardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuya</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2496" to="2506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Characterizing signal propagation to close the performance gap in unnormalized resnets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soham</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2101" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">High-performance large-scale image recognition without normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soham</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2102" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<editor>Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Ilya Sutskever, and Dario Amodei. Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gray</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2005.14165" />
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The secret sharer: Evaluating and testing unintended memorization in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?lfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jernej</forename><surname>Kos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="267" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Extracting training data from large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulfar</forename><surname>Erlingsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th USENIX Security Symposium (USENIX Security 21)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2633" to="2650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno>abs/2002.05709</idno>
		<ptr target="https://arxiv.org/abs/2002.05709" />
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Unlocking high-accuracy differentially private image classification through scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soham</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Berrada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Balle</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2204.13650" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2009.5206848</idno>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><forename type="middle">Toutanova</forename><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2010.11929" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kobbi</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Theory of Cryptography</title>
		<meeting>the Third Conference on Theory of Cryptography</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="265" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Privacy amplification by iteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhradeep</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="521" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Numerical composition of differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivakanth</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin Tat</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Wutschitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11631" to="11642" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>abs/1502.03167</idno>
		<ptr target="http://arxiv.org/abs/1502.03167" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Toward training at imagenet scale with differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roxana</forename><surname>Geambasu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2201.12328" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>Andreas Terzis, and Abhradeep Thakurta</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Large language models can be strong differentially private learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Tram?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2110.05679" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Large language models can be strong differentially private learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Tram?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Private selection from private candidates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing (STOC)</title>
		<meeting>the 51st Annual ACM SIGACT Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="298" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">R?nyi differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 30th Computer Security Foundations Symposium (CSF)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="263" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10530</idno>
		<title level="m">R?nyi differential privacy of the Sampled Gaussian Mechanism</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, highperformance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susannah</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albin</forename><surname>Cassirer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maribeth</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amelia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saffron</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonia</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nat</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhant</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esme</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michela</forename><surname>Paganini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lena</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adhiguna</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aida</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Nematzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Domenic</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Donato</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2112.11446" />
		<editor>Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de Masson d&apos;Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew Johnson, Blake Hechtman, Laura Weidinger, Iason Gabriel, William Isaac, Ed Lockhart, Simon Osindero</editor>
		<imprint>
			<date type="published" when="2021" />
			<pubPlace>Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu</pubPlace>
		</imprint>
	</monogr>
	<note>and Geoffrey Irving. Scaling language models: Methods, analysis &amp; insights from training gopher</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Hierarchical textconditional image generation with clip latents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2204.06125" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1409.0575" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Imagenet large scale visual recognition challenge</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">On the generalization benefit of noise in stochastic gradient descent. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soham</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2006" />
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Fixing the train-test resolution discrepancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno>abs/2012.12877</idno>
		<ptr target="https://arxiv.org/abs/2012.12877" />
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Differentially private learning needs better features (or much more data)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Boneh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Subsampled r?nyi differential privacy and analytical moments accountant. CoRR, abs/1808.00087</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiva</forename><surname>Prasad Kasiviswanathan</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1808.00087" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Group normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1803.08494" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Differentially private learning needs hidden state (or much faster convergence)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.05363</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Opacus: User-friendly differential privacy library in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashkan</forename><surname>Yousefpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Shilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Testuggine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mani</forename><surname>Malek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sayan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akash</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Differentially private fine-tuning of language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arturs</forename><surname>Backurs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivakanth</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Huseyin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautam</forename><surname>Inan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janardhan</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kulkarni</surname></persName>
		</author>
		<editor>Yin Tat Lee, Andre Manoel, Lukas Wutschitz, Sergey Yekhanin, and Huishuai Zhang</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Wide residual networks. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno>abs/1605.07146</idno>
		<ptr target="http://arxiv.org/abs/1605.07146" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
