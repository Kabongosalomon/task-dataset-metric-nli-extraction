<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Revisiting Unsupervised Meta-Learning via the Characteristics of Few-Shot Tasks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Journal Of L A T E X Class</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Files</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vol</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xx</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">X</forename><surname>No</surname></persName>
						</author>
						<title level="a" type="main">Revisiting Unsupervised Meta-Learning via the Characteristics of Few-Shot Tasks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T17:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Unsupervised Meta-Learning</term>
					<term>Few-Shot Learning</term>
					<term>Meta-Learning</term>
					<term>Self-Supervised Learning !</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Meta-learning has become a practical approach towards few-shot image classification, where "a strategy to learn a classifier" is meta-learned on labeled base classes and can be applied to tasks with novel classes. We remove the requirement of base class labels and learn generalizable embeddings via Unsupervised Meta-Learning (UML). Specifically, episodes of tasks are constructed with data augmentations from unlabeled base classes during meta-training, and we apply embedding-based classifiers to novel tasks with labeled few-shot examples during meta-test. We observe two elements play important roles in UML, i.e., the way to sample tasks and measure similarities between instances. Thus we obtain a strong baseline with two simple modifications -a sufficient sampling strategy constructing multiple tasks per episode efficiently together with a semi-normalized similarity. We then take advantage of the characteristics of tasks from two directions to get further improvements. First, synthesized confusing instances are incorporated to help extract more discriminative embeddings. Second, we utilize an additional task-specific embedding transformation as an auxiliary component during meta-training to promote the generalization ability of the pre-adapted embeddings. Experiments on few-shot learning benchmarks verify that our approaches outperform previous UML methods and achieve comparable or even better performance than its supervised variants. 1. The "shot" means a training example per class. Labeled Base Class Set Labeled Novel Class set support set query set support set query set~U nlabeled Base Class Set Labeled Novel Class set unlabeled support set support set query set unlabeled query set Labeled Instances Unlabeled Instances (a) Supervised Meta-Learning (b) Unsupervised Meta-Learning Tasks With Real Labels Tasks With Pseudo-Labels Meta-Training Stage Meta-Test Stage Meta-Training Stage Meta-Test Stage 2 RELATED WORK Meta-learning for Few-Shot Learning (FSL). Training a high-quality visual recognition system usually requires an ample number of annotated training set with many shots [27], [28], and a few-shot training set makes the model prone to overfitting. FSL aims to enable the classification on a few-shot support set with novel classes given labeled data-rich base classes [29], [9], [30], [13], [31]. Meta-learning has become an effective tool for FSL, which generalizes a "learning strategy" from base to novel classes. One main thread of meta-learning considers transferable embeddings [10], [32], [33], [34], [11], [17], so that with the help of a non-parametric nearest neighbor classifier, novel class instances could be recognized given a few labeled examples. Other meta-learning methods explore the meta-model with initialization [9], [13], [35], optimization policies [12], [33], image generator [14], and the mapping from data to classifier [36], [37]. [38] analyzes FSL in a causal view. FSL has achieved promising results in various domains [39], [40], [41], [42], [43]. Empirical studies of FSL are in [44], [45], [15], [46]. Meta-learning with unlabeled data. Despite the success of FSL on novel classes in deployment, meta-learning requires plenty of base class labels during meta-training. One intuitive way is to utilize unlabeled data during episodic learning. In semi-supervised meta-learning, there is a pool set containing unlabeled instances even from distractor classes associated with the support set [47], [48], [49], [50]. Transductive FSL assumes all query set instances arrive simultaneously, and treat the unlabeled query set as an auxiliary set [51], [52], [53]. The relationship between unlabeled data and labeled support set facilitates the meta-model construction. Unsupervised Meta-learning (UML) trains an effective meta-model without base class labels [22], [54]. One main obstacle is how to enable episodic training in this unsupervised scenario. By substituting "classes" in the base class with "pseudo-classes", we could easily extend supervised meta-learning to an unsupervised manner. [55] utilizes off-the-shelf embedding learning methods and generates pseudo-classes by clustering multiple times, but the quality of those pseudo-labels is highly related to the results of clustering [56], [57]. Benefiting from semantic consistency among the perturbed views of a single instance, we can treat augmented versions of an instance as if they are in the same pseudo-class. Both embedding-based [58] and optimizationbased [23] methods are investigated. Empirical results show</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>T HE Few-Shot Learning (FSL) ability <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, i.e., training a model with limited data, is essential in various fields, e.g., visual recognition <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> and object detection <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. <ref type="bibr" target="#b0">1</ref> A large number of labeled classes are collected at first. By learning on these base classes, our goal is to enable the FSL over non-overlapping novel classes -a model trained on a novel few-shot support set should recognize new instances of those novel classes. Generalizable component across base and novel classes such as embedding is the key to FSL.</p><p>Meta-learning has become one popular approach for FSL, where a meta-model encodes a generalizable "learning strategy" to train a classifier given a few-shot support set <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b8">[9]</ref>. In detail, episodes of (pseudo) tasks from base classes are sampled to mimic the target FSL scenario on novel classes, where each few-shot support set of a task is associated with a query set sharing the same set of classes. We optimize the meta-model to make the "learning strategy" facilitate the query set classification conditioned on the support set. For example, we can implement the meta-model via embedding function (the feature extractor). Then the "learning strategy" becomes an embedding-based classifier, which predicts a query instance through its neighbors in the support set. By minimizing classification losses over sampled tasks, the metamodel is expected to extend the effectiveness of its "learning strategy" to few-shot support set with novel classes. Besides embeddings <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, we can also use optimizers <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> and image generators <ref type="bibr" target="#b13">[14]</ref> in meta-learning.</p><p>We illustrate (supervised) meta-learning in <ref type="figure" target="#fig_0">Fig. 1 (a)</ref>. Meta-learning reduces the number of labels during deployment on novel class tasks but requires a large annotated base The learned meta-model should be applied to novel classes few-shot tasks after meta-training on base classes. Although given unlabeled base classes, UML still facilitates the few-shot model construction on novel classes. class set. Labels in the base class set are essential to sample synthetic classification tasks during meta-training, and the label size is highly related to the meta-level generalization ability <ref type="bibr" target="#b14">[15]</ref>. In practice, we usually take advantage of those labels and pre-train a classifier discerning base classes to initialize the meta-model <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. Although labeled base classes help meta-learning, we should not overlook the expense of labeling them or assume that we will always have plenty of labels in meta-training. In the long run, metalearning with less base class labeling is critical for FSL.</p><p>We investigate whether we can get a few-shot classifier, implemented based on embedding, successfully via metatraining in an unsupervised manner. The notion of Unsupervised Meta-Learning (UML) is shown in <ref type="figure" target="#fig_0">Fig. 1 (b)</ref>. We save the labeling cost of the base classes in the holistic few-shot learning process while maintaining the generalizable ability of the meta-model. In other words, we only need a labeled arXiv:2011.14663v3 [cs.CV] 9 Jun 2022 few-shot support set in the meta-test phase.</p><p>Our main idea for UML follows the Supervised Meta-Learning (SML) but defines the "class" based on data augmentations <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref> -any two instances have different pseudo-class labels, and an instance is only similar to the copies augmented from itself. Then by sampling base class tasks following the pseudo-classes, the embedding could be meta-learned in the same way as SML. Empirical observations indicate that data augmentation makes reusing SML techniques in UML with minimal changes, but usually could not provide competitive results <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b22">[23]</ref> when compared with other embedding learning paradigms like self-supervised learning <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>.</p><p>We take a closer look at UML and analyze the key factors during meta-training. We observe that the strategy to sample (pseudo) tasks from the base class set and the way to measure the similarity between instances in a task play essential roles. To take full advantage of instances in a mini-batch, we propose Sufficient Episodic Sampling (SES), which efficiently re-samples multiple few-shot tasks from the same mini-batch. SES produces stable gradients without additional cost to extract features. Various similarity metrics are investigated in FSL <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b9">[10]</ref> , but they need careful calibrations via temperature tunning <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b16">[17]</ref>. We propose a novel Semi-Normalized Similarity (SNS) where only one instance in the input pair is normalized before computing their inner product. This similarity equals cosine similarity with a selflearned temperature, which softens the logits adaptively and shapes a discriminative embedding space.</p><p>The two simple modifications construct a strong UML baseline, which shows performance superiority over both UML and self-supervised learning methods on FSL benchmarks. Moreover, we delve into the characteristics of tasks and propose to further improve the discriminative as well as generalization ability of the learned UML embeddings.</p><p>First, we amplify the contrastiveness of instances in a task by synthesizing a more difficult task for each query instance. Specifically, we augment the support set dynamically through Hard Supports Mix (HMS). HMS constructs confusing instances by mixing up the query instances with the nearest ones belonging to different pseudo-classes. Differentiating over those confusing instances leads to more discriminative embeddings that generalize better to lowershot (e.g., 1-shot) tasks. On the other hand, since tasks from base and novels classes are constructed based on pseudolabels and real semantic labels, respectively, their distribution gap makes the generalization of the meta-model difficult. We mitigate the negative effects with an auxiliary Task-Specific Projection Head (TSP-Head) in meta-training. We decompose the adapted embedding function into generalizable and specific parts, where the auxiliary transformation handles the specific property of pseudo-labeled tasks and it makes the vanilla embedding generalize better, especially with relatively higher-shot (e.g., <ref type="bibr">20-shot)</ref>. In other words, during meta-training, we construct the embedding-based classifier using the adapted embeddings, but in deployment, we utilize the pre-adapted embedding before the TSP-Head.</p><p>Experiments on few-shot classification and cross-domain benchmarks demonstrate that our UML methods outperform other unsupervised, self-supervised, or even SML methods. Our main contributions could be summarized as follows:</p><p>? We analyze the factors to meta-train a UML method and propose SES and SNS as two key ingredients towards a strong UML baseline. <ref type="bibr">?</ref> We propose HMS and TSP-Head to further utilize the characteristic of tasks from different aspects, which additionally improve either lower or higher shots scenarios. ? Our UML methods outperform existing ones by a large margin with unlabeled base classes and even get better results when compared with supervised counterparts. The remaining parts start with related work and preliminaries. After a close study of key components in UML, we propose our strong UML baseline. Then we demonstrate the importance of considering the characteristic of tasks for further improvements. Last are experiments and conclusions. those direct extensions perform well and using large minibatches yields performance improvement <ref type="bibr" target="#b58">[59]</ref>, but a large gap still exists with their supervised counterparts <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b22">[23]</ref>. We fill the gap between UML and its supervised upper bound by taking account of the task's characteristics in efficient episodic training. Our methods outperform current ones and get similar results with supervised methods. Self-Supervised Learning (SSL) is another possible way of learning the embedding in an unsupervised manner <ref type="bibr" target="#b60">[61]</ref>. Based on pre-text tasks without explicit usage of labels, the representation of objects becomes more discriminative and generalizable to "downstream" tasks <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b63">[64]</ref>, <ref type="bibr" target="#b64">[65]</ref>, <ref type="bibr" target="#b65">[66]</ref>, <ref type="bibr" target="#b66">[67]</ref>. Inspired by the similarity between embeddingbased meta-learning and contrastive SSL methods <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, we can treat novel few-shot tasks as "downstream" ones so that the SSL-learned embeddings could help UML accordingly. Several recent approaches apply SSL with both supervised <ref type="bibr" target="#b67">[68]</ref> and unsupervised meta-learning <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b68">[69]</ref>, and demonstrate that an auxiliary self-supervised objective helps. They get a bit "counter-intuitive" results that SSL benefits more than episodic training, where the latter mimics the few-shot tasks in deployment during meta-training. For example, <ref type="bibr" target="#b59">[60]</ref> investigates MoCo <ref type="bibr" target="#b23">[24]</ref> in UML and shows MoCo outperforms many UML methods. Although SSL methods narrow the gap between UML and the supervised methods, those specific properties of tasks captured by the episodic sampling are neglected. After analyzing key factors of the meta-training in UML, we enable the episodic metatraining to get discriminative embeddings by designing special sampling and similarity measure strategies. Our UML baseline and improved variants outperform the embeddings learned by SSL methods. Experiments show that those SSL methods require deeper backbone architectures and longer training epochs to perform comparably with our methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARY OF UML</head><p>Unsupervised Meta-Learning (UML) for Few-Shot Learning (FSL). We define a task as a couple of a K-shot N -way support set S and a Q-shot N -way query set Q. The support set S = {(x i , y i )} N K i=1 contains N classes and K training examples per class. x i ? R D is an instance and y i ? {0, 1} N is its one-hot label. The query set Q has instances from the same distribution with S, which is used to evaluate the classifier trained on S. The target of FSL is to learn a classifier from a few-shot S with small K and to make the classifier has high discerning ability on the corresponding Q.</p><p>In UML, we have a related but unlabeled base class set B (a.k.a. meta-train set). The goal of UML is to find a "learning strategy" such as an embedding-based classifier from B, which could be generalized to few-shot support set with non-overlapping N novel classes (a.k.a. meta-test set). In other words, we first learn a meta-model f from B, which facilitates the construction of the task-specific classifier, i.e., f predicts a query instance in Q conditioned on the set of N K instances in S. The prediction rule f (x j ; S) is expected to generalizes to the target few-shot tasks with novel classes. We denote the two phases on base and novel classes -learning and evaluating f -as meta-training and meta-test, respectively.</p><p>Episodic Sampling in UML. Following supervised metalearning, UML mimics the target few-shot task via sampling episodes of pseudo tasks from B <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b54">[55]</ref>. Denote (?, ?) as the loss function which measures the discrepancy between the prediction and the target label. We meta-learn f with</p><formula xml:id="formula_0">min f E (S,Q)?B (xj ,yj )?Q (f (x j ; S) , y j ) .<label>(1)</label></formula><p>By minimizing Eq. 1 over sampled meta-training (pseudo) tasks, the experience in constructing an effective classifier with a few-shot support set (encoded in f ) is expected to be transferred to meta-test tasks with novel classes.</p><p>One key factor in UML is how to sample episodes of support and query sets from B. In the supervised scenario, all instances in B has a class label, so that in each episode we randomly choose N categories in B and K (resp. Q) examples from each category are preserved for support set S (resp. query set Q). The same sampling method cannot be applied to unlabeled B. Some UML methods also utilize clustering to generate pseudo-classes for instances in B <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b55">[56]</ref>. We use a simpler strategy that takes advantage of the semantic consistency among augmentations of images <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. In particular, we treat an instance and its augmentations (e.g., random crop and horizontal flip) come from the same pseudo-class, and any two instances have different pseudo-labels. In this exemplar view, the sampled K-shot N -way support instances are the K random copies of N different images, and the query set contains another Q copies per pseudo-class.</p><p>Both clustering-based and augmentation-based pseudolabeling strategies make the objective in Eq. 1 biased. For example, when we generate pseudo-labels via augmentations, although we ensure two augmented instances come from the same semantic classes, we may label semantically similar instances with different pseudo-classes <ref type="bibr" target="#b69">[70]</ref>, <ref type="bibr" target="#b70">[71]</ref>. <ref type="bibr" target="#b71">[72]</ref> proves that a rich embedding family together with some conditions may overcome the limitations of the false negative sampling. In practice, various self-supervised learning approaches use the augmentation-based labeling strategy to get stable and promising results <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. Thus, we consider data augmentation for pseudo-labeling. Similarity Measures in UML. Another key factor in UML is the implementation of f as an embedding-based classifier. We consider f as a d-dimensional embedding function, i.e., f = ? : R D ? R d . Denote y i = n selecting instances in the n-th (pseudo) class, the corresponding class center is p n = 1 K yi=n ?(x i ). The confidence of a query instance x j belonging to the N classes is based on the similarity Sim(?, ?) between the query embedding and N centers <ref type="bibr" target="#b9">[10]</ref>:</p><formula xml:id="formula_1">y j = f (x j ; S) = Softmax Sim(?(x j ), p n ) (2) = exp(Sim(?(x j ), p n )) N n =1 exp (Sim(?(x j ), p n )) N n=1 .</formula><p>Through the nearest class mean classifier, the larger the similarity between a query instance with a support center, the larger the probability the query instance comes from the corresponding class. Sim(?, ?) in Eq. 2 could be various metrics, for example, the negative Euclidean distance <ref type="bibr" target="#b9">[10]</ref>: for all (x j , y j ) ? Q do <ref type="bibr">6:</ref> Get f (x j , S) with selected metric <ref type="bibr">7:</ref> Compute (f (x j , S), y j ) 8: end for <ref type="bibr">9:</ref> Accumulate loss for all x j as Eq. 1 <ref type="bibr">10:</ref> Update ? with SGD 11: end for <ref type="bibr">12:</ref> return Embedding ? Algorithm 2 Meta-test for UML. Require: A labeled support set S and an unlabeled query instance x j (from non-overlapping novel class w.r.t. B), the meta-learned embedding ? 1: Compute p n for all n = 1, . . . , N classes 2: Compute Sim(?(x j ), p n ) with selected metric and ? 3: Predict via arg max n Sim(?(x j ), p n ) 4: return The predicted label of x j the cosine similarity <ref type="bibr" target="#b3">[4]</ref> Sim</p><formula xml:id="formula_2">Sim dis (?(x j ), p n ) = ? ?(x j ) ? p n 2 2 ,<label>(3)</label></formula><formula xml:id="formula_3">cos (?(x j ), p n ) = ?(x j ), p n ?(x j ) p n ,<label>(4)</label></formula><p>or the inner product</p><formula xml:id="formula_4">Sim inner (?(x j ), p n ) = ?(x j ), p n .<label>(5)</label></formula><p>Different similarities have diverse effects on the meta-learned embeddings. <ref type="bibr" target="#b9">[10]</ref> argues that there is a scale difference between the negative distance and cosine similarity, and <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b31">[32]</ref> propose to scale Sim(?, ?) with an additional temperature ? , i.e., Sim(?, ?)/? , to smooth the logit in Eq. 2. A large temperature ? pushes the query embeddings away from all non-belonging centers, while a smaller ? concentrates the force to push the closest wrongly assigned centers <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b72">[73]</ref>. <ref type="bibr" target="#b16">[17]</ref> verifies the importance of ? especially when the embedding is initialized with pre-trained weights. <ref type="bibr" target="#b73">[74]</ref> points out the cosine similarity with normalized embeddings works better with a pre-trained model for supervised FSL. Therefore, the way to measure instances in a task and the temperature influence the discriminative ability of the embeddings. Summary and discussions of UML. Optimizing Eq. 1 with Eq. 2 meta-learns the embedding ? in a contrastive mannerinstances are pulled to its center with the same pseudo-label, while those with different pseudo-labels are pushed away. We find this vanilla UML method could generate semantically meaningful embeddings and helps few-shot tasks with novel "non-pseudo" classes, which is also validated in <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b58">[59]</ref>. The meta-training and meta-test phases of the vanilla UML are described in Alg. 1 and Alg. 2, respectively. Inspired by the fact that self-supervised learning methods utilize data augmentation to achieve similar results with their supervised counterparts <ref type="bibr" target="#b74">[75]</ref>, <ref type="bibr" target="#b75">[76]</ref>, we also expect UML to have similar properties. However, empirical results indicate there exists a large gap between UML and supervised metalearning on FSL benchmarks <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b58">[59]</ref>. Despite mimicking FSL tasks, the episodic training in UML cannot introduce additional benefits when compared with "plain" trained embeddings with self-supervised learning ways <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b68">[69]</ref>. We find that the vanilla UML could be strong once equipped with simple modifications on key meta-training factors, facilitating filling the gap with its supervised upper bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ANALYZING META-TRAINING FACTORS IN UML</head><p>We investigate two key factors, i.e., the episodic sampling strategy and the similarity measure, in Unsupervised Meta-Learning (UML). With the proposed sufficient sampling and a new similarity, we get a strong UML baseline that makes UML practical for few-shot classification. Then we empirically explore other factors influencing UML, which provides insight into designing improved UML methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Simple Modifications towards Effective UML</head><p>We analyze how to sample episodic tasks efficiently for better gradient estimation and how to measure similarity between instances in a (pseudo) task in UML. Sufficient Episodic Sampling (SES). In Alg. 1, Stochastic gradient descent (SGD) is applied to optimize the UML objective in Eq. 1, and there is one single task sampled per episode <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b16">[17]</ref>. In other words, a gradient descent step over the embedding ? is carried out once sampling each couple of N -way support and query sets. In vanilla supervised learning, one gradient step is performed after averaging a mini-batch of losses to produce a more accurate gradient estimation. Inspired by this practical usage of SGD, we may sample multiple tasks and compute gradients over their averaged loss <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b10">[11]</ref>. Sampling more than one task per episode accelerates the convergence of meta-training. However, embeddings of multiple tasks should be extracted accordingly via multiple forward passes, which costs high memory and the number of tasks in one episode is limited. <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b76">[77]</ref> resolve the dilemma by accumulating the gradient and delaying the backward operation after multiple episodes, but cannot significantly increase the convergence speed.</p><p>We propose a more efficient implementation of the metatraining update with almost no additional computational cost. Assume we sample a C-way (K + Q)-shot task S ? Q in an episode where C ? N , then we extract embeddings of all instances with a single forward pass. Rather than computing losses on one single pair of S and Q, we randomly resplit the embeddings into couples of support and query sets. Specifically, N of C classes are sampled, K instances from each class are randomly selected into the support set, and the remaining Q instances in those N classes are used for the query set. By repeating this process multiple times, we implicitly construct lots of pseudo tasks in one single episode, and one gradient descent is executed for averaged "multitask" losses. The main steps of SES are in Alg. 3 lines 5-6 and <ref type="figure" target="#fig_3">Fig. 6</ref> (a). Since only one forward of ? is applied (Alg. 3, line 4), SES has negligible additional computational costs during meta-training. In our implementation, we set C = N , so our baseline has the same mini-batch size as the vanilla method. Experiments show SES improves the efficiency of meta-training, which fully utilizes instances in a mini-batch.</p><p>Semi-Normalized Similarity (SNS). The similarity metric in Eq. 2 plays an essential role, which determines whether two instances are similar in a task. As mentioned in <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b16">[17]</ref> and Section 3, the temperature ? in Sim(?, ?)/? smooths the logit and influences the discriminative ability of the meta-learned embedding. Instead of manually setting ? , we propose to learn the temperature adaptively during the metatraining progress. Moreover, we make the ? instance-specific, denoted as ? x , when measuring the similarity between x and prototypes. We take advantage of the fact that scale of the embedding, i.e., the embedding norm ?(x) , will not influence the relative similarity between instances in Eq. 2, so ? will have a freedom degree on its scale. With the help of the embedding norm, we propose to obtain ? x as a function of ?(x) , which also avoids introducing additional learnable parameters to determine ? x . The model will adapt ?(x) as well as ? x to the right scale and dynamically improve the discriminative ability of the learned embeddings.</p><p>To simplify the form, we implement the temperature as the reciprocal of the embedding norm, i.e., ? x = 1/ ?(x) . <ref type="bibr" target="#b1">2</ref> Thus, together with the cosine similarity, we get our SNS as</p><formula xml:id="formula_5">Sim(?(x j ), p n ) = Sim cos (?(x j ), p n )/? xj = Sim cos (?(x j ), p n ) ? ?(x j ) = ?(x j ) p n p n 2 .<label>(6)</label></formula><p>The name "semi-normalized" comes from the fact that SNS only normalizes support centers in Eq. 6. Recall that the similarity between a query instance x j and multiple support centers {p n } are compared simultaneously with the softmax operator, missing the normalization on ?(x j ) in SNS leads to the same prediction with the cosine similarity in Eq. 4.</p><p>Since the embedding norm of an instance decreases when we use Sim as the cosine similarity during the meta-training progress (as shown in <ref type="figure">Fig. 2</ref>), the instance-specific temperature in SNS becomes larger gradually, which softens the logits in an adaptive manner. In detail, based on the discussions in Section 3, the loss forces to push a query instance far from nearest non-belonging centers at the initial optimization stage (with relative larger ?(x j ) ), which captures the local similarity relationship in a task. When the embedding norm becomes smaller, the temperature helps concentrate the gradient from pushing nearest impostor centers to all non-belonging ones, which makes the optimization focuses on the global property among tasks. Experiments verify that SNS facilitates learning the best temperature for Sim cos and improves UML on various configurations of tasks.</p><p>We summarize our UML baseline with the help of SES and SNS, whose meta-training workflow is listed in Alg. 3 (especially lines 5, 6, and 8). No additional parameters are introduced in our UML baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Empirical Analyses of Key Factors for UML</head><p>Before we move on, we analyze the effectiveness of our UML baseline and explore other key elements in UML's meta-training, which lays the foundations for designing improved UML methods. Following the configuration in <ref type="bibr" target="#b20">[21]</ref>, we implement ? with a four-layer ConvNet and focus on the MiniImageNet <ref type="bibr" target="#b3">[4]</ref> benchmark with the standard split <ref type="bibr" target="#b11">[12]</ref>. <ref type="bibr" target="#b1">2</ref>. We omit the case ?(x) = 0 since ?(x) gets all zero elements with almost no chance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3</head><p>The meta-training flow of our UML Baseline. Require: Unlabeled base class set B 1: for all iteration = 1,... do <ref type="bibr">2:</ref> Sample C instances from B</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>Apply K + Q augmentations for all C instances <ref type="bibr">4:</ref> Get ?(x) for all augmentations <ref type="bibr">5:</ref> for all task_iter = 1,... do <ref type="bibr">6:</ref> Split embeddings to get a task (S, Q) <ref type="bibr">7:</ref> for all (x j , y j ) ? Q do <ref type="bibr">8:</ref> Get f (x j , S) with SNS in Eq. 6 <ref type="bibr" target="#b8">9</ref>:</p><p>Compute (f (x j , S), y j ) 10: end for <ref type="bibr">11:</ref> end for <ref type="bibr">12:</ref> Accumulate loss as Eq. 1 for all tasks <ref type="bibr">13:</ref> Update ? with SGD 14: end for <ref type="bibr">15:</ref> return Embedding ? RIHSRFKV HPEHGGLQJQRUP &amp;RVLQH 6162XUV <ref type="figure">Figure 2</ref>: The change of the embedding norm ?(x) (mean as well as std. over all instances) during the meta-training progress when learning with cosine similarity and SNS on MiniImageNet. We set ? as a four-layer ConvNet. The detailed setup is the same as that described in Section 4.2.</p><p>During meta-training, the initial learning rate is set to 0.002 and is cosine annealed over 100 epochs. C = 64 instances are sampled in each mini-batch as different pseudo-classes, and each instance is augmented into six copies. We set N = 64, K = 1, Q = 5 by default. During meta-test, we evaluate the meta-learned embeddings over 10,000 few-shot tasks (where N = 5 and Q = 15) from novel classes. Note that we only use labels to evaluate statistics such as few-shot classification accuracy, and no base class labels are utilized during meta-training. We observe the same phenomenon on other datasets with deeper backbones. More results and analyses are in Section 7. Other configurations of episodes and their influences on UML are in the supplementary. Does sufficient sampling with SES help UML? We evaluate SES by gradually increasing the number of re-sampled tasks in one episode from 1 (denoted as the "vanilla" case) to 512, and we implement the similarity measure in Eq. 2 with our SNS. The change of meta-training loss and meta-validation 1-shot 5-way accuracy over sampled 10,000 tasks are plotted in <ref type="figure" target="#fig_1">Fig. 3 (upper)</ref>. During the meta-training progress, the loss of UML objective in Eq. 1 decreases consistently, which indicates that constructing pseudo-classes with augmented views makes the meta-learned embedding discriminative. Obviously, the model converges faster and generalizes better by re-sampling more tasks in one episode. There is a huge gap over the meta-training loss/meta-validation accuracy  between the 512-task case and the vanilla one, which verifies the importance of sampling sufficient tasks in meta-training. We find that monotonously increasing the task number has no additional improvements. So in the following experiments, we set the number of tasks in SES to 512. We also compare SES with "Hard Task" sampling <ref type="bibr" target="#b77">[78]</ref>, <ref type="bibr" target="#b78">[79]</ref> (denoted as "HT" for short). HT selects hard classes from various tasks and then organizes them together. We find HT accelerates meta-training at first but slows down later. The reason mainly comes from HT's dependence on semantic information to construct hard tasks, which becomes difficult in UML. SES achieves a faster convergence rate and higher meta-val accuracy than HT once with enough tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RIHSRFKV PHWDWUDLQORVV</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Does the new similarity SNS help UML?</head><p>We compare cosine similarity, (negative) euclidean distance, inner product, and SNS. We meta-train those similarities with SES and evaluate the learned embedding with the corresponding similarity over 5-way {1, 5, 20, 50}-shot novel class tasks. We set the default temperature for cosine as 0.5 and 1 for others. The FSL accuracy on the meta-test set is shown in <ref type="figure" target="#fig_1">Fig. 3</ref> (lower left). Different from supervised meta-training where cosine is the best choice <ref type="bibr" target="#b73">[74]</ref>, in UML, later similarities outperform the former one in more shot scenarios. SNS performs the best when the embedding is meta-trained with one task per episode (results are in the supplementary). When equipped with SES, SNS also shows stable improvements when evaluated with different configurations of tasks.</p><p>Besides the change of embedding norm in <ref type="figure">Fig. 2</ref>, we analyze the norm of the embedding gradient in <ref type="figure" target="#fig_1">Fig. 3</ref> (lower right), i.e., ? ?(x) 2 averaged over all instances in the minibatch, along with the meta-training progress. We observe that cosine has very small embedding norms, so normalizing with which results in large gradient norms. The large gradients could be one reason for its instability in UML, which requires carefully tuned temperatures. Inner product and Euclidean distance without embedding normalization lead to relatively smaller gradient norms. Our SNS, however, has the smallest gradient norm compared with others. We conjecture that ? is updated in diverse ways by using different similarity measures. SNS makes ? approach the stable point directly, while others such as inner product make aggressive updates at first and then gradually adapt the embedding to the target solution in a zigzag way. Based on the meta-test classification performance, SNS converges faster and generalizes better.</p><p>We also manually tune the temperature for cosine over 16 values ? ? [0.005, 1]. We observe that the learned embeddings show diverse performance when trained with various temperatures, and the best ? for different task configurations (e.g., different K) varies. The mean and std. over temperatures in <ref type="figure" target="#fig_4">Fig. 4</ref> indicate large variances, and SNS performs on par with the best-performed cosine similarity in all cases with default ? = 1. Since we cannot determine the best ? for cosine with the final performance in advance, SNS is more practical. MoCo SimCLR CACTUs Ours How to generate pseudo-labels -clustering or augmentations? We investigate the difference between two pseudolabeling strategies. We mainly consider the clustering choice CACTUs in <ref type="bibr" target="#b54">[55]</ref>. We find that the labeling quality of clustering highly depends on the off-the-shelf learned embedding. We try several embedding learning methods (including those in <ref type="bibr" target="#b54">[55]</ref> and self-supervised learning ones) for clustering and show the best-performed CACTUs in <ref type="figure" target="#fig_2">Fig. 5</ref>. We also equip CACTUs with SES for fair comparisons. We find our UML baseline consistently outperforms CACTUs, which indicates data augmentation could be a stable and efficient manner to generate pseudo-labels in UML.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VKRW</head><p>Moderate augmentation leads to better performance. Data augmentation plays an important role in contrastive selfsupervised learning <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b82">[83]</ref>. We investigate how augmentation influences the performance of our UML baseline. We compare augmentations from SimCLR <ref type="bibr" target="#b24">[25]</ref>, AMDIM <ref type="bibr" target="#b79">[80]</ref>, AutoAug <ref type="bibr" target="#b80">[81]</ref> and RandAug <ref type="bibr" target="#b81">[82]</ref>. We also compare an augmentation "Simple" that consists of random resized crop, color distortion, and random horizontal flip. Results show that relatively strong augmentation will benefit our UML baseline. However, too strong augmentation such as RandAug may degrade the performance. These results are in accord with those in self-supervised learning <ref type="bibr" target="#b83">[84]</ref>. In our experiments, AMDIM is the best augmentation. Episodic training works better than contrastive Self-(N , K) Supervised Learning (SSL) baselines. An intuitive question is whether episodic training outperforms the contrastive SSL methods. We compare our UML baseline with two representative SSL methods, i.e., MoCo <ref type="bibr" target="#b23">[24]</ref> and SimCLR <ref type="bibr" target="#b24">[25]</ref>.</p><p>Hyper-parameters are tuned carefully for SSL methods on the meta-validation set, and they require longer epochs to converge (e.g., 800 epochs). <ref type="figure" target="#fig_2">Fig. 5</ref> shows the superiority of our episodic meta-trained UML baseline when compared with the "plain" trained SSL methods. The results indicate episodic training is an essential factor for UML. Summary. Benefiting from the task sampling strategy (i.e., SES) and the in-task similarity measure (i.e., SNS), our UML baseline meta-learns generalizable embeddings without base class labels. The results indicate the specific consideration of task characteristics with episodic training is essential for UML, so we keep SES and SNS as default configurations for UML and propose to design improved UML approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">FURTHER EXPLORING CHARACTERISTICS OF TASKS FOR UML</head><p>Analyses in Section 4 verify the effectiveness of several key factors in UML, including generating pseudo-labels with data augmentations, episodic sampling tasks with SES, and measuring in-task similarities with SNS. We further explore the characteristics of tasks to improve the discriminative and generalization ability of UML. Due to the diversity of sampled tasks in meta-training, we propose either "amplifying" or "resolving" the task level differences, which achieve stronger lower-shot (e.g., 1-shot) and higher-shot (e.g., 20-shot) FSL performance, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Adaptive Difficult Tasks via Hard Mixed Supports</head><p>In our vanilla UML baseline, all (pseudo) tasks during meta-training are sampled uniformly. We try to amplify the characteristics of tasks by learning more confusing tasks, e.g., tasks discerning "hound" and "husky" rather than "dog" and "cat". Those confusing tasks facilitate the embeddingbased classifier to identify key features to differentiate the neighbors and impostors. Then, the embedding could be more discriminative and helps novel class FSL tasks. However, given the unlabeled base class set, we cannot Given a query embedding, we mix it up with the most similar instances (with mixup strength coefficient s). The mixed embeddings are then added as extra supports for this query, which constructs a query-specific difficult task. (c) To relieve the variety of task distributions, we transform task agnostic embeddings to task-specific ones with an auxiliary task-specific projection head (implemented with Transformer <ref type="bibr" target="#b84">[85]</ref>) during meta-training. This component is discarded during meta-test.</p><p>collect semantically related classes in one task directly, so we choose to measure the difficulty of a task via the similarity in the embedding space -between a query instance and the support centers from those nearest non-belonging classes. We propose Hard Mixed Supports (HMS) to meta-learn more discriminative embeddings. HMS dynamically constructs more difficult tasks with support distractors. Given a couple of support and query sets (S, Q), we synthesize hard distractors for each query instance x j ? Q by mixing-up x j with its nearest neighbor x i ? S ? Q coming from different pseudo-classes. Formally, we find K nearest neighbors of x j in the embedding space:</p><formula xml:id="formula_6">S j = argmax K xi?S?Q {Sim (?(x j ), ?(x i )) , y j = y i } . (7)</formula><p>Sim(?, ?) is SNS as Eq. 6. y i and y j are the pseudo-classes of x i and x j , respectively. argmax K selects the top-K instances with the highest similarity <ref type="bibr" target="#b85">[86]</ref>, i.e., the most similar ones. To increase the difficulty, we further mixup ?(x j ) with the embeddings of? j :</p><formula xml:id="formula_7">S j = ??(x j ) + (1 ? ?)?(x) | x ?? j .<label>(8)</label></formula><p>? ? [0, 0.5] is a random value sampled from a uniform distribution. Eq. 8 interpolates distractors between the query instance embedding ?(x j ) with the embedding of its hard mined neighbor ?(x). The strength of the mixup coefficient ? is controlled so that the mixed instances are biased towards the mined neighbor, which guarantees the semantic space is not messed up. But in experiments, we find a larger range of ? (e.g., ? ? [0, 1]) facilitates 1-shot meta-test tasks. Each instance in the mixed support setS j is taken as a new pseudoclass other than those in S. The confusingS j amplifies the difficulty of discriminating the right queries. Finally, we augment the original support set S with the mixed on? S j and obtain a higher-way confusing support set. Denote the specific support embedding set S j = {?(x i ) | x i ? S} ?S j for each query instance x j , we re-compute the loss function in Eq. 1 over S j and optimize the model with backpropagation. HMS is operated over the embeddings, so it incurs a negligible computational burden.</p><p>In summary, we construct a query-specific hard support set by augmenting the support set with distractors for each query instance. The more confusing support set amplifies the characteristic of tasks, which leads to more discriminative embeddings. The main flow of HMS is listed in Alg. 4 (the changes w.r.t. our baseline are in lines 8-13).</p><p>Discussions. Selecting Hard Tasks (HT) has been verified to be effective in supervised meta-learning <ref type="bibr" target="#b77">[78]</ref>, <ref type="bibr" target="#b78">[79]</ref> and makes the meta-model robust. The hard classes selected from various tasks in HT may not increase the discerning difficulty of their combinations. HMS directly synthesizes confusing embeddings towards query-specific difficult tasks without multiple forward passes as in <ref type="bibr" target="#b77">[78]</ref>, <ref type="bibr" target="#b78">[79]</ref>, which is efficient and effective for UML. To demonstrate the benefit of HMS, we compare HMS with HT and various meta-learning mixup variants <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b86">[87]</ref> in Section 7.</p><p>Similar ideas constructing hard negatives have also been explored in self-supervised learning (SSL) <ref type="bibr" target="#b87">[88]</ref>, <ref type="bibr" target="#b88">[89]</ref>, <ref type="bibr" target="#b89">[90]</ref>, <ref type="bibr" target="#b90">[91]</ref>, where the main obstacle is to ensure the synthesized negatives are confusing. For example, MoCHi <ref type="bibr" target="#b87">[88]</ref> uses a large memory bank to guarantee diverse negative candidates could be searched. Different from adding negative examples in the contrastive loss, HMS augments the support set with confusing embeddings labeled as new pseudo-classes. Besides, HMS utilizes SES and searches for distractors in a minibatch efficiently without losing the diversity of candidates. Experiments show HMS outperforms SSL methods such as MoCHi when evaluated on 1-shot tasks. We also investigate the influence of SES on HMS in the supplementary. Sample C instances from B</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>Apply K + Q augmentations for all C instances <ref type="bibr">4:</ref> Get ?(x) for all augmentations <ref type="bibr">5:</ref> for all task_iter = 1,... do <ref type="bibr">6:</ref> Split instances to get an N -way K-shot task (S, Q) <ref type="bibr">7:</ref> for all (x j , y j ) ? Q do <ref type="bibr" target="#b7">8</ref>:</p><formula xml:id="formula_8">Get? j = argmax K xi?S?Q {Sim (?(x j ), ?(x i )) , y j = y i } 9: Sample ? ? U (0, 0.5) 10:S j = ??(x j ) + (1 ? ?)?(x) | x ?? j 11: Get S j = {?(x i ) | x i ? S} ?S j 12:</formula><p>Get f (x j , S j ) with SNS in Eq. 6 <ref type="bibr" target="#b12">13</ref>:</p><formula xml:id="formula_9">Compute (f (x j , S j ), y j ) 14:</formula><p>end for <ref type="bibr">15:</ref> end for <ref type="bibr">16:</ref> Accumulate loss as Eq. 1 for all tasks <ref type="bibr">17:</ref> Update ? with SGD 18: end for <ref type="bibr">19:</ref> return Embedding ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Task-specific Projection Head</head><p>The embedding ? could have diverse (or even contradictory) update directions during meta-training since the optimal embedding-based classifiers for sampled tasks are different. Moreover, the tasks during meta-training and meta-test of UML are composed of pseudo-classes and real semantic classes, respectively. So the distribution gap makes the embedding learned on the unlabeled base classes hard to fit the tasks from novel classes.</p><p>Unlike HMS, we turn to resolve the negative effect owing to the characteristics of pseudo UML tasks. We propose to adapt embeddings in a task with an auxiliary Task-Specific Projection Head (TSP-Head) <ref type="bibr" target="#b16">[17]</ref>, which decouples the specific and generalizable components -the specific properties in a (pseudo) task will be captured by the toplayer transformation, while the pre-adapted embedding ? could be more generalizable and facilitates novel class fewshot tasks during meta-test.</p><p>In meta-training, support and query embeddings in a task are transformed with an auxiliary set-to-set function T:</p><formula xml:id="formula_10">?(x) = T(?(x) | x ? S ? Q) .<label>(9)</label></formula><p>T(?) contextualizes the union of support and query sets. We measure the similarity between query and support in Eq. 6 with the transformed task-specific embedding ?(x) in meta-training, while during meta-test only ?(x) is used.</p><p>Following <ref type="bibr" target="#b16">[17]</ref>, we implement T(?) with Transformer <ref type="bibr" target="#b84">[85]</ref>, and ?(x) is adapted based on a "key-value" dictionary module. In particular, denote W Q , W K , and W V as three d ? d projections, and the affinity ? i between one instance x and another instance x i in a sampled task is measured by their projected inner product</p><formula xml:id="formula_11">? i = Softmax i ? ? ? W Q ?(x) W K ?(x i ) ? d ? ? ? .<label>(10)</label></formula><p>The transformed embedding ?(x) is a weighted sum over another transformed set of embeddings {?(x)} x?S?Q in the union of support and query sets</p><formula xml:id="formula_12">?(x) = ?(x) + L x?S?Q ? i W Q ?(x) .<label>(11)</label></formula><p>L(?) is a sequential operation of layer normalization <ref type="bibr" target="#b91">[92]</ref>, dropout <ref type="bibr" target="#b92">[93]</ref>, and linear projection. There are two extension configurations for Transformer. First, T could be processed multiple times (a.k.a. multi-layer). Second, if more than one set of projection matrices are allocated, multiple adapted embeddings could be concatenated followed by a linear projection to dimensionality d (a.k.a. multi-head). In our empirical study, we find the multi-head version of Transformer works better, but using more layers will not help. Detailed results are in the supplementary. Alg. 5 shows the main flow of TSP-Head (the changes w.r.t. our UML baseline model are in lines <ref type="bibr">7, 9, and 14)</ref>. Based on Eq. 9, the adapted embedding ? takes a holistic consideration of other embeddings in the task, which frees the vanilla embedding ? from encoding the specific properties of different tasks. In other words, with the help of ? dealing with characteristics of tasks, ? becomes more generalizable, so we apply ? to measure the similarity in evaluation.</p><p>TSP-Head has another two benefits. It is inevitable that we assign semantically similar instances into different pseudoclasses in UML tasks, and requiring the embedding to distinguish between them will mislead models to push instances from the same semantic category away. TSP-Head accounts for possible semantic contradiction with the adapted embeddings and counters the negative influence of the semantically similar instances from different pseudoclasses. Furthermore, UML suffers from the shift of task distribution between base and novel classes. The tasks in meta-training are sampled from an unlabeled base class set with augmentations, while a novel few-shot support set during meta-test is composed according to supervised semantic labels. This difference indicates that we could not directly adapt task-specific embedding as in the supervised FSL, and a more generalizable ? with the auxiliary T helps. Discussions. Transformer is used as an adaptation component in the meta-model to obtain task-specific embeddings in FEAT <ref type="bibr" target="#b16">[17]</ref>, where the adapted embeddings are applied for both base and novel tasks. However, in TSP-Head we use Transformer as an auxiliary component to take account of characteristics of different (pseudo) tasks, i.e., we compute loss with adapted embedding during meta-training and only the vanilla embedding ? is used during meta-test. Experiments show that using the adapted embedding ? during meta-test suffers from the distribution gap since those tasks are not generated based on data augmentations. We also find that Transformer performs differently in supervised and unsupervised cases. For example, a multi-head version of T cannot help FEAT but is useful in our TSP-Head.</p><p>The projection head is a commonly used trick in selfsupervised learning <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b74">[75]</ref> to improve the quality of the representation. In detail, another linear layer is jointly learned in training and is discarded during evaluation. Different from the vanilla supervised training where all instances are i.i.d. sampled, in UML, instances in a task are related. Thus the set- Sample C instances from B</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>Apply K + Q augmentations for all C instances <ref type="bibr">4:</ref> Get ?(x) for all augmentations <ref type="bibr">5:</ref> for all task_iter = 1,... do <ref type="bibr">6:</ref> Split instances to get an N -way K-shot task (S, Q)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>Transform embedding in the task</p><formula xml:id="formula_13">?(x) = T(?(x) | x ? S ? Q) 8:</formula><p>for all (x j , y j ) ? Q do <ref type="bibr">9:</ref> Get f (x j , S) with SNS and ?(x) in Eq. 6 <ref type="bibr" target="#b9">10</ref>:</p><p>Compute (f (x j , S), y j ) <ref type="bibr">11:</ref> end for <ref type="bibr">12:</ref> end for <ref type="bibr">13:</ref> Accumulate loss as Eq. 1 for all tasks <ref type="bibr">14:</ref> Update ? and T with SGD 15: end for <ref type="bibr">16:</ref> return Embedding ? wise diversity in UML is difficult to be captured by a linear layer. We use set-to-set transformation as a more competitive module. We show that Transformer is a good choice than other implementations such as FILM <ref type="bibr" target="#b93">[94]</ref>, <ref type="bibr" target="#b31">[32]</ref> in Section 7 and the supplementary.</p><p>HMS and TSP-Head change the meta-training flow, and the meta-learned embedding ? is used during meta-test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTAL SETUPS</head><p>We describe the concrete setups for experiments, including datasets, evaluations, and implementation details. Code is available at https://github.com/hanlu-nju/revisiting-UML.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>MiniImageNet <ref type="bibr" target="#b3">[4]</ref> contains 100 classes and 600 images per class. Three non-overlapping splits with class number 64/16/20 are used as meta-training/validation/test <ref type="bibr" target="#b11">[12]</ref>, respectively. TieredImageNet <ref type="bibr" target="#b46">[47]</ref> splits its 608 classes into 351/97/160, and there are 779,165 images in total. For MiniImageNet and TieredImageNet, all images are cropped to 84 ? 84. Two splits of CIFAR-100 <ref type="bibr" target="#b10">[11]</ref> are investigated with 32 by 32 small images. In CIFAR-FS, 64/16/20 classes are selected from the 100 classes for meta-training/validation/test. While for FC-100, 60, 20, and 20 classes are selected in a special manner to enlarge the discrepancy among the three sets. Each class contains 600 images. No meta-training/validation labels are used by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation protocols</head><p>Since there are no labels in the meta-validation set, we evaluate UML based on the performance of the last epoch's model. We follow the classical protocol to evaluate the meta-learned model on few-shot classification tasks <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b73">[74]</ref>. 10,000 tasks with N -way K-shot support set are sampled from the meta-test set during the model evaluation, and there are 15 instances per N classes in the corresponding query set. We set N = 5 and K = {1, 5, 20, 50}. We compute mean accuracy and the 95% confidence interval. Since the confidence intervals over 10,000 trials vary around 0.15-0.20 in all settings, we omit them for clarity. Detailed results with confidence intervals are in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Implementation details</head><p>Network architectures. We implement ? with two representative backbones. ConvNet <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b8">[9]</ref> has four sequential blocks with convolution, batch normalization <ref type="bibr" target="#b94">[95]</ref>, ReLU, and Max Pooling. Each of the blocks outputs 64-dimensional latent embeddings, and we append a global average pooling at last. We also consider a 12-layer residual network <ref type="bibr" target="#b95">[96]</ref>, <ref type="bibr" target="#b10">[11]</ref>, which is denoted as ResNet. Optimization. We apply Adam <ref type="bibr" target="#b96">[97]</ref> on ConvNet with an initial learning rate 0.002 over 100 epochs. For ResNet, we follow <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b16">[17]</ref> and use SGD w/ momentum 0.9 over 200 epochs, whose initial learning rate is 0.03. Cosine annealing is utilized to tune the learning rate for both architectures. Augmentations. We use data augmentation from AMDIM <ref type="bibr" target="#b79">[80]</ref> by default, taking advantage of a composition of the random resized crop, random translation, color distortions, and random grayscale to construct the pseudo-labels for unsupervised meta-training.</p><p>? Random resized crop makes a crop of random size (uniform from 0.08 to 1.0 in the area) of the original size and a random aspect ratio (default: of 3/4 to 4/3) of the original aspect ratio. Then the uncovered blank area is filled with reflect padding. ? Random translation translates vertically and horizontally by n pixels where n is an integer drawn uniformly and independently for each axis from <ref type="bibr">[?4, 4]</ref>. Then the uncovered blank area is filled with reflect padding. ? Color distortions randomly change the brightness, contrast, and saturation of an image. ? Random grayscale randomly converts the image to grayscale with a probability of 0.25. Similarity metrics. There are four different kinds of similarity metrics, namely cosine, inner product, (negative) Euclidean distance, and our proposed SNS. Due to the ReLU layer at the end of the backbone, the embeddings have non-negative values. Inner product and SNS have range (0, +?). Euclidean ranges in (??, 0]. But the range of cosine is [0, 1], whose values influences the compactness of the final embeddings <ref type="bibr" target="#b97">[98]</ref>. Since the best temperature varies for different configurations of tasks, we set ? = 0.5 to scale the logit <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b23">[24]</ref> for cosine similarity, and ? = 1 for others. Hard Mixed Supports (HMS). If not specified, HMS selects 10 nearest neighbors for each query. The embedding mixup coefficient is drawn from a uniform distribution, i.e., ? ? U (0, s). s is 0.5 by default. We investigate the influence of the mixup strength s in Section 7. <ref type="bibr" target="#b84">[85]</ref>. The dimensionality of key, query, and value vectors is the same as the input, i.e., 64 for ConvNet and 640 for ResNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task-Specific Projection Head (TSP-Head). TSP-Head uses a 1-layer and 8-head Transformer by default</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EXPERIMENTAL RESULTS</head><p>We evaluate our UML baseline, HMS, and TSP-Head on FSL benchmarks. The generalization ability on novel domains and the performance change given limited base class labels (N , K)   <ref type="bibr" target="#b98">[99]</ref> and more ablation studies are in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Comparisons on Benchmarks</head><p>The average 5-way {1,5,20,50}-shot classification accuracy over 10,000 trials on MiniImageNet, TieredImageNet, CIFAR-FS, and FC-100 with ConvNet and ResNet backbones are listed in <ref type="table" target="#tab_5">Table 2</ref>, <ref type="table" target="#tab_8">Table 3, and Table 4</ref>. We mark the best results in bold. Our UML baseline generates pseudo-labels through data augmentation and utilizes sufficient episodic sampling (SES) as well as semi-normalized similarity (SNS). Based on this baseline, we apply our hard mixed supports (HMS) and task-specific projection head (TSP-Head). <ref type="table" target="#tab_5">Table 2</ref> has three blocks, including UML methods, Self-Supervised Learning (SSL) methods, and our approaches. "Vanilla" denotes the traditional UML baseline using Euclidean distance and vanilla episodic sampling method. Some recent UML methods like UMTRA <ref type="bibr" target="#b20">[21]</ref> using episodic training could not perform as well as the ones based on SSL methods. Our baseline with SNS and SES already outperforms some previous UML and SSL methods with a large margin -for example, an 8%-9% accuracy superiority when compared with UMTRA <ref type="bibr" target="#b20">[21]</ref>, and an 5%-10% accuracy superiority when compared with SimCLR <ref type="bibr" target="#b24">[25]</ref>. ProtoCLR works similarly with ours, which learns representations in a contrastive manner over the prototypes. For fair comparisons, we cite the values of ProtoCLR <ref type="bibr" target="#b58">[59]</ref> without an additional step of fine-tuning on the meta-test support set. Our superiority verifies that the strategy to sample pseudo tasks and the way to measure similarities are important for meta-training. We also apply our SES and SNS together with existing UML methods (denoted as "w/ SES+SNS" in tables). We find SES and SNS consistently improve the vanilla baseline, as well as CACTUs <ref type="bibr" target="#b54">[55]</ref> and CUMCA <ref type="bibr" target="#b56">[57]</ref>, which demonstrate the generality of our proposed key factors in UML.</p><p>CACTUs <ref type="bibr" target="#b54">[55]</ref> is a representative clustering-based method in UML. Once trained with our SES and SNS, CACTUs gets improved results than the reported ones in <ref type="bibr" target="#b54">[55]</ref>. CACTUs generates UML tasks based on the clustering results over the off-the-shelf learned embeddings. We try various ways to learn the embedding including those in <ref type="bibr" target="#b54">[55]</ref> and SSL methods listed in the table, then we report the best performed results. Although clustering may mitigate the false negative pseudolabels in UML to some extent, we find CACTUs highly depends on the quality of the pre-learned embeddings. If pre-learned embeddings cannot differentiate instances from semantically similar classes, annotating them with different pseudo-labels during the clustering stage is hard. Another drawback of the clustering-based approaches could be the two-stage training, where the inconsistent learning objectives in the two stages degrades the performance. We find our baseline obtains stably better results than the improved CACTUs, and the results validate that data augmentation is an effective way to generate pseudo-labels in UML.</p><p>HMS and TSP-Head achieve further improvements. In detail, HMS works well with lower shots (especially 1-shot) while TSP-Head performs better when evaluated with higher shots. <ref type="bibr" target="#b2">3</ref> As reported by <ref type="bibr" target="#b59">[60]</ref>, MoCo achieves 56.2% and 75.4% classification accuracy on 1-shot and 5-shot MiniImageNet tasks upon the ResNet-50 backbone, respectively. Compared with our results in <ref type="table">Table 3</ref>, our proposed UML methods get better performance with the shallow ResNet-12 backbone.</p><p>We make detailed comparisons between HMS and MoCHi <ref type="bibr" target="#b87">[88]</ref>, where MoCHi uses synthesized hard negatives in contrastive SSL. We find HMS performs better in most cases without using a memory bank. The success of HMS may come from the special configuration of episodic tasks during meta-training. We provide the detailed influence of SES on HMS in the supplementary. Limited base class labels lead to a strong FSL model. We investigate how the embedding learned with UML facilitates supervised meta-learning given limited base class labels. Given the initialized embedding ?, we fine-tune the same objective in Eq. 1, but the episodes of tasks are constructed based on the ground-truth labels of base class examples. Our proposed SES and SNS are applied to make the two-stage embedding updates consistent.</p><p>We fine-tune the embedding for 50 and 100 epochs when the labeling ratio is below and above 10%, respectively. There are ten episodes per epoch. In each episode, we sample a mini-batch consisting of 256 images from 64 base classes with four images in each class. Based on the sampled batch, 512 tasks are further re-sampled via SES. The learning rate is 0.0001, and the optimizer is SGD w/ momentum.</p><p>Results based on ResNet are shown in <ref type="figure" target="#fig_6">Fig 7.</ref> We control the fraction of labeled instances in each base class. The zero label ratio corresponds to the fully unsupervised case (the same as UML), which is then utilized as the initial weights for <ref type="bibr" target="#b2">3</ref>. The advantages of HMS and TSP-Head show different phenomena on CIFAR variants, e.g., HMS always performs better than TSP-Head on FC-100. One possible reason is that HMS highlights the difference among smaller images via synthesized hard supports, and discriminative ability of the meta-learned embeddings helps more in this case.  <ref type="table">Table 3</ref>: UML comparisons on MiniImageNet, CIFAR-FS, and FC-100 with ResNet. Methods are evaluated over different N -way K-shot tasks, and we report the mean classification accuracy over 10,000 trials. * MoCo-v2 is also the method used in <ref type="bibr" target="#b59">[60]</ref>, but we got better results with the same backbone architecture.  MoCo-V2 SimCLR baseline HMS TSP-Head other analyses. By fine-tuning ? with more labeled base class instances, FSL accuracy on the meta-test set increases due to richer supervisions and even exceeds the fully supervised  <ref type="table">Table 5</ref>: Mean classification accuracy of methods learned from the base class set of MiniImageNet and evaluated on N -way K-shot novel class tasks of CUB.</p><p>ProtoNet meta-trained on a labeled base class set from scratch <ref type="bibr" target="#b9">[10]</ref> (the dotted line in the <ref type="figure">figure)</ref>. The phenomenon indicates that the UML pre-trained weights are tremendously label-efficient -we get a strong FSL model given a large unlabeled base class set and a small number of labels.</p><p>Some semi-supervised meta-learning methods utilize the unlabeled data in meta-training set <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>, but could not perform as well as the fully supervised upper bound. Surprisingly, we find that based on the UML pre-trained weights and with only 1% labels, fine-tuning via classical meta-learning method can achieve performance comparable to a fully supervised model. When pre-trained with HMS, the fine-tuned model with 10% labels can even be competitive to a number of state-of-the-art supervised FSL methods using supervised pre-trained weights with full labels.</p><p>Similar observations are also verified in <ref type="bibr" target="#b74">[75]</ref> that semisupervised classification improves a lot with self-supervised learned weights. We verify the importance of the unsupervised learned weights to supervised meta-learning. We also initialize the embedding with weights learned by SSL methods in the same FSL configuration. We find results based on MoCo and SimCLR improve with more labels but are far away from those based on UML-learned embeddings given more labels. One possible reason is the inconsistency between the pre-training and fine-tuning objectives.   <ref type="table">Table 7</ref>: Comparison between HMS and other mixup-based methods. We record the N -way K-shot classification accuracy on the meta-test set of MiniImageNet with ResNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Cross-Domain Comparisons</head><p>Since the embeddings are learned in an unsupervised manner, it could be memoryless of the base-class information and become more generalizable on novel domains. With the embedding meta-learned on the base class set of MiniImageNet, we evaluate (meta-test) it on CUB <ref type="bibr" target="#b99">[100]</ref>. CUB is a fine-grained dataset on different species of birds. Following the splits of <ref type="bibr" target="#b16">[17]</ref>, 50 classes are randomly selected from CUB as the meta-test set, where 5-way {1,5,20}-shot tasks are sampled for embedding evaluation in <ref type="table">Table 5</ref>.</p><p>Results verify that improvements on the in-domain evaluations also generalize to novel domains. We find TSP-Head gets the best results in all cases, which is consistent with its motivation -an auxiliary task-specific projection head makes the pre-adapted embedding becomes more generalizable even to other domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Ablation Studies</head><p>We further investigate the properties of the UML learned embedding on MiniImageNet with ResNet backbone. Comparison with the supervised upper-bound. The embedding learned without base class labels show strong discriminative ability on benchmarks. We compare UML embedding with its supervised upper bound (ProtoNet <ref type="bibr" target="#b9">[10]</ref>) in <ref type="table" target="#tab_11">Table 6</ref>. There are two versions of supervised upperbound. One optimizes the meta-learning objective in Eq. 1 from scratch directly, and another one fine-tunes the metalearning objective with supervised pre-trained weights. We denote the latter one with ? in the table. Since the supervised pre-training optimizes a classifier over all base classes, it improves the meta-learned embeddings a lot <ref type="bibr" target="#b16">[17]</ref>. We find our UML variants outperform the vanilla ProtoNet in all cases. The TSP-Head even gets better classification accuracy than (N , K)  <ref type="table">Table 8</ref>: The influence of mixup strength in HMS. All experiments select 10 nearest neighbors for each query instance but mixed up with coefficients sampled from different uniform distributions. We record the N -way K-shot classification accuracy on the meta-test set of MiniImageNet with ResNet backbone. When ? = 0, HMS only augments the support set with the nearest neighbors with different pseudo-classes without performing mixup.</p><p>the supervised pre-trained ProtoNet when meta-tested with higher-shots. The results indicate the strong discriminative and generalization ability of the UML embedding. Comparison with other mixup strategies. HMS creates query-specific hard tasks by mixing up the mined confusing instances with a query instance. The same notion is also applied in various supervised meta-learning methods. For example, HT <ref type="bibr" target="#b77">[78]</ref>, <ref type="bibr" target="#b78">[79]</ref> synthesizes hard tasks with selected confusing classes in advance. MetaMix <ref type="bibr" target="#b86">[87]</ref> mixups embeddings between support and query sets. CUMCA <ref type="bibr" target="#b56">[57]</ref> proposes Prior-Mixup as a kind of data augmentation for UML. We compare HMS with these methods in <ref type="table">Table 7</ref>. The results indicate that HMS constructs confusing tasks in a more effective manner. The strength to mixup embeddings in HMS. By default, the mixup coefficient is sampled from a uniform distribution ranging from 0 to 0.5, i.e., ? ? U (0, 0.5). We set the upper bound as 0.5 to ensure the mixed embedding is biased towards the mined instance and semantically different from the query <ref type="bibr" target="#b87">[88]</ref>. Although HMS with the default range show promising results, we investigate the influence of mixup coefficient strength, i.e., sampling ? ? U (0, s) with different s, e.g., s = 0.05 or even s = 1.0. <ref type="table">Table 8</ref> shows that when the mixup strength s becomes larger, HMS gets better few-shot classification accuracy, especially 1-shot and 5-shot. Different from <ref type="bibr" target="#b87">[88]</ref>, our HMS achieves the best 1-shot classification performance with s = 1.0, which we could not preserve the semantic meaning of the synthesized hard support instance. One possible reason is that in UML we do not have a strict requirement on the negative candidates in a pseudo task. Therefore, larger mixup strength helps HMS with lower shots and smaller strength facilitates higher shots. We keep s = 0.5 in all our experiments, but with carefully selected s, HMS is able to get better results especially in 1-shot, 20-shot, and 50-shot tasks as <ref type="table">Table 8</ref>. Does TSP-Head bridge the task distribution gap? As mentioned in Section 5.2, one main motivation of TSP-Head is to mitigate the negative effects of the task distribution gap between the pseudo-labeled tasks in meta-training and the real-labeled tasks in meta-test. We evaluate the learned TSP-Head on two types of tasks on the meta-test set -"pseudo (N , K)  <ref type="table">Table 9</ref>: We evaluate the pre-adapted (w/o head) and postadapted (w/ head) embeddings on two kinds of tasks based on the learned TSP-Head. The "pseudo tasks" are generated based on pseudo-classes determined by data augmentations as in meta-training, while the "real tasks" are sample based on real semantic classes. Methods are evaluated over N -way K-shot tasks on MiniImageNet with ResNet.   <ref type="table" target="#tab_3">Table 10</ref>: Mean classification accuracy between task-agnostic projection head / task-specific projection head on different N -way K-shot tasks on MiniImageNet. In addition to Transformer, we also investigate another implementation of the TSP-Head based on DeepSets and FiLM.</p><p>tasks" sampled based on pseudo-classes (determined by data augmentations as in meta-training), and "real tasks" that are sampled based on real semantic classes. Given a learned TSP-Head model, we report the accuracy w/ and w/o the Transformer head, i.e., using the post-adapted ?(x) and pre-adapted ?(x) in Eq. 11, respectively. Since TSP-Head is applied over both support and query sets during meta-training, we keep the same in meta-test when using the Transformer head. In other words, "w/ head" adapts instances in a transductive way. More discussions are in the supplementary. From <ref type="table">Table 9</ref>, we find when evaluating on pseudo tasks, the same task distribution as meta-training, maintaining the projection head and using the post-adapted embedding perform better. In contrast, using the pre-adapted embedding without the projection head generalizes better on real tasks (the same as our UML evaluations), which verifies that TSP-Head eases the problem of overfitting pseudo tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Is task-specific projection head necessary?</head><p>The projection head is a useful component in SSL, e.g., SimCLR <ref type="bibr" target="#b24">[25]</ref>, where a nonlinear projection layer is appended over the top-layer embedding. We also implement the projection head as a taskagnostic one, and the results are in <ref type="table" target="#tab_3">Table 10</ref>. The advantage of the TSP-Head indicates that the explicit consideration of the specific properties of sampled tasks during metatraining is necessary. We also compare our Transformer-based task-specific projection head with another implementation -DeepSets [101] + FiLM <ref type="bibr" target="#b93">[94]</ref>. In this method, we use DeepSets to generate task-specific linear transformation parameters   for the FiLM layer. Detailed configurations are in the supplementary. <ref type="table" target="#tab_3">Table 10</ref> shows that when compared with the task-agnostic one, TSP-Head generally improves UML when evaluated on higher shot tasks. Among the implementations, our Transformer-based TSP-Head is the best choice. Combine two techniques together? We propose two methods to take the characteristics of tasks into account. An intuitive question is whether the two methods could be fused to get further improvements. As shown in <ref type="table" target="#tab_3">Table 11</ref>, we find HMS and TSP-Head are not compatible, and directly combining them cannot get better results. One main reason could be that HMS and TSP-Head improve the embeddings from two different perspectives, so we need some special strategies to combine their advantages together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Linear Evaluation</head><p>We also evaluate our UML methods following the SSL protocol. In detail, we freeze the feature extractor (i.e., the embedding) and train a linear classifier on top of it. After extracting the features of all instances in the meta-test set, we randomly split the meta-test set into 10 folds. Each fold has the same number of samples from each class. 9 of the 10 folds are used to train a linear logistic regression, and we test the learned linear classifier on the remaining one fold. The logistic regression is trained with 2 regularization, whose weight is searched in a logarithmic scale between 10 ?4 and 10 4 with 5-fold cross-validation. We report test accuracy in <ref type="figure" target="#fig_8">Fig. 8</ref>. Two representative SSL methods, MoCo-v2 <ref type="bibr" target="#b75">[76]</ref> and SimCLR <ref type="bibr" target="#b24">[25]</ref>, are compared, whose hyper-parameters are consistent with those in their published papers. We use circle and cross to represent "base" and "novel" classes, respectively. ProtoNet is trained in a supervised manner, and the other three are trained without using any base class labels.</p><p>With this special evaluation protocol, we find although our UML baseline outperforms SSL methods on few-shot learning tasks, it does not necessarily have an advantage on other downstream tasks like linear classification. By equipping the baseline with HMS or TSP-head, it achieves better results as shown in <ref type="figure" target="#fig_8">Fig. 8</ref>, which indicates that through incorporating characteristics of tasks, the learned embeddings can be more generalizable to handle such a heterogeneous linear evaluation task. The TSP-Head achieves the best result, which is consistent with our observation that TSP-Head facilitates more shot tasks. We hope the evaluations with few-shot tasks and with linear models will draw more insights on both the UML and the SSL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Visualize learned embeddings</head><p>In <ref type="figure" target="#fig_9">Fig. 9</ref>, we visualize the learned embedding with t-SNE and show the difference when the embedding is applied over meta-training (denoted as "base") and meta-test (denoted as "novel") sets of MiniImageNet. In detail, we randomly select 5 classes with 40 instances per class from both splits. Different colors represent different classes. " " marks the center of the corresponding class.</p><p>As shown in 9(a), the embeddings learned in a supervised manner present a good clustering effect on base classes, but the embeddings of novel classes are close to each other and can not be easily separated. On the contrary, our UML methods show similar properties on both base and novel classes, in either 9(b) or 9(c). They form kinds of clusters but do not overfit on base class data, which indicates that the embeddings learned with UML may have more generalization potential. <ref type="figure" target="#fig_9">Fig. 9(d)</ref> shows obviously different embeddings learned by TSP-Head. Samples are scattered among the space, keeping a certain distance from each other. This kind of uniformity may explain why TSP-Head is good at 20-shot and 50-shot tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>Instead of learning to learn embeddings for few-shot classification through a labeled base class set, we propose to transform the meta-learning methods to a fully unsupervised manner from both sampling and modeling aspects without noticeable performance degrades. Simple modifications like Sufficient Episodic Sampling (SES) and Semi-Normalized Similarity (SNS) lead to strong Unsupervised Meta-Learning (UML) baselines. We further take full advantage of the characteristic of tasks from two directions. We consider Hard Mixed Supports (HMS) constructing difficult meta-training tasks dynamically. Moreover, another strategy utilizing Task-Specific Projection Head (TSP-Head) takes the divergence across tasks into account. Both approaches make the meta-learned embeddings more discriminative and generalizable. Our proposed UML methods outperform other UML models on few-shot classification benchmarks. They also achieve similar state-of-the-art performance with its supervised variants given only 10% of base class labels. Please see the texts for more details. We observe by increasing the number of ways we can get more discriminative embeddings on more shot evaluations, and further increase of the way value N does not show apparent contribution when N exceeds some threshold. 1 shot 5 shot 10 shot <ref type="figure" target="#fig_0">Figure 11</ref>: Investigation on the influence of the support set shot number K ? {1, 5, 10} in a task. All meta-learned embeddings are evaluated on 5-way {1, 5, 20, 50}-shot classification tasks over 10,000 trials on MiniImageNet. Please see the texts for more details. We find using smaller shot numbers in a task generalizes better, especially in the 1-shot meta-test case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A TASKS CONFIGURATIONS FOR UML</head><p>As mentioned in Section 4 in the main paper, there are various key factors for (pseudo) task configurations during metatraining. We empirically explore how they influence the Unsupervised Meta-Learning (UML) with our UML baseline and find the best configuration of tasks. Following the same setting in Section 4, we implement the feature extractor ? with a four-layer ConvNet and focus on the MiniImageNet <ref type="bibr" target="#b3">[4]</ref> benchmark with the standard splits. During meta-training, we optimize over episodes of (pseudo) tasks over 100 epochs. In each episode, we sample C instances and make K + Q random augmentations for    each of them. So the batch-size is C ? (K + Q) with C different pseudo-classes. <ref type="bibr" target="#b3">4</ref> We sample 512 N -way K-shot support sets corresponding with N -way Q-shot query sets from the mini-batch with Sufficient Episodic Sampling (SES). Semi-Normalized Similarity is applied in the embeddingbased classifier in a (pseudo) task by default, which measures whether two instances are similar or not. The initial learning rate is set to 0.002 and is cosine annealed. The default values of the factors N , K, Q, and C are 5, 1, 5, 64, respectively. We investigate the influence of N , K, Q, and C in meta-training <ref type="bibr" target="#b3">4</ref>. We enumerate all base class instances per epoch with multiple episodes, and a larger C decreases the number of episodes per epoch.  Cosine Inner Product Euclidean SNS (ours) <ref type="figure" target="#fig_0">Figure 14</ref>: Comparison of different similarities for UML. We sample one task per episode (the task number is set to one in SES) during meta-training. All meta-learned embeddings are evaluated on 5-way {1, 5, 20, 50}-shot classification tasks over 10,000 trials on MiniImageNet with ConvNet backbone. Please see the texts for more details. The figure illustrates our SNS is superior to other existing similarities.</p><p>by varying a particular factor and keeping others as those default values. During meta-test, we evaluate the learned embedding ? over 10,000 5-way K = {1, 5, 20, 50}-shot tasks, which means we change the shot number in the support set, and we keep Q = 15 for all query sets. We only use labels to evaluate some statistics such as few-shot classification accuracy, and no base class labels are utilized during meta-training. The influence of the "way" number N . In <ref type="figure" target="#fig_0">Fig. 10</ref>, we fix K = 1, Q = 5 and vary N ? {5, 32, 64}. We observe by increasing the number of ways N , we can get more discriminative embeddings on more shot evaluations, and further increase of N does not show apparent contribution when N exceeds some threshold. One explanation for this phenomenon is that, similar to the supervised scenario <ref type="bibr" target="#b9">[10]</ref>, the number of ways is related to the difficulty of the sampled (pseudo) tasks during meta-training. The more difficult the meta-training process is, the better model we have. In other words, we sample N -way K-shot tasks from the mini-batch by increasing N as large as C. Although larger N (as well as larger C since C = N ) decreases the number of shots and query instances in a task when we fix the size of mini-batch, the larger-way tasks promote the diversity of instances and facilitate UML. The influence of the "shot" number K. Since we observe sampling larger-way tasks always achieves better results, so we fix N = C = 64 in <ref type="figure" target="#fig_0">Fig. 11</ref>. By fixing Q = 5 during metatraining, we change the number of shots K = {1, 5, 10}. It is notable that by increasing K those tasks have different mini-batch sizes. We find using smaller shot numbers in a task generalizes better especially in the 1-shot meta-test case. It is also consistent with the notion that difficult (pseudo) tasks (with a smaller support set) facilitate meta-training. The influence of the "query" number Q. We also investigate the size of the query set in meta-training. In detail, we fix K = 1, C = N = 64 and vary Q ? {1, 5, 10}. <ref type="figure" target="#fig_0">Fig. 12</ref> illustrates that the number of query instances needs to reach a certain value to make accurate enough evaluations for few-shot classification in meta-test. But too many query instances will not get further improvements. The influence of the instance number C. We demonstrate the influence of the value C in <ref type="figure" target="#fig_0">Fig. 13</ref>. We fix K = 1, Q = 5 and vary C ? {5, 8, 16, 32, 64}. A larger C indicates more diverse pseudo-classes per episode, and based on our previous discussions, we set N = C when sampling tasks with SES. Benefited from the proposed SES and SNS, <ref type="figure" target="#fig_0">Fig. 13</ref> reveals that our UML baseline method is not sensitive to size of batches, which differs from usual SSL methods <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b75">[76]</ref>. The influence of different kinds of similarities. We compare various similarities used in the embedding-based classifier in each task, namely, cosine similarity, inner product, (negative) Euclidean distance, and our Semi-Normalized Similarity (SNS). We keep the same similarity during metatraining and meta-test while using the default values of C, N K, Q in meta-training. The results of vanilla episodic training, i.e., we only sample one task per episode with SES, is shown in <ref type="figure" target="#fig_0">Fig. 14. Fig. 3 (lower left)</ref> in the main paper shows the similarities comparison results when sampling 512 tasks per episode with SES. We find SNS outperforms other similarities in all cases. For example, it achieves 46.0% when evaluated on 5-way 1-shot tasks vs. the second best 44.9%. Although the superiority gap between SNS and others becomes smaller when we sampling more tasks with SES, our SNS still gets stable improvements. Summary. The empirical investigations in this section indicate good choices of various factors in meta-training of UML. In our UML baseline, we sample (pseudo) tasks efficiently with SES and measure similarities between instances with SNS. With a fixed size of mini-batch, we increase the "way" number N as large as C, and optimize over (pseudo) tasks with 1-shot support sets. Since the number of sampled instances C does not make much difference to the performance, we take C = 32 on account of efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B BENCHMARK RESULTS</head><p>We include the concrete results over various benchmarks in <ref type="table" target="#tab_3">Table 12</ref>. All methods are evaluated over 10,000 trials. The mean few-shot classification accuracy as well as 95% confidence interval are reported.</p><p>In addition to our UML variants, we also compare with some re-implemented self-supervised learning methods such as SimCLR <ref type="bibr" target="#b24">[25]</ref>, MoCo-v2 <ref type="bibr" target="#b75">[76]</ref>, and MoCHi <ref type="bibr" target="#b87">[88]</ref>. We conclude that our UML methods show great superiority in shallow networks (ConvNet) and higher shots. In these cases, our methods usually surpass self-supervised learning methods by a large margin.</p><p>The results of one representative UML method CAC-TUs <ref type="bibr" target="#b20">[21]</ref> are also listed, which constructs pseudo-labels by clustering over pre-learned embeddings. We try various ways to obtain the embeddings for clustering, including those used in <ref type="bibr" target="#b20">[21]</ref> and the previous three self-supervised learning methods. The best results among using different pre-learned embeddings are listed as the results of CACTUs in <ref type="table" target="#tab_3">Table 12</ref>. Note that for fair comparisons, we equip CACTUs with our proposed SES and SNS. Our UML methods perform better than CACTUs in all cases.</p><p>We also compare various methods based on the Wide ResNet 28-10 backbone (abbreviated as WRN) <ref type="bibr" target="#b98">[99]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b16">[17]</ref>. The results are shown in the last part of <ref type="table" target="#tab_3">Table 12</ref>, which demonstrates similar phenomena as those using other backbones -HMS outperforms others on lower shots tasks while TSP-Head works the best on higher shots tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX C ABLATION STUDIES</head><p>In this section, we provide more ablation studies on our UML methods on MiniImageNet with ResNet-12 backbone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 The influence of Data Augmentations</head><p>During meta-training of UML, we generate (pseudo) tasks based on data augmentations. In table 3 in the main paper, we investigate the influence of different data augmentation strategies on various UML methods based on ConvNet. Here we provide the results based on ResNet. We report the few-shot classification performance of both self-supervised learning methods and our UML methods when meta-training with different data augmentation strategies in <ref type="table" target="#tab_3">Table 13</ref>. We find with deeper backbones, RandAug <ref type="bibr" target="#b81">[82]</ref> improves our UML baseline more than AMDIM <ref type="bibr" target="#b79">[80]</ref>, but with AMDIM our UML methods get the best results in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Comparison with Sampling Strategies</head><p>We compare our SES with "Hard Task" sampling method <ref type="bibr" target="#b77">[78]</ref>, <ref type="bibr" target="#b78">[79]</ref> (denoted as and "HT" for short). HT constructs hard tasks in meta-training in a two-stage manner and improves supervised FSL. HT first selects hard classes candidates from various tasks and then organizes those hard classes together to get hard tasks. SES is more efficient since it does not require multiple forward passes per gradient descent step.</p><p>We compare SES with the vanilla sampling (with only 1 task per episode) and HT on MiniImageNet with both ConvNet and ResNet backbones. Detailed N -way K-shot results are reported in <ref type="table" target="#tab_3">Table 14</ref>. Our SES works better than vanilla sampling and HT consistently. The reasons why HT cannot help may come from two factors. First, HT relies on semantic information to construct hard tasks, which becomes difficult in the UML scenario. Moreover, the hard (pseudo) class in one task may not still be hard when it is combined with others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Transformer configurations in TSP-head.</head><p>As we stated in Section 5.2 in the main paper, the Transformer could be processed multiple times (a.k.a. multi-layer). More than one set of projection matrices could be allocated, and the multiple adapted embeddings could be concatenated followed by a linear projection to dimensionality d (a.k.a. multi-head). We investigate whether such more complicated versions of Transformer will help TSP-Head. The comparison results of different setups are shown in <ref type="figure" target="#fig_0">Fig. 15 and Fig. 16</ref>, respectively.</p><p>Based on the results in <ref type="figure" target="#fig_0">Fig. 15</ref>, we find increasing the number of Transformer heads does help learn better embeddings. In contrast, the results in <ref type="figure" target="#fig_0">Fig. 16</ref>   1-layer version of Transformer in TSP-Head. It is notable that the configuration of the Transformer is different from a recent supervised usage of Transformer for few-shot classification FEAT <ref type="bibr" target="#b16">[17]</ref>. In FEAT, the Transformer is used in both metatraining and meta-test. In other words, the post-adapted embeddings with Transformer are used in the embeddingbased few-shot classifier in meta-test. Experiments in <ref type="bibr" target="#b16">[17]</ref> show only one head and one layer works the best with FEAT.</p><p>In TSP-Head, we use Transformer only in unsupervised meta-training. The results in <ref type="figure" target="#fig_0">Fig. 15</ref> indicate that a stronger Transformer with more heads increases the generalization ability of the pre-adapted embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Maintaining TSP-Head in Meta-Test or Not?</head><p>In our TSP-Head, we meta-train the post-adapted embedding ? = T ? ? while use the pre-adapted vanilla embedding ? method augmentation  <ref type="table" target="#tab_3">Table 13</ref>: Few-shot classification accuracy of both self-supervised learning methods and our UML methods when meta-training with different data augmentation strategies. Methods are evaluated over 10,000 N -way K-shot tasks on MiniImageNet with ResNet-12 backbone.  <ref type="table" target="#tab_3">Table 14</ref>: UML comparisons on MiniImageNet with ConvNet and ResNet. Methods are evaluated over different N -way K-shot tasks, and we report the mean classification accuracy over 10,000 trials. For fair comparisons, we use the same similarity, i.e., SES, in the vanilla method (sampling only 1 task) and that with the Hard Task Sampling <ref type="bibr" target="#b77">[78]</ref>, <ref type="bibr" target="#b78">[79]</ref> strategy.</p><p>during meta-test. We expect that ? decomposes the special and general properties of tasks into the transformation T and ?, respectively, so that ? could be more generalizable.</p><p>We verify that TSP-Head achieves better results than the UML baseline especially evaluated with higher shots, but a natural question is whether maintaining the transformation T in meta-test could get further improvement. When using TSP-Head, we transform all embeddings in both support and query sets during meta-training, however, since we cannot collect all query set instances in advance during meta-test, the learned TSP-Head can only be applied to the support set of novel classes. We compare TSP-Head with FEAT <ref type="bibr" target="#b16">[17]</ref>, which constructs the embedding-based classifier with the adapted task-specific embeddings during meta-test. FEAT applies the Transformer head over the support set during meta-test. We also include the results using the learned Transformer head in both support and query sets during evaluation for reference, which is denoted as "w/ head". "w/ head" works in a transductive manner, the same as what TSP-Head works in meta-training (see also <ref type="table">Table 8</ref> in the main paper). The results are listed in <ref type="table" target="#tab_3">Table 15</ref>, which shows using the preadapted task-agnostic embedding ? outperforms using the task-specific embedding ?.</p><p>Since using the post-adapted embeddings in meta-test equals applying embedding adaptation methods based on the sampled (pseudo) tasks in both meta-training and meta-(N , K)  <ref type="table" target="#tab_3">Table 15</ref>: Few-shot classification accuracy of FEAT and MetaOptNet on MiniImageNet with ResNet-12 backbone, which utilize adapted embeddings during both meta-training and meta-test. "FEAT" applies the Transformer head over the support set during meta-test. We also include the results using the learned Transformer head in both support and query sets for evaluation as TSP-Head works in metatraining, denoted as "w/ head". Methods are evaluated over 10,000 N -way K-shot tasks.</p><p>(N , K)  <ref type="table" target="#tab_3">Table 16</ref>: Mean classification accuracy between task-agnostic projection head / task-specific projection head on different Nway K-shot tasks over 10,000 trials on MiniImageNet. Taskspecific projection head outperforms task-agnostic ones in almost all setups, especially those with higher shots. Besides, our Transformer-based TSP-head performs better than the FiLM-based TSP-head in all cases.</p><p>test, we also compare with another embedding adaptation method MetaOptNet <ref type="bibr" target="#b10">[11]</ref>. MetaOptNet adapts embeddings with a task-specific convex optimization. From the results in <ref type="table" target="#tab_3">Table 15</ref>, MetaOptNet also degrades a lot during meta-test. Therefore, results in <ref type="table" target="#tab_3">Table 15</ref> reveal that TSP-Head makes the pre-adapted embedding ? more generalizable than the post-adapted one. One possible reason could be the inconsistency of task generation between meta-training and meta-test -the embedding optimizes over (pseudo) tasks during meta-training, which pulls different views of an instance together and pushes any two instances away. In meta-test, however, the learned embedding is asked to discern few-shot classification tasks with semantically similar or dissimilar classes (based on ground-truth class labels).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Configurations of DeepSets and FiLM</head><p>We study other ways to implement the transformation T in the TSP-Head besides Transformer <ref type="bibr" target="#b84">[85]</ref>. Inspired from <ref type="bibr" target="#b31">[32]</ref>, we consider FiLM <ref type="bibr" target="#b93">[94]</ref> layer as another effective choice of the task-specific transformation. FiLM generates taskspecific scale and bias to make the transformation taskdependent. Following <ref type="bibr" target="#b16">[17]</ref>, we use DeepSets <ref type="bibr" target="#b100">[101]</ref> to capture the characteristic of a task. To be specific, for instances in the # of Tasks (5,1) (5,5) (5,20) (5,50)  <ref type="table" target="#tab_3">Table 17</ref>: The change of performance of HMS when metatrained with different configurations of SES. We increase the number of task per-episode in SES from 1 to 512. Methods are evaluated over 10,000 N -way K-shot tasks on MiniImageNet with ResNet-12 backbone and average accuracy is reported.</p><p>union of support and query sets, x ? S ? Q, its embedding ?(x) is transformed with the following manner</p><formula xml:id="formula_14">(?, ?) = h ? ? x ?(S,Q) f (? (x )) ? ? ,<label>(12)</label></formula><formula xml:id="formula_15">?(x) = ? ?(x) + ? .<label>(13)</label></formula><p>where we implement h and f as two-layer MLPs. ? and ? has the same dimension as ?(x). is element-wise product of two vectors. The summation in Eq. 12 makes the transformation permutation invariant <ref type="bibr" target="#b100">[101]</ref>, <ref type="bibr" target="#b16">[17]</ref>.</p><p>Similar to our Transformer-based projection head, FiLMbased projection head adapts ?(x) with ?(x) and the postadapted ?(x) is used to calculate the meta-training objective. Once finishing meta-training, the pre-adapted embedding ?(x) is used in meta-test. Results in <ref type="table" target="#tab_3">Table 16</ref> indicate that the Transformer implementation of TSP-Head works better than the FiLM implementation. Besides, task-specific projection head outperforms task-agnostic ones in almost all the setup, especially higher shots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.6 The Influence of Task Number in HMS</head><p>We report the results of HMS based on the usage of SES in the main paper. In this subsection, we investigate how the number of sampled (pseudo) tasks per episode influences the performance of HMS. In <ref type="table" target="#tab_3">Table 17</ref>, we gradually increase the task number in SES from 1 to 512. Results show that HMS benefits from the increased number of tasks, e.g., from 50.98% to 58.51% evaluated on 5-way 1-shot tasks. Therefore, instead of choosing hard negatives from a large memory bank <ref type="bibr" target="#b87">[88]</ref>, our HMS takes advantage of the re-sampled tasks per episode and makes the meta-learned embeddings discriminative.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Supervised meta-learning (a) and Unsupervised Meta-Learning (UML) (b) for few-shot image classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Empirical study to show the importance of sufficient sampling and semi-normalized similarity in UML on MiniImageNet with a four-layer ConvNet over 100 epochs. Upper: the meta-training loss and 5-way 1-shot meta-validation accuracy along epochs. Sufficient sampling with multiple tasks demonstrates fast convergence speed and high generalization ability. Lower left: By comparing different similarity measures, we find SNS always performs the best when tested with 5-way {1, 5, 20, 50}-shot tasks. Lower right: The gradient norms w.r.t. embeddings averaged over all instances in the mini-batch along with the meta-training progress. Different similarities have diverse changes in their gradient norms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Comparisons among our augmentation-based UML baseline, clustering-based UML method CACTUs, and representative self-supervised learning methods (i.e., MoCo and SimCLR). All methods are trained with a four-layer ConvNet on MiniImageNet. The meta-learned embeddings with UML show better discriminative ability on "downstream" novel class 5-way {1, 5, 20, 50}-shot tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Illustrations of our proposed UML methods. (a) Based on a sampled mini-batch, we apply image augmentations to construct pseudo-classes. Multiple tasks are re-sampled from a mini-batch with Sufficient Episodic Sampling (SES). (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 4</head><label>4</label><figDesc>The meta-training flow of HMS. Require: Unlabeled base class set B 1: for all iteration = 1,... do 2:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 5</head><label>5</label><figDesc>The meta-training flow of TSP-Head. Require: Unlabeled base class set B 1: for all iteration = 1,... do 2:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>The change of 5-way 1-shot classification accuracy on MiniImageNet with ResNet when the label ratio in the base class set increases. The dotted line is the performance of the ProtoNet learned with a fully labeled meta-training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Linear evaluation comparisons. The meta-test set is split into 10 folds. A logistic regression is trained on frozen embeddings of the 9 folds, and the remaining fold is used to evaluate accuracy. All methods are learned on the metatraining set of MiniImageNet with ResNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>T-SNE visualization of learned embeddings on the MiniImageNet. Four plots display results of ProtoNet [10] (a), UML baseline (b), HMS (c), and TSP-Head (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Investigation on the number of way N ? {5, 32, 64} during meta-training for UML. All meta-learned embeddings are evaluated on 5-way {1, 5, 20, 50}-shot classification tasks over 10,000 trials on MiniImageNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Investigation on the number of shot in the query set Q ? {1, 5, 10} during meta-training of UML. All metalearned embeddings are evaluated on 5-way {1, 5, 20, 50}shot classification tasks over 10,000 trials on MiniImageNet. Please see the texts for more details. The figure illustrates that the number of query instances needs to reach a certain value to make the meta-learned embeddings generalizable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 13 :</head><label>13</label><figDesc>Investigation on the number of sampled instances C per episode during meta-training of UML. The larger the value of C, the larger the size of the mini-batch in metatraining. All meta-learned embeddings are evaluated on 5-way {1, 5, 20, 50}-shot classification tasks over 10,000 trials on MiniImageNet. Please see the texts for more details. The figure illustrates that our UML baseline is insensitive to the mini-batch size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 16 :</head><label>16</label><figDesc>The influence of the number of Transformer layers used in TSP-Head. The number of heads is fixed to 1, and each layer of the Transformer projects the input into vectors with the same dimensionality. Reported results are the averaged 5-way {1, 5, 20, 50}-shot meta-test accuracy over 10,000 trials on MiniImageNet with ResNet backbone. Results show that using one Transformer layer in TSP-Head performs the best.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Comparison between SNS and cosine onMiniImageNet with ConvNet. We carefully tune the temperature for cosine with 16 values in [0.005, 1], and show mean as well as std. over all temperatures.</figDesc><table><row><cell></cell><cell>&amp;RVLQH</cell><cell></cell></row><row><cell>WHVWDFFXUDF\</cell><cell>6162XUV</cell><cell></cell></row><row><cell></cell><cell></cell><cell>VKRW RIVKRWV VKRW</cell><cell>VKRW</cell></row><row><cell cols="2">Figure 4: 1 shot 40 45 50 55 60 65 70 75 42.1 42.0 44.5 47.4 meta-test accuracy</cell><cell>5 shot # of shot 20 shot 55.9 62.2 55.0 60.6 58.2 65.1 64.1 72.5</cell><cell>50 shot 63.9 62.3 67.1 74.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>AutoAug [81] 44.81 61.05 69.94 72.62 RandAug [82] 45.94 61.47 68.85 71.12 Comparison of different augmentations on MiniImageNet with ConvNet backbone. Methods are evaluated over different N -way K-shot tasks. Compared augmentations are Simple, SimCLR, AMDIM, AutoAug, and RandAug. "Simple" consists of random resized crop, color distortion, and random horizontal flip, which is commonly used in supervised learning. Moderate augmentation such as AMDIM shows the best results. Too strong augmentation like RandAug will degenerate the performance.</figDesc><table><row><cell></cell><cell>(5,1)</cell><cell>(5,5)</cell><cell>(5,20)</cell><cell>(5,50)</cell></row><row><cell>Simple</cell><cell cols="3">44.42 60.18 69.07</cell><cell>71.63</cell></row><row><cell>SimCLR [25]</cell><cell cols="3">46.51 62.91 71.35</cell><cell>73.66</cell></row><row><cell>AMDIM [80]</cell><cell cols="3">47.43 64.11 72.52</cell><cell>74.72</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>UML comparison on MiniImageNet with ConvNet backbone. We report the averaged classification accuracy over 10,000 different N -way K-shot tasks. "Vanilla" is the traditional UML baseline without SES and SNS.are investigated. Results with Wide ResNet backbone</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>08 84.51 37.88 53.68 65.14 69.1575.89 83.77 85.72 54.65 73.70 81</head><label></label><figDesc>Vanilla 48.52 65.77 73.98 76.20 46.73 62.93 67.43 70.76 32.81 42.17 51.60 55.02 SimCLR [25] 57.75 72.84 78.45 79.75 53.86 69.19 75.22 77.11 34.69 47.07 54.87 57.54 MoCo-v2 * [76] 54.92 71.18 77.64 79.30 49.73 64.81 71.14 72.70 32.86 44.08 51.55 54.15 MoCHi [88] 57.64 75.53 82.91 84.76 48.42 63.91 71.10 72.90 35.51 46.95 54.52 57.14 CACTUs [55] 55.62 69.50 74.67 75.68 51.96 69.08 74.11 75.38 35.91 47.29 53.89 55.94 CACTUs w/ SES+SNS 57.25 71.49 76.27 77.59 52.53 73.57 78.48 79.80 36.79 48.60 55.52 57.85 CUMCA [57] 51.66 67.15 75.50 76.71 50.48 67.83 73.04 75.04 33.00 47.41 56.66 58.68 CUMCA w/ SES+SNS 54.95 71.85 79.06 80.98 53.11 70.99 78.75 80.95 36.15 50.04 59.61 62.89 Baseline (Ours) 56.74 74.05 81.24 83.04 53.25 72.05 80.03 82.16 37.31 51.62 61.80 65.54 HMS (Ours) 58.20 75.77 82.69 84.41 52.20 72.23 82.TSP-Head (Ours) 56.99 .67 83.86 36.83 51.78 62.73 66.56</figDesc><table><row><cell></cell><cell></cell><cell>MiniImageNet</cell><cell>CIFAR-FS</cell><cell>FC-100</cell></row><row><cell>(N , K)</cell><cell>(5,1)</cell><cell>(5,5) (5,20) (5,50) (5,1)</cell><cell>(5,5) (5,20) (5,50) (5,1)</cell><cell>(5,5) (5,20) (5,50)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>The mean classification accuracy on TieredImageNet with ResNet backbone. Methods are evaluated over 10,000 N -way K-shot tasks.</figDesc><table><row><cell>meta-test accuracy</cell><cell>52.5 55.0 57.5 60.0 62.5 65.0 67.5 70.0</cell><cell>54.9</cell><cell>57.8</cell><cell>56.7</cell><cell>58.2</cell><cell>57.0</cell><cell>55.5</cell><cell>59.4</cell><cell>59.2</cell><cell>63.6</cell><cell>62.3</cell><cell>58.0</cell><cell>59.8</cell><cell>62.4</cell><cell>65.2</cell><cell>62.8</cell><cell>58.4</cell><cell>60.9</cell><cell>62.7</cell><cell>65.9</cell><cell>62.6</cell><cell>58.9</cell><cell>60.6</cell><cell>62.9</cell><cell>65.4</cell><cell>62.9</cell></row><row><cell></cell><cell>50.0</cell><cell></cell><cell cols="3">0%</cell><cell></cell><cell></cell><cell cols="3">1%</cell><cell cols="7">5% label ratio</cell><cell cols="3">10%</cell><cell></cell><cell></cell><cell cols="3">20%</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>40.75 58.32 68.61</head><label></label><figDesc></figDesc><table><row><cell>(N , K)</cell><cell>(5,1)</cell><cell>(5,5) (5,20)</cell></row><row><cell>SimCLR [25]</cell><cell cols="2">38.91 54.88 63.76</cell></row><row><cell>MoCo-v2 [76]</cell><cell cols="2">37.52 51.04 59.48</cell></row><row><cell>Baseline (Ours)</cell><cell cols="2">39.72 55.45 64.45</cell></row><row><cell>HMS (Ours)</cell><cell cols="2">40.65 57.56 67.57</cell></row><row><cell>TSP-Head (Ours)</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Mean classification accuracy evaluated on different N -way K-shot tasks on MiniImageNet. The top and bottom parts are unsupervised and supervised methods, respectively.? denotes the method that utilizes initialization weights pretrained over all labeled base classes.</figDesc><table><row><cell>(N , K)</cell><cell>(5,1)</cell><cell>(5,5) (5,20) (5,50)</cell></row><row><cell>MetaMix [87]</cell><cell cols="2">50.23 68.30 71.02 73.62</cell></row><row><cell>CUMCA [57]</cell><cell cols="2">51.66 67.15 75.50 76.71</cell></row><row><cell cols="3">Hard Task [78], [79] 54.74 72.61 78.96 80.93</cell></row><row><cell>HMS</cell><cell cols="2">58.20 75.77 82.69 84.41</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>HMS) 56.74 74.05 81.24 83.04 ? = 0 55.86 75.02 83.41 85.43 ? ? U (0, 0.05) 56.37 75.49 83.57 85.63 ? ? U (0, 0.1) 56.55 75.60 83.71 85.66 ? ? U (0, 0.2) 57.03 75.66 83.40 85.19 ? ? U (0, 0.5) 58.20 75.77 82.69 84.41 ? ? U (0, 1.0) 59.27 74.55 80.46 81.82</figDesc><table><row><cell>(5,1)</cell><cell>(5,5) (5,20) (5,50)</cell></row><row><cell>baseline (w/o</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>99.73 99.78 99.8056.99 75.94 83.72 85.74</head><label></label><figDesc>w/o head 98.64 99.72 99.77 99.79 Meta-test with real tasks w/ head 56.90 75.87 83.59 85.69 w/o head</figDesc><table><row><cell></cell><cell>(5,1)</cell><cell>(5,5) (5,20) (5,50)</cell></row><row><cell cols="3">Meta-test on pseudo tasks</cell></row><row><cell>w/ head</cell><cell>98.87</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>75.89 83.77 85.72</head><label></label><figDesc>TSP-Head + HMS 56.74 74.58 82.21 84.11</figDesc><table><row><cell>(N , K)</cell><cell>(5,1)</cell><cell>(5,5) (5,20) (5,50)</cell></row><row><cell>HMS</cell><cell>58.20</cell><cell>75.77 82.69 84.41</cell></row><row><cell>TSP-Head</cell><cell>56.99</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 11 :</head><label>11</label><figDesc>Mean accuracy between HMS, TSP-Head, and their combination on N -way K-shot tasks on MiniImageNet.</figDesc><table><row><cell>linear evaluation accuracy</cell><cell>70 72 74 76 78 80 82 84</cell><cell>MoCo 74.92</cell><cell>SimCLR Baseline method 78.08 75.92</cell><cell>HMS 79.58</cell><cell>TSP-Head 80.92</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head></head><label></label><figDesc>indicate using more transformer layers leads to the performance drop. Therefore, we use an 8-head</figDesc><table><row><cell>meta-test accuracy</cell><cell>55 60 65 70 75 80 85 90</cell><cell>55.9 56.2 56.5 57.0 1 head 2 head 4 head 8 head</cell><cell>74.6 74.8 74.9 75.9</cell><cell>82.5 82.3 82.6 83.8</cell><cell>84.5 84.3 84.5 85.7</cell></row><row><cell></cell><cell>50</cell><cell>1 shot</cell><cell cols="2">5 shot # of shot 20 shot</cell><cell>50 shot</cell></row><row><cell cols="6">Figure 15: The influence of the number of Transformer</cell></row><row><cell cols="6">heads used in TSP-Head. The number of layers is fixed to 1.</cell></row><row><cell cols="6">Reported results are the averaged 5-way {1, 5, 20, 50}-shot</cell></row><row><cell cols="6">meta-test accuracy over 10,000 trials on MiniImageNet with</cell></row><row><cell cols="6">ResNet backbone. Using more heads in TSP-Head makes the</cell></row><row><cell cols="5">learned embedding generalizable better.</cell><cell></cell></row><row><cell>meta-test accuracy</cell><cell>40 50 60 70 80 90</cell><cell>1 shot 55.9 43.3 44.0 1 layer 2 layer 3 layer</cell><cell cols="2">5 shot # of shot 20 shot 61.8 57.5 62.8 69.5 74.6 82.5</cell><cell>50 shot 63.9 71.3 84.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>52.93 ? 0.20 70.91 ? 0.17 79.53 ? 0.14 81.76 ? 0.1375.70 ? 0.15 83.38 ? 0.12 85.39 ? 0.11</head><label></label><figDesc>? 0.20 72.84 ? 0.16 78.45 ? 0.13 79.75 ? 0.12 MoCo-v2<ref type="bibr" target="#b75">[76]</ref> AMDIM<ref type="bibr" target="#b79">[80]</ref> 54.92 ? 0.20<ref type="bibr" target="#b70">71</ref>.18 ? 0.15 77.64 ? 0.13 79.30 ? 0.11 MoCHi [88] AMDIM [80] 57.64 ? 0.20 75.53 ? 0.15 82.91 ? 0.12 84.76 ? 0.11 Baseline (Ours) AMDIM [80] 56.74 ? 0.20 74.05 ? 0.16 81.24 ? 0.13 83.04 ? 0.12 HMS (Ours) AMDIM [80] 58.20 ? 0.20 75.77 ? 0.16 82.69 ? 0.13 84.41 ? 0.12 TSP-Head (Ours) AMDIM [80] 56.99 ? 0.20 75.89 ? 0.15 83.77 ? 0.12 85.72 ? 0.11 ? 0.19 72.94 ? 0.15 80.66 ? 0.12 82.59 ? 0.11 MoCo-v2 [76] SimCLR [25] 56.50 ? 0.20 73.33 ? 0.16 79.41 ? 0.13 80.80 ? 0.13 MoCHi [88] SimCLR [25] 54.94 ? 0.20 72.68 ? 0.15 80.30 ? 0.12 82.18 ? 0.11 Baseline (Ours) SimCLR [25] 55.33 ? 0.20 72.58 ? 0.16 79.98 ? 0.13 81.87 ? 0.12 HMS (Ours) SimCLR [25] 57.21 ? 0.20 74.81 ? 0.16 81.26 ? 0.13 83.20 ? 0.12 TSP-Head (Ours) SimCLR [25] 55.65 ? 0.20 73.18 ? 0.16 81.96 ? 0.13 83.72 ? 0.12 SimCLR [25] AutoAug [81] 49.01 ? 0.20 65.98 ? 0.18 75.03 ? 0.15 77.64 ? 0.13 MoCo-v2 [76] AutoAug [81] 48.37 ? 0.20 64.47 ? 0.18 72.96 ? 0.16 75.56 ? 0.14 MoCHi [88] AutoAug [81] 52.69 ? 0.20 70.08 ? 0.17 79.14 ? 0.14 81.40 ? 0.13 Baseline (Ours) AutoAug [81] 51.49 ? 0.20 69.43 ? 0.18 77.86 ? 0.15 80.08 ? 0.14 HMS (Ours) AutoAug [81] 52.91 ? 0.21 70.76 ? 0.18 78.67 ? 0.15 80.80 ? 0.14 TSP-Head (Ours) AutoAug [81] SimCLR [25] RandAug [82] 54.22 ? 0.19 72.80 ? 0.15 80.59 ? 0.12 82.13 ? 0.11 MoCo-v2 [76] RandAug [82] 55.21 ? 0.20 73.07 ? 0.15 80.25 ? 0.13 81.91 ? 0.12 MoCHi [88] RandAug [82] 56.27 ? 0.20 75.55 ? 0.15 81.04 ? 0.13 82.44 ? 0.12 Baseline (Ours) RandAug [82] 57.12 ? 0.20 75.47 ? 0.16 82.13 ? 0.13 83.80 ? 0.12 HMS (Ours) RandAug [82] 58.04 ? 0.21 74.92 ? 0.16 82.21 ? 0.13 84.28 ? 0.11 TSP-Head (Ours) RandAug [82] 56.86 ? 0.20</figDesc><table><row><cell>(5,1)</cell><cell>(5,5)</cell><cell>(5,20)</cell><cell>(5,50)</cell></row><row><cell>SimCLR [25] 57.75 SimCLR [25] AMDIM [80] SimCLR [25] 55.21</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head></head><label></label><figDesc>Vanilla 43.01 57.94 65.46 67.62 48.52 65.77 73.98 76.20 Hard Task [78], [79] 46.37 62.88 72.28 73.86 54.74 72.61 78.96 80.93 SES (Ours) 47.43 64.11 72.52 74.72 56.74 74.05 81.24 83.04</figDesc><table><row><cell></cell><cell></cell><cell>ConvNet</cell><cell></cell><cell>ResNet</cell></row><row><cell>(N , K)</cell><cell>(5,1)</cell><cell>(5,5) (5,20) (5,50)</cell><cell>(5,1)</cell><cell>(5,5) (5,20) (5,50)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>99 75.89 83.77 85.72</head><label></label><figDesc>Meta-test with post-adapted embeddings MetaOptNet [11] 56.71 68.11 74.65 79.02 FEAT [17] 56.67 73.77 81.09 82.97 w/ head 56.90 75.87 83.59 85.69Meta-test with pre-adapted embeddings TSP-Head 56.</figDesc><table><row><cell>(5,1)</cell><cell>(5,5) (5,20) (5,50)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>56.99 75.89 83.77 85.72</head><label></label><figDesc>Task-specific projection head DeepSets [101]+FiLM [94] 51.71 73.28 82.15 84.48 TSP-Head (ours)</figDesc><table><row><cell></cell><cell>(5,1)</cell><cell>(5,5) (5,20) (5,50)</cell></row><row><cell>Task-agnostic projection head</cell><cell></cell></row><row><cell>Projection Head [25]</cell><cell cols="2">53.32 70.87 78.38 80.32</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>51 76.27 83.28 84.97</head><label></label><figDesc>1 50.98 69.30 78.73 81.10 8 54.83 73.02 81.02 83.16 64 55.97 74.16 82.11 83.99 256 58.20 75.77 82.69 84.41 512 58.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Thanks to Hexiang Hu for valuable discussions. This work is partially supported by The National Key R&amp;D Program of China (2020AAA0109401), NSFC (62006112, 61773198, 61921006), NSF of Jiangsu Province (BK20200313), CCF-Baidu Open Fund (NO.2021PP15002000).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">One shot learning of simple visual concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<editor>CogSci</editor>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Humanlevel concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Heterogeneous few-shot model rectification with semantic mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3878" to="3891" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Few-shot object detection with attention-rpn and multi-relation detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4012" to="4021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Meta-rcnn: Meta learning for few-shot object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM, 2020</title>
		<imprint>
			<biblScope unit="page" from="1679" to="1687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Contexttransformer: Tackling object confusion for few-shot detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">660</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4080" to="4090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On first-order metalearning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno>abs/1803.02999</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lowshot learning from imaginary data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7278" to="7286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Revisiting meta-learning as supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>abs/2002.00573</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Few-shot image recognition by predicting parameters from activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7229" to="7238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Few-shot learning via embedding adaptation with set-to-set functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8808" to="8817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Rethinking few-shot image classification: A good embedding is all you need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="266" to="282" />
		</imprint>
	</monogr>
	<note>in ECCV, 2020</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="766" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised metalearning for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khodadadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>B?l?ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page" from="10" to="132" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Assume, augment and learn: Unsupervised few-shot meta-learning via random labels and data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Storkey</surname></persName>
		</author>
		<idno>abs/1902.09884</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised few-shot learning via distribution shift-based augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<idno>abs/2004.05805</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in CVPR</title>
		<imprint>
			<biblScope unit="page" from="4367" to="4375" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="594" to="611" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Meta-sgd: Learning to learn quickly for few shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/1707.09835</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Gradient-based meta-learning with learned layerwise metric and subspace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICML</title>
		<imprint>
			<biblScope unit="page" from="2933" to="2942" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">TADAM: task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page" from="719" to="729" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multimodal modelagnostic meta-learning via task-aware modulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vuorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">How to train your MAML to excel in few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Chao</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to learn: Model regression networks for easy small sample learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="616" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7032" to="7042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Interventional few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Few-shot learning through an information retrieval lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2252" to="2262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Domain adaption in one-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML/PKDD</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="573" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Transferable meta learning across domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in UAI</title>
		<imprint>
			<biblScope unit="page" from="177" to="187" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dense classification and implanting for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lifchitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Avrithis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bursuc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9258" to="9267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Few-shot text classification by leveraging bi-directional attention and cross-class knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Information Sciences</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Meta-dataset: A dataset of datasets for learning to learn from few examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Evci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gelada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Few-shot learning with a strong teacher</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Task cooperation for semisupervised few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Zhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">690</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Transmatch: A transferlearning scheme for semi-supervised few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12" to="853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Label independent memory for semisupervised few-shot video classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="273" to="285" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning to self-train for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page" from="10" to="276" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">ECKPN: explicit class knowledge propagation network for transductive few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6596" to="6605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Meta-learning update rules for unsupervised representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Unsupervised learning via metalearning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Meta-gmvae: Mixture of gaussian VAE for unsupervised meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Unsupervised meta-learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page">107951</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Unsupervised few-shot feature learning via self-supervised training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Computational Neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">83</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Self-supervised prototypical transfer learning for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Devos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grossglauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Shot in the dark: Few-shot learning with no base-class labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Learned-Miller</surname></persName>
		</author>
		<idno>abs/2010.02430</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Self-supervised learning of pretextinvariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6707" to="6717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2536" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Photorealistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">When does self-supervision improve few-shot learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<biblScope unit="page" from="645" to="666" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Few-shot image classification via contrastive self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Debiased contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Boosting contrastive self-supervised learning with false negative cancellation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khademi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Khandeparkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5628" to="5637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Heated-up softmax embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
		<idno>abs/1809.04157</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Simpleshot: Revisiting nearest-neighbor classification for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="1911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Improved baselines with momentum contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Lgm-net: Learning to generate matching networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-G</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3825" to="3834" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Meta-transfer learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Meta-transfer learning through hard tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Buchwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page" from="15" to="509" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation policies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Man?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno>abs/1805.09501</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Contrastive multiview coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="776" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">What makes for good views for contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Improving generalization in meta-learning via task augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Hard negative mixing for contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Sariyildiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Larlus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Un-mix: Rethinking image mixtures for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<idno>abs/2003.05438</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Mix&apos;em: Unsupervised image classification using a mixture of embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varamesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV, 2020</title>
		<imprint>
			<biblScope unit="page" from="38" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Augmentation invariant and instance spreading feature for softmax embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Layer normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno>abs/1607.06450</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Film: Visual reasoning with a general conditioning layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in AAAI</title>
		<imprint>
			<biblScope unit="page" from="3942" to="3951" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Redesigning the classification layer by randomizing the class representation vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shalev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-L</forename><surname>Shalev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Keshet</surname></persName>
		</author>
		<idno>abs/2011.08704</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<title level="m">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Deep sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>P?czos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3391" to="3401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(n</forename></persName>
		</author>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">50</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">TieredImageNet with ResNet</title>
		<imprint>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Detailed report of meta-test average few-shot classification accuracy with 95% confidence interval on different datasets and backbones. Please see Section B for details</title>
	</analytic>
	<monogr>
		<title level="j">Table</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
