<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A modular U-Net for automated segmentation of X-ray tomography images in composite materials</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><forename type="middle">P C</forename><surname>Bertoldo</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Centre des Mat?riaux b Centre de Morphologie Math?matique</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Decenci?re</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ryckelynck</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Centre des Mat?riaux b Centre de Morphologie Math?matique</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Proudhon</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Centre des Mat?riaux b Centre de Morphologie Math?matique</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">MINES ParisTech</orgName>
								<orgName type="institution" key="instit2">PSL Research University</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A modular U-Net for automated segmentation of X-ray tomography images in composite materials</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Preprint submitted to Nature Machine Intelligence July 2021 arXiv:2107.07468v1 [eess.IV] 15 Jul 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T14:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep Learning</term>
					<term>U-Net</term>
					<term>Modular Network Architecture</term>
					<term>Semantic Segmentation</term>
					<term>3D X-ray Computed Tomography</term>
					<term>Composite Material</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>X-ray Computed Tomography (XCT) techniques have evolved to a point that high-resolution data can be acquired so fast that classic segmentation methods are prohibitively cumbersome, demanding automated data pipelines capable of dealing with non-trivial 3D images. Deep learning has demonstrated success in many image processing tasks, including material science applications, showing a promising alternative for a humanfree segmentation pipeline. In this paper a modular interpretation of U-Net (Modular U-Net) is proposed and trained to segment 3D tomography images of a three-phased glass fiber-reinforced Polyamide 66. We compare 2D and 3D versions of our model, finding that the former is slightly better than the latter. We observe that human-comparable results can be achievied even with only 10 annotated layers and using a shallow U-Net yields better results than a deeper one. As a consequence, Neural Network (NN) show indeed a promising venue to automate XCT data processing pipelines needing no human, adhoc intervention.</p></div>
			</abstract>
		</profileDesc>
		<revisionDesc>
				<date type="submission" when="-1" />
		</revisionDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>X-ray Computed Tomography (XCT), a characterization technique used by material scientists for non-invasive analysis, has tremendously progressed over the last 10 years with improvements in both spatial resolution and throughput <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Progress with synchrotron sources, including the recent European Synchrotron Radiation Facility (ESRF) upgrade <ref type="bibr" target="#b2">[3]</ref>, made it possible to look inside a specimen without destroying it in a matter of seconds <ref type="bibr" target="#b3">[4]</ref> -sometimes even faster <ref type="bibr" target="#b4">[5]</ref>.</p><p>This results in a wealth of 3D tomography images (stack of 2D images) that need to be analyzed and, in some applications, it is desirable to segment them (i.e. transform the gray-scaled voxels in semantic categorical values). A segmented image is crucial for quantitative analyses; for instance, measuring the distribution of precipitate length and orientation <ref type="bibr" target="#b5">[6]</ref>, or phase characteristics, which can be useful for more downstream applications like estimating thermo-mechanical properties <ref type="bibr" target="#b6">[7]</ref>.</p><p>XCT images typically have billions of voxels, weighting several gigabytes, and remain complex to inspect manually even using dedicated costly software (e.g.: Avizo 2 , VGStudioMax 3 ). Using thresholds on the gray level image is an easy, useful method to segment phases in tomographies, but it fails in complex cases, in particular when acquisition artifacts (e.g.: rings, beam hardening, phantom gradients) are present. Algorithms based on mathematical morphology like the watershed segmentation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> help tackling more complex scenarios, but they need human parametrization, which often requires expertise in the application domain. Thus, scaling quantitative analyses is expensive, creating a bottleneck to process 3D XCT -or even 4D (3D with time steps).</p><p>Deep Learning approaches offer a viable solution to attack this issue because Neural Networks (NNs) can generalize patterns learned from annotated data. A NN is a statistical model originated from perceptrons <ref type="bibr" target="#b9">[10]</ref> capable of approximating a generic function. Convolutional NNs (CNNs) <ref type="bibr" target="#b10">[11]</ref>, a variation adapted to spatially-structured data (time series, images, volumes), made great advances in computer vision tasks. Since the emergence of popular frameworks like TensorFlow <ref type="bibr" target="#b11">[12]</ref>, more problem-specific architectures have been proposed, such as Fully-convolutional NNs <ref type="bibr" target="#b12">[13]</ref>, a convolution-only type of model used to map image pixel values to another domain (e.g. classification or regression). <ref type="bibr" target="#b5">[6]</ref> trained a model to segment three phases in 3D nanotomographies of an Al-Cu alloy, showing that even a simple CNN can reproduce patterns of a human-made segmentation. <ref type="bibr" target="#b13">[14]</ref> optimized a SegNet <ref type="bibr" target="#b14">[15]</ref> to segment dendrites of different alloys, including a 4D XCT. <ref type="bibr" target="#b6">[7]</ref> identified Aluminides and Si phases in XCT using a U-Net, an architecture that, along with its many flavors <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref>, has shown success in a variety of applications <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref>. Finally, <ref type="bibr" target="#b22">[23]</ref> combined U-Nets with classic segmentation algorithms (e.g. marker-based watershed) to segment grain boundaries in successive XCTs of an Al-Cu specimen as it is submitted to Ostwald ripening steps.</p><p>In this paper, an annotated 3D XCT of glass fiber-reinforced Polyamide 66 is presented as an example of segmentation problem in Materials Science that can be automated with a deep learning approach. Our NN architecture, the Modular U-Net ( <ref type="figure" target="#fig_3">Fig. 2 and Fig. 3</ref>), is proposed as a generalized representation of the U-Net, explicitly factorizing the U-like structure from its composing blocks.</p><p>Like <ref type="bibr" target="#b22">[23]</ref>, we compare three variants on the composite material dataset focusing on the dimensionality of the convolutions (2D or 3D), obtaining qualitatively human-like segmentation ( <ref type="figure" target="#fig_0">Fig. 1 and Fig. 4</ref>) with all of them although 2D-convolutions yield better results ( <ref type="figure" target="#fig_5">Fig. 5a</ref>). We find that (for the considered material) the U-Net architecture can be shallow without loss of performance, but batch normalization is necessary for the optimization ( <ref type="figure" target="#fig_5">Fig. 5b</ref>). Finally, a model's learning curve ( <ref type="figure" target="#fig_6">Fig. 6</ref>) shows that only ten annotated 2D slices are necessary to train our NN.</p><p>Our results show that NNs can be not only a quality-wise satisfactory but also a viable solution in practice for XCT segmentation as it requires relatively little annotated data and shallow models (therefore faster to train).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Data</head><p>The data used in this work is composed of synchrotron X-ray tomography volumes recorded using 2 mm ? 2 mm cross section composite specimens of Polyamide 66 reinforced by glass fibers. A volume of 2048 3 voxels, referred to as Train-Val-Test ( <ref type="figure" target="#fig_0">Fig. 1 and Fig. A.7)</ref>, was cropped to get rid of the specimen's borders, and its ground truth segmentation was created semi-manually with ImageJ <ref type="bibr" target="#b23">[24]</ref> (using Fiji <ref type="bibr" target="#b24">[25]</ref>) and Avizo. The tomography of another specimen of the same material was also processed and partially annotated in order to evaluate our models ( <ref type="figure" target="#fig_4">Fig. 4</ref>) -it is further referred to as the "crack" volume because of the fracture inside it. Both image volumes and the former's annotations are publicly available <ref type="bibr" target="#b25">[26]</ref>.</p><p>Acquisition. X-ray tomography scans were recorded on the Psich? beamline at the Synchrotron SOLEIL using a parallel pink beam. The incident beam spectrum was characterized by a peak intensity at 25 keV, defined by the silver absorption edge, with a full width at half maximum bandwidth of approximately 1.8 keV. The total flux at the sample position was about 2.8 ? 10 12 photons/s/mm 2 . The detector placed after the sample was constituted by a LuAG scintillator, a 5? magnifying optics, and a Hamamatsu CMOS 2048 x 2048 pixels detector (effective pixel size of 1.3 ?m). 1500 radiographs were collected over a 180?rotation and an exposure of 50 ms (full scan duration of 2 minutes). The sets of radiographs were then processed using PyHST2 reconstruction software <ref type="bibr" target="#b26">[27]</ref> with the Paganin filter <ref type="bibr" target="#b27">[28]</ref> activated to enhance the contrast between the phases.</p><p>Phases. The three phases present in the material are visible in <ref type="figure" target="#fig_0">Fig. 1</ref>: the polymer matrix (gray), the glass fibers (white, hatched in blue), and damage in form of pores (dark gray and black, contoured in yellow) -referred as porosity here. One can observe that the orientation of the fibers is unevenly distributed; they are mostly along the axes Y (vertical) and Z (out of the plane) in <ref type="figure" target="#fig_8">Fig. A.7</ref>.</p><p>Ground truth. The data was annotated in two steps: first, the fiber and the porosity phases were independently segmented using Seeded Region Growing <ref type="bibr" target="#b28">[29]</ref>; then, ring artifacts that leaked to the porosity class were manually corrected. A detailed description of the procedure is presented in the Appendix A.</p><p>Data split. The ground truth layers (of the Train-Val-Test volume) were sequentially split -their order were preserved to train the 3D models (Section 2.2) -into three sets: train (1300 layers), validation (128 layers), and test (300 layers). A margin of 86 layers between these sets was adopted to avoid information leakage. The train layers were used to train the NNs, the validation layers were used to select the best model (during the optimization), and the test layers were used to evaluate the models (Section 3).</p><p>Class imbalance. Due to the material's nature, the classes (phases) in this dataset are intrinsically imbalanced. The matrix, the fiber, and the porosity represent, respectively, 82.3%, 17.2%, and 0.5% of the voxels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Neural Network</head><p>Problem formulation. Let x ? X = [0, 1] w?h?d be a normalized gray 3D image. Its segmentation y ? Y = C w?h?d , where C = {0, 1, . . . , C ? 1} , contains a class value in each voxel, which may represent any categorical information, such as the phase of the material. In this setting, a segmentation algorithm is a function f : X ? Y . In this section we present our approach (that is, the f ) used to segment the data described in the previous section.</p><p>First, a generic U-Net architecture, which we coined Modular U-Net ( <ref type="figure" target="#fig_10">Fig. 2)</ref>, is proposed; then, the modules used in this work are briefly exposed (detailed description and hyperparameters in the Appendix B); finally, three variations of the Modular U-Net, based on the input, convolution, and output nature (2D or 3D), are presented. Our training setup (loss function, optimizer, learning rate, data augmentation, implementation framework, and hardware) is described in Appendix C.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Modular U-Net</head><p>Since <ref type="bibr" target="#b15">[16]</ref> proposed U-Net, variations of it emerged in the literature (e.g.: <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>). Here we propose a generalized version, preserving its overall structure. The Modular U-Net <ref type="figure" target="#fig_10">(Fig. 2</ref>) is based on three blocks: the Convolutional Block (ConvBlock), the Downsampling Block (DownBlock), and the Upsampling Block (UpBlock).</p><p>The left/right side of the architecture corresponds to an encoder/decoder, a repetition of pairs of ConvBlock and DownBlock/UpBlock modules. They are connected by concatenations between their respective parts at the same U-level -which corresponds to the inner tensors' resolutions (higher U-level means lower resolution). The U-depth, a hyperparameter, is the number of U-levels in a model, corresponding to the number of DownBlock (and equivalently UpBlock) modules.</p><p>The ConvBlock is a combination of operations that outputs a tensor with the same spatial dimensions of its input, though the number of channels may differ -in our models it always doubles. The assumption of equally-sized input/output is optional, but we admit it for the sake of simplicity because it makes the model easier to be used with an arbitrarily shaped volume. The numbers of channels after the ConvBlocks is 2 U-level ? f 0 , where f 0 is the number of filters in the first convolution.</p><p>The DownBlock/UpBlock divides/multiplies the input tensor's shape by two in every spatial dimension: width, length, and depth in the 3D case. In other words, a tensor with shape (w, h, d, c) , where c is the number of channels, becomes, respectively, ( w 2 , h 2 , d 2 , c) after a DownBlock and (2w, 2h, 2d, c) after an UpBlock.</p><p>In <ref type="bibr" target="#b15">[16]</ref>, for instance, the ConvBlock is a sequence of two 3x3 convolutions with ReLU activation, the DownBlock is a max pooling, and the UpBlock is an up-sampling layer. In <ref type="bibr" target="#b16">[17]</ref>, the ConvBlock is a 3D convolutional layer, and in <ref type="bibr" target="#b17">[18]</ref> it is a nested U-Net.</p><p>The ConvBlock used here ( <ref type="figure" target="#fig_3">Fig. 3</ref>) is a sequence of two 3x3 (x3 in the 3D case) convolutions with ReLU activation, a residual connection with another convolution, batch normalization before each activation, and dropout at the end. The DownBlock is a 3 ? 3 convolution with 2 ? 2 stride, and the UpBlock is a 3 ? 3 transposed convolution with 2 ? 2 stride.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Variations: 2D, 2.5D, and 3D</head><p>Since our dataset contains intrinsically 3D structures, we compared the performances of this architecture using 2D and 3D convolutions. The former processes individual tomography z-slices (XY plane) independently, and the latter processes several at once (i.e. a volume).</p><p>We also compared an "intermediate" version, which we coined 2.5D, that processes one tomography z-slice at a time using 2D convolutions, but takes five slices at the input, as if the pairs of data slices above and below were channels of the 2D image. <ref type="table" target="#tab_0">Table B</ref>.2 summarizes these differences.</p><p>The visual characteristics of the z-slices are mostly invariant, and we observed a high correlation between adjacent z-slices; therefore, the 2D and 2.5D models take 2D cuts in the XY plane, as in <ref type="figure" target="#fig_0">Fig. 1 Fig. A.7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>In this section we present a compilation of qualitative and quantitative results obtained. The segmentations from the three Modular U-Net versions presented in Section 2 are quantitatively compared, then an ablation analysis and the learning curve of the 2D model are presented. All the quantitative analyses were made on the test split (see Section 1), which contains 1300 ? 1040 ? 300 ? 406 ? 10 6 voxels. Other images and videos are provided along with further detailed analysis as supplementary material in the Appendix D. The trained models and the data used to produce our results are publicly available online <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>Qualitative results. <ref type="figure" target="#fig_0">Figure 1</ref> shows two snapshots of the segmentation generated with a 2D model. <ref type="figure" target="#fig_4">Figure 4</ref> shows the segmentation obtained with the 2D model from the crack volume, used evaluate its usability in terms of processing speed and applicability of the method to other data. The segmented data was then used to generate a surface of the crack inside it 4we refer to it as the "crack" volume in the next section. Using an NVIDIA Quadro P2000 5 (5 GB), it took 32 minutes to process a 1579 ? 1845 ? 2002 (? 5800 Mvoxels) volume. This shows that this type of analysis could carried out almost in real time using typical hardware available at a synchrotron beamline.</p><p>Baseline. For the sake of comparison, we considered the expected performance of two theoretical models: the Zero th Order Classifier (ZeroOC) and the Bin-wise ZeroOC. The ZeroOC relies only on the class imbalance, while Bin-ZeroOC takes the individual gray values into consideration, leveraging information from the histograms of each class <ref type="figure" target="#fig_9">(Fig. A.8</ref>) -see <ref type="table" target="#tab_0">Table D</ref>.4 for more details.</p><p>Quantitative results. <ref type="figure" target="#fig_5">Figure 5</ref> presents a comparison of the three model variations (2D, 2.5D, and 3D) and an ablation study of the 2D model in terms of number of parameters and performance. The three variations of the Modular U-Net are evaluated with varying sizes. The models are scaled with the hyperparameter f 0 (values inside the parentheses in <ref type="figure" target="#fig_5">Fig. 5a</ref>). The performance is measured using the Jaccard index, also known as Intersection over Union (IoU), on each phase (class). Our main metric is the arithmetic mean of the three class-wise indices, and the baseline (minimum) is 76.2% <ref type="table" target="#tab_0">(Table D.</ref> <ref type="bibr" target="#b3">4)</ref>. This metric provides a good visibility of the performance differences and resumes the precision-recall trade off; other classic metrics -even the area under the ROC <ref type="bibr" target="#b30">[31]</ref> curve -are close to 100% (see Appendix D), so the differences are hard to compare.</p><p>Ablation study. <ref type="figure" target="#fig_5">Figure 5b</ref> is a component ablation analysis of the 2D model with f 0 = 16 . Starting with the 2D model with the default hyperparameters (see <ref type="figure" target="#fig_3">Fig. 3</ref>, and Section Appendix B), we retrained other models removing one component at a time. The learnable up/down-samplings were replaced by "rigid" ones (see <ref type="figure" target="#fig_3">Fig. 3</ref>), the 2D convolutions were replaced by separable ones, and the batch normalization was replaced by layer normalization. Finally, we varied the U-depth from 2 to 4. Notice that the model without dropout performed better than the reference model, but we kept it in our default parameters because the same thing did not occur with other variations and sizes.</p><p>Learning curve. Finally, we computed the learning curve of the 2D model ( <ref type="figure" target="#fig_6">Fig. 6</ref>) logarithmically reducing the size of the train dataset from 1024  <ref type="figure" target="#fig_3">(Fig. 3)</ref>, and batch normalization by layer normalization. We also compare the effect of the U-depth, i.e. number of levels in the U structure. Notice that the data point of the batch normalization removal is out of scale in the y-axis for the sake of visualization. z-slices until a single layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Overview</head><p>Our models, trained in one to three hours 6 , achieved, qualitatively, very satisfactory results from a Materials Science application point of view, with 87% of mean class-wise Jaccard index and an F1-score macro average of 92.4% <ref type="table" target="#tab_0">(Table D.</ref> <ref type="bibr" target="#b4">5)</ref>. We stress the fact that these results were achieved without any strategy to compensate the (heavy) class imbalance (82.3% of the voxels belong to the class matrix); they may be further improved using, for instance, re-sampling strategies <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>, class-balanced loss functions <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>, or self-supervised pre-training <ref type="bibr" target="#b35">[36]</ref>.</p><p>The results obtained with another specimen (the crack volume), thus with slight variations in the acquisition conditions, were of good quality (inspection by an expert showed no visible error in the segmentation) and way faster than the manual process. The crack was mostly, and correctly, segmented as porosity without retraining the model, showing its capacity to generalize -an important feature for its practical use, although some misclassified regions can be seen as holes (missing pieces) in the fracture's surface <ref type="figure" target="#fig_4">(Fig. 4a)</ref>.</p><p>Moreover, the processing time achieved (32 miutes) is indeed a promising prospect compared to classic approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Segmentation errors</head><p>As highlighted in <ref type="figure" target="#fig_0">Fig. 1</ref>, the model's mistakes (in red), are mostly on the interfaces of the phases, which are fairly comparable to a human annotator's. We (informally) estimate that they are in the error margin because, in some regions, there is no clear definition of the phases' limits. The fibers may show smooth, blurred phase boundaries with the matrix, while part of the porosities are under the image resolution.</p><p>Another issue is the loss of information (all-zero regions) in some rings (e.g.: <ref type="figure" target="#fig_8">Fig. A.7b</ref>). In such cases, even though one could deduce that there is indeed a porosity, it is practically impossible to draw a well-defined porosity/matrix interface.</p><p>Finally, we reiterate that the ground truth remains slightly imperfect despite our efforts to mitigate these issues. For instance, in <ref type="figure" target="#fig_0">Figure 1</ref> we see, inside the C-like shaped porosity, a blue region, meaning that it was "correctly" segmented as a fiber -yet, there is no fiber in it. <ref type="figure" target="#fig_12">Figures D.9</ref> and 6 confirm that, no matter the model variation, the porosity is harder to detect. Although, the qualitative results are reasonable, and we underline that the Jaccard index is more sensitive on underrepresented classes because the size of the union will always be smaller (see Equation C.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Model variations</head><p>Contrarily to our expectations, <ref type="figure" target="#fig_5">Figure 5a</ref> shows that the 2D model performed systematically better than the 3D (albeit the difference is admittedly small). We expected the 3D model to perform better because the morphology of the objects in the image are naturally three-dimensional; besides, other work <ref type="bibr" target="#b22">[23]</ref> have obtained better results in binary segmentation problems. We raise two hypotheses about this result: (1) the set of hyperparameters is not optimal, and (2) the performance metric is biased because the annotation process uses a 2D algorithm. <ref type="figure" target="#fig_5">Figure 5b</ref> contains a few interesting findings about the hyperparameters of the Modular U-Net:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Model ablation</head><p>1. using learnable up/down-sampling operations indeed gives more flexibility to the model, improving its performance compared to "rigid" (not learnable) operations; 2. separable convolutions slightly hurt the performance, but it reduces the number of parameters by 60%; 3. decreasing the U-depth, therefore shrinking the receptive field, improved the performance while reducing 75% of the model size; on the other hand, increasing the depth had the opposite effect, multiplying the model size by four, while degrading the performance; 4. batch normalization is essential for the training -notice that the version without batch normalization is out of scale in <ref type="figure" target="#fig_5">Fig. 5b</ref>, and its performance corresponds to the ZeroOC model <ref type="table" target="#tab_0">(Table D.</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4);</head><p>Model depth (item 3). This finding gives a valuable information for our future work because using shallower models require less memory (i.e.: bigger crops can be processed at once), making it possible to accelerate the processing time. We hypothesize that the necessary receptive field is smaller than the depth-three model's. Therefore, a spatially bigger input captures irrelevant, spurious context to the classification. <ref type="figure" target="#fig_6">Figure 6</ref> highlights the most promising finding in our results. Our model was capable of learning with only 1% of the training dataset (about ten z-slices) even with no "smart" strategy to select the layers in the experiment (the training volume was sequentially reduced along the z-axis), and even a single layer was sufficient to achieve nearly the same performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Learning curve</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>An annotated dataset of a three-phase composite material was presented, and a reinterpretation of the U-Net architecture as a modularized structure was proposed as a solution to scale up the segmentation of such images. Our models achieved satisfactory results showing a promising venue to automate processing pipelines of XCTs of this material with only a few annotated tomography slices. The Modular U-Net is a conceptually more compact interpretation of its precursor, providing a more abstract representation of this family of network architectures.</p><p>2D and 3D versions of the Modular U-Net were compared, showing that both were capable of learning the patterns in a human-made annotation, but the former was systematically better than the latter. An ablation study provided insights about the hyperparameters of our architecture, especially revealing that we might further accelerate the processing with smaller models. We also qualitatively analyzed the usability of our models on an image of a different specimen, confirming that it is a viable solution.</p><p>Our code is available on GitHub 7 , and the data and trained models referred here are publicly available on Zenodo <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Future work</head><p>Carrying on the encouraging results found in this work, we envision scaling up the use of our models to process other volumes and 4D X-ray Computed Tomographys (XCTs). We also plan identifying better strategies to deal with ill-defined regions (e.g.: matrix/fiber blurred interfaces), an issue modestly mitigated in our work, to improve our approach's usability. Two possibilities are considered: (1) post-processing the class probabilities to detect bad predictions, for instance using the method proposed by <ref type="bibr" target="#b36">[37]</ref>; (2) define a special class for uncertain regions. Finally, we might as well search for better ways to measure a prediction's consistency with respect to the objects' 3D morphology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgement</head><p>Jo?o P C Bertoldo would like to acknowledge funding from the BIG-M?CA research initiative <ref type="bibr" target="#b7">8</ref>   Data annotation step 2: artifacts correction. We separated 2D blobs (connected components) in the porosity phase, then extracted region properties (e.g.area, aspect ratio, etc) to find outliers -mostly, porosities significantly larger than the average. Using Avizo, we then corrected imperfections manually editing the annotation. Most problematic regions were on pronounced rings, where it is hard to define the borders of a porosity (e.g.: <ref type="figure" target="#fig_8">Fig. A.7)</ref>, so we cleaned ill-defined porosities conservatively shrinking their volume/borders based on the layers above and below.</p><p>Appendix A.2. Ground truth analysis Class-wise histogram. <ref type="figure" target="#fig_9">Figure A.8</ref> shows a normalized gray level histogram per class (the normalization is relative to all the classes confounded). Using a threshold approach is naturally prone to imprecise results because a voxel's gray value is insufficient to determine its class. This illustrates how this volume cannot be segmented using a threshold. An example can be seen in <ref type="figure" target="#fig_8">Fig. A.7b</ref>, where the rings are as dark as the porosities. idation, test) together (1900 z-slices), while the volumes (c) and (d) correspond to their last 300 z-slices. The values in the segmentation volumes (predictions and ground truth) are 0, 1, and 2, which respectively correspond to the phases matrix, fiber, and porosity. The volumes (e) and (f) correspond to the volume in <ref type="figure" target="#fig_4">Fig. 4</ref>. The .raw files have complementary .raw.info files containing metadata (volume dimensions and data type) about its respective volume. crack.prediction.raw (f) Segmentation generated with the best 2D model on the crack volume. <ref type="figure" target="#fig_8">Figure A.7</ref> was generated in Fiji <ref type="bibr" target="#b24">[25]</ref> with the volume (a). <ref type="figure" target="#fig_0">Figure 1</ref> was generated in Avizo with volumes (a) and (d), which is derived from volumes (b) and (c). <ref type="figure" target="#fig_4">Figure 4b</ref> was generated in Avizo with volumes (e) and (f). All the supplementary videos were generated in Avizo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Default hyperparameters</head><p>Parameters not mentioned are the default in TensorFlow 2.2.0. <ref type="table" target="#tab_0">Table B</ref>.2: Modular U-Net variations: input, convolutional layer, and output nature (2D or 3D).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Input (data) Convolution Output (segm.)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2D</head><p>2D </p><formula xml:id="formula_0">2D 2D 2.5D 3D 2D 2D 3D 3D 3D 3D</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C. Training</head><p>Loss function. We trained our models using a custom loss inspired on the Jaccard index, also known as Intersection over Union (IoU).</p><p>Def. 1. Let A and B be two discrete sets. The Jaccard index J ? [0, 1] is</p><formula xml:id="formula_1">J(A, B) = |A ? B| |A ? B| = |A ? B| |A| + |B| ? |A ? B| (C.1)</formula><p>We adapt, similarly to <ref type="bibr" target="#b40">[41]</ref>, the second form in Equation C.1 to define the multi-class Jaccard 2 loss for a batch of voxels (a batch of 2D or 3D images unraveled on the spatial dimensions) as follows. </p><formula xml:id="formula_2">= 1 ? ? N i=1 ? C c=1 y ic?ic ? N i=1 ? C c=1 y ic y ic + ? N i=1 ? C c=1? ic?ic ? ? N i=1 ? C c=1 y ic?ic (C.2) = 1 ? ? N i=1? i * N + ? N i=1 ? C c=1? 2 ic ?? i * (C.3)</formula><p>where? i * = ? C c=1 y ic?ic is the probability assigned to the correct class of the voxel i.</p><p>Notice that the J2 ? [0, 1], which is convenient because it can be expressed as a percentage. J2 = 100% is a completely uncorrelated estimation, and J2 = 0% is a perfect replication of the ground truth.</p><p>Optimizer and Learning Rate. We used AdaBelief <ref type="bibr" target="#b41">[42]</ref>, an optimizer that combines the training stability and fast convergence of adaptive optimizers (e.g.: Adam <ref type="bibr" target="#b42">[43]</ref>) and good generalization capabilities of accelerated schemes (e.g.: Stochastic Gradient Descent (SGD) <ref type="bibr" target="#b43">[44]</ref>). We used a learning rate of 10 ?3 for 100 epochs (10 batches each with batch size 10), followed by a linearly decaying rate until 10 ?4 in another 100 epochs. Adam gave equivalent results but took longer (more epochs) to converge.</p><p>Data augmentation. In order to increase the variability of the data, random crops are selected from the data volume, then a random geometric transformation (flip, 90?rotation, transposition, etc) is applied. As our training dataset is reasonably large, we used a simple data augmentation scheme, but richer transformations may be applied as long as the transformations result in credible samples.</p><p>Implementation and hardware. We trained our models using Keras <ref type="bibr" target="#b44">[45]</ref> with TensorFlow's <ref type="bibr" target="#b11">[12]</ref> GPU-enabled version 10 with CUDA 10.1 running on two NVIDIA Quadro P4000 11 (2x 8 GB). The implementation of our experiments is available on GitHub 12 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D. Further results</head><p>In this section we present complementary performance metrics, images, and videos from the segmentation generated by the 2D model (see Section 2) using our default hyperparameters (Appendix B) on the test split. Videos are available as supplementary material <ref type="bibr" target="#b12">13</ref> . <ref type="table" target="#tab_0">Table D</ref>.4 presents the expected performances of the two baseline models we considered (Section 3).  <ref type="table" target="#tab_0">Table D</ref>.5 shows a report with classic classification metrics and the Jaccard index by class along with their macro/micro averages. As one can see, the accuracy, precision, and recall of the matrix and the fiber are all close to 100%, while the porosity's scores are considerably lower.  <ref type="figure">Figure D</ref>.9 shows that, as the matrix and the fiber phases have high scores, the mean Jaccard index is driven by the performance on the porosity detection, which can also seen in <ref type="figure" target="#fig_6">Fig. 6</ref>. Recall that the baseline model Bin-ZeroOC is expected to have a Jaccard index of 35% on the porosity and 76.2% of mean <ref type="table" target="#tab_0">(Table D.</ref>   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Segmentation on the test set. Color code: blue represents voxels correctly classified as fiber (hatched), yellow as porosity (contours), and red represents misclassification. Supplementary video: youtu.be/HvdWhDZJgLE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2 2 x f 0 Figure 2 :</head><label>02</label><figDesc>Modular U-Net: a generalization of the U-Net architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Examples of Modular U-Net blocks. Left: our ConvBlock. Middle/right: rigid/learnable DownBlock and UpBlock.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Segmentation of the volume crack. Color code: blue represents the fiber and yellow represents the porosity. Supplementary video: youtu.be/rmBTZrcMrCk. (a) Two orthogonal planes inside the specimen; the fibers are rendered in 3D at the bottom of the volume, and the crack is rendered as a surface. (b) A crop from the vertical plane in a slice passing through the fracture. The fiber segmentation is hatched in blue and the porosity segmentation is contoured in yellow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Modular U-Net variations comparison. On the x-axis, the number of parameters; on the yaxis the mean class-wise Jaccard indices. (a) The Modular U-Net 2D, 2.5D, and 3D versions are scaled with f 0 (in parentheses), the number of filters of the first convolution of the first ConvBlock. (b) Components were removed individually, or replaced by alternatives. Removals: dropout, gaussian noise, residual (skip connection), batch normalization (out of scale). Replacements: convolutions by separable ones, learnable DownBlock/UpBlock by rigid ones</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Learning curve of the 2D model with default hyperparameters (Appendix B).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>, funded by Safran and MINES ParisTech. Henry Proudhon would like to acknowledge beam time allocation at the Psich? beamline of Synchrotron SOLEIL 9 for the proposal number 20150371. Appendix A. Data: further details (a) A 1300 ? 1040 slice on the XY plane of the volume Train-Val-Test. On the upper left corner, a histogram of the gray level values in the image; linear scale in black, log scale in gray.(b) Zoom. Ring artifacts, from the acquisition process, can be as dark as porosities, making it harder to segment such regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure A. 7 :</head><label>7</label><figDesc>Glass fiber-reinforced Polyamide 66 raw tomography. Supplementary video: youtu.be/ 4kifxlvxzb8.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure A. 8 :</head><label>8</label><figDesc>Glass fiber-reinforced Polyamide 66 gray value (normalized) histograms (one per class). The histogram is normalized globally, i.e. a bin's value is the proportion of voxels out of all the voxels (all classes confounded). The superposition of the classes' value ranges make it impossible to segment the image with a threshold on the gray values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Def. 2 .</head><label>2</label><figDesc>Let y i ? {0, 1} C be the one-hot-encoding ground truth vector of the voxel at position i ? B in a batch of B voxels y ? {0, 1} B?C , where y ic ? {0, 1} is its value in the c-th position. y ic = 1, if the voxel i belongs to the class c ? C 0 otherwise A model's last activation map, a per-voxel softmax, is a tensor? ? [0, 1] B?C , where each row is a probability vector? i ? [0, 1] C , and the component? ic corresponds to the probability assigned to the class c . The Jaccard 2 loss J2 ? [0, 1] of the batch (y,?) is J2(y,?)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>4).Figure D.10 presents detailed confusion matrices. The top one is expressed percentage of the number of voxel counts. The two bottom ones are normalized, respectively, by row and column, and their diagonals correspond to the recall and the precision of each class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure D. 9 :</head><label>9</label><figDesc>Class-wise Jaccard index Modular U-Net 2D, 2.5D, and 2D variations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure D. 10 :</head><label>10</label><figDesc>Confusion matrices of the 2D model on the test set normalized in three different ways.(top) Normalized by the sum of all cells confounded. (bottom left) Normalized by the sum of ground truth labels (a.k.a. support) of each class (each line sums up to 100%); the diagonal corresponds to the recall values. (bottom right) Normalized by the sum of predicted labels of each class (each column sums up to 100%); the diagonal corresponds to the precision values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table A .</head><label>A</label><figDesc>1: Published 3D volumes: all the data necessary to train and test the models presented in this paper are publicly available on Zenodo<ref type="bibr" target="#b25">[26]</ref>. A demo of how to read the data is available on GitHub.</figDesc><table><row><cell>.zip file</cell><cell>.raw file</cell><cell>Description</cell></row><row><cell>pa66.zip</cell><cell>pa66.raw (a) pa66.ground_truth.raw (b)</cell><cell>Data (gray level image stack) of the Train-Val-Test volume. Ground truth segmentation of the Train-Val-Test volume.</cell></row><row><cell>pa66_test.zip</cell><cell>pa66.test.prediction.raw (c) pa66.test.error_volume.raw (d)</cell><cell>Segmentation generated by the best 2D model on the test set. Disagreement between the ground truth and the model's prediction</cell></row><row><cell></cell><cell></cell><cell>on the test set: 1 means incorrect, 0 means correct.</cell></row><row><cell>crack.zip</cell><cell>crack.raw (e)</cell><cell>Data of the non-annotated volume containing a crack inside.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table B</head><label>B</label><figDesc></figDesc><table><row><cell cols="3">.3: Default hyperparameters.</cell><cell></cell></row><row><cell>Parameter</cell><cell>2D</cell><cell>2.5D</cell><cell>3D</cell></row><row><cell>U-depth</cell><cell>3</cell><cell>3</cell><cell>3</cell></row><row><cell>Convolution kernel</cell><cell>3 ? 3</cell><cell>3 ? 3</cell><cell>3 ? 3 ? 3</cell></row><row><cell>Batch size</cell><cell>10</cell><cell>10</cell><cell>10</cell></row><row><cell>Crop shape</cell><cell cols="3">160 ? 160 160 ? 160 ? 5 32 ? 32 ? 32</cell></row><row><cell>Dropout</cell><cell>10%</cell><cell>10%</cell><cell>10%</cell></row><row><cell>Gaussian noise (zero mean)</cell><cell>0.03</cell><cell>0.03</cell><cell>0.03</cell></row><row><cell>standard deviation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>f0</cell><cell>16</cell><cell>16</cell><cell>16</cell></row><row><cell>Up/Down-sampling stride</cell><cell>2 ? 2</cell><cell>2 ? 2</cell><cell>2 ? 2 ? 2</cell></row><row><cell>or Max pooling size</cell><cell></cell><cell></cell><cell></cell></row><row><cell>BatchNorm momentum</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table D .</head><label>D</label><figDesc>4: Expected performance of baseline theoretical models in terms of class-wise Jaccard index (%).</figDesc><table><row><cell>Model</cell><cell>Description</cell><cell cols="4">Matrix Fiber Porosity Mean</cell></row><row><cell>ZeroOC</cell><cell>Classify every voxel with the major-</cell><cell>81.0</cell><cell>0</cell><cell>0</cell><cell>27.0</cell></row><row><cell></cell><cell>ity class (matrix).</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Bin-ZeroOC Classify a voxel based only on its</cell><cell>98.4</cell><cell>94.2</cell><cell>35.9</cell><cell>76.2</cell></row><row><cell></cell><cell>value. The majority class of each</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>value is chosen. This is equivalent</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>to a ZeroOC model per gray level.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table D .</head><label>D</label><figDesc>5: 2D Modular U-Net ( f 0 = 16 ) classification report.</figDesc><table><row><cell>class</cell><cell cols="5">accuracy (%) precision (%) recall (%) f1 (%) jaccard (%)</cell><cell>support</cell></row><row><cell>matrix</cell><cell>99.0</cell><cell>99.3</cell><cell>99.4</cell><cell>99.4</cell><cell>98.8</cell><cell>334.4 million</cell></row><row><cell>fiber</cell><cell>99.2</cell><cell>97.7</cell><cell>97.6</cell><cell>97.6</cell><cell>95.3</cell><cell>69.1 million</cell></row><row><cell>porosity</cell><cell>99.8</cell><cell>84.2</cell><cell>76.5</cell><cell>80.2</cell><cell>66.9</cell><cell>2.1 million</cell></row><row><cell>macro avg.</cell><cell>99.3</cell><cell>93.7</cell><cell>91.2</cell><cell>92.4</cell><cell>87.0</cell><cell>-</cell></row><row><cell>micro avg.</cell><cell>99.0</cell><cell>99.0</cell><cell>99.0</cell><cell>99.0</cell><cell>-</cell><cell>-</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">thermofisher.com 3 volumegraphics.com/en/products/vgstudio-max.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">youtu.be/rmBTZrcMrCk 5 pny.com/nvidia-quadro-p2000</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Up to eight hours for the largest 3D model.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">github.com/joaopcbertoldo/tomo2seg</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">https://bigmeca.minesparis.psl.eu/ 9 https://www.synchrotron-soleil.fr/fr</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">tensorflow-gpu on PyPi 11 pny.com/nvidia-quadro-p4000 12 github.com/joaopcbertoldo/tomo2seg</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">youtu.be/HvdWhDZJgLE, youtu.be/dXlYcLXHFAA, youtu.be/CjwG-1FoSCY</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix A. <ref type="bibr" target="#b0">1</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. Data annotation</head><p>We annotated the data in two phases. First, the fiber and the porosity were separated from the matrix independently using Seeded Region Growing <ref type="bibr" target="#b28">[29]</ref>. As the results carried a considerable amount of artifacts in the porosity phase, we manually corrected them with a second procedure.</p><p>Data annotation step 1: Seeded Region Growing <ref type="bibr" target="#b28">[29]</ref>. To generate the seeds, we applied contrast and brightness transformations to enhance the information on the phase of interest, then applied Non-Local Means <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref> to attenuate the ring artifacts, and finally used manual thresholds to select "easy" voxels (mostly, regions without class superposition in <ref type="figure">Fig. A.8</ref>). Finally, we run it on each tomography z-slice independently.</p><p>We observed that some regions were poorly segmented due to the ring artifacts, creating false, larger porosities. To mitigate this issue, we manually corrected part of the artifacts, reducing their size while keeping it consistent with adjacent z-slices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A.3. Data availability</head><p>The volumes mentioned here <ref type="table">(Table A.</ref>1) are available on Zenodo <ref type="bibr" target="#b39">[40]</ref>. Notice that the volumes (a) and (b) contain all the three splits (train, val-</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">X-ray computed tomography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Withers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Methods Primers</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Quantitative x-ray tomography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Withers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Materials Reviews</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An upgrade to a bright future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pacchioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Physics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="100" to="101" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast synchrotron x-ray tomographic quantification of dendrite evolution during the solidification of mgsn alloys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shuai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Materialia</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="260" to="269" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">20 hz x-ray tomography during an in situ tensile test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Le Bourlot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Adrien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mortensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mokso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Fracture</title>
		<imprint>
			<biblScope unit="volume">200</biblScope>
			<biblScope unit="page" from="3" to="12" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automated correlative segmentation of large Transmission X-ray Microscopy (TXM) tomograms using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shashank Kaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Materials Characterization</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page" from="203" to="210" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semantic segmentation of synchrotron tomography of multiphase Al-Si alloys using a convolutional neural network with a pixel-wise weighted loss function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Strohmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hierarchical Segmentation and Waterfall Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Beucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Watershed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Morphology and Its Applications to Image Processing</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Use of Watersheds in Contour Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lantuejoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Image Processing : Real-time Edge and Motion Detection/Estimation</title>
		<meeting><address><addrLine>Rennes, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The perceptron: a probabilistic model for information storage and organization in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="386" to="408" />
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Convolutional networks for images, speech, and time-series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/.Soft-wareavailablefromtensorflow.org" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fully Convolutional Networks for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.4038</idno>
		<idno>1411.4038. ArXiv: 1411.4038</idno>
		<ptr target="http://arxiv.org/abs/" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimizing convolutional neural networks to perform semantic segmentation on large materials imaging datasets: X-ray tomography and serial sectioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Stan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zachary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Materials Characterization</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page">110119</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TPAMI.2016.2644615</idno>
		<idno>arxiv: 1511.00561</idno>
	</analytic>
	<monogr>
		<title level="m">Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>U-Net</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.04597</idno>
		<idno>1505.04597</idno>
		<title level="m">Convolutional Networks for Biomedical Image Segmentation</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning Dense Volumetric Segmentation from Sparse Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>?i?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brox &amp;amp; Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>3d U-Net</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention (MICCAI)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">U 2 -Net: Going Deeper with Nested U-Structure for Salient Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaiane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Osmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jagersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">9007</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M R</forename><surname>Siddiquee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Unet++</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.10165</idno>
		<idno>1807.10165. ArXiv: 1807.10165</idno>
		<ptr target="http://arxiv.org/abs/" />
		<title level="m">A Nested U-Net Architecture for Medical Image Segmentation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>cs, eess, stat]</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Oktay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03999</idno>
		<idno>1804.03999</idno>
		<title level="m">Attention U-Net: Learning Where to Look for the Pancreas</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stoller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ewert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wave-U-Net</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.03185</idno>
		<idno>1806.03185</idno>
		<title level="m">A Multi-Scale Neural Network for End-to-End Audio Source Separation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>cs, eess, stat</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Road Extraction by Deep Residual U-Net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="749" to="753" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Machine Learning Techniques for the Segmentation of Tomographic Image Data of Functional Materials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Furat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Materials</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">NIH Image to ImageJ: 25 years of image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Rasband</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eliceiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="671" to="675" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fiji: An open-source platform for biological-image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schindelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="676" to="682" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Glass fiber-reinforced polyamide 66 3D X-ray computed tomography dataset for deep learning segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bertoldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Decenci?re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ryckelynck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Proudhon</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4587827</idno>
		<ptr target="https://doi.org/10.5281/zenodo.4587827" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The pyhst2 hybrid distributed code for high speed tomographic reconstruction with iterative reconstruction and a priori knowledge capabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mirone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gouillart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tafforeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kieffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
	<note>1st International Conference on Tomography of Materials and Structures</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simultaneous phase and amplitude extraction from a single defocused image of a homogeneous object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Paganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Mayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Gureyev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Wilkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Microscopy</title>
		<imprint>
			<biblScope unit="volume">206</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Seeded region growing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="641" to="647" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Glass fiber-reinforced polyamide 66 3D X-ray computed tomography segmentation segmentation U-Nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bertoldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Decenci?re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ryckelynck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Proudhon</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4601560</idno>
		<ptr target="https://doi.org/10.5281/zenodo.4601560" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The meaning and use of the area under a receiver operating characteristic (ROC) curve</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Mcneil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="29" to="36" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamic Sampling in Convolutional Neural Networks for Imbalanced Data Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pouyanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="112" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep Over-sampling Framework for Classifying Imbalanced Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<editor>Ceci, M., Hollm?n, J., Todorovski, L., Vens, C. &amp; D?eroski, S.</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="770" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07413</idno>
		<idno>1906.07413</idno>
		<title level="m">Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.07590</idno>
		<idno>1901.07590</idno>
		<title level="m">Striking the Right Balance with Uncertainty</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Rethinking the Value of Labels for Improving Class-Imbalanced Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07529</idno>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7529</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Energy-based Out-ofdistribution Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.03759[cs](2020).2010.03759</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Non-Local Means Denoising. Image Processing On Line</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="208" to="212" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fast nonlocal filtering applied to electron cryomicroscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Darbon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cunha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th IEEE International Symposium on Biomedical Imaging: From Nano to Macro</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1331" to="1334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title/>
		<ptr target="https://www.zenodo.org/" />
	</analytic>
	<monogr>
		<title level="j">European Organization For Nuclear Research &amp; OpenAIRE. Zenodo</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On power Jaccard losses for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duque-Arias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VISAPP 2021 : 16th International Conference on Computer Vision Theory and Applications</title>
		<meeting><address><addrLine>Vienne; Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>on line</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhuang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.07468[cs,stat](2020).2010.07468</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<idno>1412.6980</idno>
		<title level="m">A Method for Stochastic Optimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A stochastic approximation method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="400" to="407" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
