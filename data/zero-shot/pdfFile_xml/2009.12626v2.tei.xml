<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DWIE: an entity-centric dataset for multi-task document-level information extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klim</forename><surname>Zaporojets</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Ghent University -imec</orgName>
								<address>
									<addrLine>Technologiepark Zwijnaarde 15</addrLine>
									<postCode>9052</postCode>
									<settlement>IDLab, Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Deleu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Ghent University -imec</orgName>
								<address>
									<addrLine>Technologiepark Zwijnaarde 15</addrLine>
									<postCode>9052</postCode>
									<settlement>IDLab, Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Develder</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Ghent University -imec</orgName>
								<address>
									<addrLine>Technologiepark Zwijnaarde 15</addrLine>
									<postCode>9052</postCode>
									<settlement>IDLab, Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Ghent University -imec</orgName>
								<address>
									<addrLine>Technologiepark Zwijnaarde 15</addrLine>
									<postCode>9052</postCode>
									<settlement>IDLab, Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DWIE: an entity-centric dataset for multi-task document-level information extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Named Entity Recognition</term>
					<term>Entity Linking</term>
					<term>Relation Extraction</term>
					<term>Coreference Resolution</term>
					<term>Joint Models</term>
					<term>Graph Neural Networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents DWIE, the 'Deutsche Welle corpus for Information Extraction', a newly created multitask dataset that combines four main Information Extraction (IE) annotation subtasks: (i) Named Entity Recognition (NER), (ii) Coreference Resolution, (iii) Relation Extraction (RE), and (iv) Entity Linking. DWIE is conceived as an entity-centric dataset that describes interactions and properties of conceptual entities on the level of the complete document. This contrasts with currently dominant mention-driven approaches that start from the detection and classification of named entity mentions in individual sentences. Further, DWIE presented two main challenges when building and evaluating IE models for it. First, the use of traditional mention-level evaluation metrics for NER and RE tasks on entity-centric DWIE dataset can result in measurements dominated by predictions on more frequently mentioned entities. We tackle this issue by proposing a new entity-driven metric that takes into account the number of mentions that compose each of the predicted and ground truth entities. Second, the document-level multi-task annotations require the models to transfer information between entity mentions located in different parts of the document, as well as between different tasks, in a joint learning setting. To realize this, we propose to use graph-based neural message passing techniques between document-level mention spans. Our experiments show an improvement of up to 5.5 F 1 percentage points when incorporating neural graph propagation into our joint model. This demonstrates DWIE's potential to stimulate further research in graph neural networks for representation learning in multi-task IE. We make DWIE publicly available at https://github.com/klimzaporojets/DWIE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Information Extraction (IE) plays a fundamental role as a backbone component in many downstream applications. For example, an application such as question answering may be improved by relying on relation extraction (RE) <ref type="bibr" target="#b35">(Hu et al., 2019;</ref><ref type="bibr" target="#b90">Yu et al., 2017)</ref>, coreference resolution <ref type="bibr" target="#b10">(Bhattacharjee et al., 2020;</ref><ref type="bibr" target="#b28">Gao et al., 2019)</ref>, named entity recognition (NER) <ref type="bibr" target="#b59">(Molla et al., 2006;</ref><ref type="bibr" target="#b71">Singh et al., 2018)</ref>, and entity linking (EL) <ref type="bibr" target="#b11">(Broscheit, 2019;</ref><ref type="bibr" target="#b12">Chen et al., 2017)</ref> components. This also holds for other applications such as personalized news recommendation <ref type="bibr" target="#b41">(Karimi et al., 2018;</ref><ref type="bibr" target="#b79">Wang et al., 2018</ref><ref type="bibr" target="#b80">Wang et al., , 2019</ref>, fact checking <ref type="bibr" target="#b76">(Thorne &amp; Vlachos, 2018;</ref><ref type="bibr" target="#b92">Zhang &amp; Ghorbani, 2020)</ref>, opinion mining <ref type="bibr" target="#b75">(Sun et al., 2017)</ref>, semantic search <ref type="bibr" target="#b15">(Cifariello et al., 2019)</ref>, and conversational agents <ref type="bibr" target="#b67">(Roller et al., 2020)</ref>. The last decade has shown a growing interest in IE datasets suitably annotated for developing multi-task models where each of the tasks (e.g., NER, RE, etc.) would <ref type="figure">Figure 1</ref>: An example from the DWIE dataset with entity mentions underlined. We show 8 of the 29 entities in the graph on the right. It illustrates the relations that can be derived from the content of the article. The relations that are explicitly mentioned in the text (trigger-based) are depicted by solid arrows. Conversely, the relations that are implicit and/or need the whole document context (document-based) to be derived are represented by dashed arrows.</p><p>benefit from the interaction with (an)other task(s) <ref type="bibr" target="#b8">(Bekoulis et al., 2018b;</ref><ref type="bibr" target="#b26">Fei et al., 2020;</ref><ref type="bibr" target="#b48">Lee et al., 2017</ref><ref type="bibr" target="#b49">Lee et al., , 2018</ref><ref type="bibr" target="#b55">Luan et al., 2019)</ref>, to boost their performance. However, the currently widely used IE datasets to build such multi-task models exhibit three major limitations. First, the annotation schema adopted in most of these datasets is mention-driven, focusing on annotating elements (e.g., relations, entity types) that involve specific entity mentions explicitly mentioned in the text. This produces very localized annotations (e.g., sentence-based relations between entity mentions) that do not reflect meaning that can be inferred on a more general document-level. Second, the number of annotated extraction tasks in most of the IE datasets is rather limited. Most of them focus on a single or at most a few different tasks. Furthermore, some other datasets, including the well-known TAC-KBPs <ref type="bibr" target="#b37">Ji et al., 2010</ref><ref type="bibr" target="#b38">Ji et al., , 2015</ref><ref type="bibr" target="#b39">Ji et al., , 2017</ref>, use different non-overlapping corpora for each of the tracks that group a few related tasks. Consequently, current models addressing multiple IE tasks together often use multi-tasking (with different datasets per task) rather than really joint modeling approaches. Finally, the annotation of currently widely used IE datasets is driven by either relying on a priori defined annotation schemas <ref type="bibr" target="#b3">(Augenstein et al., 2017;</ref><ref type="bibr" target="#b21">Doddington et al., 2004;</ref><ref type="bibr" target="#b32">Hendrickx et al., 2010;</ref><ref type="bibr" target="#b73">Song et al., 2015;</ref><ref type="bibr" target="#b78">Walker et al., 2006;</ref><ref type="bibr" target="#b94">Zhang et al., 2017b)</ref> or on distantly supervised labeling techniques <ref type="bibr" target="#b31">(Han et al., 2018;</ref><ref type="bibr" target="#b60">Peng et al., 2017;</ref><ref type="bibr" target="#b66">Riedel et al., 2010;</ref><ref type="bibr" target="#b89">Yao et al., 2019)</ref>. In consequence, the resulting annotations are not necessarily representative of the actual information contained in the annotated corpus.</p><p>In this work, we tackle the aforementioned limitations of IE datasets by introducing a new dataset named DWIE. It consists of 802 general news articles in English, selected randomly from a corpus collected from Deutsche Welle 2 between 2002 and 2018, as part of the CPN project. <ref type="bibr">3</ref> We focus on annotating four main IE tasks: (i) Named Entity Recognition (NER), (ii) Coreference Resolution, (iii) Relation Extraction (RE), and (iv) Entity Linking. 4 <ref type="figure">Figure 1</ref> shows an example snippet from the DWIE corpus. We adopt an entity-centric approach where all annotations (i.e., for NER, RE and Entity Linking tasks) are made on the entity 5 level. Each of the entities is composed by the coreferenced entity mentions from the entire document (e.g., the entity Meghan in <ref type="figure">Fig. 1</ref> clusters the entity mentions "Meghan Markle" and "Meghan" across the whole document). This entity-centric approach contrasts with mention-driven annotations in widely used IE datasets <ref type="bibr" target="#b21">(Doddington et al., 2004;</ref><ref type="bibr" target="#b31">Han et al., 2018;</ref><ref type="bibr" target="#b32">Hendrickx et al., 2010;</ref><ref type="bibr" target="#b38">Ji et al., 2015;</ref><ref type="bibr" target="#b53">Luan et al., 2018;</ref><ref type="bibr" target="#b73">Song et al., 2015;</ref><ref type="bibr" target="#b94">Zhang et al., 2017b)</ref> where the annotation process is biased towards considering only local explicit textual evidence to annotate elements such as relations and entity types (e.g., the relation spouse of Meghan, Harry that can be extracted from the 1st sentence in <ref type="figure">Fig. 1</ref>). Consequently, our DWIE dataset paves the way for research on more complex document-level reasoning that goes beyond only the local textual context directly surrounding individual entity mentions. For example, consider the relation ministry of Ministry of Defense, Britain in <ref type="figure">Fig. 1</ref>: while the text of the document does not directly state such a relation, it can be deduced from a more general document-level entity-centric vision of the article, i.e., combining the information involving the entities Ministry of Defense and Harry in sentence 7 with the one involving Britain and Harry in sentence 2. Finally, the entity-centric approach provides entity linking annotations that are consistent across the document: by clustering mentions of the same entity, and then providing links to the Wikidata KB (or NIL if the entity does not appear there) for the whole cluster at once, we limit annotation errors or accidental inconsistencies (in the linking itself, but also in terms of NER labels). To our knowledge, DWIE is the first dataset with this level of conceptual consistency over the considered information extraction tasks. We therefore expect that the dataset will play a key role in advancing research exploring potential benefits of (i) entity-level information extraction in terms of reducing potential inconsistent decisions (within EL across multiple mentions, as well as across multiple tasks), and (ii) using entity-centric information stored in a KB to complement the otherwise exclusively text-dependent IE tasks such as NER, RE, and coreference resolution.</p><p>Additionally, we use a bottom-up, data-driven annotation approach where we manually define our annotations (e.g., in terms of the entity and relation types) to maximally reflect the information of the corpus at hand. Currently dominant datasets are driven by distant supervision and executed top-down, by which we mean that the selection of entity and relation types is a priori defined and limited in coverage (i.e., the raw data potentially contains other types that thus remain un-annotated). Conversely, we do not a priori limit the entity and relation types to annotate, but adopt a bottom-up approach driven by the data itself. Our proposed bottom-up approach encompasses a three-pass annotation procedure where we use the first exploratory annotation pass to derive the main annotation types (annotation schema) from the corpus, and the next two passes to perform schema-driven annotations and refine them by carrying out an additional parallel annotation of the corpus for fixing errors inferred from inter-annotator inconsistencies.</p><p>Besides the dataset itself, we also contribute empirical modeling results to address the aforementioned IE tasks. Our goal is to study two important properties that are inherent to DWIE. The first key property is the need for long-range contextual information sharing to make document-level predictions involving entities whose mentions are located in different parts of the document. The second key property involves the joint interaction between tasks where the information obtained in one task can help to solve another task. For example, in <ref type="figure">Fig. 1</ref> knowing the types of entities (which involves NER and coreference tasks) Britain and Kensington Palace can boost the performance of the relation extraction task by limiting the number of possible relation types between these two entities (e.g., ministry of but not citizen of). In order to study the impact of these two phenomena inherent to our DWIE dataset on the final results, we experiment with neural graph-based models <ref type="bibr" target="#b52">(Li et al., 2016b;</ref><ref type="bibr" target="#b87">Wu et al., 2020;</ref><ref type="bibr" target="#b88">Xu et al., 2018)</ref>. These models allow message passing between local contextual encodings, making it possible to measure the impact of local contextual information sharing both on a more general document level and across the tasks. Furthermore, previous work already has shown the positive effect of using graph-based information passing techniques on single tasks <ref type="bibr" target="#b40">(Kantor &amp; Globerson, 2019;</ref><ref type="bibr" target="#b49">Lee et al., 2018)</ref>, and between tasks <ref type="bibr" target="#b26">(Fei et al., 2020;</ref><ref type="bibr" target="#b27">Fu et al., 2019;</ref><ref type="bibr" target="#b55">Luan et al., 2019;</ref><ref type="bibr" target="#b77">Wadden et al., 2019)</ref> on mention-driven datasets. We expand this work even further by extending these models to be used on the entity-centric, document-level DWIE dataset. More specifically, we experiment with both single-task (Section 4.5) as well as joint (Section 4.2) models to study the effect of contextual information propagation in single task and joint settings. Additionally, for the NER and RE tasks, we propose a new entity-centric evaluation metric that not only considers the predictions on separate entity mentions (as is done in related IE datasets), but also accounts for the impact of the predictions on entity cluster level.</p><p>In summary, the main objective that we address in the current paper is to introduce an entity-centric multi-task IE dataset that covers different related tasks on a document level as well as provides a connection with external structured knowledge (through the entity linking task). Furthermore, we aim to explore how neural graph-based models can boost the performance by enabling local contextual information propagation across the document (single-task models) and between different tasks (joint models). The results presented in this paper suggest that, while challenging, DWIE opens up new possibilities of research in the domain of joint entity-centric information extraction methods. The main contributions of our work are that:</p><p>(1) We construct a self-contained dataset (Section 3) with joint annotations for four basic information extraction tasks (NER, entity linking, coreference resolution, and RE), that provide entity-centric document-level annotations (as opposed to typical mention-driven sentence-level annotations for, e.g., RE) connecting unstructured (text) and structured (KB) information sources.</p><p>(2) We introduce a data-driven, bottom-up three-pass annotation approach complemented by contextbased logical rules to build such dataset (Section 3).</p><p>(3) We propose a new evaluation metric for the NER and RE tasks (Section 5), in line with the entitycentric nature of DWIE.</p><p>(4) We extend the competitive graph-based neural IE model DyGIE  for the four IE tasks in DWIE (Section 4) and provide source code for NER, coreference resolution, and RE. Furthermore, we introduce a new latent attention-driven AttProp graph propagation method and show its advantages in both single and joint model settings. The experimental results (Section 6) demonstrate the potential of such neural graph based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>This section summarizes the overview of related datasets (Section 2.1), and explores the differences between our newly created DWIE and other similar datasets widely used by the scientific community. The main qualitative differences are presented in <ref type="table" target="#tab_10">Table 1</ref>, while the quantitative comparison is provided in <ref type="table" target="#tab_0">Table 2</ref>. Next, we describe the current trends in IE to solve the tasks included in DWIE, and compare them to our proposed approach (Section 2.2). Finally, we discuss currently used metrics to evaluate model performance on IE datasets and introduce some challenges in applying them to measuring the performance on DWIE (Section 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Related Datasets</head><p>Most of IE datasets have focused on a single task, making it very challenging to develop systems that jointly train for different annotation subtasks on a single corpus. Well-known single-task datasets include (i) for NER: <ref type="bibr">CoNLL-2003</ref><ref type="bibr" target="#b68">(Sang &amp; De Meulder, 2003</ref> and WNUT 2017 <ref type="bibr" target="#b18">(Derczynski et al., 2017)</ref>, (ii) for relation extraction: Semeval-2010 T8 <ref type="bibr" target="#b32">(Hendrickx et al., 2010)</ref>, TACRED <ref type="bibr" target="#b94">(Zhang et al., 2017b)</ref> and FewRel <ref type="bibr" target="#b31">(Han et al., 2018)</ref>, (iii) for entity linking: IITB <ref type="bibr" target="#b45">(Kulkarni et al., 2009)</ref>, CoNLL-YAGO <ref type="bibr" target="#b33">(Hoffart et al., 2011)</ref>, and WikilinksNED <ref type="bibr" target="#b25">(Eshel et al., 2017)</ref>, and (iv) for coreference resolution: CoNLL-2012 <ref type="bibr" target="#b64">(Pradhan et al., 2012)</ref> and GAP <ref type="bibr" target="#b81">(Webster et al., 2018)</ref>. Conversely, in this work we propose a multi-task dataset as a single corpus annotated with different information extraction layers: named entities, mention clustering in entities (i.e., coreference), relations between entity clusters of mentions, and entity linking. We further complement our dataset with additional tasks such as document classification and keyword extraction. It is worth noting that our coreference annotations differ from the widely adopted CoNLL-2012 <ref type="bibr" target="#b64">(Pradhan et al., 2012)</ref> scheme in two aspects: (i) we retain singleton entities composed by only one mention as a valid entity cluster, (ii) we only cluster proper nouns, leaving out nominal and anaphoric expressions.</p><p>Furthermore, most prominent efforts to produce jointly annotated datasets have focused on using a topdown annotation approach. This method involves an a priori defined annotation schema that drives the process of selection and labeling of the corpus. The de facto datasets used in most of the joint learning baselines such as ACE 2005 <ref type="bibr" target="#b21">(Doddington et al., 2004;</ref><ref type="bibr" target="#b78">Walker et al., 2006)</ref>, TAC-KBPs <ref type="bibr" target="#b37">Ji et al., 2010</ref><ref type="bibr" target="#b38">Ji et al., , 2015</ref><ref type="bibr" target="#b39">Ji et al., , 2017</ref> and Rich ERE  use this annotation approach. More specifically, during the creation of the ACE 2005 dataset, the annotators initially tagged candidate documents as "good" or "bad" depending on the estimated number and types of entities present in each one. In subsequent <ref type="table" target="#tab_10">Table 1</ref>: Qualitative comparison of the datasets. We divide our comparison in five groups: (i) Core Tasks represent the main subtasks covered in DWIE, (ii) Doc-Based indicates whether different subtasks are annotated on the document-level, (iii) Entity-Centric indicates which annotations are done with respect to entity clusters () as opposed to individual mentions (), (iv) Unaided specifies whether the annotation process was completely manual () or with some form of distant supervision (), and (v) Open indicates whether the dataset is freely available.</p><p>annotation stages, only "good" documents were fully annotated and included in the final dataset. Similarly, during the creation of the TAC-KBP datasets, the annotators focused on producing annotations evenly distributed among three entity types (PERs, ORGs, and GPEs) by annotating only the documents that contained a minimum number of entities related to event types. In the case of Rich ERE, the documents to tag were prioritized by the event trigger word density calculated per 1,000 tokens, thus focusing only on content with a high number of previously defined key event-related tokens. Furthermore, other IE-related datasets <ref type="bibr" target="#b3">(Augenstein et al., 2017;</ref><ref type="bibr" target="#b31">Han et al., 2018;</ref><ref type="bibr" target="#b32">Hendrickx et al., 2010;</ref><ref type="bibr" target="#b89">Yao et al., 2019;</ref><ref type="bibr" target="#b94">Zhang et al., 2017b)</ref> use similar pre-filtering techniques in order to select the text to be annotated. As a consequence, the corpus and annotations in these datasets tend to be biased and likely not representative of the language used in the different input domains. Conversely, we adopt a radically different bottom-up approach where we derive the annotations (e.g., entity classification types, relation types) from the data itself. This bottom-up data-driven procedure guarantees that the annotations in DWIE are representative of the document corpus information and reflects the particularities of the language used in its journalistic domain. Furthermore, it better represents the properties that are inherently present in written corpora, e.g., the long-tail distribution of different annotation types.</p><p>Finally, from the perspective of the necessary evidence to annotate a particular entity type or relation, we propose to make a distinction for the currently existing datasets between trigger-based and documentbased annotations (see Doc-Based comparison group in <ref type="table" target="#tab_10">Table 1</ref>). The trigger-based datasets require that a particular relation or entity type should only be annotated if it is supported by an explicit reference in a text. For example, in <ref type="figure">Fig. 1</ref> there is a concrete reference of the relation between "Meghan" and "Harry" in form of triggers such as "gets engaged" in sentence 1 and "The wedding" in sentence 2. Most of the 6 The EDL track only of TAC-KBP 2010. 7 Numbers based on publicly available train and development sets.  <ref type="bibr" target="#b21">(Doddington et al., 2004;</ref><ref type="bibr" target="#b78">Walker et al., 2006)</ref>, TAC-KBPs <ref type="bibr" target="#b37">Ji et al., 2010</ref><ref type="bibr" target="#b38">Ji et al., , 2015</ref><ref type="bibr" target="#b39">Ji et al., , 2017</ref> and Rich ERE , as well as others, including FewRel <ref type="bibr" target="#b31">(Han et al., 2018)</ref>, OntoNotes <ref type="bibr" target="#b34">(Hovy et al., 2006;</ref><ref type="bibr" target="#b84">Weischedel et al., 2013)</ref>, TACRED <ref type="bibr" target="#b94">(Zhang et al., 2017b)</ref>, SemEval 2010 Task 8 <ref type="bibr" target="#b32">(Hendrickx et al., 2010)</ref> and SciERC <ref type="bibr" target="#b53">(Luan et al., 2018)</ref>, are trigger-based. The disadvantage of such an approach is that it only captures the most simple cases of relations and entity types that are explicitly mentioned in the text. As a general rule, this also limits the datasets to cover only the relations between entity mentions (i.e., the annotation process is mention-driven) that appear within a single or at most few adjacent sentences where the relation trigger occurs (see <ref type="figure" target="#fig_0">Fig. 2</ref> in Section 3 for a more detailed illustration of this phenomenon). However, as we move to a broader documentbased interpretation, it is common to find relations that are not explicitly mentioned in text. Thus, in our example of <ref type="figure">Fig. 1</ref> the relation between "Ministry of Defense" and "Britain" is not explicitly indicated in the text. However, after reading the whole article we can infer relations such as ministry of, agency of and based in between these two entities. This document-level reasoning makes it essential to adopt an entitycentric approach (see Entity-Centric comparison group in <ref type="table" target="#tab_10">Table 1)</ref> where each entity comprises one or more entity mentions, and the annotations (i.e., relations, entity tags and entity linking in DWIE) are made on the entity level, thus abstracting from specific mention-driven triggers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Recent advances in Information Extraction</head><p>In the last couple of years, the advances in joint modeling have been accompanied by an ever increasing interest in the use of graph-based neural networks <ref type="bibr" target="#b52">(Li et al., 2016b;</ref><ref type="bibr" target="#b87">Wu et al., 2020;</ref><ref type="bibr" target="#b88">Xu et al., 2018)</ref>. Initially, this approach has been applied to improve the performance of the single coreference resolution task by transferring document-level contextual information between coreferenced entity mention spans <ref type="bibr" target="#b40">(Kantor &amp; Globerson, 2019;</ref><ref type="bibr" target="#b49">Lee et al., 2018)</ref>. Most recently, these graph propagation techniques have been successfully used in a joint setting <ref type="bibr" target="#b26">(Fei et al., 2020;</ref><ref type="bibr" target="#b27">Fu et al., 2019;</ref><ref type="bibr" target="#b55">Luan et al., 2019;</ref><ref type="bibr" target="#b77">Wadden et al., 2019)</ref> by performing graph message passing updates between the shared spans across different tasks. However, while successful on mention-driven datasets such as ACE 2005 <ref type="bibr" target="#b78">(Walker et al., 2006)</ref> and NYT <ref type="bibr" target="#b66">(Riedel et al., 2010)</ref>, as far as we are aware, the advantages of these techniques have not yet been investigated in an entity-centric documentlevel setting. We fill this gap by extending the neural graph-based model initially proposed by <ref type="bibr" target="#b55">Luan et al. (2019)</ref> to be used on DWIE (see Section 4). More specifically, we explore the effect of performing documentlevel coreference (CorefProp) <ref type="bibr" target="#b49">(Lee et al., 2018;</ref><ref type="bibr" target="#b55">Luan et al., 2019)</ref> and relation-driven (RelProp)  graph message passing updates between the spans. Additionally, we introduce a new latent attention-based graph propagation method (AttProp) and compare it to previously proposed task-driven graph propagation methods (CorefProp and RelProp).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Metrics and evaluation</head><p>Current dominant IE systems consider mention-level scoring of NER as well as RE components when reporting on datasets such as <ref type="bibr">CoNLL-2003</ref><ref type="bibr" target="#b1">(Akbik et al., 2019</ref><ref type="bibr" target="#b4">Baevski et al., 2019;</ref><ref type="bibr" target="#b14">Chiu &amp; Nichols, 2016;</ref><ref type="bibr" target="#b46">Lample et al., 2016)</ref>, OntoNotes <ref type="bibr" target="#b14">(Chiu &amp; Nichols, 2016;</ref><ref type="bibr" target="#b16">Clark et al., 2018;</ref><ref type="bibr" target="#b74">Strubell et al., 2017)</ref>, ACE 2004 <ref type="bibr" target="#b7">(Bekoulis et al., 2018a;</ref><ref type="bibr" target="#b51">Li &amp; Ji, 2014;</ref><ref type="bibr" target="#b91">Zhang et al., 2017a</ref><ref type="bibr">), ACE 2005</ref><ref type="bibr" target="#b26">(Fei et al., 2020</ref><ref type="bibr" target="#b55">Luan et al., 2019;</ref><ref type="bibr" target="#b91">Zhang et al., 2017a)</ref>, TACRED <ref type="bibr" target="#b72">(Soares et al., 2019;</ref><ref type="bibr" target="#b93">Zhang et al., 2018</ref><ref type="bibr" target="#b94">Zhang et al., , 2017b</ref>, and SelEval 2010-Task 8 <ref type="bibr" target="#b36">Hu et al., 2020;</ref><ref type="bibr" target="#b62">Peters et al., 2019)</ref> among others. In contrast, the DWIE dataset is entity-centric where all the annotations are done on the entity cluster level. Consequently, adopting a purely mention-based evaluation approach can lead to a dominance of the score by predictions on entities composed by many mentions as opposed to entities composed by only few ones. Conversely, a purely clusterlevel evaluation would be overly strict, requiring correct prediction of relation/entity types as well as an exact match of the predicted entity clusters. To tackle this problem, we propose a new scoring method that combines entity mention-level and cluster-level evaluation, while avoiding the pitfalls of either method alone (see Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Annotation process</head><p>In this work we introduce our bottom-up data-driven annotation approach. Our main goal is to get an annotation schema that reflects the types of entities and relations that are effectively mentioned throughout the corpus to maximally capture the information it contains. Therefore, we derive the annotation schema from the corpus itself, adopting three annotation passes that are detailed next: (i) exploratory pass, (ii) schemadriven pass, and (iii) inter-annotator refinement. Each pass encompasses substeps to cover all IE subtasks: (i) mention annotation (i.e., the entities and their types), (ii) coreference resolution, (iii) relation extraction on the entity level (i.e., clustering all mentions referring to the same entity), and (iv) entity linking (again, on the entity level, providing the same link for all clustered mentions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Exploratory pass</head><p>The first annotation pass aims to discover the annotation structure (i.e., annotation schema) to be used on the corpus, in particular the types to use for named entity recognition (NER) and relation extraction (RE) tasks. Three annotators are involved in this step to provide annotations on the mention level: one expert annotator and two paid students. However, no parallel annotation is done and the role of the expert annotator is to annotate part of the corpus, as well as instructing and supervising the paid annotators. No a priori fixed schema is followed, but we ask the annotators to be as consistent as possible during the process. More specifically, the annotators are free to define their own entity and relation types for the NER and RE tasks that reflect the contents of the articles as long as they comply with the following generic guidelines:</p><p>1. Named Entities: any physical or abstract object (e.g., "Washington","Jeff Davis","Nobel Prize", "Lisbon Treaty", etc.) that can be denoted with a proper noun. Entities are usually upper-cased in the text, although values such as money and time can also be included. Use short and specific entity types (e.g., person, organization, etc.) to classify entities, the types can be overlapping (a single entity can have multiple types).</p><p>2. Relations: identify meaningful relations between entities. The type of a relation should be specific and reflect the type of the connected entities as well as the semantic meaning of the relation. For example, instead of using a generic "located in" relation for entities located in a particular country, we can divide it in "based in country" for organizations that are based in a country, "city located in OTHER Includes the nominal variations of entity types (e.g., includes variations of country names such as "German", which is a variation of "Germany").</p><p>"Franco-German 'war child' granted German citizenship."  <ref type="bibr">(right)</ref>. The graph at the top illustrates the relations coverage measuring the minimum distance between entities (closest mentions). Conversely, the graph at the bottom shows the coverage measuring the maximum distance between entity mentions. In both graphs, we note that the distance between the related mentions in our dataset is higher than in other widely used datasets.</p><p>country" for cities located in the country, etc. The types of the relations should have short names, ideally not exceeding 15 characters.</p><p>By not constraining the annotation process to specific entity and relation types, we ensure that our annotations are representative of the actual information contained in the annotated corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Schema-driven pass</head><p>The main goal of this step is to create a consistent annotation schema for (i) named entity types and (ii) relation types based on the annotations made in the exploratory pass. As a first step, we identify the classification tags to be assigned to entities. We divide these tags in five main categories: type, topic, iptc, slot, and gender (see <ref type="table" target="#tab_10">Table A</ref>.4). Our type tag is organized in a hierarchical structure (see <ref type="table" target="#tab_10">Table A</ref>.1 in Appendix A), making it easier to extend our annotations to more granular subtypes. <ref type="table" target="#tab_1">Table 3</ref> defines and provides examples of each of the top type tags in the entity type hierarchy (ENTITY, VALUE and OTHER) as well as the direct subtypes of ENTITY. The topic tag allows to assign topics (e.g., politics, culture, education, etc.) to the entities and it complements the type tag (see <ref type="table" target="#tab_10">Table A</ref>.2). The iptc tag is used for the universally defined IPTC news categories based on a media taxonomy (https://iptc.org/standards/ subject-codes/). The slot tag is used for additional categorization that is transversal to different entity types. One example of this is the slot interviewee that can be assigned to any person (entity of type person) interviewed in a particular article. 8 Finally, the gender tag is used to indicate the gender of the entities that refer to people. By defining these multiple overlapping tag types, we realize that the entity classification is multi-label by nature and thus allows different complementary entity tags to be assigned to a particular entity. 9 This contrasts with prevailing single-label multi-class datasets such as ACE 2005 <ref type="bibr" target="#b21">(Doddington et al., 2004;</ref><ref type="bibr" target="#b78">Walker et al., 2006)</ref>, TAC-KBPs <ref type="bibr" target="#b38">Ji et al., 2015</ref><ref type="bibr" target="#b39">Ji et al., , 2017</ref>, Rich ERE , WNUT 2017 <ref type="bibr" target="#b18">(Derczynski et al., 2017)</ref> and <ref type="bibr">CoNLL-2003</ref><ref type="bibr" target="#b68">(Sang &amp; De Meulder, 2003</ref>. Relations between geographic locations and the countries they are located in, ex: For our relation annotations, we focus on annotating relations between entities themselves (cf. documentbased entity-centric approach). Our adopted approach allows us to think concept-wise and come up not only with relations that are explicitly stated, but also those that can be implicitly inferred from the text. As a result, our dataset includes relations whose connected mentions are located further apart in the document. This can be seen in <ref type="figure" target="#fig_0">Fig. 2</ref>, where we compare the minimum (Min.) and maximum (Max.) distances between the mentions of the two entities connected by a relation for various mention-driven (Rich ERE 10 , TAC-KBP 11 , and ACE 2005) and entity-centric (DocRED, BC5CDR, and the final version of our DWIE dataset) RE datasets. We note how other datasets that define the relation in terms of entities (BC5CDR and DocRED) require a higher number of token and sentence spans to cover all the relations in the respective dataset: entity-centric relations very often involve mentions located in different sentences in the document that refer to those entities. This is not the case for mention-driven trigger-based relations as in the TAC-KBP, Rich ERE and ACE 2005 datasets, where the annotation bias is towards finding explicitly mentioned relations, often involving entity mentions in a single sentence.</p><p>Similarly as with entity tags, we organize our relation annotations using multi-label types (see <ref type="table" target="#tab_10">Table A</ref>.5 for details). <ref type="table" target="#tab_2">Table 4</ref> gives some examples from the DWIE corpus for the top 5 most occurring relation types (a detailed list can be consulted in <ref type="table" target="#tab_10">Table A</ref> <ref type="bibr">.6)</ref>. For reasons of space, the examples only involve relations between entities whose mentions occur in a single sentence; for an example involving document-level relations we refer to <ref type="figure">Fig. 1</ref>.</p><p>Additionally, we define logical rules to automatically guarantee the consistency of the relations and their types. The following is an example,</p><formula xml:id="formula_0">based in2 X, Z ? in0 Z, Y =? based in0 X, Y<label>(1)</label></formula><p>reflecting the knowledge that if an organization X is based in a city Z (relation based in2), and that this city Z is located in the country Y (relation in0), the fact that company X is also located in that country (relation based in0) is valid as well. The goal of this step is mainly consistency of the annotations, but it implies that an effective predictor would need to perform some form of reasoning to correctly predict all relations in the dataset. A complete list of logical rules is provided in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Inter-Annotator Refinement</head><p>In order to assess and further improve the quality of our dataset we re-annotate a 100 randomly selected news articles (12.5% of the articles used in the previous annotation rounds) from scratch. This work is done by a second independent expert annotator. The annotations in this pass are performed by following the already defined annotation schema based on the annotation process in the exploratory and schema-driven passes. We use this second annotated subset to measure the inter-annotator agreement and subsequently determine the parts of the dataset that still need to be improved. <ref type="table" target="#tab_3">Table 5</ref> compares the kappa scores before and after this refinement pass for each of the tasks (see Appendix B for details on how the kappa score is calculated). We observe that, after the refinement, all of the kappa scores are above 0.85, which is considered a 'strong' <ref type="bibr" target="#b58">(McHugh, 2012)</ref> to 'almost perfect' <ref type="bibr" target="#b47">(Landis &amp; Koch, 1977)</ref> agreement.</p><p>Note that the revisions were seeded by and evaluated on the subset of 100 re-annotated articles. However, we argue that the inter-annotator refinement improved the annotation consistency of the entire dataset, given that the reviewed entity and relation types are used in more than 99.4% of all annotations in DWIE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Model Architecture</head><p>In this section we introduce the end-to-end architecture used to compare the performance of models trained on the separate tasks with the models that are trained jointly for multiple tasks on the DWIE dataset. The main component of our approach is the use of Graph Neural Networks <ref type="bibr" target="#b52">(Li et al., 2016b;</ref><ref type="bibr" target="#b69">Scarselli et al., 2008;</ref><ref type="bibr" target="#b87">Wu et al., 2020;</ref><ref type="bibr" target="#b88">Xu et al., 2018)</ref>, relying on propagation techniques in both single-task and joint setups. More specifically, we implement span-based graph message passing on coreference (CorefProp) <ref type="bibr" target="#b49">(Lee et al., 2018;</ref><ref type="bibr" target="#b55">Luan et al., 2019)</ref> and relation levels (RelProp) . Additionally, we introduce a latent attentive propagation method (AttProp) which is not driven by annotations of any task in particular and, as a result, can be freely applied to any task or joint combination of tasks. The interconnection between the different components of our model architecture is depicted in <ref type="figure" target="#fig_2">Fig. 3</ref>. It is based on the span-based architecture introduced in Lee et al. <ref type="formula" target="#formula_0">(2017)</ref>, which supports training on the space of all entity spans simultaneously, dynamically updating span representations by using the graph propagation approach (further detailed in Section 4.4). Recent works have shown that this idea has the potential for improved effectiveness (albeit at a higher computational cost) <ref type="bibr" target="#b20">(Dixit &amp; Al-Onaizan, 2019;</ref><ref type="bibr" target="#b26">Fei et al., 2020;</ref><ref type="bibr" target="#b49">Lee et al., 2018;</ref><ref type="bibr" target="#b55">Luan et al., 2019)</ref>, compared to more traditional sequence-labeling approaches <ref type="bibr" target="#b42">(Katiyar &amp; Cardie, 2018;</ref><ref type="bibr" target="#b46">Lample et al., 2016;</ref><ref type="bibr" target="#b54">Luan et al., 2017;</ref><ref type="bibr" target="#b57">Ma &amp; Hovy, 2016)</ref>. More concretely, the use of a span-based approach where all the spans are shared between the individual task modules avoids the cascading of errors from the entity mention identification module (entity scorer in <ref type="figure" target="#fig_2">Fig. 3</ref>) to the rest of the tasks.</p><p>The most similar architecture to ours in using joint span-based neural graph IE is DyGIE  and its successor DyGIE++ . Our model is described in detail below, but here we already list the aspects in which it differs from these models:</p><p>1. We introduce the graph propagation technique AttProp (see Section 4.4), which is not directly conditioned on a particular task and can be used in single-task (for each of the tasks) as well as joint settings.</p><p>2. We define a coreference architecture that, unlike previous work in span-based coreference resolution <ref type="bibr" target="#b48">(Lee et al., 2017</ref><ref type="bibr" target="#b49">(Lee et al., , 2018</ref>, allows to also account for singleton entities in the DWIE dataset (see Sections 4.2.2 and 4.5.2) by using an additional pruner loss, which turns out essential for the single model focusing on end-to-end coreference resolution.</p><p>3. Due to the document-level nature of DWIE, we run graph propagations on the whole document. This contrasts with a sentence-based approach adopted initially in the DyGIE/DyGIE++ architectures. It also drives some changes such as the use of a single pruner (see Section 4.1) to extract spans used in coreference and RE modules. Similarly, instead of applying the shared BiLSTM sentence by sentence as in <ref type="bibr" target="#b55">Luan et al. (2019)</ref> and <ref type="bibr" target="#b77">Wadden et al. (2019)</ref>, we do it on the entire document, in order to allow capturing cross-sentence dependencies for document-level relations and entity clusters in DWIE.</p><p>4. We add an additional decoding step (see Section 4.3) needed to transform mention-based predictions for RE and NER tasks into entity-based ones, as required by the entity-centric nature of DWIE, and propose corresponding evaluation metrics (see Section 5).</p><p>5. Finally, we make changes in the loss and prediction components to support multi-label classification (in NER and RE) as required in DWIE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Span-Based Representation</head><p>The input to our model consists of document-level annotation instances. Each document D from the considered document collection D is represented by its sequence T of tokens. These tokens are represented internally as a concatenation of GloVe <ref type="bibr" target="#b61">(Pennington et al., 2014)</ref> and character embeddings <ref type="bibr" target="#b57">(Ma &amp; Hovy, 2016)</ref>. We also experiment with additionally concatenating BERT <ref type="bibr" target="#b19">(Devlin et al., 2019)</ref> contextualized embeddings. Since BERT is run on a sub-token level, to the representation of each token we only concatenate the BERT-based representation of the first sub-token, as originally proposed by <ref type="bibr" target="#b19">Devlin et al. (2019)</ref>. This input is fed into a BiLSTM layer in order to obtain the output token representations by concatenating the forward and backward LSTM hidden states. The BiLSTM outputs for the considered document D are written on the token level as e i ? R m (i = 1, . . . , |T |). These are converted into span representations. The set of all possible spans for D, up to maximum span width w max (which is a hyperparameter of the model), is written as S = {s 1 , . . . , s |S| }. The number of spans can be calculated as follows,</p><formula xml:id="formula_1">|S| = wmax k=1 |T | ? k + 1 = w max |T | ? w max ? 1 2 (2)</formula><p>We obtain the representation g 0 i for span s i , ranging from token l to token r, by concatenating their respective BiLSTM states e l and e r with an embedding ? r?l for the span width w i = r ? l</p><formula xml:id="formula_2">g 0 i = [e l ; e r ; ? r?l ]<label>(3)</label></formula><p>As seen from Eq.</p><p>(2), the number of possible spans scales approximately linearly with the maximum span width w max , as well as the document length |T | (assuming w max |T |). This leads to a strongly increased set of spans, as compared to previous works where |S| scales with the length of individual sentences rather than entire documents <ref type="bibr" target="#b77">Wadden et al., 2019)</ref>. In order to mitigate the required memory of our model, we use a shared pruner to reduce S to a smaller set P of candidate spans to be used by 3) scorers independently from entity scorer (Section 4.2.1). However, a pruning step (described in Section 4.1) is needed in order to limit the memory required to perform matrix operations on span representations involved in graph propagation (AttProp, CorefProp, RelProp)(Section 4.4) as well as in the attention, coreference and relation scorer modules. The pruned spans share the same representation with the rest of the spans (shared representation). This way, the update in span representations caused by the graph propagation modules also affects the entity scorer. Our AttProp graph propagation method runs independently from coreference, relation, and entity scorers, enabling its use in combination with any task. Finally, the entity-centric decoder (Section 4.3) uses the entity clusters predicted by the coreference scorer to convert the span-based predictions from the relation and entity scorers to entity-centric ones.</p><p>the coreference and RE scorers and in the graph propagation modules (see further). The choice of using a single pruner contrasts with similar work in <ref type="bibr" target="#b55">Luan et al. (2019)</ref> and <ref type="bibr" target="#b77">Wadden et al. (2019)</ref> where two separate pruners are used, one for the relation task, and another for coreference. Our design choice is based on the fact that both of these tasks use the same document-level entity mentions. This contrasts with datasets used in <ref type="bibr" target="#b55">Luan et al. (2019)</ref> and <ref type="bibr" target="#b77">Wadden et al. (2019)</ref> where, while the coreference is defined on the document-level, the relations are sentence-based. Finally, we use graph propagation to iteratively refine the pruned spans representations. Three graph propagation mechanisms are compared in the experiments. Our own contribution is the attention-based graph propagation method AttProp, where the span representations are updated in ? A iterations. Alternatively, ? C iterations of CorefProp <ref type="bibr" target="#b49">(Lee et al., 2018;</ref><ref type="bibr" target="#b55">Luan et al., 2019)</ref> can be performed, or ? R iterations of RelProp .</p><p>The span representation of a particular span s i after iteration t is denoted as g t i in our notation. The details of graph propagation are explained in Section 4.4. Note that in theory several of these graph propagation techniques could be accumulated, but in our setting the benefits thereof in terms of model effectiveness were minor, at a significantly higher computational cost. Therefore, in our experiments, we only compare models without graph propagation with models applying a single form of graph propagation.</p><p>To keep the sections introducing the models clear, we will write ? to denote the number of propagations in general (which could be 0, or any of ? A , ? C or ? R , depending on the chosen experiments and considered model components).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Joint Model for Entity Recognition, Coreference Resolution, and Relation Extraction</head><p>In this section, we present the joint model including recognition of entity mentions as belonging to L T types (introduced as NER), the clustering of the entity mentions into entities (coreference resolution), and identifying relations between entities, all on the document level. The building blocks responsible for the three subtasks are discussed next, as well as the total loss of the joint model. The details of the graph propagation mechanisms are then provided further on (Section 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Entity Mention Module</head><p>All spans s i (up to width w max ) of the considered document 12 are scored by feeding their representation (starting from Eq. (3) and potentially updated after ? graph propagation iterations) into the feed-forward neural network (FFNN) written as F mention , with as many outputs as there are entity types:</p><formula xml:id="formula_3">? ? mention (s i ) = F mention (g ? i ).<label>(4)</label></formula><p>Throughout this section, we will maintain the same notation of F (x) to denote a FFNN that takes as input a vector x and produces a vector of scores, and F(x) to refer to a FFNN with a scalar output. The probability of each label being valid for the considered span is modeled by component-wise application of a sigmoid (?(x) = 1/(1 + e ?x )) to these scores ? ? mention (s i ) ? R L T (with L T the number of entity tags). The log probability of the ground truth mention labels for all spans of document D is given by</p><formula xml:id="formula_4">log P mention (E * |G ? ) = |S| i=1 L T l=1 I i,l log ?(? ? mention (s i ) l ) + (1 ? I i,l ) log 1 ? ? (? ? mention (s i ) l ) ,<label>(5)</label></formula><p>in which E * represents the set of ground truth mention labels for all spans in the document, and I i,l ? {0, 1} is the ground truth indicator label for mention tag l of span s i . G ? denotes the set of all considered span representations for the current document. The superscript ? reflects the fact that, in case graph propagation is applied, the subset of |P | representations (for the spans retained after pruning) have been updated over ? iterations. By summing over all entity types (l = 1, . . . , L T ), we account for the fact that a particular span can have multiple associated entity tags (i.e., the considered NER task is multi-label). At inference time, spans get assigned those entity types for which the corresponding score ? ? mention (s i ) &gt; 0. Note that not all valid entity mentions necessarily get an entity type assigned: if the relation extractor determines that a span is part of a relation, it effectively becomes an entity mention, even if none of the pre-defined types is considered applicable by the entity scorer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Coreference Module</head><p>While the entity scoring is performed on all span representations S, this is not possible for the coreference and relation scorers, due to memory limitations. The latter scorers predict on pruned spans, as shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. How the pruner is trained jointly with the model, is described in Section 4.2.4. In order to avoid confusion by introducing additional notations, we list the spans in the pruned set P as s 1 , . . . , s |P | , according to their original order in the text.</p><p>The module for coreference resolution is based on pairwise scoring of the pruned spans from P . Following ideas from <ref type="bibr" target="#b48">Lee et al. (2017</ref><ref type="bibr" target="#b49">Lee et al. ( , 2018</ref>; <ref type="bibr" target="#b53">Luan et al. (2018</ref><ref type="bibr" target="#b55">Luan et al. ( , 2019</ref>, for any span s j , scores with respect to each of the preceding (also referred to as 'antecedent') spans s i (i ? j) in the document are calculated with a neural network F coref :</p><formula xml:id="formula_5">? ? coref (s i , s j ) = F coref [g ? i ; g ? j ; g ? i g ? j ; ? i,j ] .<label>(6)</label></formula><p>This expression scores the compatibility between spans s i and s j , taking as input the concatenation of their respective span representations (after ? propagation iterations), their component-wise product, and an embedding ? i,j representing their distance in terms of the number of ordered candidate spans from s i to s j . In order to deal with non-coreferent or incorrect spans, previous work in span-based coreference <ref type="bibr" target="#b48">(Lee et al., 2017</ref><ref type="bibr" target="#b49">(Lee et al., , 2018</ref>) defines a dummy antecedent to which all non-coreferent or invalid spans point. While this approach is effective in datasets that do not contain singleton entity clusters, such as OntoNotesbased CoNLL-2012 <ref type="bibr" target="#b64">(Pradhan et al., 2012)</ref>, it does not allow to distinguish between valid singleton entity mentions and invalid mention spans. This makes it unsuitable to use on DWIE, since it contains singleton entity clusters, consisting of a single mention. In fact, 66.4% of the entity clusters in DWIE are singletons. Furthermore, the current official CoNLL-2012 evaluation script 13 based on <ref type="bibr" target="#b63">Pradhan et al. (2014)</ref> accounts for scenarios where either the dataset or the predicted mentions are singletons, which has a direct impact on the established B-CUBED <ref type="bibr" target="#b5">(Bagga &amp; Baldwin, 1998)</ref> and CEAF e <ref type="bibr" target="#b56">(Luo, 2005)</ref> coreference scores. In order to tackle the singleton entity cluster detection in our coreference model, we propose to start from ? ? coref (s j , s j ) 14 as a self-coreference span score. By applying the correct target in the coreference loss, it allows indicating that either the span s j is not a valid mention, or that it is a valid mention that is not co-referenced with any antecedent span.</p><p>The log probability of the ground truth coreference labels of document D is given by</p><formula xml:id="formula_6">log P coref (C * |G ? ) = |P | j=1 log s * ?S * j exp (? ? coref (s * , s j )) j i=1 exp (? ? coref (s i , s j )) .<label>(7)</label></formula><p>The set of ground truth coreference labels is indicated as C * . The summation over j represents the contribution to the log likelihood of the correct antecedent labels for each span s j in the pruned set P . The individual terms in the right-hand side correspond to the log probability of the correct antecedent labels for a particular span s j . In the denominator, the summation ranges from the first span, up to span s j itself (i.e., for the self-coreference score), but not beyond it (given that only antecedents in the sorted sequence of pruned spans are considered). The numerator contains the contributions from the potentially multiple ground truth antecedents for span s j . This stems from the fact that multiple antecedent mentions may belong to the same cluster as s j , which all contribute to the probability of the correct antecedent labels. The set of ground truth antecedents corresponding to span s j is written S * j . At inference time, the highest scoring antecedent for span s j (including s j itself) is picked. Due to the idea of only predicting antecedents, picking any of the ground truth antecedents leads to the correct mention clusters <ref type="bibr" target="#b22">(Durrett &amp; Klein, 2013;</ref><ref type="bibr" target="#b48">Lee et al., 2017</ref><ref type="bibr" target="#b49">Lee et al., , 2018</ref><ref type="bibr" target="#b85">Wiseman et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Relation Module</head><p>Similar to the coreference module (Eq. (6)), we score span pairs using an FFNN</p><formula xml:id="formula_7">? ? relation (s i , s j ) = F relation [g ? i ; g ? j ; g ? i g ? j ; ? i,j ] ,<label>(8)</label></formula><p>where ? i,j is again the distance embedding as introduced in Section 4.2.2. ? ? relation (i, j) ? R L R is a vector representing relation span pair scores for each of the L R possible relation types between spans s i and s j .</p><p>The log probability of the ground truth relation labels of document D is given by</p><formula xml:id="formula_8">log P relation (R * |G ? ) = |P | i,j=1 L R l=1 I i,j,l log ?(? ? relation (s i , s j ) l ) + (1 ? I i,j,l ) log (1 ? ?(? ? relation (s i , s j ) l )),<label>(9)</label></formula><p>in which R * represents the set of ground truth relation labels for all combination of pruned span pairs in the document, and I i,j,l ? {0, 1} is the ground truth indicator label for relation type l of the span pair (s i , s j ). Note that all |P | 2 pruned span pairs are considered, since the order of the spans in the relation matters (unlike the coreference case). By summing over all possible relation types L R , we account for the fact that a particular relation between two spans can be multi-label (which is the case for more than 30% of relations, as shown in <ref type="table" target="#tab_10">Table A</ref>.5).</p><p>Since this model is run in parallel with the coreference module, it is used to predict relations only between entity mentions and not entity clusters. During inference, candidate relations are accepted when ? ? relation (s i , s j ) l &gt; 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4.">Span Pruner</head><p>The span pruner is an FFNN, denoted F pruner , that scores all spans s i based on their initial representation g 0 i , after which only the highest scoring spans are retained in the pruned span set P . In our experiments P contains the top 0.2 |T | highest scoring spans, which covers more than 98% of all the ground truth mention spans in the DWIE dataset. We represent the pruner score for span s i as</p><formula xml:id="formula_9">? pruner (s i ) = F pruner g 0 i .<label>(10)</label></formula><p>Several strategies can be used to train the pruner. One option is to directly optimize the probability of the pruner to detect the spans of correct entity mentions. With S * the set of spans with at least one ground truth entity type, and I i ? {0, 1} an indicator for whether s i ? S * , the corresponding log likelihood can be written as</p><formula xml:id="formula_10">log P pruner S * |G 0 = |S| i=1 I i log ? (? pruner (s i )) + (1 ? I i ) log (1 ? ? (? pruner (s i ))) ,<label>(11)</label></formula><p>leading to a separate pruner loss term. Alternatively, the pruner can be trained indirectly by adapting the mention score from Eq. (4), the coreference score from Eq. (6) or the relation score from Eq. (8) as follows:</p><formula xml:id="formula_11">? ? mention (s i ) = ? ? mention (s i ) + ? pruner (s i ) (12) ? ? coref (s i , s j ) = ? ? coref (s i , s j ) + ? pruner (s i ) (13) ? ? relation (s i , s j ) = ? ? relation (s i , s j ) + ? pruner (s i )<label>(14)</label></formula><p>for use in the expressions Eq. (5), Eq. <ref type="formula" target="#formula_6">(7)</ref> and Eq. (9), respectively. As such, higher pruner scores would directly correspond to higher mention or coreference scores, and lead to a meaningful ranking of spans according to pruner scores. All three strategies seem to work on a similar level, but for the presented joint model experiments, we use the indirect training through the coreference module, as in Eq. (13). Note that we did not experiment with training the pruner through the relation module, because it would be trained only on those spans involved in relations, which is a mere subset of all valid mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5.">Joint Model</head><p>We perform joint training in order to explore the degree to which the graph propagation techniques (see Section 4.4) affect related tasks in DWIE. For instance, we expect that performing a coreference propagation can have a positive impact on the NER task. We hypothesize that enriching the entity spans with broader contextual information coming from other mention spans in the cluster, can improve the effectiveness of the entity module. Furthermore, given the entity-centric nature of DWIE, the mention-based predictions for NER and RE have to be grouped in coreference clusters (see section 4.3 for details), which makes it necessary to execute these tasks jointly with the coreference task.</p><p>The joint loss for each document D is a weighted sum of the individual loss functions of the subtasks:</p><formula xml:id="formula_12">L joint D = (E * ,C * ,R * ) ? E log P mention (E * |G ? ) + ? C log P coref (C * |G ? ) + ? R log P relation (R * |G ? ) ,<label>(15)</label></formula><p>in which ? E , ? C , and ? R are hyperparameters of the joint model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Decoding and Prediction</head><p>Unlike previous datasets used in span-based predictions <ref type="bibr" target="#b21">(Doddington et al., 2004;</ref><ref type="bibr" target="#b44">Kulkarni et al., 2018;</ref><ref type="bibr" target="#b53">Luan et al., 2018;</ref><ref type="bibr" target="#b78">Walker et al., 2006)</ref> where the relation and entity extraction are done on the mentionlevel, DWIE is an entity-centric dataset. During inference, this requires an additional decoding step to cluster the mention-based span-dependent predictions into entity-centric ones. The component responsible for this decoding in the proposed architecture is the entity-centric decoder (see <ref type="figure" target="#fig_2">Fig. 3</ref>). The pseudo-code in Algorithm 1 summarizes the steps performed by this component. First, the decoder receives as input the predicted span clusters (p cl), entity mentions (p men) and relations between spans (p rel) obtained from the scores calculated in Eq. (13), Eq. (4) and Eq. (8), respectively. Next, the predicted entity mentions are connected with the respective clusters by using the dictionary C that maps mention spans to cluster ids (lines 3-12 in Algorithm 1). Specifically, each of the entity clusters is assigned the union of the entity types predicted for any of the mention spans inside the cluster (line 11 in Algorithm 1). If the predicted entity mention can not be located inside the predicted clusters, a new singleton cluster is added (lines 5-6 in Algorithm 1). Finally, all the pairwise predicted relations on the mention level (p rel) between members of two different clusters are assigned as predicted relations between the (cluster-level) entities (lines 13-20 in Algorithm 1). Similarly as with entity mentions, the dictionary C is used to map the mention spans (span h and span t) of a particular relation type rel type to the corresponding cluster ids. Furthermore, the relations added between two clusters are the union of all the relations predicted between any pair of mentions inside these clusters (line 18 in Algorithm 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Graph Propagation Mechanisms</head><p>In order to evaluate the impact of graph-based propagation of contextual information between the spans, we propose AttProp, and reimplement the CorefProp and RelProp graph propagation algorithms. <ref type="bibr" target="#b49">Lee et al. (2018)</ref> proposed the gated graph propagation update function for use on coreference resolution, which was then successfully applied in a joint multi-task setting by <ref type="bibr" target="#b55">Luan et al. (2019)</ref>; <ref type="bibr" target="#b77">Wadden et al. (2019)</ref>. The graph propagation equations are written as:</p><formula xml:id="formula_13">f t x (s i ) = ? F x ([g t i ; u t x (s i )]) ,<label>(16)</label></formula><formula xml:id="formula_14">g t+1 i = f t x (s i ) g t i + 1 ? f t x (s i ) u t x (s i ),<label>(17)</label></formula><p>where in our case x ? {A, C, R} denotes AttProp, CorefProp, and RelProp, respectively. The n-dimentional vector f t x (s i ), produced by the single-layer FFNN F x can be interpreted as a gating vector that acts as a switch between the current span representations g t i ? R n , and the update span vector u t x (s i ) ? R n . The various graph propagation methods differ in how u t x (s i ) is calculated. CorefProp -The coreference confidence score between span s i and s j for propagation iteration t is denoted as P t C (s i , s j ) and calculated as follows,</p><formula xml:id="formula_15">P t C (s i , s j ) = exp ? t coref (s i , s j ) j i =1 exp ?t coref (s i , s j ) ,<label>(18)</label></formula><p>in which i ? {1, . . . , j} refers to all antecedent spans s i to span s j in the pruned span set. Note that the coreference scores according to Eq. <ref type="formula" target="#formula_0">(13)</ref>  end if 20: end for the considered spans are compatible, but also whether the individual spans are likely to be retained by the pruner as potential entity mentions. In order to perform a CorefProp graph iteration, the span update vector u t C (i) ? R n is first calculated as a weighted average of the current representation of span s j and all of its antecedents</p><formula xml:id="formula_16">u t C (s j ) = j i=1 P t C (s i , s j ) g t i ,<label>(19)</label></formula><p>in which the weighting coefficients quantify the coreference compatibility of the corresponding span with s j . After that, the update equations Eq. (16) and Eq. <ref type="formula" target="#formula_0">(17)</ref>  </p><formula xml:id="formula_17">u t R (s j ) = |P | i=1 A R f ? t relation (s i , s j ) g t i ,<label>(20)</label></formula><p>where A R ? R n?L R is a trainable projection tensor, and f is a non-linear activation function (ReLU). Similarly as in Eq. <ref type="formula" target="#formula_0">(19)</ref>, the update vector can be interpreted as a weighted sum of all span representations, with the additional expressiveness stemming from the projection matrix A R in accounting for the relation scores.</p><p>AttProp -In order to measure the impact of the 'supervised' CorefProp and RelProp propagation techniques described by equations (18)-(20) above, we introduce a latent attentive propagation. Unlike CorefProp and RelProp that are driven by the task-specific confidence propagation scores ? t coref (s i , s j ) and ? t relation (s i , s j ), AttProp is influenced only by latent attention weights between all the pruned spans P calculated as follows,</p><formula xml:id="formula_18">? t att (s i , s j ) = F att [g t i ; g t j ; g t i g t j ; ? i,j ] ,<label>(21)</label></formula><p>where ? i,j is the distance feature embedding function between spans s i and s j , and ? t att (s i , s j ) is the attention score between these spans. This score is normalized with a softmax to get the P t A (s i , s j ) confidence score</p><formula xml:id="formula_19">P t A (s i , s j ) = exp (? t att (s i , s j )) |P | j =1 exp (? t att (s i , s j ))</formula><p>.</p><p>The span update vector u t A (s i ) ? R n is calculated as a weighted sum of all the P span representations as opposed to only antecedents in CorefProp</p><formula xml:id="formula_21">u t A (s i ) = |P | j=1 P t A (s i , s j ) g t j .<label>(23)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Single Task Models</head><p>In this section we shortly describe independent baseline models for the three individual core tasks under study in this paper, as training these models not entirely corresponds to merely minimizing the corresponding loss term from the total loss Eq. (15).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1.">Single Entity Recognition Model</head><p>The single-task NER model is designed for detecting and correctly labeling the individual entity spans, and is based on Eq. (5). However, even for the single models, the graph propagation mechanism AttProp may be useful, but for that the pruner needs to be jointly trained with the model. This is obtained by augmenting the mention loss ? log P mention (E * |G ? ) with the pruner loss ? log P pruner S * |G 0 according to Eq. (11).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2.">Single Coreference Resolution Model</head><p>The single-task end-to-end coreference model needs to detect mentions and correctly cluster them. Here again, the standard coreference loss ? log P coref (C * |G ? ) according to Eq. (13) and Eq. <ref type="formula" target="#formula_6">(7)</ref> is extended with the pruner loss ? log P pruner (S * |G 0 ). This turned out essential for correctly predicting the singleton clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3.">Single Relation Extraction Model</head><p>The single relation extraction model is trained to detect mentions as well as the correct pairwise relations between mentions (i.e., without the coreference step). In order to train the pruner as well, the standard relation score is extended as described in Eq. (14) before calculating the loss ? log P relation (R * |G ? ) based on Eq. (9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Entity-Centric Metrics</head><p>Unlike the currently widespread datasets that use a mention-driven approach to annotate named entities <ref type="bibr" target="#b6">(Bekoulis et al., 2017;</ref><ref type="bibr" target="#b18">Derczynski et al., 2017;</ref><ref type="bibr" target="#b68">Sang &amp; De Meulder, 2003;</ref><ref type="bibr" target="#b83">Weischedel et al., 2011)</ref>, relations <ref type="bibr" target="#b3">(Augenstein et al., 2017;</ref><ref type="bibr" target="#b6">Bekoulis et al., 2017;</ref><ref type="bibr" target="#b21">Doddington et al., 2004;</ref><ref type="bibr" target="#b39">Ji et al., 2017;</ref><ref type="bibr" target="#b43">Kim et al., 2003;</ref><ref type="bibr" target="#b53">Luan et al., 2018;</ref><ref type="bibr" target="#b73">Song et al., 2015)</ref> and entity linking <ref type="bibr" target="#b9">(Bentivogli et al., 2010;</ref><ref type="bibr" target="#b33">Hoffart et al., 2011;</ref><ref type="bibr" target="#b66">Riedel et al., 2010)</ref>, DWIE is entirely entity-centric. As explained before, we group entity mentions s i referring to the same entity into clusters C k . While we can, and will, adopt the traditional coreference measures as defined by <ref type="bibr" target="#b63">Pradhan et al. (2014)</ref> to judge this cluster formation, the NER and relation extraction (RE) evaluation (using precision, recall and F 1 ) can be done either on (i) mention level, or (ii) entity (cluster) level. The first option however would have the metrics being dominated by the more frequently occurring entities, while the second would penalize mistakes in the clustering (since partially correctly identified clusters would be seen as completely incorrect). This is illustrated in <ref type="figure" target="#fig_3">Fig. 4</ref> and the corresponding performance metrics in <ref type="table" target="#tab_10">Table 6</ref>, where scenarios 1 and 2 highlight the effect of making labeling mistakes on the cluster level for different sizes, and scenario 3 highlights the pessimistic view of hard entity-level metrics in case of clustering mistakes. Note that we indicate the mention-level metrics with subscript m, while the (hard) entity-level metrics will have subscript with e.</p><p>Because the (hard) entity-level metrics in our opinion overly penalize clustering mistakes (cf. scenario 3), we propose a variant of entity-level evaluation which we term soft entity-level metrics (denoted by subscript s). Basically, instead of adopting a binary count of 1 (all mentions correct) or 0 (as soon as a single mention is missed) on an entity cluster level, we rather count the fraction of its mentions that are correctly labeled. This is illustrated in the formula part of <ref type="figure" target="#fig_3">Fig. 4(a)</ref> for NER, and below we present the adopted formulas in detail. Note that in case clusters are completely predicted correctly, the soft entity-level metrics are the same as hard entity-level metrics (and thus avoid the metric being dominated by frequent mentions, as in the mention-level case).</p><p>The formal definition of the metrics depends on counting true positives tp p (l) and tp g (l), false positives fp(l), and false negatives fn(l) for a particular NER tag/relation type l, which are specified in Eq. (24)-(25). These and other notation definitions are summarized in <ref type="table" target="#tab_6">Table 8</ref>. Further, note that we define two true positives for a particular label l, because of the potential difference between predicted and ground truth clusters: tp p (l) sums fractions of predicted clusters and is used to calculate the precision Pr s in Eq. (26), while tp g (l) considers ground truth clusters and is used for the recall Re s in Eq. (26). This allows us to preserve the cluster-based relationships between true positives, false positives and false negatives as described for expressions tp p (l) + fp(l) and tp g (l) + fn(l) in <ref type="table" target="#tab_10">Table 7</ref>. Thus our soft entity-level metrics are still clusterbased, while accounting for the mention-level predictions.  <ref type="figure">and (b)</ref> relation extraction, with large clusters (C 1 , C 3 ) and smaller ones (C 2 , C 4 ). Scenario 1 erroneously labels the large one, scenario 2 incorrectly labels the small one, scenario 3 incorrectly splits up the large one and makes a mistake for one of its mentions, s 9 . The formulas in the grey box illustrate the calculation of mention-level (Prm, Rem), hard entity-level (Pre, Ree) and soft entity-level (Prs, Res) precision and recall for NER in scenario 3. Note that in (b), the mention dots are colored for correct (green) and incorrect (red) relation heads only. <ref type="table" target="#tab_10">Table 6</ref>: Comparison of different metrics for the example scenarios depicted in <ref type="figure" target="#fig_3">Fig. 4, for (a) NER and (b)</ref> relation extraction.</p><formula xml:id="formula_22">tp p (l) = Cp?P C (l) |C p ? G M (l)| |C p | , tp g (l) = Cg?G C (l) |C g ? P M (l)| |C g | (24) fp(l) = |P C (l)| ? tp p (l), fn(l) = |G C (l)| ? tp g (l)<label>(25)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mention-Level Hard Entity-Level Soft Entity-Level</head><p>Pr m Re m F 1,m Pr s Re s F 1,s Pr e Re e F 1,e</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) NER</head><p>Ground Truth 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 Scenario 1 0.143 0.100 0.118 0.600 0.500 0.545 0.600 0.500 0.545 Scenario 2 0.931 0.900 0.915 0.600 0.500 0.545 0.600 0.500 0.545 Scenario 3 1.000 0.900 0.947 0.333 0.500 0.400 1.000 0.944 0.971</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) RE</head><p>Ground Truth 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 Scenario 1 1.000 0.027 0.053 1.000 0.500 0.667 1.000 0.500 0.667 Scenario 2 1.000 0.973 0.986 1.000 0.500 0.667 1.000 0.500 0.667 Scenario 3 0.983 0.783 0.872 0.000 0.000 0.000 0.889 0.889 0.889 <ref type="table" target="#tab_10">Table 7</ref>: The relations between the weighted true positives by the size of predicted (tp p (l)) and ground truth (tp g (l)) entity clusters allows us to achieve the constraints needed for the denominators of precision (tp p (l) + fp(l)) and recall (tp p (l) + fn(l)) functions (Eq. (26)) in terms of the number of entity clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Expression (a) Meaning for NER (b) Meaning for RE</head><p>tp p (l) + fp(l) Number of predicted entity clusters with tag l. Number of predicted relations of type l between entity clusters.</p><p>tp g (l) + fn(l) Number of ground truth entity clusters with tag l.</p><p>Number of ground truth relations of type l between entity clusters.</p><p>Our soft entity-level precision, recall and F 1 metrics are formally defined as follows, where L refers to either the number of all possible tags for NER or the number of all possible relation types for RE:</p><formula xml:id="formula_23">Pr s = L l=1 tp p (l) L l=1 tp p (l) + fp(l) , Re s = L l=1 tp g (l) L l=1 tp g (l) + fn(l)</formula><p>, F 1,s = 2 ? Pr s ? Re s Pr s + Re s (26)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Experimental Setup</head><p>We train and evaluate our model as described in Section 4 on three tasks: NER, coreference, and relation extraction (RE) independently and jointly. We experiment with three main model variations:</p><p>1. Single: Experiments on individual tasks by training with the respective loss functions as described in Section 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Joint:</head><p>Experiments jointly on all three tasks using pre-trained GloVe representations 15 concatenated to character embeddings in the shared input layer (see <ref type="figure" target="#fig_2">Fig. 3</ref>). For training we use the joint loss defined in Section 4.2.</p><p>3. Joint+BERT: as in the Joint setting, experiments jointly on all three tasks, but using pre-trained BERT BASE embeddings 16 concatenated to the GloVe and character embeddings. We use an input window size of 250 tokens and concatenate the last 2 hidden layers of BERT to get token representations.</p><p>Additionally, for each of the three model setups we experiment with the graph propagation techniques defined in Section 4.4. To maximize result consistency, we train each model 5 times and report the average of these 5 results for each of the experiments. We use a single-layer BiLSTM with forward and backward hidden states of 200 dimensions each. All our FFNNs used to obtain confidence scores (F pruner , F coref , F mention , F relation , and F att ) have two 150dimensional hidden layers trained with a dropout of 0.4. We set the maximum span width w max to 5 and the pruner ratio to 0.2 of the total number of tokens in a document. For training, we use Adam with a learning rate of 1e?3 for 100 epochs with a linear decay of 0.1 starting at epoch 15. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Symbol (a) Meaning for NER (b) Meaning for RE</head><p>PC (l) Set of predicted entity clusters with tag l. Set of predicted relations of type l between the predicted entity clusters.</p><p>Cp ? PC (l) Set of predicted entity mentions for a particular entity cluster in PC (l).</p><p>Set of relations between the predicted entity mentions for a particular pair of related entity clusters in PC (l).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GC (l)</head><p>Set of ground truth entity clusters annotated with tag l.</p><p>Set of ground truth relations of type l between the ground truth entity clusters.</p><p>Cg ? GC (l) Set of ground truth entity mentions for a particular entity cluster in GC (l).</p><p>Set of relations between the ground truth entity mentions for a particular pair of related entity clusters in GC (l) PM (l) Set of predicted entity mentions with tag l. Set of predicted relations of type l between the predicted entity mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GM (l)</head><p>Set of ground truth entity mentions annotated with tag l.</p><p>Set of ground truth relations of type l between the ground truth entity mentions.</p><p>tp p (l)</p><p>Number of true positive predictions of tag l on mentions re-weighted by predicted cluster sizes.</p><p>Number of true positive predictions of relation type l between mentions re-weighted by the number of mention level relations between the connected pairs of predicted clusters.</p><p>tp g (l)</p><p>Number of true positive mention level predictions of tag l re-weighted by ground truth cluster sizes.</p><p>Number of true positive predictions of relation type l between mentions re-weighted by the number of mention level relations between the connected pairs of ground truth clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>fp(l)</head><p>Number of false positive mention level predictions of tag l re-weighted by predicted cluster sizes.</p><p>Number of false positive predictions of relation type l between mentions re-weighted by the number of mention level relations between the connected pairs of predicted clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>fn(l)</head><p>Number of false negative mentions with ground truth tag l re-weighted by ground truth cluster sizes.</p><p>Number of false negative relations of type l between mentions re-weighted by the number of mention level relations between the connected pairs of ground truth clusters.  <ref type="table" target="#tab_7">Table 9</ref> gives an overview of the results achieved in Single as well as Joint and Joint + BERT setups. Additionally, <ref type="figure" target="#fig_4">Fig. 5</ref> illustrates the impact of the number of graph propagation iterations for each of the span graph propagation methods on the final results.</p><p>First, we observe a general improvement in all our Single tasks when using graph propagation techniques. More specifically, our proposed latent AttProp achieves superior results compared to the relation (RelProp) and coreference (CorefProp) propagations when added to the Single setup. The biggest improvement across iterations (see <ref type="figure" target="#fig_4">Fig. 5</ref>) is for the single RE task mention-level F 1,m score with a boost of ?3 percentage points when incorporating AttProp. We also observe an improvement of ?1.5 percentage points in F 1,m for the NER task and a consistent but smaller improvement of 0.5 F 1 percentage points for the coreference task. These results illustrate the effectiveness of AttProp when applied to single task models.</p><p>A further improvement in results is achieved by training our model jointly (see the Joint setup in <ref type="table" target="#tab_7">Table 9</ref> and graphs in <ref type="figure" target="#fig_4">Fig. 5</ref>) for NER and RE tasks. This illustrates that, besides the positive effect of neural graph propagation on single task models, training our model jointly has an additional benefit by exploiting the interaction between tasks. In particular, this effect can be seen for RE, where our Joint model achieves a boost in performance of 0.8 percentage points for the mention-level F 1,m metric compared to the best result for the Single setup. Furthermore, our AttProp graph propagation method achieves the best performance on all the metrics for the RE task in the Joint setting with up to ? 5.5 percentage points improvement in our newly proposed F 1,s metric. Additionally, we observe a beneficial effect of graph propagation for the NER task in the Joint setup with slightly better results for the F 1,m metric compared to the Single setting. Our AttProp technique performs on par with CorefProp, outperforming the latter by a small margin in terms of F 1,s metric.</p><p>Similarly to the Joint model variation, we observe benefits when using graph propagation techniques in the Joint+BERT models. <ref type="table" target="#tab_8">Table 10</ref> illustrates the deltas in performance for the NER and relation extraction tasks. This way, we can see more clearly the difference in impact of our neural message passing methods grouped by the model setup and metric type. First, we observe that the general performance boost from using graph propagation techniques is lower in Joint+BERT than in the Joint setup. We hypothesize that this effect is due to the fact that BERT itself has a better long-range context extraction due to the attention-based mechanism, which spans the input window as opposed to purely local (non-contextualized) GloVe embeddings used in the Joint setting. This is in line with the findings in <ref type="bibr" target="#b30">Han &amp; Wang (2020)</ref>, <ref type="bibr" target="#b77">Wadden et al. (2019)</ref>, and <ref type="bibr" target="#b86">Wu &amp; He (2019)</ref> that show the advantage of using large BERT input window sizes to produce better IE results. Second, we observe that our AttProp method achieves consistently superior performance on our proposed soft entity-level metric F 1,s , capturing thus better the mention-based predictions as weighted by their cluster sizes. Finally, from We hypothesize that this is due to the fact that RelProp propagation can capture relational semantics that goes beyond BERT's contextual span representation similarity (which mainly drives the positive impact of Joint+BERT ). Unlike for the NER and RE tasks, where we observe a consistent positive impact of span graph propagation and joint modeling across all our experiments, the impact on the coreference task is not clear. Our experiments on Single setup show small, but constant improvement of the Avg.-F 1 score with the number of AttProp propagation iterations (see <ref type="figure" target="#fig_4">Fig. 5</ref>). However, in our Joint and Joint+BERT setups the graph propagation appears to not have any positive impact on Avg.-F 1 coreference scores. We hypothesize that the main reason for this phenomenon lies in the coreference annotations in DWIE: since we only annotate clusters of proper nouns, leaving out the nominal (e.g., "the prime minister") and anaphoric expressions (e.g., "he", "she", "they", etc), there might be little to no additional benefit in propagating information between co-referenced entity mentions, since the representation of proper nouns likely is not much influenced by textual context (e.g., the span "Merkel" can have very similar span representation to "Angela Merkel", gaining nothing in adding contextual graph propagation).</p><p>Additionally, we explore in more detail the effect of the number of AttProp, CorefProp, RelProp graph propagation iterations on the final F 1 score of all the tasks in <ref type="figure" target="#fig_4">Fig. 5</ref>. We observe that the number of iterations have a decreasing effect on the improvement of performance for the NER and RE tasks. Furthermore, the positive effect of CorefProp and RelProp tends to saturate or even become negative after 1 or 2 iterations. This is in line with findings of <ref type="bibr" target="#b55">Luan et al. (2019)</ref> on other datasets, where the performance peak is usually achieved at 2 graph propagation iterations. For our AttProp however, we observe that the positive effect of additional iterations tends to persist longer, particularly on the Joint setup where the positive effect of AttProp seems to be still growing after the last iteration (3) in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions and Future Work</head><p>In this work we introduced DWIE, a manually annotated multi-task dataset that comprises Named Entity Recognition, Coreference, Relation Extraction and Entity Linking as main tasks. We highlight how DWIE is different from the mainstream datasets by focusing on document-level and entity-centric annotations. This also makes the predictions on this dataset more challenging by having not only to consider explicit, but also implicit document-level interactions between entities. Furthermore, we showed how Graph Neural Networks can help to tackle this issue by propagating local contextual mention span information on a document level for a single task as well as across the tasks on the DWIE dataset. We experiment with known graph propagation techniques driven by the scores of the coreference resolution (CorefProp) and relation extraction (RelProp) components, as well as introduced a new latent task-independent attentionbased graph propagation method (AttProp). We demonstrated that, without relying on the task-specific scorers, AttProp can boost the performance of single-task as well as joint models, performing on par and even outperforming significantly in some scenarios the RelProp and CorefProp graph propagations. In future work we will aim to integrate an entity linking component into our joint architecture. As a consequence, we expect to obtain a further boost in performance of different tasks included in DWIE by taking advantage of the information coming from Wikipedia 2018, the reference knowledge base for the entity linking annotations. Conversely, we conjecture that the results of the entity linking component can be improved when training it jointly with other tasks, such as NER and coreference resolution. Finally, we plan extending the coreference annotations to include nominal and anaphoric expressions. We expect that including these diverse mention types, whose initial span embedding representation can be different from coreferenced named entities, will make our coreference resolution task more challenging, allowing to investigate further the potential benefits of using graph-based neural networks.   <ref type="table" target="#tab_10">Table A</ref>.3 describes the statistics of linked entities with respect to the total number of entities in each of the Entity subtypes. The columns % Linked Entities and % Linked Mentions indicate the percentage of annotated linked entities and mentions with respect to the total number of annotated entities/mentions in a particular Entity type category. Furthermore, we calculate two accuracies on test split when linking the entity mention with the most frequent entity link used either in DWIE: (i) training set of DWIE dataset ("Acc. Prior Train"), or (ii) Wikipedia corpus ("Acc. Prior Wiki"). Overall, using prior linking annotations from Wikipedia gives 9 percentage points better performance (79.0%) than when using train set (70.0%). This difference is explained by the fact that Wikipedia has much larger corpus to calculate the prior linking information from. Nevertheless, we still observe that for some entity types such as sport team and media the accuracy based on DWIE training set prior is higher. This suggests the use of domain-specific language to refer to some entities in DWIE not used in a more general Wikipedia domain.  <ref type="table" target="#tab_10">Table A</ref>.4 illustrates the number of annotated entities and mentions per each tag category (type, topic, iptc, gender and slot). It also showcases the multi-label nature of entity classification task in DWIE, with the average number of labels per entity of 4.0. <ref type="table" target="#tab_10">Table A</ref>.5 illustrates the number and percentage of related entities and mentions of our dataset grouped by the number of relation labels. It also compares with other entity-centric RE datasets, namely BC5CDR <ref type="bibr" target="#b50">(Li et al., 2016a;</ref><ref type="bibr" target="#b82">Wei et al., 2015)</ref> and DocRED <ref type="bibr" target="#b89">(Yao et al., 2019)</ref> datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Inter-annotator agreement calculations</head><p>In order to measure the agreement we use Cohen's kappa coefficient <ref type="bibr" target="#b17">(Cohen, 1960)</ref>, defined as</p><formula xml:id="formula_24">? = po ? pe 1 ? pe (B.1)</formula><p>where po represents the observed agreement between the two annotators and pe is the expected agreement between the annotators (i.e., agreement by chance). More specifically, in our case we calculate the observed probability po as in <ref type="figure" target="#fig_0">Eq. (B.2)</ref> where N is the number of annotated items, Ai,j is the annotation made by annotator i for item j, and 1{A1,j = A2,j} returns 1 if A1,j is equal to A2,j and 0 otherwise. Thus, po can be interpreted as the fraction of the labels two annotators agree, also called percent agreement <ref type="bibr" target="#b58">(McHugh, 2012;</ref><ref type="bibr" target="#b70">Scott, 1955)</ref>.</p><formula xml:id="formula_25">po = N j=1 1{A1,j = A2,j} N (B.2)</formula><p>To calculate the expected agreement probability we use the formulation in Eq. (B.3). It can be interpreted as the probability that both annotators, when randomly distributing all of their label annotations among the items to be annotated, assign the same label to a given item. pe = L l=1 n 1,l N n 2,l N (B.3)</p><p>In this context, n i,l is the number of items the annotator i annotated with label l and L is the total number of labels. For multi-label annotations where it is possible to assign multiple classes for a particular annotation item (i.e., named entity and relation types), we report a weighted kappa score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C. Relation consistency rules</head><p>This appendix enumerates the logical predicates used as a consistency check in our dataset. in0- </p><formula xml:id="formula_26">x X, Z ? gpe0 Z, Y =? in0 X, Y (C.23) in0 X, Y ? gpe0 Z, Y =? in0-x X, Z (C.24) in2 X, Z ? in0 Z, Y =? in0 X, Y (C.25) in1 X, Z ? in0 Z, Y =? in0 X, Y (C.26) based in2 X, Z ? in0 Z, Y =? based in0 X, Y (C.27) based in1 X, Z ? in0 Z, Y =? based in0 X, Y (C.28) agency of X, Y ? gpe0 Y =? based in0 X, Y (C.29) event in2 X, Z ? in0 Z, Y =? event in0 X, Y (C.30) event in1 X, Z ? in0 Z, Y =? event in0 X,</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Comparison of the coverage of the % of relations with increasing interval in tokens (left) and interval in sentences</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>in0 Athens, Greece "The murder of a left-wing activist in Athens has shaken up Greece and inspired a backlash." citizen of Relations between people and the country they are citizens of, ex: citizen of Guerrero, Peru "Even as a teenager, Guerrero played for the national side in his native Peru." based in0-x Relations between organizations and the nominal variations of the countries they are based in, ex: based in0-x SPD, German "SPD denies 'green light' for new German government, but keeps options open" citizen of-x Relations between people and the nominal variations of the countries they are citizens of, ex: citizen of-x Assange, Australian "Australian national Assange said the accusations were politically motivated."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Architecture of our model; the span-oriented approach makes it possible to execute coreference (Section 4.2.2) and relation (Section 4.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Illustration of entity prediction scenarios for (a) NER</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Impact of AttProp, CorefProp and RelProp graph propagations on performance metrics for each of the Single, Joint and Joint+BERT model setups. Note the different Y-axis scales.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>spouse of Y, X =? spouse of X, Y (C.1) vs Y, X =? vs X, Y (C.2) won vs X, Y =? vs X, Y (C.3) won vs X, Y =? vs Y, X (C.4) child of Y, X =? parent of X, Y (C.5) parent of Y, X =? child of X, Y (C.6) ministry of X, Y =? agency of X, Y (C.7) agency of-x X, Z ? gpe0 Z, Y =? agency of X, Y (C.8) agency of X, Y ? gpe0 Z, Y =? agency of-x X, Z (C.9) agent of-x X, Z ? gpe0 Z, Y =? agent of X, Y (C.10) agent of X, Y ? gpe0 Z, Y =? agent of-x X, Z (C.11) minister of X, Y =? agent of X, Y (C.12) head of gov X, Y =? agent of X, Y (C.13) head of state X, Y =? agent of X, Y (C.14) citizen of-x X, Z ? gpe0 Z, Y =? citizen of X, Y (C.15) citizen of X, Y ? gpe0 Z, Y =? citizen of-x X, Z (C.16) minister of-x X, Z ? gpe0 Z, Y =? minister of X, Y (C.17) minister of X, Y ? gpe0 Z, Y =? minister of-x X, Z (C.18) head of state-x X, Z ? gpe0 Z, Y =? head of state X, Y (C.19) head of state X, Y ? gpe0 Z, Y =? head of state-x X, Z (C.20) head of gov-x X, Z ? gpe0 Z, Y =? head of gov X, Y (C.21)head of gov X, Y ? gpe0 Z, Y =? head of gov-x X, Z (C.22)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Y (C.31) head of X, Y =? member of X, Y (C.32) coach of X, Y =? member of X, Y (C.33) spokesperson of X, Y =? member of X, Y (C.34) member of X, Y ? sport player X =? player of X, Y (C.35) mayor of X, Y =? head of gov X, Y (C.36) directed by X, Y =? created by X, Y (C.37) character in X, Y ? played by X, Z =? plays in Z, Y (C.38) institution of X, Y =? part of X, Y (C.39) based in0-x X, Z ? gpe0 Z, Y =? based in0 X, Y (C.40) based in0 X, Y ? gpe0 Z, Y =? based in0-x X, Z (C.41)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>Numerical comparison of DWIE and well-known IE datasets. Note that some datasets (including DWIE) use an entity-centric approach, organizing entity mentions in entity clusters, and annotating entities, relations, and linking on the cluster level. Hence, we provide both mention-level as well as cluster-level (if a particular dataset supports it) statistics.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Entities</cell><cell></cell><cell></cell><cell>Relations</cell><cell></cell><cell cols="2">Linking</cell></row><row><cell>Dataset</cell><cell cols="9"># Tokens # Mentions # Entity # Entity # Relation # Relation # Relation # Mention # Cluster</cell></row><row><cell></cell><cell></cell><cell></cell><cell>clusters</cell><cell>types</cell><cell>mentions</cell><cell>clusters</cell><cell>types</cell><cell>KB Links</cell><cell>KB Links</cell></row><row><cell>NYT</cell><cell cols="2">5,765,332 1,388,982</cell><cell>-</cell><cell>-</cell><cell>142,823</cell><cell>-</cell><cell>52</cell><cell>1,388,982</cell><cell>-</cell></row><row><cell>TACRED</cell><cell cols="2">3,866,863 -</cell><cell>-</cell><cell>-</cell><cell>21,784</cell><cell>-</cell><cell>42</cell><cell>-</cell><cell>-</cell></row><row><cell>TAC-KBP 6</cell><cell cols="2">3,053,336 6,495</cell><cell>3,750</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>3,818</cell><cell>2,094</cell></row><row><cell cols="3">OntoNotes 5.0 2,088,832 161,783</cell><cell>136,037</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>FewRel 7</cell><cell cols="2">1,397,333 114,213</cell><cell>112,000</cell><cell>-</cell><cell>58,267</cell><cell>56,000</cell><cell>80</cell><cell>114,213</cell><cell>112,000</cell></row><row><cell>DocRED</cell><cell cols="2">1,018,297 132,392</cell><cell>98,610</cell><cell>6</cell><cell>155,535</cell><cell>50,503</cell><cell>96</cell><cell>-</cell><cell>-</cell></row><row><cell>MUC-4</cell><cell>717,798</cell><cell>14,196</cell><cell>-</cell><cell>13</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>GENIA</cell><cell>554,346</cell><cell>56,743</cell><cell>10,728</cell><cell>5</cell><cell>2,337</cell><cell>-</cell><cell>2</cell><cell>-</cell><cell>-</cell></row><row><cell>DWIE</cell><cell>501,095</cell><cell>43,373</cell><cell>23,130</cell><cell>311</cell><cell>317,204</cell><cell>21,749</cell><cell>65</cell><cell>28,482</cell><cell>13,086</cell></row><row><cell>BC5CDR</cell><cell>343,175</cell><cell>29,271</cell><cell>10,326</cell><cell>2</cell><cell>47,813</cell><cell>3,116</cell><cell>1</cell><cell>29,562</cell><cell>10,326</cell></row><row><cell>CoNLL-2003</cell><cell>301,418</cell><cell>35,089</cell><cell>-</cell><cell>4</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">CoNLL-YAGO 301,418</cell><cell>34,929</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>34,929</cell><cell>-</cell></row><row><cell>ACE 2005</cell><cell>259,889</cell><cell>54,824</cell><cell>37,622</cell><cell>51</cell><cell>8,419</cell><cell>7,786</cell><cell>18</cell><cell>-</cell><cell>-</cell></row><row><cell>ACEtoWiki</cell><cell>259,889</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>16,310</cell><cell>-</cell></row><row><cell cols="2">SEval 2010 T8 207,307</cell><cell>21,434</cell><cell>-</cell><cell>-</cell><cell>6,674</cell><cell>-</cell><cell>9</cell><cell>-</cell><cell>-</cell></row><row><cell>ACE 2004</cell><cell>185,696</cell><cell>29,949</cell><cell>12,507</cell><cell>43</cell><cell>5,976</cell><cell>5,525</cell><cell>24</cell><cell>-</cell><cell>-</cell></row><row><cell>WNUT 2017</cell><cell>101,857</cell><cell>3,890</cell><cell>-</cell><cell>6</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>ScienceIE</cell><cell>99,580</cell><cell>9,946</cell><cell>9,536</cell><cell>3</cell><cell>638</cell><cell>-</cell><cell>1</cell><cell>-</cell><cell>-</cell></row><row><cell>SciERC</cell><cell>65,334</cell><cell>8,094</cell><cell>1,015</cell><cell>6</cell><cell>2,687</cell><cell>-</cell><cell>7</cell><cell>-</cell><cell>-</cell></row><row><cell cols="6">traditionally used jointly annotated datasets such as ACE 2005</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Descriptions and Examples (with entity mentions underlined) of each of the most granular entity classes in DWIE (EN-TITY, VALUE and OTHER) in the type tag hierarchy. Additionally, for the type ENTITY, we describe and give examples of each of its direct subtypes(location, organization, person, misc, event and ethnicity).</figDesc><table><row><cell>Entity Tag</cell><cell>Description</cell><cell>Example</cell></row><row><cell>ENTITY</cell><cell>All nominal named entities.</cell><cell>"UK court rules WikiLeaks' Assange</cell></row><row><cell></cell><cell></cell><cell>should be extradited to Sweden"</cell></row><row><cell>location</cell><cell>Entities referring to a particular geograph-</cell><cell></cell></row><row><cell></cell><cell>ical location.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>"</cell></row><row><cell>misc</cell><cell>Miscellaneous entity types such as names</cell><cell>"According to the director's own words,</cell></row><row><cell></cell><cell>of work of arts, treaties, product names,</cell><cell>The Post is a 'patriotic film'."</cell></row><row><cell></cell><cell>etc.</cell><cell></cell></row><row><cell>event</cell><cell>Events such as sport competitions, sum-</cell><cell>"Last year's Champions League final drew</cell></row><row><cell></cell><cell>mits, etc.</cell><cell>a crowd of just 14,303."</cell></row><row><cell>ethnicity</cell><cell>Entity type used to identify different ethnic</cell><cell></cell></row><row><cell></cell><cell>groups.</cell><cell></cell></row></table><note>"Libya is one of Germany's strongest trad- ing partners in northern Africa." organization Organizations such as companies, govern- mental organizations, etc."According to the report, Amazon would pay the same level of royalty fees as Apple." person Entities referring to people in general such as politicians, artists, sport players, etc."With Ramires out, Drogba could start as striker, with Torres moving to the wing."Attempt to assimilate Uyghurs into dom- inant Han Chinese culture." VALUE Values in general such as time, money, etc. "It ended the 2014 fiscal year 45 million euros ($51 million) in the red."</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 :</head><label>4</label><figDesc>Descriptions and Examples of the top 5 most occurring relation types in DWIE. The entity mentions involved in the relations are underlined.</figDesc><table><row><cell>Relation Type</cell><cell>Description</cell><cell>Example</cell></row><row><cell>based in0</cell><cell>Relations between organizations and</cell><cell>"Now he's back in Germany carrying</cell></row><row><cell></cell><cell>the countries they are based in, ex:</cell><cell>on with his cancer research at the</cell></row><row><cell></cell><cell>based in0 University of Cologne, Germany</cell><cell>University of Cologne."</cell></row><row><cell>in0</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 :</head><label>5</label><figDesc>The inter-annotation agreement Cohen's kappa scores for all the different annotation tasks before and after the dataset refinement used to analyze and correct the discrepancies between the parallel annotations.</figDesc><table><row><cell>Task</cell><cell cols="2">Before Refinement After Refinement</cell></row><row><cell>Named Entity</cell><cell>0.8497</cell><cell>0.8703</cell></row><row><cell>Named Entity Detection</cell><cell>0.9665</cell><cell>0.9673</cell></row><row><cell>Named Entity Classification</cell><cell>0.8812</cell><cell>0.9026</cell></row><row><cell>Coreference</cell><cell>0.9302</cell><cell>0.9324</cell></row><row><cell>Entity Linking</cell><cell>0.9280</cell><cell>0.9320</cell></row><row><cell>Relation</cell><cell>0.6594</cell><cell>0.8729</cell></row><row><cell>Relation Detection</cell><cell>0.7686</cell><cell>0.8727</cell></row><row><cell>Relation Classification</cell><cell>0.8118</cell><cell>0.9666</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Entity-centric decoder for the Joint model.</figDesc><table><row><cell cols="2">Input: predicted clusters (p cl), entity mentions (p men) and relations between mentions (p rel):</cell></row><row><cell></cell><cell>1. p cl is a dictionary (map) that maps cluster ids to mention spans</cell></row><row><cell></cell><cell>2. p men is list of tuples predicted span, predicted tag</cell></row><row><cell></cell><cell>3. p rel is list of tuples predicted head span, predicted relation, predicted tail span</cell></row><row><cell>4:</cell><cell>if span not in C.keys() then</cell></row><row><cell>5:</cell><cell>C[span] ? new concept id</cell></row><row><cell>6:</cell><cell>p cl[C[span]] ? list([span])</cell></row><row><cell>7:</cell><cell>end if</cell></row><row><cell>8:</cell><cell>if C[span] not in d ent.keys() then</cell></row><row><cell>9:</cell><cell>d ent[C[span]] ? empty set</cell></row><row><cell>10:</cell><cell>end if</cell></row><row><cell>11:</cell><cell>d ent[C[span]].add(tag)</cell></row><row><cell cols="2">12: end for</cell></row><row><cell></cell><cell>Decode relations between mentions (p rel) to relations between entities (d rel) (lines 13-20)</cell></row><row><cell cols="2">13: for span h, rel type, span t in p rel do</cell></row><row><cell>14:</cell><cell>if (span h in C.keys()) and (span t in C.keys()) then</cell></row><row><cell>15:</cell><cell>if C[span h], C[span t] not in d rel.keys() then</cell></row><row><cell>16:</cell><cell>d rel[ C[span h], C[span t] ] ? empty set</cell></row><row><cell>17:</cell><cell>end if</cell></row><row><cell>18:</cell><cell>d rel[ C[span h], C[span t] ].add(rel type)</cell></row><row><cell>19:</cell><cell></cell></row></table><note>are used. This means the confidence scores not only reflect whether Algorithm 1Output: clusters (p cl), decoded entities (d ent) and relations between entities (d rel)1: Initialize d ent, d rel ? empty dictionary (map)2: C ? transformed p cl that maps spans to cluster ids Decode entity mentions (p men) to entities (d ent) (lines 3-12)3: for span, tag in p men do</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>are applied. RelProp -Similarly as with CorefProp, a relation span update vector is calculated as formalized next,</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 :</head><label>8</label><figDesc>Short definition of the symbols and expressions involved in our soft-entity level metric formulation in Eq. (24)-(26) for both NER and RE tasks.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9 :</head><label>9</label><figDesc>Main results of the experiments grouped in three model setups: (i) Single models trained individually, (ii) Joint model trained using as input GloVe and character embeddings, and (iii) Joint+BERT model trained on BERT BASE embeddings. To report the results, we use MUC, CEAFe, B 3 as well as the average (Avg.) of these three metrics for coreference resolution. For NER and RE we use mention-level (F 1,m ), hard entity-level (F 1,e ), and soft entity-level (F 1,s ) metrics described in Section 5. In bold we mark the best results for each model setup, the best overall results are underlined. Note that the metrics are expressed in percentage points.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Coreference F 1</cell><cell></cell><cell cols="2">NER F 1</cell><cell></cell><cell></cell><cell>RE F 1</cell><cell></cell></row><row><cell cols="5">Model Setup MUC CEAF e B 3 Avg.</cell><cell cols="3">F 1,m F 1,e F 1,s</cell><cell cols="3">F 1,m F 1,e F 1,s</cell></row><row><cell>Single</cell><cell>92.8</cell><cell>90.9</cell><cell cols="2">88.2 90.6</cell><cell>85.7</cell><cell>-</cell><cell>-</cell><cell>68.2</cell><cell>-</cell><cell>-</cell></row><row><cell>+AttProp</cell><cell>93.2</cell><cell>91.5</cell><cell cols="2">88.7 91.1</cell><cell>87.1</cell><cell>-</cell><cell>-</cell><cell>71.3</cell><cell>-</cell><cell>-</cell></row><row><cell>+CorefProp</cell><cell>92.8</cell><cell>90.9</cell><cell cols="2">88.3 90.7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>+RelProp</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>68.2</cell><cell>-</cell><cell>-</cell></row><row><cell>Joint</cell><cell>92.5</cell><cell>90.5</cell><cell cols="2">87.3 90.1</cell><cell cols="3">85.4 71.7 84.4</cell><cell cols="3">68.1 46.8 66.5</cell></row><row><cell>+AttProp</cell><cell>92.3</cell><cell>90.4</cell><cell cols="2">87.3 90.0</cell><cell cols="3">87.1 72.9 86.1</cell><cell cols="3">72.1 50.4 72.1</cell></row><row><cell>+CorefProp</cell><cell>92.3</cell><cell>90.3</cell><cell cols="2">87.2 89.9</cell><cell cols="3">87.2 73.2 86.0</cell><cell cols="3">71.6 50.2 71.0</cell></row><row><cell>+RelProp</cell><cell>92.6</cell><cell>90.2</cell><cell cols="2">86.8 89.9</cell><cell cols="3">86.7 72.4 85.2</cell><cell cols="3">69.5 48.2 68.8</cell></row><row><cell>Joint+BERT</cell><cell>93.8</cell><cell>92.1</cell><cell cols="2">89.0 91.6</cell><cell cols="3">87.6 74.2 86.4</cell><cell cols="3">70.6 48.7 68.9</cell></row><row><cell>+AttProp</cell><cell>93.2</cell><cell>91.4</cell><cell cols="2">88.6 91.1</cell><cell cols="3">88.8 74.2 87.7</cell><cell cols="3">72.3 50.4 73.0</cell></row><row><cell>+CorefProp</cell><cell>93.5</cell><cell>91.8</cell><cell cols="2">88.7 91.3</cell><cell cols="3">88.7 74.4 87.4</cell><cell cols="3">72.7 50.0 71.9</cell></row><row><cell>+RelProp</cell><cell>93.7</cell><cell>91.8</cell><cell cols="2">88.7 91.4</cell><cell cols="3">88.4 74.8 87.0</cell><cell cols="3">72.0 49.9 71.4</cell></row><row><cell cols="2">6.2. Results and Analyses</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10 :</head><label>10</label><figDesc>Deltas of improvement in performance for each of the graph propagation methods (AttProp, CorefProp, RelProp) in F 1 scores for (a) NER and (b) relation extraction tasks.</figDesc><table><row><cell></cell><cell></cell><cell>Joint</cell><cell cols="3">Joint+BERT</cell></row><row><cell></cell><cell></cell><cell>F 1,m F 1,e F 1,s</cell><cell cols="3">F 1,m F 1,e F 1,s</cell></row><row><cell></cell><cell>? AttProp</cell><cell>1.69 1.18 1.67</cell><cell cols="3">1.16 ?0.02 1.31</cell></row><row><cell>(a) NER</cell><cell cols="2">? CorefProp 1.78 1.50 1.54</cell><cell>1.05</cell><cell>0.20</cell><cell>1.02</cell></row><row><cell></cell><cell>? RelProp</cell><cell>1.33 0.70 0.75</cell><cell cols="3">0.78 0.56 0.60</cell></row><row><cell></cell><cell>? AttProp</cell><cell>3.97 3.62 5.56</cell><cell cols="3">1.66 1.69 4.05</cell></row><row><cell>(b) RE</cell><cell cols="2">? CorefProp 3.48 3.45 4.47</cell><cell cols="2">2.02 1.29</cell><cell>2.95</cell></row><row><cell></cell><cell>? RelProp</cell><cell>1.35 1.47 2.32</cell><cell>1.37</cell><cell>1.20</cell><cell>2.48</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10</head><label>10</label><figDesc>(b)  we notice that adding BERT to our joint model does not affect the boost in performance caused by the RelProp method for relation extraction.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table A .</head><label>A</label><figDesc>1: Statistics depicting the hierarchical structure of entity types described in Section 3.2. Only the most frequent entity types/subtypes are shown (% Mentions &gt; 0.5%)</figDesc><table><row><cell>Entity Type</cell><cell cols="4"># Entities % Entities # Mentions % Mentions</cell></row><row><cell>ENTITY</cell><cell>13,151</cell><cell>56.9 %</cell><cell>30,719</cell><cell>70.8 %</cell></row><row><cell>location</cell><cell>4,957</cell><cell>21.4%</cell><cell>11,548</cell><cell>26.6%</cell></row><row><cell>gpe</cell><cell>3,965</cell><cell>17.1%</cell><cell>9,830</cell><cell>22.7%</cell></row><row><cell>gpe0</cell><cell>2,225</cell><cell>9.6%</cell><cell>6,559</cell><cell>15.1%</cell></row><row><cell>gpe2</cell><cell>1,497</cell><cell>6.5%</cell><cell>2,873</cell><cell>6.6%</cell></row><row><cell>gpe1</cell><cell>244</cell><cell>1.1%</cell><cell>406</cell><cell>0.9%</cell></row><row><cell>regio</cell><cell>479</cell><cell>2.1%</cell><cell>916</cell><cell>2.1%</cell></row><row><cell>facility</cell><cell>259</cell><cell>1.1%</cell><cell>385</cell><cell>0.9%</cell></row><row><cell>organization</cell><cell>3,434</cell><cell>14.8%</cell><cell>8,165</cell><cell>18.8%</cell></row><row><cell>media</cell><cell>659</cell><cell>2.8%</cell><cell>984</cell><cell>2.3%</cell></row><row><cell>igo</cell><cell>547</cell><cell>2.4%</cell><cell>1,992</cell><cell>4.6%</cell></row><row><cell>so</cell><cell>171</cell><cell>0.7%</cell><cell>912</cell><cell>2.1%</cell></row><row><cell>party</cell><cell>381</cell><cell>1.6%</cell><cell>949</cell><cell>2.2%</cell></row><row><cell>company</cell><cell>368</cell><cell>1.6%</cell><cell>932</cell><cell>2.1%</cell></row><row><cell>sport team</cell><cell>367</cell><cell>1.6%</cell><cell>1,106</cell><cell>2.5%</cell></row><row><cell cols="2">governmental organization 342</cell><cell>1.5%</cell><cell>636</cell><cell>1.5%</cell></row><row><cell>agency</cell><cell>228</cell><cell>1.0%</cell><cell>444</cell><cell>1.0%</cell></row><row><cell>armed movement</cell><cell>108</cell><cell>0.5%</cell><cell>374</cell><cell>0.9%</cell></row><row><cell>person</cell><cell>3,390</cell><cell>14.7%</cell><cell>8,259</cell><cell>19.0%</cell></row><row><cell>politician</cell><cell>1,184</cell><cell>5.1%</cell><cell>3,326</cell><cell>7.7%</cell></row><row><cell>head of state</cell><cell>380</cell><cell>1.6%</cell><cell>1,271</cell><cell>2.9%</cell></row><row><cell>head of gov</cell><cell>247</cell><cell>1.1%</cell><cell>673</cell><cell>1.6%</cell></row><row><cell>minister</cell><cell>217</cell><cell>0.9%</cell><cell>458</cell><cell>1.1%</cell></row><row><cell>sport player</cell><cell>405</cell><cell>1.8%</cell><cell>844</cell><cell>1.9%</cell></row><row><cell>artist</cell><cell>260</cell><cell>1.1%</cell><cell>586</cell><cell>1.4%</cell></row><row><cell>politics per</cell><cell>209</cell><cell>0.9%</cell><cell>457</cell><cell>1.1%</cell></row><row><cell>manager</cell><cell>104</cell><cell>0.4%</cell><cell>297</cell><cell>0.7%</cell></row><row><cell>offender</cell><cell>75</cell><cell>0.3%</cell><cell>347</cell><cell>0.8%</cell></row><row><cell>misc</cell><cell>823</cell><cell>3.6%</cell><cell>1,646</cell><cell>3.8%</cell></row><row><cell>work of art</cell><cell>174</cell><cell>0.8%</cell><cell>247</cell><cell>0.6%</cell></row><row><cell>event</cell><cell>354</cell><cell>1.5%</cell><cell>701</cell><cell>1.6%</cell></row><row><cell>sport competition</cell><cell>183</cell><cell>0.8%</cell><cell>410</cell><cell>0.9%</cell></row><row><cell>ethnicity</cell><cell>84</cell><cell>0.4%</cell><cell>242</cell><cell>0.6%</cell></row><row><cell>VALUE</cell><cell>5,903</cell><cell>25.5 %</cell><cell>7,104</cell><cell>16.4 %</cell></row><row><cell>time</cell><cell>2,907</cell><cell>12.6%</cell><cell>3,608</cell><cell>8.3%</cell></row><row><cell>role</cell><cell>2,390</cell><cell>10.3%</cell><cell>2,865</cell><cell>6.6%</cell></row><row><cell>money</cell><cell>606</cell><cell>2.6%</cell><cell>631</cell><cell>1.5%</cell></row><row><cell>OTHER</cell><cell>2,724</cell><cell>11.8 %</cell><cell>5,482</cell><cell>12.6 %</cell></row><row><cell>gpe0-x</cell><cell>1,596</cell><cell>6.9%</cell><cell>3,827</cell><cell>8.8%</cell></row><row><cell>footer</cell><cell>413</cell><cell>1.8%</cell><cell>413</cell><cell>1.0%</cell></row><row><cell>loc-x</cell><cell>353</cell><cell>1.5%</cell><cell>585</cell><cell>1.3%</cell></row><row><cell>religion-x</cell><cell>235</cell><cell>1.0%</cell><cell>486</cell><cell>1.1%</cell></row><row><cell>TOTAL</cell><cell>23,130</cell><cell>100.0%</cell><cell>43,373</cell><cell>100.0%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Table A.2: Illustration of NER entity types in DWIE. Each cells contains possible entity subtypes (of different hierarchy levels) corresponding to the respective parent entity type (column) and topic (row).</figDesc><table><row><cell></cell><cell>person</cell><cell>organization</cell><cell>event</cell><cell>location</cell><cell>misc</cell></row><row><cell>politics</cell><cell>head of gov, head of state, minister,</cell><cell>politics institution, politics org, party,</cell><cell>summit meeting,</cell><cell>politics facility</cell><cell>politics misc, project, treaty, report</cell></row><row><cell></cell><cell>politician regional, politician local,</cell><cell>ngo, igo, so, policy institute, movement,</cell><cell>scandal,</cell><cell></cell><cell></cell></row><row><cell></cell><cell>politician national, candidate, politician,</cell><cell>agency, ministry, military alliance</cell><cell>politics event</cell><cell></cell><cell></cell></row><row><cell></cell><cell>politics per, activist, gov per</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>culture</cell><cell>character, culture per, artist, writer,</cell><cell>music band, culture org, theatre org,</cell><cell>festival,</cell><cell>culture facility</cell><cell>art title, culture title, exhibition title, culture misc,</cell></row><row><cell></cell><cell>actor, filmmaker, musician, photographer</cell><cell>dance org</cell><cell>film festival</cell><cell></cell><cell>work of art, book title, film title, tv title, music title,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>theatre title, musical title, film award, book award,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>music award, tv award, column title, game, comic,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>radio title, dance title, opera</cell></row><row><cell cols="2">education teacher, education per,</cell><cell>education org</cell><cell></cell><cell>education facility</cell><cell>education study</cell></row><row><cell></cell><cell>education student</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>religion</cell><cell>deity, clergy</cell><cell>religion org</cell><cell>religious event</cell><cell>religion facility</cell><cell>religion, religion misc</cell></row><row><cell>human</cell><cell>royalty</cell><cell></cell><cell></cell><cell></cell><cell>film award, book award, award, music award, tv award,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>sport award</cell></row><row><cell>conflict</cell><cell>military personnel, military rebel</cell><cell cols="2">army, military alliance, armed movement war, protest</cell><cell>military facility</cell><cell>military equipment, military mission</cell></row><row><cell>media</cell><cell>journalist</cell><cell>media</cell><cell></cell><cell></cell><cell></cell></row><row><cell>science</cell><cell>researcher, science per</cell><cell>research center</cell><cell></cell><cell></cell><cell>species, research journal, technology</cell></row><row><cell>sport</cell><cell>sport player, sport coach, sport head,</cell><cell>sport team, sport org</cell><cell cols="2">sport competition sport facility</cell><cell>sport award</cell></row><row><cell></cell><cell>sport referee, sport person</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>labor</cell><cell>union head, union member, union rep,</cell><cell>union</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>union per</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>business</cell><cell>manager, employee, business per</cell><cell>company, business org, brand, trade fair,</cell><cell></cell><cell>business facility</cell><cell>product, market index, business misc</cell></row><row><cell></cell><cell></cell><cell>market exchange, advocacy</cell><cell></cell><cell></cell><cell></cell></row><row><cell>health</cell><cell>health per</cell><cell>health org</cell><cell></cell><cell>health facility</cell><cell>health disease, health drug</cell></row><row><cell>justice</cell><cell>offender, advisor, victim, judge,</cell><cell>court, criminal org, police org,</cell><cell></cell><cell>prison</cell><cell>justice misc, case</cell></row><row><cell></cell><cell>police per, justice per</cell><cell>justice org</cell><cell></cell><cell></cell><cell></cell></row><row><cell>weather</cell><cell></cell><cell></cell><cell>storm</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table A .</head><label>A</label><figDesc>3: Entity linking statistics, only the top 5 types and subtypes with largest number of linked entities are showed. The total is calculated on all the entity types. The accuracy (both for most likely prior links on train and Wiki corpora) is computed on test set.Table A.4: Main named entity tag categories with statistics of the number and % of covered entities and mentions as well as the number of classes in each and average number of labels per entity cluster.</figDesc><table><row><cell>Entity Tag Category</cell><cell cols="7"># Entities % Entities # Mentions % Mentions # Classes</cell><cell>Labels per Entity</cell></row><row><cell>type</cell><cell>21,745</cell><cell>94.0%</cell><cell></cell><cell cols="2">43,122</cell><cell>99.4%</cell><cell>174</cell><cell>2.9</cell></row><row><cell>topic</cell><cell>7,843</cell><cell>33.9%</cell><cell></cell><cell cols="2">18,359</cell><cell>42.3%</cell><cell>14</cell><cell>1.0</cell></row><row><cell>iptc</cell><cell>7,059</cell><cell>30.5%</cell><cell></cell><cell cols="2">17,195</cell><cell>39.6%</cell><cell>114</cell><cell>1.3</cell></row><row><cell>gender</cell><cell>3,352</cell><cell>14.5%</cell><cell></cell><cell cols="2">8,200</cell><cell>18.9%</cell><cell>2</cell><cell>1.0</cell></row><row><cell>slot</cell><cell>3,232</cell><cell>14.0%</cell><cell></cell><cell cols="2">14,983</cell><cell>34.5%</cell><cell>7</cell><cell>1.2</cell></row><row><cell>TOTAL</cell><cell>23,130</cell><cell cols="2">100.0%</cell><cell cols="2">43,373</cell><cell>100.0%</cell><cell>311</cell><cell>4.0</cell></row><row><cell></cell><cell></cell><cell># Linked</cell><cell cols="2">% Linked</cell><cell># Linked</cell><cell>% Linked</cell><cell>Acc. Prior</cell><cell>Acc. Prior</cell></row><row><cell>Entity Type</cell><cell></cell><cell>Entities</cell><cell cols="2">Entities</cell><cell>Mentions</cell><cell>Mentions</cell><cell>Train</cell><cell>Wiki</cell></row><row><cell>LOCATION</cell><cell></cell><cell>4,863</cell><cell>98.1 %</cell><cell></cell><cell>11,496</cell><cell>99.5 %</cell><cell>85.7%</cell><cell>92.9%</cell></row><row><cell>gpe</cell><cell></cell><cell>3,938</cell><cell>99.3%</cell><cell></cell><cell>9,810</cell><cell>99.8%</cell><cell>89.8%</cell><cell>95.6%</cell></row><row><cell>regio</cell><cell></cell><cell>456</cell><cell>95.2%</cell><cell></cell><cell>889</cell><cell>97.1%</cell><cell>83.3%</cell><cell>76.3%</cell></row><row><cell>facility</cell><cell></cell><cell>229</cell><cell>88.4%</cell><cell></cell><cell>381</cell><cell>99.0%</cell><cell>19.7%</cell><cell>73.8%</cell></row><row><cell>waterbody</cell><cell></cell><cell>90</cell><cell>98.9%</cell><cell></cell><cell>145</cell><cell>100.0%</cell><cell>83.3%</cell><cell>91.7%</cell></row><row><cell>district</cell><cell></cell><cell>37</cell><cell>94.9%</cell><cell></cell><cell>45</cell><cell>100.0%</cell><cell>33.3%</cell><cell>33.3%</cell></row><row><cell cols="2">ORGANIZATION</cell><cell>3,145</cell><cell>91.6 %</cell><cell></cell><cell>8,029</cell><cell>98.3 %</cell><cell>69.8%</cell><cell>70.8%</cell></row><row><cell>media</cell><cell></cell><cell>622</cell><cell>94.4%</cell><cell></cell><cell>979</cell><cell>99.5%</cell><cell>81.8%</cell><cell>59.5%</cell></row><row><cell>igo</cell><cell></cell><cell>525</cell><cell>96.0%</cell><cell></cell><cell>1,952</cell><cell>98.0%</cell><cell>76.4%</cell><cell>78.8%</cell></row><row><cell>party</cell><cell></cell><cell>358</cell><cell>94.0%</cell><cell></cell><cell>897</cell><cell>94.5%</cell><cell>77.5%</cell><cell>66.7%</cell></row><row><cell>company</cell><cell></cell><cell>320</cell><cell>87.0%</cell><cell></cell><cell>923</cell><cell>99.0%</cell><cell>67.6%</cell><cell>89.7%</cell></row><row><cell>sport team</cell><cell></cell><cell>366</cell><cell>99.7%</cell><cell></cell><cell>1,105</cell><cell>99.9%</cell><cell>71.0%</cell><cell>47.5%</cell></row><row><cell>PERSON</cell><cell></cell><cell>2,627</cell><cell>77.5 %</cell><cell></cell><cell>8,217</cell><cell>99.5 %</cell><cell>45.7%</cell><cell>69.4%</cell></row><row><cell>politician</cell><cell></cell><cell>1,162</cell><cell>98.1%</cell><cell></cell><cell>3,324</cell><cell>99.9%</cell><cell>66.0%</cell><cell>78.1%</cell></row><row><cell>sport player</cell><cell></cell><cell>404</cell><cell>99.8%</cell><cell></cell><cell>843</cell><cell>99.9%</cell><cell>34.4%</cell><cell>71.3%</cell></row><row><cell>artist</cell><cell></cell><cell>246</cell><cell>94.6%</cell><cell></cell><cell>567</cell><cell>96.8%</cell><cell>0.0%</cell><cell>29.4%</cell></row><row><cell>politics per</cell><cell></cell><cell>126</cell><cell>60.3%</cell><cell></cell><cell>456</cell><cell>99.8%</cell><cell>23.7%</cell><cell>42.1%</cell></row><row><cell>manager</cell><cell></cell><cell>58</cell><cell>55.8%</cell><cell></cell><cell>296</cell><cell>99.7%</cell><cell>22.2%</cell><cell>33.3%</cell></row><row><cell>MISC</cell><cell></cell><cell>607</cell><cell>73.8 %</cell><cell></cell><cell>1,532</cell><cell>93.1 %</cell><cell>58.4%</cell><cell>73.4%</cell></row><row><cell>work of art</cell><cell></cell><cell>142</cell><cell>81.6%</cell><cell></cell><cell>246</cell><cell>99.6%</cell><cell>0.0%</cell><cell>100.0%</cell></row><row><cell>award</cell><cell></cell><cell>72</cell><cell>80.0%</cell><cell></cell><cell>186</cell><cell>94.9%</cell><cell>63.6%</cell><cell>81.8%</cell></row><row><cell>treaty</cell><cell></cell><cell>60</cell><cell>74.1%</cell><cell></cell><cell>149</cell><cell>99.3%</cell><cell>66.7%</cell><cell>50.0%</cell></row><row><cell>product</cell><cell></cell><cell>50</cell><cell>76.9%</cell><cell></cell><cell>146</cell><cell>98.6%</cell><cell>52.0%</cell><cell>92.0%</cell></row><row><cell>species</cell><cell></cell><cell>10</cell><cell>25.0%</cell><cell></cell><cell>14</cell><cell>18.4%</cell><cell>0.0%</cell><cell>100.0%</cell></row><row><cell>EVENT</cell><cell></cell><cell>320</cell><cell>90.4 %</cell><cell></cell><cell>683</cell><cell>97.4 %</cell><cell>49.4%</cell><cell>67.1%</cell></row><row><cell cols="3">sport competition 163</cell><cell>89.1%</cell><cell></cell><cell>397</cell><cell>96.8%</cell><cell>64.6%</cell><cell>87.5%</cell></row><row><cell cols="2">summit meeting</cell><cell>15</cell><cell>68.2%</cell><cell></cell><cell>37</cell><cell>92.5%</cell><cell>100.0%</cell><cell>100.0%</cell></row><row><cell>holiday</cell><cell></cell><cell>21</cell><cell>95.5%</cell><cell></cell><cell>39</cell><cell>97.5%</cell><cell>100.0%</cell><cell>100.0%</cell></row><row><cell>history</cell><cell></cell><cell>17</cell><cell>89.5%</cell><cell></cell><cell>30</cell><cell>100.0%</cell><cell>100.0%</cell><cell>100.0%</cell></row><row><cell>protest</cell><cell></cell><cell>14</cell><cell>100.0%</cell><cell></cell><cell>22</cell><cell>100.0%</cell><cell>80.0%</cell><cell>100.0%</cell></row><row><cell>TOTAL</cell><cell></cell><cell>13,086</cell><cell>56.6%</cell><cell></cell><cell>28,482</cell><cell>65.7%</cell><cell>70.0%</cell><cell>79.0%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table A .</head><label>A</label><figDesc>5: This table groups the number of related pairs in DWIE by the number of assigned relation labels to each of these pairs. We compare with other two entity-centric datasets: BC5CDR and DocRED.Table A.6: Relation type statistics. We compare the number of related entity and mention pairs per relation type. Only the most frequent relation types are shown (% Related Mention Pairs &gt; 0.1%)</figDesc><table><row><cell></cell><cell>Relation</cell><cell cols="2"># Related</cell><cell>% Related</cell><cell># Related</cell><cell>% Related</cell><cell></cell></row><row><cell></cell><cell>Type</cell><cell cols="2">Ent. Pairs</cell><cell>Ent. Pairs</cell><cell>Men. Pairs</cell><cell>Men. Pairs</cell><cell></cell></row><row><cell></cell><cell>based in0</cell><cell>2,361</cell><cell></cell><cell>14.0%</cell><cell>18,771</cell><cell>11.6%</cell><cell></cell></row><row><cell></cell><cell>in0</cell><cell>2,120</cell><cell></cell><cell>12.6%</cell><cell>15,810</cell><cell>9.7%</cell><cell></cell></row><row><cell></cell><cell>citizen of</cell><cell>1,969</cell><cell></cell><cell>11.7%</cell><cell>25,752</cell><cell>15.9%</cell><cell></cell></row><row><cell></cell><cell>based in0-x</cell><cell>1,882</cell><cell></cell><cell>11.2%</cell><cell>12,211</cell><cell>7.5%</cell><cell></cell></row><row><cell></cell><cell>citizen of-x</cell><cell>1,844</cell><cell></cell><cell>10.9%</cell><cell>17,049</cell><cell>10.5%</cell><cell></cell></row><row><cell></cell><cell>member of</cell><cell>1,616</cell><cell></cell><cell>9.6%</cell><cell>19,953</cell><cell>12.3%</cell><cell></cell></row><row><cell></cell><cell>gpe0</cell><cell>1,569</cell><cell></cell><cell>9.3%</cell><cell>18,110</cell><cell>11.2%</cell><cell></cell></row><row><cell></cell><cell>in0-x</cell><cell>1,474</cell><cell></cell><cell>8.8%</cell><cell>8,784</cell><cell>5.4%</cell><cell></cell></row><row><cell></cell><cell>agent of</cell><cell>954</cell><cell></cell><cell>5.7%</cell><cell>15,776</cell><cell>9.7%</cell><cell></cell></row><row><cell></cell><cell>head of</cell><cell>564</cell><cell></cell><cell>3.3%</cell><cell>7,710</cell><cell>4.7%</cell><cell></cell></row><row><cell></cell><cell>agency of</cell><cell>435</cell><cell></cell><cell>2.6%</cell><cell>4,775</cell><cell>2.9%</cell><cell></cell></row><row><cell></cell><cell>player of</cell><cell>401</cell><cell></cell><cell>2.4%</cell><cell>5,692</cell><cell>3.5%</cell><cell></cell></row><row><cell></cell><cell>agency of-x</cell><cell>382</cell><cell></cell><cell>2.3%</cell><cell>2,108</cell><cell>1.3%</cell><cell></cell></row><row><cell></cell><cell>head of state</cell><cell>380</cell><cell></cell><cell>2.3%</cell><cell>7,986</cell><cell>4.9%</cell><cell></cell></row><row><cell></cell><cell>head of state-x</cell><cell>343</cell><cell></cell><cell>2.0%</cell><cell>3,853</cell><cell>2.4%</cell><cell></cell></row><row><cell></cell><cell>appears in</cell><cell>294</cell><cell></cell><cell>1.7%</cell><cell>4,555</cell><cell>2.8%</cell><cell></cell></row><row><cell></cell><cell>vs</cell><cell>281</cell><cell cols="2">DWIE 1.7%</cell><cell>7,187</cell><cell>BC5CDR 4.4%</cell><cell>DocRED</cell></row><row><cell cols="8"># Relation # Related % Related # Related head of gov 273 1.6% labels head of gov-x 247 1.5% ent. pairs ent. pairs mention pairs mention pairs ent. pairs ent. pairs % Related 4,015 2.5% % Related % Related 2,383 1.5% minister of 234 1.4% 2,280 1.4%</cell></row><row><cell>1</cell><cell>12,856 minister of-x</cell><cell>76.32% 213</cell><cell cols="2">112,708 1.3%</cell><cell>69.40% 1,629</cell><cell>100% 1.0%</cell><cell>92.89%</cell></row><row><cell>2</cell><cell>3,101 based in2</cell><cell>18.41% 185</cell><cell cols="2">34,948 1.1%</cell><cell>21.52% 971</cell><cell>0% 0.6%</cell><cell>6.82%</cell></row><row><cell>3</cell><cell>884 event in0</cell><cell>5.25% 181</cell><cell cols="2">14,650 1.1%</cell><cell>9.02% 843</cell><cell>0% 0.5%</cell><cell>0.26%</cell></row><row><cell>4</cell><cell>3 part of</cell><cell>0.02% 164</cell><cell>100</cell><cell>1.0%</cell><cell>0.06% 2,858</cell><cell>0% 1.8%</cell><cell>0.03%</cell></row><row><cell>TOTAL</cell><cell>16,844 in2 created by</cell><cell>100.0% 157 134</cell><cell cols="2">162,406 0.9% 0.8%</cell><cell>100.0% 1,055 945</cell><cell>100.0% 0.6% 0.6%</cell><cell>100.0%</cell></row><row><cell></cell><cell>agent of-x</cell><cell>125</cell><cell></cell><cell>0.7%</cell><cell>897</cell><cell>0.6%</cell><cell></cell></row><row><cell></cell><cell>award received</cell><cell>111</cell><cell></cell><cell>0.7%</cell><cell>969</cell><cell>0.6%</cell><cell></cell></row><row><cell></cell><cell>institution of</cell><cell>105</cell><cell></cell><cell>0.6%</cell><cell>2,113</cell><cell>1.3%</cell><cell></cell></row><row><cell></cell><cell>ministry of</cell><cell>81</cell><cell></cell><cell>0.5%</cell><cell>666</cell><cell>0.4%</cell><cell></cell></row><row><cell></cell><cell>coach of</cell><cell>65</cell><cell></cell><cell>0.4%</cell><cell>1,211</cell><cell>0.7%</cell><cell></cell></row><row><cell></cell><cell>won vs</cell><cell>61</cell><cell></cell><cell>0.4%</cell><cell>1,531</cell><cell>0.9%</cell><cell></cell></row><row><cell></cell><cell>spouse of</cell><cell>55</cell><cell></cell><cell>0.3%</cell><cell>599</cell><cell>0.4%</cell><cell></cell></row><row><cell></cell><cell>directed by</cell><cell>44</cell><cell></cell><cell>0.3%</cell><cell>318</cell><cell>0.2%</cell><cell></cell></row><row><cell></cell><cell>is meeting</cell><cell>41</cell><cell></cell><cell>0.2%</cell><cell>968</cell><cell>0.6%</cell><cell></cell></row><row><cell></cell><cell>event in2</cell><cell>40</cell><cell></cell><cell>0.2%</cell><cell>259</cell><cell>0.2%</cell><cell></cell></row><row><cell></cell><cell cols="2">spokesperson of 39</cell><cell></cell><cell>0.2%</cell><cell>177</cell><cell>0.1%</cell><cell></cell></row><row><cell></cell><cell>plays in</cell><cell>38</cell><cell></cell><cell>0.2%</cell><cell>330</cell><cell>0.2%</cell><cell></cell></row><row><cell></cell><cell>gpe1</cell><cell>35</cell><cell></cell><cell>0.2%</cell><cell>135</cell><cell>0.1%</cell><cell></cell></row><row><cell></cell><cell>product of</cell><cell>31</cell><cell></cell><cell>0.2%</cell><cell>334</cell><cell>0.2%</cell><cell></cell></row><row><cell></cell><cell>parent of</cell><cell>22</cell><cell></cell><cell>0.1%</cell><cell>281</cell><cell>0.2%</cell><cell></cell></row><row><cell></cell><cell>child of</cell><cell>22</cell><cell></cell><cell>0.1%</cell><cell>281</cell><cell>0.2%</cell><cell></cell></row><row><cell></cell><cell>based in1</cell><cell>22</cell><cell></cell><cell>0.1%</cell><cell>376</cell><cell>0.2%</cell><cell></cell></row><row><cell></cell><cell>signed by</cell><cell>20</cell><cell></cell><cell>0.1%</cell><cell>521</cell><cell>0.3%</cell><cell></cell></row><row><cell></cell><cell>law of</cell><cell>16</cell><cell></cell><cell>0.1%</cell><cell>286</cell><cell>0.2%</cell><cell></cell></row><row><cell></cell><cell>TOTAL</cell><cell>16,844</cell><cell></cell><cell>100.0%</cell><cell>162,406</cell><cell>100.0%</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.dw.com 3 https://www.projectcpn.eu 4 The linking is done to Wikipedia version 20181115. 5 Also referred to as entity cluster or just cluster.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Other possible slot values are: keyword, head, death, interviewer and expert.9  The average number of labels per entity is 4.0 in our DWIE dataset.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">We use the Rich ERE dataset from the LDC2015E29 and LDC2015E68 catalogs.11  We use the TAK-KBP 2017 dataset from the LDC2017E54 and LDC2017E55 catalogs.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">For convenience, the subscript D indicating the current document is left out in the equations of this section.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">https://github.com/conll/reference-coreference-scorers 14 This would be replaced with ? ? coref ( , s j ) in the dummy-based formulation defined in<ref type="bibr" target="#b48">Lee et al. (2017)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">http://nlp.stanford.edu/data/glove.840B.300d.zip 16 https://storage.googleapis.com/bert models/2018 10 18/cased L-12 H-768 A-12.zip</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17">https://www.projectcpn.eu/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Part of the research leading to these results has received funding from (i) the European Union's Horizon 2020 research and innovation programme under grant agreement no. 761488 for the CPN project, 17 and (ii) the Flemish Government under the "Onderzoeksprogramma Artifici?le Intelligentie (AI) Vlaanderen" programme.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Dataset Insights</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A comparison of the events and relations across ace, ere, tac-kbp, and framenet annotation standards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on EVENTS: Definition, Detection, Coreference, and Representation</title>
		<meeting>the 2nd Workshop on EVENTS: Definition, Detection, Coreference, and Representation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="45" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pooled contextualized embeddings for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="724" to="728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Contextual string embeddings for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 International Conference on Computational Linguistics</title>
		<meeting>the 2018 International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semeval 2017 task 10: Scienceie-extracting keyphrases and relations from scientific publications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vikraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
		<meeting>the 11th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="546" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cloze-driven pretraining of self-attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5363" to="5372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Algorithms for scoring coreference chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 International Conference on Language Resources and Evaluation Workshop on Linguistics Coreference</title>
		<meeting>the 1998 International Conference on Language Resources and Evaluation Workshop on Linguistics Coreference</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="563" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reconstructing the house from the ad: Structured prediction on real estate classifieds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bekoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Develder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="274" to="279" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adversarial training for multi-context joint entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bekoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Develder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2830" to="2836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Joint entity recognition and relation extraction as a multi-head selection problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bekoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Develder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="34" to="45" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extending english ace 2005 corpus annotation with ground-truth links to wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Giuliano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pianta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tymoshenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on The People&apos;s Web Meets NLP: Collaboratively Constructed Semantic Resources</title>
		<meeting>the 2nd Workshop on The People&apos;s Web Meets NLP: Collaboratively Constructed Semantic Resources</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Investigating query expansion and coreference resolution in question answering on bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>De Buy Wenniger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Applications of Natural Language to Information Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="47" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Investigating entity knowledge in bert with simple neural end-to-end entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Broscheit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 23rd Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="677" to="685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer open-domain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Muc-7 information extraction task definition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chinchor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Marsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 1998 Message Understanding Conference (MUC-7)</title>
		<meeting>eeding of the 1998 Message Understanding Conference (MUC-7)</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="359" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Named entity recognition with bidirectional lstm-cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nichols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="357" to="370" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Wiser: A semantic approach for expert finding in academia based on entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cifariello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ponza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Systems</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence modeling with cross-view training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1914" to="1925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and psychological measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Results of the wnut2017 shared task on novel and emerging entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Erp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Limsopatham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Noisy User-generated Text</title>
		<meeting>the 3rd Workshop on Noisy User-generated Text</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="140" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Span-level model for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Al-Onaizan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 2019 Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5308" to="5314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The automatic content extraction (ace) program -tasks, data, and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 International Conference on Language Resources and Evaluation Workshop on Linguistics</title>
		<meeting>the 2004 International Conference on Language Resources and Evaluation Workshop on Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="837" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Easy victories and uphill battles in coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1971" to="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Overview of linguistic resources for the TAC KBP 2015 evaluations: Methodologies and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Getman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Strassel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Text Analysis Conference</title>
		<meeting>the 2015 Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Overview of linguistic resources for the tac kbp 2014 evaluations: Planning, execution, and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Getman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Strassel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TAC KBP 2014 Workshop, National Institute of Standards and Technology</title>
		<meeting>TAC KBP 2014 Workshop, National Institute of Standards and Technology</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="17" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Named entity disambiguation for noisy text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Eshel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Radinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Computational Natural Language Learning</title>
		<meeting>the 2017 Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="58" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Boundaries and edges rethinking: An end-to-end neural model for overlapping entity relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page">102311</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Graphrel: Modeling text as relational graphs for joint entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 2019 Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1409" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Interconnected question generation with coreference alignment and conversation flow modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4853" to="4862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Attention guided graph convolutional networks for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 2019 Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="241" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A novel document-level relation extraction method based on bert and entity information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fewrel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4803" to="4809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hendrickx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">?</forename><surname>S?aghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pad?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pennacchiotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Szpakowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
		<meeting>the 5th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust disambiguation of named entities in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>F?rstenau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="782" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Ontonotes: the 90% solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2006 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Language-conditioned graph networks for relational reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10294" to="10303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A cross-media deep relationship classification method using discrimination information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page">102344</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Overview of the tac 2010 knowledge base population track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Text Analysis Conference</title>
		<meeting>the 2010 Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Overview of tac-kbp2015 tri-lingual entity discovery and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hachey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Text Analysis Conference</title>
		<meeting>the 2015 Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Overview of tac-kbp2017 13 languages entity discovery and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Hub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Text Analysis Conference</title>
		<meeting>the 2017 Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Coreference resolution with entity equalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kantor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Globerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 2019 Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="673" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">News recommender systems-survey and roads ahead</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jannach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jugovac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1203" to="1227" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Nested named entity recognition revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="861" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Genia corpus -a semantically annotated corpus for bio-textmining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="180" to="182" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">An annotated corpus for machine reading of instructions in wet lab protocols</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Machiraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="97" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Collective annotation of wikipedia entities in web text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="457" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="188" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Higher-order coreference resolution with coarse-to-fine inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="687" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Biocreative v cdr task corpus: a resource for chemical disease relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sciaky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Mattingly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Wiegers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Incremental joint extraction of entity mentions and relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 2014 Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="402" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Conference on Learning Representations</title>
		<meeting>the 2016 International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3219" to="3232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Scientific information extraction with semi-supervised neural tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2641" to="2651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A general framework for information extraction using dynamic span graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3036" to="3046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">On coreference resolution performance metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 Conference on Human Language Technology and Empirical Methods in Natural Language Processing</title>
		<meeting>the 2005 Conference on Human Language Technology and Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 2016 Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Interrater reliability: the kappa statistic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Mchugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biochemia medica: Biochemia medica</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="276" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Named entity recognition for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Molla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Zaanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian Language Technology Workshop</title>
		<meeting>the Australasian Language Technology Workshop</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Cross-sentence n-ary relation extraction with graph lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="101" to="115" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing</title>
		<meeting>the 2014 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Knowledge enhanced contextual word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="43" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Scoring coreference partitions of predicted mentions: A reference implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 2014 Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="30" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference on Computational Natural Language Learning</title>
		<meeting>the 2012 Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction beyond the sentence boundary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2017 Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1171" to="1182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<meeting>the 2010 European Conference on Machine Learning and Knowledge Discovery in Databases</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13637</idno>
		<title level="m">Recipes for building an open-domain chatbot</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F T K</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Reliability of content analysis: The case of nominal scale coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public opinion quarterly</title>
		<imprint>
			<biblScope unit="page" from="321" to="325" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Why reinvent the wheel: Let&apos;s build question answering systems together</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Radhakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Both</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shekarpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lytra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Usbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khikmatullaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Punjani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference</title>
		<meeting>the 2018 World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1247" to="1256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Matching the blanks: Distributional similarity for relation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 2019 Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2895" to="2905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">From light to rich ere: annotation of entities, relations, and events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Riese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kulick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the the 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation</title>
		<meeting>the the 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Fast and accurate entity recognition with iterated dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2670" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A review of natural language processing techniques for opinion mining systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information fusion</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="10" to="25" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Automated fact checking: Task formulations, methods and future directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3346" to="3359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Entity, relation, and event extraction with contextualized span representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Wennberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5788" to="5793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Medero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Maeda</surname></persName>
		</author>
		<title level="m">Ace 2005 multilingual training corpus. Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">57</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Dkn: Deep knowledge-aware network for news recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 world wide web conference</title>
		<meeting>the 2018 world wide web conference</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1835" to="1844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Multi-task feature learning for knowledge graph enhanced recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2000" to="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Mind the gap: A balanced corpus of gendered ambiguous pronouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Axelrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="605" to="617" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Overview of the biocreative v chemical disease relation (cdr) task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Mattingly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Wiegers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th BioCreative Challenge Evaluation Workshop</title>
		<meeting>the 5th BioCreative Challenge Evaluation Workshop</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Ontonotes: A large training corpus for enhanced processing. Handbook of Natural Language Processing and Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Belvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
			<biblScope unit="page">59</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Franchini</surname></persName>
		</author>
		<title level="m">Ontonotes release 5.0 ldc2013t19. Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Learning anaphoricity and antecedent ranking features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Annual Meeting of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing</title>
		<meeting>the 2015 Annual Meeting of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1416" to="1426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Enriching pre-trained language model with entity information for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 2019 ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2361" to="2364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 International Conference on Learning Representations</title>
		<meeting>the 2018 International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Docred: A large-scale document-level relation extraction dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 2019 Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="764" to="777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Improved neural relation detection for knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="571" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">End-to-end neural relation extraction with global optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1730" to="1740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">An overview of online fake news: Characterization, detection, and discussion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Ghorbani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page">102025</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Graph convolution over pruned dependency trees improves relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2205" to="2215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Position-aware attention and supervised data improve slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
