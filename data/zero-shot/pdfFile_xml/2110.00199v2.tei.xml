<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">XXX-X-XXXX-XXXX-X/XX/$XX.00 ?20XX IEEE Perturbated Gradients Updating within Unit Space for Deep Learning Manufacturing Taiwan Semi-condoctor Manufacturing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hsun</forename><surname>Tseng</surname></persName>
							<email>ching-hsun.tseng@postgrad.manchester.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeng</forename><surname>Xiaojun</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsueh-Cheng</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Co</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ltd</forename><surname>Hinschu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taiwan</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin-Jye</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Manchester Manchester</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Manchester</orgName>
								<address>
									<settlement>Manchester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer-Intergrated</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Institute of Management of Technology National Yang Ming Chiao</orgName>
								<orgName type="institution">Tung University Hinschu</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">XXX-X-XXXX-XXXX-X/XX/$XX.00 ?20XX IEEE Perturbated Gradients Updating within Unit Space for Deep Learning Manufacturing Taiwan Semi-condoctor Manufacturing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep Learning</term>
					<term>Image classification</term>
					<term>Optimization</term>
					<term>Generalization</term>
					<term>Smooth loss landscape</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In deep learning, optimization plays a vital role. By focusing on image classification, this work investigates the pros and cons of the widely used optimizers, and proposes a new optimizer: Perturbated Unit Gradient Descent (PUGD) algorithm with extending normalized gradient operation in tensor within perturbation to update in unit space. Via a set of experiments and analyses, we show that PUGD is locally bounded updating, which means the updating from time to time is controlled. On the other hand, PUGD can push models to a flat minimum, where the error remains approximately constant, not only because of the nature of avoiding stationary points in gradient normalization but also by scanning sharpness in the unit ball. From a series of rigorous experiments, PUGD helps models to gain a state-of-the-art Top-1 accuracy in Tiny ImageNet and competitive performances in CIFAR-{10, 100}. We open-source our code at link: https://github.com/hanktseng131415go/PUGD. ! -norm is infeasible. Therefore, the second motivation of this work is developing the tensor version of NGD for deep learning.</p><p>* DenseNet-121: growth rate in 16.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>An optimizer plays an essential role in updating weights to find optimum in machine learning. Since the introduction of Stochastic Gradient Descent (SGD) <ref type="bibr" target="#b0">[1]</ref>, updating in minibatch has become the mainstream. Thus, applying SGD and other mini-batch optimizers has turned into a natural choice. Later, the proposition of SGD-based Adaptive Gradient Algorithm (Adagrad) <ref type="bibr" target="#b1">[2]</ref> has opened another path of using the adaptive gradient to get a suitable learning rate with the individual accumulating gradients as a divider. By combining the mini-batch upgrading with the adaptive mechanism, models quickly reach a minimum. On the other hand, Normalized Gradient Descent (NGD) <ref type="bibr" target="#b2">[3]</ref> applies ! -norm of overall or individual gradient as a scaler to modify the updating step toward vector space. By the statement from NGD <ref type="bibr" target="#b2">[3]</ref>, this gradient scaling operation brings a range of properties: 1. Prevent models from stocking in saddle points and a local minimum in a loss surface (although these terrains are unlikely to exist in deep learning <ref type="bibr" target="#b3">[4]</ref>); 2. Ameliorate the slow crawling problem of standard gradient descent near the minimum; 3. Push model to flat regions. Despite these merits, this normalization has not been seen in deep learning updating toward tensor. Thus, it inspires this work, and motivates * Corresponding author introducing the normalization in deep learning gradient updating.</p><p>By applying gradient normalization, it is expected that having a normalized gradient for updating in each step could bring a better generalization as the discussions in Path-SGD <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b5">[6]</ref>. Furthermore, each step length is bounded or controlled with a normalized gradient each time, which could further alleviate the potential of reaching a sharp minimum difficulty or sub-optimum due to stochastic <ref type="bibr" target="#b6">[7]</ref>. In order to have bounded updating length between time to time, applying the gradient normalization in ! -norm is doable when facing a 1-D or 2-D vector. However, as deep learning works on tensors (vector with inner vectors), we need to extend the normalization operator from vector to tensor. Because it is unlikely to require each component (inner vector) of tensor to be the same shape, scaling the magnitude of the gradient by In deep learning, while investigating generalization bound is still one of the mainstreams, sharpness-aware generalization has boomed. A series of works <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref> has tried to explain the generalization mechanism via theoretical perspectives and proofs. By the findings of the positive relationship between sharpness-awareness and generalization <ref type="bibr" target="#b5">[6]</ref>, the same authors proposed Sharpness-Awareness Minimization (SAM) <ref type="bibr" target="#b12">[13]</ref>, which considers sharpness-aware generalization bounds and obtains state-of-the-art performances in image classifications. Based on another widely-accepted relationship between generalization and flat minimum <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>, SAM and Adversarial Model Perturbation (AMP) <ref type="bibr" target="#b16">[17]</ref> has ramped up attention toward this by showing models can reach flat minimum with the sharpness-awareness mechanisms during updating.</p><p>Summing up the above overview and extending the investigations in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref>, this work focuses on inheriting the merits of gradient normalization by extending to a tensor version in deep learning and utilizing the two criteria to form a good optimizer: locally bounded updating and sharpness-awareness. Therefore, we introduce a new minibatch gradient descent with perturbation in unit space, called the perturbated unit gradient descent (PUGD). In brief, the main contributions in this work include:</p><p>? Usher tensor normalization for gradient updating.</p><p>? Reveal that updating within unit gradient space is locally bounded updating. ? Propose the Perturbated Unit Gradient Descent (PUGD), a gradient descent optimizer with perturbation within a unit ball. We furtherly present that PUGD outperforms the existing optimizer in <ref type="figure" target="#fig_0">Fig. 1</ref> and alleviates the chaos problem in NGDs in <ref type="figure" target="#fig_1">Fig. 2</ref> ? Carry out a series of comparisons to show that PUGD can help models obtain a state-of-the-art 1 performance in Tiny ImageNet, competitive results in CIFAR-10 and CIFAR-100 with outperforming current sharpness-aware optimizers.  The rest of this paper is divided into five parts. First, the background, motivation and a summary of PUGD have been present in this. Then, in section II, similar optimizers are listed. After, we present the mathematical proofs of (P)UGD properties among deep learning in III. Finally, a series of simulations on PUGD and competitors is shown in IV, with the conclusion in V and supplements in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>Since the introduction of SGD, the natural step of the mainstream has been choosing SGD as a default optimizer. <ref type="bibr" target="#b0">1</ref> Checked on June 29 th , 2021</p><p>However, SGD has been argued with the downsides of often being unstable or reaching a bad optimum easily due to stochasticity <ref type="bibr" target="#b6">[7]</ref>. In terms of ushering dynamic gradients, Adagrad cannot be ignored as it brought the adaptive mechanism in optimization, but the adaptive mechanism from accumulating gradients will speed up too much in the early epochs and make the gradients in later epochs vanish into zero. That is gradient vanishing by the escalating divider, so the unstable path updating becomes severe. While there are RMSProp <ref type="bibr" target="#b21">[22]</ref> and ADAM <ref type="bibr" target="#b22">[23]</ref>, the rapid convergence speed has been negatively correlated to generalization <ref type="bibr" target="#b5">[6]</ref>. Toward the same direction of avoiding the stationary point, NGD <ref type="bibr" target="#b2">[3]</ref> formed its methods by applying full-magnitude (NGD-FM) and component-wise gradient norm (NGD-CW) in vector. NGD-FM, nonetheless, will easily stick the model with an extremely small divided gradient when having a great amount of gradient <ref type="bibr" target="#b2">[3]</ref>, and normalizing gradients will make convergence uneasy. On the other hand, to avoid the sticking issue in NGD-FW, NGD-CW scales every gradient component by ! -norm of each component. The component gradient normalization makes every weight only update a length of one. In other words, the update length of NGD-CW is decided by the learning rate. In our experiments, component-wise gradient normalizations intend to mess the updating and end up with sub-optimum generalization performance, which is also witnessed in Adagrad, despite achieving fast-updating in early steps. Therefore, this work tries to usher the full-magnitude normalization into deep learning by formally defining the gradient normalization toward tensor, so it could also bring a better generalization.</p><p>Regarding what factor could link to better generalization, gradient flow <ref type="bibr" target="#b20">[21]</ref> offers a mathematical perspective to prove that SGD with locally Lipschitz gradients in deep learning benefits the stable converge. With the observation in Path-SGD <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b5">[6]</ref>, creating a controllable updating process is positive related to generalization. Path-norm designs an updating policy based on the stable direction, balancing the difference of parameters by the norm of overall weights. Although the results with Path-norm fall behind SGD in <ref type="bibr" target="#b4">[5]</ref>, it opened a path for caring for the stability (invariant) of updating weights. Although the result of Path-SGD in <ref type="bibr" target="#b4">[5]</ref> did not outshine SGD, the survey in <ref type="bibr" target="#b5">[6]</ref> does support the positive relation. This work takes the same notion but creates a bounded updating process by considering overall gradient with normalization in SGD-based optimization.</p><p>Taking SGD as a based optimizer for finding a flat minimum in deep learning, the attention on local sharpness is ramping up. What has led to the surge could be SAM and AMP, which argues that the flat minimum can bring a more robust result compared with other directions, with the author's previous survey work <ref type="bibr" target="#b5">[6]</ref> and the works <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref> from the antecedents. The authors of SAM furtherly prove that it follows the PAC Bayesian Generalization bounds and can create a smooth space in empirical tests. Then, an adaptive modification of SAM is proposed, ASAM <ref type="bibr" target="#b23">[24]</ref>. An invertible scaling operator in ASAM can help loss surface more fit to real contour. Following the same direction, Entropy-SGD <ref type="bibr" target="#b17">[18]</ref> focuses on the local entropy of empirical loss in 2017. It utilizes the local geometry of the energy landscape to help models obtain a flat plateau with the baby steps roaming in Gibbs distribution. Some related works <ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref> investigated finding generalization well minima using local entropy. SWA <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b29">29]</ref> performs the average weights traversed based on SGD in a scheduled training plan using an intuitive method to find a flat area. Furthermore, an extension of SWA <ref type="bibr" target="#b30">[30]</ref> also obtains the efficient PAC Bayesian criteria. By building a unit sharpness-aware in UGD, the PUGD visualization of landscape did help the models to find a flat minimum. Also, the loss history shows a better generalization bound, which implies less possibility of facing an overfitting problem.</p><p>III. PERTURBATED GRADIENTS UPDATING WITHIN UNIT SPACE This section proposes PUGD along with unit gradient descent (UGD, a simplified variant of PUGD) and proves its properties. As the discussion toward vector and tensor in section I, one major point of this work is to build a connection between vector and tensor by precisely defining the gradient normalization in tensor. In order to connect the existing knowledge for knowing the properties toward tensor, the proposed normalization in (P)UGD equipped with dual-norm in = 2 is chosen. Therefore, a descending operation in unit space by normalizing gradient in deep learning is UGD. PUGD is proposed with a unit space perturbation to serve the purpose of sharpness-awareness in unit space. The following contents state the preliminaries and properties of (P)UGD to be a decent optimizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Notation and Preliminary 1) Notation</head><p>Throughout the work, given learning rate and a training set</p><formula xml:id="formula_0">? ? {( " , " )| " ? , " ? } # "$% ~ (.(.*.</formula><p>, we let a single data-generation model ? ? parametrized from a weight vector ? ? ? + . Then, the loss function ? ( ) ? [ ( , ( , ( )], where indicates the -. batch data and ( , ( , ( ) represents the -. loss term under parameter .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Preliminary</head><p>The definitions and preliminary concepts toward this work are listed and discussed firstly and below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1 (Dual-norm). If</head><formula xml:id="formula_1">??? / is the / -norm on ? 0?2?3 , then its dual-norm is ??? 4 , where % / + % 4 = 1. We denote (? ? / / ) %/4</formula><p>as the dual-norm in <ref type="formula" target="#formula_2">(1)</ref>:</p><formula xml:id="formula_2">!? ? ! ! $ " # = ? ? ? ? ? ? ? ? ? ? ) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? *) ) * $("),&amp;(") ! ? $("),'(") ! ? ? ? (("),&amp;(") ! ? (("),'(") ! / ((") $)" '(") &amp;)" / " ! ? ? ? ? ? # ? ? ? ? ? ? *) ) 3 $($),&amp;($) ! $($),'($) ! (($),&amp;($) ! (($),'($) ! 4 (($) $)" '($) &amp;)" / " ! ? ? ? ? ? # ? ? ? ? ? ? ? ? ? ? + ,)" ? ? ? ? ? ? ? ? ? ? " # = ?7?8% 9 , for all , V? ? 0?2?3 ,<label>(1)</label></formula><formula xml:id="formula_3">where + ? ? 2 (") ?3 (") is composed of ( (") ,; (") / , ( (") ,; (") /</formula><p>indicates an element among -. matrix of a matrix with row index (+) , column index (+) , and is powered by . When listing each flattened + in a matrix, the dual-norm forms the &gt; -norm in ? ? / as <ref type="formula" target="#formula_5">(2)</ref>:</p><formula xml:id="formula_4">? ? / = N O 0 +$% P %/4 = "? ? ? " 5 (") ,7 (") 8 ? 9 ($) ,: ($) 8 ' 9 5&lt;=</formula><p>: 7&lt;=</p><formula xml:id="formula_5">&gt; ?&lt;= ' =/A .<label>(2)</label></formula><p>When = = 2, we simply denote the dual-norm as ??? along with the ! -norm in ??? ! .</p><p>When having ! -norm in ??? ! , dual-norm in ???, and a tensor = R <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>, <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>V , we say that is a group of vectors with various component shapes in vector, and % = [1, 2, 3] and ! = <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> are the components in vector. In this case, calculating components in ! -norm becomes infeasible, since it is facing a vector instead of a single value among each component. Namely, directly getting ! -norm of is impropriate. On the other hand, because a dual of dual-norm is the original norm <ref type="bibr" target="#b31">[31]</ref>(Theorem 13.1), calculating dualnorm in ! of turns into ? ? = B C " --</p><formula xml:id="formula_6">+ C - - - = C? " ? - -+ ? -? - -.</formula><p>This operator makes norm of element-wise in tensor possible. It should be noticed that, for a tensor, the (dual-) norm when = 2 and = 2 defined in the above is the square root of the simple square sum of each element in the tensor. This is not true in general when and are not equal to 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2 (Unit tensor).</head><p>Let ? be a tensor in tensor space , and ??? be the dual-norm of the tensor, then the tensor Z = ? ??? is the unit tensor of , and ? Z? = 1.</p><p>SGD has brought online learning with stochastic minibatch learning into metadata learning to set a proper learning rate. The typical updating process with stochastically minibatch updating can be presented in (3) with the rightto reach the optimum. -is referred to the size of updated steps at different times, . The descent process follows:</p><formula xml:id="formula_7">-@% = -? --.<label>(3)</label></formula><p>where -, -, anddenotes the weight, learning rate, and gradients from ? , respectively.</p><p>Based on the same notion in NGD <ref type="bibr" target="#b2">[3]</ref> and discussions <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, having a bounded updating throughout the training process is essential. Under the same perspective, applying fullmagnitude gradient normalization with ! -norm as NGD can help gain that. Although there is no formal work to define the algorithm, NGD (in the full-magnitude gradient) can be represented as:</p><formula xml:id="formula_8">-@% = -? - A $ ?A $ ? % ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_9">A $ ?A $ ? %</formula><p>is the normalizing gradients with ! -norm. By this gradient normalization, the updating tendency is expected to address the stochastic behaviour of SGD and prevent to stuck in stationary points. However, although the advantages of having a stable gradient difference and avoiding local minimum, this work shows that normalizing gradients could affect the final convergence, which might dim the stable updating in the final iterations. From another standpoint, Path-SGD argues that SGD tends to update networks poorly with unbalanced updated weights. The pathnorm in Path-SGD can be seen as a weight normalization and is argued to be positive with generalization in a survey <ref type="bibr" target="#b5">[6]</ref>. Therefore, this work picks up a similar idea toward tensor to introduce a gradient normalization in dual-norm as the unit gradients and tries to explain its benefits toward the stochastic issue. We argue that unit gradients are also a regularization in the gradient perspective. It can bound the difference of updating and thus alleviate the issue of unstable updating due to stochasticity.</p><p>In the light of sharpness-awareness, (A)SAM and AMP have attracted much attention to date. Different from the typical method of minimizing one step empirical risk loss, sharpness-aware optimizers minimize the following PAC-Bayesian generalization bound based on the sharp risk * from the second step with the following expression (i.e., SAM):</p><formula xml:id="formula_10">? ( ) ? ?D?8E ? ( + ) + ?( ?F? % % E % ),<label>(5)</label></formula><p>where ?: ? @ ? ? @ is a strictly increasing function. Therefore, the goal is to minimize a dual-norm ball with , which is another hyperparameter to decide the size of sharpness-aware space, and then this minimization can further be solved by finding the max perturbation * of ? ( + ):</p><formula xml:id="formula_11">* = ?D?8E ? ( + ) ? G? (F) ?G? (F)? .<label>(6)</label></formula><p>Optimizers can help models choose a flat direction by observing sharpness geometry around a radius. Nonetheless, setting the radius or the sharpness distribution requires prior knowledge, which implies a careless setting could easily pollute the performance. Different from the mentioned perturbated optimizers, we comment that a perturbation with a similar adaptive mechanism with ASAM's as <ref type="bibr" target="#b6">(7)</ref>,</p><formula xml:id="formula_12">I9 ( )* DI + 8E ? ( + ) ? ? ( )<label>(7)</label></formula><p>where F J% is the normalization operator which does not change the loss function, in a unit gradient space can generalize well.</p><p>This work answers the needed criteria as a decent optimizer: locally bounded updating and sharpness-awareness, in the following parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Unit Gradient Descent</head><p>Applying the unit vector into typical gradient descent (3) makes sure that the gradient norm becomes one based on Definition 2. However, there is no formal optimization of applying normalizing gradients in deep learning toward tensor. As discussed in III.A.2) and Definition 1, ! -norm is a special case in dual-norm. Following, we formally define the tensor gradient normalization in descending as Definition 3. <ref type="figure">Unit gradient descent, UGD)</ref>. Let -= ?( -) be the gradients of the loss function at , and then be divided with the overall norm of gradient. We form a gradient descent in unit gradient space:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 3 (</head><formula xml:id="formula_13">-@% = -? - A $ ?A $ ? = -? -- h,<label>(8)</label></formula><p>where ? -? is dual-norm of full magnitude of gradients,</p><formula xml:id="formula_14">A $ ?A $ ?</formula><p>is the unit gradients corresponding to each component, and ? -h? = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Difference between preliminaries</head><p>In <ref type="formula" target="#formula_13">(8)</ref>, the formal equation of gradient normalization in tensor is defined. Compared with (4), the conventional gradient normalization in machine learning is using <ref type="bibr" target="#b1">(2)</ref>, which is a special case of (1) and has a drawback of being unable to deal with tensor. The different shape makes operating impossible, as ! -norm calculates the root of the sum from each square element. Nonetheless, each square element in the tensor is not a single value but a matrix. Applying ???, it makes this operation possible.</p><p>On the side of using dual-norm in deep learning, we have seen (A)SAM and AMP that also use dual-norm as a highdimensional space scaler for sharpness detecting, ? ? ( )? in <ref type="bibr" target="#b5">(6)</ref>. However, this operation seems to generate landscape noise instead of updating the scaler. The above moves inspire this work, and then we propose a bounded updating with adaptive operation and perturbation both within unit space by applying dual-norm within gradients. The following content only focuses on and discusses tensors in deep learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Locally bounded updating</head><p>To achieve a bounded difference during updating, having a bounded difference with following uniform distribution as Definition 4 is expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4 (Uniform bounded difference). Letbe a sequence function of the difference between two steps such that:</head><formula xml:id="formula_15">-= ? -? -@% ?.<label>(9)</label></formula><p>If there exists a constant ? 0 for all :</p><formula xml:id="formula_16">? -? ? ,<label>(10)</label></formula><p>we say thatis uniformly bounded difference.</p><p>Different from Path-SGD, we expect to obtain the stability by caring the locally difference of gradients among steps ? + 1, as Definition 4. The benefits of caring locally gradients toward convergence have also been argued in <ref type="bibr" target="#b20">[21]</ref>. In that case, we present that gradients amongand -@% following the uniform bounded difference under UGD form a locally bounded updating as Theorem 1 below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1 (Locally bounded updating). Given ?( ), the loss function under UGD constructs a locally stable difference of gradients for any at step ? + 1:</head><formula xml:id="formula_17">-= n G?( ) ?G?( )? ? G?L +1 O IG?L +1 OI n ? .<label>(11)</label></formula><p>Please see the proof in Appendix. A</p><p>The proof indicates locally bounded updating in a gradient unit space. The identical phenomenon has been observed in <ref type="figure" target="#fig_0">Fig. 1 and Fig. 2</ref>, where UGD stably converge (before the chaotic in the final iterations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Perturbated Unit Gradient Descent</head><p>Although the locally bounded updating within unit gradients has been proved in Theorem 1, the chaotic issue in the final convergence steps remains, see <ref type="figure" target="#fig_0">Fig. 1 and Fig. 2</ref>. A typical suggestion for this dilemma is applying early-stop (also called elbow method) to prevent. Unfortunately, such a scheme only cures the symptoms, not the disease. Toward this disease, we offer a solution by extending the basics of UGD with the intuitive solution from the practical perspective: perturbation. More precisely, we propose unit perturbation and merge it into UGD to become Perturbated Unit Gradient Descent (PUGD). By strictly obeying Definition 2, the unit perturbation is designed with an adaptive mechanism as ASAM but scans in a unit radius and updates the gradients in a unit ball at any . Furthermore, the unit perturbation keeps the dual-norm of gradients non-zero, so it will prevent gradients bouncing up because of getting zero gradients as the divider. Eventually, we define PUGD as Definition 4. <ref type="figure">Unit gradient descent, PUGD)</ref>. Let -= ?( -) be the gradients of the loss function at with perturbation and descending within unit space:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4 (Perturbated</head><formula xml:id="formula_18">? ? ? ? ? - s = |F $ |?A $ ?|F $ |?A $ ? - * = ( -+ - s ) -@% = -? - LA $ * @A $ O IA $ * @A $ I = R,-? -- ,<label>(12)</label></formula><p>where - * is the gradients from the unit perturbationwith adaptive steps toward each component in a unit ball within the norm of total perturbation radius ? -s ? = 1 , -= LA $ * @A $ O IA $ * @A $ I is the unit gradient at , and the step length of unit gradients ? -? = 1 . As a result, the adaptive sharpnessaware process within a unit space can be further expressed as Theorem 2 to become unit sharpness-aware optimizer, analogue <ref type="bibr" target="#b12">[13]</ref> (Theorem 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 2 (Unit sharpness-awareness, state informally).</head><p>For any distribution , with probability 1 ? over the choice of the training set ~,</p><formula xml:id="formula_19">? ( ) ? max ?D?$% ? ( + ) + ?( ?F? % % S % ),<label>(13)</label></formula><p>where ?: ? @ ? ? @ is a strictly increasing function (under some technical conditions on ? ( )).</p><p>Please see the detail proof in Appendix. B</p><p>Finally, the whole algorithm is demonstrated in <ref type="figure" target="#fig_2">Fig. 3</ref> and the following pseudo-code. In PUGD, Unit sharpnessawareness does not require setting a fitting radius as SAM and an inner learning rate as AMP. Also, the final converge path (red arrow in <ref type="figure" target="#fig_2">Fig. 3</ref>) has thoroughly considered the surrounding geometry, inheriting the merits of UGD. Compute the gradients from a batch set :</p><formula xml:id="formula_20">( = ? + ? , ( ( ) ; 2.</formula><p>Noise the weight by manually adding perturbation:</p><formula xml:id="formula_21">( * = ( + ( M , where ( M = |+ / |?0 / ?|+ / |?0 / ? ; 3.</formula><p>Compute the perturbation gradients of the same set :</p><formula xml:id="formula_22">( * = ? , ( ( + ( M ); 4.</formula><p>Call back to ( :</p><formula xml:id="formula_23">( = ( * ? ( M 5.</formula><p>Descend by using the unit gradients: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, we implemented three experiments, including (1) optimizing behaviours comparison, (2) end-toend comparison, and (3) finetuning comparison. The experiments were implemented on open datasets in the equipment with RTX-Titan, 32G RAM, and an eight-core processor. In addition, every experiment followed the hyperparameters setting in the learning rate (LR) = 0.1 , weight decay = 0.0005, momentum = 0.9 (if there is), Nesterov = False, and the learning schedule of cosine annealing <ref type="bibr" target="#b32">[32]</ref>. Every subject followed the same Pytorch default initial weights policy, a random uniform distribution (weight number, weight number).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Optimizing behaviors</head><p>To observe the behaviours of (P)UGD and others, this subsection of simulation has been organized into four-folds: by highly referring to the visualization loss landscape work <ref type="bibr" target="#b33">[33]</ref> and animation code in the link 3 . Through these observations, we can get a picture of what (P)UGD can do with models.</p><formula xml:id="formula_24">IV</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) CIFAR-10 training history</head><p>When it comes to understanding the training behaviour, analyzing the training history in 1-D is one of the widely-used and easy options. Therefore, we presented the loss and accuracy history together from SGD, Adagrad, NGDs, (A)SAM, and (P)UGD in <ref type="figure" target="#fig_5">Fig. 4</ref> to <ref type="figure" target="#fig_6">Fig. 5</ref>. Among the loss plots, the gap represents the difference between training loss and testing loss, so it could also indicate the overfitting problem when it surged. We implemented all subjects by following the experiment settings at the beginning of IV. Every performance was recorded from 100 epochs in perturbated optimizers: (A)SAM and PUGD, 200 epochs in non-perturbated ones: SGD, Adagrad, NGDs, and UGD. Also, every subject followed the same batch size in 100 by training UPANet16 <ref type="bibr" target="#b34">[34]</ref> for having faster speed and updating smooth path every time. Finally, the setting from each optimizer followed the default and recommended parameters from the proposed authors.  The training histories can be split into two types of patterns, smooth and fluctuated, based on taking SGD as the standard. Among the fluctuating training histories, SGD is in line with the argument of the stochasticity issue. Except for SGD, NGD-CW experienced a severe fluctuated history, which might be due to the amplification from component-wise normalization. Later, the result from NGD-FM and UGD share the same pattern, a hybrid with smooth histories before the 175 th epoch and vibrate histories after that. At the end of the spectrum, the smooth history of Adagrad is a sugar coat that has a high loss. In the rest of the outcomes from (A)SAM to PUGD, (A)SAM are promising with smooth history and low loss. However, they all seem not to have the ability to bound the testing loss under the training loss as PUGD did. Most importantly, the gap of PUGD decreased in the last epochs. To summarize this part, PUGD is much better than others from the training histories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) CIFAR-10 loss landscapes in 3D</head><p>Obeying the same setting as the last part, we extended the 1-D loss history to the 3-D space to show a transparent optimizing environment where each updating method was created in CIFAR-10 for the model. Please see <ref type="figure" target="#fig_7">Fig. 6</ref> to <ref type="figure">Fig.  7</ref>.</p><p>The landscape from SGD guarantees a smooth landscape in UPANet16, but Adagrad turned the landscape to a steep view. Moreover, NGD-CW made it full of valleys, so we can deduce that the component-wise method makes the space fluctuate. Conversely, smoother ones can be seen from (A)SAM, which is consistent with the experimental result in SAM <ref type="bibr" target="#b12">[13]</ref>. As the last part observation, PUGD shows a smoother one than (A)SAM and ASAM's. Moreover, the landscape from PUGD has the lowest overall loss. From this observation, PUGD can create a smoother updating area for models from viewing loss landscape. 3) CIFAR-10 updating trajectories in 2-D Combing a 1-D loss history with a 3-D landscape and then projecting it to the 2-D landscape, we can obtain the possible updating trajectories based on different optimizers. We present trajectories with the same setting as the last two parts but in a 2-D space with a trajectory log in each plot. Please see <ref type="figure" target="#fig_8">Fig. 8</ref> and <ref type="figure">Fig. 9</ref>.</p><p>In these contours, we can furtherly assure that componentwise adaptive gradient operation will aggregate the fluctuation of the space and, possibly, turn the flat landscape into a steep one, from Adagrad and NGD-CW results. Apart from that, PUGD has the flattest convergence area as the last two observations. Therefore, we can answer that PUGD created a great generalization bound and flat updating environment. However, we cannot get more information about each optimizer lead a model to a minimum from sharing a similar path, so a simulation of gathering subjects in the same landscape was conducted in IV.A.4). (g) UGD (h) PUGD <ref type="figure">Fig. 9</ref>. The contours and trajectories of (P)UGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) MNIST updating trajectories with MLPs in 2D</head><p>To gain a better picture, we gathered all competitors in the same fixed loss landscape. Different from the referenced code 4 , we plotted the terrain of the first 100 th training data (the green-blue landscape) and the terrain of the first 100 th testing data (the blue-red landscape) from MNIST together. In this way, we can compare the reaching training area with the testing one. When the time spot of the model is located in a blue area of training but has a red area of testing, it indicates the optimizer risk a model in an overfitting situation. An ideal direction is a way to a plateau (flat minimum) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">18]</ref> to have a robust result and avoid potential overfitting problems. Because of involving eight optimizers, every optimizer was iterated 10000 times in total, except perturbated ones {(A)SAM, AMP, PUGD} in 5000, by sampling every 100 iterations from the same start point in <ref type="bibr">[-10.1, -15]</ref>, which can be viewed as the initial weight of the model. The rest of the experiment settings remained identical to the referenced code. We presented the 3D trajectories in <ref type="figure" target="#fig_0">Fig. 10</ref> and the 2D ones in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>The patterns of this simulation can be roughly divided into three types based on their final locations: the sharp minima, flat minimum, and halfway. This simulation expects a decent optimizer to lead the model to the flat minimum where the green area is in training and the blue area is in testing. Among the endpoints on the sub-optimum, it contains most of the existing optimizers. In the sharp minimum with potential overfitting problem in testing, the end location of Adagrad is in line with the above discussions. However, it is surprising that NGD-CW reached the exact location. The underlying reason for having a sharp minimum in Adagrad and NGD-CW could be the fast descending and vanishing gradients of component-wise gradient normalization. On the other side, SGD is halfway to the flat area. While existing perturbation-or sharpness-awareness-based optimizers claimed superior mechanisms in the leading model, we did not see a clear picture of superiority in this simulation. These sharpness-aware optimizers avoided a sharp region where SGD stepped in, but they ended up marching on a highland with higher training and testing loss. Lastly, it is also surprising that AMP neither outshined SGD nor sheernessaware in this experiment. Although (P)UGD and NGD-FM share similar trajectories, PUGD has a stabler updating and surpasses others. Firstly, UGD shared the same trajectory as the NGD-FM, which is deducible because of equality between dualnorm and ! -norm when = 2. At the same time, NGD-FM and UGD suffer difficult convergence issues, similar to <ref type="figure" target="#fig_1">Fig.  2</ref>. We answered this issue with the unit perturbation in PUGD that fixed the issue and helped to sharpness-aware as the red trajectory in the yellow rectangle in <ref type="figure" target="#fig_0">Fig. 1</ref>. From this simulation, we can furtherly assure that PUGD pushed the model to the flat minimum stably, referencing the green rectangle in <ref type="figure" target="#fig_0">Fig. 1</ref>. Moreover, this also completed why PUGD can create a smooth landscape and lead to a broader flat minimum in the above simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation in end-to-end training</head><p>In this sub-section, we conducted PUGD in CIFAR-10 and CIFAR-100 compared with the optimizers in IV.A.4). The experimental setting followed the description in IV.A.1). Meanwhile, a series of models have been used to evaluate the optimizers effect toward various structures, including the types of deep like VGGs, a residual connection like ResNets, a dense connection like DenseNets, and a hybrid connection UPANets. The recorded average and standard deviation performances were obtained from three testing results on the test data. Please see the below comparisons from TABLE IV and TABLE V in Appendix. <ref type="figure" target="#fig_0">Fig. 11</ref>. CIFAR-10 end-to-end training results. From <ref type="figure" target="#fig_0">Fig. 11</ref> and <ref type="figure" target="#fig_0">Fig. 12</ref>, despite the difference in epochs for doubling time in perturbation-based optimizers training, it can easily be seen that the results from PUGD have improved. Moreover, PUGD has the best performance among these. The results are in line with the updating behaviour of PUGD in marching on the plateau, which assures better performance even in more complex tasks, CIFAR-100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Evaluation in finetuning</head><p>The goal of transfer learning <ref type="bibr" target="#b35">[35]</ref> is to improve the performance of the target learner by training a previous model on a large (or similar) dataset and then transferring the knowledge from the previous model to the target learner. Because transfer learning is a powerful technique, we used the pre-trained models (on 1K-ImageNet <ref type="bibr" target="#b36">[36]</ref>) to finetune CIFAR-10, CIFAR-100, and Tiny ImageNet by the proposed method PUGD. The most experimental setting followed the setting in IV.B except the hyperparameters: learning rate (LR) = {0.01, 0.001, 0.005} and input size = (224, 224). Then, more models were finetuned and recorded in the best accuracy as the following.</p><p>The finetuning outcomes of PUGD in Tiny ImageNet obtained state-of-the-art performance to the best of our knowledge. Also, compared with the result from the paper of SAM, the finetuning results of PUGD outperformed SAM significantly, especially in CIFAR-100. We also learned another lesson: despite testing on varied models, improvement is guaranteed in PUGD. That reassures the superiority of PUGD in our comparisons. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>This work proposed a perturbated gradient updating within unit space for deep learning focusing on image classification. First, a bridge between vector and tensor is built by formally introducing the gradient normalization in tensor with dualnorm. Later, the proofs explained locally bounded updating gradients in unit space and sharpness-awareness of PUGD. The implemented simulations also show that PUGD can reach a flat minimum and outperform others with SOTA performances. We hope this work can raise the attention of the communities to research the unit tensor in deep learning given having better performance and bounded updating difference during optimization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Illustration of (P)UGD and other optimizers updating trajectories in MNIST 2-D landscape with mean square error. The whole picture is in the background, and the zoom-in pictures are in green and yellow rectangles. A sharp minimum is on the top right side. A flat minimum is on the bottom right side. Lastly, an area of the saddle is between the sharp and flat minimum. Every dot in the same mark represents the location of the model at t (iteration position). PUGD outperforms others with the fastest convergence, most stable trajectory, and a better sharpness-awareness. Please see detail in IV.A.4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>UPANet16 training histories of (P)UGD and other optimizers in CIFAR-10. The histories of grad norm 2 and test loss are on the left and right, respectively. Although NGD-FM and UGD converged stably before the last iterations, dividing gradients with zero norm gradients makes chaos. PUGD, otherwise, converged stably with the lowest testing loss. Please see the same test loss results and experiment settings in IV.A.1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Demonstration of PUGD ignoring learning rate ?.Algorithm Perturbated Unit Gradient Descent (PUGD)Input: Training set ? ? {( " , " )} # "$% with the loss function ? ( ) ? [ ( , ' , ' )] , whereindicating () batch data and ( , ' , ' ) represents () loss term under parameter by setting random initial weight * with any ( ? (0,1], given t = 0. Output: Trained weight ( with PUGD while do: For in random sample batch : {( % , % ), ? , ( " , " )}: 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>.A.1) CIFAR-10 training history; IV.A.2) CIFAR-10 loss landscapes in 3D; IV.A.3) CIFAR-10 updating trajectories in 2-D; IV.A.4) MNIST updating trajectories with MLPs in 2-D;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>4 .</head><label>4</label><figDesc>Training histories of other optimizers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>5 .</head><label>5</label><figDesc>Training histories of (P)UGD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Visualization loss landscapes of other optimizers.(g) UGD (h) PUGDFig. 7. Visualization loss landscapes of (P)UGD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>8 .</head><label>8</label><figDesc>The contours and trajectories of other optimizers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>The 3D trajectories in MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>CIFAR-100 end-to-end training results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I .</head><label>I</label><figDesc>CIFAR-10 FINETUNING RESULTS (TOP-1%) The current top fifth checked on June 29 th , 2021TABLE III. TINY IMAGENET FINETUNING RESULTS (TOP-1%)</figDesc><table><row><cell>Dataset</cell><cell></cell></row><row><cell></cell><cell>CIFAR-10</cell></row><row><cell>Model (LR)</cell><cell></cell></row><row><cell>ResNet18 (0.01)</cell><cell>97.46</cell></row><row><cell>ResNet50 (0.01)</cell><cell>97.95</cell></row><row><cell>ResNet101 (0.01)</cell><cell>98.40</cell></row><row><cell>ResNet152 (0.01)</cell><cell>98.50</cell></row><row><cell>ViT-B/16 (SAM [13])</cell><cell>98.60</cell></row><row><cell>ViT-B/16 (0.001)</cell><cell>99.13 *</cell></row><row><cell>DeiT-B/16 (0.005)</cell><cell>98.74</cell></row><row><cell cols="2">* The current top fifth checked on June 29 th , 2021</cell></row><row><cell cols="2">TABLE II. CIFAR-100 FINETUNING RESULTS (TOP-1%)</cell></row><row><cell>Dataset</cell><cell></cell></row><row><cell></cell><cell>CIFAR-100</cell></row><row><cell>Model (LR)</cell><cell></cell></row><row><cell>ViT-B/16 (SAM [13])</cell><cell>89.1</cell></row><row><cell>ViT-B/16 (0.001)</cell><cell>93.95 *</cell></row><row><cell>Dataset</cell><cell></cell></row><row><cell></cell><cell>Tiny ImageNet</cell></row><row><cell>Model (LR)</cell><cell></cell></row><row><cell>ViT-B/16 (0.001)</cell><cell>90.74*</cell></row><row><cell>DeiT-B/16 (0.005)</cell><cell>91.02*</cell></row></table><note>** The SOTA checked on until June 29 th , 2021.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The gradient dual-norm in = 2 is the same as ! -norm toward flattening every element in tensor into vector.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://towardsdatascience.com/animations-of-gradient-descent-andloss-landscapes-of-neural-networks-in-python-e757f3584057</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proof of Theorem 1</head><p>Suppose ?( -) ? ?( -@% ) ? 1, we obtain the difference of gradients under UGD at any step ? + 1:</p><p>(1)</p><p>Based on Definition 1, the difference of gradients under UGD can be further expressed as:</p><p>by applying Cauchy-Schwarz inequality, so (2), with the inequality (3), it can further be manipulated into: </p><p>where = | | , is the number of parameters, and we assumed</p><p>Based on <ref type="bibr" target="#b37">[37]</ref> (Theorem 3.2), the generalization of a perturbated module is bounded by</p><p>In the case of perturbation in UGD, the generalization bound follows ? ? = 1 from the unit gradient, so there is a probability of 1 ? 1 ? ? that the generalization can be bounded by  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Tables of Evaluation in end-to-end training</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COMPSTAT&apos;2010</title>
		<meeting>COMPSTAT&apos;2010</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Watt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Borhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
		<title level="m">Machine learning refined: foundations, algorithms, and applications</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deep learning without poor local minima</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kawaguchi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07110</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02617</idno>
		<title level="m">Path-sgd: Pathnormalized optimization in deep neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Fantastic generalization measures and where to find them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.02178</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>G?ron</surname></persName>
		</author>
		<title level="m">Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems. O&apos;Reilly Media</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Dziugaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.11008</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Generalization bounds for deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sedghi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.12600</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deterministic PAC-bayesian generalization bounds for deep networks via generalizing noiseresilience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.13344</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Exploring generalization in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.08947</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Data-dependent sample complexity of deep neural networks via lipschitz augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.03684</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Sharpnessaware minimization for efficiently improving generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Foret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kleiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.01412</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Simplifying neural nets by discovering flat minima</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">On large-batch training for deep learning: Generalization gap and sharp minima</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mudigere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smelyanskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T P</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04836</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sharp minima can generalize for deep nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1019" to="1028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Regularizing neural networks via adversarial model perturbation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8156" to="8165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Entropy-sgd: Biasing gradient descent into wide valleys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Mechanics: Theory and Experiment</title>
		<imprint>
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">124018</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Averaging weights leads to wider optima and better generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05407</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A primer on PAC-Bayesian learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Guedj</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.05353</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Directional convergence and alignment in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Telgarsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06657</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural networks for machine learning lecture 6a overview of mini-batch gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cited on</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">K</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.11600</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Subdominant dense clusters allow for simple learning and high computational performance in neural networks with discrete synapses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baldassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ingrosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lucibello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saglietti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zecchina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review letters</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">128101</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural networks and principal component analysis: Learning from examples without local minima</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="58" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Deep learning with elastic averaging SGD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Choromanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6651</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kirichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SWALP: Stochastic weight averaging in low precision training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De</forename><surname>Sa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7015" to="7024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">There are many consistent explanations of unlabeled data: Why you should average</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Athiwaratkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Finzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.05594</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A simple baseline for bayesian uncertainty in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Maddox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="13153" to="13164" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Duality Uses and Correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="13" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Visualizing the loss landscape of neural nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Studer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.09913</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">UPANets: Learning from the Universal Pixel Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Tseng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.08640</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A comprehensive survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="76" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">The intriguing role of module criticality in the generalization of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Chatterji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sedghi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00528</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
