<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rethinking the Value of Labels for Improving Class-Imbalanced Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhe</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">EECS Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Xu</surname></persName>
							<email>zhixu@mit.edu</email>
							<affiliation key="aff1">
								<orgName type="department">EECS Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Rethinking the Value of Labels for Improving Class-Imbalanced Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Real-world data often exhibits long-tailed distributions with heavy class imbalance, posing great challenges for deep recognition models. We identify a persisting dilemma on the value of labels in the context of imbalanced learning: on the one hand, supervision from labels typically leads to better results than its unsupervised counterparts; on the other hand, heavily imbalanced data naturally incurs "label bias" in the classifier, where the decision boundary can be drastically altered by the majority classes. In this work, we systematically investigate these two facets of labels. We demonstrate, theoretically and empirically, that class-imbalanced learning can significantly benefit in both semi-supervised and self-supervised manners. Specifically, we confirm that (1) positively, imbalanced labels are valuable: given more unlabeled data, the original labels can be leveraged with the extra data to reduce label bias in a semi-supervised manner, which greatly improves the final classifier; (2) negatively however, we argue that imbalanced labels are not useful always: classifiers that are first pre-trained in a self-supervised manner consistently outperform their corresponding baselines. Extensive experiments on large-scale imbalanced datasets verify our theoretically grounded strategies, showing superior performance over previous state-of-the-arts. Our intriguing findings highlight the need to rethink the usage of imbalanced labels in realistic long-tailed tasks. Code is available at https://github.com/YyzHarry/imbalanced-semi-self.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Imbalanced data is ubiquitous in the real world, where large-scale datasets often exhibit long-tailed label distributions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr">24,</ref><ref type="bibr">33]</ref>. In particular, for critical applications related to safety or health, such as autonomous driving and medical diagnosis, the data are by their nature heavily imbalanced. This posts a major challenge for modern deep learning frameworks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b31">53]</ref>, where even with specialized techniques such as data re-sampling approaches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr">41]</ref> or class-balanced losses <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr">26</ref>], significant performance drops still remain under extreme class imbalance. In order to further tackle the challenge, it is hence vital to understand the different characteristics incurred by class-imbalanced learning.</p><p>Yet, distinct from balanced data, the labels in the context of imbalanced learning play a surprisingly controversial role, which leads to a persisting dilemma on the value of labels: (1) On the one hand, learning algorithms with supervision from labels typically result in more accurate classifiers than their unsupervised counterparts, demonstrating the positive value of labels; (2) On the other hand, however, imbalanced labels naturally impose "label bias" during learning, where the decision boundary can be significantly driven by the majority classes, demonstrating the negative impact of labels. Hence, the imbalanced label is seemingly a double-edged sword. Naturally, a fundamental question arises:</p><p>How to maximally exploit the value of labels to improve class-imbalanced learning?</p><p>In this work, we take initiatives to systematically decompose and analyze the two facets of imbalanced labels. As our key contributions, we demonstrate that the positive and the negative viewpoint of the 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada. dilemma are indeed both enlightening: they can be effectively exploited, in semi-supervised and self-supervised manners respectively, to significantly improve the state-of-the-art.</p><p>On the positive viewpoint, we argue that imbalanced labels are indeed valuable. Theoretically, via a simple Gaussian model, we show that extra unlabeled data benefits imbalanced learning: we obtain a close estimate with high probability that increases exponentially in the amount of unlabeled data, even when unlabeled data are also (highly) imbalanced. Inspired by this, we confirm empirically that by leveraging the label information, class-imbalanced learning can be substantially improved by employing a simple pseudo-labeling strategy, which alleviates the label bias with extra data in a semi-supervised manner. Regardless of the imbalanceness on both the labeled and unlabeled data, superior performance is established consistently across various benchmarks, signifying the valuable supervision from the imbalanced labels that leads to substantially better classifiers.</p><p>On the negative viewpoint, we demonstrate that imbalanced labels are not advantageous all the time. Theoretically, via a high-dimensional Gaussian model, we show that if given informative representations learned without using labels, with high probability depending on the imbalanceness, we obtain classifier with exponentially small error probability, while the raw classifier always has constant error. Motivated by this, we verify empirically that by abandoning label at the beginning, classifiers that are first pre-trained in a self-supervised manner consistently outperform their corresponding baselines, regardless of settings and base training techniques. Significant improvements on large-scale datasets reveal that the biased label information can be greatly compensated through natural self-supervision.</p><p>Overall, our intriguing findings highlight the need to rethink the usage of imbalanced labels in realistic imbalanced tasks. With strong performance gains, we establish that not only the positive viewpoint but also the negative one are both promising directions for improving class-imbalanced learning.</p><p>Contributions. (i) We are the first to systematically analyze imbalanced learning through two facets of imbalanced label, validating and exploiting its value in novel semi-and self-supervised manners.</p><p>(ii) We demonstrate, theoretically and empirically, that using unlabeled data can substantially boost imbalanced learning through semi-supervised strategies. (iii) Further, we introduce self-supervised pre-training for class-imbalanced learning without using any extra data, exhibiting both appealing theoretical interpretations and new state-of-the-art on large-scale imbalanced benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Imbalanced Learning with Unlabeled Data</head><p>As motivated, we explore the positive value of labels. Naturally, we consider scenarios where extra unlabeled data is available and hence, the limited labeling information is critical. Through a simple theoretical model, we first build intuitions on how different ingredients of the originally imbalanced data and the extra data affect the overall learning process. With a clearer picture in mind, we design comprehensive experiments to confirm the efficacy of this direction on boosting imbalanced learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Theoretical Motivation</head><p>Consider a binary classification problem with the data generating distribution P XY being a mixture of two Gaussians. In particular, the label Y is either positive (+1) or negative (-1) with equal probability (i.e., 0.5). Condition on Y = +1, X|Y = +1 ? N (? 1 , ? 2 ) and similarly, X|Y = ?1 ? N (? 2 , ? 2 ). Without loss of generality, let ? 1 &gt; ? 2 . It is straightforward to verify that the optimal Bayes's classifier is f (x) = sign(x ? ?1+?2 2 ), i.e., classify x as +1 if x &gt; (? 1 + ? 2 )/2. Therefore, in the following, we measure our ability to learn (? 1 + ? 2 )/2 as a proxy for performance.</p><p>Suppose that a base classifier f B , trained on imbalanced training data, is given. We consider the case where extra unlabeled data {X i }? i (potentially also imbalanced) from P XY are available, and study how this affects our performance with the label information from f B . Precisely, we create pseudo-label for {X i }? i using f B . Let {X + i }? + i=1 be the set of unlabeled data whose pseudo-label is +1; similarly let {X ? i }? ? i=1 be the negative set. Naturally, when the training data is imbalanced, f B is likely to exhibit different accuracy for different class. We model this as follows. Consider the case where pseudo-label is +1 and let {I + i }? + i=1 be the indicator that the i-th pseudo-label is correct, i.e., if I + i = 1, thenX + i ? N (? 1 , ? 2 ) and otherwiseX + i ? N (? 2 , ? 2 ). We assume I + i ? Bernoulli(p), which means f B has an accuracy of p for the positive class. Analogously, we define</p><formula xml:id="formula_0">{I ? i }? ? i=1 , i.e., if I ? i = 1, thenX ? i ? N (? 2 , ? 2 ) and otherwiseX ? i ? N (? 1 , ? 2 ). Let I ? i ? Bernoulli(q)</formula><p>, which means f B has an accuracy of q for the negative class. Denote by ? p ? q the imbalance in accuracy.</p><p>As mentioned, we aim to learn (? 1 + ? 2 )/2 with the above setup, via the extra unlabeled data. It is natural to construct our estimate as? = 1 2 ?+ i=1X</p><formula xml:id="formula_1">+ i /? + + ?? i=1X ? i /? ? .</formula><p>Then, we have: Theorem 1. Consider the above setup. For any ? &gt; 0, with probability at least 1 ? 2e</p><formula xml:id="formula_2">? 2? 2 9? 2 ?? +?? n ? +? + ? 2e ? 8? + ? 2 9(? 1 ?? 2 ) 2 ? 2e ? 8? ? ? 2 9(? 1 ?? 2 ) 2 our estimates? satisfies ? ? (? 1 + ? 2 )/2 ? ?(? 1 ? ? 2 )/2 ? ?.</formula><p>Interpretation. The result illustrates several interesting aspects. (1) Training data imbalance affects the accuracy of our estimation. For heavily imbalanced training data, we expect the base classifier to have a large difference in accuracy between major and minor classes. That is, the more imbalanced the data is, the larger the gap ? would be, which influences the closeness between our estimate and desired value (? 1 + ? 2 )/2. (2) Unlabeled data imbalance affects the probability of obtaining such a good estimation. For a reasonably good base classifier, we can roughly view? + and? ? as approximations for the number of actually positive and negative data in unlabeled set. For term</p><formula xml:id="formula_3">2 exp(? 2? 2 9? 2 ?? +?? n ? +? + ), note that? +?? n ? +? + is maximized when? + =? ? , i.e., balanced unlabeled data. For terms 2 exp(? 8? + ? 2 9(? 1 ?? 2 ) 2 ) and 2 exp(? 8? ? ? 2 9(? 1 ?? 2 ) 2 )</formula><p>, if the unlabeled data is heavily imbalanced, then the term corresponding to the minor class dominates and can be moderately large. Our probability of success would be higher with balanced data, but in any case, more unlabeled data is always helpful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semi-Supervised Imbalanced Learning Framework</head><p>Our theoretical findings show that pseudo-label (and hence the label information in training data) can be helpful in imbalanced learning. The degree to which this is useful is affected by the imbalanceness of the data. Inspired by these, we systematically probe the effectiveness of unlabeled data and study how it can improve realistic imbalanced task, especially with varying degree of imbalanceness.</p><p>Semi-Supervised Imbalanced Learning. To harness the unlabeled data for alleviating the inherent imbalance, we propose to adopt the classic self-training framework, which performs semi-supervised learning (SSL) by generating pseudo-labels for unlabeled data. Precisely, we obtain an intermediate classifier f? using the original imbalanced dataset D L , and apply it to generate pseudo-labels? for unlabeled data D U . The data and pseudo-labels are combined to learn a final model f? f by minimizing a loss function as L(D L , ?) + ?L(D U , ?), where ? is the unlabeled weight. This procedure seeks to remodel the class distribution with D U , obtaining better class boundaries especially for tail classes.</p><p>We remark that besides self-training, more advanced SSL techniques can be easily incorporated into our framework by modifying only the loss function, which we will study later. As we do not specify the learning strategy of f? and f? f , the semi-supervised framework is also compatible with existing class-imbalanced learning methods. Accordingly, we demonstrate the value of unlabeled data -a simple self-training procedure can lead to substantially better performance for imbalanced learning.</p><p>Experimental Setup. We conduct thorough experiments on artificially created long-tailed versions of CIFAR-10 <ref type="bibr" target="#b6">[7]</ref> and SVHN <ref type="bibr">[36]</ref>, which naturally have their unlabeled part with similar distributions: 80 Million Tiny Images <ref type="bibr" target="#b26">[48]</ref> for CIFAR-10, and SVHN's own extra set [36] with labels removed for SVHN. Following <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11]</ref>, the class imbalance ratio ? is defined as the sample size of the most frequent (head) class divided by that of the least frequent (tail) class. Similarly for D U , we define the unlabeled imbalance ratio ? U in the same way. More details of datasets are reported in Appendix D.</p><p>For long-tailed dataset with a fixed ?, we augment it with 5 times more unlabeled data, denoted as D U @5x. As we seek to study the effect of unlabeled imbalance ratio, the total size of D U @5x is fixed, where we vary ? U to obtain corresponding imbalanced D U . We select standard cross-entropy (CE) training, and a recently proposed state-of-the-art imbalanced learning method LDAM-DRW <ref type="bibr" target="#b6">[7]</ref> as baseline methods. We follow <ref type="bibr" target="#b6">[7,</ref><ref type="bibr">25,</ref><ref type="bibr">33]</ref> to evaluate models on corresponding balanced test datasets. <ref type="table" target="#tab_0">Table 1</ref> summarizes the results on two long-tailed datasets. For each ?, we vary the type of class imbalance in D U to be uniform (? U = 1), half as labeled (? U = ?/2), same (? U = ?), and doubled (? U = 2?). As shown in the table, the SSL scheme can consistently and substantially improve existing techniques across different ?. Notably, under extreme class imbalance (? = 100), using unlabeled data can lead to +10% on CIFAR-10-LT, and +6% on SVHN-LT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Main Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-10-LT &amp; SVHN-LT.</head><p>Imbalanced Distribution in Unlabeled Data. As indicated by Theorem 1, unlabeled data imbalance affects the learning of final classifier. We observe in <ref type="table" target="#tab_0">Table 1</ref> that gains indeed vary under different ? U , with smaller ? U (i.e., more balanced D U ) leading to larger gains. Interestingly however, as the original dataset becomes more balanced, the benefits from D U tend to be similar across different ? U .</p><p>Qualitative Results. To further understand the effect of unlabeled data, we visualize representations learned with vanilla CE ( <ref type="figure" target="#fig_0">Fig. 1a</ref>) and with SSL ( <ref type="figure" target="#fig_0">Fig. 1b</ref>) using t-SNE <ref type="bibr">[34]</ref>. The figures show that imbalanced training set can lead to poor class separation, particularly for tail classes, which results in mixed class boundary during class-balanced inference. In contrast, by leveraging unlabeled data, the boundary of tail classes can be better shaped, leading to clearer separation and better performance.</p><p>Summary. Consistently across various settings, class-imbalanced learning tasks benefit greatly from additional unlabeled data. The superior performance obtained demonstrates the positive value of imbalanced labels as being capable of exploiting the unlabeled data for extra benefits. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Further Analysis and Ablation Studies</head><p>Different Semi-Supervised Methods (Appendix E.1). In addition to the simple pseudo-label, we select more advanced SSL techniques <ref type="bibr">[35,</ref><ref type="bibr" target="#b24">46]</ref> and explore the effect of different methods under the imbalanced settings. In short, all SSL methods can achieve remarkable performance gains over the supervised baselines, with more advanced SSL method enjoying larger improvements in general.</p><p>Generalization on Minority Classes (Appendix E.2). Besides the reported top-1 accuracy, we further study generalization on each class with and without unlabeled data. We show that while all classes can obtain certain improvements, the minority classes tend to exhibit larger gains.</p><p>Unlabeled &amp; Labeled Data Amount (Appendix E.3 &amp; E.4). Following [39], we investigate how different amounts of D U as well as D L can affect our SSL approach in imbalanced learning. We find that larger D U or D L often brings higher gains, with gains gradually diminish as data amount grows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Closer Look at Unlabeled Data under Class Imbalance</head><p>With significant boost in performance, we confirm the value of imbalanced labels with extra unlabeled data. Such success naturally motivates us to dig deeper into the techniques and investigate whether SSL is the solution to practical imbalanced data. Indeed, in the balanced case, SSL is known to have issues in certain scenarios when the unlabeled data is not ideally constructed. Techniques are often sensitive to the relevance of unlabeled data, and performance can even degrade if the unlabeled data is largely mismatched <ref type="bibr">[39]</ref>. The situation becomes even more complicated when imbalance comes into the picture. The relevant unlabeled data could also exhibit long-tailed distributions. With this, we aim to further provide an informed message on the utility of semi-supervised techniques.</p><p>Data Relevance under Imbalance. We construct sets of unlabeled data with the same imbalance ratio as the training data but varying relevance. Specifically, we mix the original unlabeled dataset with irrelevant data, and create unlabeled datasets with varying data relevance ratios (detailed setup can be found in Appendix D.2). <ref type="figure">Fig. 2</ref> shows that in imbalanced learning, adding unlabeled data from mismatched classes can actually hurt performance. The relevance has to be as high as 60% to be effective, while better results could be obtained without unlabeled data at all when it is only moderately relevant. The observations are consistent with the balanced cases <ref type="bibr">[39]</ref>.</p><p>Varying ? U under Sufficient Data Relevance. Furthermore, even with enough relevance, what will happen if the relevant unlabeled data is (heavily) long-tailed? As presented in <ref type="figure">Fig. 3</ref>, for a fixed relevance, the higher ? U of the relevant data is, the higher the test error. In this case, to be helpful, ? U cannot be larger than 50 (which is the imbalance ratio of the training data). This highlights that unlike traditional setting, the imbalance of the unlabeled data imposes an additional challenge.</p><p>Why Do These Matter. The observations signify that semi-supervised techniques should be applied with care in practice for imbalanced learning. When it is readily to obtain relevant unlabeled data of each class, they are particularly powerful as we demonstrate. However, certain practical applications, especially those extremely imbalanced, are situated at the worst end of the spectrum. For example, in medical diagnosis, positive samples are always scarce; even with access to more "unlabeled" medical records, positive samples remain sparse, and the confounding issues (e.g., other disease or symptoms) undoubtedly hurt relevance. Therefore, one would expect the imbalance ratio of the unlabeled data to be higher, if not lower, than the training data in these applications.</p><p>To summarize, unlabeled data are useful. However, semi-supervised learning alone is not sufficient to solve the imbalanced problem. Other techniques are needed in case the application does not allow constructing meaningful unlabeled data, and this, exactly motivates our subsequent studies.</p><formula xml:id="formula_4">0% 20% 40% 60% 80% 100%</formula><p>Relevance Ratio beled data on CIFAR-10-LT with ? = 50. We fix the unlabeled data relevance ratio as 60%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Imbalanced Learning from Self-Supervision</head><p>The previous studies naturally motivate our next quest: can the negative viewpoint of the dilemma, i.e., the imbalanced labels introduce bias and hence are "unnecessary", be successfully exploited as well to advance imbalanced learning? In answering this, our goal is to seek techniques that can be broadly applied without extra data. Through a theoretical model, we first justify the usage of selfsupervision in the context of imbalanced learning. Extensive experiments are then designed to verify its effectiveness, proving that thinking through the negative viewpoint is indeed promising as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Theoretical Motivation</head><p>We start with another inspiring model to study how imbalanced learning benefits from self-supervision. Consider d-dimensional binary classification with data generating distribution P XY being a mixture of Gaussians. In particular, the label Y = +1 with probability p + while Y = ?1 with probability</p><formula xml:id="formula_5">p ? = 1?p + . Let p ? ? 0.5, i.e., major class is negative. Condition on Y = +1, X is a d-dimensional isotropic Gaussian, i.e., X|Y = +1 ? N (0, ? 2 1 I d ). Similarly, X|Y = ?1 ? N (0, ?? 2 1 I d ) for some constant ? &gt; 3, i.e., the negative samples have larger variance. The training data, {(X i , Y i )} N i=1</formula><p>, could be highly imbalanced, and we denote by N + &amp; N ? as number of positive &amp; negative samples.</p><p>To develop our intuition, we consider learning a linear classifier with and without self-supervision. In particular, consider the class of linear classifiers f (x) = sign( ?, feature + b), where feature would be the raw input X in standard training, and for the self-supervised learning, feature would be Z = ?(X) for some representation ? learned through a self-supervised task. For convenience, we consider the case where the intercept b ? 0. We assume a properly designed black-box self-supervised task so that the learned representation is</p><formula xml:id="formula_6">Z = k 1 ||X|| 2 2 + k 2 , where k 1 , k 2 &gt; 0.</formula><p>Precisely, this means that we have access to the new features Z i for the i-th data after the black-box self-supervised step, without knowing explicitly what the transformation ? is. Finally, we measure the performance of a classifier f using the standard error probability:</p><formula xml:id="formula_7">err f = P (X,Y )?P XY f (X) = Y .</formula><p>Theorem 2. Let ? be the CDF of N (0, 1). For any linear classifier of the form f (X) = sign ?, X + b where b &gt; 0, the error probability satisfies:</p><formula xml:id="formula_8">err f = p + ? ? b ||?||2?1 + p ? ? b ||?||2 ? ??1 ? 1 4 .</formula><p>Theorem 2 states that for standard training, regardless of whether the training data is imbalanced or not, the linear classifier cannot have an accuracy ? 3/4. This is rather discouraging for such a simple case. However, we show that self-supervision and training on the resulting Z provides a better classifier. Consider the same linear class f (x) = sign( ?, feature + b), b &gt; 0 and following explicit classifier</p><formula xml:id="formula_9">with feature Z = ?(X): f ss (X) = sign(?Z + b), b = 1 2 N i=1 1 {Y i =+1} Zi N+ + N i=1 1 {Y i =?1} Zi N?</formula><p>. The next theorem shows a high probability error bound for the performance of this linear classifier. Theorem 3. Consider the linear classifier with self-supervised learning, f ss . For any ? ? 0, ??1 ?+1 , we have that with probability at least 1 ? 2e ?N?d? 2 /8 ? 2e ?N+d? 2 /8 , the classifier satisfies</p><formula xml:id="formula_10">err fss ? ? ? ? p + e ?d? (??1?(1+?)?) 2 32 + p ? e ?d? (??1?(1+?)?) 2 32? 2 , if ? ? ??3 ?+1 , ??1 ?+1 ; p + e ?d? (??1?(1+?)?) 16 + p ? e ?d? (??1?(1+?)?) 2 32? 2 , if ? ? 0, ??3 ?+1 .</formula><p>Interpretation. Theorem 3 implies the following interesting observations. By first abandoning imbalanced labels and learning an informative representation via self-supervision, (1) With high probability, we obtain a satisfying classifier f ss , whose error probability decays exponentially on the dimension d. The probability of obtaining such a classifier also depends exponentially on d and the number of data. These are rather appealing as modern data is of extremely high dimension. That is, even for imbalanced data, one could obtain a good classifier with proper self-supervised training; <ref type="bibr" target="#b1">(2)</ref> Training data imbalance affects our probability of obtaining such a satisfying classifier. Precisely, given N data, if it is highly imbalanced with an extremely small N + , then the term 2 exp(?N + d? 2 /8) could be moderate and dominate 2 exp(?N ? d? 2 /8). With more or less balanced data (or just more data), our probability of success increases. Nevertheless, as the dependence is exponential, even for imbalanced training data, self-supervised learning can still help to obtain a satisfying classifier. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Self-Supervised Imbalanced Learning Framework</head><p>Motivated by our theoretical results, we again seek to systematically study how self-supervision can help and improve class-imbalanced tasks in realistic settings.</p><p>Self-Supervised Imbalanced Learning. To utilize self-supervision for overcoming the intrinsic label bias, we propose to, in the first stage of learning, abandon the label information and perform self-supervised pre-training (SSP). This procedure aims to learn better initialization that is more label-agnostic from the imbalanced dataset. After the first stage of learning with self-supervision, we can then perform any standard training approach to learn the final model initialized by the pre-trained network. Since the pre-training is independent of the learning approach applied in the normal training stage, such strategy is compatible with any existing imbalanced learning techniques.</p><p>Once the self-supervision yields good initialization, the network can benefit from the pre-training tasks and finally learn more generalizable representations. Since SSP can be easily embedded with existing techniques, we would expect that any base classifiers can be consistently improved using SSP. To this end, we empirically evaluate SSP and show that it leads to consistent and substantial improvements in class-imbalanced learning, across various large-scale long-tailed benchmarks.</p><p>Experimental Setup. We perform extensive experiments on benchmark CIFAR-10-LT and CIFAR-100-LT, as well as large-scale long-tailed datasets including ImageNet-LT [33] and real-world dataset iNaturalist 2018 <ref type="bibr">[24]</ref>. We again evaluate models on the corresponding balanced test datasets <ref type="bibr" target="#b6">[7,</ref><ref type="bibr">25,</ref><ref type="bibr">33]</ref>. We use Rotation <ref type="bibr" target="#b15">[16]</ref> as SSP method on CIFAR-LT, and MoCo <ref type="bibr" target="#b18">[19]</ref> on ImageNet-LT and iNaturalist.</p><p>In the classifier learning stage, we follow <ref type="bibr" target="#b6">[7,</ref><ref type="bibr">25]</ref> to train all models for 200 epochs on CIFAR-LT, and 90 epochs on ImageNet-LT and iNaturalist. Other implementation details are in Appendix D.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Main Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-10-LT &amp; CIFAR-100-LT.</head><p>We present imbalanced classification on long-tailed CIFAR in <ref type="table" target="#tab_1">Table 2</ref>. We select standard cross-entropy (CE) loss, Focal loss [32], class-balanced (CB) loss <ref type="bibr" target="#b10">[11]</ref>, re-weighting or re-sampling training schedule <ref type="bibr" target="#b6">[7]</ref>, and recently proposed LDAM-DRW <ref type="bibr" target="#b6">[7]</ref> as stateof-the-art methods. We group the competing methods into four sessions according to which basic loss or learning strategies they use. As <ref type="table" target="#tab_1">Table 2</ref> reports, in each session across different ?, adding SSP consistently outperforms the competing ones by notable margins. Further, the benefits of SSP become more significant as ? increases, demonstrating the value of self-supervision under class imbalance.  <ref type="table" target="#tab_3">Table 3</ref> and 4 present results on two datasets, respectively.  On both datasets, adding SSP sets new state-of-the-arts, substantially improving current techniques with 4% absolute performance gains. The consistent results confirm the success of applying SSP in realistic large-scale imbalanced learning scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ImageNet-LT</head><p>Qualitative Results. To gain additional insight, we look at the t-SNE projection of learnt representations for both vanilla CE training ( <ref type="figure">Fig. 4a</ref>) and with SSP ( <ref type="figure">Fig. 4b</ref>). For each method, the projection is performed over both training and test data, thus providing the same decision boundary for better visualization. The figures show that the decision boundary of vanilla CE can be greatly altered by the head classes, which results in the large leakage of tail classes during (balanced) inference. In contrast, using SSP sustains clear separation with less leakage, especially between adjacent head and tail class.</p><p>Summary. Regardless of the settings and the base training techniques, adding our self-supervision framework in the first stage of learning can uniformly boost the final performance. This highlights that the negative, "unnecessary" viewpoint of the imbalanced labels is also valuable and effective in improving the state-of-the-art imbalanced learning approaches. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Further Analysis and Ablation Studies</head><p>Different Self-Supervised Methods (Appendix F.1). We select four different SSP techniques, and evaluate them across four benchmark datasets. In general, all SSP methods can lead to notable gains compared to the baseline, while interestingly the gain varies across methods. We find that MoCo <ref type="bibr" target="#b18">[19]</ref> performs better on large-scale datasets, while Rotation <ref type="bibr" target="#b15">[16]</ref> achieves better results on smaller ones.</p><p>Generalization on Minority Classes (Appendix F.2). In addition to the top-1 accuracy, we further study the generalization on each specific class. On both CIFAR-10-LT and ImageNet-LT, we observe that SSP can lead to consistent gains across all classes, where trends are more evident for tail classes.</p><p>Imbalance Type (Appendix F.3). While the main paper is focused on the long-tailed imbalance distribution which is the most common type of imbalance, we remark that other imbalance types are also suggested in literature <ref type="bibr" target="#b4">[5]</ref>. We present ablation study on another type of imbalance, i.e., step imbalance <ref type="bibr" target="#b4">[5]</ref>, where consistent improvements and conclusions are verified when adding SSP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Imbalanced Learning &amp; Long-tailed Recognition. Literature is rich on learning long-tailed imbalanced data. Classical methods have been focusing on designing data re-sampling strategies, including over-sampling the minority classes <ref type="bibr" target="#b1">[2,</ref><ref type="bibr">41,</ref><ref type="bibr" target="#b22">44]</ref> as well as under-sampling the frequent classes <ref type="bibr" target="#b4">[5,</ref><ref type="bibr">31]</ref>. In addition, cost-sensitive re-weighting schemes <ref type="bibr" target="#b5">[6,</ref><ref type="bibr">22,</ref><ref type="bibr">23,</ref><ref type="bibr">27,</ref><ref type="bibr" target="#b30">52]</ref> are proposed to (dynamically) adjust weights during training for different classes or even different samples. For imbalanced classification problems, another line of work develops class-balanced losses <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr">26</ref>, 32] by taking intra-or inter-class properties into account. Other learning paradigms, including transfer learning <ref type="bibr">[33,</ref><ref type="bibr" target="#b32">54]</ref>, metric learning <ref type="bibr" target="#b33">[55,</ref><ref type="bibr" target="#b36">58]</ref>, and meta-learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">45]</ref>, have also been explored. Recent studies <ref type="bibr">[25,</ref><ref type="bibr" target="#b37">59]</ref> also find that decoupling the representation and classifier leads to better long-tailed learning results. In contrast to existing works, we provide systematic strategies through two viewpoints of imbalanced labels, which boost imbalanced learning in both semi-supervised and self-supervised manners.</p><p>Semi-Supervised Learning. Semi-supervised learning is concerned with learning from both unlabeled and labeled samples, where typical methods ranging from entropy minimization <ref type="bibr" target="#b17">[18]</ref>, pseudolabeling [30], to generative models <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr">29,</ref><ref type="bibr">42,</ref><ref type="bibr" target="#b34">56]</ref>. Recently, a line of work that proposes to use consistency-based regularization approaches has shown promising performance in semi-supervised tasks, where consistency loss is integrated to push the decision boundary to low-density areas using unlabeled data <ref type="bibr" target="#b2">[3,</ref><ref type="bibr">28,</ref><ref type="bibr">35,</ref><ref type="bibr" target="#b21">43,</ref><ref type="bibr" target="#b24">46,</ref><ref type="bibr" target="#b28">50]</ref>. The common evaluation protocol assumes the unlabeled data comes from the same or similar distributions as labeled data, while authors in [39] argue it may not reflect realistic settings. In our work, we consider the data imbalance in both labeled and unlabeled datasets, as well as the data relevance for the unlabeled data, which altogether provides a principled setup on semi-supervised learning for imbalanced learning tasks.</p><p>Self-Supervised Learning. Learning with self-supervision has recently attracted increasing interests, where early approaches mainly rely on pretext tasks, including exemplar classification <ref type="bibr" target="#b13">[14]</ref>, predicting relative locations of image patches <ref type="bibr" target="#b11">[12]</ref>, image colorization <ref type="bibr" target="#b35">[57]</ref>, solving jigsaw puzzles of image patches [37], object counting [38], clustering <ref type="bibr" target="#b8">[9]</ref>, and predicting the rotation of images <ref type="bibr" target="#b15">[16]</ref>. More recently, a line of work based on contrastive losses <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr">40,</ref><ref type="bibr" target="#b25">47]</ref> shows great success in self-supervised representation learning, where similar embeddings are learned for different views of the same training example, and dissimilar embeddings for different training examples. Our work investigates self-supervised pre-training in class-imbalanced context, revealing surprising yet intriguing findings on how the self-supervision can help alleviate the biased label effect in imbalanced learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We systematically study the value of labels in class-imbalanced learning, and propose two theoretically grounded strategies to understand, validate, and leverage such imbalanced labels in both semi-and self-supervised manners. On both sides, sound theoretical guarantees as well as superior performance on large-scale imbalanced datasets are demonstrated, confirming the significance of the proposed schemes. Our findings open up new avenues for learning imbalanced data, highlighting the need to rethink what is the best way to leverage the inherently biased labels to improve imbalanced learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>Real-world data often exhibits skewed distributions with a long tail, rather than the ideal uniform distributions over each class. We tackle this important problem through two novel perspectives: (1) using unlabeled data without depending on additional human labeling; (2) explore intrinsic properties from data itself with self-supervision. These simple yet effective strategies introduce new frameworks for improving generic imbalanced learning tasks, which we believe will broadly benefit practitioners dealing with heavily imbalanced data in realistic applications.</p><p>On the other hand, however, we only extensively test our strategies on academic datasets. In many real-world applications such as autonomous driving, medical diagnosis, and healthcare, beyond being naturally imbalanced, the data may impose additional constraints on learning process and final models, e.g., being fair or private. We focus on standard accuracy as our measure and largely ignore other ethical issues in imbalanced data, especially in minor classes. As such, the risk of producing unfair or biased outputs reminds us to carry rigorous validations in critical, high-stakes applications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices A Proof of Theorem 1</head><p>Given the pseudo-labels, we note that we can rewriteX</p><formula xml:id="formula_11">+ i = (1 ? I + i )(? 2 ? ? 1 ) + Z + i , where Z + i ? N (? 1 , ? 2 ) and I + i ? Bernoulli(p). That is, if the pseudo-label is correct, thenX + i ? Z + i and otherwise,X + i ? (? 2 ? ? 1 ) + Z + i . Similarly,X ? i = (1 ? I ? i )(? 1 ? ? 2 ) + Z ? i , where Z ? i ? N (? 2 , ? 2 ) and I ? i ? Bernoulli(q). Now, ? = 1 2 ?+ i=1X + ? n + + ?? i=1X ? ? n ? = 1 2 ?+ i=1 (1 ? I + i )(? 2 ? ? 1 ) + Z + ? n + + ?? i=1 (1 ? I ? i )(? 1 ? ? 2 ) + Z ? ? n ? = 1 2 ?+ i=1 I + i (? 1 ? ? 2 ) n + + ?? i=1 I ? i (? 2 ? ? 1 ) n ? + ?+ i=1 Z + ? n + + ?? i=1 Z ? ? n ? .<label>(1)</label></formula><p>We bound each term in Eq. (1) separately. First, note that</p><formula xml:id="formula_12">?+ i=1 Z + ? n + + ?? i=1 Z ? ? n ? ? N ? 1 + ? 2 , ? 2 1 n + + 1 n ? .</formula><p>By standard Gaussian concentration, we have</p><formula xml:id="formula_13">P ?+ i=1 Z + ? n + + ?? i=1 Z ? ? n ? ? (? 1 + ? 2 ) &gt; t ? 2e ? t 2 2? 2 ? 1 1 n + + 1 n ? .<label>(2)</label></formula><p>Next, we bound the term</p><formula xml:id="formula_14">? + i=1 I + ? n+</formula><p>. Since I + i ? Bernoulli(p), applying Hoeffding inequality</p><formula xml:id="formula_15">P ?+ i=1 I + ? n + ? p &gt; t ? 2e ?2?+t 2 .<label>(3)</label></formula><p>Similarly, we have</p><formula xml:id="formula_16">P ?? i=1 I ? ? n ? ? q &gt; t ? 2e ?2??t 2 .<label>(4)</label></formula><p>Note that by triangle inequality,</p><formula xml:id="formula_17">? ? ?(? 1 ? ? 2 ) 2 ? (? 1 + ? 2 ) 2 = 1 2 ?+ i=1X + ? n + + ?? i=1X ? ? n ? ? p(? 1 ? ? 2 ) 2 ? q(? 2 ? ? 1 ) 2 ? (? 1 + ? 2 ) 2 ? 1 2 ?+ i=1 I + ? n + ? p 2 |? 1 ? ? 2 | + 1 2 ?? i=1 I ? ? n ? ? q 2 |? 1 ? ? 2 | + 1 2 ?+ i=1 Z + ? n + + ?? i=1 Z ? ? n ? ? ? 1 + ? 2 2 .</formula><p>Given ? &gt; 0, consider the event that</p><formula xml:id="formula_18">E = 1 2 ?+ i=1 I + ? n + ? p 2 |? 1 ? ? 2 | ? ? 3 and 1 2 ?? i=1 I ? ? n ? ? q 2 |? 1 ? ? 2 | ? ? 3 and 1 2 ?+ i=1 Z + ? n + + ?? i=1 Z ? ? n ? ? ? 1 + ? 2 2 ? ? 3 .</formula><p>Using union bound and the concentration inequalities Eqs. <ref type="bibr" target="#b1">(2)</ref>, <ref type="formula" target="#formula_15">(3)</ref> and <ref type="formula" target="#formula_16">(4)</ref>, we obtain the following lower bound on the probability of event E:</p><formula xml:id="formula_19">P(E) ? 1 ? 2e ? 2? 2 9? 2 ? 1 1 n + + 1 n ? ? 2e ? 8? + ? 2 9(? 1 ?? 2 ) 2 ? 2e ? 8? ? ? 2 9(? 1 ?? 2 ) 2 .</formula><p>Finally, the above equation and the triangle inequality implies that</p><formula xml:id="formula_20">P ? ? ?(? 1 ? ? 2 ) 2 ? (? 1 + ? 2 ) 2 ? ? ? 1 ? 2e ? 2? 2 9? 2 ? 1 1 n + + 1 n ? ? 2e ? 8? + ? 2 9(? 1 ?? 2 ) 2 ? 2e ? 8? ? ? 2 9(? 1 ?? 2 ) 2 .</formula><p>This completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Proof of Theorem 2</head><p>Note that if X ? N (0, ? 2 I d ), then for a given ?, ? T X ? N (0, ||?|| 2 2 ? 2 ). Based on the form of the linear classifier, we know that</p><formula xml:id="formula_21">err f = P (X,Y )?P XY y(? T X + b) &lt; 0 = P (X,Y )?P XY y(? T X + b) &lt; 0 Y = +1 P Y = +1 + P (X,Y )?P XY y(? T X + b) &lt; 0 Y = ?1 P Y = ?1 = p + P N (0, ||?|| 2 2 ? 2 1 ) &lt; ?b + p ? P N (0, ||?|| 2 2 ?? 2 1 ) &gt; ?b = p + P N (0, 1) &lt; ? b ||?|| 2 ? 1 + p ? P N (0, 1) &lt; b ||?|| 2 ? ?? 1 = p + ? ? b ||?|| 2 ? 1 + p ? ? b ||?|| 2 ? ?? 1 .</formula><p>Finally, note that for b &gt; 0, ? b ||?||2 ? ??1 ? 1/2. Since p ? is assumed to be at least 1/2, the error probability of the classifier is at least 1/4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Proof of Theorem 3</head><p>We recall the following standard concentration inequality for sub-exponential random variables <ref type="bibr" target="#b29">[51]</ref>. Suppose that W 1 , W 2 , . . . , W n are i.i.d. sub-exponential random variables with parameters (?, ?). Then,</p><formula xml:id="formula_22">P 1 n n i=1 (W i ? E [X i ]) ? ? ? ? ? ? e ? n? 2 2? 2 , for 0 ? ? ? ? 2 ? ; e ? n? 2?</formula><p>, for ? &gt; ? 2 ? . We remark that a similar two-sided tail bounds also hold. For our purpose, note that if W ? N (0, 1), then W 2 is sub-exponential with parameter <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b3">4)</ref>. Therefore, we have the standard ? 2 -concentration for a ? 2 random variable with degree n as follows:</p><formula xml:id="formula_23">P 1 n n i=1 W 2 i ? 1 ? ? ? 2e ?n? 2 /8 , ? ? ? (0, 1).</formula><p>Let us now analyze the classifier f ss (X) = sign(?Z +b) obtained by self-supervised training. Recall that we assume Z = ?(X) = k 1 ||X|| 2 2 + k 2 . For the negative training data, we note that Zi?k2</p><formula xml:id="formula_24">k1?? 2 1 ? ? 2 d</formula><p>(the ? 2 distribution with d degree of freedom). Using the previous ? 2 concentration, we have that for ? ? (0, 1),</p><formula xml:id="formula_25">P 1 N ? d N i=1 1 {Yi=?1} Z i ? k 2 k 1 ?? 2 1 ? 1 ? ? ? 2e ?N?d? 2 /8 .</formula><p>Rearrange the terms, we obtain</p><formula xml:id="formula_26">P 1 N ? N i=1 1 {Yi=?1} Z i ? dk 1 ?? 2 1 + k 2 ? ?dk 1 ?? 2 1 ? 2e ?N?d? 2 /8 .</formula><p>Similarly, for the positive training data, we have</p><formula xml:id="formula_27">P 1 N + N i=1 1 {Yi=+1} Z i ? dk 1 ? 2 1 + k 2 ? ?dk 1 ? 2 1 ? 2e ?N+d? 2 /8 .</formula><p>Therefore, by an application of union bound, with probability at least 1 ? 2e ?N?d? 2 /8 ? 2e ?N+d? 2 /8 , the intercept b of the self-supervised classifier, i.e., b = 1</p><formula xml:id="formula_28">2 N i=1 1 {Y i =+1} Zi N+ + N i=1 1 {Y i =?1} Zi N? &gt; 0, satisfies b ? dk 1 (? + 1)? 2 1 2 ? k 2 ? ?dk 1 (? + 1)? 2 1 2 .<label>(5)</label></formula><p>In the following, we condition on the event that b satisfies the bound in Eq. <ref type="bibr" target="#b4">(5)</ref>. Then,</p><formula xml:id="formula_29">err fss = P (X,Y )?P XY y(?Z + b) &lt; 0 = P (X,Y )?P XY y(?Z + b) &lt; 0|Y = +1 P Y = +1 + P (X,Y )?P XY y(?Z + b) &lt; 0|Y = ?1 P Y = ?1 = p + P (X,Y )?P XY Z &gt; b|Y = +1 + p ? P (X,Y )?P XY Z &lt; b|Y = ?1 ? p + P (X,Y )?P XY Z &gt; dk 1 (? + 1)? 2 1 2 + k 2 ? ?dk 1 (? + 1)? 2 1 2 Y = +1 + p ? P (X,Y )?P XY Z &lt; dk 1 (? + 1)? 2 1 2 + k 2 + ?dk 1 (? + 1)? 2 1 2 Y = ?1 . (6)</formula><p>We analyze the two terms in the bound Eq. <ref type="bibr" target="#b5">(6)</ref>. First, condition on Y = ?1, again note that</p><formula xml:id="formula_30">Z?k2 k1?? 2 1 ? ? 2 d . Therefore, P Z &lt; dk 1 (? + 1)? 2 1 2 + k 2 + ?dk 1 (? + 1)? 2 1 2 Y = ?1 = P Z ? (dk 1 ?? 2 1 + k 2 ) &lt; ? (? ? 1 ? ?(? + 1)) 2? dk 1 ?? 2 1 Y = ?1 ? exp ?d ? (? ? 1 ? ?(? + 1)) 2 32? 2 ,</formula><p>where the last inequality follows from the concentration inequality and note that 0 &lt; (? ? 1 ? ?(? + 1)/2? &lt; 1. In a similar manner, for Y = +1, note that Z?k2</p><formula xml:id="formula_31">k1? 2 1 ? ? 2 d . Hence, P Z &gt; dk 1 (? + 1)? 2 1 2 + k 2 ? ?dk 1 (? + 1)? 2 1 2 Y = +1 = P Z ? (dk 1 ? 2 1 + k 2 ) &gt; (? ? 1 ? ?(? + 1)) 2 dk 1 ? 2 1 Y = +1 ? ? ? ? ? ? exp ?d ? (??1??(?+1)) 2 32 , if ? ? ??3 ?+1 , ??1 ?+1 ; exp ?d ? (??1??(?+1)) 16 , if ? ? 0, ??3 ?+1 .</formula><p>For the last inequality, we note that if ? ? ??3 ?+1 , ??1 ?+1 , 0 &lt; (??1??(?+1)) 2 ? 1; otherwise, (??1??(?+1)) 2 &gt; 1. Substituting the above inequalities into the error probability err fss (Eq. (6)) completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Experimental Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Imbalanced Dataset Details</head><p>In this section, we provide the detailed information of five long-tailed imbalanced datasets we use in our experiments. <ref type="table" target="#tab_6">Table 5</ref> provides an overview of the five datasets. CIFAR-10-LT and CIFAR-100-LT. The original versions of CIFAR-10 and CIFAR-100 contain 50,000 images for training and 10,000 images for testing with class number of 10 and 100, respectively. We create the long-tailed CIFAR versions following <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11]</ref> with controllable degrees of data imbalance, and keep the test set unchanged. We vary the class imbalance ratio ? from 10 to 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SVHN-LT.</head><p>The original SVHN dataset contains 73,257 images for training and 26,032 images for testing with 10 classes. Similarly to CIFAR-LT, we create SVHN-LT dataset with maximally 1,000 images per class (head class), and vary ? from 10 to 100 for different long-tailed versions.</p><p>ImageNet-LT. ImageNet-LT [33] is artificially truncated from its balanced version, with sample size in the training set following an exponential decay across different classes. ImageNet-LT has 1,000 classes and 115.8K training images, with number of images ranging from 1,280 to 5 images per class.</p><p>iNaturalist 2018. iNaturalist 2018 [24] is a real-world fine-grained visual recognition dataset that naturally exhibits long-tailed class distributions, consisting of 435,713 samples from 8,142 species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Unlabeled Data Details</head><p>We provide additional information on the unlabeled data we use in the semi-supervised settings, i.e., the unlabeled data sourcing, and how we create unlabeled sets with different imbalanced distributions.</p><p>Unlabeled Data Sourcing. To obtain the unlabeled data needed for our semi-supervised setup, we follow <ref type="bibr" target="#b7">[8]</ref> to mine the 80 Million Tiny Images (80M) dataset <ref type="bibr" target="#b26">[48]</ref> to source unlabeled and uncurated data for CIFAR-10. In particular, CIFAR-10 is a human-labeled subset of 80M, which is manually restricted to 10 classes. Accordingly, most images in 80M do not belong to any image categories in CIFAR-10. To select unlabeled data that exhibit similar distributions as labeled ones, we follow the procedure as in <ref type="bibr" target="#b7">[8]</ref>, where an 11-class classification model is trained to distinguish CIFAR-10 classes and an "non-CIFAR" class. For each class, we then rank the images based on the prediction confidence, and construct the unlabeled (imbalanced) dataset D U according to our settings.</p><p>For SVHN, since its own dataset contains an extra part [36] with 531.1K additional (labeled) samples, we directly use these additional data to simulate the unlabeled dataset, which exhibits similar data distribution as the main dataset. Specifically, the ground truth labels are used only for preparing D U , and are abandoned throughout experiments (i.e., before performing pseudo-labeling).</p><p>Relevant (and Irrelevant) Unlabeled Data. To analyze the data relevance of unlabeled data with class imbalance (cf. Sec. 3), we again employ the 11-way classifier to select samples with prediction scores that are high for the extra class, and use them as proxy for irrelevant data. We then mix the irrelevant dataset and our main unlabeled dataset with different proportions, thus creating a sequence of unlabeled datasets with different degrees of data relevance.</p><p>Unlabeled Data with Class Imbalance. With the sourced unlabeled data, we construct the demanded unlabeled dataset D U also with class imbalance. In <ref type="figure">Fig. 5</ref>, we show an example of data distributions of both original labeled imbalanced dataset D L and D U with different unlabeled imbalance ratio. Specifically, <ref type="figure">Fig. 5a</ref> presents the training and test set of CIFAR-10-LT with ? = 100, where a long  <ref type="figure">Figure 5</ref>: An illustration of labeled dataset (DL) as well as its corresponding unlabeled dataset (DU @5x) under different unlabeled imbalance ratio ?U . Given DL with a fixed ?, the total amount of DU is fixed, while different ?U will lead to different class distributions of the unlabeled data.</p><p>tail can be observed for the training set, while the test set is balanced across classes. With labeled data on hand, we create different degrees of class imbalance in D U to be (1) uniform (? U = 1, <ref type="figure">Fig. 5b</ref>), (2) half imbalanced as labeled set (? U = ?/2, <ref type="figure">Fig. 5c</ref>), (3) same imbalanced (? U = ?, <ref type="figure">Fig. 5d</ref>), and (4) double imbalanced (? U = 2?, <ref type="figure">Fig. 5e</ref>). Note that the total data amount of D U is fixed (e.g., 5x as labeled set) given D L , while different ? U will result in different unlabeled data distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Implementation Details</head><p>CIFAR-10-LT and CIFAR-100-LT. Following <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11]</ref>, we use ResNet-32 <ref type="bibr" target="#b19">[20]</ref> for all CIFAR-LT experiments. The data augmentation follows <ref type="bibr" target="#b19">[20]</ref> to use zero-padding with 4 pixels on each side and then random crop back to the original image size, after which a random horizontal flip is performed. We train all models for 200 epochs, and remain all other hyper-parameters the same as <ref type="bibr" target="#b6">[7]</ref>. In the semi-supervised settings, we fix the unlabeled weight ? = 1 for all experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SVHN-LT.</head><p>Similarly to CIFAR-LT, we use ResNet-32 model for all SVHN-LT experiments, and fix the same hyper-parameters as in CIFAR-LT experiments throughout training.</p><p>ImageNet-LT. We follow [25,33] to report results with ResNet-10 and ResNet-50 models. Since <ref type="bibr">[33]</ref> only employs ResNet-10 model, we reproduce the results with ResNet-50 using the public code from the authors for fair comparison. During the classifier training stage, we train all models for 90 epochs, and keep all other hyper-parameters identical to those in <ref type="bibr">[25]</ref>. During the self-supervised pre-training stage, we leave the hyper-parameters unchanged as in <ref type="bibr" target="#b18">[19]</ref>, but only use samples from ImageNet-LT.</p><p>iNaturalist 2018. We follow <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr">25</ref>] to use ResNet-50 model. Similar to ImageNet-LT, we train all models for 90 epochs in the classifier training stage, and other hyper-parameters are kept the same as in <ref type="bibr">[25]</ref>. The self-supervised pre-training stage is remained the same as that on ImageNet-LT. We reproduce the results for <ref type="bibr" target="#b6">[7]</ref> on iNaturalist 2018 using the authors' code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Additional Results for Semi-Supervised Imbalanced Learning E.1 Different Semi-Supervised Learning Methods</head><p>We study the effect of different advanced semi-supervised learning methods, in addition to the simple pseudo-label strategy we apply in the main text. We select the following two methods for analysis.</p><p>Virtual Adversarial Training. Virtual adversarial training (VAT) <ref type="bibr">[35]</ref> is one of the state-of-the-art semi-supervised learning methods, which aims to make the predicted labels robust around input data point against local perturbation. It approximates a tiny perturbation adv to add to the (unlabeled) inputs which would most significantly affect the outputs of the model. Note that the implementation difference between VAT and the pseudo-label is the loss term on the unlabeled data, where VAT exhibits a consistency regularization loss rather than supervised loss, resulting in a loss function as L(D L , ?) + ?L con (D U , ?). We add an additional entropy regularization term following <ref type="bibr">[35]</ref>.</p><p>Mean Teacher. The mean teacher (MT) <ref type="bibr" target="#b24">[46]</ref> method is also a representative algorithm using consistency regularization, where a teacher model and a student model are maintained and a consistency cost between the student's and the teacher's outputs is introduced. The teacher weights are updated through an exponential moving average (EMA) of the student weights.</p><p>Similar to pseudo-label, the two semi-supervised methods can be seamlessly incorporated with our imbalanced learning framework. We present the results with these methods in <ref type="table" target="#tab_7">Table 6</ref>. For each run, we construct D U @5x with the same imbalance ratio as the labeled set (i.e., ? U = ?). As  <ref type="table" target="#tab_7">Table 6</ref> reports, across different datasets and imbalance ratios, adding unlabeled data can consistently benefit imbalanced learning via semi-supervised learning. Moreover, by using more advanced SSL techniques, larger improvements can be obtained in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Class-wise Generalization Results</head><p>In the main paper, we report the top-1 test errors as the final performance metric. To gain additional insights on how unlabeled data helps imbalanced tasks, we further look at the generalization results in each class, especially on the minority (tail) classes.</p><p>Generalization on Minority Classes. In <ref type="figure" target="#fig_4">Fig. 6</ref> we plot the test error on each class on CIFAR-10-LT and SVHN-LT with ? = 50. As the figure shows, regardless of the base training technique, using unlabeled data can consistently and substantially improve the generalization on tail classes. Confusion Matrix. We further show the confusion matrices on CIFAR-10-LT with and without D U . <ref type="figure">Fig. 7</ref> presents the results, where for the vanilla CE training, predictions for tail classes are biased towards the head classes significantly. In contrast, by using unlabeled data, the leakage from tail classes to head classes can be largely eliminated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Effect of Unlabeled Data Amount</head><p>We study the effect of the size of the unlabeled dataset on our SSL approach in imbalanced learning. We first fix the labeled dataset D L with ? = 50, the unlabeled imbalance ratio to be ? U = ?, and then vary the amount of D U to be {0.5x,1x,5x,10x} of the size of D L . <ref type="table" target="#tab_8">Table 7</ref> reports the results, where we can observe that larger D U consistently leads to higher gains. Furthermore, even with only 0.5x more unlabeled data, the performance can be boosted largely compared to that without unlabeled data. Interestingly however, as the size of D U becomes larger, the gains gradually diminish. , we further study how the labeled data amount affects SSL in imbalanced learning. We fix the imbalance ratios of D L and D U as ? = ? U = 50, and also fix the size of D U to be 5x of D L . We vary D L amount to be {0.5x,0.75x,1x} with respect to the original labeled data amount. As <ref type="table" target="#tab_9">Table 8</ref> shows, with smaller size of labeled data, the test errors of vanilla CE training increases largely, while adding unlabeled data can maintain sufficiently low errors. Interestingly, when unlabeled data is added, using only 50% of labeled data can already surpass the fully-supervised baseline on both datasets, demonstrating the power of unlabeled data in the context of imbalanced learning. In this section, we investigate the effect of different SSP methods on imbalanced learning tasks. We select four different SSP approaches, ranging from pretext tasks to recent contrastive methods.</p><p>Solving Jigsaw Puzzles. Jigsaw [37] is a classical method based on pretext tasks, where an image is divided into patches, and a classifier is trained to predict the correct permutation of these patches.</p><p>Rotation Prediction. Predicting rotation <ref type="bibr" target="#b15">[16]</ref> is another simple yet effective method, where an image is rotated by a random multiple of 90 degrees, constructing a 4-way classification problem; a classifier is then trained to determine the degree of rotation applied to an input image.</p><p>Selfie. Selfie <ref type="bibr" target="#b27">[49]</ref> works by masking out select patches in an image, and then constructs a classification problem to determine the correct patch to be filled in the masked location.</p><p>Momentum Contrast. The momentum contrast (MoCo) <ref type="bibr" target="#b18">[19]</ref> method is one of the recently proposed contrastive techniques, where contrastive losses <ref type="bibr" target="#b18">[19]</ref> are applied in a representation space to measure the similarities of positive and negative sample pairs, and a momentum-updated encoder is employed.</p><p>We conduct controlled experiments over four benchmark imbalanced datasets, and report the results in <ref type="table" target="#tab_10">Table 9</ref>. As the table reveals, all self-supervised pre-training methods can benefit the imbalanced learning, consistently across different datasets. Interestingly however, the performance gain varies across SSP techniques. Specifically, on datasets with smaller scale, i.e., CIFAR-10-LT and CIFAR-100-LT, methods using pretext tasks are generally better than using contrastive learning, with Rotation performs the best. In contrast, on larger datasets, i.e., ImageNet-LT and iNaturalist, MoCo outperforms other SSP methods by a notable margin. We hypothesize that since MoCo needs a large number of (negative) samples to be effective, the smaller yet imbalanced datasets thus may not benefit much from MoCo, compared to those with larger size and more samples. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Class-wise Generalization Results</head><p>Similar to the semi-supervised setting, we again take a closer look at generalization on each class to gain further insights, in addition to the top-1 test error rates reported in the main text.</p><p>Generalization on Minority Classes. We plot the class-wise top-1 errors on CIFAR-10-LT ( <ref type="figure" target="#fig_6">Fig. 8a)</ref> and ImageNet-LT ( <ref type="figure" target="#fig_6">Fig. 8b)</ref>, respectively. For ImageNet-LT, we follow [25, 33] to split the test set into three subsets for evaluating shot-wise accuracy, namely Many-shot (classes with more than 100 images), Medium-shot (20 ? 100 images), and Few-shot (less than 20 images). On both datasets, we can observe that regardless of training techniques for the base classifier, using SSP can consistently and substantially improve the generalization on tail (few-shot) classes, while maintaining or slightly improving the performance on head (many-shot) classes. The consistent gains demonstrate the effectiveness of SSP in the context of imbalanced learning, especially for the tail classes. stands for the tail class. On ImageNet-LT we follow [33] to report test error on three splits of the set of classes: Many-shot, Medium-shot, and Few-shot. Using SSP leads to better generalization on both head and tail classes, and can consistently boost different training techniques. Results are averaged across 5 runs.</p><p>Confusion Matrix. To further understand how self-supervision helps imbalanced learning, we again plot the confusion matrices on CIFAR-10-LT with and without SSP, respectively. As illustrated in <ref type="figure" target="#fig_7">Fig. 9</ref>, the prediction results of vanilla CE training suffers from the large leakage from tail classes to head classes, leading to low accuracy on minority categories. In contrast, by using self-supervised pre-training, the tail-to-head class leakages are greatly compensated, resulting in better performance and consistent improvements across the tail classes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 Effect of Imbalance Type</head><p>Finally, we conduct ablation study on another type of imbalance. The majority of the literature <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr">25,</ref><ref type="bibr">33,</ref><ref type="bibr" target="#b37">59]</ref> focused on the long-tailed imbalance distribution, which is also the typical scenario for large-scale real-world datasets <ref type="bibr">[24,</ref><ref type="bibr">33]</ref>. Yet, few other manually designed imbalance types are also investigated by researchers <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7]</ref> to provide a comprehensive picture. For completeness, we study the performance of SSP under another imbalance type, i.e., the step imbalance <ref type="bibr" target="#b4">[5]</ref>, where the training instances of half of the classes (i.e., the minority classes) are reduced to a fixed size. The minority classes are defined to have the same sample size, and so do all frequent classes. The imbalance ratio ? is the same as in long-tailed setting, i.e., ? = max i {n i }/ min i {n i }. <ref type="table" target="#tab_0">Table 10</ref> presents the results, where we confirm that SSP can bring in consistent benefits across different imbalanced learning techniques on various datasets. Furthermore, when the dataset is more imbalanced (i.e., with higher ?), the performance gains from SSP tend to be even larger, demonstrating the value of self-supervision under extreme class imbalance. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(a) Standard CE training (b) With unlabeled data DU @5x (colored in black) t-SNE visualization of training &amp; test set on SVHN-LT. Using unlabeled data helps to shape clearer class boundaries and results in better class separation, especially for the tail classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Test errors of different unlabeled data relevance ratios on CIFAR-10-LT with ? = 50. We fix ?U = 50 for the relevant unlabeled data. Test errors of different ?U of relevant unla-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) Standard CE training (b) Standard CE training with SSP Figure 4: t-SNE visualization of training &amp; test set on CIFAR-10-LT. Using SSP helps mitigate the tail classes leakage during testing, which results in better learned boundaries and representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>DU , ?U = 2?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Class-wise top-1 error rates. C0 stands for the head class, and C9 stands for the tail class. Using unlabeled data leads to better generalization on tail classes while keeping the performance on head classes almost unaffected, and can consistently boost different training techniques. Results are averaged across 5 runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>8 (Figure 7 :</head><label>87</label><figDesc>b) CE with unlabeled data DU @5x Confusion matrices of standard CE training and using DU @5x on CIFAR-10-LT with ? = 100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Class-wise top-1 error rates on CIFAR-10-LT and ImageNet-LT. C0 stands for the head class, and C9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Confusion matrices of standard CE training and using SSP on CIFAR-10-LT with ? = 100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Top-1 test errors (%) of ResNet-32 on long-tailed CIFAR-10 and SVHN. We compare SSL using 5x unlabeled data (DU @5x) with corresponding supervised baselines. Imbalanced learning can be drastically improved with unlabeled data, which is consistent across different ?U and learning strategies. DU @5x 11.32 11.70 11.92 12.78 10.98 11.14 11.26 11.51 8.94 9.08 8.70 9.35</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">(a) CIFAR-10-LT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Imbalance Ratio (?)</cell><cell></cell><cell>100</cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell><cell>10</cell><cell></cell></row><row><cell cols="2">DU Imbalance Ratio (?U ) 1</cell><cell>?/2</cell><cell>?</cell><cell>2?</cell><cell>1</cell><cell>?/2</cell><cell>?</cell><cell>2?</cell><cell>1</cell><cell>?/2</cell><cell>?</cell><cell>2?</cell></row><row><cell>CE</cell><cell></cell><cell cols="2">29.64</cell><cell></cell><cell></cell><cell cols="2">25.19</cell><cell></cell><cell></cell><cell cols="2">13.61</cell></row><row><cell>CE + DU @5x</cell><cell cols="12">17.48 18.42 18.74 20.06 16.79 16.88 18.36 19.94 10.22 10.48 10.86 11.04</cell></row><row><cell>LDAM-DRW [7]</cell><cell></cell><cell cols="2">22.97</cell><cell></cell><cell></cell><cell cols="2">19.06</cell><cell></cell><cell></cell><cell cols="2">11.84</cell></row><row><cell cols="13">LDAM-DRW + DU @5x 14.96 15.18 15.33 15.55 14.33 14.70 14.93 15.24 8.72 8.24 8.68 8.97</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) SVHN-LT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Imbalance Ratio (?)</cell><cell></cell><cell>100</cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell><cell>10</cell><cell></cell></row><row><cell cols="2">DU Imbalance Ratio (?U ) 1</cell><cell>?/2</cell><cell>?</cell><cell>2?</cell><cell>1</cell><cell>?/2</cell><cell>?</cell><cell>2?</cell><cell>1</cell><cell>?/2</cell><cell>?</cell><cell>2?</cell></row><row><cell>CE</cell><cell></cell><cell cols="2">19.98</cell><cell></cell><cell></cell><cell cols="2">17.50</cell><cell></cell><cell></cell><cell cols="2">11.46</cell></row><row><cell>CE + DU @5x</cell><cell cols="12">13.02 13.73 14.65 15.04 13.07 13.36 13.16 14.54 10.01 10.20 10.06 10.71</cell></row><row><cell>LDAM-DRW [7]</cell><cell></cell><cell cols="2">16.66</cell><cell></cell><cell></cell><cell cols="2">14.59</cell><cell></cell><cell></cell><cell cols="2">10.27</cell></row><row><cell>LDAM-DRW +</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Top-1 test error rates (%) of ResNet-32 on long-tailed CIFAR-10 and CIFAR-100. Using SSP, we consistently improve different imbalanced learning techniques, and achieve the best performance.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>CIFAR-10-LT</cell><cell></cell><cell></cell><cell>CIFAR-100-LT</cell><cell></cell></row><row><cell>Imbalance Ratio (?)</cell><cell>100</cell><cell>50</cell><cell>10</cell><cell>100</cell><cell>50</cell><cell>10</cell></row><row><cell>CE</cell><cell>29.64</cell><cell>25.19</cell><cell>13.61</cell><cell>61.68</cell><cell>56.15</cell><cell>44.29</cell></row><row><cell>CB-CE [11]</cell><cell>27.63</cell><cell>21.95</cell><cell>13.23</cell><cell>61.44</cell><cell>55.45</cell><cell>42.88</cell></row><row><cell>CB-CE + SSP</cell><cell>23.47</cell><cell>19.60</cell><cell>11.57</cell><cell>56.94</cell><cell>52.91</cell><cell>41.94</cell></row><row><cell>Focal [32]</cell><cell>29.62</cell><cell>23.29</cell><cell>13.34</cell><cell>61.59</cell><cell>55.68</cell><cell>44.22</cell></row><row><cell>CB-Focal [11]</cell><cell>25.43</cell><cell>20.73</cell><cell>12.90</cell><cell>60.40</cell><cell>54.83</cell><cell>42.01</cell></row><row><cell>CB-Focal + SSP</cell><cell>22.90</cell><cell>18.74</cell><cell>11.75</cell><cell>57.03</cell><cell>53.12</cell><cell>41.16</cell></row><row><cell>CE-DRW [7]</cell><cell>24.94</cell><cell>21.10</cell><cell>13.57</cell><cell>59.49</cell><cell>55.31</cell><cell>43.78</cell></row><row><cell>CE-DRS [7]</cell><cell>25.53</cell><cell>21.39</cell><cell>13.73</cell><cell>59.62</cell><cell>55.46</cell><cell>43.95</cell></row><row><cell>CE-DRW + SSP</cell><cell>23.04</cell><cell>19.93</cell><cell>12.66</cell><cell>57.21</cell><cell>53.57</cell><cell>41.77</cell></row><row><cell>LDAM [7]</cell><cell>26.65</cell><cell>23.18</cell><cell>13.04</cell><cell>60.40</cell><cell>55.03</cell><cell>43.09</cell></row><row><cell>LDAM-DRW [7]</cell><cell>22.97</cell><cell>19.06</cell><cell>11.84</cell><cell>57.96</cell><cell>53.85</cell><cell>41.29</cell></row><row><cell>LDAM-DRW + SSP</cell><cell>22.17</cell><cell>17.87</cell><cell>11.47</cell><cell>56.57</cell><cell>52.89</cell><cell>41.09</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Top-1 test error rates (%) on ImageNet-LT. ? denotes results reproduced with authors' code.</figDesc><table><row><cell>Method</cell><cell cols="2">ResNet-10 ResNet-50</cell></row><row><cell>CE (Uniform)</cell><cell>65.2</cell><cell>61.6</cell></row><row><cell>CE (Uniform) + SSP</cell><cell>64.1</cell><cell>54.4</cell></row><row><cell>CE (Balanced)</cell><cell>62.9</cell><cell>59.7</cell></row><row><cell>CE (Balanced) + SSP</cell><cell>61.6</cell><cell>52.4</cell></row><row><cell>OLTR [33]</cell><cell>64.4</cell><cell>62.6  ?</cell></row><row><cell>OLTR + SSP</cell><cell>62.3</cell><cell>53.9</cell></row><row><cell>cRT [25]</cell><cell>58.2</cell><cell>52.7</cell></row><row><cell>cRT + SSP</cell><cell>56.8</cell><cell>48.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Top-1 test error rates (%) on iNaturalist 2018. ? denotes results reproduced with authors' code.</figDesc><table><row><cell>Method</cell><cell>ResNet-50</cell></row><row><cell>CE (Uniform)</cell><cell>39.3</cell></row><row><cell>CE (Uniform) + SSP</cell><cell>35.6</cell></row><row><cell>CE (Balanced)</cell><cell>36.5</cell></row><row><cell>CE (Balanced) + SSP</cell><cell>34.1</cell></row><row><cell>LDAM-DRW [7]</cell><cell>35.4  ?</cell></row><row><cell>LDAM-DRW + SSP</cell><cell>33.7</cell></row><row><cell>cRT [25]</cell><cell>34.8</cell></row><row><cell>cRT + SSP</cell><cell>31.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>[22] Chen Huang, Yining Li, Chen Change Loy, and Xiaoou Tang. Learning deep representation for imbalanced classification. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5375-5384, 2016.[23] Chen Huang, Yining Li, Change Loy Chen, and Xiaoou Tang. Deep imbalanced learning for face recognition and attribute prediction. IEEE transactions on pattern analysis and machine intelligence, 2019.</figDesc><table><row><cell>[24] iNatrualist. The inaturalist 2018 competition dataset. https://github.com/visipedia/</cell></row><row><cell>inat_comp/tree/master/2018, 2018.</cell></row><row><cell>[25] Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng,</cell></row><row><cell>and Yannis Kalantidis. Decoupling representation and classifier for long-tailed recognition.</cell></row><row><cell>arXiv:1910.09217, 2019.</cell></row><row><cell>[26] Salman Khan, Munawar Hayat, Syed Waqas Zamir, Jianbing Shen, and Ling Shao. Striking</cell></row><row><cell>the right balance with uncertainty. In The IEEE Conference on Computer Vision and Pattern</cell></row><row><cell>Recognition (CVPR), June 2019.</cell></row><row><cell>[27] Salman H Khan, Munawar Hayat, Mohammed Bennamoun, Ferdous A Sohel, and Roberto</cell></row><row><cell>Togneri. Cost-sensitive learning of deep feature representations from imbalanced data. IEEE</cell></row><row><cell>transactions on neural networks and learning systems, 29(8):3573-3587, 2017.</cell></row></table><note>[28] Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. arXiv preprint arXiv:1610.02242, 2016.[29] Bruno Lecouat, Chuan-Sheng Foo, Houssam Zenati, and Vijay Chandrasekhar. Manifold regularization with gans for semi-supervised learning. arXiv preprint arXiv:1807.04307, 2018.[30] Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In ICML Workshop on Challenges in Representation Learning, 2013.[31] Hansang Lee, Minseok Park, and Junmo Kim. Plankton classification on imbalanced large scale database via convolutional neural networks with transfer learning. In IEEE international conference on image processing (ICIP), pages 3713-3717, 2016.[32] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll?r. Focal loss for dense object detection. In ICCV, pages 2980-2988, 2017.[33] Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and Stella X Yu. Large-scale long-tailed recognition in an open world. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2537-2546, 2019.[34] Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 9:2579-2605, 2008.[35] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE transactions on pattern analysis and machine intelligence, 41(8):1979-1993, 2018.[36] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011.[37] Mehdi Noroozi and Paolo Favaro. Unsupervised learning of visual representations by solving jigsaw puzzles. In European Conference on Computer Vision, pages 69-84. Springer, 2016.[38] Mehdi Noroozi, Hamed Pirsiavash, and Paolo Favaro. Representation learning by learning to count. In ICCV, 2017.[39] Avital Oliver, Augustus Odena, Colin A Raffel, Ekin Dogus Cubuk, and Ian Goodfellow. Realistic evaluation of deep semi-supervised learning algorithms. In NeurIPS, 2018.[40] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive coding. arXiv:1807.03748, 2018.[41] Samira Pouyanfar, Yudong Tao, Anup Mohan, et al. Dynamic sampling in convolutional neural networks for imbalanced data classification. In IEEE conference on multimedia information processing and retrieval (MIPR), 2018.[42] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Overview of the five imbalanced datasets used in our experiments. ? indicates the imbalance ratio.</figDesc><table><row><cell>Dataset</cell><cell># Class</cell><cell>?</cell><cell cols="2">Head class size Tail class size</cell><cell># Training set</cell><cell cols="2"># Val. set # Test set</cell></row><row><cell>CIFAR-10-LT</cell><cell>10</cell><cell>10 ? 100</cell><cell>5,000</cell><cell>500 ? 50</cell><cell>20,431 ? 12,406</cell><cell>?</cell><cell>10,000</cell></row><row><cell>CIFAR-100-LT</cell><cell>100</cell><cell>10 ? 100</cell><cell>500</cell><cell>50 ? 5</cell><cell>19,573 ? 10,847</cell><cell>?</cell><cell>10,000</cell></row><row><cell>SVHN-LT</cell><cell>10</cell><cell>10 ? 100</cell><cell>1,000</cell><cell>100 ? 10</cell><cell>4,084 ? 2,478</cell><cell>?</cell><cell>26,032</cell></row><row><cell>ImageNet-LT</cell><cell>1,000</cell><cell>256</cell><cell>1,280</cell><cell>5</cell><cell>115,846</cell><cell>20,000</cell><cell>50,000</cell></row><row><cell cols="2">iNaturalist 2018 8,142</cell><cell>500</cell><cell>1,000</cell><cell>2</cell><cell>437,513</cell><cell>24,426</cell><cell>?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Ablation study of different semi-supervised learning methods on CIFAR-10-LT and SVHN-LT. We fix ?U = ? for each specific setting. Best results of each column are in bold and the second best are underlined.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>CIFAR-10-LT</cell><cell></cell><cell></cell><cell>SVHN-LT</cell><cell></cell></row><row><cell>Imbalance Ratio (?)</cell><cell>100</cell><cell>50</cell><cell>10</cell><cell>100</cell><cell>50</cell><cell>10</cell></row><row><cell>Vanilla CE</cell><cell>29.64</cell><cell>25.19</cell><cell>13.61</cell><cell>19.98</cell><cell>17.50</cell><cell>11.46</cell></row><row><cell>DU @5x + Pseudo-label [30]</cell><cell>18.74</cell><cell>18.36</cell><cell>10.86</cell><cell>14.65</cell><cell>13.16</cell><cell>10.06</cell></row><row><cell>DU @5x + VAT [35]</cell><cell>17.93</cell><cell>16.53</cell><cell>9.44</cell><cell>13.07</cell><cell>12.27</cell><cell>9.29</cell></row><row><cell>DU @5x + MT [46]</cell><cell>16.52</cell><cell>15.79</cell><cell>9.53</cell><cell>12.34</cell><cell>11.12</cell><cell>8.62</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Ablation study of how unlabeled data amount affects SSL in imbalanced learning. We fix the imbalance ratios as ? = ?U = 50. We vary the amount of DU with respect to labeled data amount (e.g., 0.5x means the size of DU is half of DL). Best results of each part are in bold and the second best are underlined.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell cols="2">CIFAR-10-LT</cell><cell></cell><cell></cell><cell cols="2">SVHN-LT</cell><cell></cell></row><row><cell>DU Size (w.r.t. DL)</cell><cell>0.5x</cell><cell>1x</cell><cell>5x</cell><cell>10x</cell><cell>0.5x</cell><cell>1x</cell><cell>5x</cell><cell>10x</cell></row><row><cell>CE</cell><cell></cell><cell cols="2">25.19</cell><cell></cell><cell></cell><cell cols="2">17.50</cell><cell></cell></row><row><cell>CE + DU</cell><cell>21.75</cell><cell>20.35</cell><cell>18.36</cell><cell>16.88</cell><cell>14.96</cell><cell>14.13</cell><cell>13.16</cell><cell>13.02</cell></row><row><cell>LDAM-DRW [7]</cell><cell></cell><cell cols="2">19.06</cell><cell></cell><cell></cell><cell cols="2">14.59</cell><cell></cell></row><row><cell>LDAM-DRW + DU</cell><cell>17.43</cell><cell>16.59</cell><cell>14.93</cell><cell>13.91</cell><cell>13.93</cell><cell>13.07</cell><cell>11.26</cell><cell>11.09</cell></row><row><cell cols="3">E.4 Effect of Labeled Data Amount</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Following [39]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Ablation study of how labeled data amount affects SSL in imbalanced learning. We fix the imbalance ratios as ? = ?U = 50, and fix unlabeled data amount to be 5x of labeled data used. We vary the amount of DL with respect to their original labeled data amount (e.g., 0.5x means only half of the initial labeled data is used).</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>CIFAR-10-LT</cell><cell></cell><cell></cell><cell>SVHN-LT</cell><cell></cell></row><row><cell>DL Size</cell><cell>0.5x</cell><cell>0.75x</cell><cell>1x</cell><cell>0.5x</cell><cell>0.75x</cell><cell>1x</cell></row><row><cell>CE</cell><cell>33.35</cell><cell>28.65</cell><cell>25.19</cell><cell>23.19</cell><cell>19.73</cell><cell>17.50</cell></row><row><cell>CE + DU @5x</cell><cell>20.77</cell><cell>18.67</cell><cell>18.36</cell><cell>14.80</cell><cell>13.51</cell><cell>13.16</cell></row><row><cell cols="7">F Additional Results for Self-Supervised Imbalanced Learning</cell></row><row><cell cols="4">F.1 Different Self-Supervised Pre-Training Methods</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Ablation study of different self-supervised pre-training methods. We set imbalance ratio of ? = 50 for CIFAR-LT. Best results of each column are in bold and the second best are underlined.</figDesc><table><row><cell>Dataset</cell><cell>CIFAR-10-LT</cell><cell>CIFAR-100-LT</cell><cell>ImageNet-LT</cell><cell>iNaturalist 2018</cell></row><row><cell>Vanilla CE</cell><cell>25.19</cell><cell>56.15</cell><cell>61.6</cell><cell>39.3</cell></row><row><cell>+ Jigsaw [37]</cell><cell>24.68</cell><cell>55.89</cell><cell>60.2</cell><cell>38.2</cell></row><row><cell>+ Selfie [49]</cell><cell>22.75</cell><cell>55.31</cell><cell>58.3</cell><cell>36.9</cell></row><row><cell>+ Rotation [16]</cell><cell>21.80</cell><cell>54.96</cell><cell>55.7</cell><cell>36.5</cell></row><row><cell>+ MoCo [19]</cell><cell>24.18</cell><cell>55.83</cell><cell>54.4</cell><cell>35.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 :</head><label>10</label><figDesc>Top-1 test errors (%) of ResNet-32 on CIFAR-10 and CIFAR-100 with step imbalance<ref type="bibr" target="#b4">[5]</ref>. Using SSP, we can consistently and substantially improve different imbalanced learning techniques across various datasets, and achieve the best performance. ? denotes results that reported in<ref type="bibr" target="#b6">[7]</ref>.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Imbalanced CIFAR-10</cell><cell cols="2">Imbalanced CIFAR-100</cell></row><row><cell>Imbalance Ratio (?)</cell><cell>100</cell><cell>10</cell><cell>100</cell><cell>10</cell></row><row><cell>CE</cell><cell>36.70</cell><cell>17.50</cell><cell>61.45</cell><cell>45.37</cell></row><row><cell>CB-CE [11]  ?</cell><cell>38.06</cell><cell>16.20</cell><cell>78.69</cell><cell>47.52</cell></row><row><cell>CE + SSP</cell><cell>27.27</cell><cell>12.04</cell><cell>55.57</cell><cell>42.90</cell></row><row><cell>Focal [32]</cell><cell>36.09</cell><cell>16.36</cell><cell>61.43</cell><cell>46.54</cell></row><row><cell>CB-Focal [11]  ?</cell><cell>39.73</cell><cell>16.54</cell><cell>80.24</cell><cell>49.98</cell></row><row><cell>Focal + SSP</cell><cell>27.00</cell><cell>12.07</cell><cell>55.12</cell><cell>42.93</cell></row><row><cell>LDAM [7]  ?</cell><cell>33.42</cell><cell>15.00</cell><cell>60.42</cell><cell>43.73</cell></row><row><cell>LDAM-DRW [7]  ?</cell><cell>23.08</cell><cell>12.19</cell><cell>54.64</cell><cell>40.54</cell></row><row><cell>LDAM-DRW + SSP</cell><cell>22.95</cell><cell>11.83</cell><cell>54.28</cell><cell>40.33</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Rethinking class-balanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10780</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep over-sampling framework for classifying imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun Yuan</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="770" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning with pseudo-ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ouais</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3365" to="3373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Buchwalter</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A systematic study of the class imbalance problem in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej A</forename><surname>Mazurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="249" to="259" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">What is the effect of importance weighting in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="872" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Learning imbalanced datasets with label-distribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Unlabeled data improves adversarial robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Carmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditi</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy S</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9268" to="9277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Imbalanced deep learning by minority class incremental rectification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1367" to="1381" />
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="766" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishmael</forename><surname>Vincent Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Mastropietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00704</idno>
	</analytic>
	<monogr>
		<title level="j">Adversarially learned inference</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07728</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.05722</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>H?naff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sm Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den Oord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.09272</idno>
		<title level="m">Data-efficient image recognition with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehran</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1163" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Relay backpropagation for effective learning of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="467" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.07379</idno>
		<title level="m">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05849</idno>
		<title level="m">Contrastive multiview coding</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">80 million tiny images: A large data set for nonparametric object and scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1958" to="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Selfie: Self-supervised pretraining for image embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02940</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Interpolation consistency training for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03825</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">High-dimensional statistics: A non-asymptotic viewpoint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wainwright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">48</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7029" to="7039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">ME-Net: Towards effective adversarial robustness with matrix estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dina</forename><surname>Katabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning (ICML)</title>
		<meeting>the 36th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Feature transfer learning for face recognition with under-represented data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of IEEE Computer Vision and Pattern Recognition</title>
		<meeting>eeding of IEEE Computer Vision and Pattern Recognition<address><addrLine>Long Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A scalable exemplar-based subspace clustering algorithm for class-imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren?</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">S4l: Self-supervised semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.03670</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Range loss for deep face recognition with long-tailed training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5409" to="5418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Min</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.02413</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
