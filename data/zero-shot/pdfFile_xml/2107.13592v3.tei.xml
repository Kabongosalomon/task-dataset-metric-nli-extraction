<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Detecting Abusive Albanian</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erida</forename><surname>Nur?e</surname></persName>
							<email>nurce.erida@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorgel</forename><surname>Keci</surname></persName>
							<email>kecijo@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">ITU</orgName>
								<address>
									<settlement>Copenhagen</settlement>
									<country>Microsoft</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">ITU Copenhagen / UN Development Programme</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">ITU</orgName>
								<address>
									<settlement>Copenhagen</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Detecting Abusive Albanian</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The ever growing usage of social media in the recent years has had a direct impact on the increased presence of hate speech and offensive speech in online platforms. Research on effective detection of such content has mainly focused on English and a few other widespread languages, while the leftover majority fail to have the same work put into them and thus cannot benefit from the steady advancements made in the field. In this paper we present Shaj, an annotated Albanian dataset for hate speech and offensive speech that has been constructed from user-generated content on various social media platforms. Its annotation follows the hierarchical schema introduced in Zampieri et al. (2019b). The dataset is tested using three different classification models, the best of which achieves an F1 score of 0.77 for the identification of offensive language, 0.64 F1 score for the automatic categorization of offensive types and lastly, 0.52 F1 score for the offensive language target identification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A large number of people are using social media to spread hate and offensive content while using the freedom of speech as a justification for their actions. Simultaneously, studies have shown that an increase in hate speech on social media leads to more hate crimes against minorities in the physical world <ref type="bibr" target="#b27">(Williams et al., 2019)</ref>. <ref type="bibr">1</ref>  <ref type="bibr" target="#b1">Arcan (2013)</ref> explains how hate crime follows hate speech, and the connection between the two can be drawn using the rhetorical stratagem of hate speech described by <ref type="bibr">Slayden et al. (1995)</ref>.</p><p>The growing presence of hate speech on the internet and its connection to hate crimes has emphasised the need for accurately detecting and censor- * Equal contribution 1 https://phys.org/news/2019-10-online-speech-crimesminorities.html ing this type of content while respecting the freedom of speech <ref type="bibr" target="#b12">(Kemp, 2019)</ref>. A combination of Natural Language Processing (NLP) and Machine Learning techniques have been used for this task. <ref type="bibr" target="#b26">Waseem and Hovy (2016)</ref> state the difficulty of detecting hate speech, often due to the lack of sexist, racial or offensive language used in such content. On the other hand, <ref type="bibr" target="#b6">Davidson et al. (2017)</ref> discusses how some terms generally regarded as offensive lose their negative connotations when used in certain contexts. Examples mentioned in this paper include African Americans using the term n--in everyday language online <ref type="bibr" target="#b24">(Warner and Hirschberg, 2012)</ref>, or people quoting explicit rap songs that often include derogatory terms. Furthermore, offensive words are often purposely misspelled or transformed into social media, making them harder to detect.</p><p>Hate speech and offensive speech have become more eminent and concerning phenomena in the Albanian speaking subset of the internet. Platforms such as Facebook, Instagram and YouTube have been the main communication medium and source of information for the past few years. Due to the loose regulations and lack of offensive speech detection for the language, the amount of homophobic, sexist and racist comments has exhibited a drastic increase.</p><p>Therefore, we aim to contribute to the field by creating the "Spoken Hate in the Albanian Jargon (Shaj)" dataset, a new Albanian dataset annotated using the OffensEval taxonomy <ref type="bibr" target="#b28">(Zampieri et al., 2019a)</ref>. To benchmark this data, we then experiment with the constructed dataset using various models and see their performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background 2.1 Hate Speech Regulations</head><p>Hate speech is regulated by international conventions such as the Universal Declaration of Human Rights (UDHR) <ref type="bibr" target="#b22">UN-UDHR (2017)</ref>, the Convention on Human Rights (ECHR) ECHR (1950) and the International Covenant on Civil and Political Rights (ICCPR) which are mentioned in <ref type="bibr" target="#b4">Chetty and Alathur (2018)</ref>. Countries also have their own legislation regarding this topic (ibid.).</p><p>According to <ref type="bibr">Lani (2014)</ref>, the Constitution of the Republic of Albania does not mention the term 'hate speech'. However, it includes articles regarding the respect towards human rights and freedom, religious co-existence and respect for minorities. Hate speech is regulated in the Criminal Code and it is not only applicable to social media usage. According to (ibid.) the main targets of hate speech in Albania are the LGBT community, minorities eg. Roma, and lastly politicians. Lastly, (ibid.) also states that user-generated comments frequently contain hate speech and not much is being done in terms of regulating or restricting hate speech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Definitions</head><p>Even though the subject of hate speech and offensive language in social media is relatively new, there has been a great number of papers that address the issue all of which have had various definitions of hate speech. As mentioned by <ref type="bibr" target="#b19">Ross et al. (2016)</ref> cited in <ref type="bibr" target="#b15">Macavaney et al. (2019)</ref>, having a concise definition of what hate speech is could positively contribute to the research of hate speech, by making the task of annotation more reliable and easier. This is also reflected in the limitations present in Natural Language Processing (NLP) research <ref type="bibr" target="#b26">Waseem and Hovy (2016)</ref>. Below, we give some of the most commonly occurring definitions of hate speech.</p><p>? <ref type="bibr" target="#b6">Davidson et al. (2017)</ref>: "Language that is used to expresses hatred towards a targeted group or is intended to be derogatory, to humiliate, or to insult the members of the group."</p><p>? <ref type="bibr" target="#b10">Gibert et al. (2018)</ref>: "Hate speech is a deliberate attack directed towards a specific group of people motivated by aspects of the group's identity."</p><p>? Cohen-Almagor (2011) has defined hate speech "as biasmotivated, hostile, malicious speech aimed at a person or a group of people because of some of their actual or perceived innate characteristics"</p><p>Hate speech definitions are not only established by researchers, but also from social media giants. Twitter and Facebook have contributed with definitions of their own, all of which are cited in <ref type="bibr" target="#b15">Macavaney et al. (2019)</ref>.</p><p>In many of the articles published, hate speech is closely related to offensive language and even used interchangeably at times. However, in <ref type="bibr" target="#b6">Davidson et al. (2017)</ref>, a difference is drawn between the terms in hopes of having a more accurate classification. Nonetheless, the work conducted in (ibid.), still lacks a concise distinction between the terms. An example of this misclassification mentioned in (ibid.) deals with song lyrics being mistakenly detected as hate speech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Criteria</head><p>Some of the definitions created throughout the years specify various criteria for classification. <ref type="bibr" target="#b26">Waseem and Hovy (2016)</ref> has based the distinction of offensive and not offensive speech on the following criteria:</p><p>? Racial or sexist slur Other related papers, such as <ref type="bibr" target="#b4">Chetty and Alathur (2018)</ref>, depict a very detailed classification of hate speech detected in social networks. (ibid.) differentiates between two types of hate speech: direct and indirect. When the targeted person or group is immediately impacted by the speech, it is considered to be direct hate speech. Indirect hate speech, on the other hand, indicates that the speech is a starting point of generating more hate. In this paper and also in <ref type="bibr" target="#b11">Gitari et al. (2015)</ref>, the main types of hate speech are: Gendered, Religious, Racist and Disability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Annotation Standards</head><p>Given that hate speech is widespread and among the most studied subjects of NLP research, it is important to follow predefined practices when creating a new dataset. In <ref type="bibr" target="#b23">Vidgen and Derczynski (2020)</ref>, the dataset creators put different level of emphasis to the annotation guidelines which leads to a subjective process of annotation. Ibid. also states that it is difficult for annotators to objectively identify irony and intent expression through written. Considering that various factors influence the creation of an abusive language training data corpus, <ref type="bibr" target="#b23">Vidgen and Derczynski (2020)</ref> summarize the best practices of such task into the following points:</p><p>? Defining the task addressed by the dataset ? Selecting data for abusive language annotation ? Annotating abusive language through clear guidelines ? Documenting methods, data, and annotators</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">OffensEval Schema</head><p>In this work, we follow closely the hierarchy schema developed in the work of <ref type="bibr" target="#b28">Zampieri et al. (2019a)</ref> which frames the schema into three subtasks:</p><p>? Offensive Language Detection</p><p>? Automatic categorization of offensive types</p><p>? Offensive language target identification</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Offensive Language Detection</head><p>The goal of the first subtask is to distinguish between offensive and non-offensive language. Offensive content is characterized by the usage of profanity, insults or threats. Examples of sentences pertaining to these two labels are:</p><p>? Not Offensive (NOT): "edhe 100 klm sot e pergjithmonte puth tezja fort"</p><p>Translation: "100 more! (Albanian way of wishing happy birthday). Have a nice time today and always! Kisses from your aunt"</p><p>? Offensive (OFF): "Shtet pleeeer"</p><p>Translation: "Garbage country/government".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Automatic categorization of offensive types</head><p>The goal of the second subtask is to further categorize the data that was annotated as offensive in the first subtask. The two categories of this task aim to distinguish whether the offense is targeted -if the post directly relates to an individual,group or other entity -or untargeted.</p><p>Examples of sentences pertaining to these two labels are:</p><p>? Targeted insults (TIN): "Po ti ca je spiun pall"</p><p>Translation: "What about you? Are you a spy, you prick?"</p><p>? Untargeted instults (UNT): "Na hnksh riken"</p><p>Translation: "Suck my d*ck"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Offensive language target identification</head><p>The last subtask of the annotation schema aims to distinguish the actual target of the offensive text. <ref type="bibr" target="#b28">Zampieri et al. (2019a)</ref> identifies three main types of targets: individuals, groups and others. Individual targeting includes insults or threats towards a person, famous or not, named or unnamed. The second label deals with groups of people that share a common characteristic such as ethnicity, gender, <ref type="bibr" target="#b30">(Zeinert et al., 2021)</ref> sexual orientation, political affiliation, religious belief, etc. The third label in the subtask corresponds to comments that do not target an individual nor a group, but rather some organization, event, etc. Examples of sentences pertaining to these three labels are:</p><p>? Individual (IND): "Je shume budalla"</p><p>Translation: "You are such an idiot"</p><p>? Group (GRP): "Ne burg pederastat"</p><p>Translation: "Jail for the faggots"</p><p>? Other (OTH): "Pershendetje joq po cfar i keni keto idiotesira qe postoni se lat nam."</p><p>Translation: "Hello JOQ what are these idiotic things that you are posting you are embarrassing yourselves."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Classifiers</head><p>An variety of Machine Learning and Deep Learning models have been used for hate speech classification. <ref type="bibr" target="#b6">Davidson et al. (2017)</ref> start their work by running a logistic regression with L1 regularization to reduce data dimensionality. Later on, they evaluate commonly used models such as Na?ve Bayes, Random Forest, Logistic Regression and Linear Support Vector Machines (SVMs). The data in this paper is classified into 3 categories: hate speech, offensive language and neither. In their tests, they conclude that the Logistic Regression and SVMs perform slightly better than the other models. For their final model, they use Logistic Regression with L2 regularization which achieves a precision of 0.91, recall of 0.90 and F1-Score of 0.90. However, they raise the issue of a large amount of hate speech data being misclassified.</p><p>In <ref type="bibr" target="#b31">Zenuni et al. (2017)</ref> they use Support Vector Machines (SVM) instead of bag-of-words approaches since these produce a high rate of false positives. They try to classify the data as hate speech or not. Their model results in a precision of 0.61, recall of 0.57 and F1-Score of 0.58. Given that the latter model is trained using an Albanian dataset, the results sparked our interest since the work in our paper will try to outscore the aforementioned model.</p><p>In <ref type="bibr" target="#b29">Zampieri et al. (2019b)</ref>, several models were introduced in the competition, all of which were using the Offensive Language Identification Dataset OLID <ref type="bibr" target="#b28">Zampieri et al. (2019a)</ref>. These models ranged from Logistic Regression to advanced and state of the art deep learning models such as <ref type="bibr">BERT Devlin et al. (2019b)</ref> and ELMo <ref type="bibr" target="#b18">Peters et al. (2018)</ref>. Their work was split into three subtasks. For subtask A, BERT was the dominant model with an F1-Score of 82.9%. For subtask B, the best team used a rule-based approach with a keyword filter based on Twitter language behaviour list. This model produced an F1-Score of 75.5%. For subtask C, BERT was once more the dominant model producing an F1-Score of 66.6%. Even though the best results were achieved from deep learning models, <ref type="bibr" target="#b29">Zampieri et al. (2019b)</ref>, concludes that machine learning classifiers were among the most used and achieved good results for the task in hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Purpose</head><p>The main goal behind the creation of our dataset is to improve hate speech and offensive speech detection for less widespread languages. Even though an extensive amount of work and research has been done regarding hate speech, this effort has mainly targeted the English language. This leads to a situation in which the vast majority of the World's languages are still under-resourced in that they have few or no language processing tools and resources <ref type="bibr" target="#b16">(Mossie and Wang, 2018)</ref>. The Shaj dataset provides a foundation for research regarding hate speech detection for the Albanian language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Text selection goals and methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Text selection goals</head><p>In order to construct a platform-independent dataset, we have gathered data from multiple accounts in various social media platforms. Our reasoning behind this approach is that the language used online differs depending on the platform's content and user demographics. This way, as mentioned in Bender and Friedman (2018), the dataset will reflect a wholesome portrait of how Albanian language is used throughout platforms including different dialects, writing styles, content types and tone of language.</p><p>According to <ref type="bibr" target="#b12">Kemp (2019)</ref> the top three social media platforms in Albania are Facebook, Pinterest and Instagram. Due to recent privacy concerns, the bulk extraction of other users' comments on Facebook is no longer possible through their own developer tools (the Graph API 2 ). Further on, after taking into consideration that Pinterest is a platform heavily based on images rather than user interaction through the written language, we proceeded with Instagram and YouTube as our main sources of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Extraction methods</head><p>Comments coming from Instagram were retrieved from two public accounts, namely "@jetaoshqef (JOQ)" 3 and "@lagjia_jone (LJ)" 4 with the help of an open-source tool named Instaloader 5 . JOQ, the most followed Albanian Instagram account not pertaining to an individual, is an informal news portal whose content encompasses versatile topics and constantly generates high user engagement. On the other hand, LJ is an account dedicated to creating memes, funny and controversial content. Its comment section regularly includes examples of offensive speech and hate speech, often expressed in slang that you would not encounter in formal media outlets. Data obtained from each of the sources contains the comments of the 100 most recent posts at the time of retrieval (October 2019).</p><p>Comments coming from Youtube (YT) were retrieved also from two channels with the help of Google's Youtube Data API 6 . According to So-cialbakers 7 , RTV Klan 8 is the second most-viewed Youtube (YT) channel in Albania. We, therefore, extracted comments from some of their most commented videos. Furthermore, comments were also collected from episodes of one of the TV shows with the highest audience numbers of this TV channel, which are posted on another account, namely "Ermal Mamaqi"(the host of the show) 9 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ethics and Privacy</head><p>When handling this kind of data, it is important to ensure the anonymity of the speaker. To conform with the General Data Protection Regulations in Europe (GDPR) 10 , we have taken some precautions when dealing with speaker's identity. Firstly, every username has been replaced with the @USER tag to avoid direct addressing of the speakers. Furthermore, we were cautious to not include sensitive user data, such as addresses, phone numbers, emails, etc. in our data. This approach is also used in other works such as Sigurbergsson and Derczynski (2020), <ref type="bibr" target="#b29">Zampieri et al. (2019b)</ref> and <ref type="bibr" target="#b28">Zampieri et al. (2019a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Annotation Procedure</head><p>During the annotation procedure, 4 different annotators participated in the process including the authors of this paper. In order to mitigate annotator bias <ref type="bibr" target="#b25">(Waseem, 2016)</ref>, the annotators first started a process of annotating a portion of the same comments individually, later comparing the given labels and having discussions about their thought process. The final dataset annotation was again reviewed from the authors of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Annotator demographic</head><p>Annotator demographics is an essential part of the annotated corpus creation, as emphasised in Bender and Friedman (2018). The annotators of Shaj ranged for all the specifications mentioned in (.ibid) except their native language, which was Albanian. Male and female annotators between the ages of 22 and 25 years old participated in the process. They come from different cities of Albania and belong to different religious groups (Muslim, Orthodox, Catholic, Bektashi). Experience wise, all of the annotators were involved in such a process for the first time and based their decisions on the annotation schema provided to them combined with their personal experience with common uses of language in social media.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Examples of data corpus</head><p>During the annotation process, a variety comments were present, with some of them raising a challenge regarding their appropriate labelling. The main issue we encountered relates to the comment's context. It was at times uncertain whether some phrases where being used as insults or simply stating facts relating to the image of the post or a sequence of a video. Such an example can be raised when comments included the word "kungull" which translates to "pumpkin" in English. This term is often used in the Albanian language to describe someone who is stupid (their head is hollow as a pumpkin , thus missing a brain). Without the context of the post, it was difficult to differentiate whether the word was being used literally to describe the vegetable or as a metaphor to offend someone. In this case, the original post was traced and checked in order to provide the most appropriate label.</p><p>Another issue we faced during this process, is the multiple meanings of the words used in the comments. A lot of words in the Albanian language can be translated into insults and profanity given the complete sentence structure. When dealing with these kind of comments, the annotators, who have been used to the social media jargon and phrases, raised discussions and opinions that lead to a label as a final verdict from the authors. Examples for this case can be the usage of "ME PLASI ADMI-RALIIIII" which roughly translates to "My admiral does not care, however the admiral word is also used in social media to refer to a male's genital organ.</p><p>During the annotation process there were also clear cases that helped us give a correct label to the data corpus. The usage of the personal pronouns such as you, him/her, they, them etc., along with the use of profane words/phrase helped us identify the target of the offensive and hate speech. Such an example for targeted insults is "@USER ti je kokrra kurves si se ke iden per ket gje thjesht do si njerzit te ndjekin ty", translated to "@USER you are a slut you have no idea about this thing, you only want people's attention". An example for NOT label is "@USER un them se nuk eshte e vertet", which translates to "@USER I do not think this is true.".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Final dataset</head><p>Table 1 displays information about the final Shaj 11 dataset according to their sources and distributed labels. The final size of the dataset was 11874 comments.</p><p>From table 1 we observe that the dataset is skewed towards not offensive (NOT) content that makes up 87% of the whole corpus. However, as seen in works of Sigurbergsson and Derczynski (2020), <ref type="bibr" target="#b28">Zampieri et al. (2019a)</ref> and ??ltekin (2020), this skew is evident in many datasets that portray real life user-generated content on social media platforms. This argument is also re-enforced when we have tried to cut down some repetitive comments or comments that tag one or multiple people. Such instances have not been removed completely to maintain a true representation of real-life content.</p><p>While gathering the comments from different platforms, we noticed the importance of the emoticons used extensively in the daily online language. These emoticons can express different emotions or opinions ranging from a happy smiley face to an insult. A concrete example from our dataset would be the sentence "ky duhet #EMOJI_FIRE". Without the emoticon the sentence translates to "you need this guy". However with the inclusion of the emoticon the meaning of the sentence changes to "you should burn this guy". We can see that social media text comprehension often relies on emoticon usage and therefore, decided to keep the emoticons as an important part of the dataset. This choice is also seen in the work of <ref type="bibr" target="#b11">Gitari et al. (2015)</ref>, whereas <ref type="bibr" target="#b0">Albadi et al. (2018)</ref>, <ref type="bibr" target="#b31">Zenuni et al. (2017)</ref> choose to remove emoticons as part of their data cleaning process. Orts <ref type="formula">(2019)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Automatically detecting abuse in Albanian 4.1 Model introduction</head><p>We choose BiLSTM as the main model to perform abusive speech detection for Albanian language. The model is firstly comprised of the embedding layer which will use vectors representation of words in our corpus. These vectors come from the Fast-Text library 12 . For words that do not have a vector representation from FastText, but appear in our corpus, we construct the same sized random vector as FastText following a normal distribution. The next layers of the model consist of the bidirectional long short-term memory (BiLSTM) layer, a fully connected hidden layer and an output layer. The bidirectional LSTMs consists of 100 nodes each. The activation function used in our case is RELU, the output activation function used in softmax. The optimizer used is adam Kingma and Ba (2017) and the loss is calculated with sparse_categorical_crossentropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data split, tuning and metrics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Data split</head><p>Having described the corpus size in Section 3.7, we use a 80-20 split ratio between training and testing the model. This 80-20 is kept for each of the labels we have.   <ref type="table" target="#tab_3">Table 3</ref> displays the parameters that were used to conduct the experiments for the BiLSTM model. As less and less data belongs to the more specific subtasks expressed in Section 2.4, we have increased the number of epochs to allow the model to train more. The tuning process was established by conducting many experiments with different parameters and observing when the model performed best. During these experiments, we present the parameters that have not shown model to overfit. <ref type="table" target="#tab_1">A  20  adam 0.001  128  B</ref> 20 adam 0.001 128 C 50 adam 0.001 128 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Model Tuning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subtask Epochs Opt LR Batch</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Metrics</head><p>We choose F1 score as the main metric for our model's performance. F1 score is calculated as F 1 = 2?precision?recall precision+recall and gives a better overall understanding of the model's results since it evaluates the scores of each class independently and calculate an unweighted average of these. Its benefits over metrics such as accuracy would be that when having the model classifying a lot more samples of one class would produce a high accuracy, but a low macro average F1 score. Thus, we use the macro averaged F1 score to see if our models have been over-fitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baseline</head><p>In order to compare our model scores, we introduce Na?ve Bayes as a baseline model. The algorithm used in Na?ve Bayes has its synthesis from the Bayes Theorem. It calculates the probability of a class c given some initial information about a feature vector x. The Na?ve part of the name comes from the assumption that is being made when using the theorem that every pair of features given a value of the class variable are conditional independent. In this paper, we use the Gaussian distribution and algorithm used in sklearn library 13 to implement such baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">BERT</head><p>Deep-learning models are not the only ones used when detecting offensive speech. The transformer approach has proven to have high results with the task in hand and therefore we include <ref type="bibr">BERT Devlin et al. (2019a)</ref> as one of the models that uses this approach. We use BERT base model consisting of 12 layers, 768 hidden size and 12 self attention heads. The Huggingface library 14 includes a variety of BERT models, but we have chosen to work with the base case of bert-base-multilingual-uncased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis and Discussion</head><p>In this section we provide the results obtained from the three different models described in Section 4 according to the subtasks described in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Offensive Language Detection</head><p>In table 4, we share the results achieved for the first subtask, according to the F1 score and observe that BERT achieves the best performance with a 0.77 F1 Score. The results are then followed by the BiLSTM model with a score of 0.70. Comparing our results with similar papers that propose new datasets such as <ref type="bibr" target="#b20">Sigurbergsson and Derczynski (2020)</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Automatic categorization of offensive types</head><p>In <ref type="table" target="#tab_7">Table 5</ref>, we share the results achieved from the second subtask according to the F1 score. The best scoring results are again achieved from BERT with a 0.64 F1 score. In these experiments, we see a drop in performance in BiLSTM and BERT. This is due to the amount of data used for the second subtask.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Offensive language target identification</head><p>In <ref type="table" target="#tab_9">Table 6</ref>, we share the results achieved from the third subtask according to the F1 score. Due to the small amount of data that the models are run on, we see a significant drop from the first two subtasks. In this subtask, we also increase the number of epochs so that the model can train longer, keeping in mind not to overfit it. Again, we observe that BERT is the best scoring model according the F1 score.  During the different experiments performed in this paper, we see a gradual decrease in results as with each subtask. This is because less data that is being fed to each of the models. An additional factor for the third subtask results is the complex concept of the OTH target, which is often assigned when none of the two other targets types are appropriate rather than having a very clear definition of its own.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>A comparison between BERT and BiLSTM results in subtask B and C, suggests that BiLSTM and BERT have little difference when dealing with smaller datasets. However, judging by the results or subtask A, the pre-trained and fine-tuning approach established with BERT, gives insights that the transformer approach is better prepared with the language used. The difference between the approach of the models where BERT does not make use of the word vectors, help its performance when learning the contextual relationship in a text.</p><p>The parameters used when conducting the experiments also play a role in the results of the subtasks. The experiments shown in this paper, followed a fine-tuning process of the parameters, ensuring that the model would not overfit during training, by also constantly validating the training results against a smaller portion of validation data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Discussions</head><p>The experiments performed in this paper helped us identify a few interesting points about our dataset and also brought into light some of the common pitfalls of hate speech detection.</p><p>The models helped us identify mis-annotated data in our corpus. After running the experiments, we observed entries in our corpus that at a second glance were not correctly annotated. A point made in <ref type="bibr" target="#b23">Vidgen and Derczynski (2020)</ref> and also in Section 3.5 has been identified that annotators demographic features and social upbringing have influenced the annotation label. An example of this issue is:</p><p>? ku ka magji qe i mer ato persiper m translated to "not even magic can take care of those" Failures of the model on identifying the intent, irony or even sarcasm by the model were depicted in other results.</p><p>? tamam parkim bjondeje translated to "typical blondie parking"</p><p>? bjonde do kete qene me siguri translated to "she must have been a blonde for sure"</p><p>These problems are known in NLP, as stated in <ref type="bibr" target="#b23">Vidgen and Derczynski (2020)</ref>. The issues discussed in the previous paragraphs, however, are a great example of the diversity of expression that characterises the Albanian language. Sentence structure, words with multiple meanings, context, irony and sarcasm make hate speech detection even more difficult and our contribution with the dataset more valuable towards the improvement of hate speech detection in social media.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Hate speech in social media is a concerning phenomenon that has gained attention in the recent years. Effective detection systems for all languages are required to minimise such content.</p><p>We have presented Shaj, the first publicly available Albanian dataset for hate speech detection. The dataset of ?12000 entries is comprised of Instagram and YouTube comments and annotated using the OffensEval schema.</p><p>We have experimented with various models such as Na?ve Bayes as our baseline, BiLSTM and BERT to see how well hate speech can be detected using Shaj. While our baseline has an F1 score of 0.41 in detecting offensive speech, we achieve an F1 score of 0.77 using BERT.</p><p>The outcomes of our experiments show that while detecting hate speech is difficult, in part due to irony, sarcasm, or lack of context, it is still possible to achieve useful results on new languages with the help of well-constructed and annotated datasets combined with advanced machine learning and deep learning models.</p><p>Shaj is available under CC-BY 4.0 at https://doi.org/10.6084/m9.figshare.19333298.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>describes the details of this split.</figDesc><table><row><cell>Label</cell><cell cols="2">Training Testing</cell></row><row><cell>NOT</cell><cell>8245</cell><cell>2061</cell></row><row><cell>OFF, UNT</cell><cell>358</cell><cell>90</cell></row><row><cell>OFF, TIN, IND</cell><cell>590</cell><cell>148</cell></row><row><cell>OFF, TIN, GRP</cell><cell>186</cell><cell>48</cell></row><row><cell>OFF, TIN, OTH</cell><cell>118</cell><cell>30</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics for each datasource of the Albanian dataset</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: Parameter tuning. Note that LR=Learning</cell></row><row><cell>Rate and Opt=Optimizer. All subtasks train the initial</cell></row><row><cell>weight of the embedding layer</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Results for subtask A using Shaj dataset</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Results for subtask B using Shaj dataset</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Results for subtask C using Shaj dataset</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://developers.facebook.com/docs/graph-api/reference/v5.0/object/comments 3 https://www.instagram.com/joqalbania/ 4 https://www.instagram.com/lagjia_jone/ 5 https://instaloader.github.io/ 6 https://developers.google.com/youtube/v3/getting-started</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">www.socialbakers.com/statistics/youtube/channels/albania 8 https://www.youtube.com/user/televizioniKLAN 9 https://www.youtube.com/user/ErmalMamaqiOfficial 10 https://gdpr-info.eu/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">https://fasttext.cc/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">https://scikit-learn.org/stable/modules/naive_bayes.html 14 https://github.com/huggingface/transformers</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Are they our brothers? analysis and detection of religious hate speech in the arabic twittersphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuha</forename><surname>Albadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maram</forename><surname>Kurdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivakant</forename><surname>Mishra</surname></persName>
		</author>
		<idno type="DOI">10.1109/asonam.2018.8508247</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Interrupted social peace: Hate speech in turkish media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Esra</forename><surname>Arcan</surname></persName>
		</author>
		<idno type="DOI">10.22492/ijmcf.1.1.04</idno>
	</analytic>
	<monogr>
		<title level="j">IAFOR Journal of Media</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="56" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Communication |&amp; Film</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Data statements for natural language processing: Toward mitigating system bias and enabling better science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Batya</forename><surname>Friedman</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00041</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="587" to="604" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A corpus of turkish offensive language on social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>?a?r???ltekin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)</title>
		<meeting>the 12th Conference on Language Resources and Evaluation (LREC 2020)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6174" to="6184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hate speech review in the context of online social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naganna</forename><surname>Chetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sreejith</forename><surname>Alathur</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.avb.2018.05.003</idno>
	</analytic>
	<monogr>
		<title level="j">Aggression and Violent Behavior</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="108" to="118" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fighting hate and bigotry on the internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Cohen-Almagor</surname></persName>
		</author>
		<idno type="DOI">10.2202/1944-2866.1059</idno>
	</analytic>
	<monogr>
		<title level="j">Policy &amp; Internet</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="89" to="114" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automated hate speech detection and the problem of offensive language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dana</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International AAAI Conference on Web and Social Media</title>
		<meeting>the Eleventh International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><forename type="middle">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">La Convention des droits de lhomme: Charte de la liberte: Charter of freedom</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Echr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1950" />
		</imprint>
	</monogr>
	<note>Conseil de lEurope, Dir. de linformation</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hate speech dataset from a white supremacy forum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ona</forename><surname>De Gibert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiara</forename><surname>Perez</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w18-5102</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Aitor Garc?a-Pablos, and Montse Cuadros</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A lexicon-based approach for hate speech detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Njagi</forename><surname>Dennis Gitari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuping</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanyurwimfura</forename><surname>Damien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Long</surname></persName>
		</author>
		<idno type="DOI">10.14257/ijmue.2015.10.4.21</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Multimedia and Ubiquitous Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="215" to="230" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Digital 2019: Essential insights into how people around the world usethe internet, mobile devices, social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kemp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>and ecommercedigital</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Hate Speech in Online media in South East Europe</title>
		<editor>R Lani</editor>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Albanian Media Institute</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hate speech detection: Challenges and solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hao-Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katina</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazli</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ophir</forename><surname>Goharian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frieder</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0221152</idno>
	</analytic>
	<monogr>
		<title level="j">Plos One</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Social network hate speech detection for amharic language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zewdie</forename><surname>Mossie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenq-Haur</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.5121/csit.2018.80604</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multilingual detection of hate speech against immigrants and women in twitter at semeval-2019 task 5: Frequency analysis interpolation for hate in speech detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?scar</forename><surname>Garibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Orts</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/s19-2081</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technology</title>
		<meeting>the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technology</meeting>
		<imprint>
			<publisher>NAACL-HLT</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Measuring the reliability of hate speech annotations: The case of the european refugee crisis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kurowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wojatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 3rd Workshop on Natural Language Processing for Computer-Mediated Com-munication@Conference on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Offensive language and hate speech detection for Danish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Gudbjartur Ingi Sigurbergsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Derczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 12th Language Resources and Evaluation Conference</title>
		<meeting>The 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3498" to="3508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Rita Kirk Whillock, and undefined undefined undefined. 1995. The Use of Hate as Stratagem for Achieving Political and Social Goals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Slayden</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="28" to="54" />
			<pubPlace>Sage</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Universal Declaration of Human Rights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Un-Udhr</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">United Nations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Directions in abusive language training data, a systematic review: Garbage in, garbage out</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertie</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plos one</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">243300</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Detecting hate speech on the world wide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Warner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Language in Social Media</title>
		<meeting>the Second Workshop on Language in Social Media<address><addrLine>Montr?al, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Are you a racist or am i seeing things? annotator influence on hate speech detection on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w16-5618</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on NLP and Computational Social Science</title>
		<meeting>the First Workshop on NLP and Computational Social Science</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hateful symbols or hateful people? predictive features for hate speech detection on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n16-2013</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Student Research Workshop</title>
		<meeting>the NAACL Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Corrigendum to: Hate in the machine: Anti-black and anti-muslim social media posts as predictors of offline racially and religiously aggravated crime</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pete</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Burnap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sefa</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ozalp</surname></persName>
		</author>
		<idno type="DOI">10.1093/bjc/azz064</idno>
	</analytic>
	<monogr>
		<title level="j">The British Journal of Criminology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="242" to="242" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Predicting the type and target of offensive posts in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1144</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North</title>
		<meeting>the 2019 Conference of the North</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semeval -2019 task 6: Identifying and categorizing offensive language in social media (offenseval)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/s19-2010</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Annotating Online Misogyny</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philine</forename><surname>Zeinert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanna</forename><surname>Inie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.247</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic hate speech detection in online contents using latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xhemal</forename><surname>Zenuni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaumin</forename><surname>Ajdari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florije</forename><surname>Ismaili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bujar</forename><surname>Raufi</surname></persName>
		</author>
		<idno type="DOI">10.17261/pressacademia.2017.612</idno>
	</analytic>
	<monogr>
		<title level="j">Pressacademia</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="368" to="371" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
