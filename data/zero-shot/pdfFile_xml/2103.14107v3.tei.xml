<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stepwise Goal-Driven Networks for Trajectory Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022">2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuhua</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingze</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
						</author>
						<title level="a" type="main">Stepwise Goal-Driven Networks for Trajectory Prediction</title>
					</analytic>
					<monogr>
						<title level="m">IEEE ROBOTICS AND AUTOMATION LETTERS. PREPRINT VERSION. ACCEPTED JANUARY</title>
						<imprint>
							<biblScope unit="issue">1</biblScope>
							<date type="published" when="2022">2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Autonomous vehicle navigation</term>
					<term>autonomous agents</term>
					<term>trajectory prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose to predict the future trajectories of observed agents (e.g., pedestrians or vehicles) by estimating and using their goals at multiple time scales. We argue that the goal of a moving agent may change over time, and modeling goals continuously provides more accurate and detailed information for future trajectory estimation. To this end, we present a recurrent network for trajectory prediction, called Stepwise Goal-Driven Network (SGNet). Unlike prior work that models only a single, long-term goal, SGNet estimates and uses goals at multiple temporal scales. In particular, it incorporates an encoder that captures historical information, a stepwise goal estimator that predicts successive goals into the future, and a decoder that predicts future trajectory. We evaluate our model on three first-person traffic datasets (HEV-I, JAAD, and PIE) as well as on three bird's eye view datasets (NuScenes, ETH, and UCY), and show that our model achieves state-of-theart results on all datasets. Code has been made available at: https://github.com/ChuhuaW/SGNet.pytorch.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>P REDICTING the future behavior of other agents is crucial in the real world <ref type="bibr" target="#b0">[1]</ref>: safe driving requires predicting future movements of other cars and pedestrians, for example, while effective social interactions require anticipating the actions of social partners. However, predicting another agent's future actions is challenging because such actions depend on numerous factors including the environment and the other agent's internal state (e.g., its intentions and goals). Recent work <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b4">[5]</ref> has explored goal-driven methods for trajectory prediction, which explicitly try to estimate the other agent's long-term goal to help predict its future behavior. While these models make a significant step forward, they adopt the simplistic assumption that an agent's intentions are exclusively represented by a single long-term goal.</p><p>However, work in psychology and cognitive science suggests that people base their actions not on a single long-term Manuscript received September 9, 2021; revised November 23, 2021; accepted December 30, 2021. This paper was recommended for publication by Editor Cesar Cadena Lerma upon evaluation of the Associate Editor and Reviewers' comments. This work was supported in part by a grant from the U.S. Navy (N00164-21-1-1002) and the Indiana University Office of the Vice Provost for Research through the Emerging Areas of Research project "Learning: Brains, Machines, and Children." (Chuhua Wang and Yuchen Wang contributed equally to this work.) (Corresponding author: Chuhua Wang.) <ref type="bibr" target="#b0">1</ref> The authors are with the Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408, USA (e-mail: cw234@indiana.edu; wang617@indiana.edu; djcran@indiana.edu). <ref type="bibr" target="#b1">2</ref> The author was with the Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408, USA. He is now with Amazon/AWS AI, Seattle, WA, USA (e-mail: mx6@indiana.edu).</p><p>Digital Object Identifier (DOI): see top of this page.</p><p>T+0 T+1 T+2 T+3 <ref type="figure">Fig. 1</ref>: Illustration of stepwise goals (clockwise from top left). Panes (T+0), (T+1), and (T+2) show the initial, second, and third time step, respectively, where yellow indicates observed trajectory, red indicates ground truth future trajectory, green indicates stepwise goals, and cyan indicates prediction. As the model accumulates historical data, goals build up progressively and become more accurate, creating better representations of intention. The goals help predict future trajectory in Pane (T+3). Goals are represented as feature vectors, but we map them to locations for visualization purposes.</p><p>goal, but instead on a series of goals at different time scales. Some literature <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref> uses the term intention to refer to a representation of planned actions and the term goal to stress the end result of an action. This suggests that a series of goals may better represent an intention than using a single, longterm goal. Besides, people's intentions build up progressively, and each decision made in the past may have an impact on how the future is determined. For example, a pedestrian plans a trajectory before crossing the street; when he or she takes a step forward, the prior planned trajectory and the actual situation are both taken into account to update a new set of stepwise goals. We show that estimating stepwise goals at the initial time step and carrying them over to subsequent time steps results in a more precise model of intention and better guidance for future trajectory.</p><p>We present Stepwise Goal-Driven Network (SGNet) to address the trajectory prediction problem. SGNet consists of three main components: (1) A stepwise goal estimator (SGE) that predicts coarse future goals at multiple temporal scales to encode a comprehensive representation of the intention. To determine the significance of each stepwise goal, a lightweight module with an attention mechanism is used. (2) An encoder that records past data in conjunction with predicted stepwise goals, to incorporate a richer hidden representation that aids in predicting the future and in creating new stepwise goals for the next time step. (3) A decoder that takes advantage of stepwise goals to predict future trajectories. We show how stepwise goals evolve and aid in predicting future trajectory in <ref type="figure">Fig. 1</ref>.</p><p>We evaluate our model on multiple first-and third-person datasets, including both vehicles and pedestrians, and compare to an extensive range of existing work ranging from deterministic to stochastic approaches. We surpass or match the stateof-the-art performance on multiple benchmarks, including different viewpoints (i.e., first-and third-person) and agents (i.e., cars and pedestrians).</p><p>The contributions of this paper are three-fold. First, our work highlights a new direction for goal-driven trajectory prediction by modeling goals at multiple time scales. SGE is a versatile module that may be applied to a wide range of architectures. Second, we show how to effectively incorporate each series of stepwise goals into an encoder and decoder. By integrating stepwise objectives into the decoder, we can direct the trajectory prediction in the current step, and by embedding stepwise goals into encoder, we can generate more accurate future goals for the next time step. Finally, our goal aggregator employs an attention mechanism to adaptively learn the relative relevance of each stepwise goal, thereby improving performance even further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Trajectory prediction from first-person views jointly models the motion of observed objects and the ego-camera. Bhattacharyya et al. <ref type="bibr" target="#b7">[8]</ref> propose the Bayesian LSTMs to model observation uncertainty and predict the distribution of future locations. Yagi et al. <ref type="bibr" target="#b8">[9]</ref> use multi-modal data, such as human pose, scale, and ego-motion, as cues in a convolutiondeconvolution (Conv1D) framework to predict future pedestrian locations. Yao et al. <ref type="bibr" target="#b9">[10]</ref> introduce a multi-stream encoder-decoder that separately captures both object location and appearance. Makansi et al. <ref type="bibr" target="#b10">[11]</ref> estimate a reachability prior for objects from the semantic map and propagate them into the future.</p><p>Trajectory prediction from a bird's eye view simplifies the problem by removing the ego-motion. Alahi et al. <ref type="bibr" target="#b11">[12]</ref> propose Social-LSTM to model pedestrians' trajectories and interactions. Their social pooling module was improved by <ref type="bibr" target="#b12">[13]</ref> to capture global context. SoPhie <ref type="bibr" target="#b13">[14]</ref> applies generative models to model the uncertainty of future paths. Lee et al. <ref type="bibr" target="#b14">[15]</ref> use RNNs with conditional variational autoencoders (CVAEs) to generate multi-modal predictions. Recent work <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b17">[18]</ref> also proposes graph-based recurrent models, simultaneously predicting potential trajectories of multiple objects, while <ref type="bibr" target="#b18">[19]</ref> exploits more dynamic and heterogeneous inputs. PLOP <ref type="bibr" target="#b19">[20]</ref> and Argoverse <ref type="bibr" target="#b20">[21]</ref> use the ego trajectory in a bird's eye view map. Simaug and SMARTS <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref> take advantage of simulation data to train the prediction model. Others <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b28">[29]</ref> have explored multimodal inputs, such as Lidar <ref type="bibr" target="#b29">[30]</ref>- <ref type="bibr" target="#b32">[33]</ref>, to aid in trajectory prediction.</p><p>Goal-driven trajectory prediction incorporates estimated future goals. Rhinehart et al. <ref type="bibr" target="#b1">[2]</ref> anticipate multi-modal semantic actions as the goal and conduct conditional forecasting using imitative models. Deo et al. <ref type="bibr" target="#b33">[34]</ref> estimate goal states and fuse the results with past trajectories using maximum entropy inverse reinforcement learning. PECNet <ref type="bibr" target="#b2">[3]</ref> infers distant destinations to improve long-range trajectory prediction. TNT <ref type="bibr" target="#b3">[4]</ref> decomposes the prediction task into three stages: predicting potential target states, generating trajectory state sequences, and estimating trajectory likelihoods. BiTraP <ref type="bibr" target="#b4">[5]</ref> uses a bidirectional decoder on the predicted goal to improve long-term trajectory prediction.</p><p>In contrast to the above methods that only estimate and use the final goal (i.e., the destination), our model predicts goals at multiple temporal scales and incorporates them into our encoder-decoder framework using attentive mechanisms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. STEPWISE GOAL-DRIVEN NETWORK (SGNET)</head><p>At time step t, given an object's observed trajectory in the last e steps, X t = {x t? e+1 , x t? e +2 , . . . , x t }, where x t includes its bounding box (i.e., centroid position and width and height in pixels) and motion (e.g., optical flow, velocity, and acceleration), our goal is to predict its future positions Y t = {y t+1 , y t+2 , . . . , y t+ d } in the next d frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>Because a person's intentions are a representation of planned actions, employing a single long-term goal to portray it is quite limited. To give a more comprehensive intention representation and improve the quality of trajectory prediction, we propose estimating numerous smaller goals along the way and explicitly including them at each decoder time step. Furthermore, people regularly adjust and optimize their intentions, and previous intentions can impact how they perceive the present, as well as aid in the development of new future plans. Thus historical goals can be treated as additional information in the encoder for embedding the present representation and to forecast future stepwise goals. One simple way to merge the stepwise goals is through average pooling as in <ref type="bibr" target="#b34">[35]</ref>. However, we believe that at each time step, each individual goal has a different impact on the prediction. Average pooling smooths out the goal features and hence the important goal features may not be identified. Therefore, we use an aggregator that adaptively learns the importance of each stepwise goal with an attention mechanism. We propose a new recurrent encoderdecoder architecture, Stepwise Goal-Driven Network (SGNet), which predicts goals step-by-step to provide guidance during trajectory prediction as well as supplementary features to help predict new goals at the next time step. <ref type="figure" target="#fig_2">Fig. 2</ref> presents an overview of SGNet. In particular, the stepwise goal estimator (SGE) predicts an object's future locations from t + 1 to t + d as stepwise goals, and embeds them as input to the decoder in an incremental manner to ensure trajectory prediction is guided without receiving any redundant information. SGE also fuses and feeds all predicted goals into the encoder for the next time step, which, as our experiments will show, helps encode a better representation of the current information, and help predicting new stepwise goals for the next time step. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Goal t+2</head><p>Goal t+1 Stepwise Goal Estimator (SGE) </p><formula xml:id="formula_0"># !#$ # !#% # !#&amp;! Goal t+ ! Goal t+2 Goal t+ ! ! !#$ ? !#$ ' ? !#&amp;!($ ' &amp; ! " &amp; !#$ " ? !($ " &amp; !#$ ' &amp; !#% ' !#$?&amp; !</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target Encoder</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FC</head><formula xml:id="formula_1">!#% ' !#- ' !#$ ' ? !#$: / ? !#%: / ? !#&amp; ! : / &amp; !#&amp; ! ' ? ! " ? ! " ? 0 " ? Goal Aggregator Goal Aggregator Goal Aggregator Goal Aggregator ? ! " ? ! " ? !#$ " ? !#$: / ? !#$: / CVAE Encoder RNN Cell</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Encoder</head><p>The encoder captures an agent's movement behavior as a latent vector by embedding its historical trajectory X t using a single fully-connected layer. If additional motion features (e.g., optical flow) are available, they are also embedded using a separate fully-connected layer and concatenated with the trajectory representations. The input feature x e t is then concatenated with the aggregated goal information x e t from the previous time step t ? 1, and then the new hidden state h e t is updated through a recurrent cell. Hidden state h e t+1 and goals x e t+1 are both set to zero for the first time step. We next discuss how to obtain the aggregated goal input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Stepwise Goal Estimator (SGE)</head><p>The main idea of SGE is to generate coarse stepwise goals to assist trajectory prediction in a coarse-to-fine manner. These goals also help the network to create a new stepwise goal for the next step. Consequently, we design SGE to predict and convey the predicted coarse stepwise goals to both encoder and decoder. For encoder, at each time step t, a set of stepwise goals from t ? 1 is concatenated with the input to serve as supplementary features, helping the encoder learn a more discriminative representation of the sequence. Since inaccurate future goals may mislead the prediction, we use a goal aggregator that adaptively learns the importance of each stepwise goal by using an attention mechanism. Meanwhile, for decoder, at each time step t + i (i ? [1, d ]), a subset of stepwise goals h t+i: serves as coarse guidance to help trajectory prediction, and a goal aggregator again gathers the selected goals.</p><p>We define a generic SGE module f SGE as,</p><formula xml:id="formula_2">h g t+1: = f SGE (ReLU (W T ? h e t + b ? ))<label>(1)</label></formula><p>where h g t+1: is a sequence of stepwise goals, and h g t+1: = {h g t+1 , h g t+2 , . . . , h g t+ d }. h e t is the encoder hidden state at time t. We found that SGE is open to different implementations including recurrent, convolution, and fully-connected layers, as will be described in Sec. IV-D. To regularize SGE to generate goals that contain precise future information, we regress the goal position Y g t using the same regressor defined in Sec. III-E to minimize the distance between goal position and the ground truth.</p><p>Goal Aggregator for Encoder and Decoder. We design goal aggregators for both the encoder and decoder, in order to combine and compress multiple goals into a single representation with attention. We define the goal aggregator,</p><formula xml:id="formula_3">w = Softmax(W T Tanh(h g t+i: ) + b)<label>(2)</label></formula><p>x</p><formula xml:id="formula_4">t+i = f attn (h g t+i: ) = d s=t+i w s h g s ,<label>(3)</label></formula><p>where w is an attention vector corresponding to the probability distribution over a subset of estimated goals, and w s is the weight for each individual goal h g s . The overall structure is shown in <ref type="figure" target="#fig_3">Fig. 3</ref>.</p><p>For the encoder, we hypothesize that the anticipation differs at each time step, and people's anticipation in the past may influence their perception of the present and future. As a result, at time t, the encoder receives stepwise goals h g t+1: = {h g t+1 , h g t+2 , ..., h g t+ d }. For the decoder, at time step t+i, the decoder receives goals h g t+i: = {h g t+i , h g t+i+1 , ..., h g t+ d }, and the goals before t + i are ignored, because these are redundant and have been encoded in the historical information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Conditional Variational Autoencoder (CVAE)</head><p>A Conditional Variational Autoencoder (CVAE) framework is applied to learn the distribution of future trajectory Y t conditioned on the observed trajectory X t by introducing a latent variable z. Following prior work <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, our CVAE consists of three components: recognition network Q ? (z|X t , Y t ), prior network P ? (z|X t ), and generation network P ? (h d t |X t , z), where ?, ?, ? denote the parameters of these three networks, and h d t is the trajectory encoded by the generation network. Recognition, prior, and generation networks are implemented with fully-connected layers.</p><p>During training, the ground truth future trajectory Y t is fed into the target encoder to output the hidden state h Yt . To capture the dependencies between observed and ground truth trajectories, the recognition network takes hidden states h e t and h Yt and predicts the distribution mean ? q z and standard deviation ? q z . The prior network takes h e t only and predicts ? p z and ? p z . We sample z from N (? q z , ? q z ) and concatenate it with h e t to generate h d t with the generation network. During testing, the ground truth future trajectory is not available. The generation network concatenates z, which is sampled from N (? p z , ? p z ) with h e t and produces h d t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Decoder</head><p>Our recurrent decoder outputs the final trajectory Y t = {y t+1 , y t+2 , . . . , y t+ d } with a trajectory regressor. Given h d t and estimated goal input x d t+1 , it produces a new hidden state for the next time step through a recurrent cell. Our trajectory regressor is a single fully-connected layer that takes hidden states h d t+i and computes a trajectory y t+i at each time step,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Loss Functions</head><p>We use the Root Mean Square Error (RMSE) as loss function to supervise trajectory prediction from our decoder. For our stochastic model using CAVE, we follow <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref> and adapt best-of-many (BoM) approach to minimize the distance between our best prediction Y t and target Y t . This approach leads to more accurate and diverse predictions and encourages the model to capture the true variation in data. To ensure SGE to predict accurate goal states, we also optimize the prediction from SGE using RMSE between goal prediction Y g t and ground truth Y t . Finally, we add KL-divergence loss (KLD) to optimize the prior network in the CVAE. Thus, for each training sample, our final loss is summarized as follows,</p><formula xml:id="formula_5">L total = min ?k?K RMSE( Y k t , Y t ) + RMSE( Y g t , Y t ) + KLD(Q ? (z|X t , Y t ), P ? (z|X t )),</formula><p>where Y k t is the k-th trajectory hypothesis from CVAE, Y g t is the predicted stepwise goal location, and Y t is the object's ground truth location at time t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS A. Datasets</head><p>First-person datasets. JAAD <ref type="bibr" target="#b40">[41]</ref> and PIE <ref type="bibr" target="#b36">[37]</ref> have egocentric videos recorded at 30 frames per second (fps), and consist of 2,800 and 1,835 pedestrian trajectories, respectively. Following <ref type="bibr" target="#b36">[37]</ref>, we divided the datasets into train (50%), validation (10%), and test (40%) sets. HEV-I <ref type="bibr" target="#b41">[42]</ref> includes 230 videos that are splitted into 40,000 train and 17,000 test samples. Following <ref type="bibr" target="#b9">[10]</ref>, the annotations are generated by using Mask-RCNN and Sort <ref type="bibr" target="#b42">[43]</ref> with a Kalman filter. We use 1.6 seconds of observations to predict future trajectories of length 0.5, 1.0, and 1.5 seconds.</p><p>Third-person dataset. ETH <ref type="bibr" target="#b43">[44]</ref> and UCY <ref type="bibr" target="#b44">[45]</ref> include 1,536 pedestrians in 5 sets of data with 4 unique scenes. Following prior work <ref type="bibr" target="#b18">[19]</ref>, a leave-one-out strategy is used to split the train and test sets. We use 3.2 seconds of observations to predict 4.8 seconds future trajectories. NuScenes <ref type="bibr" target="#b45">[46]</ref> is a dataset for autonomous driving, and we follow the their prediction challenge splits and settings. We use 2 seconds of observations to predict 6 seconds future trajectories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details</head><p>We use Gated Recurrent Units (GRUs) as the backbone for both encoder and decoder with 512 hidden size. The length of the observation e is determined by the default setting of each benchmark: e is 16 on HEV-I, 15 on JAAD, 15 on PIE, and 8 on ETH-UCY. Object bounding boxes are taken as inputs for JAAD and PIE, and following <ref type="bibr" target="#b9">[10]</ref>, optical flow is also included on HEV-I. We follow <ref type="bibr" target="#b18">[19]</ref> to use object centroids, velocities, and accelerations as inputs for ETH and UCY. We use the Adam <ref type="bibr" target="#b46">[47]</ref> optimizer with initial learning rate 5?10 ?4 , which is dynamically reduced based on the validation loss. Our models are optimized end-to-end with batch size 128 and the training is terminated after 50 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Evaluation Protocols</head><p>Our main evaluation metrics are average displacement error (ADE), which measures accuracy along the whole trajectory, and final displacement error (FDE), which measures accuracy only at the trajectory end point. For first-person datasets, we use upper-left and lower-right coordinates of bounding boxes to calculate ADE and FDE, except for HEV-I where we only use the upper-left coordinate to be consistent with prior work. In the bird's eye view ETH and UCY datasets, we follow prior work to use the coordinates of points. To compare to the state-of-the-art <ref type="bibr" target="#b35">[36]</ref> in HEV-I, we also use final intersection over union (FIOU), the overlap between the predicted bounding box and ground truth at the final step, which measures the model's ability to predict both the scale and location of bounding boxes in the long-term. We use mean squared error (MSE) to evaluate our performance on JAAD and PIE, calculated according to the upper-left and lower-right coordinates of the bounding box. Center mean squared error (C M SE ) and center final mean squared error (CF M SE ) are similar to ADE and FED except they are computed based on the bounding box centroids. All results metrics used for HEV-I, JAAD, and PIE dataset are in pixels, while for ETH and UCY we compute the ADE and FDE in Euclidean space.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SGE Encoder Decoder #Goals Attention</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Exploration Study</head><p>We begin with experiments for design trade-offs and training strategies of our architecture with JAAD and PIE.</p><p>How to implement SGE? We considered three instantiations of f attn in the SGE module. First, we implement SGE with GRUs <ref type="table" target="#tab_1">(Table I, row 9</ref>). The hidden size is set to 128, since we only need a lightweight module to produce a coarse goal prediction. h g t+i is defined to be the hidden state at time t + i, which is initialized by using the encoder hidden state h e t after a linear transformation. The GRU input x g t+1 is initialized with a zero vector and updated using the auto-regressive strategy, and the sequence of the output hidden state at each time step is used as the stepwise goals. Second, we try SGE with a multilayer perceptron (MLP) (Table I, row 10) that takes the encoder hidden states h e t as input, and directly outputs d goals of size 128. We call this SGNet-ED-MLP. Third, we follow <ref type="bibr" target="#b8">[9]</ref> and implement a convolution-deconvolution framework for SGE to predict the stepwise goals <ref type="table" target="#tab_1">(Table I,  row 11</ref>).</p><p>As shown in <ref type="table" target="#tab_1">Table I</ref>, all of the above variants achieve the state-of-the-art results, indicating that the SGE module is not sensitive to the choice of f attn . The results also suggest that using temporal models, such as GRU, as SGE is more effective and robust in future trajectory prediction. Thus, we use this version in the remaining experiments (SGNet-ED). What if the decoder or the encoder does not receive predicted goals? To evaluate the importance of using predicted goals in the decoder and encoder, we implemented two baselines that remove the connection between SGE and the decoder (first row) or the encoder (second row).    to help predicting trajectory, and thus using loss to optimize SGE is important in our model. What if we exclude goal aggregator? For each time step, each individual goal has a different impact on the prediction. Thus we develop goal aggregators that use an attention mechanism to understand the relative importance of different subsets of future goals. The results in <ref type="table" target="#tab_1">Table I</ref> show that excluding this attention mechanism (row 3) reduces significantly reduces results compared to our full model. Are stepwise goals better than fewer goals? To further illustrate that using stepwise goals is superior to fewer or only long-term goals, we replace stepwise goals with different number of goals in the encoder and decoder. We show the results in <ref type="table" target="#tab_1">Table I</ref> (Row 4-9). For each setting, we always include the last goal, and add more goals incrementally. The results indicate that as goals are added, they offer extra information and can significantly enhance trajectory prediction performance. Performance is optimal when goals are predicted at each time step. Our full model (SGNet-ED) thus uses GRU as the backbone for SGE, and the output stepwise goals are fed into both encoder and decoder. Our final loss term includes goal loss, BoM trajectory loss, and KLD loss. How to handle multi-modal data? Handling multi-modal input such as social cues/interactions or ego-motion is a classic problem in trajectory prediction. For demonstration, we conducted an experiment on NuScenes prediction challenge split in the Table VI to show the ability to integrate map and interaction information: we followed CoverNet <ref type="bibr" target="#b49">[50]</ref> to rasterize the location of each agent in the scene and overlay it on the map. We use a four layer CNN to extract features from the overplayed map and combine it with the initial decoder hidden state. We submitted our result to NuScenes and ranked third place in NuScenes prediction challenge at the 6th AI Driving Olympics <ref type="bibr" target="#b50">[51]</ref>. The results suggest that social cues and map information can be implicitly learned and integrated into our model, considerably improving the final results. Note our proposed module is a simple and efficient temporal unit, and we only take historical trajectory as an input in the following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Comparison with the State-of-the-art</head><p>In this section, we compare our best model under two different settings: deterministic, in which the model returns a single trajectory, and stochastic, in which we report the bestperforming sample among K trajectories.</p><p>1) Deterministic Results on First-person Benchmarks: We start by evaluating our model's performance on predicting pedestrian trajectory in two first-person datasets. As shown in <ref type="table" target="#tab_1">Table II</ref>, our model (SGNet-ED) significantly outperforms the state-of-the-art on the first-person pedestrian detection datasets. Compared to <ref type="bibr" target="#b4">[5]</ref> on JAAD, our model reduces the MSE error by 13%, 15%, and 15% for 0.5s, 1.0s, and 1.5s prediction, respectively. On PIE, our model reduces MSE by 3%, 9%, and 11% for 0.5s, 1.0s, and 1.5s prediction. As the prediction time range increases (and thus the problem becomes harder), our model decreases MSE more significantly, suggesting that SGE is especially helpful for long-term prediction. We obtain similar results from other evaluation metrics, as shown in <ref type="table" target="#tab_1">Table II</ref>. In addition, we perform experiments on the HEV-I first-person vehicle dataset. Our SGNet-ED yields 6.28, 11.35 <ref type="figure">Fig. 4</ref>: Qualitative results. The yellow color indicates the observed trajectory, the red color indicates the ground truth future trajectory, and the cyan color indicates the predictions from our SGDNet-ED model (better in color). and 18.27 for 0.5s, 1.0s, and 1.5s ADE, 39.86 for FDE, and 0.63 for FIOU. Our results improve by an average of 10% over <ref type="bibr" target="#b35">[36]</ref>.</p><formula xml:id="formula_6">(a) (b) (c) (d) (e) (f) (g) (h)</formula><p>2) Deterministic Results on Third-person Benchmarks: <ref type="table" target="#tab_1">Table III</ref> shows that our model outperforms the state-of-the-art by more than 10% in terms of ADE and FDE on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Stochastic Results on First-person Benchmarks:</head><p>To fairly compare with <ref type="bibr" target="#b4">[5]</ref>, we generate K = 20 proposals and report the best-performing sample. For the first-person datasets, our method outperforms the state-of-the-art by an average of 14% on JAAD and 25% on PIE <ref type="table" target="#tab_1">(Table IV)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Stochastic Results on Third-person Benchmarks:</head><p>For ETH-UCY, we follow the leave-one-out evaluation protocol with K = 20 by following the prior work in <ref type="table" target="#tab_6">Table V</ref>. SGNet-ED outperforms the current state-of-the-art stochastic model <ref type="bibr" target="#b4">[5]</ref> by 5% on average on ETH, ZARA1 and ZARA2, and achieves comparable results on HOTEL and UNIV.</p><p>As with the first-person datasets, our model leads to a larger improvement as the prediction length increases, implying that estimated stepwise goals provide better temporal information for accurately predicting the location and magnitude of objects. For the third-person dataset, our model does not explicitly model interaction, which may explain why our model is better on less complex scenes (ETH, ZARA1 and ZARA2). Including interaction or scene maps may help our model to improve on crowd scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Qualitative Results</head><p>The first row of <ref type="figure">Fig. 4</ref> shows four examples of our best model's deterministic predictions on JAAD, HEV-I, ETH, and UCY, respectively. In (a), the pedestrian intends to cross the street as the ego-vehicle approaches. The historical trajectory was determined by the pedestrian's movement and the vehicle's ego-motion. The prediction shows the intention of the pedestrian to cross ahead of the ego-vehicle, avoiding a collision. In (b), the target vehicle makes a right turn ahead of the ego-vehicle, and the ego-vehicle waits for it after the turn. In (c), the pedestrian follows a curved route, and (d) demonstrates our ability to notice the pedestrian's immediate change and make an accurate prediction.</p><p>The second row of <ref type="figure">Fig. 4</ref> shows four examples of our best model's stochastic predictions. We show all 20 stochastic trajectories generated by our best model. Images (e) and (f) illustrate the results of JAAD and PIE, respectively, which both anticipate the presence of a pedestrian crossing the street. Images (g) and (h) show the scene in ETH and UCY. Most of the predictions are close to the ground truth trajectory and bounding box, indicating the stability of our stochastic prediction model. <ref type="figure" target="#fig_4">Fig. 5</ref> studies two failure cases of our model. In case (a), the marked person is descending the stairs in the near future, but our model fails to predict the correct trajectory due to the lack of context information and interaction between pedestrians. In case (b), most of the stochastic predictions show the pedestrian walking along the road, but one prediction indicates the possibility that the pedestrian may cross the road along the zebra crossing. However, this error may be a "blessing in disguise", for example helping an autonomous driving system to prepare for a potential future risk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Failure Cases</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We presented SGNet to tackle the trajectory prediction problem. Unlike most existing goal-driven models that only estimates final destination or distant goals, SGNet predicts both long-and short-term goals and explicitly incorporates these estimated future states. We showed that these goals can help to predict the trajectory. We conducted extensive experiments on three first-person and three bird's eye view datasets to evaluate the proposed approach. Experimental results showed the effectiveness and robustness of our models against the state-of-the-art methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Visualization of SGNet. Arrows in red, yellow, and black indicate connections during training, inference, and both training and inference, respectively. Encoder time evolves vertically, from time t to t+1, while decoder time flows horizontally, predicting the trajectory at t + 1 to t + l d . For deterministic results, we replace CVAE with a non-linear embedding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Detailed structure of Goal Aggregator. It receives a set of stepwise goals as inputs and calculates the attention weights adaptively. The re-weighted goal features are fed into encoder or decoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Failure cases of deterministic (a) and stochastic (b) predictions. The yellow color indicates the observed trajectory, the red color indicates the ground truth future trajectory, and cyan color indicates the predictions from our SGNet-ED model (better in color).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Exploration study of our model on JAAD and PIE. ? denotes lower is better. The last row is our best model.</figDesc><table><row><cell></cell><cell></cell><cell>JAAD</cell><cell></cell><cell></cell><cell>PIE</cell><cell></cell></row><row><cell>Method</cell><cell>MSE ?</cell><cell>CMSE ?</cell><cell>CFMSE ?</cell><cell>MSE ?</cell><cell>CMSE ?</cell><cell>CFMSE ?</cell></row><row><cell></cell><cell>(0.5s / 1.0s / 1.5s)</cell><cell>(1.5s)</cell><cell>(1.5s)</cell><cell>(0.5s / 1.0s / 1.5s)</cell><cell>(1.5s)</cell><cell>(1.5s)</cell></row><row><cell>Bayesian-LSTM [8]</cell><cell>159 / 539 / 1535</cell><cell>1447</cell><cell>5615</cell><cell>101 / 296 / 855</cell><cell>811</cell><cell>3259</cell></row><row><cell>FOL-X [36]</cell><cell>147 / 484 / 1374</cell><cell>1290</cell><cell>4924</cell><cell>47 / 183 / 584</cell><cell>546</cell><cell>2303</cell></row><row><cell>PIEtraj [37]</cell><cell>110 / 399 / 1248</cell><cell>1183</cell><cell>4780</cell><cell>58 / 200 / 636</cell><cell>596</cell><cell>2477</cell></row><row><cell>BiTraP-D [5]</cell><cell>93 / 378 / 1206</cell><cell>1105</cell><cell>4565</cell><cell>41 / 161 / 511</cell><cell>481</cell><cell>1949</cell></row><row><cell>SGNet-ED</cell><cell>82 / 328 / 1049</cell><cell>996</cell><cell>4076</cell><cell>34 / 133 / 442</cell><cell>413</cell><cell>1761</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II :</head><label>II</label><figDesc>Deterministic results on JAAD and PIE in terms of MSE/C M SE /CF M SE . ? denotes lower is better.</figDesc><table><row><cell>Method</cell><cell></cell><cell></cell><cell cols="2">ADE (4.8s) ? / FDE (4.8s) ?</cell><cell></cell></row><row><cell></cell><cell>ETH</cell><cell>HOTEL</cell><cell>UNIV</cell><cell>ZARA1</cell><cell>ZARA2</cell><cell>Avg</cell></row><row><cell cols="7">Social-LSTM [12] 1.09 / 2.35 0.79 / 1.76 0.67 / 1.40 0.47 / 1.00 0.56 / 1.17 0.72 / 1.54</cell></row><row><cell>Social-GAN [13]</cell><cell cols="6">1.13 / 2.21 1.01 / 2.18 0.60 / 1.28 0.42 / 0.91 0.52 / 1.11 0.74 / 1.54</cell></row><row><cell>MATF [38]</cell><cell cols="6">1.33 / 2.49 0.51 / 0.95 0.56 / 1.19 0.44 / 0.93 0.34 / 0.73 0.64 / 1.26</cell></row><row><cell>FvTraj [39]</cell><cell cols="6">0.62 / 1.23 0.53 / 1.10 0.57 / 1.19 0.42 / 0.89 0.38 / 0.79 0.50 / 1.04</cell></row><row><cell>STAR-D [40]</cell><cell cols="6">0.56 / 1.11 0.26 / 0.50 0.52 / 1.15 0.41 / 0.90 0.31 / 0.71 0.41 / 0.87</cell></row><row><cell>Trajectron++ [19]</cell><cell cols="6">0.71 / 1.68 0.22 / 0.46 0.41 / 1.07 0.30 / 0.77 0.23 / 0.59 0.37 / 0.91</cell></row><row><cell>SGNet-ED</cell><cell cols="6">0.63 / 1.38 0.27 / 0.63 0.40 / 0.96 0.26 / 0.64 0.21 / 0.53 0.35 / 0.83</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III :</head><label>III</label><figDesc>Deterministic results on ETH and UCY in terms of ADE/FDE. ? denotes the lower the better.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>This change decreases the accuracy of our best model by 13/68/208 and 15/57/181 on JAAD/PIE for 0.5s, 1.0s, and 1.5s MSE, respectively. This suggests supervision on SGE leads to better goal representation</figDesc><table><row><cell></cell><cell></cell><cell>JAAD</cell><cell></cell><cell></cell><cell>PIE</cell><cell></cell></row><row><cell>Method (Best of 20)</cell><cell>MSE ?</cell><cell>CMSE ?</cell><cell>CFMSE ?</cell><cell>MSE ?</cell><cell>CMSE ?</cell><cell>CFMSE ?</cell></row><row><cell></cell><cell>(0.5s / 1.0s / 1.5s)</cell><cell>(1.5s)</cell><cell>(1.5s)</cell><cell>(0.5s / 1.0s / 1.5s)</cell><cell>(1.5s)</cell><cell>(1.5s)</cell></row><row><cell>BiTrap-GMM [5]</cell><cell>153 / 250 / 585</cell><cell>501</cell><cell>998</cell><cell>38 / 90 / 209</cell><cell>171</cell><cell>368</cell></row><row><cell>BiTrap-NP [5]</cell><cell>38 / 94 / 222</cell><cell>177</cell><cell>565</cell><cell>23 / 48 / 102</cell><cell>81</cell><cell>261</cell></row><row><cell>SGNet-ED</cell><cell>37 / 86 / 197</cell><cell>146</cell><cell>443</cell><cell>16 / 39 / 88</cell><cell>66</cell><cell>206</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Table I</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">demonstrates that our best model (last row) outperforms both</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">baselines significantly, highlighting the importance of incor-</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">porating predicted goals in both the decoder and encoder for</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">achieving more accurate results.</cell><cell></cell></row></table><note>Does SGE need supervision? To investigate whether su- pervised stepwise goals offer more accurate information for trajectory prediction, we train our network without the goal module loss, RMSE( Y g t , Y t ).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV :</head><label>IV</label><figDesc>Stochastic results on JAAD and PIE in terms of MSE/C M SE /CF M SE . ? denotes lower is better.</figDesc><table><row><cell>Method (Best of 20)</cell><cell></cell><cell></cell><cell cols="2">ADE (4.8s) ? / FDE (4.8s) ?</cell><cell></cell></row><row><cell></cell><cell>ETH</cell><cell>HOTEL</cell><cell>UNIV</cell><cell>ZARA1</cell><cell>ZARA2</cell><cell>Avg</cell></row><row><cell>Social-GAN [13]</cell><cell cols="6">0.81 / 1.52 0.72 / 1.61 0.60 / 1.26 0.34 / 0.69 0.42 / 0.84 0.58 / 1.18</cell></row><row><cell>Sophie [14]</cell><cell cols="6">0.70 / 1.43 0.76 / 1.67 0.54 / 1.24 0.30 / 0.63 0.38 / 0.78 0.54 / 1.15</cell></row><row><cell>CGNS [48]</cell><cell cols="6">0.62 / 1.40 0.70 / 0.93 0.48 / 1.22 0.32 / 0.59 0.35 / 0.71 0.49 / 0.97</cell></row><row><cell>MATF GAN [38]</cell><cell cols="6">1.01 / 1.75 0.43 / 0.80 0.44 / 0.91 0.26 / 0.45 0.26 / 0.57 0.48 / 0.90</cell></row><row><cell>FvTraj [39]</cell><cell cols="6">0.56 / 1.14 0.28 / 0.55 0.52 / 1.12 0.37 / 0.78 0.32 / 0.68 0.41 / 0.85</cell></row><row><cell>DSCMP [49]</cell><cell cols="6">0.66 / 1.21 0.27 / 0.46 0.50 / 1.07 0.33 / 0.68 0.28 / 0.60 0.41 / 0.80</cell></row><row><cell>PECNet [3]</cell><cell cols="6">0.54 / 0.87 0.18 / 0.24 0.35 / 0.60 0.22 / 0.39 0.17 / 0.30 0.29 / 0.48</cell></row><row><cell>STAR [40]</cell><cell cols="6">0.36 / 0.65 0.17 / 0.36 0.31 / 0.62 0.26 / 0.55 0.22 / 0.46 0.26 / 0.53</cell></row><row><cell>Trajectron++ [19]</cell><cell cols="6">0.43 / 0.86 0.12 / 0.19 0.22 / 0.43 0.17 / 0.32 0.12 / 0.25 0.21 / 0.41</cell></row><row><cell>BiTrap-GMM [5]</cell><cell cols="6">0.40 / 0.74 0.13 / 0.22 0.19 / 0.40 0.14 / 0.28 0.11 / 0.22 0.19 / 0.37</cell></row><row><cell>BiTrap-NP [5]</cell><cell cols="6">0.37 / 0.69 0.12 / 0.21 0.17 / 0.37 0.13 / 0.29 0.10 / 0.21 0.18 / 0.35</cell></row><row><cell>SGNet-ED</cell><cell cols="6">0.35 / 0.65 0.12 / 0.24 0.20 / 0.42 0.12 / 0.24 0.10 / 0.21 0.18 / 0.35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE V :</head><label>V</label><figDesc>Stochastic results on ETH and UCY in terms of ADE/FDE. ? denotes lower is better.</figDesc><table><row><cell>Method</cell><cell>NuScenes (K=5)</cell><cell>NuScenes (K=10)</cell></row><row><cell></cell><cell cols="2">ADE / FDE (6s) ? ADE / FDE (6s) ?</cell></row><row><cell>SGDNet-ED</cell><cell>2.1 / 4.65</cell><cell>1.67 / 3.53</cell></row><row><cell>SGDNet-ED (MI)</cell><cell>1.85 / 3.87</cell><cell>1.32 / 2.50</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI :</head><label>VI</label><figDesc>Results on NuScenes without (first row) and with (second row) map and interaction (MI).</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Human motion trajectory prediction: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rudenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Gavrila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Arras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Precog: Prediction conditioned on goals in visual multi-agent settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>It is not the journey but the destination: Endpoint conditioned trajectory prediction,&quot; ECCV, 2020. 1, 2, 4</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">TNT: Target-driven trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRL</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Bitrap: Bi-directional pedestrian trajectory prediction with multi-modal goal estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson-Roberson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note>RA-L, 2021. 1, 2, 4, 5</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A theory of goal setting &amp; task performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Locke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Latham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Prentice-Hall, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The role of intentions in work motivation: Implications for goal-setting theory and research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Tubbs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Ekeberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Academy of Management Review</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Long-term on-board prediction of people in traffic scenes under uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Future person localization in first-person videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yonetani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Egocentric vision-based future vehicle localization for intelligent driving assistance systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dariush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICRA</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multimodal future localization and emergence prediction for objects in egocentric view with a reachability prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Makansi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Cicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Buchicchio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Social LSTM: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Social GAN: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Multiple futures prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.00997</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mart?n-Mart?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Trajectron++: Multi-agent generative trajectory forecasting with heterogeneous data for control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Buhet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wirbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Perrotton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.08744</idno>
		<title level="m">Plop: Probabilistic polynomial objects trajectory planning for autonomous driving</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Argoverse: 3d tracking and forecasting with rich maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sangkloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hartnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Simaug: Learning robust representations from simulation for trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Smarts: Scalable multiagent reinforcement learning training school for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Villela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fadakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09776</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sr-lstm: State refinement for lstm towards pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-modal trajectory prediction of surrounding vehicles with maneuver based lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Social-vrnn: Oneshot multi-modal trajectory prediction for interacting pedestrians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alonso-Mora</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09056</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Differentiable logic layer for rule guided trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rosman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gilitschenski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Decastro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-I</forename><surname>Vasile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Daniela Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRL</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Peeking into the future: Predicting future person activities and locations in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Shared cross-modal trajectory prediction for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Malla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">R2p2: A reparameterized pushforward policy for diverse, precise generative path forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Drogon: A trajectory prediction model based on intention-conditioned behavior reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Malla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.00024</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Liranet: End-to-end trajectory prediction using spatio-temporal radar fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laddha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vallespi-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.00731</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">End-to-end interpretable neural motion planner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Trajectory forecasts in unknown environments conditioned on grid-based plans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00735</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Temporal recurrent networks for online action detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unsupervised traffic accident detection in first-person videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Atkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">PIE: A large-scale dataset and models for pedestrian intention estimation and trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kotseruba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kunic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multi-agent tensor fusion for contextual trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">How can i see my future? fvtraj: Using first-person view for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph transformer networks for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kotseruba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04741</idno>
		<title level="m">Joint attention in autonomous driving (JAAD)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Egocentric vision-based future vehicle localization for intelligent driving assistance systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dariush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICRA</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Simple online and realtime tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Upcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">You&apos;ll never walk alone: Modeling social behavior for multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Crowds by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chrysanthou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer graphics forum</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">nuscenes: A multimodal dataset for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bankiti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">E</forename><surname>Liong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Baldan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
		<idno>2020. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>2015. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Conditional generative neural system for probabilistic trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tomizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IROS</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Dynamic and static contextaware lstm for multi-agent motion prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Covernet: Multimodal behavior prediction using trajectory sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Phan-Minh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Grigore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Boulton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Nuscenes prediction challenge at the 6th ai driving olympics</title>
		<ptr target="https://www.nuscenes.org/prediction6" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
