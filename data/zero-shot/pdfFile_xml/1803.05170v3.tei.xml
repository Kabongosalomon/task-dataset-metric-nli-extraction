<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">United Kingdom and Guangzhong Sun</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 19-23. 2018. 2018. August 19-23. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
							<email>jianxun.lian@outlook.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohuan</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
							<email>fuzzhang@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongxia</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
							<email>xingx@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangzhong</forename><surname>Sun</surname></persName>
							<email>gzsun@ustc.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohuan</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongxia</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">United Kingdom and Guangzhong Sun</title>
					</analytic>
					<monogr>
						<title level="j" type="main">KDD</title>
						<meeting> <address><addrLine>London; London</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">18</biblScope>
							<date type="published">August 19-23. 2018. 2018. August 19-23. 2018</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3219819.3220023</idno>
					<note>ACM ISBN 978-1-4503-5552-0/18/08. . . $15.00 United Kingdom. ACM, New York, NY, USA, 10 pages. https://</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS ? Information systems ? Personalization</term>
					<term>? Computing method- ologies ? Neural networks</term>
					<term>Factorization methods</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Combinatorial features are essential for the success of many commercial models. Manually crafting these features usually comes with high cost due to the variety, volume and velocity of raw data in web-scale systems. Factorization based models, which measure interactions in terms of vector product, can learn patterns of combinatorial features automatically and generalize to unseen features as well. With the great success of deep neural networks (DNNs) in various fields, recently researchers have proposed several DNNbased factorization model to learn both low-and high-order feature interactions. Despite the powerful ability of learning an arbitrary function from data, plain DNNs generate feature interactions implicitly and at the bit-wise level. In this paper, we propose a novel Compressed Interaction Network (CIN), which aims to generate feature interactions in an explicit fashion and at the vector-wise level. We show that the CIN share some functionalities with convolutional neural networks (CNNs) and recurrent neural networks (RNNs). We further combine a CIN and a classical DNN into one unified model, and named this new model eXtreme Deep Factorization Machine (xDeepFM). On one hand, the xDeepFM is able to learn certain bounded-degree feature interactions explicitly; on the other hand, it can learn arbitrary low-and high-order feature interactions implicitly. We conduct comprehensive experiments on three real-world datasets. Our results demonstrate that xDeepFM outperforms state-of-the-art models. We have released the source code of xDeepFM at https:// github.com/ Leavingseason/ xDeepFM.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Features play a central role in the success of many predictive systems. Because using raw features can rarely lead to optimal results, data scientists usually spend a lot of work on the transformation of raw features in order to generate best predictive systems <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b24">24]</ref> or to win data mining games <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b26">26]</ref>. One major type of feature transformation is the cross-product transformation over categorical features <ref type="bibr" target="#b4">[5]</ref>. These features are called cross features or multi-way features, they measure the interactions of multiple raw features. For instance, a 3-way feature AND(user_organization=msra, item_category=deeplearning, time=monday) has value 1 if the user works at Microsoft Research Asia and is shown a technical article about deep learning on a Monday.</p><p>There are three major downsides for traditional cross feature engineering. First, obtaining high-quality features comes with a high cost. Because right features are usually task-specific, data scientists need spend a lot of time exploring the potential patterns from the product data before they become domain experts and extract meaningful cross features. Second, in large-scale predictive systems such as web-scale recommender systems, the huge number of raw features makes it infeasible to extract all cross features manually. Third, hand-crafted cross features do not generalize to unseen interactions in the training data. Therefore, learning to interact features without manual engineering is a meaningful task.</p><p>Factorization Machines (FM) <ref type="bibr" target="#b32">[32]</ref> embed each feature i to a latent factor vector v i = [v i1 , v i2 , ..., v i D ], and pairwise feature interactions are modeled as the inner product of latent vectors: f <ref type="bibr" target="#b1">(2)</ref> (i, j) = ?v i , v j ?x i x j . In this paper we use the term bit to denote a element (such as v i1 ) in latent vectors. The classical FM can be extended to arbitrary higher-order feature interactions <ref type="bibr" target="#b1">[2]</ref>, but one arXiv:1803.05170v3 <ref type="bibr">[cs.</ref>LG] 30 May 2018 major downside is that, <ref type="bibr" target="#b1">[2]</ref> proposes to model all feature interactions, including both useful and useless combinations. As revealed in <ref type="bibr" target="#b43">[43]</ref>, the interactions with useless features may introduce noises and degrade the performance. In recent years, deep neural networks (DNNs) have become successful in computer vision, speech recognition, and natural language processing with their great power of feature representation learning. It is promising to exploit DNNs to learn sophisticated and selective feature interactions. <ref type="bibr" target="#b46">[46]</ref> proposes a Factorisation-machine supported Neural Network (FNN) to learn high-order feature interactions. It uses the pre-trained factorization machines for field embedding before applying DNN. <ref type="bibr" target="#b31">[31]</ref> further proposes a Product-based Neural Network (PNN), which introduces a product layer between embedding layer and DNN layer, and does not rely on pre-trained FM. The major downside of FNN and PNN is that they focus more on high-order feature interactions while capture little low-order interactions. The Wide&amp;Deep <ref type="bibr" target="#b4">[5]</ref> and DeepFM <ref type="bibr" target="#b9">[9]</ref> models overcome this problem by introducing hybrid architectures, which contain a shallow component and a deep component with the purpose of learning both memorization and generalization. Therefore they can jointly learn low-order and high-order feature interactions.</p><p>All the abovementioned models leverage DNNs for learning high-order feature interactions. However, DNNs model high-order feature interactions in an implicit fashion. The final function learned by DNNs can be arbitrary, and there is no theoretical conclusion on what the maximum degree of feature interactions is. In addition, DNNs model feature interactions at the bit-wise level, which is different from the traditional FM framework which models feature interactions at the vector-wise level. Thus, in the field of recommender systems, whether DNNs are indeed the most effective model in representing high-order feature interactions remains an open question. In this paper, we propose a neural network-based model to learn feature interactions in an explicit, vector-wise fashion. Our approach is based on the Deep &amp; Cross Network (DCN) <ref type="bibr" target="#b40">[40]</ref>, which aims to efficiently capture feature interactions of bounded degrees. However, we will argue in Section 2.3 that DCN will lead to a special format of interactions. We thus design a novel compressed interaction network (CIN) to replace the cross network in the DCN. CIN learns feature interactions explicitly, and the degree of interactions grows with the depth of the network. Following the spirit of the Wide&amp;Deep and DeepFM models, we combine the explicit high-order interaction module with implicit interaction module and traditional FM module, and name the joint model eXtreme Deep Factorization Machine (xDeepFM). The new model requires no manual feature engineering and release data scientists from tedious feature searching work. To summarize, we make the following contributions:</p><p>? We propose a novel model, named eXtreme Deep Factorization Machine (xDeepFM), that jointly learns explicit and implicit high-order feature interactions effectively and requires no manual feature engineering. ? We design a compressed interaction network (CIN) in xDeepFM that learns high-order feature interactions explicitly. We show that the degree of feature interactions increases at each layer, and features interact at the vector-wise level rather than the bit-wise level.</p><p>? We conduct extensive experiments on three real-world dataset, and the results demonstrate that our xDeepFM outperforms several state-of-the-art models significantly.</p><p>The rest of this paper is organized as follows. Section 2 provides some preliminary knowledge which is necessary for understanding deep learning-based recommender systems. Section 3 introduces our proposed CIN and xDeepFM model in detail. We will present experimental explorations on multiple datasets in Section 4. Related works are discussed in Section 5. Section 6 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES 2.1 Embedding Layer</head><p>In computer vision or natural language understanding, the input data are usually images or textual signals, which are known to be spatially and/or temporally correlated, so DNNs can be applied directly on the raw feature with dense structures. However, in web-scale recommender systems, the input features are sparse, of huge dimension, and present no clear spatial or temporal correlation. Therefore, multi-field categorical form is widely used by related works <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b46">46]</ref>. For example, one input instance [user_id=s02,gender=male, organization=msra,interests=comedy&amp;rock] is normally transformed into a high-dimensional sparse features via field-aware one-hot encoding:</p><formula xml:id="formula_0">[0, 1, 0, 0, ..., 0 user id ] [ 1, 0 ?ender ] [0, 1, 0, 0, ..., 0 or ?anizat ion ] [0, 1, 0, 1, ..., 0 int er est s ]</formula><p>An embedding layer is applied upon the raw feature input to compress it to a low dimensional, dense real-value vector. If the field is univalent, the feature embedding is used as the field embedding. Take the above instance as an example, the embedding of feature male is taken as the embedding of field gender. If the field is multivalent, the sum of feature embedding is used as the field embedding. The embedding layer is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. The result of embedding layer is a wide concatenated vector:</p><formula xml:id="formula_1">e = [e 1 , e 2 , ..., e m ]</formula><p>where m denotes the number of fields, and e i ? R D denotes the embedding of one field. Although the feature lengths of instances can be various, their embeddings are of the same length m ? D, where D is the dimension of field embedding. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Implicit High-order Interactions</head><p>FNN <ref type="bibr" target="#b46">[46]</ref>, Deep Crossing <ref type="bibr" target="#b37">[37]</ref>, and the deep part in Wide&amp;Deep <ref type="bibr" target="#b4">[5]</ref> exploit a feed-forward neural network on the field embedding vector e to learn high-order feature interactions. The forward process is :</p><formula xml:id="formula_2">x 1 = ? (W (1) e + b 1 ) (1) x k = ? (W (k) x (k?1) + b k )<label>(2)</label></formula><p>where k is the layer depth, ? is an activation function, and x k is the output of the k-th layer. The visual structure is very similar to what is shown in <ref type="figure">Figure 2</ref>, except that they do not include the FM or Product layer. This architecture models the interaction in a bit-wise fashion. That is to say, even the elements within the same field embedding vector will influence each other. PNN <ref type="bibr" target="#b31">[31]</ref> and DeepFM <ref type="bibr" target="#b9">[9]</ref> modify the above architecture slightly. Besides applying DNNs on the embedding vector e, they add a twoway interaction layer in the architecture. Therefore, both bit-wise and vector-wise interaction is included in their model. The major difference between PNN and DeepFM, is that PNN connects the outputs of product layer to the DNNs, whereas DeepFM connects the FM layer directly to the output unit (refer to <ref type="figure">Figure 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2:</head><p>The architecture of DeepFM (with linear part omitted) and PNN. We re-use the symbols in <ref type="bibr" target="#b9">[9]</ref>, where red edges represent weight-1 connections (no parameters) and gray edges represent normal connections (network parameters). <ref type="bibr" target="#b40">[40]</ref> proposes the Cross Network (CrossNet) whose architecture is shown in <ref type="figure" target="#fig_1">Figure 3</ref>. It aims to explicitly model the high-order feature interactions. Unlike the classical fully-connected feed-forward network, the hidden layers are calculated by the following cross operation:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Explicit High-order Interactions</head><formula xml:id="formula_3">x k = x 0 x T k ?1 w k + b k + x k ?1<label>(3)</label></formula><p>where w k , b k , x k ? R mD are weights, bias and output of the k-th layer, respectively. We argue that the CrossNet learns a special type of high-order feature interactions, where each hidden layer in the CrossNet is a scalar multiple of x 0 .</p><p>Theorem 2.1. Consider a k-layer cross network with the (i+1)-th layer defined as</p><formula xml:id="formula_4">x i+1 = x 0 x T i w i+1 + x i .</formula><p>Then, the output of the cross network x k is a scalar multiple of x 0 . Proof. When k=1, according to the associative law and distributive law for matrix multiplication, we have:</p><formula xml:id="formula_5">x 1 = x 0 (x T 0 w 1 ) + x 0 = x 0 (x T 0 w 1 + 1) = ? 1 x 0 (4)</formula><p>where the scalar ? 1 = x T 0 w 1 + 1 is actually a linear regression of x 0 . Thus, x 1 is a scalar multiple of x 0 . Suppose the scalar multiple statement holds for k=i. For k=i + 1, we have :</p><formula xml:id="formula_6">x i+1 = x 0 x T i w i+1 + x i = x 0 ((? i x 0 ) T w i+1 ) + ? i x 0 = ? i+1 x 0 (5) where, ? i+1 = ? i (x T 0 w i+1 + 1) is a scalar. Thus x i+1</formula><p>is still a scalar multiple of x 0 . By induction hypothesis, the output of cross network x k is a scalar multiple of x 0 . ? Note that the scalar multiple does not mean x k is linear with x 0 . The coefficient ? i+1 is sensitive with x 0 . The CrossNet can learn feature interactions very efficiently (the complexity is negligible compared with a DNN model), however the downsides are: (1) the output of CrossNet is limited in a special form, with each hidden layer is a scalar multiple of x 0 ; (2) interactions come in a bit-wise fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OUR PROPOSED MODEL 3.1 Compressed Interaction Network</head><p>We design a new cross network, named Compressed Interaction Network (CIN), with the following considerations: <ref type="bibr" target="#b0">(1)</ref> interactions are applied at vector-wise level, not at bit-wise level; (2) high-order feature interactions is measured explicitly; (3) the complexity of network will not grow exponentially with the degree of interactions.</p><p>Since an embedding vector is regarded as a unit for vector-wise interactions, hereafter we formulate the output of field embedding as a matrix X 0 ? R m?D , where the i-th row in X 0 is the embedding vector of the i-th field: X 0 i, * = e i , and D is the dimension of the field embedding. The output of the k-th layer in CIN is also a matrix X k ? R H k ?D , where H k denotes the number of (embedding) feature vectors in the k-th layer and we let H 0 = m. For each layer, X k are (a) Outer products along each dimension for feature interactions. The tensor Z k +1 is an intermediate result for further learning.  calculated via:</p><formula xml:id="formula_7">X k h, * = H k ?1 i=1 m j=1 W k,h i j (X k?1 i, * ? X 0 j, * ) (6) where 1 ? h ? H k , W k,h ? R H k ?1 ?m</formula><p>is the parameter matrix for the h-th feature vector, and ? denotes the Hadamard product, for example,</p><formula xml:id="formula_8">?a 1 , a 2 , a 3 ? ? ?b 1 , b 2 , b 3 ? = ?a 1 b 1 , a 2 b 2 , a 3 b 3 ?.</formula><p>Note that X k is derived via the interactions between X k ?1 and X 0 , thus feature interactions are measured explicitly and the degree of interactions increases with the layer depth. The structure of CIN is very similar to the Recurrent Neural Network (RNN), where the outputs of the next hidden layer are dependent on the last hidden layer and an additional input. We hold the structure of embedding vectors at all layers, thus the interactions are applied at the vector-wise level. It is interesting to point out that Equation 6 has strong connections with the well-known Convolutional Neural Networks (CNNs) in computer vision. As shown in <ref type="figure" target="#fig_3">Figure 4a</ref>, we introduce an intermediate tensor Z k +1 , which is the outer products (along each embedding dimension) of hidden layer X k and original feature matrix X 0 . Then Z k +1 can be regarded as a special type of image and W k,h is a filter. We slide the filter across Z k+1 along the embedding dimension (D) as shown in <ref type="figure" target="#fig_3">Figure 4b</ref>, and get an hidden vector X k+1 i, * , which is usually called a feature map in computer vision. Therefore, X k is a collection of H k different feature maps. The term "compressed" in the name of CIN indicates that the k-th hidden layer compress the potential space of H k ?1 ? m vectors down to H k vectors. <ref type="figure" target="#fig_3">Figure 4c</ref> provides an overview of the architecture of CIN. Let T denotes the depth of the network. Every hidden layer X k , k ? [1,T ] has a connection with output units. We first apply sum pooling on each feature map of the hidden layer:</p><formula xml:id="formula_9">p k i = D j=1 X k i, j<label>(7)</label></formula><p>for i ? [1, H k ]. Thus, we have a pooling vector</p><formula xml:id="formula_10">p k = [p k 1 , p k 2 , ..., p k H k ]</formula><p>with length H k for the k-th hidden layer. All pooling vectors from hidden layers are concatenated before connected to output units:</p><formula xml:id="formula_11">p + = [p 1 , p 2 , ..., p T ] ? R T i =1 H i .</formula><p>If we use CIN directly for binary classification, the output unit is a sigmoid node on p + :</p><formula xml:id="formula_12">y = 1 1 + exp(p +T w o )<label>(8)</label></formula><p>where w o are the regression parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CIN Analysis</head><p>We analyze the proposed CIN to study the model complexity and the potential effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Space Complexity.</head><p>The h-th feature map at the k-th layer contains H k ?1 ? m parameters, which is exactly the size of W k,h . Thus, there are H k ? H k ?1 ? m parameters at the k-th layer. Considering the last regression layer for the output unit, which has T k =1 H k parameters, the total number of parameters for CIN is</p><formula xml:id="formula_13">T k =1 H k ? (1 + H k ?1 ? m). Note that CIN is independent of the embedding dimension D. In contrast, a plain T -layers DNN contains m ? D ? H 1 + H T + T k=2 H k ? H k?1 parameters</formula><p>, and the number of parameters will increase with the embedding dimension D.</p><p>Usually m and H k will not be very large, so the scale of W k,h is acceptable. When necessary, we can exploit a L-order decomposition and replace W k,h with two smaller matrices  </p><formula xml:id="formula_14">U k,h ? R H k ?1 ?L and V k,h ? R m?L : W k,h = U k,h (V k,h ) T<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Polynomial Approximation.</head><p>Next we examine the highorder interaction properties of CIN. For simplicity, we assume that numbers of feature maps at hidden layers are all equal to the number of fields m. Let [m] denote the set of positive integers that are less than or equal to m. The h-th feature map at the first layer, denoted as x 1 h ? R D , is calculated via:</p><formula xml:id="formula_15">x 1 h = i ?[m] j ?[m] W 1,h i, j (x 0 i ? x 0 j )<label>(10)</label></formula><p>Therefore, each feature map at the first layer models pair-wise interactions with O(m 2 ) coefficients. Similarly, the h-th feature map at the second layer is:</p><formula xml:id="formula_16">x 2 h = i ?[m] j ?[m] W 2,h i, j (x 1 i ? x 0 j ) = i ?[m] j ?[m] l ?[m] k ?[m] W 2,h i, j W 1,i l,k (x 0 j ? x 0 k ? x 0 l )<label>(11)</label></formula><p>Note that all calculations related to the subscript l and k is already finished at the previous hidden layer. We expand the factors in Equation 11 just for clarity. We can observe that each feature map at the second layer models 3-way interactions with O(m 2 ) new parameters.</p><p>A classical k-order polynomial has O(m k ) coefficients. We show that CIN approximate this class of polynomial with only O(km 3 ) parameters in terms of a chain of feature maps. By induction hypothesis, we can prove that the h-th feature map at the k-th layer is:</p><formula xml:id="formula_17">x k h = i ?[m] j ?[m] W k,h i, j (x k ?1 i ? x 0 j ) = i ?[m] j ?[m]</formula><p>...</p><formula xml:id="formula_18">r ?[m] t ?[m] l ?[m] s ?[m] W k,h i, j ...W 1,r l,s (x 0 j ? ... ? x 0 s ? x 0 l k vect or s )<label>(12)</label></formula><p>For better illustration, here we borrow the notations from <ref type="bibr" target="#b40">[40]</ref>. Let ? = [? 1 , ..., ? m ] ? N d denote a multi-index, and |? | = m i=1 ? i . We omit the original superscript from x 0 i , and use x i to denote it since we only we the feature maps from the 0-th layer (which is exactly the field embeddings) for the final expanded expression (refer to Eq. 12). Now a superscript is used to denote the vector operation, such as</p><formula xml:id="formula_19">x 3 i = x i ? x i ? x i . Let V P k (X) denote a multi-vector polynomial of degree k: V P k (X) = ? w ? x ? 1 1 ? x ? 2 2 ? ... ? x ? m m 2 ? |? | ? k<label>(13)</label></formula><p>Each vector polylnomial in this class has O(m k ) coefficients. Then, our CIN approaches the coefficient w ? with:</p><formula xml:id="formula_20">w ? = m i=1 m j=1 B ?P ? |? | t =2 W t, j i, B t<label>(14)</label></formula><p>where, B = [B 1 , B 2 , ..., B |? | ] is a multi-index, and P ? is the set of all the permutations of the indices ( 1, ...1</p><formula xml:id="formula_21">? 1 t imes , ..., m, ..., m ? m t imes</formula><p>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Combination with Implicit Networks</head><p>As discussed in Section 2.2, plain DNNs learn implicit high-order feature interactions. Since CIN and plain DNNs can complement each other, an intuitive way to make the model stronger is to combine these two structures. The resulting model is very similar to the Wide&amp;Deep or DeepFM model. The architecture is shown in <ref type="figure" target="#fig_5">Figure 5</ref>. We name the new model eXtreme Deep Factorization Machine (xDeepFM), considering that on one hand, it includes both low-order and high-order feature interactions; on the other hand, it includes both implicit feature interactions and explicit feature interactions. Its resulting output unit becomes:</p><formula xml:id="formula_22">y = ? (w T linear a + w T dnn x k dnn + w T cin p + + b)<label>(15)</label></formula><p>where ? is the sigmoid function, a is the raw features. x k dnn , p + are the outputs of the plain DNN and CIN, respectively. w * and b are learnable parameters. For binary classifications, the loss function is the log loss:</p><formula xml:id="formula_23">L = ? 1 N N i=1 y i lo?? i + (1 ? y i )lo?(1 ?? i )<label>(16)</label></formula><p>where N is the total number of training instances. The optimization process is to minimize the following objective function:</p><formula xml:id="formula_24">J = L + ? * ||?||<label>(17)</label></formula><p>where ? * denotes the regularization term and ? denotes the set of parameters, including these in linear part, CIN part, and DNN part.   <ref type="figure" target="#fig_5">Figure 5</ref> that, when the depth and feature maps of the CIN part are both set to 1, xDeepFM is a generalization of DeepFM by learning the linear regression weights for the FM layer (note that in DeepFM, units of FM layer are directly linked to the output unit without any coefficients). When we further remove the DNN part, and at the same time use a constant sum filter (which simply takes the sum of inputs without any parameter learning) for the feature map, then xDeepFM is downgraded to the traditional FM model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we conduct extensive experiments to answer the following questions:</p><p>? (Q1) How does our proposed CIN perform in high-order feature interactions learning? ? (Q2) Is it necessary to combine explicit and implicit highorder feature interactions for recommender systems? ? (Q3) How does the settings of networks influence the performance of xDeepFM? We will answer these questions after presenting some fundamental experimental settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Datasets.</head><p>We evaluate our proposed models on the following three datasets:</p><p>1. Criteo Dataset. It is a famous industry benchmarking dataset for developing models predicting ad click-through rate, and is publicly accessible <ref type="bibr" target="#b0">1</ref> . Given a user and the page he is visiting, the goal is to predict the probability that he will clik on a given ad.</p><p>2. Dianping Dataset. Dianping.com is the largest consumer review site in China. It provides diverse functions such as reviews, check-ins, and shops' meta information (including geographical messages and shop attributes). We collect 6 months' users checkin activities for restaurant recommendation experiments. Given a user's profile, a restaurant's attributes and the user's last three visited POIs (point of interest), we want to predict the probability that he will visit the restaurant. For each restaurant in a user's check-in instance, we sample four restaurants which are within 3 kilometers as negative instances by POI popularity.</p><p>3. Bing News Dataset. Bing News 2 is part of Microsoft's Bing search engine. In order to evaluate the performance of our model in a real commercial dataset, we collect five consecutive days' impression logs on news reading service. We use the first three days' data for training and validation, and the next two days for testing.</p><p>For the Criteo dataset and the Dianping dataset, we randomly split instances by 8:1:1 for training , validation and test. The characteristics of the three datasets are summarized in <ref type="table" target="#tab_1">Table 1</ref>. We use two metrics for model evaluation: AUC (Area Under the ROC curve) and Logloss (cross entropy). These two metrics evaluate the performance from two different angels: AUC measures the probability that a positive instance will be ranked higher than a randomly chosen negative one. It only takes into account the order of predicted instances and is insensitive to class imbalance problem. Logloss, in contrast, measures the distance between the predicted score and the true label for each instance. Sometimes we rely more on Logloss because we need to use the predicted probability to estimate the benefit of a ranking strategy (which is usually adjusted as CTR ? bid).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Baselines.</head><p>We compare our xDeepFM with LR(logistic regression), FM, DNN (plain deep neural network), PNN (choose the better one from iPNN and oPNN) <ref type="bibr" target="#b31">[31]</ref>, Wide &amp; Deep <ref type="bibr" target="#b4">[5]</ref>, DCN (Deep &amp; Cross Network) <ref type="bibr" target="#b40">[40]</ref> and DeepFM <ref type="bibr" target="#b9">[9]</ref>. As introduced and discussed in Section 2, these models are highly related to our xDeepFM and some of them are state-of-the-art models for recommender systems. Note that the focus of this paper is to learn feature interactions automatically, so we do not include any hand-crafted cross features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Reproducibility.</head><p>We implement our method using Tensorflow <ref type="bibr" target="#b2">3</ref> . Hyper-parameters of each model are tuned by grid-searching on the validation set, and the best settings for each model will be shown in corresponding sections. Learning rate is set to 0.001. For optimization method, we use the Adam <ref type="bibr" target="#b16">[16]</ref> with a mini-batch size of 4096. We use a L2 regularization with ? = 0.0001 for DNN, DCN, Wide&amp;Deep, DeepFM and xDeepFM, and use dropout 0.5 for PNN. The default setting for number of neurons per layer is: (1) 400 for DNN layers; (2) 200 for CIN layers on Criteo dataset, and 100 for CIN layers on Dianping and Bing News datasets. Since we focus on neural networks structures in this paper, we make the dimension of field embedding for all models be a fixed value of 10. We conduct experiments of different settings in parallel with 5 Tesla K80 GPUs. The source code is available at https:// github.com/ Leavingseason/ xDeepFM.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Comparison among Individual Neural Components (Q1)</head><p>We want to know how CIN performs individually. Note that FM measures 2-order feature interactions explicitly, DNN model highorder feature interactions implicitly, CrossNet tries to model highorder feature interactions with a small number of parameters (which is proven not effective in Section 2.3), and CIN models high-order feature interactions explicitly. There is no theoretic guarantee of the superiority of one individual model over the others, due to that it really depends on the dataset. For example, if the practical dataset does not require high-order feature interactions, FM may be the best individual model. Thus we do not have any expectation for which model will perform the best in this experiment. <ref type="table" target="#tab_2">Table 2</ref> shows the results of individual models on the three practical datasets. Surprisingly, our CIN outperform the other models consistently. On one hand, the results indicate that for practical datasets, higher-order interactions over sparse features are necessary, and this can be verified through the fact that DNN, CrossNet and CIN outperform FM significantly on all the three datasets. On the other hand, CIN is the best individual model, which demonstrates the effectiveness of CIN on modeling explicit high-order feature interactions. Note that a k-layer CIN can model k-degree feature interactions. It is also interesting to see that it take 5 layers for CIN to yield the best result ON the Bing News dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance of Integrated Models (Q2)</head><p>xDeepFM integrates CIN and DNN into an end-to-end model. While CIN and DNN covers two distinct properties in learning feature interactions, we are interested to know whether it is indeed necessary and effective to combine them together for jointly explicit and implicit learning. Here we compare several strong baselines which are not limited to individual models, and the results are shown in <ref type="table" target="#tab_3">Table 3</ref>. We observe that LR is far worse than all the rest models, which demonstrates that factorization-based models are essential for measuring sparse features. Wide&amp;Deep, DCN, DeepFM and xDeepFM are significantly better than DNN, which directly reflects that, despite their simplicity, incorporating hybrid components are important for boosting the accuracy of predictive systems. Our proposed xDeepFM achieves the best performance on all datasets, which demonstrates that combining explicit and implicit high-order feature interaction is necessary, and xDeepFM is effective in learning this class of combination. Another interesting observation is that, all the neural-based models do not require a very deep network structure for the best performance. Typical settings for the depth hyper-parameter are 2 and 3, and the best depth setting for xDeepFM is 3, which indicates that the interactions we learned are at most 4-order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Hyper-Parameter Study (Q3)</head><p>We study the impact of hyper-parameters on xDeepFM in this section, including (1) the number of hidden layers; (2) the number of neurons per layer; and (3) activation functions. We conduct experiments via holding the best settings for the DNN part while varying the settings for the CIN part.</p><p>Depth of Network. <ref type="figure" target="#fig_8">Figure 6a</ref> and 7a demonstrate the impact of number of hidden layers. We can observe that the performance of xDeepFM increases with the depth of network at the beginning. However, model performance degrades when the depth of network is set greater than 3. It is caused by overfitting evidenced by that we notice that the loss of training data still keeps decreasing when we add more hidden layers.</p><p>Number of Neurons per Layer. Adding the number of neurons per layer indicates increasing the number of feature maps in CIN. As shown in <ref type="figure" target="#fig_8">Figure 6b</ref> and 7b, model performance on Bing News dataset increases steadily when we increase the number of neurons from 20 to 200, while on Dianping dataset, 100 is a more suitable setting for the number of neurons per layer. In this experiment we fix the depth of network at 3.</p><p>Activation Function. Note that we exploit the identity as activation function on neurons of CIN, as shown in Eq. 6. A common practice in deep learning literature is to employ non-linear activation functions on hidden neurons. We thus compare the results of different activation functions on CIN (for neurons in DNN, we keep the activation function with relu). As shown in <ref type="figure" target="#fig_8">Figure 6c</ref> and 7c, identify function is indeed the most suitable one for neurons in CIN.    , are widely adopted as they are easy to manage, maintain, and deploy. Because linear models lack the ability of learning feature interactions, data scientists have to spend a lot of work on engineering cross features in order to achieve better performance <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b35">35]</ref>. Considering that some hidden features are hard to design manually, some researchers exploit boosting decision trees to help build feature transformations <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b25">25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Factorization Models.</head><p>A major downside of the aforementioned models is that they can not generalize to unseen feature interactions in the training set. Factorization Machines <ref type="bibr" target="#b32">[32]</ref> overcome this problem via embedding each feature into a low dimension latent vector. Matrix factorization (MF) <ref type="bibr" target="#b18">[18]</ref>, which only considers IDs as features, can be regarded as a special kind of FM. Recommendations are made via the product of two latent vectors, thus it does not require the co-occurrence of user and item in the training set. MF is the most popular model-based collaborative filtering method in the RS literature <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b38">38]</ref>. <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b28">28]</ref> extend MF to leveraging side information, in which both a linear model and a MF model are included. On the other hand, for many recommender systems, only implicit feedback datasets such as users' watching history and browsing activities are available. Thus researchers extend the factorization models to a Bayesian Personalized Ranking (BPR) framework <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b44">44]</ref> for implicit feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Recommender Systems with Deep Learning</head><p>Deep learning techniques have achieved great success in computer vision <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b19">19]</ref>, speech recognition <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b15">15]</ref> and natural language understanding <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b29">29]</ref>. As a result, an increasing number of researchers are interested in employing DNNs for recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Deep Learning for High-Order Interactions.</head><p>To avoid manually building up high-order cross features, researchers apply DNNs on field embedding, thus patterns from categorical feature interactions can be learned automatically. Representative models include FNN <ref type="bibr" target="#b46">[46]</ref>, PNN <ref type="bibr" target="#b31">[31]</ref>, DeepCross <ref type="bibr" target="#b37">[37]</ref>, NFM <ref type="bibr" target="#b12">[12]</ref>, DCN <ref type="bibr" target="#b40">[40]</ref>, Wide&amp;Deep <ref type="bibr" target="#b4">[5]</ref>, and DeepFM <ref type="bibr" target="#b9">[9]</ref>. These models are highly related to our proposed xDeepFM. Since we have reviewed them in Section 1 and Section 2, we do not further discuss them in detail in this section. We have demonstrated that our proposed xDeepFM has two special properties in comparison with these models: (1) xDeepFM learns high-order feature interactions in both explicit and implicit fashions; (2) xDeepFM learns feature interactions at the vector-wise level rather than at the bit-wise level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Deep</head><p>Learning for Elaborate Representation Learning. We include some other deep learning-based RSs in this section due to that they are less focused on learning feature interactions. Some early work employs deep learning mainly to model auxiliary information, such as visual data <ref type="bibr" target="#b11">[11]</ref> and audio data <ref type="bibr" target="#b41">[41]</ref>. Recently, deep neural networks are used to model the collaborative filtering (CF) in RSs. <ref type="bibr" target="#b13">[13]</ref> proposes a Neural Collaborative Filtering (NCF) so that the inner product in MF can be replaced with an arbitrary function via a neural architecture. <ref type="bibr" target="#b36">[36,</ref><ref type="bibr" target="#b42">42]</ref> model CF base on the autoencoder paradigm, and they have empirically demonstrated that autoencoder-based CF outperforms several classical MF models. Autoencoders can be further employed for jointly modeling CF and side information with the purpose of generating better latent factors <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b45">45]</ref>. <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b23">23]</ref> employ neural networks to jointly train multiple domains' latent factors. <ref type="bibr" target="#b2">[3]</ref> proposes the Attentive Collaborative Filtering (ACF) to learn more elaborate preference at both item-level and component-level. <ref type="bibr" target="#b47">[47]</ref> shows tha traditional RSs can not capture interest diversity and local activation effectively, so they introduce a Deep Interest Network (DIN) to represent users' diverse interests with an attentive activation mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>In this paper, we propose a novel network named Compressed Interaction Network (CIN), which aims to learn high-order feature interactions explicitly. CIN has two special virtues: (1) it can learn certain bounded-degree feature interactions effectively; (2) it learns feature interactions at a vector-wise level. Following the spirit of several popular models, we incorporate a CIN and a DNN in an end-to-end framework, and named the resulting model eXtreme Deep Factorization Machine (xDeepFM). Thus xDeepFM can automatically learn high-order feature interactions in both explicit and implicit fashions, which is of great significance to reducing manual feature engineering work. We conduct comprehensive experiments and the results demonstrate that our xDeepFM outperforms stateof-the-art models consistently on three real-world datasets.</p><p>There are two directions for future work. First, currently we simply employ a sum pooling for embedding multivalent fields. We can explore the usage of the DIN mechanism <ref type="bibr" target="#b47">[47]</ref> to capture the related activation according to the candidate item. Second, as discussed in section 3.2.2, the time complexity of the CIN module is high. We are interested in developing a distributed version of xDeepFM which can be trained efficiently on a GPU cluster.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The field embedding layer. The dimension of embedding in this example is 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>The architecture of the Cross Network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(b) The k-th layer of CIN. It compresses the intermediate tensor Z k +1 to H k +1 embedding vectors (aslo known as feature maps).(c) An overview of the CIN architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Components and architecture of the Compressed Interaction Network (CIN).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>3. 2 . 2</head><label>22</label><figDesc>Time Complexity. The cost of computing tensor Z k +1 (as shown in Figure 4a) is O(mHD) time. Because we have H feature maps in one hidden layer, computing a T -layers CIN takes O(mH 2 DT ) time. AT -layers plain DNN, by contrast, takes O(mH D+ H 2 T ) time. Therefore, the major downside of CIN lies in the time complexity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>The architecture of xDeepFM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>3. 3 . 1</head><label>31</label><figDesc>Relationship with FM and DeepFM. Suppose all fields are univalent. It's not hard to observe from</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Impact of network hyper-parameters on AUC performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Number of layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Impact of network hyper-parameters on Logloss performance. 5 RELATED WORK 5.1 Classical Recommender Systems 5.1.1 Non-factorization Models. For web-scale recommender systems (RSs), the input features are usually sparse, categoricalcontinuous-mixed, and high-dimensional. Linear models, such as logistic regression with FTRL [27]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>where L ? H and L ? m. Hereafter we assume that each hidden layer has the same number (which is H ) of feature maps for simplicity. Through the L-order decomposition, the space complexity of CIN is reduced from O(mT H 2 ) to O(mT HL + T H 2 L). In contrast, the space complexity of the plain DNN is O(mDH + T H 2 ), which is sensitive to the dimension (D) of field embedding.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the evaluation datasets. M indicates million and K indicates thousand.</figDesc><table><row><cell>Datasest</cell><cell cols="3">#instances #fields #features (sparse)</cell></row><row><cell>Criteo</cell><cell>45M</cell><cell>39</cell><cell>2.3M</cell></row><row><cell>Dianping</cell><cell>1.2M</cell><cell>18</cell><cell>230K</cell></row><row><cell>Bing News</cell><cell>5M</cell><cell>45</cell><cell>17K</cell></row><row><cell cols="2">4.1.2 Evaluation Metrics.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Performance of individual models on the Criteo, Dianping, and Bing News datasets. Column Depth indicates the best network depth for each model.</figDesc><table><row><cell>Model name</cell><cell>AUC</cell><cell cols="2">Logloss Depth</cell></row><row><cell></cell><cell>Criteo</cell><cell></cell><cell></cell></row><row><cell>FM</cell><cell>0.7900</cell><cell>0.4592</cell><cell>-</cell></row><row><cell>DNN</cell><cell>0.7993</cell><cell>0.4491</cell><cell>2</cell></row><row><cell>CrossNet</cell><cell>0.7961</cell><cell>0.4508</cell><cell>3</cell></row><row><cell>CIN</cell><cell cols="2">0.8012 0.4493</cell><cell>3</cell></row><row><cell></cell><cell cols="2">Dianping</cell><cell></cell></row><row><cell>FM</cell><cell>0.8165</cell><cell>0.3558</cell><cell>-</cell></row><row><cell>DNN</cell><cell>0.8318</cell><cell>0.3382</cell><cell>3</cell></row><row><cell>CrossNet</cell><cell>0.8283</cell><cell>0.3404</cell><cell>2</cell></row><row><cell>CIN</cell><cell cols="2">0.8576 0.3225</cell><cell>2</cell></row><row><cell></cell><cell cols="2">Bing News</cell><cell></cell></row><row><cell>FM</cell><cell>0.8223</cell><cell>0.2779</cell><cell>-</cell></row><row><cell>DNN</cell><cell>0.8366</cell><cell>0.273</cell><cell>2</cell></row><row><cell>CrossNet</cell><cell>0.8304</cell><cell>0.2765</cell><cell>6</cell></row><row><cell>CIN</cell><cell cols="2">0.8377 0.2662</cell><cell>5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Overall performance of different models on Criteo, Dianping and Bing News datasets. The column Depth presents the best setting for network depth with a format of (cross layers, DNN layers).</figDesc><table><row><cell></cell><cell></cell><cell>Criteo</cell><cell></cell><cell></cell><cell>Dianping</cell><cell></cell><cell></cell><cell>Bing News</cell><cell></cell></row><row><cell>Model name</cell><cell>AUC</cell><cell>Logloss</cell><cell>Depth</cell><cell>AUC</cell><cell>Logloss</cell><cell>Depth</cell><cell>AUC</cell><cell>Logloss</cell><cell>Depth</cell></row><row><cell>LR</cell><cell>0.7577</cell><cell>0.4854</cell><cell>-,-</cell><cell>0.8018</cell><cell>0.3608</cell><cell>-,-</cell><cell>0.7988</cell><cell>0.2950</cell><cell>-,-</cell></row><row><cell>FM</cell><cell>0.7900</cell><cell>0.4592</cell><cell>-,-</cell><cell>0.8165</cell><cell>0.3558</cell><cell>-,-</cell><cell>0.8223</cell><cell>0.2779</cell><cell>-,-</cell></row><row><cell>DNN</cell><cell>0.7993</cell><cell>0.4491</cell><cell>-,2</cell><cell>0.8318</cell><cell>0.3382</cell><cell>-,3</cell><cell>0.8366</cell><cell>0.2730</cell><cell>-,2</cell></row><row><cell>DCN</cell><cell>0.8026</cell><cell>0.4467</cell><cell>2,2</cell><cell>0.8391</cell><cell>0.3379</cell><cell>4,3</cell><cell>0.8379</cell><cell>0.2677</cell><cell>2,2</cell></row><row><cell>Wide&amp;Deep</cell><cell>0.8000</cell><cell>0.4490</cell><cell>-,3</cell><cell>0.8361</cell><cell>0.3364</cell><cell>-,2</cell><cell>0.8377</cell><cell>0.2668</cell><cell>-,2</cell></row><row><cell>PNN</cell><cell>0.8038</cell><cell>0.4927</cell><cell>-,2</cell><cell>0.8445</cell><cell>0.3424</cell><cell>-,3</cell><cell>0.8321</cell><cell>0.2775</cell><cell>-,3</cell></row><row><cell>DeepFM</cell><cell>0.8025</cell><cell>0.4468</cell><cell>-,2</cell><cell>0.8481</cell><cell>0.3333</cell><cell>-,2</cell><cell>0.8376</cell><cell>0.2671</cell><cell>-,3</cell></row><row><cell>xDeepFM</cell><cell>0.8052</cell><cell>0.4418</cell><cell>3,2</cell><cell>0.8639</cell><cell>0.3156</cell><cell>3,3</cell><cell>0.8400</cell><cell>0.2649</cell><cell>3,2</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset/ 2 https://www.bing.com/news</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://www.tensorflow.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors would like to thank the anonymous reviewers for their insightful reviews, which are very helpful on the revision of this paper. This work is supported in part by Youth Innovation Promotion Association of CAS.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep speech 2: End-to-end speech recognition in english and mandarin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishita</forename><surname>Sundaram Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingliang</forename><surname>Anubhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Battenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Case</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Higher-order factorization machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akinori</forename><surname>Fujino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naonori</forename><surname>Ueda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masakazu</forename><surname>Ishihata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3351" to="3359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Attentive collaborative filtering: Multimedia recommendation with item-and component-level attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="335" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SVDFeature: a toolkit for feature-based collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuxia</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="3619" to="3622" />
			<date type="published" when="2012-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heng-Tze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levent</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremiah</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Harmsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrishi</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ispir</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Wide &amp; deep learning for recommender systems</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</title>
		<meeting>the 1st Workshop on Deep Learning for Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Hybrid Collaborative Filtering Model with Deep Structure for Recommender Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghuo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxia</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangxi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1309" to="1315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A multi-view deep learning approach for cross domain user modeling in recommendation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Mamdouh Elkahky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="278" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deepfm: A factorization-machine based neural network for CTR prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04247</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">VBPR: Visual Bayesian Personalized Ranking from Implicit Feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="144" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural factorization machines for sparse predictive analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Practical lessons from predicting clicks on ads at facebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinran</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junfeng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ou</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Atallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Bowers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Workshop on Data Mining for Online Advertising</title>
		<meeting>the Eighth International Workshop on Data Mining for Online Advertising</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdel-Rahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Local low-rank matrix approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joonseok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Lebanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.03928</idno>
		<title level="m">Cross-Device User Matching Based on Massive Browse Logs: The Runner-Up Solution for the 2016 CIKM Cup</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Practical Lessons for Job Recommendations in the Cold-Start Scenario</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangzhong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1145/3124791.3124794</idno>
		<ptr target="https://doi.org/10.1145/3124791.3124794" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Recommender Systems Challenge 2017 (RecSys Challenge &apos;17)</title>
		<meeting>the Recommender Systems Challenge 2017 (RecSys Challenge &apos;17)<address><addrLine>New York, NY, USA, Article</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">CCCFNet: a content-boosted collaborative filtering neural network for cross domain recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangzhong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="817" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Restaurant Survival Analysis with Heterogeneous Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangzhong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="993" to="1002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Model Ensemble for Click Prediction in Bing Search Ads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hucheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="689" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Repeat buyer prediction for e-commerce</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guimei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianneng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peilin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ad click prediction: a view from the trenches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>H Brendan Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietmar</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Davydov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Golovin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1222" to="1230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A log-linear model with latent features for dyadic prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Elkan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 10th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="364" to="373" />
		</imprint>
	</monogr>
	<note>Data Mining (ICDM)</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom??</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafi?t</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luk??</forename><surname>Burget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eleventh Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2010-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">One-class collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Lukose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining, 2008. ICDM&apos;08</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="502" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Product-based neural networks for user response prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanru</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 16th International Conference on. IEEE</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1149" to="1154" />
		</imprint>
	</monogr>
	<note>Data Mining (ICDM)</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Factorization machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steffen Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 10th International Conference on. IEEE</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="995" to="1000" />
		</imprint>
	</monogr>
	<note>Data Mining (ICDM)</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence</title>
		<meeting>the twenty-fifth conference on uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pairwise interaction tensor factorization for personalized tag recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third ACM international conference on Web search and data mining</title>
		<meeting>the third ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Predicting clicks: estimating the click-through rate for new ads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewa</forename><surname>Dominowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ragno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on World Wide Web</title>
		<meeting>the 16th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="521" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Autorec: Autoencoders meet collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suvash</forename><surname>Sedhain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Sanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lexing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="111" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep crossing: Web-scale modeling without manually crafted combinatorial features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Hoens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Maximum-margin matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Rennie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1329" to="1336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoxi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingliang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.05123</idno>
		<title level="m">Deep &amp; Cross Network for Ad Click Predictions</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Improving content-based and hybrid music recommendation using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Multimedia</title>
		<meeting>the 22nd ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="627" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Collaborative denoising auto-encoders for top-n recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Ninth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>Hao Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chua</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2017/435</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2017/435" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-19" />
			<biblScope unit="page" from="3119" to="3125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Lambdafm: learning optimal ranking with factorization machines using lambda surrogates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guibing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joemon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Collaborative knowledge base embedding for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><forename type="middle">Jing</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep learning over multi-field categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianming</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on information retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="45" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengru</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingya</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.06978</idno>
		<title level="m">Deep interest network for click-through rate prediction</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
