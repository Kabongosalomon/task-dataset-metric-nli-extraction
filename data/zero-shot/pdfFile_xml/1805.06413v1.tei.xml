<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CASCADE: Contextual Sarcasm Detection in Online Discussion Forums</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
							<email>hazarika@comp.nus.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
							<email>sporia@ihpc.a-star.edu.sg</email>
							<affiliation key="aff1">
								<orgName type="department">Artificial Intelligence Initiative</orgName>
								<address>
									<region>A*STAR</region>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sruthi</forename><surname>Gorantla</surname></persName>
							<email>gorantlas@iisc.ac.in</email>
							<affiliation key="aff2">
								<orgName type="department">Computer Science &amp; Automation Indian Institute of Science</orgName>
								<address>
									<settlement>Bangalore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
							<email>cambria@ntu.edu.sg</email>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Zimmermann</surname></persName>
							<email>rogerz@comp.nus.edu.sg</email>
							<affiliation key="aff4">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
							<email>mihalcea@umich.edu</email>
							<affiliation key="aff5">
								<orgName type="department">Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CASCADE: Contextual Sarcasm Detection in Online Discussion Forums</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The literature in automated sarcasm detection has mainly focused on lexical, syntactic and semantic-level analysis of text. However, a sarcastic sentence can be expressed with contextual presumptions, background and commonsense knowledge. In this paper, we propose CASCADE (a ContextuAl SarCasm DEtector) that adopts a hybrid approach of both content and context-driven modeling for sarcasm detection in online social media discussions. For the latter, CASCADE aims at extracting contextual information from the discourse of a discussion thread. Also, since the sarcastic nature and form of expression can vary from person to person, CASCADE utilizes user embeddings that encode stylometric and personality features of the users. When used along with content-based feature extractors such as Convolutional Neural Networks (CNNs), we see a significant boost in the classification performance on a large Reddit corpus.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sarcasm is a linguistic tool that uses irony to express contempt. Its figurative nature poses a great challenge for affective systems performing sentiment analysis. Previous research in automated sarcasm detection has primarily focused on lexical, pragmatic cues found in sentences <ref type="bibr" target="#b17">(Kreuz and Caucci, 2007)</ref>. Interjections, punctuations, sentimental shifts, etc., have been considered as major indicators of sarcasm <ref type="bibr" target="#b12">(Joshi et al., 2017)</ref>. When such lexical cues are present in sentences, sarcasm detection can achieve high accuracy. However, sarcasm is also expressed implicitly, i.e., without the use of any explicit lexical cues. Such use of sarcasm also relies on the context which involves the presumption of commonsense and background knowledge of an event. When it comes to detecting sarcasm in a discussion forum, it may not only require understanding the context of the previous comments but also need necessary external background knowledge about the topic of discussion. The usage of slangs and informal language also diminishes the reliance on lexical cues. This particular type of sarcasm is tough to detect <ref type="bibr" target="#b25">(Poria et al., 2016)</ref>.</p><p>Contextual dependencies for sarcasm can take many forms. As an example, a sarcastic post from Reddit 1 , "I'm sure Hillary would've done that, lmao." requires background knowledge about the event, i.e., Hillary Clinton's action at the time the post was made. Similarly, sarcastic posts like "But atheism, yeah *that's* a religion!" requires the knowledge that topics like atheism often contain argumentative discussions and are more prone towards sarcasm.</p><p>In this work, we attempt the task of sarcasm detection in online discussion forums. Particularly, we propose a hybrid network, named CASCADE, that utilizes both content and contextual-information required for sarcasm detection. It starts by processing contextual information in two ways. First, it performs user profiling to create user embeddings that capture indicative behavioral traits for sarcasm. Recent findings suggest that such modeling of the user and their preferences, is highly effective for the given task <ref type="bibr" target="#b0">(Amir et al., 2016)</ref>. It makes use of users' historical posts to model their writing style (stylometry) and personality indicators, which are then fused into comprehensive user embeddings using a multi-view fusion approach, Canonical Correlation Analysis (CCA). Second, it extracts contextual information from the discourse of comments in the discussion forums. This is done by document modeling of these consolidated comments belonging to the same forum. We hypothesize that these discourse features would give the important contextual information, background cues along with topical information required for detecting sarcasm.</p><p>After the contextual modeling phase, CASCADE is provided with a comment for sarcasm detection. It performs content-modeling using a Convolutional Neural Network (CNN) to extract its syntactic features. This CNN representation is then concatenated with the relevant user embedding and discourse features to get the final representation which is used for classification. The overall contribution of this work can be summarized as:</p><p>? We propose a novel hybrid sarcasm detector, CASCADE that models content and contextual information. ? We model stylometric and personality details of users along with discourse features of discussion forums to learn informative contextual representations. Experiments on a large Reddit corpus, SARC, demonstrate significant performance improvement over state-of-the-art automated sarcasm detectors.</p><p>In the remaining paper, Section 2 compares our model to related works; Section 3 provides the task description and proposed approach; here, Section 3.3 explains the process of learning contextual features comprising user embeddings and discourse features; Section 3.6 presents the hybrid prediction model followed by experimentation details and result analysis in Section 4; finally, Section 5 draws conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Automated sarcasm detection is a relatively recent field of research. The previous works in the literature can be largely classified into two categories, content and context-based sarcasm detection models.</p><p>Content-based: These networks model the problem of sarcasm detection as a standard classification task and try to find lexical and pragmatic indicators to identify sarcasm. Numerous works have taken this path and presented innovative ways to unearth interesting cues for sarcasm. <ref type="bibr" target="#b29">Tepperman et al. (2006)</ref> investigate sarcasm detection in spoken dialogue systems using prosodic and spectral cues. <ref type="bibr" target="#b4">Carvalho et al. (2009)</ref> use linguistic features like positive predicates, interjections and gestural clues such as emoticons, quotation marks, etc. ,  use syntactic patterns to construct classifiers. <ref type="bibr" target="#b8">Gonz?lez-Ib?nez et al. (2011)</ref> also study the use of emoticons, mainly amongst tweets. <ref type="bibr" target="#b27">Riloff et al. (2013)</ref> assert sarcasm to be a contrast to positive sentiment words and negative situations.  use multiple features comprising lexical, pragmatics, implicit and explicit context incongruity. In the explicit case, they include relevant features to detect thwarted sentimental expectations in the sentence. For implicit incongruity, they generalize <ref type="bibr" target="#b27">Riloff et al. (2013)</ref>'s work in identifying verb-noun phrases containing contrast in both polarities.</p><p>Context-based: Usage of contextual sarcasm has increased in the recent past, especially in online platforms. Texts found in microblogs, discussion forums, social media, etc., are plagued by grammatical inaccuracies and contain information which is highly temporal and contextual. In such scenarios, mining linguistic information becomes relatively inefficient and need arises for additional clues <ref type="bibr" target="#b4">(Carvalho et al., 2009)</ref>. <ref type="bibr" target="#b31">Wallace et al. (2014)</ref> demonstrate this need by showing how traditional classifiers fail in instances where humans require additional context. They also indicate the importance of speaker and/or topical information associated to a text to gather such context. <ref type="bibr" target="#b25">Poria et al. (2016)</ref> use additional information by sentiment, emotional and personality representations of the input text. Previous works have mainly used historical posts of users to understand sarcastic tendencies <ref type="bibr" target="#b26">(Rajadesingan et al., 2015;</ref><ref type="bibr" target="#b33">Zhang et al., 2016)</ref>. <ref type="bibr" target="#b13">Khattri et al. (2015)</ref> try to find users' sentiments towards entities in their histories to find contrasting evidence. <ref type="bibr" target="#b32">Wallace et al. (2015)</ref> utilize sentiments and noun phrases used within a forum to gather context typical to that forum. Such forum based modeling simulates user-communities. Our work follows similar motivation where we explore context provided by user profiling and the topical knowledge embedded in the discourse of comments in discussion-forums (subreddits 2 ). <ref type="bibr" target="#b0">Amir et al. (2016)</ref> perform user modeling by learning embeddings that capture homophily. This work is closest to our approach given the fact that we too learn user embeddings to acquire context. However, we take a different approach that involve stylometric and personality description of the users. Empirical evidence shows that these proposed features are better than previous user modeling approaches. Moreover, we learn discourse features which has not been explored before in the context of this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>The task involves detection of sarcasm for comments made in online discussion forums, i.e., Reddit. Let us denote the set U = {u 1 , ..., u Nu } for N u -users, where each user participates across a subset of N t -discussion forums (subreddits). For a comment C ij made by the i th user u i in the j th discussion forum t j , the objective is to predict whether the comment posted is sarcastic or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Summary of the Proposed Approach</head><p>Given the comment C ij to be classified, CASCADE leverages content and context-based information from the comment. For content-based modeling of C ij , a CNN is used to generate the representation vector ? c i,j for a comment. CNNs generate abstract representations of text by extracting location-invariant local patterns. This vector ? c i,j captures both syntactic and semantic information useful for the task at hand. For contextual modeling, CASCADE first learns user embeddings and discourse features of all users and discussion forums, respectively (Section 3.3). Following this phase, CASCADE then retrieves the learnt user embedding ? u i of user u i and discourse feature vector ? t j of forum t j . Finally, all three vectors ? c i,j , ? u i , and ? t j are concatenated and used for the classification (Section 3.6). One might argue that instead of using one CNN, we could use multiple CNN (explained in <ref type="bibr" target="#b20">(Majumder et al., 2017)</ref>) to get better text representations whenever a comment contains multiple sentences. However that is out of the scope of this work. Here, we aim to show the effectiveness of user specific analysis and context-based features extracted from the discourse. Also the use of a single CNN for text representation helps to consistently compare with the state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Learning Contextual Features</head><p>We now detail the procedures to generate the contextual features, i.e., user embeddings and discourse features. The user embeddings try to capture users' traits that correlate to their sarcastic tendencies. These embeddings are created considering the accumulated historical posts of each user (Section 3.4). Contextual information are also extracted from the discourse of comments within each discussion forum. These extracted features are named as discourse features (Section 3.5). The aim of learning these contextual features is to acquire discriminative information crucial for sarcasm detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">User Embeddings</head><p>To generate user embeddings, we model their stylometric and personality features and then fuse them using CCA to create a single representation. Below we explain the generation of user embedding ? u i , for the i th user u i . <ref type="figure" target="#fig_0">Figure 1</ref> also summarizes the overall architecture for this user profiling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Stylometric features</head><p>People possess their own idiolect and authorship styles, which is reflected in their writing. These styles are generally affected by attributes such as gender, diction, syntactic influences, etc. <ref type="bibr" target="#b6">(Cheng et al., 2011;</ref><ref type="bibr" target="#b28">Stamatatos, 2009</ref>) and present behavioral patterns which aid sarcasm detection <ref type="bibr" target="#b26">(Rajadesingan et al., 2015)</ref>.</p><p>We use this motivation to learn stylometric features of the users by consolidating their online comments into documents. We first gather all the comments by a user and create a document by appending them using a special delimiter &lt;END&gt;. An unsupervised representation learning method ParagraphVector <ref type="bibr" target="#b18">(Le and Mikolov, 2014)</ref> is then applied on this document. This method generates a fixed-sized vector for each user by performing the auxiliary task of predicting the words within the documents. The choice of ParagraphVector is governed by multiple reasons. Apart from its ability to effectively encode a user's writing style, it has the advantage of applying to variable lengths of text. ParagraphVector also has been shown to perform well for sentiment classification tasks. The existence of synergy between sentiment and sarcastic orientation of a sentence also promotes the use of this method.</p><p>We now describe the functioning of this method. Every user-document and all words within them are first mapped to unique vectors such that each vector is represented by a column in matrix D ? R ds?Nu and W s ? R ds? V , respectively. Here, d s is the embedding size and V represents the size of the vocabulary. Continuous-bag-of-words approach <ref type="bibr" target="#b23">(Mikolov et al., 2013)</ref> is then performed where a target word is predicted given the word vectors from its context-window. The key idea here is to use the document vector of the associated document as part of the context words. More formally, given a user-document d i for user u i comprising a sequence of n i -words w 1 , w 2 , ..., w n i , we calculate the average log probability of predicting each word within a sliding context window of size k s . This average log probability is:</p><formula xml:id="formula_0">1 n i n i ?ks t=ks log p(w t d i , w t?ks , ..., w t+ks )<label>(1)</label></formula><p>To predict a word within a window, we take the average of all the neighboring context word vectors along with the document vector ? d i and use a neural network with softmax prediction:</p><formula xml:id="formula_1">p(w t d i , w t?ks , ..., w t+ks ) = e ? yw t ? i e ? y i<label>(2)</label></formula><p>Here, ? y = [y 1 , ..., y V ] is the output of the neural network, i.e.,</p><formula xml:id="formula_2">? y = U d h( ? d i , ? w t?ks , ..., ? w t+ks ; D, W s ) + ? b d (3) ? b d ? R V , U d ? R V ?ds are parameters and h(?) represents the average of vectors ? d i , ? w t?ks , .</formula><p>.., ? w t+ks taken from D and W s . Hierarchical softmax is used for faster training <ref type="bibr" target="#b24">(Morin and Bengio, 2005)</ref>. Finally, after training, D learns the users' document vectors which represent their stylometric features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Personality features</head><p>Discovering personality from text has numerous NLP applications such as product recognition, mental health diagnosis, etc. <ref type="bibr" target="#b20">(Majumder et al., 2017)</ref>. Described as a combination of multiple characteristics, personality detection helps in identifying behavior, thought patterns of an individual. To model the dependencies of users' personality with their sarcastic nature, we include personality features in the user embeddings. Previously, <ref type="bibr" target="#b25">Poria et al. (2016)</ref> also utilize personality features in sentences. However, we take a different and more-involved approach of extracting the personality features of a user instead.</p><p>For user u i , we iterate over all the v i -comments {S 1 u i , ..., S v i u i } written by them. For each S j u i , we provide the comment as an input to a pre-trained Convolutional Neural Network (CNN) which has been trained on a multi-label personality detection task. Specifically, the CNN is pre-trained on a benchmark corpus developed by <ref type="bibr" target="#b21">Matthews and Gilliland (1999)</ref> which contains 2, 400 essays and is labeled with the Big-Five personality traits, i.e., Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism (OCEAN). After the training, this CNN model is used to infer the personality traits present in each comment. This is done by extracting the activations of the CNN's last hidden layer vector which we call as the personality vector ? p j u i . The expectation over the personality vectors for all v i -comments made by the user is then defined as the overall personality feature vector ? p i of user u i :</p><formula xml:id="formula_3">? p i = E j?[v i ] [ ? p j u i ] = 1 v i v i j=1 ? p j u i<label>(4)</label></formula><p>CNN: Here, we describe the CNN that generates the personality vectors. Given a user's comment, which is a text S = [w 1 , ..., w n ] composed of n words, each word w i is represented as a word embedding ? w i ? R dem using the pre-trained FastText embeddings <ref type="bibr" target="#b3">(Bojanowski et al., 2016)</ref>. A single-layered CNN is then modeled on this input sequence S <ref type="bibr" target="#b15">(Kim, 2014)</ref>. First, a convolutional layer is applied having three filters F [1,2,3] ? R dem?h <ref type="bibr">[1,</ref><ref type="bibr">2,</ref><ref type="bibr">3]</ref> of heights h <ref type="bibr">[1,</ref><ref type="bibr">2,</ref><ref type="bibr">3]</ref> , respectively. For each k ? {1, 2, 3}, filter F k slides across S and extracts h k -gram features at each instance. This creates a feature map vector ? m k of size R S ?h k +1 , whose each entry m k,j is obtained as:</p><formula xml:id="formula_4">m k,j = ?( F k ? S [j?j+h k ?1] + b k )<label>(5)</label></formula><p>here, b k ? R is the bias and ?(?) is a non-linear activation function. M feature maps are created from each filter F k giving a total of 3M feature maps as output. Following this, a max-pooling operation is performed across the length of each feature map. Thus, for all M feature maps computed from</p><formula xml:id="formula_5">F k , output ? o k is calculated as, ? o k = [ max( ? m 1 1 ), ..., max( ? m M 1 ) ]. Overall the max-pooling output is calculated by concatenation of each ? o k to get ? o = [ ? o 1 ? ? o 2 ? ? o 3 ] ? R 3M , where ? represents concatenation. Finally, ?</formula><p>o is projected onto a dense layer with d p neurons followed by the final sigmoid-prediction layer with 5 classes denoting the five personality traits <ref type="bibr" target="#b22">(Matthews et al., 2003)</ref>. We use sigmoid instead of softmax to facilitate multi-label classification. This is calculated as,</p><formula xml:id="formula_6">y = ?( W 2 ? q + ? b 2 ) , where ? q = ?( W 1 ? o + ? b 1 )<label>(6)</label></formula><p>W 1 ? R dp?3M , W 2 ? R 5?dp , ? b 1 ? R dp and ? b 2 ? R 5 are parameters and ?(.) represents non-linear activation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Fusion</head><p>We take a multi-view learning approach to combine both stylometric and personality features into a comprehensive embedding for each user. We use Canonical Correlation Analysis (CCA) <ref type="bibr" target="#b10">(Hotelling, 1936)</ref> to perform this fusion. CCA captures maximal information between two views and creates a combined representation <ref type="bibr" target="#b9">(Hardoon et al., 2004;</ref><ref type="bibr" target="#b1">Benton et al., 2016)</ref>. In the event of having more than two views, fusion can be performed using an extension of CCA called Generalized CCA (see <ref type="figure">Supplementary)</ref>.</p><p>Canonical Correlation Analysis: Let us consider the learnt stylometric embedding matrix D ? R ds?Nu and personality embedding matrix P ? R dp?Nu containing the respective embedding vectors of user u i in their i th columns. The matrices are then mean-centered and standardized across all user columns. We call these new matrices as X 1 and X 2 , respectively. Let the correlation matrix for X 1 be R 11 = X 1 X 1 T ? R ds?ds , for X 2 be R 22 = X 2 X 2 T ? R dp?dp and the cross-correlation matrix between them be R 12 = X 1 X 2 T ? R ds?dp . For each user u i , the objective of CCA is to find the linear projections of both embedding vectors that have a maximum correlation. We create K such projections, i.e., K-canonical variate pairs such that each pair of projection is orthogonal with respect to the previous pairs. This is done by constructing:</p><formula xml:id="formula_7">W = X T 1 A 1 and Z = X T 2 A 2<label>(7)</label></formula><p>where, A 1 ? R ds?K , A 2 ? R dp?K and W T W = Z T Z = I. To maximize correlation between W and Z, optimal A 1 and A 2 are calculated by performing singular value decomposition as:  It can be seen that,</p><formula xml:id="formula_8">R ? 1 2 11 R 12 R ? 1 2 22 = A?B ? , where A 1 = R ? 1 2 11 A and A 2 = R ? 1 2 22 B<label>(8)</label></formula><formula xml:id="formula_9">W T W = A 1 T R 11 A 1 = A T A = I and Z T Z = A 2 T R 22 A 2 = B T B = I (9) also, W T Z = Z T W = ?<label>(10)</label></formula><p>Once optimal A 1 and A 2 are calculated, overall user embedding ? u i ? R K of user u i is generated by fusion of ? d i and ? p i as:</p><formula xml:id="formula_10">? u i = ( ? d i ) T A 1 + ( ? p i ) T A 2<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Discourse Features</head><p>Similar to how a user influences the degree of sarcasm in a comment, we assume that the discourse of comments belonging to a certain discussion forum contain contextual information relevant to the sarcasm classification. They embed topical information that selectively incur bias towards degree of sarcasm in the comments of a discussion. For example, comments on political leaders or sports matches are generally more susceptible to sarcasm than natural disasters. Contextual information extracted from the discourse of a discussion can also provide background knowledge or cues about the topic of that discussion. To extract the discourse features, we take a similar approach of document modeling performed for stylometric features (Section 3.4.1). For all N t -discussion forums, we compose each forum's document by appending the comments within them. As before, ParagraphVector is employed to generate discourse representations for each document. We denote the learnt feature vector of j th forum t j as ? t j ? R dt .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Final Prediction</head><p>Following the extraction of text representation ? c i,j for comment C i,j and retrieval of user embedding ? u i for author u i and discourse feature vector ? t j for discussion forum t j , we concatenate all three vectors to form the unified text</p><formula xml:id="formula_11">representation? i,j = [? c i,j ? ? u i ? ? t j ].</formula><p>Here, ? refers to concatenation. The CNN used for extraction of ? c i,j has the same design as the CNN we used to extract personality features described in Section 3.4.2. Finally,? i,j is projected to the output layer having two neurons with a softmax activation. This gives a softmax-probability over whether a comment is sarcastic or not. This probability estimate is then used to calculate the categorical cross-entropy which is used as the loss function:</p><formula xml:id="formula_12">Loss = ?1 N N i=1 2 j=1 y i,j log 2 (? i,j ) , where? = sof tmax(W o?i,j + ? b o )<label>(12)</label></formula><p>Here, N is the number of comments in the training set, y i is the one-hot vector ground truth of the i th comment and? i,j is its predicted probability of belonging to class j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We perform our experiments on a large-scale self-annotated corpus for sarcasm, SARC 3 <ref type="bibr" target="#b14">(Khodak et al., 2017)</ref>. This dataset contains more than a million examples of sarcastic/non-sarcastic statements made in the social media site Reddit. Reddit comprises of topic-specific discussion forums, also known as subreddits, each titled by a post. In each forum, users communicate either by commenting to the titled post or other's comments, resulting in a tree-like conversation structure. This structure can be unraveled to a linear format, thus creating a discourse of the comments by keeping the topological constraints intact. Each comment is accompanied with its author details and parent comments (if any) which is subsequently used for our contextual processing. It is important to note that almost all comments in the SARC dataset are composed of a single sentence. We consider three variants of the SARC dataset in our experiments.</p><p>? Main balanced: This is the primary dataset which contains a balanced distribution of both sarcastic and non-sarcastic comments. The dataset contains comments from 1246058 users (118940 in training and 56118 in testing set) distributed across 6534 forums (3868 in training and 2666 in testing set).</p><p>? Main imbalanced: To emulate real-world scenarios where the sarcastic comments are typically lesser than non-sarcastic ones, we use an imbalanced version of the Main dataset. Specifically, we maintain a 20 ? 80 ratio (approx.) between the sarcastic and non-sarcastic comments in both training/testing sets.</p><p>? Pol: To further test the effectiveness of our user embeddings, we perform experiments on a subset of Main, comprising of forums associated with the topic of politics. The choice of using SARC for our experiments comes with multiple reasons. First, this corpus is the first of its kind that was purposely developed to investigate the necessity of contextual information in sarcasm classification. This characteristic aligns well with the main goal of this paper. Second, the large size of the corpus allows for statistically-relevant analyses. Third, the dataset annotations contain a small false-positive rate for sarcastic labels thus providing reliable annotations. Also, its self-annotation scheme rules out the annotation errors induced by third-party annotators. Finally, the corpus structure provides meta-data (e.g., user information) for its comments, which is useful for contextual modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training details</head><p>We hold out 10% of the training data for validation. Hyper-parameter tuning is performed using this validation set through RandomSearch <ref type="bibr" target="#b2">(Bergstra and Bengio, 2012)</ref>. To optimize the parameters, Adam optimizer (Kingma and Ba, 2014) is used, starting with an initial learning rate of 1e ?4 . The learnable parameters in the network consists of ? = {U d , D, W <ref type="bibr">[1,2,o,s]</ref> , F <ref type="bibr">[1,</ref><ref type="bibr">2,</ref><ref type="bibr">3]</ref> , ? b <ref type="bibr">[1,2,o,d]</ref> , b <ref type="bibr">[1,</ref><ref type="bibr">2,</ref><ref type="bibr">3]</ref> }. Training termination is decided using early stopping technique with a patience of 12. For the batched-modeling of comments in CNNs, each comment is either restricted or padded to 100 words for uniformity. The optimal hyper-parameters are found to be {d s , d p , d t , K} = 100, d em = 300, k s = 2, M = 128, and ? = ReLU (Implementation details are provided in the supplementary).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baseline Models</head><p>Here we describe the state-of-the-art methods and baselines that we compare CASCADE with.</p><p>? Bag-of-Words: This model uses a comment's word-counts as features in a vector. The size of the vector is the vocabulary size of the training dataset. ? CNN: We compare our model with this individual CNN version. This CNN is capable of modeling only the content of a comment. The architecture is similar to the CNN used in CASCADE (see Section 3.2). ? CNN-SVM: This model proposed by <ref type="bibr" target="#b25">Poria et al. (2016)</ref> consists of a CNN for content modeling and other pre-trained CNNs for extracting sentiment, emotion and personality features from the given comment. All the features are concatenated and fed into an SVM for classification. ? CUE-CNN: This method proposed by <ref type="bibr" target="#b0">Amir et al. (2016)</ref> also models user embeddings with a method akin to ParagraphVector. Their embeddings are then combined with a CNN thus forming the CUE-CNN model. We compare with this model to analyze the efficiency of our embeddings as opposed to theirs. Released software 4 is used to produce results on the SARC dataset. <ref type="table" target="#tab_3">Table 2</ref> presents the performance results on the SARC datasets. CASCADE manages to achieve major improvement across all datasets with statistical significance. The lowest performance is obtained by the Bag-of-words approach whereas all neural architectures outperform it. Amongst the neural networks, the CNN baseline receives the least performance. CASCADE comfortably beats the state-of-the-art neural models CNN-SVM and CUE-CNN. Its improved performance on the Main imbalanced dataset also reflects its robustness towards class imbalance and establishes it as a real-world deployable network. We further compare our proposed user-profiling method with that of CUE-CNN, with absolute differences shown in the bottom row of <ref type="table" target="#tab_3">Table 2</ref>. Since CUE-CNN generates its user embeddings using a method similar to the ParagraphVector, we test the importance of personality features being included in our user profiling. As seen in the table, CASCADE without personality features drops in performance to a range similar to CUE-CNN. This suggests that the combination of stylometric and personality features are indeed crucial for the improved performance of CASCADE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Study</head><p>We experiment on multiple variants of CASCADE so as to analyze the importance of the various features present in its architecture. <ref type="table" target="#tab_4">Table 3</ref> provides the results of all the combinations. First, we test performance for the content-based CNN only (row 1). This setting provides the worst relative performance with almost 10% lesser accuracy than optimal. Next, we include contextual features to this network. Here, the effect of discourse features is primarily seen in the Pol dataset getting an increase of 3% in F1 (row 2). A major boost in performance is observed (8 ? 12% accuracy and F1) when user embeddings are introduced (row 5). Visualization of the user embedding cluster (Section 4.6) provides insights for this positive trend.</p><p>Overall, CASCADE consisting of CNN with user embeddings and contextual discourse features provide the best performance in all three datasets (row 6).</p><p>We challenge the use of CCA for the generation of user embeddings and thus replace it with simple concatenation. This however causes a significant drop in performance (row 3). Improvement is not observed even when discourse features are used with these concatenated user embeddings (row 4). We assume the increase in parameters caused by concatenation for this performance degradation. CCA on the other hand creates succinct representations with maximal information, giving better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">User Embedding Analysis</head><p>We investigate the learnt user embeddings in more detail. In particular, we plot random samples of users on a 2D-plane using t-SNE <ref type="bibr" target="#b19">(Maaten and Hinton, 2008)</ref>. The users who have greater sarcastic comments (atleast 2 more than the other type) are termed as sarcastic users (colored red). Conversely, the users having lesser sarcastic comments are called non-sarcastic users (colored green). Equal number of users from both the categories are plotted. We aim to analyze the reason behind the performance boost provided by the user embeddings as shown in <ref type="table" target="#tab_4">Table 3</ref>. We see in <ref type="figure" target="#fig_3">Figure 3</ref> that both the user types belong to similar distributions. However, the sarcastic users have a greater spread than the non-sarcastic ones (red belt around the green region). This is also evident from the variances of the distributions where the sarcastic distribution comprises of 10.92 variance as opposed to 5.20 variance of the non-sarcastic distribution. We can infer from this observation that the user embeddings belonging to this non-overlapping red-region provide discriminative information regarding the sarcastic tendencies of their users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Case Studies</head><p>Results demonstrate that discourse features provide an improvement over baselines, especially on the Pol dataset. This signifies the greater role of the contextual cues for classifying comments in this dataset over the other dataset variants used in our experiment. Below, we present a couple of cases from the Pol dataset where our model correctly identifies the sarcasm which is evident only with the neighboring comments. The previous state-of-the-art CUE-CNN, however, misclassifies them.</p><p>? For the comment Whew, I feel much better now!, its sarcasm is evident only when its previous comment is seen So all of the US presidents are terrorists for the last 5 years. ? The comment The part where Obama signed it. doesn't seem to be sarcastic until looked upon as a remark to its previous comment What part of this would be unconstitutional?.</p><p>Such observations indicate the impact of discourse features. However, sometimes contextual cues from the previous comments are not enough and misclassifications are observed due to lack of necessary commonsense and background knowledge about the topic of discussion. There are also other cases where our model fails despite the presence of contextual information from the previous comments. During exploration, this is primarily observed for contextual comments which are very long. Thus, sequential discourse modeling using RNNs may be better suited for such cases. Also, in the case of user embeddings, CASCADE Main Pol user dis-balanced imbalanced cca concat. course Acc. F1 Acc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F1</head><p>Acc.   misclassifications were common for users with lesser historical posts. In such scenarios, potential solutions would be to create user networks and derive information from similar users within the network. These are some of the issues which we plan to address in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we introduce Contextual Sarcasm Detector called as CASCADE which leverages both content and contextual information for the classification. For contextual details, we perform user profiling along with discourse modeling from comments in discussion threads. When this information is used jointly with a CNN-based textual model, we obtain state-of-the-art performance on a large-scale Reddit corpus. Our results show that discourse features along with user embeddings play a crucial role in the performance of sarcasm detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The figure describes the process of user profiling. Stylometric and Personality embeddings are generated and then fused in a multi-view setting using CCA to get the user embeddings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>This figure presents the overall hybrid network CASCADE. For the comment Ci,j, its content-based sentential representation ? ci,j is extracted using a CNN and appended with context vectors ? ui and ? tj.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>0.77 0.79 0.86 0.74 0.75</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>2D-Scatterplot of the user embeddings visualized using t-SNE<ref type="bibr" target="#b19">(Maaten and Hinton, 2008)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 Table 1 :</head><label>11</label><figDesc>provides the comment distribution of all the dataset variants mentioned. Details of comments in the SARC datasets.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Training set</cell><cell></cell><cell></cell><cell cols="2">Testing set</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">no. of comments</cell><cell cols="2">avg. no. of words per comment</cell><cell cols="2">no. of comments</cell><cell cols="2">avg. no. of words per comment</cell></row><row><cell></cell><cell></cell><cell>non-sarc</cell><cell>sarc</cell><cell>non-sarc</cell><cell>sarc</cell><cell>non-sarc</cell><cell>sarc</cell><cell>non-sarc</cell><cell>sarc</cell></row><row><cell>Main</cell><cell>balanced imbalanced</cell><cell>77351 77351</cell><cell>77351 25784</cell><cell>55.13 55.13</cell><cell>55.08 55.21</cell><cell>32333 32333</cell><cell>32333 10778</cell><cell>55.55 55.55</cell><cell>55.01 55.48</cell></row><row><cell>Pol</cell><cell>balanced</cell><cell>6834</cell><cell>6834</cell><cell>64.74</cell><cell>62.36</cell><cell>1703</cell><cell>1703</cell><cell>62.99</cell><cell>62.14</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">*  non-sarc: non-sarcastic, sarc: sarcastic</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison of CASCADE with state-of-the-art networks and baselines on multiple versions of the SARC dataset. We assert significance when p &lt; 0.05 under paired-t test. Results comprise of 10 runs with different initializations. The bottom row shows the absolute difference with respect to the CUE-CNN system.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparison with variants of the proposed CASCADE network. All combinations use content-based CNN.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://www.reddit.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.reddit.com/reddits/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://nlp.cs.princeton.edu/SARC/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/samiroid/CUE-CNN</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Modelling context with user embeddings for sarcasm detection in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Byron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paula Carvalho M?rio J</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silva</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.00976</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning multiview embeddings of twitter users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Benton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="14" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04606</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Clues for detecting irony in user-generated contents: oh</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paula</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu?s</forename><surname>Sarmento</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>M?rio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eug?nio De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliveira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">s so easy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>!! It</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st international CIKM workshop on Topic-sentiment analysis for mass opinion</title>
		<meeting>the 1st international CIKM workshop on Topic-sentiment analysis for mass opinion</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="53" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Author gender identification from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Na</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarathnam</forename><surname>Chandramouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Subbalakshmi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Digital Investigation</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="78" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semi-supervised recognition of sarcastic sentences in twitter and amazon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Davidov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Tsur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth conference on computational natural language learning</title>
		<meeting>the fourteenth conference on computational natural language learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identifying sarcasm in twitter: a closer look</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Gonz?lez-Ib?nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Wacholder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="581" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Canonical correlation analysis: An overview with application to learning methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandor</forename><surname>David R Hardoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2639" to="2664" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Relations between two sets of variates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harold</forename><surname>Hotelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="321" to="377" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Harnessing context incongruity for sarcasm detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinita</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="757" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic sarcasm detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark J</forename><surname>Carman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Your sentiment precedes you: Using an author&apos;s historical tweets to predict sarcasm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anupam</forename><surname>Khattri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Carman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<meeting>the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A large self-annotated corpus for sarcasm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiran</forename><surname>Vodrahalli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05579</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Lexical influences on the perception of sarcasm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gina</forename><forename type="middle">M</forename><surname>Kreuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on computational approaches to Figurative Language</title>
		<meeting>the Workshop on computational approaches to Figurative Language</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning-based document modeling for personality detection from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="74" to="79" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The personality theories of hj eysenck and ja gray: A comparative review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirby</forename><surname>Gilliland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personality and Individual differences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="583" to="626" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><forename type="middle">C</forename><surname>Deary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Whiteman</surname></persName>
		</author>
		<title level="m">Personality traits</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hierarchical probabilistic neural network language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Aistats</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="246" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A deeper look into sarcastic tweets using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.08815</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Devamanyu Hazarika, and Prateek Vij</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sarcasm detection on twitter: A behavioral modeling approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Rajadesingan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Zafarani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Eighth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="97" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sarcasm as contrast between a positive sentiment and negative situation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashequl</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Surve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lalindra De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="704" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A survey of modern authorship attribution methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">yeah right&quot;: Sarcasm recognition for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Tepperman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrikanth</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth International Conference on Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Icwsm-a great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Tsur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Davidov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="162" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Humans require context to infer ironic intent (so computers probably do, too)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Byron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Kertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="512" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sparse, contextually informed models for irony detection: Exploiting user communities, entities and sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Byron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1035" to="1044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tweet sarcasm detection using deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guohong</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2449" to="2460" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
