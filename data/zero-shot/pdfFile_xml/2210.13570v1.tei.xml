<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Strong-TransCenter: Improved Multi-Object Tracking based on Transformers with Dense Representations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Galor</surname></persName>
							<email>amitgalor@mai1.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering</orgName>
								<orgName type="institution">Tel-Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Orfaig</surname></persName>
							<email>royorfaig@tauex.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering</orgName>
								<orgName type="institution">Tel-Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben-Zion</forename><surname>Bobrovsky</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering</orgName>
								<orgName type="institution">Tel-Aviv University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Strong-TransCenter: Improved Multi-Object Tracking based on Transformers with Dense Representations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>: IDF1-HOTA-MOTA comparisons of transformer-based trackers with our proposed Strong-TransCenter tracker on the MOT17 and MOT20 test sets. The x-axis is IDF1, the y-axis is HOTA, and the radius of the circle is MOTA. Our STC Tracker achieves the best IDF1 and HOTA performance and second best MOTA performance on the MOT17 dataset, and the best IDF1, HOTA and MOTA on the MOT20 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Transformer networks have been a focus of research in many fields in recent years, being able to surpass the stateof-the-art performance in different computer vision tasks. A few attempts have been made to apply this method to the task of Multiple Object Tracking (MOT), among those the state-of-the-art was TransCenter, a transformer-based MOT architecture with dense object queries for accurately tracking all the objects while keeping reasonable runtime. TransCenter is the first center-based transformer framework for MOT, and is also among the first to show the benefits of using transformer-based architectures for MOT. In this paper we show an improvement to this tracker using post processing mechanism based in the Track-by-Detection paradigm: motion model estimation using Kalman filter and target Re-identification using an embedding network. Our new tracker shows significant improvements in the IDF1 and HOTA metrics and comparable results on the MOTA metric (70.9%, 59.8% and 75.8% respectively) on the MOTChallenge MOT17 test dataset and improvement on all 3 metrics (67.5%, 56.3% and 73.0%) on the MOT20 test dataset. Our tracker is currently ranked first among transformer-based trackers in these datasets. The code is publicly available at: https://github.com/ amitgalor18/STC_Tracker</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The task of multiple object tracking in video has been the center of much focus in computer vision research in the past few years, with various real world applications (e.g. autonomous vehicles, sport analysis, surveillance etc.). One of the most comprehensive benchmarks dedicated to this task is MOTChallenge <ref type="bibr" target="#b0">[1]</ref>, having several datasets such as MOT17 and MOT20 which consist of fully annotated videos of pedestrians in various scenarios and environments. The goal of the tracker in the challenge is to infer the positions of each of the pedestrians in each frame while retaining their identities throughout the trajectories. There is a distinction in the challenge between online (causal) trackers which only use past and current frames information for the inference of a current frame and offline (noncausal) trackers that have access to information from all of the video frames and can therefore infer on a current frame using future frame information. Much research was done using these datasets <ref type="bibr" target="#b1">[2]</ref>, with many trackers using different approaches to complete the task. One of the major breakthroughs in the field was SORT (Simple Online and Realtime Tracking) <ref type="bibr" target="#b2">[3]</ref>, having simplified the task and divide it to several sub-tasks: Detection of all the pedestrians in the frame, association (Re-ID) between previous tracks (trajectories) and new detections, and prediction of track locations using a motion model. The association sub-task was done using the well known Hungarian Algorithm <ref type="bibr" target="#b3">[4]</ref>, and the track prediction was done using a standard Kalman Filter <ref type="bibr" target="#b4">[5]</ref>. The method was further improved in the publication of DeepSORT <ref type="bibr" target="#b5">[6]</ref>, that introduced the use of a neural networks for the detection subtask. Many more trackers in the following years used this Tracking-by-Detection paradigm <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b9">[10]</ref>, which introduced mainly improvement to the detector network and to the track management methods, while some trackers featured a separate network for occlusion handling <ref type="bibr" target="#b10">[11]</ref>, advanced methods of assignment <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> or camera motion compensation <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Other trackers proposed to combine the detection with other components (e.g. appearance embedding, motion model, association) in one module <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b14">[15]</ref>. In the last few years, several trackers <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b18">[19]</ref> introduced frameworks based on Transformer networks <ref type="bibr" target="#b19">[20]</ref> for MOT in order to benefit from the advantages of the generalizability of the model. The main advantage is the ability of the encoder-decoder architecture to encode features from the scene using a CNN <ref type="bibr" target="#b20">[21]</ref> or PVT <ref type="bibr" target="#b21">[22]</ref> while also encoding information about relationships between different parts of the scene, and then decode the queries with one-to-one assignment to objects. Transformer architectures have been shown to achieve better performance than CNN based methods on several benchmarks, with great flexibility in the tasks they can complete <ref type="bibr" target="#b22">[23]</ref>. Nevertheless, with limited data transformer-based trackers still fall short of surpassing trackers based on state-of-theart object detectors, and fail in some scenarios due to detection imprecision. Our tracker is an attempt to improve upon a transformer-based tracker using post processing methods for motion model estimation and re-identification, and as shown in <ref type="figure">Fig 1,</ref> it achieves better results in the HOTA and IDF1 evaluation metrics on the MOT17 test dataset and better results on HOTA, IDF1 and MOTA on the MOT20 test dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Transformers. In Multiple Object Tracking, the input is a sequence of frames. The encoder-decoder transformer architecture is therefore designed to encode the representations of the frames, use self-attention to reason about the objects in the scene and the encoder-decoder attention to access information from the whole frame. The self attention helps to avoid ID-switches, terminate occluded tracks and initiate new tracks. Both Transtrack <ref type="bibr" target="#b16">[17]</ref> and TrackFormer <ref type="bibr" target="#b15">[16]</ref> use sparse object queries to detect new objects and initialize tracking based on the DETR <ref type="bibr" target="#b22">[23]</ref> architecture method, and track queries to keep information about the different objects across the frames, in order to achieve multi-frame attention. The most significant differences between the two is the association stage, in which TrackFormer took a point-based approach and TransTrack uses bounding-box based association. MOTR <ref type="bibr" target="#b17">[18]</ref> also employs a track query strategy but uses a temporal aggregation network to learn stronger temporal relations and obviate the need for IoU-based matching or Re-ID features. TransCenter <ref type="bibr" target="#b18">[19]</ref> took a different approach and achieved the best results out of all the Transformer-based trackers in the MOTChallenge benchmark <ref type="bibr" target="#b0">[1]</ref>, and therefore was chosen as the basis for our tracker. TransCenter trains pixel-wise dense queries to learn point-based tracking of pedestrian heatmap centers and sizes. They feed multi-scale tracking and detection queries into the decoder in order to find objects at different resolutions of the feature maps. It improved the efficiency by abandoning the heavy ResNet <ref type="bibr" target="#b20">[21]</ref> based feature extraction and using the PVT <ref type="bibr" target="#b21">[22]</ref> architecture as an encoder. TransCenter also uses pixel-level dense queries for detection, to avoid the insufficient number and the overlapping nature of sparse queries without positional correlations. The query-pixel correspondence discards the time-consuming Hungarian matching <ref type="bibr" target="#b3">[4]</ref> for the query-ground truth association during training, though the method is still being used for inference. The track queries are kept active even when the object is not found for a few frames, in case it reappears after an occlusion. The main drawback is that the spatial information embedded into the query prevents application for long term occlusions, in the case the reappearance location is far from the disappearance location.</p><p>Kalman Filter. Most of the trackers using the trackby-detection paradigm use the famous Kalman filter <ref type="bibr" target="#b4">[5]</ref> to estimate the object's motion model and hence predict the location of the object in each frame. The implementation of the Kalman filter that appeared in DeepSORT <ref type="bibr" target="#b5">[6]</ref> was successfully used by many more modern trackers <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. Kalman filter allows a more precise association based on position, even in scenarios where the detector performs poorly, e.g. during occlusions. Re-ID. Retaining <ref type="figure">Figure 2</ref>: A flowchart overview of our STC tracker. The TransCenter <ref type="bibr" target="#b18">[19]</ref> main architecture was simplified on the left. The additional blocks are in dark red (Kalman Filter 3.2 and Embedding Network 3.3) and the modified blocks are in purple. The cascade matching contains two association steps that match new detections with existing tracks using a combined appearance and GIoU <ref type="bibr" target="#b25">[26]</ref> score. The Re-ID module attempts to match remaining detections with inactive tracks. The post-processing block is an optional addition, as in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b24">[25]</ref> and described in 4.3.</p><p>an object's identity in a crowded scene is one of the main challenges in MOT. Several trackers use the same network for object detection and for extracting appearance features <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b26">[27]</ref> in order to increase efficiency, while other methods use a separate deep neural network to extract features from the detected objects <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b24">[25]</ref>. Several methods train both networks together in order to achieve both efficiency and high performance <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b29">[30]</ref>. The latest works <ref type="bibr" target="#b6">[7]</ref> use the Strong Baseline for person Re-identification <ref type="bibr" target="#b30">[31]</ref> and the FastReID pytorch library <ref type="bibr" target="#b31">[32]</ref>, since this network achieves state-of-the-art performance on many person re-identification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overview</head><p>Our tracker is based on TransCenter <ref type="bibr" target="#b18">[19]</ref> with two main modifications integrated into the algorithm: Kalman Filter <ref type="bibr" target="#b4">[5]</ref> and an Embedding Network based on FastReID <ref type="bibr" target="#b31">[32]</ref>. A flowchart of our tracker pipeline is presented in <ref type="figure">Fig 2.</ref> The TransCenter main encoder-decoder architecture was kept as is. It takes as input two consecutive frames at a time and outputs the object location heatmaps with great performance. The modifications to the algorithm were mainly in the track management and track-detection association. The cascade matching block contains two-step association depending on detection confidence as in <ref type="bibr" target="#b8">[9]</ref>, and a third Re-ID association. The first association stage matches active tracks in memory to new objects detected by the transformer with high detection score. The second association stage matches the remaining active tracks with objects detected with low detection score. The third association matches the remaining detected objects with inactive tracks (tracks that were lost recently) and attempts to recover them back to the active tracks list. All three associations were adapted to include both a proximity score (generalized Intersection over Union <ref type="bibr" target="#b25">[26]</ref>) and an appearance score based on embedding from an Embedding network. An optional offline module was added and discussed in 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Kalman Filter</head><p>Kalman Filter in a tracking task is used on trajectories to propagate each track's location to the next frame (Kalman predict phase), while the Kalman motion model is updated every time a track is associated to a new detection (Kalman update phase). These two steps can be represented by these recursive equations for each frame k ? N: predict phase:</p><formula xml:id="formula_0">x k|k?1 = F kxk?1|k?1 P k|k?1 = F k P k?1|k?1 F k + Q k<label>(1)</label></formula><p>update phase:</p><formula xml:id="formula_1">K k = P k|k?1 H k (H k P k|k?1 H k + R k ) ?1 x k|k =x k|k?1 + K k (z k ? H kxk|k?1 ) P k|k = (I ? K k H k )P k|k?1<label>(2)</label></formula><p>Where F k is the transition matrix, P k is the covariance matrix, K k is the Kalman gain, H k is the observation matrix, Q k is the process noise covariance, and R k is the measurement noise covariance. The implementation we chose, based on the work of DeepSORT <ref type="bibr" target="#b5">[6]</ref> as mentioned in 2, represented the object's state as:</p><formula xml:id="formula_2">x = [x c , y c , a, h,? c ,? c ,?,?]<label>(3)</label></formula><p>where (x c , y c ) are the 2D coordinates of the object center in the image plane. h is the bounding box height and a is the bounding box aspect ratio. The integration of motion model estimation allows a more precise track position estimation and prevents misdetections and ID-switches, especially in cases where the detection is difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Embedding Network</head><p>In order to tackle the problem of ID switches, especially in cases of crowded scenes with many possible matches in close proximity, we incorporated a method to base association on appearance instead of only IoU. The implementation we chose was the FastReID library <ref type="bibr" target="#b31">[32]</ref>, based on the SBS architecture <ref type="bibr" target="#b30">[31]</ref> with ResNeSt50 backbone <ref type="bibr" target="#b32">[33]</ref>. The model was trained on the MOT17 and MOT20 train sets as in <ref type="bibr" target="#b6">[7]</ref>. Attempts were made to use the features derived from the TransCenter transformer itself as the object embeddings but it achieved poor results compared to the SBS network, which was trained specifically for the Re-ID task. The network creates an embedding vector to represent the image patch containing the detected object using the heatmap centers locations from the transformer. After every matching with a high enough detection score, the embedding vector is updated as the new appearance of the associated track. This is because a low score detection from the transformer network usually correlates with a problematic visual detection, e.g. a partially occluded object, that does not represent the object's regular appearance. The update is applied using an exponential moving average (EMA), as in <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b7">[8]</ref>. The embedding vector for track i at frame k will be therefore updated as such:</p><formula xml:id="formula_3">e k i = ?e k?1 i + (1 ? ?)f k i<label>(4)</label></formula><p>Where f k i is the appearance embedding of the current matched detection and ? = 0.9 is a momentum term. In every association stage an embedding distance is calculated between all the existing tracks and the new detections, as the cosine similarity between the track embedding e k i and the new detection embedding vector f k j . As in <ref type="bibr" target="#b6">[7]</ref>, the combination of IoU score and appearance embedding score was done by taking the minimum value between the two:</p><formula xml:id="formula_4">C i,j = min{d iou i,j ,d cos i,j }<label>(5)</label></formula><p>Where C i,j is the (i, j) element of cost matrix C. d iou i,j is the IoU distance between the i-th track bounding box and the j-th detection bounding box, representing the motion cost. d cos i,j is the cosine distance between the average track appearance vector i and the new detection appearance embedding j.d cos i,j is our new appearance cost. Before combining the distances we filter out potential matches that don't comply with chosen thresholds for appearance distance and IoU distance. The chosen set of thresholds differs in our case since we used GIoU (generalized intersection over union <ref type="bibr" target="#b25">[26]</ref>) instead of the regular IoU. The thresholds were chosen empirically using a grid search. The association itself, after creating the cost matrix, is done using the Hungarian algorithm <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset and Evaluation Metrics</head><p>The experiments were conducted on the MOT17 dataset <ref type="bibr" target="#b0">[1]</ref> which is composed of 7 videos for training and 7 videos for testing, and the MOT20 dataset <ref type="bibr" target="#b33">[34]</ref> which is composed of 4 videos for training and 4 videos for testing. The videos feature many pedestrians in various natural scenarios (streets, shopping centers etc.) with different lighting conditions, static or moving camera, different camera fps and resolution etc. The train set contains annotation files with bounding box locations for every object in every frame. The test set has only the videos available while performance evaluation is done using the MOTchallenge website with restrictive measures to avoid overfitting.</p><p>Methods in the MOTChallenge are evaluated using several main metrics. MOTA (Multipe Object Tracking Accuracy) <ref type="bibr" target="#b43">[44]</ref> has been used as the main evaluation metric for MOT for many years. It is calculated by the formula:</p><formula xml:id="formula_5">M OT A = 1 ? F N + F P + IDSW GT<label>(6)</label></formula><p>Where F N , F P , IDSW , and GT are the numbers of false negatives (misses), false positives, ID switches and ground truth labels respectively in all the frames of the sequence. MOTP (Multiple Object Tracking Precision) <ref type="bibr" target="#b43">[44]</ref> is the measure of position precision, regardless of of the detection and identification skills of the tracker. It is calculated as:</p><formula xml:id="formula_6">M OT P = D M<label>(7)</label></formula><p>Where D is the sum of distances between predicted positions and ground truth positions, and M is the number of matches found for all frames. IDF1 <ref type="bibr" target="#b44">[45]</ref> is a measurement of the tracker's ability to retain all of the objects identifications throughout the sequence, and is based on the standard F1 score that balances between precision and recall in classification tasks. It is widely used in the MOTChallenge benchmark and is calculated by the formula: Where IDF P , IDF N and IDT P are identification false positive matches, false negative matches and true positive matches. HOTA (Higher Order Tracking Accuracy) <ref type="bibr" target="#b45">[46]</ref> is a relatively new evaluation metric that aims to balance between the ability of a tracker to detect all objects and associate their individual identifications in one number. It is calculated by the formula:</p><formula xml:id="formula_7">IDF 1 = 2IDT P 2IDT P + IDF P + IDF N<label>(8)</label></formula><formula xml:id="formula_8">HOT A = ? c A(c) |T P | + |F N | + |F P | A(c) = |T P A(c)| |T P A(c)| + |F N A(c)| + |F P A(c)| (9)</formula><p>Where T P , F N and F P are the detection true positive, false negative and false positives respectively, and each T P of interest c has a weighted metric A(c) that weighs the association true positives, false negatives and false positives T P A, F N A and F P A, as thoroughly explained and illustrated in <ref type="bibr" target="#b45">[46]</ref>. This evaluation method produces more intuitive performance score in many scenarios.</p><p>The results rely on a series of thresholds for different parts of the pipeline. The high detection threshold for the first association stage is 0.3 in MOT17 and 0.4 in MOT20, and the low detection threshold for the second association stage is 0.1, based on the detection confidence score as in <ref type="bibr" target="#b18">[19]</ref>. The threshold for the embedding distance and IoU distance are 0.4 and 0.8 respectively. Based on the combined distance, the matching threshold for the linear association itself is 0.9 for the first association and the Re-ID recovery association, and 0.4 for the second association, since the second association considers detections with lower confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>Results on the MOT17 and MOT20 test datasets are presented in <ref type="table" target="#tab_0">table 1 and table 2</ref> respectively. On the MOT20 test set STC outperforms the trackers using the same pretraining conditions in all three main metrics (HOTA, MOTA, and IDF1). On the MOT17 test set STC outperforms the trackers that used the same pretraining conditions in the IDF1 and HOTA metrics and has comparable results in the MOTA metric. It is worth noting that STC outperforms all of the transformer-based methods in these 2 metrics, as visualized in <ref type="figure">Fig 1.</ref> The STC results also feature the lowest FN count on both datasets, demonstrating both the performance of the accurate detection process by the original TransCenter <ref type="bibr" target="#b18">[19]</ref> with the pixel-level dense detection queries, and the ability of the Kalman filter motion model and improved association to lower the amount of lost tracks. These results make STC the highest ranked transformer-based tracker in terms of HOTA and IDF1 on these MOTChallenge datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Offline modules</head><p>The tracker we presented is an online tracker (causal), which means it generates the prediction for the track locations on each frame only based on information from the current and previous frames. Other trackers <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref> developed methods for offline tracking (non-causal), which have the advantage of using information from future frames as well. These trackers can be used for various tasks such as sports analysis or analysis of past surveillance videos, but not for real-time tasks which require immediate response. Nevertheless, we decided to test two non-causal features in <ref type="table">Table 2</ref>: Results on MOT20 testset on public and private detections. The methods chosen for comparison use the same dataset for pretraining or additional datasets, indicated by the background color. The best result within the same training conditions (background color) is in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Public Detections</head><p>Private Detections   <ref type="bibr" target="#b24">[25]</ref>. AFLink (Appearance-Free Link) is a linking algorithm, predicting connectivity between two trajectories based on the spatio-temporal information, i.e. the change of their respective positions through time. It is essentially able to conclude whether two predicted tracks by the original tracker are in fact from the same object and therefore decrease the number of ID switches. GSI (Gaussian-smoothed Interpolation) is an interpolation algorithm, intended to fill gaps in predicted trajectories by the original tracker. It models the trajectory as a gaussian process with a function kernel in order to interpolate the track's position in the missing segment.</p><formula xml:id="formula_9">Method Data MOTA ? MOTP ? IDF1 ? HOTA ? MT ? ML ? FP ? FN ? IDSW ? Data MOTA ? MOTP ? IDF1 ? HOTA ? MT ? ML ? FP ? FN ? IDSW ? CorrTracker [30]<label>5D1</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>In our ablation study we compared some of the separable modules we added to our tracker and to the original TransCenter <ref type="bibr" target="#b18">[19]</ref>. The AFLink and GSI modules are the non-causal features developed in <ref type="bibr" target="#b24">[25]</ref> and described in 4.3.</p><p>As we can see in the results table 3 the AFLink module mainly improves the IDSW number, so it mostly improves the IDF1 and HOTA measures when the IDSW number is more significant to begin with, and has no significant effect on the MOTA metric. The GSI module has a significant effect on the number of FP (false positives) and FN (false negatives, i.e. misdetections) since it was able to complete missing trajectories but at the same time generated false trajectories, and the balance between them only had an effect on the main evaluation metrics in several configurations, depending on parameters of the GSI function. In order to optimize the association step between tracks and new detections we tested association using only the appearance embeddings (noted as "only Emb") or only the generalized IoU <ref type="bibr" target="#b25">[26]</ref> score (noted as "only IoU"). Using only the embedding distance caused a very high number of IDSW and poor metric results as expected, since it caused the association to match tracks and detections with no regard to their positions. Using only the IoU without using the embedding distance is essentially the same as not using the FastReID feature at all, and cause a slightly smaller number of FP but higher number of IDSW. The last experiment is testing the classic method of fusing the embedding and IoU scores for the final association distance, using the formula:</p><formula xml:id="formula_10">Dist = ? ? d emb + (1 ? ?) ? d iou<label>(10)</label></formula><p>Where Dist is the fused association distance, d emb is the appearance embedding distance, d iou is the bounding box IoU distance and ? is a configurable parameter for the respective weight, that we chose as 0.5 for this example after testing various values. We found that like in <ref type="bibr" target="#b6">[7]</ref> the best way to utilize the information from the embedding distances is by using the minimum between the two distances. The minimum is taken after filtering the IoU distance with a higher threshold to guarantee the track predicted position and the positions of the potential matchings are close, before considering a match based on appearance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Qualitative Analysis</head><p>A qualitative analysis was performed on the MOT17 and MOT20 train datasets, in order to find differences between our tracker and its predecessor, as well as demonstrate the noise reducing qualities of the Kalman filter. One of the methods used was plotting trajectories of every track on the video and find inconsistencies between the predicted trajectory of a tracker and the ground truth trajectory. This allowed us to find problems and edge cases where the tracker performs poorly. We noticed the amount of IDSW cases decreased significantly in the analyzed videos after adding the Kalman motion model, since the predicted position of each track is more precise than using the previous detection position with only optic flow for the whole frame as the motion progression method. An example for an IDSW is demonstrated in <ref type="figure">Fig 3.</ref> In this example the transformer in the original tracker identified the pedestrian emerging into the frame, but the association matched the newly detected pedestrian to an existing track that disappeared on the right. After adding the Kalman filter and embedding network the pedestrian was correctly associated to a new track.</p><p>Another method of analysis included plotting bounding boxes to indicate true positive tracking (TP) in green, false negative (FN) in red and false positive (FP) in pink. An additional example for improved tracking is demonstrated in <ref type="figure">Fig 4,</ref> in which the indicated boxes show a pedestrian that is almost entirely occluded and was detected by the Transformer attention mechanism in the wrong position, but the addition of a motion model made it possible to associate it to the existing track in our STC tracker. The original Tran-sCenter managed to detect the mostly occluded pedestrian but positioned the track in the wrong location, causing both an FN in the ground truth location and an FP in the tracker predicted location. Our STC tracker managed to predict the <ref type="figure">Figure 3</ref>: Visualization of a specific scenario in the results of a tracker based only on transformer (TransCenterV2 <ref type="bibr" target="#b18">[19]</ref>) at the top and our STC tracker results (Transformer with Kalman and Embedding) at the bottom. The green trajectories are the tracker prediction with a history of 20 frames and the orange trajectories are the ground truth positions. An ID switch has occurred in the top image, and is demonstrated by the big "jump" in the trajectory from right to left, giving the new pedestrian that emerged an existing track ID. In the bottom image the trajectory only began when the pedestrian emerged. The results are from the MOT17-09 video on frame 389. correct location in this scenario due to the added Kalmanbased motion model. This demonstrates both the ability of the transformer attention mechanism to infer the existence of occluded objects and the assistance of the motion model in predicting the location of lost objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we tackled the problem of multi-object tracking and demonstrated the potential of a Transformerbased tracker with a combination of several known methods to create a robust tracker and outperform existing trackers on the MOTChallenge MOT17 and MOT20 benchmark datasets. Our tracker is currently ranked first among the transformer-based trackers in these datasets in terms of <ref type="figure">Figure 4</ref>: Visualization of a specific scenario in the results of a tracker based only on transformer (TransCenterV2 <ref type="bibr" target="#b18">[19]</ref>). The full frame shows the results of the TransCenterV2 tracker compared to the ground truth: green boxes are True Positive (TP), red boxes are False negative (FN) and pink boxes are False Positive (FP). The zoom-in image shows the area of the error in the frame with the original TransCenter on the right and with our STC tracker on the left. The results are from the MOT20-01 video on frame 299.</p><p>HOTA and IDF1. We demonstrated the benefits of including Kalman motion estimation and integrating a combination of appearance embedding and position in the track association stage, both of which improved the rate of misdetections and ID switches. We believe future work on transformers and their implementation on the MOT task might lead to an allin-one transformer based tracker without the need for additional modules.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Results on MOT17 testset on public and private detections. The methods chosen for comparison use the same dataset for pretraining or additional datasets, indicated by the background color. The best result among methods trained in the same conditions is in bold. MOTP ? IDF1 ? HOTA? MT ? ML ? FP ? FN ? IDSW ? Data MOTA ? MOTP ? IDF1 ? HOTA? MT ? ML ? FP ? FN ? IDSW ?</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Public Detections</cell><cell></cell><cell></cell><cell></cell><cell cols="3">Private Detections</cell></row><row><cell cols="3">Method MOTA ? GSDT [35] Data</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5D1</cell><cell>66.2</cell><cell>79.9</cell><cell>68.7</cell><cell>55.5</cell><cell>40.8 18.3 43,368 144,261 3,318</cell></row><row><cell>SOTMOT [27]</cell><cell>5D1</cell><cell>62.8</cell><cell></cell><cell>67.4</cell><cell></cell><cell>24.4 33.0 6,556 201,319 2,017</cell><cell>5D1</cell><cell>71.0</cell><cell></cell><cell>71.9</cell><cell></cell><cell>42.7 15.3 39,537 118,983 5,184</cell></row><row><cell>GSDT V2 [35]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5D1</cell><cell>73.2</cell><cell></cell><cell>66.5</cell><cell>55.2</cell><cell>41.7 17.5 26,397 120,666 3,891</cell></row><row><cell>CorrTracker [30]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5D1</cell><cell>76.5</cell><cell></cell><cell>73.6</cell><cell>60.7</cell><cell>47.6 12.7 29,808 99,510 3,369</cell></row><row><cell>FairMOT [24]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5D1+CH</cell><cell>73.7</cell><cell>81.3</cell><cell>72.3</cell><cell>59.3</cell><cell>43.2 17.3 27,507 117,477 3,303</cell></row><row><cell>RelationTrack [28]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5D1+CH</cell><cell>73.8</cell><cell>81.0</cell><cell>74.7</cell><cell>61.0</cell><cell>41.7 23.2 27,999 118,623 1,374</cell></row><row><cell>CSTrack [29]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5D1+CH</cell><cell>74.9</cell><cell>80.9</cell><cell>72.6</cell><cell>59.3</cell><cell>41.5 17.5 23,847 114,303 3,567</cell></row><row><cell>MLT [36]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(5D1+CH)</cell><cell>75.3</cell><cell>81.7</cell><cell>75.5</cell><cell></cell><cell>49.3 19.5 27,879 109,836 1,719</cell></row><row><cell>FUFET [37]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(5D1+CH)</cell><cell>76.2</cell><cell>81.1</cell><cell>68.0</cell><cell>57.9</cell><cell>51.1 13.6 32,796 98,475 3,237</cell></row><row><cell cols="2">TransCenterV2 [19] 5D1+CH</cell><cell>76.0</cell><cell>81.4</cell><cell>65.6</cell><cell></cell><cell>47.3 15.3 28,369 101,988 4,972</cell><cell>5D1+CH</cell><cell>76.4</cell><cell>81.2</cell><cell>65.4</cell><cell></cell><cell>51.7 11.6 37,005 89,712 6,402</cell></row><row><cell>MOTDT17 [38]</cell><cell>RE1</cell><cell>50.9</cell><cell>76.6</cell><cell>52.7</cell><cell>41.2</cell><cell>17.5 35.7 24,069 250,768 2,474</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>UnsupTrack [13]</cell><cell>PT</cell><cell>61.7</cell><cell>78.3</cell><cell>58.1</cell><cell>46.9</cell><cell>27.2 32.4 16,872 197,632 1,864</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GMT CT [39]</cell><cell>RE2</cell><cell>61.5</cell><cell></cell><cell>66.9</cell><cell></cell><cell>26.3 32.1 14,059 200,655 2,415</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TrackFormer [16]</cell><cell>CH</cell><cell>62.5</cell><cell></cell><cell>60.7</cell><cell></cell><cell>29.8 26.9 14,966 206,619 1,189</cell><cell>CH</cell><cell>74.1</cell><cell></cell><cell>68.0</cell><cell>57.3</cell><cell>47.3 10.4 34,602 108,777 2,829</cell></row><row><cell>SiamMOT [40]</cell><cell>CH</cell><cell>65.9</cell><cell></cell><cell>63.5</cell><cell></cell><cell>34.6 23.9 18,098 170,955 3,040</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MOTR [18]</cell><cell>CH</cell><cell>67.4</cell><cell></cell><cell>67.0</cell><cell></cell><cell>34.6 24.5 32,355 149,400 1,992</cell><cell>CH</cell><cell>73.4</cell><cell></cell><cell>68.6</cell><cell>57.8</cell><cell>2439</cell></row><row><cell>CenterTrack [41]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CH</cell><cell>67.8</cell><cell>78.4</cell><cell>64.7</cell><cell></cell><cell>34.6 24.6 18,489 160,332 3,039</cell></row><row><cell>TraDeS [42]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CH</cell><cell>69.1</cell><cell></cell><cell>63.9</cell><cell>52.7</cell><cell>36.4 21.5 20,892 150,060 3,555</cell></row><row><cell>PermaTrack [43]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CH</cell><cell>73.8</cell><cell></cell><cell>68.9</cell><cell>55.5</cell><cell>43.8 17.2 28,998 114,104 3,699</cell></row><row><cell>TransTrack [17]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CH</cell><cell>75.2</cell><cell></cell><cell>63.5</cell><cell>54.1</cell><cell>55.3 10.2 50,157 86,442 3,603</cell></row><row><cell>TransCenterV2 [19]</cell><cell>CH</cell><cell>75.9</cell><cell>81.2</cell><cell>65.9</cell><cell>56.7</cell><cell>49.8 12.1 30,190 100,999 4,626</cell><cell>CH</cell><cell>76.2</cell><cell>81.1</cell><cell>65.5</cell><cell>56.7</cell><cell>53.5 7.9 40,101 88,827 5,394</cell></row><row><cell>STC (ours)</cell><cell>CH</cell><cell>75.8</cell><cell>81.3</cell><cell>70.8</cell><cell>59.5</cell><cell>49.7 11.7 33,833 99,074 3,784</cell><cell>CH</cell><cell>75.8</cell><cell>81.1</cell><cell>70.9</cell><cell>59.8</cell><cell>53.6 7.6 44,952 87,039 4,533</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Ablation study of different components of our tracker. The experiments were conducted on the mot17 train dataset using private detections. Best results are underlined, best online results are in bold.</figDesc><table><row><cell>Setting</cell><cell cols="4">MOTA ? IDF1 ? HOTA ? FP ?</cell><cell cols="2">FN ? IDSW ?</cell></row><row><cell>TransCenterV2</cell><cell>86.9</cell><cell>77.3</cell><cell>70.4</cell><cell cols="2">1272 12813</cell><cell>678</cell></row><row><cell>TransCenterV2 + AFLink</cell><cell>86.9</cell><cell>79.9</cell><cell>71.7</cell><cell cols="2">1251 12892</cell><cell>603</cell></row><row><cell>TransCenterV2 + GSI</cell><cell>87.0</cell><cell>77.2</cell><cell>70.4</cell><cell cols="2">2442 11490</cell><cell>663</cell></row><row><cell>TransCenterV2 + AFLink + GSI</cell><cell>87.1</cell><cell>79.9</cell><cell>71.9</cell><cell cols="2">2306 11583</cell><cell>565</cell></row><row><cell>STC</cell><cell>86.7</cell><cell>82.8</cell><cell>73.6</cell><cell cols="2">1611 12802</cell><cell>583</cell></row><row><cell>STC + AFLink</cell><cell>86.7</cell><cell>82.3</cell><cell>72.9</cell><cell cols="2">1553 12823</cell><cell>562</cell></row><row><cell>STC + GSI</cell><cell>87.8</cell><cell>83.0</cell><cell>73.8</cell><cell cols="2">2055 11088</cell><cell>520</cell></row><row><cell>STC + AFLink + GSI</cell><cell>87.7</cell><cell>82.6</cell><cell>73.4</cell><cell cols="2">2288 11100</cell><cell>455</cell></row><row><cell>STC only emb</cell><cell>85.7</cell><cell>76.2</cell><cell>69.5</cell><cell cols="2">1435 12767</cell><cell>1820</cell></row><row><cell>STC only iou</cell><cell>86.7</cell><cell>82.0</cell><cell>73.0</cell><cell cols="2">1553 12779</cell><cell>622</cell></row><row><cell>STC fused emb &amp; iou</cell><cell>86.7</cell><cell>80.53</cell><cell>72.29</cell><cell cols="2">1325 12789</cell><cell>624</cell></row><row><cell cols="2">our ablation study 4.4 -AFLink and GSI, both of which</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>were developed in the work of StrongSORT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank Shlomo Shmeltzer Institute for Smart Transportation at Tel-Aviv University for the scholarship for the first author and for the support of our Autonomous Mobile Laboratory.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Mot16: A benchmark for multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-03" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiple object tracking: A literature review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2020.103448</idno>
		<idno>ISSN: 00043702. DOI: 10 . 1016 / j . artint.2020.103448</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="page">103</biblScope>
			<date type="published" when="2021-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Simple online and realtime tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Upcroft</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICIP.2016.7533003</idno>
		<idno>DOI: 10 . 1109 / ICIP . 2016 . 7533003</idno>
		<imprint>
			<date type="published" when="2016-02" />
			<biblScope unit="page" from="3464" to="3468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
		<idno type="DOI">10.1002/nav.3800020109</idno>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics Quarterly</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="1955-03-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Introduction to random signals and applied Kalman Filtering, 4th</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Hwang</surname></persName>
		</author>
		<idno>978-0-470-60969-9</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simple online and realtime tracking with a deep association metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wojke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Paulus</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICIP.2017.8296962</idno>
		<idno>ISBN: 978- 1-5090-2175-8. DOI: 10 . 1109 / ICIP . 2017 . 8296962</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="3645" to="3649" />
			<date type="published" when="2017-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Botsort: Robust associations multi-pedestrian tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Orfaig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-Z</forename><surname>Bobrovsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-06" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Towards real-time multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<idno>DOI: 10 . 48550</idno>
		<ptr target="http://arxiv.org/abs/1909.12605" />
		<imprint>
			<date type="published" when="2019-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Bytetrack: Multi-object tracking by associating every detection box</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-10" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improving multiple pedestrian tracking by track management and occlusion handling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyerer</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR46437.2021.01081</idno>
		<idno>ISBN: 978-1-6654-4509-2. DOI: 10.1109/ CVPR46437.2021.01081</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="10" to="953" />
			<date type="published" when="2021-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Coupled network for robust pedestrian detection with gated multi-layer feature extraction and deformable occlusion handling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Stathaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dai</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIP.2020.3038371</idno>
		<idno>DOI: 10 . 1109 / TIP . 2020 . 3038371</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1057" to="7149" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modelling ambiguous assignments for multi-person tracking in crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyerer</surname></persName>
		</author>
		<idno type="DOI">10.1109/WACVW54805.2022.00019</idno>
		<idno>ISBN: 978-1-6654- 5824-5. DOI: 10 . 1109 / WACVW54805 . 2022 . 00019</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="133" to="142" />
			<date type="published" when="2022-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Simple unsupervised multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karthik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gandhi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tracking without bells and whistles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Meinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixe</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2019.00103</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="941" to="951" />
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Online multi-target tracking using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v31i1.11194</idno>
		<idno>DOI: 10 . 1609 / aaai . v31i1.11194</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017-02-01" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="2374" to="3468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Trackformer: Multi-object tracking with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Meinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-01" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<title level="m">Transtrack: Multiple object tracking with transformer</title>
		<imprint>
			<date type="published" when="2020-12" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Motr: End-to-end multiple-object tracking with transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-05" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Delorme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Alameda-Pineda</surname></persName>
		</author>
		<title level="m">Transcenter: Transformers with dense representations for multiple-object tracking</title>
		<imprint>
			<date type="published" when="2022-03" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page" from="5998" to="6008" />
			<date type="published" when="2017-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2016.90</idno>
		<idno>ISBN: 978-1-4673-8851-1. DOI: 10 . 1109/CVPR.2016.90</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="770" to="778" />
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pvt v2: Improved baselines with pyramid vision transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="DOI">10.1007/s41095-022-0274-8</idno>
	</analytic>
	<monogr>
		<title level="m">Computational Visual Media</title>
		<imprint>
			<date type="published" when="2022-09-03" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="415" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">End-to-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-05" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fairmot: On the fairness of detection and re-identification in multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-021-01513-4</idno>
		<idno>DOI: 10 . 1007/s11263-021-01513-4</idno>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="3069" to="3087" />
			<date type="published" when="2021-11-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<title level="m">Strongsort: Make deepsort great again</title>
		<imprint>
			<date type="published" when="2022-02" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generalized intersection over union: A metric and a loss for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2019.00075</idno>
		<idno>ISBN: 978- 1-7281-3293-8. DOI: 10 . 1109 / CVPR . 2019 . 00075</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="658" to="666" />
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Improving multiple object tracking with single object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR46437.2021.00248</idno>
		<idno>ISBN: 978-1-6654-4509-2. DOI: 10 . 1109 / CVPR46437.2021.00248</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="2453" to="2462" />
			<date type="published" when="2021-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Relationtrack: Relation-aware multiple object tracking with decoupled representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMM.2022.3150169</idno>
		<idno>DOI: 10 . 1109/TMM.2022.3150169</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="page" from="1520" to="9210" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rethinking the competition between detection and reid in multiobject tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIP.2022.3165376</idno>
		<idno>DOI: 10 . 1109 / TIP . 2022 . 3165376</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1057" to="7149" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multiple object tracking with correlation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR46437.2021.00387</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="3875" to="3885" />
			<date type="published" when="2021-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Bag of tricks and a strong baseline for deep person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Fastreid: A pytorch toolbox for general instance reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Resnest: Split-attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2020-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<title level="m">Mot20: A benchmark for multi object tracking in crowded scenes</title>
		<imprint>
			<date type="published" when="2020-03" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Joint object detection and multi-object tracking with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICRA48506.2021.9561110</idno>
		<idno>ISBN: 978-1-7281-9077-8. DOI: 10.1109/ ICRA48506.2021.9561110</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">715</biblScope>
			<biblScope unit="page" from="13" to="708" />
			<date type="published" when="2021-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multiplex labeling graph for near-online tracking in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="DOI">10.1109/JIOT.2020.2996609</idno>
		<idno>DOI: 10 . 1109 / JIOT . 2020 . 2996609</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2327" to="4662" />
			<date type="published" when="2020-09-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liang</surname></persName>
		</author>
		<title level="m">Tracklets predicting based adaptive graph tracking</title>
		<imprint>
			<date type="published" when="2020-10" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Real-time multiple people tracking with deeply learned candidate selection and person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICME.2018.8486597</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Learnable graph matching: Incorporating graph partitioning with deep feature learning for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-03" />
			<biblScope unit="page" from="5299" to="5309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Siammot: Siamese multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Berneshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Modolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tighe</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR46437.2021.01219</idno>
		<idno>ISBN: 978- 1-6654-4509-2. DOI: 10 . 1109 / CVPR46437 . 2021.01219</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="12" to="367" />
			<date type="published" when="2021-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Tracking objects as points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58548-8_28</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">12349</biblScope>
			<biblScope unit="page" from="474" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Track to detect and segment: An online multi-object tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR46437.2021.01217</idno>
		<idno>ISBN: 978-1-6654-4509-2. DOI: 10.1109/ CVPR46437.2021.01217</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="page" from="12" to="347" />
			<date type="published" when="2021-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning to track with object permanence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tokmakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV48922.2021.01068</idno>
		<idno>ISBN: 978-1-6654- 2812-5. DOI: 10 . 1109 / ICCV48922 . 2021 . 01068</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="10" to="840" />
			<date type="published" when="2021-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Evaluating multiple object tracking performance: The clear mot metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bernardin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<idno type="DOI">10.1155/2008/246309</idno>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Image and Video Processing</title>
		<imprint>
			<biblScope unit="page" from="1687" to="5176" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Performance measures and a data set for multitarget, multi-camera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Francesco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C R</forename><surname>Rita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Solera</forename><surname>Ergys</surname></persName>
		</author>
		<editor>H. H. Gang and J?gou</editor>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="978" to="981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Hota: A higher order metric for evaluating multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luiten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-020-01375-2</idno>
		<idno>DOI: 10 . 1007 / s11263 -020 - 01375-2</idno>
		<imprint>
			<date type="published" when="2020-09" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Remot: A model-agnostic refinement for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakamura</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.imavis.2020.104091</idno>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="104" to="091" />
			<date type="published" when="2021-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Improving multi-target tracking via social grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Shelton</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2012.6247899</idno>
		<idno>ISBN: 978-1-4673-1228-8. DOI: 10. 1109/CVPR.2012.6247899</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="1972" to="1978" />
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
