<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Plane Geometry Diagram Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Liang</forename><surname>Zhang</surname></persName>
							<email>zhangmingliang2018@ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation of Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Yin</surname></persName>
							<email>fyin@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation of Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Han</forename><surname>Hao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation of Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Electronic Information Engineering</orgName>
								<orgName type="institution">Beijing Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Lin</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation of Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Plane Geometry Diagram Parsing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T22:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Geometry diagram parsing plays a key role in geometry problem solving, wherein the primitive extraction and relation parsing remain challenging due to the complex layout and between-primitive relationship. In this paper, we propose a powerful diagram parser based on deep learning and graph reasoning. Specifically, a modified instance segmentation method is proposed to extract geometric primitives, and the graph neural network (GNN) is leveraged to realize relation parsing and primitive classification incorporating geometric features and prior knowledge. All the modules are integrated into an end-to-end model called PGDP-Net to perform all the sub-tasks simultaneously. In addition, we build a new large-scale geometry diagram dataset named PGDP5K with primitive level annotations. Experiments on PGDP5K and an existing dataset IMP-Geometry3K show that our model outperforms state-of-the-art methods in four sub-tasks remarkably. Our code, dataset and appendix material are available at https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic geometry problem solving is a long-standing problem and has important applications in the intelligent education field <ref type="bibr" target="#b2">[Chou et al., 1996;</ref><ref type="bibr" target="#b11">Seo et al., 2015;</ref><ref type="bibr" target="#b0">Amini et al., 2019]</ref>. The problem involves text parsing, corresponding diagram parsing and logical reasoning. Previous research works <ref type="bibr" target="#b10">[Sachan et al., 2017;</ref><ref type="bibr" target="#b10">Sachan et al., 2020]</ref> mainly concentrated on text parsing and logical reasoning, but little attention has been paid to diagram parsing <ref type="bibr" target="#b11">[Seo et al., 2014;</ref><ref type="bibr" target="#b9">Lu et al., 2021]</ref>. Geometry diagrams carry rich information about the geometry problem, which can provide crucial cues to aid problem solving. In this work, we focus on plane geometry diagram parsing (PGDP) and propose a powerful diagram parser. Generally, the PGDP task involves identifying and locating visual primitives in the diagram and discovering relationships among them. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, a geometry diagram consists of various types and layouts of geometry, symbols and * Contact Author texts, and these visual primitives are semantically related to each other in various ways. Due to the diversity of style and the interference of primitives, traditional methods, such as Hough transform and Freeman chain-code <ref type="bibr" target="#b10">[Pratt, 2007]</ref>, perform poorly in geometric primitive extraction. Meanwhile, the spatial, structural and semantic relations among primitives cannot be parsed correctly by simple rule-based methods <ref type="bibr" target="#b11">[Seo et al., 2014;</ref><ref type="bibr" target="#b9">Lu et al., 2021]</ref>. Therefore, great efforts are needed for geometric primitive extraction and betweenprimitive relationship parsing. We cast geometric primitive extraction as an instance segmentation problem. Geometric primitives such as lines and arcs are often slender and overlapped. Thus, bounding box based instance segmentation methods <ref type="bibr" target="#b9">Neven et al., 2019;</ref><ref type="bibr" target="#b13">Ying et al., 2021]</ref> are not suitable for this task. Our proposed PGDP framework instead employs a geometric segmentation module (GSM), consisting of a semantic segmentation branch and a segmentation embedding branch, to cluster multi-class primitive instances at pixel level, so as to overcome the issues stated above.</p><p>For primitive relation parsing, we model PGDP as a special scene graph generation (SGG) problem <ref type="bibr">[Xu et al., 2017;</ref>. In contrast to ordinary SGG, as shown in <ref type="figure">Figure 2</ref>, PGDP deals with graphs with heterogeneous nodes and multi-edges associated, when primitives and their relations are seen as nodes and edges, respectively. To optimize reasoning incorporating geometry prior knowledge, we adopt a GNN module (GM) aggregated with visual, spatial ? (girl, ride, horse) ? (girl, wear, hat) ? (horse, on, beach) P1 P2 P3 L2 L1 P4 T1 T2 T3 S1 ? (T1, (P1, P2, L1)) ? (T2, (S1)) ? (T3, (P4)) ? (S1, (P2, P3, L2)) ? (P2, (L1)) ? (P2, (L2)) . . . . . . ? (T1, (S1)) ? (S1, (P1, L3 , L4)) ? (P1, (C1)) T1 S1 S2 S3 P1 P2 P3 L1 L2 L3 L4 C1 P4 L5 ? (P2, (C1)) ? (S3, (P3, L1 , L2)) ? (S2, (P2, P4 , L5)) . . . . . . ? (T1, (S1 , S2)) ? (S1, (P1)) ? (S2, (P2)) T1 S1 S2 S3 L1 P1 P2 S4 L2 ? (S3, (L1)) ? (S4, (L2)) . . . . . . <ref type="figure">Figure 2</ref>: Comparison between tasks of SGG (first image) and PGDP (next three images). Relation tuples are shown below each image. 'P#','L#','C#','T#' and 'S#' denote instances of point, line, circle, text and symbol, respectively. and structural information to predict the primitive relation and identify the text class simultaneously.</p><p>Integrating with GSM and GM, we present the deep learning model for PGDP called PGDPNet. The PGDPNet is trained end-to-end so as to optimize the overall primitive extraction and relation reasoning performance. Also, to facilitate the research of PGDP, we build a new large-scale geometry diagram dataset named PGDP5K, labeled with annotations of primitive locations, classes and their relations. Experiments on PGDP5K and an existing dataset IMP-Geometry3K demonstrate that our method can boost the performance of primitive detection, relation parsing and geometry formal language generation prominently, compared to state-of-the-art methods, and consequently improves the accuracy of geometry problem solving.</p><p>The contributions of this work are summarized in three folds: (1) We propose the PGDPNet, the first end-to-end deep learning model for explicit geometry diagram parsing.</p><p>(2) We build a large-scale dataset PGDP5K, containing finegrained annotations of primitives and relations. (3) Our method demonstrates superior performance of geometry diagram parsing, outperforming previous methods significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Automatic analysis of geometry diagrams has been studied in two main aspects: primitive extraction and relation reasoning. As to primitive extraction, traditional methods such as Hough transform and its improved methods <ref type="bibr" target="#b10">[Pratt, 2007]</ref> are still adopted in most recent geometry diagram parsing works <ref type="bibr" target="#b11">[Seo et al., 2014;</ref><ref type="bibr" target="#b11">Seo et al., 2015;</ref><ref type="bibr" target="#b4">Gan et al., 2018;</ref><ref type="bibr" target="#b9">Lu et al., 2021]</ref> for their simplicity and efficiency. However, in the scenes of complex layout and multi-primitive interference, traditional methods inevitably suffer severe performance degradation. Deep learning based geometric primitive extraction methods <ref type="bibr" target="#b6">[Huang et al., 2018;</ref><ref type="bibr" target="#b13">Zhou et al., 2019]</ref> have been proposed recently. Nevertheless, they only focus on one type of geometric primitive such as straight line in nature scenes. Research works about geometric relation reasoning of diagrams are undergoing. Some methods <ref type="bibr" target="#b11">[Seo et al., 2014;</ref><ref type="bibr" target="#b9">Lu et al., 2021]</ref> use greedy or optimization strategies based on distance and content rules, but cannot parse complicated between-primitive relations correctly. Our work, inspired by the SGG task <ref type="bibr">[Xu et al., 2017;</ref><ref type="bibr" target="#b5">Guo et al., 2021]</ref>, reasons primitive relations with the GNN model <ref type="bibr" target="#b12">[Veli?kovi? et al., 2018;</ref><ref type="bibr" target="#b13">Ye et al., 2020]</ref>. The detailed comparison between these two tasks will be described in Section 3.2. To sum up, our work proposes a more powerful geometry diagram parser with a novel and effective scheme for diagram primitive extraction and reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminary</head><p>Before the description of problem formulation and solution, we introduce the terms involved in PGDP. The basic element in plane geometry diagram is called primitive, which is generally categorized into geometric primitive and non-geometric primitive. The main categories of geometric primitives are point, line and circle (arc), while non-geometric primitives include text and symbol. Predicate is the general term of geometric shape entity, geometric relation or arithmetic function. Proposition is the logical expression combined with predicate and primitive. A set of propositions makes up the geometry formal language of a diagram.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Formulation</head><p>The PGDP consists of three fundamental sub-tasks: (1) detection and identification of primitives; (2) building basic relationships among primitives; (3) generating the geometry formal language. In this work, we model PGDP as special SGG, which is formulated in the following form:</p><formula xml:id="formula_0">O = {O geo , O sym , O text } , B = {B geo (mask), B sym (box), B text (box)} , R = {R geo2geo , R text2geo , R sym2geo , R text2sym } ,<label>(1)</label></formula><p>where O is the primitive set, the subscripts geo, sym, text stand for geometric primitive, symbol and text, respectively; B is the primitive position set (geometric and non-geometric primitives are represented by mask and bounding box); R is the primitive relation set among geometric primitive, symbol and text. G={O,B,R} constitutes a special scene graph. The parsing on image I is aimed to predict the constituents of G:</p><formula xml:id="formula_1">P (G | I, K) = P (B | I) ? P ({O geo , O sym } | I, B) ? P (R, O text | {O geo , O sym } , B, I, K) ,<label>(2)</label></formula><p>where K denotes the knowledge graph of geometry; P (B | I) ? P ({O geo , O sym } | I, B) refers to the steps of object detection and instance segmentation for obtaining the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison with SGG</head><p>PGDP is different from general SGG in two respects as shown in <ref type="figure">Figure 2</ref>. First, SGG obtains coarse box positions of targets from nature scene images through object detection, while PGDP is aimed to get the fine-grained masks of geometric primitives through instance segmentation, because they largely overlap with each other in box. Second, the SGG constructs the relationship graph in the form of subject-predicateobject triplets, which has no necessary dependency between the predicate and subject/object classes, while the betweenobject relationship in PGDP is mostly geometric, and specific relations (predicate) could be inferred according to primitive classes (subject/object) and prior knowledge, do not require an extra classification step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PGDP5K Dataset</head><p>Although several datasets <ref type="bibr" target="#b11">[Seo et al., 2015;</ref><ref type="bibr" target="#b10">Sachan et al., 2017;</ref><ref type="bibr" target="#b9">Lu et al., 2021;</ref><ref type="bibr" target="#b1">Chen et al., 2021]</ref> for solving geometry problems have been proposed, there is no dataset focusing on PGDP. To facilitate research in geometry problem solving, we build a new large-scale and fine-annotated plane geometry diagram dataset named PGDP5K 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Statistics</head><p>The PGDP5K dataset contains 5,000 diagram samples, consisting of 1,813 non-duplicated images from the Geometry3K dataset and other 3,187 images collected from three popular textbooks across grades 6-12 on mathematics curriculum websites 2 . We randomly split the dataset into three subsets: train set (3,500), validation set (500) and test set (1,000). In contrast to previous datasets, diagrams in PGDP5K have more complex layouts such as multiple classes of primitives and complicated primitive relations, which make our dataset more challenging. Specifically, we divide the geometric primitive, text and symbol into 3, 6 and 16 classes respectively, and Appendix A displays several instances of each class primitive. Some classes of primitives have great withinclass style variations. The Appendix B shows distributions of shape, symbol, text and relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Annotations</head><p>The annotations of PGDP5K dataset include three types: geometric primitive, non-geometric primitive and primitive relation. These annotations can generate geometry formal language automatically and uniquely. As to geometric primitives, we annotate their pixel positions and uniform pixel widths. For non-geometric primitives, bounding box, symbol class, text class and text content are labeled. As to primitive relations, we construct a relation graph of elementary relationships among primitives exhibited in <ref type="figure" target="#fig_1">Figure 3</ref>, where we only construct relations between point and line, point and circle for relations of geometric primitives, because other highlevel relations among geometric primitives can be derived from these two basic relations. A two-tuple with multiple entities is used to represent one relationship as demonstrated in <ref type="figure">Figure 2</ref>. Compared with the triplet of SGG, we take point, symbol and text as subjects, and serve other related primitives as objects, neglecting the relation class term. Finally, we define geometry proposition templates of basic relations listed in Appendix C. For more annotation details, please refer to the website of PGDP5K dataset. In addition, we re-annotate diagrams of the Geometry3K in our way and rename it IMP-Geometry3K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Model</head><p>The proposed PGDPNet depicted in <ref type="figure" target="#fig_2">Figure 4</ref> is presented hereon in detail, focusing on the geometric primitive segmentation and the primitive relation parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Backbone Module (BM)</head><p>A typical FPN architecture <ref type="bibr" target="#b7">[Lin et al., 2017]</ref> is used as the BM for visual feature extraction. The FPN layers P3-P7 are exploited for text and symbol detection, and the FPN layer P2 embedded with the location maps is shared by the geometric segmentation module (GSM) and the visual-location embedding module (VLEM). Visual features mixed with spatial information will facilitate model learning of follow-up tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Non-geometric Detection Module (NDM)</head><p>The non-geometric primitives, symbol and text, are detected in NDM. Given the diverse size scales of text and symbol in geometry diagrams, an anchor-free detection method FCOS <ref type="bibr" target="#b12">[Tian et al., 2020]</ref> is utilized to avoid the setting of prior anchors and improve the detection speed. This module consists of regression, center-ness and classification branches. The loss in training is L FCOS = L reg + L cns + L cls , where L reg , L cns and L cls are the losses of three branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Geometric Segmentation Module (GSM)</head><p>Due to complex layouts and elongated shapes, traditional methods and current instance segmentation approaches based on bounding boxes are all not suitable for geometric primitive extraction. We propose a new instance segmentation method, where two branches, semantic segmentation branch and segmentation embedding branch, together implement the multiclass instance segmentation of geometric primitives. The semantic segmentation branch performs binary segmentation "point_instances": ["B","C","X","D","O"], "line_instances":</p><p>["BX","BO","XO","CO","CX","CD","XD"], "circle_instances":</p><p>["O"], "diagram_logic_forms":</p><p>["PointLiesOnLine(X, Line(B, O))", "PointLiesOnLine(X, Line(C, D))", "PointLiesOnCircle(C, Circle(O, radius_0_0))", "PointLiesOnCircle(B, Circle(O, radius_0_0))", "PointLiesOnCircle(D, Circle(O, radius_0_0))", "Perpendicular(Line(B, X), Line(D, X))"], "point_positions":</p><p>{  with the weighted binary cross-entropy (BCE) loss:</p><formula xml:id="formula_2">L bs * = ?w * M map Mmap i=1 y * i log (p * i )+(1?y * i ) log (1?p * i ) ,<label>(3)</label></formula><p>where * denotes the primitive class, w is the weight ratio for balancing positive and negative class pixels, empirically as w p = 5, w l = 1, w c = 4, and M map is the pixel number of segmentation map. Then the segmentation loss of all classes is L bs = L bsp +L bsl +L bsc . The discriminative loss <ref type="bibr" target="#b3">[De Brabandere et al., 2017;</ref><ref type="bibr" target="#b9">Neven et al., 2018]</ref> is used in the segmentation embedding branch to better differentiate instances:</p><formula xml:id="formula_3">? ? ? ? ? ? ? ? ? ? ? L dist = 1 N lc (N lc ?1) N lc n1=1 N lc n 2 =1 n 2 =n 1 [2? d ? ? n1 ?? n2 ] 2 + , L var = 1 N lc N lc n=1 1 M n Mn i=1 [ ? n ?x i ?? v ] 2 + ,<label>(4)</label></formula><p>where N lc = N l + N c is the sum of instance number of line and circle, M is the pixel instance number, x is the pixel embedding, ? is the center of instance embedding. In default, the threshold ? d of center distance is set as 1.5 and threshold ? v of embedding radius is set as 0.5. The line instances and circle instances are learned simultaneously to obtain more distinctive features. In contrast, due to inherent instance separation in space, point instances are acquired just by connected component analysis according to the results of semantic segmentation, reducing difficulty of model learning. Eventually, the whole loss of GSM is L ins = L bs +L dist +L var .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">GNN Module (GM)</head><p>After obtaining the primitives, the relationship among primitives is reasoned by the GM. Before that, the VLEM unifies all primitive features and works as the initialization of GM. We treat primitives as nodes and primitive relations as edges to compose a primitive relation graph, represented as</p><formula xml:id="formula_4">G = {V = {V geo , V Non?geo }, E = {e ij |K}}, where V geo ,</formula><p>V Non?geo and E denote the node sets of geometric and nongeometric primitive, and the edge set. The cardinality of geometric node set is |V geo | = N p +N l +N c , where N p is the instance number of point. The original relation graph is a difficult hyper-graph with heterogeneous nodes (mask and box) and multi-edge relationship. For efficient solution, we transform the graph to a simple isomorphic graph and then construct the sparse graph like the one in <ref type="figure" target="#fig_1">Figure 3</ref>. Specifically, we only connect nodes that may have relations according to geometric prior knowledge K, and then categorize edges to determine final results. The initial features of nodes are represented by the fusion of visual-location embedding VL, parsing position feature PL and class semantic feature SE. For visual-location embedding, we transform mask features of variable shapes into vector features of fixed length by the mask average:</p><formula xml:id="formula_5">VL geo i = B T mask i mask i 1 ,<label>(5)</label></formula><p>where B is the visual-location embedding map. The mask average can also reduce the influence of error caused by inaccurate segmentation. In addition, we employ the RoIAlign method  to normalize multi-scale box features as vector features of the same length:</p><formula xml:id="formula_6">VL non?geo i = RoIAlign(B, box i ).<label>(6)</label></formula><p>Besides, parsing position in plane space is a significant feature of geometric primitives. We incorporate it into the GM to further facilitate relation building, formulated as: where pr * is the parsing representation of primitives, while point, line, circle and box denotes as a point, two endpoints, center with radius, and top-left point with bottom-right point, respectively, f * is a network module of two fully-connected layers with ReLU activation. In that way, the final node feature is formulated as</p><formula xml:id="formula_7">PL i = f * (pr * i ), pr * = ? ? ? ? ? [x, y], * = point, [x 1 , y 1 , x 2 , y 2 ], * = line, [x, y, r], * = circle, [x 1 , y 1 , x 2 , y 2 ], * = box,<label>(7)</label></formula><formula xml:id="formula_8">FN &amp; i = VL &amp; i +PL &amp; i +SE &amp; i , i=1? ? ?|V &amp; |, where &amp; is the primitive class geo or non?geo.</formula><p>The edge features are only generated for arrow indication relations, and the rest are aggregated through layer propagation of GNN. Because of elongated shape, the detection performance of arrows is less satisfactory. Instead of detecting boundary boxes of arrows, we use the union box of head box and corresponding text box to represent the relation:</p><formula xml:id="formula_9">FE ij = RoIAlign(B,box i ?box j ), (v i ,v j )=(head,text), 0, others.<label>(8)</label></formula><p>Although union box cannot enclose the whole arrow in some cases, it works well in experiments because the feature box has a larger receptive field than its own size with the FPN. The GM performs two sub-tasks. The first is predicting the edge class to judge whether existing relationship between nodes, with the loss function as:</p><formula xml:id="formula_10">L edge = ?1 |E| |E| i=1 y i log (p i )+(1?y i ) log (1?p i ) .<label>(9)</label></formula><p>The second is the fine-grained text classification with CE loss:</p><formula xml:id="formula_11">L node = ?1 N t Nt i=1 Ctext c=1 y ic log(p ic ),<label>(10)</label></formula><p>where N t is the instance number of text and C text is the text class number. Compared with visual features alone, the combined features including spatial structure information promote fine-grained classification, considering that some texts of different classes are visually identical. As to the architecture of GNN, the edge graph attention network (EGAT) <ref type="bibr" target="#b5">[Guo et al., 2021;</ref><ref type="bibr" target="#b13">Ye et al., 2020]</ref> is employed as the backbone of GM for its excellent reasoning ability among nodes and edges, and the whole loss of GM is L GNN = L edge +L node .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Training and Testing</head><p>During the training, the model PGDPNet is trained end-toend with the aggregated loss:</p><formula xml:id="formula_12">L all = L FCOS + ? ? L ins + ? ? L GNN .</formula><p>(11) Empirically we set the weight coefficients ? = ? = 4. During testing, according to binary masks obtained from the semantic segmentation branch of GSM, the segmentation embedding branch clusters embedding features to get instances of line and circle by the MeanShift cluster method. The parsing position of instance masks could be located accurately by simple fitting methods due to precise segmentation. The extracted geometric and non-geometric primitives go through the VLEM to generate initial features of GM, then the GM gets relations among primitives via node and edge classification. In the end, geometric propositions are produced according to geometry prior knowledge and language grammar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>We implemented our method using the PyTorch and FCOS framework <ref type="bibr" target="#b12">[Tian et al., 2020]</ref>. The backbone adopts Mo-bileNetV2 <ref type="bibr" target="#b10">[Sandler et al., 2018]</ref>. The NDM, GSM and VLEM all use 3 groups of 128-channel convolution layers with corresponding BatchNorm layers. The segmentation embedding dimensionality is 8 and the visual-location embedding dimensionality is 64. The layer number of GM is 5 and the feature dimensionalities of nodes and edges are all set to 64. To improve the diversity of samples, two enhancement strategies, random scale scaling and random flipping, are exploited during the training. We choose the Adam optimizer with an initial learning rate 5e ?4 , weight decay 1e ?4 , step decline schedule decaying with a rate of 0.2 at 20K, 30K and 35K iterations. We train our model in 40K iterations with batch size of 12 on 4 TITAN-Xp GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison Methods</head><p>To evaluate the effects of different modules, we compare three methods: InterGPS, PGDPNet without GNN, and PGDPNet. As described in <ref type="table">Table 1</ref>, these approaches respectively adopt different technologies on sub-tasks, where our PGDPNet is a concise and efficient framework that could be learned end-to-end from datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Protocols</head><p>We evaluate the methods at four levels: primitive detection, relation parsing, geometry formal language generation, and problem solving. Considering that some labels of bounding box are loose especially for single-word texts and arrowheads, we set threshold IOU=0.5 to evaluate the nongeometric primitive detection. As to geometric primitive extraction, there are two evaluation manners: one (manner 1) is parsing position evaluation that applies to the Hough transform route and the other (manner 2) is mask evaluation designed for the instance segmentation route. We set the distance threshold as 15 consistent with the InterGPS <ref type="bibr" target="#b9">[Lu et al., 2021]</ref> for the first manner and set IOU as 0.75 by de-  fault for the second manner. As to relation parsing, we divide one multivariate relation into multiple binary relations, and evaluate the precision, recall and F1 of binary relation terms. The geometry formal language is characterized by diversity and equivalence, for example, "Angle(P,R,Q)" is equivalent to "Angle(P,R,N)" in <ref type="figure" target="#fig_0">Figure 1(e)</ref>. For rationality and fairness of evaluation, we improve the existing evaluation method <ref type="bibr" target="#b9">[Lu et al., 2021]</ref> focusing on propositions with line and angle. Experimental results are evaluated on four indicators: Likely Same (F1?50%), Almost Same (F1?75%), Perfect Recall (recall=100%) and Totally Same (F1=100%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Primitive Detection</head><p>To evaluate the effects of NDM and GSM, we give the performance of primitive extraction on PGDP5K. <ref type="table" target="#tab_4">Table 2</ref> depicts the geometric primitive detection results using the evaluation manner 1, in which line instance covers all collinear line segments. We can see that our approach achieves a remarkable improvement over traditional methods such as Freeman <ref type="bibr" target="#b10">[Pratt, 2007]</ref> and GEOS <ref type="bibr" target="#b11">[Seo et al., 2015]</ref>, particularly on point and line. Appendix D lists the performance of all primitive classes adopting the evaluation manner 2. We find that most primitives could be well located and recognized except some minority classes, and joint classification in the GNN evidently improves the performance of text recognition compared with classification in the NDM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Primitive Relation Parsing</head><p>To better demonstrate advantages of graph feature generation, we conducted ablation studies in primitive relation parsing. <ref type="table" target="#tab_6">Table 3</ref> displays performances of different feature initialization methods, where baseline denotes the method of with only visual-location embedding, SE and PL refer to class semantic feature and parsing position feature formulated in Eq <ref type="formula" target="#formula_7">(7)</ref>, respectively. The performance gap is mainly reflected in the relationships of text2geo, sym2geo and text2head. However, most relations among primitives belong to geo2geo, so the overall performance of relationships shows little difference. We also compare the methods using another evaluation indicator complete accuracy, which refers to the proportion of complete correct sample. On the whole, fusion with parsing position and class semantic information makes model easier to learn representative features so as to promote relation reasoning, and gains 1.7% complete accuracy improvement.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Geometry Formal Language Generation</head><p>We also conducted experiments in the generation of geometry formal language for a more advanced evaluation. The outcomes of geometry formal language depend on the complete results of primitive extraction and relation reasoning to form comprehensible geometric propositions, and any error in preceding sub-tasks will influence the final generation results. <ref type="table" target="#tab_7">Table 4</ref> shows experimental results of all, geo2geo and non-geo2geo relationship. Our method without GNN sharply outperforms the InterGPS on geo2geo relationship, and the GNN module further improves non-geo2geo relationship reasoning in spite of a slight performance decline on geo2geo, because segmentation results are already accurate enough to determine the geo2geo relation by the distance rules. Finally, on two datasets, our PGDPNet respectively achieves 57.2% and 57.4% improvements of Totally Same of All compared with the InterGPS, and exceeds the one without GNN by 11.0% and 6.5%.   <ref type="figure">(Line(A, B)</ref>), 8)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>True:</head><p>Equals(MeasureOf <ref type="figure">(Angle(A, B, C)</ref>), MeasureOf(angle 8))</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Error:</head><p>Equals(MeasureOf(Angle(P, Q, S)), 124)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>True:</head><p>Equals(MeasureOf(Angle(P, Q, R)), 124) <ref type="figure">Figure 5</ref>: Failure examples of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">InterGPS System Problem Solving</head><p>To show the potential of our approach in geometry problem solving, we evaluate the performance using an existing problem solver, the one of InterGPS system, by replacing its geometry diagram parser with ours while remaining other modules unchanged. <ref type="table" target="#tab_9">Table 5</ref> reports the Inter-GPS performance feeding with different sources of propositions. When using the text parser of InterGPS with propositions generated from our PGDPNet, Inter-GPS achieves accuracy of 74.1%, nearly 16.6% higher than the diagram parser of InterGPS. The GM improves performance by 4.8% compared to the one without GNN. Slight gaps among generated diagram propositions, generated text propositions and annotations show that the symbolic geometry solver of InterGPS still has much room to improve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Limitations</head><p>We show some failure cases of our method in <ref type="figure">Figure 5</ref>. In <ref type="figure">Figure 5</ref>(a), the text "8" is mistaken as the radius of circle, while the problem text shows that it is an angle label. In <ref type="figure">Figure 5(b)</ref>, The text "124 ? " is incorrectly denoted as the degree of ?P QS but is actually the degree of ?P QR. This reveals that geometry diagram parsing should not rely on images alone but also make full use of textual semantics, and it even involves geometry logical reasoning. Future works will consider incorporating the text description to aid diagram parsing to further improve parsing performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We propose the first end-to-end deep learning model PGDP-Net for PGDP, which gives explicit primitive instance extraction, classification and between-primitive relationship reasoning. We also construct a new large-scale geometry diagram dataset PGDP5K with primitive level annotations. Experi-mental results demonstrate the superiority of proposed parsing method. This work promotes the benchmark of plane geometry diagram parsing, and provides a powerful tool to aid geometry problem solving and Q&amp;A.</p><p>Several typical examples of geometric primitive, symbol and text are displayed in <ref type="figure">Figure 6</ref>, <ref type="figure">Figure 8</ref> and <ref type="figure">Figure 9</ref>, respectively:</p><p>? The geometric primitive includes point, line and circle three classes. The point covers intersection point, tangent point, endpoint and independent point. The line consists of solid line, dash line and mixture of solid and dash. It is worth noting that we only label the longest line segment of all collinear lines. The circle includes complete circle and arc. ? Symbol has 6 super-classes and 16 sub-classes: perpendicular, angle, bar, parallel, arrow and head, where super-classes of angle, bar and parallel have multiple sub-classes, and head is subdivided into two sub-classes to distinguish the indication relations of different types of arrows. ? We divide text into 6 classes, including line, point, angle, length, degree and area. In many cases, there is no visual distinction among different text classes, e.g. angle, length and degree. So we need to combine spatial and structure information to carry out the fine-grained classification of text.</p><p>To sum up, the diagrams in PGDP5K have more complicated layouts and even primitives of the same class have great difference in style, which make our dataset more challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Dataset PGDP5K Distribution</head><p>Figure 7 displays class distributions of geometry shape, symbol, text and relation. They all obey the long-tailed distribution evidently. Note that text is seen as a special symbol recorded in the symbol distribution. In experiments, the minority class with few samples performs poorly in tasks of detection, classification and relation reasoning. Mitigating the effects of the long tail is a considerable direction for the future research of PGDP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Geometric Proposition Templates</head><p>We realize geometric propositions about basic primitive relations listed in <ref type="table" target="#tab_10">Table 6</ref>: geometry shape, geometric primitive with geometric primitive, text with geometric primitive, and symbol with geometric primitive:</p><p>? Geometry shapes are basic elements of high-level propositions. We give proposition templates of 5 types of fundamental geometry shapes: point, line, circle, angle and arc, where line, angle and arc have several equivalent expressions. ? We define 3 types of proposition templates about relations among geometric primitives: point lies on line, point lies on circle, and point is center of circle. These three primary relations could produce more other highlevel relations among geometric primitives. ? According to text class, we divide relations of text with geometric primitive into 6 types of propositions, where proposition templates of degree and length are not unique.</p><p>? Same as text with geometric primitive, propositions of symbol with geometric primitive are divided into 4 groups due to symbol class, and there are 2 proposition templates of bar. The design of proposition templates does not only relate to primitive relation parsing but also applies to logical reasoning of problem solving. Consequently, geometric proposition templates are the crystallization of geometry knowledge. <ref type="table" target="#tab_11">Table 7</ref> exhibits performance results of each primitive class with evaluation manner 2 on PGDP5K. Since that evaluation manner 2 only applies to the segmentation route, in this experiment, we compare with methods of PGDPNet with or without the GNN module, but exclude the InterGPS method. The method of PGDPNet without GNN identifies the fine-grained text classes along with symbol classes in the NDM, while the PGDPNet first detects a coarse-grained text class and then implements fine-grained text classification in the GM, combined with visual, semantic and structural information. End-to-end learning with all modules not only promotes the primitive relation parsing but also slightly boosts performance of primitive extraction according to experimental results. Nevertheless, some minority classes with fewer samples, e.g. "quad bar", "triple parallel" and "penta angle", perform poorly. Sym bar Equals(LengthOf(Line($, $)), LengthOf(Line($, $))) Equals(LengthOf(Arc($, $)), LengthOf(Arc($, $))) Sym parallel Parallel(Line($, $), Line($, $))  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Primitive Detection Performance</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Examples of plane geometry diagram.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Primitive relationship graph of plane geometry diagram. primitive positions and classes of symbol and geometric primitive; P (R, O text | {O geo , O sym } , B, I, K) stands for relation inference to acquire the primitive relationship and text class. At last, we generate the proposition set to form the readable description language.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Overview of our proposed PGDPNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Distributions of PGDP5K Dataset. (a)(b)(c)(d) respectively denote the class distribution of shape, symbol, text and relation. (Line($, $), Line($, $)) Sym angle Equals(MeasureOf(Angle($, $, $)), MeasureOf(Angle($, $, $)))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Detection performance of geometric primitives with the evaluation manner 1.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Ablation studies of primitive relation parsing. "A2B" denotes the relationship between class A and class B by default.</figDesc><table><row><cell></cell><cell></cell><cell>IMP-Geometry3K</cell><cell>PGDP5K</cell></row><row><cell></cell><cell>Likely Same</cell><cell>73.71 / 99.17 / 99.33</cell><cell>65.70 / 98.40 / 99.00</cell></row><row><cell>All</cell><cell>Almost Same Perfect Recall</cell><cell>50.08 / 95.51 / 98.50 45.26 / 81.03 / 92.18</cell><cell>44.40 / 93.10 / 96.60 40.00 / 79.70 / 86.20</cell></row><row><cell></cell><cell>Totally Same</cell><cell>34.28 / 80.53 / 91.51</cell><cell>27.30 / 78.20 / 84.70</cell></row><row><cell></cell><cell>Likely Same</cell><cell>69.88 / 99.67 / 99.50</cell><cell>63.90 / 99.10 / 99.00</cell></row><row><cell>Geo2Geo</cell><cell>Almost Same Perfect Recall</cell><cell>56.24 / 99.50 / 99.00 74.71 / 99.33 / 99.17</cell><cell>49.40 / 97.30 / 97.10 78.70 / 96.90 / 97.40</cell></row><row><cell></cell><cell>Totally Same</cell><cell>47.59 / 98.84 / 98.33</cell><cell>40.80 / 93.60 / 94.50</cell></row><row><cell></cell><cell>Likely Same</cell><cell>77.04 / 96.01 / 99.00</cell><cell>67.30 / 95.80 / 98.00</cell></row><row><cell>Non-geo</cell><cell>Almost Same</cell><cell>59.07 / 89.35 / 96.01</cell><cell>49.80 / 88.20 / 94.90</cell></row><row><cell>2Geo</cell><cell>Perfect Recall</cell><cell>50.92 / 81.20 / 92.85</cell><cell>45.70 / 81.30 / 87.00</cell></row><row><cell></cell><cell>Totally Same</cell><cell>48.59 / 80.87 / 92.85</cell><cell>40.50 / 80.60 / 86.40</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: Evaluation results of specification generation in geometry</cell></row><row><cell>formal language. "&amp;/&amp;/&amp;" denotes performances of three methods</cell></row><row><cell>compared: InterGPS, PGDPNet without GNN and PGDPNet.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Problem solving accuracy of InterGPS system on IMP-Geometry3K dataset.</figDesc><table><row><cell>Problem Text:</cell><cell>Error:</cell><cell>a)</cell></row><row><cell>Find angle 8.</cell><cell>Equals(LengthOf</cell><cell></cell></row><row><cell>Choices:</cell><cell></cell><cell></cell></row><row><cell>A. 20 B. 70 C. 90 D. 180</cell><cell></cell><cell></cell></row><row><cell>Answer: C</cell><cell></cell><cell></cell></row><row><cell>Problem Text:</cell><cell></cell><cell>(b)</cell></row><row><cell>QS is angle bisector of ?PQR?</cell><cell></cell><cell></cell></row><row><cell>what are the measures of</cell><cell></cell><cell></cell></row><row><cell>?PQS and ?SQR?</cell><cell></cell><cell></cell></row><row><cell cols="3">Answer: 62?(</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Geometric proposition templates of primitive relation.</figDesc><table><row><cell></cell><cell cols="3">PGDP-Net w/o GNN</cell><cell></cell><cell>PGDP-Net</cell><cell></cell></row><row><cell></cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell></row><row><cell>Geo-All</cell><cell>99.57</cell><cell>99.49</cell><cell>99.53</cell><cell>99.55</cell><cell>99.36</cell><cell>99.46</cell></row><row><cell>point</cell><cell>99.44</cell><cell>99.60</cell><cell>99.52</cell><cell>99.46</cell><cell>99.48</cell><cell>99.47</cell></row><row><cell>line</cell><cell>99.77</cell><cell>99.40</cell><cell>99.58</cell><cell>99.70</cell><cell>99.31</cell><cell>99.50</cell></row><row><cell>circle</cell><cell>99.31</cell><cell>98.63</cell><cell>98.97</cell><cell>99.31</cell><cell>97.95</cell><cell>98.63</cell></row><row><cell>Sym-All</cell><cell>99.51</cell><cell>99.70</cell><cell>99.61</cell><cell>99.57</cell><cell>99.73</cell><cell>99.65</cell></row><row><cell>text</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>99.70</cell><cell>99.96</cell><cell>99.83</cell></row><row><cell>perpendicular</cell><cell>99.59</cell><cell>99.79</cell><cell>99.69</cell><cell>99.79</cell><cell>99.59</cell><cell>99.69</cell></row><row><cell>head</cell><cell>97.93</cell><cell>99.30</cell><cell>98.61</cell><cell>99.30</cell><cell>98.60</cell><cell>98.95</cell></row><row><cell>head len</cell><cell>100.00</cell><cell>97.80</cell><cell>98.89</cell><cell>100.00</cell><cell>98.90</cell><cell>99.45</cell></row><row><cell>angle</cell><cell>99.26</cell><cell>98.17</cell><cell>98.71</cell><cell>98.90</cell><cell>98.53</cell><cell>98.72</cell></row><row><cell>double angle</cell><cell>96.94</cell><cell>98.96</cell><cell>97.94</cell><cell>95.96</cell><cell>98.96</cell><cell>97.44</cell></row><row><cell>triple angle</cell><cell>100.00</cell><cell>94.12</cell><cell>96.97</cell><cell>100.00</cell><cell>97.06</cell><cell>98.51</cell></row><row><cell>quad angle</cell><cell>80.00</cell><cell>100.00</cell><cell>88.89</cell><cell>100.00</cell><cell>75.00</cell><cell>85.71</cell></row><row><cell>penta angle</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>bar</cell><cell>98.68</cell><cell>99.56</cell><cell>99.12</cell><cell>98.90</cell><cell>99.78</cell><cell>99.34</cell></row><row><cell>double bar</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>99.43</cell><cell>99.72</cell></row><row><cell>triple bar</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell></row><row><cell>quad bar</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>parallel</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>95.86</cell><cell>100.00</cell><cell>97.89</cell></row><row><cell>double parallel</cell><cell>100.00</cell><cell>94.44</cell><cell>97.14</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell></row><row><cell>triple parallel</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>Text-All</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>99.55</cell><cell>99.81</cell><cell>99.68</cell></row><row><cell>text point</cell><cell>99.93</cell><cell>99.86</cell><cell>99.89</cell><cell>99.86</cell><cell>99.82</cell><cell>99.84</cell></row><row><cell>text line</cell><cell>99.09</cell><cell>99.09</cell><cell>99.09</cell><cell>98.21</cell><cell>100.00</cell><cell>99.10</cell></row><row><cell>text len</cell><cell>98.94</cell><cell>99.92</cell><cell>99.43</cell><cell>98.94</cell><cell>99.77</cell><cell>99.35</cell></row><row><cell>text angle</cell><cell>99.71</cell><cell>100.00</cell><cell>99.86</cell><cell>99.43</cell><cell>99.71</cell><cell>99.57</cell></row><row><cell>text degree</cell><cell>99.58</cell><cell>99.86</cell><cell>99.72</cell><cell>99.72</cell><cell>99.86</cell><cell>99.79</cell></row><row><cell>text area</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Detailed performance of primitive detection with the evaluation manner 2.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.nlpr.ia.ac.cn/databases/CASIA-PGDP5K 2 https://www.mheducation.com/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Yunfei Guo, Jinwen Wu, and Xiaolong Yun for helpful discussions. This work has been supported by the National Key Research and Development Program under Grant No. 2020AAA0109702, the National Natural Science Foundation of China (NSFC) grants 61733007, 61721004.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A Primitive Examples</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">MathQA: Towards interpretable math word problem solving with operation-based formalisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL HLT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">GeoQA: A geometric question answering benchmark towards multimodal numerical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of ACL</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automated generation of readable proofs with geometric invariants: II. theorem proving with full-angles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Chou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="349" to="370" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic instance segmentation with a discriminative loss function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>[de Brabandere</surname></persName>
		</author>
		<idno>abs/1708.0</idno>
	</analytic>
	<monogr>
		<title level="m">CoRR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding plane geometry problems by integrating relations extracted from text and diagram</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PSIVT 2017: Image and Video Technology</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10749</biblScope>
			<biblScope unit="page" from="366" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Kaiming He, Georgia Gkioxari, Piotr Doll?r, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="386" to="397" />
		</imprint>
	</monogr>
	<note>Learning to understand traffic signs</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to parse wireframes in images of man-made environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection</title>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Masood Mortazavi, and Bir Bhanu. Fully convolutional scene graph generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Davy Neven, Bert De Brabandere, Stamatios Georgoulis, Marc Proesmans, and Luc Van Gool. Towards end-to-end lane detection: An instance segmentation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Intelligent Vehicles Symposium</title>
		<meeting>IEEE Intelligent Vehicles Symposium</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="286" to="291" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">From textbooks to knowledge: A case study in harvesting axiomatic knowledge from textbooks to solve geometry problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Pratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Pratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sachan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Menglong Zhu, Andrey Zhmoginov, and Liang Chieh Chen. MobileNetV2: Inverted residuals and linear bottlenecks</title>
		<meeting><address><addrLine>Andrew Howard</addrLine></address></meeting>
		<imprint>
			<publisher>Mark Sandler</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="627" to="665" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Solving geometry problems: Combining text and diagram interpretation</title>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<editor>Hannaneh Hajishirzi, Ali Farhadi, Oren Etzioni, and Clint Malcolm</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>AAAI</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">FCOS: A simple and strong anchor-free object detector</title>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<editor>Xu et al., 2017] Danfei Xu, Yuke Zhu, Christopher B. Choy, and Li Fei-Fei</editor>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">8828</biblScope>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Contextual stroke classification in online handwritten documents with edge graph attention networks</title>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>ICCV</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
