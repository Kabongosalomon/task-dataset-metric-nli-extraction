<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Zen-NAS: A Zero-Shot NAS for High-Performance Image Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-08-24">August 24, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Lin</surname></persName>
							<email>ming.l@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pichao</forename><surname>Wang</surname></persName>
							<email>pichao.wang@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhong</forename><surname>Sun</surname></persName>
							<email>zhenhong.szh@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hesen</forename><surname>Chen</surname></persName>
							<email>hesen.chs@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuyu</forename><surname>Sun</surname></persName>
							<email>xiuyu.sxy@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
							<email>qi.qian@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
							<email>jinrong.jr@alibaba-inc.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Alibaba Group Bellevue</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Group Bellevue</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Alibaba Group Bellevue</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Zen-NAS: A Zero-Shot NAS for High-Performance Image Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-08-24">August 24, 2021</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Accuracy predictor is a key component in Neural Architecture Search (NAS) for ranking architectures. Building a high-quality accuracy predictor usually costs enormous computation. To address this issue, instead of using an accuracy predictor, we propose a novel zero-shot index dubbed Zen-Score to rank the architectures. The Zen-Score represents the network expressivity and positively correlates with the model accuracy. The calculation of Zen-Score only takes a few forward inferences through a randomly initialized network, without training network parameters. Built upon the Zen-Score, we further propose a new NAS algorithm, termed as Zen-NAS, by maximizing the Zen-Score of the target network under given inference budgets. Within less than half GPU day, Zen-NAS is able to directly search high performance architectures in a data-free style. Comparing with previous NAS methods, the proposed Zen-NAS is magnitude times faster on multiple server-side and mobile-side GPU platforms with state-of-the-art accuracy on ImageNet. Searching and training code as well as pre-trained models are available from https://github.com/ idstcv/ZenNAS.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The design of high-performance deep neural networks is a challenging task. Neural Architecture Search (NAS) methods facilitate this progress. There are mainly two key components, architecture generator and accuracy predictor, in existing NAS algorithms. The generator proposes potential high-performance networks and the predictor predicts their accuracies. Popular generators include uniform sampling <ref type="bibr" target="#b12">[13]</ref>, evolutionary algorithm <ref type="bibr" target="#b40">[41]</ref> and reinforcement learning <ref type="bibr" target="#b29">[30]</ref>. The accuracy predictors include brute-force methods <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b40">41]</ref>, predictor-based methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b28">29]</ref> and one-shot methods <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>A major challenge of building a high-quality accuracy predictor is the enormous computational cost. Both brute-forced methods and predictor-based methods require to train considerable number of networks. The one-shot methods reduce the training cost via parameter sharing. Albeit being more efficient than brute-forced methods, the one-shot methods still need to train a huge supernet which is still computationally expensive. Recent studies also find that nearly all supernet-based methods suffer from model interfering <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b62">63]</ref> which degrades the quality of accuracy predictor <ref type="bibr" target="#b45">[46]</ref>. In addition, since the supernet must be much larger than the target network, it is difficult to search large target networks under limited resources. These issues make the one-shot methods struggling in designing high-performance networks.</p><p>To solve these problems, instead of using an expensive accuracy predictor, we propose an almost zero-cost proxy, dubbed Zen-Score, for efficient NAS. The Zen-Score measures the expressivity <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b30">31]</ref> of a deep neural network and positively correlates with the model accuracy. The computation of Zen-Score only takes a few forward inferences on randomly initialized network using random Gaussian inputs, making it extremely fast, lightweight and data-free. Moreover, Zen-Score deals with the scale-sensitive problem caused by Batch Normalization (BN) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35]</ref>, making it widely applicable to real-world problems. Based on Zen-Score, we design a novel Zen-NAS algorithm. It maximizes the Zen-Score of the target network within inference budgets. Zen-NAS is a Zero-Shot method since it does not optimize network parameters during search <ref type="bibr" target="#b0">1</ref> . We apply Zen-NAS to search optimal networks under various inference budgets, including inference latency, FLOPs (Floating Point Operations) and model size, and achieve the state-of-theart (SOTA) performance on CIFAR-10/CIFAR-100/ImageNet, outperforming previous human-designed and NAS-designed models by a large margin. Zen-NAS is the first zero-shot method that achieves SOTA results on large-scale full-resolution ImageNet-1k dataset <ref type="bibr" target="#b11">[12]</ref> by the time of writing this work <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>Our approach is inspired by recent advances in deep learning studies <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b59">60]</ref> which show that deep models are superior than shallow ones since deep models are more expressive under the same number of neurons. According to the bias-variance trade-off in statistical learning theory <ref type="bibr" target="#b18">[19]</ref>, increasing the expressivity of a deep network implies smaller bias error. When the size n of training dataset is large enough, the variance error will diminish as O(1/ ? n) ? 0. This means that the generalization error is dominated by the bias error which could be reduced by more expressive networks. These theoretical results are well-aligned with large-scale deep learning practices <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>We summarize our main contributions as follows:</p><p>? We propose a novel zero-shot proxy Zen-Score for NAS. The proposed Zen-Score is computationally efficient and is proved to be scale-insensitive in the present of BN. A novel NAS algorithm termed Zen-NAS is proposed to search for networks with maximal Zen-Score in the design space. ? Within half GPU day, the ZenNets designed by Zen-NAS achieve up to 83.6% top-1 accuracy on Im-ageNet that is as accurate as EfficientNet-B5 with inference speed magnitude times faster on multiple hardware platforms. To our best knowledge, Zen-NAS is the first zero-shot method that outperforms training-based methods on ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>We briefly review the related works. For comprehensive review of NAS, the monograph <ref type="bibr" target="#b42">[43]</ref> is referred to. In the early days of NAS, brute-force methods are adopted to search architectures by directly training a network to obtain its accuracy. For example, the AmoebaNet <ref type="bibr" target="#b40">[41]</ref> conducts structure search on CIFAR-10 using Evolutionary Algorithm (EA) <ref type="bibr" target="#b19">[20]</ref> and then transfers the structure to ImageNet. It takes about 3150 GPU days of searching and achieves 74.5% top-1 accuracy on ImageNet. Inspired by the success of AmoebaNet, many EA-based NAS algorithms are proposed to improve the searching efficiency, such as EcoNAS <ref type="bibr" target="#b68">[69]</ref>, CARS <ref type="bibr" target="#b61">[62]</ref>, GeNet <ref type="bibr" target="#b56">[57]</ref> and PNAS <ref type="bibr" target="#b24">[25]</ref>. These methods search on down-sampled images or reduce the number of queries. Reinforced Learning is another popular generator (sampler) in NAS, including NASNet <ref type="bibr" target="#b69">[70]</ref>, Mnasnet <ref type="bibr" target="#b48">[49]</ref> and MetaQNN <ref type="bibr" target="#b2">[3]</ref>.</p><p>Both EA and RL based methods require lots of network training. To address this problem, the predictorbased methods encode architectures into high dimensional vectors. A number of architectures are trained to obtain their accuracies <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b28">29]</ref> and then are used as training data for learning accuracy predictor. The oneshot methods further reduce the training cost by training a big supernet. This framework is widely applied in many efficient NAS methods, including DARTS <ref type="bibr" target="#b25">[26]</ref>, SNAS <ref type="bibr" target="#b58">[59]</ref>, PC-DARTS <ref type="bibr" target="#b60">[61]</ref>, ProxylessNAS <ref type="bibr" target="#b5">[6]</ref>, GDAS <ref type="bibr" target="#b65">[66]</ref>, FBNetV2 <ref type="bibr" target="#b53">[54]</ref>, DNANet <ref type="bibr" target="#b20">[21]</ref>, Single-Path One-Shot NAS <ref type="bibr" target="#b12">[13]</ref>.</p><p>Although the above efforts have greatly reduced the searching cost, their top-1 accuracies on ImageNet are below 80.0%. The authors of OFANet <ref type="bibr" target="#b4">[5]</ref> noted that weight-sharing suffers from model interfering. They propose a progressive-shrinking strategy to address this issue. The resultant OFANet achieves 80.1% accuracy after searching for 51.6 GPU days. EfficientNet <ref type="bibr" target="#b49">[50]</ref> is another high precision network designed by NAS. It takes about 3800 GPU days to search EfficientNet-B7 whose accuracy is 84.4%. In comparison, Zen-NAS achieves 83.6% accuracy while using magnitude times fewer resources.</p><p>A few on-going works are actively exploring zero-shot proxies for efficient NAS. However, these efforts have not delivered the SOTA results. In a recent empirical study, <ref type="bibr" target="#b0">[1]</ref> evaluates the performance of six zero-shot pruning proxies on NAS benchmark datasets. The synflow <ref type="bibr" target="#b50">[51]</ref> achieves best results in their experiments. We compare synflow with Zen-Score under fair settings and show that Zen-Score achieves +1.1% better accuracy on CIFAR-10 and +8.2% better accuracy on CIFAR-100. The concurrent work TE-NAS <ref type="bibr" target="#b6">[7]</ref> uses a combination of NTK-score and network expressivity as NAS proxy. Specifically, the TE-NAS estimates the expressivity by directly counting the number of active regions R N on randomly sampled images. In comparison, Zen-Score not only considers the distribution of linear regions but also considers the Gaussian complexity of linear classifier in each linear region, giving a more accurate estimation of network expressivity. The computation of Zen-Score is 20 to 28 times faster than TE-NAS score. In terms of performance, TE-NAS achieves 74.1% top-1 accuracy on ImageNet, lagging behind SOTA baselines. Zen-NAS achieves +9.5% better accuracy within similar searching cost. Another concurrent work NASWOT <ref type="bibr" target="#b32">[33]</ref> computes the architecture score according to the kernel matrix of binary activation patterns between mini-batch samples. It achieves similar top-1 accuracies on CIFAR-10/CIFAR-100 as TE-NAS.</p><p>It is important to distinguish Zen-NAS from unsupervised NAS (UnNAS) <ref type="bibr" target="#b23">[24]</ref>. In UnNAS, the network is trained to predict the pre-text tasks therefore it still requires parameter training. In Zen-NAS, no parameter training is required during the search.</p><p>In this work, we mostly focus on the vanilla network space described in the next section. Several previous works design networks in a more general irregular design space, such as DARTS <ref type="bibr" target="#b25">[26]</ref> and RandWire <ref type="bibr" target="#b57">[58]</ref>. Zen-NAS cannot be applied to these irregular design spaces since Zen-Score is not mathematically welldefined in irregular design spaces. In practice, the vanilla network space is a large enough space which covers most SOTA networks, including but not limited to ResNet, MobileNet and EfficientNet. Particularly, Zen-NAS outperforms DARTS-based methods by a significant margin on ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Expressivity of Vanilla Network</head><p>In this section, we discuss how to measure the expressivity of vanilla convolutional neural network (VCNN) family, an ideal prototype for theoretical studies. We show that the expressivity of a network can be efficiently measured by its expected Gaussian complexity, or ?-score for short. In the next section, we further show that for very deep networks, directly computing ?-score incurs numerical overflow. This overflow can be addressed by adding BN layers and then re-scaling the ?-score by a constant. This new score is named as Zen-Score in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notations</head><p>An L-layer neural network is formulated as a function f : R m0 ? R m L where m 0 is the input dimension and m L is the output dimension. x 0 ? R m0 denotes the input image. Correspondingly, the output feature map of the t-th layer is denoted by x t . The t-th layer has m t?1 input channels and m t output channels. The convolutional kernel is ? t ? R mt?mt?1?k?k . The image resolution is H ? W . The mini-batch size is B. The Gaussian distribution of mean ? and variance ? 2 is denoted by N (?, ?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Vanilla Convolutional Neural Network</head><p>The vanilla convolutional neural network (VCNN) is a widely used prototype in theoretical studies <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b13">14]</ref>. The main body of a vanilla network is stacked by multiple convolutional layers. Each layer consists of one convolutional operator followed by RELU activation. All other components are removed from the backbone, including residual link and Batch Normalization. After the main body, global average pool layer (GAP) reduces the feature map resolution to 1x1, followed by a fully-connected layer. At the end a soft-max operation converts the network output to label prediction. Given the input x and network parameters ?, f (x|?) refers to the output of the main body of the network, that is the feature map before the GAP layer (pre-GAP layer). We measure the network expressivity with respect to pre-GAP because it contains most of the information we need.</p><p>Modern networks use auxiliary structures such as residual link , Batch Normalization and self-attention block <ref type="bibr" target="#b15">[16]</ref>. These structures will not significantly affect the representation power of networks. For example, BN layer can be merged into convolutional kernel via kernel fusion. Self-attention linearly combines existing feature maps hence spans the same subspace. Therefore, these structures are temporarily removed when measuring network expressivity and then added back in training and testing stages. For non-RELU activation functions, they are replaced by RELU in a similar way. These simple modifications make our method applicable to a majority of non-VCNN models widely used in practice. In fact, nearly all single-branch feed-forward networks can be converted to vanilla network by the aforementioned modifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">?-Score as Proxy of Expressivity</head><p>Given a VCNN f (x|?), we propose a novel numerical index ?-score as a proxy of its expressivity. The definition of ?-score is inspired by recent theoretical studies on deep network expressivity <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b59">60]</ref>. A key observation in these studies is that a vanilla network can be decomposed into piece-wise linear functions conditioned on activation patterns <ref type="bibr" target="#b33">[34]</ref>: <ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b30">31]</ref>). Denote the activation pattern of the t-th layer as A t (x). Then for any vanilla network f (?),</p><formula xml:id="formula_0">Lemma 1 ([</formula><formula xml:id="formula_1">f (x|?) = Si?S I x (S i )W Si x (1)</formula><p>where S i is a convex polytope depending on {A 1 (x), A 2 (x), ? ? ? , A L (x)}; S is a finite set of convex polytopes in R m0 ;</p><formula xml:id="formula_2">I x (S i ) = 1 if x ? S i otherwise zero; W Si is a coefficient matrix of size R m L ?m0 .</formula><p>According to Lemma 1, any vanilla network is an ensemble of piece-wise linear functions segmented by convex polytopes S = {S 1 , S 2 , ? ? ? , S |S| } where |S| is the number of linear-regions (see <ref type="figure" target="#fig_0">Figure 2</ref> in <ref type="bibr" target="#b13">[14]</ref>. The number of linear regions |S| has been used as expressivity proxy in several theoretical studies <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b59">60]</ref>. However, directly using |S| incurs two limitations: a) Counting |S| for large network is computationally infeasible; b) The representation power of each W Si is not considered in the proxy. The first limitation is due to fact that the number of linear regions grow exponentially for large networks <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b59">60]</ref>. To understand the second limitation, we recall the Gaussian complexity <ref type="bibr" target="#b17">[18]</ref> of linear classifiers:  In other words, Lemma 2 says that the expressivity of linear function class measured by Gaussian complexity is controlled by the Frobenius norm of its parameter matrix W . Inspired by Lemma 1 and Lemma 2, we define the following index for measuring network expressivity :</p><p>Definition 1 (?-score for VCNN). The expected Gaussian complexity for a vanilla network f (?) is defined by</p><formula xml:id="formula_3">?(f ) = log E x,? Si?S I x (S i ) W Si F (2) = log E x,? ? x f (x|?) F .<label>(3)</label></formula><p>In Definition 1, we measure the network expressivity by its expected Gaussian complexity, or ?-score for short. Since any VCNN is ensemble of linear functions, it is nature to measure its expressivity by averaging the Gaussian complexity of linear function in each linear region. To this end, we randomly sample x and ? from some prior distributions and then average W Si F . This is equivalent to compute the expected gradient norm of f with respect to input x. In our implementation, x and ? are sampled from standard Gaussian distribution which works well in practice. It is important to note that in ?-score, only the gradient of x rather than ? is involved. This is different to zero-cost proxies in <ref type="bibr" target="#b0">[1]</ref> which compute gradient of ? in their formulations. These proxies measure the trainability <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b6">7]</ref> instead of the expressivity of networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Zen-Score and Zen-NAS</head><p>In this section, we show that directly computing ?-score for very deep networks incurs numerical overflow due to the gradient explosion without BN layers. The gradient explosion could be resolved by adding BN layers back but the ?-score will be adaptively re-scaled, making it difficult to compare ?-score between different networks. The same phenomenon has been known as 'scale-sensitive' problem in deep learning complexity analysis <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35]</ref>.</p><p>To address this open question, we propose to re-scale the ?-score one more time by the product of BN layers' variance statistics. This new score is denoted as Zen-Score in order to distinguish from the original ?-score. The Zen-Score is proven to be scale-insensitive. Finally, we present Zen-NAS algorithm built on Zen-Score and demonstrate its effectiveness in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overflow and BN-rescaling</head><p>When computing ?-score for very deep vanilla networks, numerical overflow incurs almost surely. This is because BN layers are removed from the network and the magnitude of network output grows exponentially along depth. To see this, we construct a set of vanilla networks P w/oBN without BN layers. All networks have the same widths but different depths. <ref type="figure" target="#fig_0">Figure 2</ref>(a) plots the ?-scores for P w/oBN . After 30 layers, ?score overflows. To address the overflow, we add BN layers back and compute the ?-scores in <ref type="figure" target="#fig_0">Figure 2</ref>(b). This time the overflow dismisses but the ?-scores are scaled-down by a large factor. This phenomenon is termed as BN-rescaling.</p><p>To demonstrate that BN-rescaling disturbs architecture ranking, we construct another two set of networks, Q w/oBN and Q BN , with and without BN respectively. All networks have two layers and have the same number of input and final output channels. The number of bottleneck channels, that is the width of the hidden layer, varies from 2 to 60. The corresponding ?-score curves are plotted in <ref type="figure" target="#fig_0">Figure 2</ref>(d) and (e) respectively. When BN layer is presented, the ?-score becomes nearly constant for all networks. This will confuse the architecture generator and drive the search to a wrong direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">From</head><p>?-Score to Zen-Score Algorithm 1 Zen-Score Require: Network F(?) with pre-GAP feature map f (?); ? = 0.01. Ensure: Zen-Score Zen(F).</p><p>1: Remove all residual links in F. <ref type="bibr">2:</ref> Initialize all neurons in F by N (0, 1).</p><formula xml:id="formula_4">3: Sample x, ? N (0, 1). 4: Compute ? E x, f (x) ? f (x + ? ) F .</formula><p>5: For the i-th BN layer with m output channels, compute? i = j ? 2 i,j /m where ? i,j is the mini-batch standard deviation statistic of the j-th channel in BN. <ref type="bibr" target="#b5">6</ref>: Zen(F ) log(?) + i log(? i ).</p><p>In the above subsection, we showed that BN layer is necessary to prevent numerical overflow in computing ?-score but comes with the side-effect of re-scaling. In this subsection, we design a new Zen-Score which is able to calibrate re-scaling when BN layer is present. The computation of Zen-Score is described in Algorithm 1. <ref type="figure" target="#fig_3">Figure 3</ref> visualizes the computational graph of Algorithm 1.</p><p>In Algorithm 1, all residual links are removed from the network as pre-processing. Then we randomly sample input vectors and perturb them with Gaussian noise. The perturbation of the pre-GAP feature map is denoted as ? in Line 4. This step replaces the gradient of x with finite differential ? to avoid backwardpropagation. To get Zen-Score, the scaling factor? 2 i is averaged from the variance of each channel in BN layer. Finally, the Zen-Score is computed by the log-sum of ? and? i . The following theorem guarantees that the Zen-Score of network with BN layers approximates the ?-score of the same network without BN layers. The proof is postponed to Supplementary H.  </p><formula xml:id="formula_5">? i . ? x0 {f (x 0 )} is the differential of pre-GAP feature map f (x 0 ) with respect to x 0 . Theorem 1. Letf (x 0 ) =x L be an L-layer vanilla network without BN layers. f (x 0 ) = x L is its sister network with BN layers. For some constants 0 &lt; ? &lt; 1, K 0 ? O[ log(1/?)], when BHW ? O[(LK 0 ) 2 ] is large enough, with probability at least 1 ? ?, we have (1 ? L ) 2 ? ( L t=1? 2 t )E ? { x L 2 } E ? x L 2 ? (1 + L ) 2 (4) where O(2K 0 / ? BHW ).</formula><p>Informally speaking, Theorem 1 says that to compute f (?) , we only need to compute f (?) then rescale with L t=1? t . The approximation error is bounded by L . By taking gradient of x on bothf (?) and f (?), we obtain the desired relationship between Zen-Score and ?-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Zen-NAS For Maximizing Expressivity</head><p>We design Zen-NAS algorithm to maximize the Zen-Score of the target network. The step-by-step description of Zen-NAS is given in Algorithm 2. The Zen-NAS uses Evolutionary Algorithm (EA) as architecture generator. It is possible to choose other generators such as Reinforced Learning or even greedy selection. The choice of EA is due to its simplicity.</p><p>In Algorithm 2, we randomly generate N structures. At each iteration step t, we randomly select a structure in the population P and mutate it. The mutation algorithm is presented in Algorithm 3. The width and depth of the selected layer is mutated in a given range. We choose [0.5, 2.0] as the mutation range in this work, that is, within half or double of the current value. The new structureF t is appended to the population if its inference cost does not exceed the budget. The maximal depth of networks is controlled by L, which prevents the algorithm generate over-deep structures. Finally, we maintain the population size by removing networks with the smallest Zen-Scores. After T iterations, the network with the largest Zen-Score is returned as the output of Zen-NAS. We name the found architectures as ZenNets.</p><formula xml:id="formula_6">Algorithm 2 Zen-NAS Require: Search space S, inference budget B, maximal depth L, total number of iterations T , evolutionary population size N , initial structure F 0 . Ensure: NAS-designed ZenNet F * . 1: Initialize population P = {F 0 }. 2: for t = 1, 2, ? ? ? , T do 3:</formula><p>Randomly select F t ? P. <ref type="bibr" target="#b3">4</ref>:</p><formula xml:id="formula_7">MutateF t = MUTATE(F t , S) 5:</formula><p>ifF t exceeds inference budget or has more than L layers then 6:</p><p>Do nothing. <ref type="bibr" target="#b6">7</ref>:</p><formula xml:id="formula_8">else 8:</formula><p>Get Zen-Score z = Zen(F t ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>AppendF t to P. Remove network of the smallest Zen-Score if the size of P exceeds B. 12: end for 13: Return F * , the network of the highest Zen-Score in P.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 MUTATE</head><p>Require: Structure F t , search space S. Ensure: Randomly mutated structureF t .</p><p>1: Uniformly select a block h in F t . <ref type="bibr">2:</ref> Uniformly alternate the block type, kernel size, width and depth of h within some range. <ref type="bibr">3:</ref> Return the mutated structureF t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, experiments on CIFAR-10/CIFAR-100 <ref type="bibr" target="#b19">[20]</ref> and ImageNet-1k <ref type="bibr" target="#b11">[12]</ref> are conducted to validate the superiority of Zen-NAS. We first compare Zen-Score to several zero-shot proxies on CIFAR-10 and CIFAR-100, using the same search space, search policy and training settings. Then we compare Zen-NAS to the state-of-the-art methods on ImageNet. Zen-NAS on CIFAR-10/CIFAR-100 can be found in Supplementary D. Finally, we compare the searching cost of Zen-NAS with SOTA methods in subsection 5.3. Due to space limitation, the inference speed on NVIDIA T4 and Google Pixel2 is reported in Supplementary C. The Zen-Scores of ResNets and accuracies under fair training settings are reported in Supplementary E. We enclose one big performance table of networks on ImageNet in Supplementary I.</p><p>To align with previous works, we consider the following two search spaces:</p><p>? Search Space I Following <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b39">40]</ref>, this search space consists of residual blocks and bottleneck blocks defined in ResNet. ? Search Space II Following <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b37">38]</ref>, this search space consists of MobileNet blocks. The depth-wise expansion ratio is searched in set {1, 2, 4, 6}. Please see Supplementary A for datasets description and detail experiment settings.</p><p>In each trial, the initial structure is a randomly selected small network which is guaranteed to satisfy the inference budget. The kernel size is searched in set {3, 5, 7}. Following conventional designs, the number of stages is three for CIFAR-10/CIFAR-100 and five for ImageNet. The evolutionary population size is 256, number of evolutionary iterations T = 96, 000. The resolution is 32x32 for CIFAR-10/CIFAR-100 and proxy CIFAR-10 CIFAR-100  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Zen-Score v.s. Other Zero-Shot Proxies</head><p>Following <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref>, we compare Zen-Score to five zero-shot proxies: FLOPs, gradient-norm (grad) of network parameters, synflow <ref type="bibr" target="#b50">[51]</ref>, TE-NAS score (TE-Score) <ref type="bibr" target="#b6">[7]</ref> and NASWOT <ref type="bibr" target="#b32">[33]</ref>. For each proxy, we replace Zen-Score by that proxy in Algorithm 2 and then run Algorithm 2 for T = 96, 000 iterations to ensure convergence. Since synflow is the smaller the better, we use its negative value in Algorithm 2. Following convention, we search for best network on CIFAR-10/CIFAR-100 within model size N ? 1 M. The convergence curves are plotted in Supplementary C. In these figures, all six scores improves monotonically along iterations.</p><p>After the above NAS step, we train the network of the best score for each proxy under the same training setting. To provide a random baseline, we randomly generate networks. The width of the layer varies in  range <ref type="bibr" target="#b3">[4,</ref><ref type="bibr">512]</ref>, and the depth of each stage varies in range <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10]</ref>. If the network size is larger than 1 M, we shrink its width by factor 0.75 each time until it satisfies the budget. 32 random networks are generated and trained in total. The top-1 accuracy is reported in <ref type="table" target="#tab_0">Table 1</ref>. Zen-Score significantly outperforms the other five proxies on both CIFAR-10 and CIFAR-100. TE-Score and NASWOT are the runner-up proxies with similar performance, followed by synflow. It is not surprise to see that naive proxies, such as FLOPs and gradient-norm, perform poorly, even worse than random search.</p><p>To compare the computational efficiency of Zen-Score and TE-score, we compute two scores for ResNet-18 and ResNet-50 at 224x224 resolution. The expected time cost is averaged over 100 trials. We find that averaging Zen/TE-Score over N = 16 random images is sufficient to reduce the statistical error below 5%. The results are reported in <ref type="table" target="#tab_1">Table 2</ref>. The computation of Zen-Score is 20 ? 28 times faster than TE-Score.</p><p>We tried our best to benchmark NASWOT for ResNet-18/50 using the official code. However, the official code always outputs Inf for ResNet-18/50 at resolution 224. Despite of the Inf issue, Zen-Score is 3.3x times faster than NASWOT on ResNet-18 and 1.6x times faster on ResNet-50.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NAS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Zen-NAS on ImageNet</head><p>We use Zen-NAS to search efficient network (ZenNet) on ImageNet. We consider the following popular networks as baselines: (a) manually-designed networks, including ResNet <ref type="bibr" target="#b14">[15]</ref>, DenseNet <ref type="bibr" target="#b16">[17]</ref>, ResNeSt <ref type="bibr" target="#b63">[64]</ref>, MobileNet-V2 <ref type="bibr" target="#b44">[45]</ref> (b) NAS-designed networks for fast inference on GPU, including OFANet-9ms/11ms <ref type="bibr" target="#b4">[5]</ref>, DFNet <ref type="bibr" target="#b21">[22]</ref>, RegNet <ref type="bibr" target="#b39">[40]</ref>; (c) NAS-designed networks optimized for FLOPs, including OFANet-389M/482M/595M <ref type="bibr" target="#b4">[5]</ref>, DNANet <ref type="bibr" target="#b20">[21]</ref>, EfficientNet <ref type="bibr" target="#b49">[50]</ref>, Mnasnet <ref type="bibr" target="#b48">[49]</ref>. Among these networks, EfficientNet is a popular baseline in NAS-related works. EfficientNet-B0/B1 are suitable for mobile device for their small FLOPs and model size. EfficientNet-B3?B7 are large models that are best to be deployed on a high-end GPU. Although EfficientNet is optimized for FLOPs, its inference speed on GPU is within top-tier ones. Many previous works compare to EfficientNet by inference speed on GPU <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>Searching Low Latency Networks Following previous works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b39">40]</ref>, we use Zen-NAS to optimize network inference speed on NVIDIA V100 GPU. We use Search Space I in this experiment. The inference speed is tested at batch size 64, half precision (float16). We search for networks of inference latency within 0.1/0.2/0.3/0.5/0.8/1.2 milliseconds (ms) per image. For testing inference latency, we set batch-size=64 and do mini-batch inference 30 times. The averaged inference latency is recorded. The top-1 accuracy on ImageNet v.s. inference latency is plotted in <ref type="figure">Figure 1</ref>. Clearly, ZenNets outperform baseline models in both accuracy and inference speed by a large margin. The largest model ZenNet-1.2ms achieves 83.6% top-1 accuracy which is between EfficientNet-B5 and B6. It is about 4.9x faster than EfficientNet at the same accuracy level.</p><p>Searching Lightweight Networks Following previous works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b49">50]</ref>, we use Zen-NAS to search lightweight networks with small FLOPs. We use Search Space II in this experiment. We search for networks of computational cost within 400/600/900 M FLOPs. Similar to OFANet and EfficientNet, we add SE-blocks after convolutional layers. The top-1 accuracy v.s. FLOPs is plotted in <ref type="figure" target="#fig_6">Figure 4</ref>. Again, ZenNets outperform most models by a large margin. ZenNet-900M-SE achieves 80.8% top-1 accuracy which is comparable to EfficientNet-B3 with 43% fewer FLOPs. The runner-up is OFANet whose efficiency is similar to ZenNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Searching Cost of Zen-NAS v.s. SOTA</head><p>The major time cost of Zen-NAS is the computation of Zen-Score. The network latency is predicted by an in-house latency predictor whose time cost is nearly zero. According to <ref type="table" target="#tab_1">Table 2</ref>, the computation of Zen-Score for ResNet-50 only takes 0.15 second. This means that scoring 96,000 networks similar to ResNet-50 only takes 4 GPU hours, or 0.17 GPU day.</p><p>We compare Zen-NAS searching cost to SOTA NAS methods in <ref type="table" target="#tab_3">Table 3</ref>. Since every NAS method uses different settings, it is difficult to make a fair comparison that everyone agrees with. Nevertheless, we only concern about the best model reported in each paper and the corresponding searching cost. This gives us a rough impression of the efficiency of these methods and their practical ability of designing high-performance models.</p><p>From <ref type="table" target="#tab_3">Table 3</ref>, for conventional NAS methods, it takes hundreds to thousands GPU days to find a good structure of accuracy better than 78.0%. Many one-shot methods are very fast. For most one-shot methods, the best accuracy is below 80%. In comparison, Zen-NAS achieves 83.6% top-1 accuracy within 0.5 GPU day. Among methods achieving above 80.0% top-1 accuracy in <ref type="table" target="#tab_3">Table 3</ref>, the searching speed of Zen-NAS is nearly 100 times faster than OFANet and 7800 times faster than EfficientNet. TE-NAS uses less GPU day than Zen-NAS in <ref type="table" target="#tab_3">Table 3</ref>. This does not conflict with <ref type="table" target="#tab_1">Table 2</ref> because the total number of networks evaluated by the two methods are different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We proposed Zen-NAS, a zero-shot neural architecture search framework for designing high performance deep image recognition networks. Without optimizing network parameters, Zen-NAS ranks networks via network expressivity which can be numerically measured by Zen-Score. The searching speed of Zen-NAS is dramatically faster than previous SOTA methods. The ZenNets automatically designed by Zen-NAS are significantly more efficient in terms of inference latency, FLOPs and model size, in multiple recognition tasks. We wish the elegance of Zen-NAS will inspire more theoretical researches towards a deeper understanding of efficient network design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Datasets and Experiment Settings</head><p>Dataset CIFAR-10 has 50 thousand training images and 10 thousand testing images in 10 classes with resolution 32x32. CIFAR-100 has the same number of training/testing images but in 100 classes. ImageNet-1k has over 1.2 million training images and 50 thousand validation images in 1000 classes. We use the official training/validation split in our experiments. Augmentation We use the following augmentations as in <ref type="bibr" target="#b37">[38]</ref>: mix-up <ref type="bibr" target="#b64">[65]</ref>, label-smoothing <ref type="bibr" target="#b47">[48]</ref>, random erasing <ref type="bibr" target="#b67">[68]</ref>, random crop/resize/flip/lighting and AutoAugment <ref type="bibr" target="#b9">[10]</ref>. Optimizer For all experiments, we use SGD optimizer with momentum 0.9; weight decay 5e-4 for CIFAR-10/100, 4e-5 for ImageNet; initial learning rate 0.1 with batch size 256; cosine learning rate decay <ref type="bibr" target="#b26">[27]</ref>. We train models up to 1440 epochs in CIFAR-10/100, 480 epochs in ImageNet. Following previous works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b4">5]</ref>, we use EfficientNet-B3 as teacher networks when training ZenNets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Implementation</head><p>Our code is implemented in PyTorch. The synflow implementation is available from https://github. com/mohsaied/zero-cost-nas/blob/main/foresight/pruners/measures/synflow. py. The official TE-NAS score implementation is available from https://github.com/VITA-Group/ TENAS/blob/main/lib/procedures. The official NASWOT implementation is available from https: //github.com/BayesWatch/nas-without-training. Our searching and training code are released on https://github.com/idstcv/ZenNAS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Additional Figures</head><p>We test the performance of ZenNets on devices other than NVIDIA V100 GPU. The two hardware platforms are considered. NVIDIA T4 is an industrial level GPU optimized for INT8 inference. All networks are exported to TensorRT engine at precision INT8 to benchmark their inference speed on T4. Google Pixel2 is a modern cell phone with moderate powerful mobile GPU. In <ref type="figure" target="#fig_8">Figure 5</ref> and <ref type="figure" target="#fig_10">Figure 6</ref>, we report the inference speed of ZenNets on T4 and Pixel2 as well as several SOTA models. The best ZenNet-1.2ms is 10.9x times faster than EfficientNet on NVIDIA T4, 1.6x times faster on Pixel2.</p><p>The evolutionary processes of optimizing zero-shot proxies are plotted in <ref type="figure">Figure 7</ref>, 8, 9, 10, 11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Zen-NAS on CIFAR</head><p>Following previous works, we use Zen-NAS to optimize model size on CIFAR-10 and CIFAR-100 datasets. We use Search Space I in this experiment. We constrain the number of network parameters within {1.0 M, 2.0 M}. The resultant networks are labeled as ZenNet-1.0M/2.0M. <ref type="table">Table 4</ref> summarized our results. We compare several popular NAS-designed models for CIFAR-10/CIFAR-100 in <ref type="figure" target="#fig_3">Figure 13</ref>, including AmoebaNet <ref type="bibr" target="#b40">[41]</ref>, DARTS <ref type="bibr" target="#b25">[26]</ref>, P-DARTS <ref type="bibr" target="#b7">[8]</ref>, SNAS <ref type="bibr" target="#b58">[59]</ref>, NASNet-A <ref type="bibr" target="#b69">[70]</ref>, ENAS <ref type="bibr" target="#b37">[38]</ref>, PNAS <ref type="bibr" target="#b24">[25]</ref>, ProxylessNAS <ref type="bibr" target="#b5">[6]</ref>. ZenNets outperform baseline methods by 30% ? 50% parameter reduction while achieving the same accuracies.   <ref type="table">Table 4</ref>: ZenNet-1.0M/2.0M on CIFAR-10 (C10) and CIFAR-100 (C100).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Zen-Scores and Accuracies of ResNets under Fair Training Setting</head><p>ResNets are widely used in computer vision. It is interesting to understand the ResNets via Zen-Score analysis. We report the Zen-Scores of ResNets in <ref type="table" target="#tab_6">Table 5</ref>. In <ref type="figure" target="#fig_6">Figure 14</ref>, we plot the Zen-Score against top-1 accuracy of ResNet and ZenNet on ImageNet. From the figure, it is clearly that even for the same model, the training method matters a lot. There is considerable performance gain of ResNets after using our enhanced training methods. The Zen-Scores positively correlate to the top-1 accuracies for both ResNet and ZenNets. Next we show that the Zen-Scores is well-aligned with top-1 accuracies across different models. We Top-1 Accuracy (%)    consider two baselines in <ref type="table">Table 6</ref>. The 2nd column reports the top-1 accuracies obtained in the ResNet original paper <ref type="bibr" target="#b14">[15]</ref>. We found that these models are under-trained. We use enhanced training methods to train ResNets in the same way as we trained ZenNets. The corresponding top-1 accuracies are reported in the 3rd column. Zen-score Zen <ref type="figure">Figure 7</ref>: NAS process for maximizing Zen-Score. x-axis: number of evolutionary iterations. y-axis: Largest Zen-Score in the current population.  <ref type="table">Table 6</ref>: Top-1 accuracies of ResNets. Reported by <ref type="bibr" target="#b14">[15]</ref> and using enhanced training methods we used in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Effectiveness of Zen-Score</head><p>We show that Zen-Score effectively indicates the model accuracy during the evolutionary search. In the searching process of ZenNet-1.0M, we uniformly sample 16 structures from the evolutionary population. These structures have different number of channels and layers. Then the sampled structures are trained on CIFAR-10/CIFAR-100. The top-1 accuracy v.s. Zen-Score are plotted in <ref type="figure" target="#fig_8">Figure 15</ref>. G FLOPs/Params/Latency of ZenNets in <ref type="table" target="#tab_0">Table 1</ref> proxy params FLOPs latency   Largest TE-NAS score in the current population. The NTK score in TE-NAS is the smaller the better. Therefore we use R N ? NTK as TE-score in EA. This is slightly different from <ref type="bibr" target="#b6">[7]</ref> where the rank of NTK is used as score.  Zen-Score </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Proof of Theorem 1</head><p>We introduce a few more notations for our proof. Suppose the network has L convolutional layers. The t-th layer has m t?1 input channels and m t output channels. The convolutional kernel is ? t ? R mt?m?1t?k?k . The image resolution is H ? W . The mini-batch size is B. The output feature map of the t-th layer is x t .</p><p>We use x</p><formula xml:id="formula_9">(i,b,h,w) t</formula><p>to denote the pixel of x t in the i-th channel, b-th image at cooridinate (h, w). N (?, ?) denotes Gaussian distribution with mean ? and variance ? 2 . For random variables z, a and a constant b, the notation z = a ? b means |z ? a| ? b. To avoid notation clutter, we use C 1/? log (?) to denote some logarithmic polynomial in 1/? and some other variables. Since the order of these variables in C 1/? log (?) is logarithmic, they do not alternate the polynomial order of our bounds.</p><p>The input image x 0 are sampled from N (0, 1). In a vanilla network without BN layer, the feature map x t is generated by the following forward inference process:</p><formula xml:id="formula_10">x 0 =x 0 x t = [? t * x t?1 ] +</formula><p>where * is the convolutional operator, [z] + = max(z, 0).</p><p>In Zen-Score computation, BN layer is inserted after every convolutional operator. The forward inference now becomes:</p><formula xml:id="formula_11">g t =? t * x t?1 (5) [? (i) t ] 2 = 1 BHW b,h,w [g (i,b,h,w) t ] 2<label>(6)</label></formula><formula xml:id="formula_12">? 2 t = 1 m t mt i=1 [? (i) t ] 2<label>(7)</label></formula><p>x (i)</p><formula xml:id="formula_13">t = g (i) t ? (i) t + = 1 ? (i) t [g (i) t ] + .<label>(8)</label></formula><p>Please note that in Eq. (8), we use a modified BN layer instead of the standard BN, where we do not subtract mean value in the normalization step. This will greatly simply the proof. If the reader is concerned about this, it is straightforward to replace all BN layers with our modified BN layers so that the computational process exactly follows our proof. In practice, we did not observe noticable difference by switching between two BN layers because the mean value of mini-batch is very close to zero. To show that the Zen-Score computed on BN-enabled network f (x 0 ) = x L approximates the ?-score computed on BN-free networkf (x 0 ) =x L , we only need to prove</p><formula xml:id="formula_14">( L t=1? t ) 2 E ? x L 2 ? E ? x L 2 .<label>(9)</label></formula><p>In deed, when Eq. (9) holds true, by taking gradient w.r.t. x on both side, the proof is then completed. To prove Eq. (9), we need the following theorems and lemmas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.1 Useful Theorems and Lemmas</head><p>The first theorem is Bernstein's inequality. It can be found in many statistical textbooks, such as [53, Theorem 2.8.1].</p><p>Theorem 2 (Bernstein's inequality). Let x 1 , x 2 , ? ? ? , x N be independent bounded random variables of mean zero, variance ?. |x i | ? K for all i ? {1, 2, ? ? ? , N }. a = [a 1 , a 2 , ? ? ? , a N ] is a fixed N -dimensional vector. Then ?t ? 0,</p><formula xml:id="formula_15">P( N i=1 a i x i ? t) ? 2 exp ?c min t 2 ? 2 a 2 2 , t K a ? .</formula><p>A direct corollary gives the upper bound of sum of random variables.</p><p>Corollary 1. Under the same setting of Theorem 2, with probability at least 1 ? ?,</p><formula xml:id="formula_16">N i=1 a i x i ? C 1/? log (?)? a 2 .</formula><p>Proof. Let</p><formula xml:id="formula_17">? 2 exp ?c min t 2 ? 2 a 2 2 , t K a ? = max 2 exp ?c t 2 ? 2 a 2 2 , 2 exp ?c t K a ? .</formula><p>That is,</p><formula xml:id="formula_18">? ? 2 exp ?c t 2 ? 2 a 2 2 ?t ? 1 c log(2/?)? a 2 = C 1/? log (?)? a 2 , and ? ? 2 exp ?c t K a ? ?t ? 1 c log(2/?)K a ? = C 1/? log (?)K a ? .</formula><p>Therefore, with probability at least 1 ? ?,</p><formula xml:id="formula_19">N i=1 a i x i ? min{C 1/? log (?)? a 2 , C 1/? log (?)K a ? } ?C 1/? log (?) min{? a 2 , K a ? } .</formula><p>That is,</p><formula xml:id="formula_20">N i=1 a i x i ? C 1/? log (?)? a 2 .</formula><p>When the random variables are sampled from Gaussian distribution, it is more convenient to use the following tighter bound. Theorem 3. Let x 1 , x 2 , ? ? ? , x N be sampled from N (0, ?), a ? R N be a fixed a vector. Then ?t ? 0,</p><formula xml:id="formula_21">P( N i=1 a i x i &gt; t) ? exp ? t 2 2? 2 a 2 2 . Corollary 2. With probability at least 1 ? ?, N i=1 a i x i ? 2 log(1/?)? a 2 = C 1/? log (?)? a 2 .</formula><p>The proof is simple since the sum of Gaussian random variables is still Gaussian random variables. The following two lemmas are critical in our lower bound analysis. The proof is straightforward once using the symmetric property of random variable distribution. </p><formula xml:id="formula_22">E ? [ i ? i x i ] 2 + = 1 2 E ? [ i ? i x i ] 2 = E ? [ i ? i y i ] 2 + . H.2 Proof of Eq. (9) Since x 0 ? N (0, 1), with probability at least 1 ? ?, x 0 ? ? C 1/? log (?) K 0 for some constant K 0 . Now suppose at layer t, x t?1 ? ? K t?1 .</formula><p>The following lemma shows that after convolution, g t ? is also bounded with high probability.</p><p>Lemma 5. Let ? (i,b,h,w) ? N (0, 1), ? t ? R mt?mt?1?k?k . For fixed x t?1 ? R mt?1?B?H?W , g t ? t * x t?1 . Then with probability at least 1 ? ?,</p><formula xml:id="formula_23">g t ? ? C 1/? log (?) 2 k ? m t?1 K t?1 .</formula><p>Proof. Let us consider g (j,b,?,?) t , that is, the j-th channel, b-th image, at pixel (?, ?). For any 1 ? j ? m t ,</p><formula xml:id="formula_24">1 ? ? ? H, 1 ? ? ? W , g (j,b,?,?) t = m?1t i=1 k?1 2 p=? k?1 2 k?1 2 q=? k?1 2 ? (j,i,p,q) t x (i,b,?+p,?+p) t?1</formula><p>Clearly,</p><formula xml:id="formula_25">E ? g (j,b,?,?) t = 0 .</formula><p>According to Corollary 2,</p><formula xml:id="formula_26">|g (j,b,?,?) t | ? C 1/? log (?)C 1/? log (?)K t?1 ? m t?1 k ? C 1/? log (?) 2 k ? m t?1 K t?1 .</formula><p>The variance of g t is bounded with high probability too. Lemma 6. With probability at least 1 ? ?,</p><formula xml:id="formula_27">E[g (j,b,?,?) t ] 2 =? * t ? C 1/? log (?)k ? m t?1 K t?1 ? * 2 t 1 4 m t?1 k 2 .</formula><p>Proof. By definition,</p><formula xml:id="formula_28">g (j,b,?,?) t = m?1t i=1 k?1 2 Similary,? 1 ? m t BHW C 1/? log (?) 5 m t?1 k 2 K 2 t?1 . Define t 1 [? * t ] 2 1 ? BHW C 1/? log (?) 5 m t?1 k 2 K 2 t?1 = 4 m t?1 k 2 C 1/? log (?) 5 1 ? BHW m t?1 k 2 K 2 t?1 =4C 1/? log (?) 5 1 ? BHW K 2 t?1</formula><p>Finally, we inductively bound |x (i,b,h,w) t |.</p><p>Lemma 9. With probability at least 1 ? ?,</p><formula xml:id="formula_29">|x (i,b,h,w) t | ? C 1/? log (?) 2 (1 ? t ) K t?1 K t ? C 1/? log (?) 2t t j=1</formula><p>(1 ? j ) ?1/2 K 0 .</p><p>Proof. By definition,</p><formula xml:id="formula_30">x (i,b,h,w) t = 1 ? (i) t [g (i,b,h,w) t ] + From Lemma 5, [g (i,b,h,w) t ] + ? C 1/? log (?) 2 K t?1 ? m t?1 k From Lemma 7, [? (i) t ] 2 = (1 ? t )[? * t ] 2 = 1 4 (1 ? t )m t?1 k 2 Then |x (i,b,h,w) t | ? C 1/? log (?) 2 K t?1 ? m t?1 k 1 4 (1 ? t )m t?1 k 2 ? C 1/? log (?) 2 K t?1 ? m t?1 k 1 4 (1 ? t )m t?1 k 2 ?2 C 1/? log (?) 2 K t?1 (1 ? t ) ? C 1/? log (?) 2 K t?1 (1 ? t ) absorb 2 into C 1/? log (?)</formula><p>Therefore,</p><formula xml:id="formula_31">K t C 1/? log (?) 2 K t?1 (1 ? t ) ?K t = C 1/? log (?) 2t t j=1 (1 ? j ) ?1/2 K 0</formula><p>Combining all above together, we are now ready to prove Eq. (9). Denote z 0 = 1. It is trivial to see that z 0 x 0 2 = z 0 x t 2 . By induction, suppose at layer t, we already have z t?1 x t?1 2 = x t?1 2 . Using Lemma 4,</p><formula xml:id="formula_32">E ? x t 2 =E ? [? t * x t?1 ] + 2 =E ? [? t * z t?1 x t?1 ] + 2 =z t?1 E ? [? t * x t?1 ] + 2 =z t?1 E ? [g t ] + 2</formula><p>On the other hand, from Lemma 8,</p><formula xml:id="formula_33">? 2 t z t?1 x t 2 =z t?1? 2 t (? * t ) 2 (? * t ) 2 x t 2 =z t?1 (1 ? t ? m t )(? * t ) 2 x t 2 Lemma [lem:sigma-i-concentration] =z t?1 (1 ? t ? m t ) 1 1 ? t [g t ] + 2 .</formula><p>Therefore,</p><formula xml:id="formula_34">E ? {? 2 t z t?1 x t 2 } = (1 ? t ? m t ) 1 1 ? t E ? x t 2 By taking z t ? 2 t z t?1 /[(1 ? t ? m t ) 1 1 ? t ] ,</formula><p>we complete the induction of z t x t 2 = x t 2 for all t. Chaining t = {1, 2, ? ? ? , L}, we get</p><formula xml:id="formula_35">E ? {( L t=1? 2 t ) x L 2 } = L t=1 (1 ? t ? m t ) 1 1 ? t E ? x L 2 , where t 4C 1/? log (?) 5 1 ? BHW K 2 t?1 K t C 1/? log (?) 2t t j=1 (1 ? j ) ?1/2 K 0 .</formula><p>Finally, integrate everything together, we have proved that, with probability at least 1 ? ?,</p><formula xml:id="formula_36">( L t=1? 2 t )E ? { x L 2 } = L t=1 (1 ? t ? m t ) 1 1 ? t E ? x L 2 .</formula><p>That is,</p><formula xml:id="formula_37">L t=1 (1 ? t ? m t ) 1 1 + ? ( L t=1? 2 t )E ? { x L 2 } E ? x L 2 ? L t=1 (1 + t ? m t ) 1 1 ? t .</formula><p>To further simply the above results, we consider the asymptotic case where BHW is large enough. Then t will be a small number. By first order approximation of binomial expansion, (1 + ) L ? 1 + L + O( 2 ). To see that t is bounded by a small constant, we denote ? t max j?[1,t] j . Then</p><formula xml:id="formula_38">K t ?O[(1 + t ? 1 2 ? t?1 )K 0 ] ? t ? O{ K 0 ? BHW [(1 + (t ? 1) 2 ? t?1 ]} .<label>(10)</label></formula><p>By the recursive equation Eq. (10), when ? t?1 ? 2 L?1 ,</p><formula xml:id="formula_39">? t ? O{ K 0 ? BHW [(1 + (t ? 1) 2 ? t?1 ]} ? O{ 2K 0 ? BHW } .</formula><p>Therefore, by taking 2K0 ? BHW ? 2 L , that is BHW ? O{L 2 K 2 0 }, we have</p><formula xml:id="formula_40">= max t ? O{ 2K 0 ? BHW }</formula><p>to be a small number. When is a small number,</p><formula xml:id="formula_41">( L t=1? 2 t )E ? { x L 2 } E ? x L 2 ? L t=1 (1 + t ? m t ) 1 1 ? t ?(1 + ) L (1 ? t ) ?L ?(1 + L ) 2 . Similarly, ( L t=1? 2 t )E ? { x L 2 } E ? x L 2 ? (1 ? L ) 2 .</formula><p>block kernel in out stride bottleneck expansion # layers    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Lemma 2 (</head><label>2</label><figDesc><ref type="bibr" target="#b17">[18]</ref>). For linear function class {f : f (X) = W X s.t. W F ? G}, its Gaussian complexity is upper bounded by O(G).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>(d) ?-score of Q w/oBN networks ?-score of Q BN networks Zen-Score of Q BN networks ?-scores and Zen-Scores of networks, with different depths and bottleneck channels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>feature map computation steps of Zen-score</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Zen-Score computational graph. x 0 is one mini-batch of input images. For each BN layer, we extract its mini-batch deviation parameter</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>ZenNets optimized for FLOPs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>ZenNets top-1 accuracy on ImageNet-1k v.s. inference latency (milliseconds per image) on NVIDIA T4, TensorRT INT8, batch size 64. ZenNet-0.8ms?1.2ms and ZenNet-400M-SE?900M-SE are plotted as two separated curves. model # params FLOPs C10 C100 ZenNet-1.0M 1.0 M 162 M 96.5% 80.1% ZenNet-2.0M 2.0 M 487 M 97.5% 84.4%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 :</head><label>6</label><figDesc>ZenNets top-1 accuracy on ImageNet-1k v.s. inference latency (milliseconds per image) on Google Pixel2, single image. ZenNet-0.8ms?1.2ms and ZenNet-400M-SE?900M-SE are plotted as two separated curves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>8 FLOPsFigure 8 :</head><label>88</label><figDesc>NAS process for maximizing FLOPs. x-axis: number of evolutionary iterations. y-axis: Largest FLOPs in the current population. effectively indicates the network accuracies, especially in high-precision regimes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 9 :Figure 10 :Figure 11 :Figure 12 :</head><label>9101112</label><figDesc>NAS process for maximizing grad-norm. x-axis: number of evolutionary iterations. y-axis: Largest grad-norm in the current population. NAS process for maximizing synflow. x-axis: number of evolutionary iterations. y-axis: Smallest synflow in the current population. NAS process for maximizing NASWOT. x-axis: number of evolutionary iterations. y-axis: Largest NASWOT score in the current population. NAS process for maximizing TE-NAS score. x-axis: number of evolutionary iterations. y-axis:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 13 :</head><label>13</label><figDesc>ZenNet accuracy v.s. model size (# params) on CIFAR-10 and CIFAR-100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 14 :</head><label>14</label><figDesc>ResNet/ZenNet Zen-Score v.s. top-1 accuracy on ImageNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 15 :</head><label>15</label><figDesc>Zen-Score v.s. top-1 accuracy, 16 randomly sampled structures generated from ResNet-50, with Kendall's ? -score between accuracy and Zen-Score.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Lemma 3 .</head><label>3</label><figDesc>Suppose x ? R is a mean zero, variance ? 2 random variable with symmetric distribution. Then E[x] 2 + = 4? 2 /4. Lemma 4. Suppose ? i ? N (0, 1). x = y are two fixed vectors. Then</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell cols="2">Zen-Score</cell><cell>96.2%</cell><cell>80.1%</cell></row><row><cell>FLOPs</cell><cell></cell><cell>93.1%</cell><cell>64.7%</cell></row><row><cell>grad</cell><cell></cell><cell>92.8%</cell><cell>65.4%</cell></row><row><cell>synflow</cell><cell></cell><cell>95.1%</cell><cell>75.9%</cell></row><row><cell cols="2">TE-Score</cell><cell>96.1%</cell><cell>77.2%</cell></row><row><cell cols="2">NASWOT</cell><cell>96.0%</cell><cell>77.5%</cell></row><row><cell>Random</cell><cell cols="4">93.5?0.7% 71.1?3.1%</cell></row><row><cell>proxy</cell><cell>model</cell><cell>N</cell><cell cols="2">time speed-up</cell></row><row><cell>TE-Score</cell><cell cols="3">ResNet-18 16 0.34</cell><cell>1/28x</cell></row><row><cell></cell><cell cols="3">ResNet-50 16 0.77</cell><cell>1/20x</cell></row><row><cell cols="4">NASWOT ? ResNet-18 16 0.040</cell><cell>1/3.3x</cell></row><row><cell></cell><cell cols="3">ResNet-50 16 0.059</cell><cell>1/1.6x</cell></row><row><cell>Zen-Score</cell><cell cols="3">ResNet-18 16 0.012</cell><cell>1.0</cell></row><row><cell></cell><cell cols="3">ResNet-50 16 0.037</cell><cell>1.0</cell></row></table><note>Top-1 accuracies on CIFAR-10/CIFAR-100 for five zero-shot proxies. Budget: model size N ? 1 M. 'Random': average accuracy ? std for random search.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Time cost (in seconds) of computing Zen/TE-Score for ResNet-18/50 at resolution 224x224. The statistical error is within 5%. 'time': time for computing Zen/TE-score for N images, measured in seconds, averaged over 100 trials. 'speed-up': speed-up rate of TE-Score v.s. Zen-Score.?: The official implementation outputs Inf score for ResNet-18/50.224x224 for ImageNet.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>NAS searching cost comparison. 'Top-1': top-1 accuracy on ImageNet-1k. 'Method': 'EA' is short for Evolutionary Algorithm; 'GD' is short for Gradient Descent; 'RL' is short for reinforcement Learning; 'ZS' is short for Zero-shot; 'SMBO', 'SSL', 'PS' and 'Scaling' are special searching methods/frameworks.?: Running on TPU; ?: The cost is estimated by [54];</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Zen-Scores of ResNets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 14 :</head><label>14</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ZenNet-400M-SE</cell><cell></cell><cell></cell></row><row><cell cols="3">block kernel in</cell><cell>out</cell><cell cols="4">stride bottleneck expansion # layers</cell></row><row><cell cols="2">Conv 3</cell><cell>3</cell><cell>24</cell><cell>2</cell><cell>-</cell><cell>-</cell><cell>1</cell></row><row><cell>MB</cell><cell>7</cell><cell>24</cell><cell>48</cell><cell>2</cell><cell>48</cell><cell>1</cell><cell>1</cell></row><row><cell>MB</cell><cell>7</cell><cell>48</cell><cell>72</cell><cell>2</cell><cell>72</cell><cell>2</cell><cell>1</cell></row><row><cell>MB</cell><cell>7</cell><cell>72</cell><cell>96</cell><cell>2</cell><cell>88</cell><cell>6</cell><cell>5</cell></row><row><cell>MB</cell><cell>7</cell><cell>96</cell><cell>192</cell><cell>2</cell><cell>168</cell><cell>4</cell><cell>5</cell></row><row><cell cols="2">Conv 1</cell><cell cols="3">192 2048 1</cell><cell>-</cell><cell>-</cell><cell>1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 15 :</head><label>15</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ZenNet-600M-SE</cell><cell></cell><cell></cell></row><row><cell cols="3">block kernel in</cell><cell>out</cell><cell cols="4">stride bottleneck expansion # layers</cell></row><row><cell cols="2">Conv 3</cell><cell>3</cell><cell>16</cell><cell>2</cell><cell>-</cell><cell>-</cell><cell>1</cell></row><row><cell>MB</cell><cell>7</cell><cell>16</cell><cell>48</cell><cell>2</cell><cell>72</cell><cell>1</cell><cell>1</cell></row><row><cell>MB</cell><cell>7</cell><cell>48</cell><cell>72</cell><cell>2</cell><cell>64</cell><cell>2</cell><cell>3</cell></row><row><cell>MB</cell><cell>7</cell><cell>72</cell><cell>152</cell><cell>2</cell><cell>144</cell><cell>2</cell><cell>3</cell></row><row><cell>MB</cell><cell>7</cell><cell cols="2">152 360</cell><cell>2</cell><cell>352</cell><cell>2</cell><cell>4</cell></row><row><cell>MB</cell><cell>7</cell><cell cols="2">360 288</cell><cell>1</cell><cell>264</cell><cell>4</cell><cell>3</cell></row><row><cell cols="2">Conv 1</cell><cell cols="3">288 2048 1</cell><cell>-</cell><cell>-</cell><cell>1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 16 :</head><label>16</label><figDesc>ZenNet-900M-SE</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Obviously, the final searched architecture must be trained on the target dataset before deployment.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t =[? * t ] 2 ?</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Therefore,</p><p>Define ? * 2 t 1 4 m t?1 k 2 , the proof is completed.</p><p>Next we show that both ?  </p><p>Proof. Directly apply Corollary 1,</p><p>Then we have</p><p>Next is our main lemma.</p><p>Under the same setting of Lemma 7, with probability 1 ? ?,</p><p>Proof. By definition,</p><p>By Lemma 7, we have</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J Detail Structure of ZenNets</head><p>We list detail structure in <ref type="table">Table 8</ref> <ref type="bibr">, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18.</ref> The 'block' column is the block type. 'Conv' is the standard convolution layer followed by BN and RELU. 'Res' is the residual block used in ResNet-18. 'Btn' is the residual bottleneck block used in ResNet-50. 'MB' is the MobileBlock used in MobileNet and EfficientNet. To be consistent with 'Btn' block, each 'MB' block is stacked by two MobileBlocks. That is, the kxk full convolutional layer in 'Btn' block is replaced by depth-wise convolution in 'MB' block. 'kernel' is the kernel size of kxk convolution layer in each block. 'in', 'out' and 'bottleneck' are numbers of input channels, output channels and bottleneck channels respectively. 'stride' is the stride of current block. '# layers' is the number of duplication of current block type.         </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Zero-Cost Proxies for Lightweight NAS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">S</forename><surname>Abdelfattah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Dudziak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><forename type="middle">D</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2021. 3, 4</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Knowledge Distillation from Internal Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenlei</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Designing Neural Network Architectures using Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spectrally-normalized margin bounds for neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><forename type="middle">J</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matus</forename><forename type="middle">J</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Telgarsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Once-for-All: Train One Network and Specialize it for Efficient Deployment on Diverse Hardware Platforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhekai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural architecture search on imagenet in four gpu hours: A theoretically inspired perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Progressive DARTS: Bridging the Optimization Gap for NAS in the Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Inductive Bias of Deep Convolutional Networks through Pooling Geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadav</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amnon</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">AutoAugment: Learning Augmentation Policies from Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Daniely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Single Path One-Shot Neural Architecture Search with Uniform Sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyuan</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zechun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Complexity of Linear Regions in Deep Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Hanin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Squeeze-and-Excitation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Albanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhua</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Densely Connected Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambuj</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Oracle Inequalities in Empirical Risk Minimization and Sparse Recovery Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Koltchinskii</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">2033</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Blockwisely Supervised Neural Architecture Search with Knowledge Distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiefeng</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuchun</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangrun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Partial Order Pruning: For Best Speed/Accuracy Trade-off in Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Why Deep Neural Networks for Function Approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Are Labels Necessary for Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progressive Neural Architecture Search. In ECCV</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SGDR: Stochastic Gradient Descent with Warm Restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Expressive Power of Neural Networks: A View from the Width</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongming</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semi-Supervised Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Architecture Optimization. In NIPS</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the Expressive Power of Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><forename type="middle">J</forename><surname>Crowley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.04647</idno>
		<idno>2021. 3</idno>
		<title level="m">Neural Architecture Search without Training</title>
		<imprint/>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural Architecture Search without Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><forename type="middle">J</forename><surname>Crowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML, 2021</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On the Number of Linear Regions of Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Mont?far</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The role of overparametrization in generalization of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Behnam Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinadh</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thao</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<idno>ICLR, 2021. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10580</idno>
		<idno>2021. 3</idno>
	</analytic>
	<monogr>
		<title level="j">Meta Pseudo Labels</title>
		<imprint/>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Efficient Neural Architecture Search via Parameters Sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melody</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Exponential expressivity in deep neural networks through transient chaos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhaneil</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note>Jascha Sohl-Dickstein, and Surya Ganguli</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Designing Network Design Spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilija</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><forename type="middle">Prateek</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Regularized Evolution for Image Classifier Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Large-Scale Evolution of Image Classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherry</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><forename type="middle">Leon</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kurakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">A Comprehensive Survey of Neural Architecture Search: Challenges and Solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengzhen</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The power of deeper networks for expressing natural functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Tegmark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">verted Residuals and Linear Bottlenecks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Evaluating the Search Phase of Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Sciuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaicheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudiu</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.08142</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bounding and Counting Linear Regions of Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thiago</forename><surname>Serra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Tjandraatmadja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikumar</forename><surname>Ramalingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Rethinking the Inception Architecture for Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">MnasNet: Platform-Aware Neural Architecture Search for Mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Pruning neural networks without any data by iteratively conserving synaptic flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hidenori</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kunin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS, 2020</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.12877[cs],2021.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Vershynin</surname></persName>
		</author>
		<title level="m">High-Dimensional Probability: An Introduction with Applications in Data Science. Cambridge Series in Statistical and Probabilistic Mathematics</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<title level="m">FBNetV2: Differentiable Neural Architecture Search for Spatial and Channel Dimensions</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note>CVPR, 2020</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Picking Winning Tickets Before Training by Preserving Gradient Flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Neural Predictor for Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Genetic CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Exploring Randomly Wired Neural Networks for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.01569[cs],2019.4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">SNAS: Stochastic neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">On the Number of Linear Regions of Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">CARS: Continuous Evolution for Efficient Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">NAS-Bench-101: Towards Reproducible Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">ResNeSt: Split-Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongruo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Mixup: Beyond Empirical Risk Minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Overcoming Multi-Model Forgetting in One-Shot NAS With Diversity Maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Empirical Studies on the Properties of Linear Regions in Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongrui</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Random Erasing Data Augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">EcoNAS: Finding Proxies for Economical Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongzhan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuesen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Learning Transferable Architectures for Scalable Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">+: OFANet trained using supernet parameters as initialization. * : OFANet trained from scratch. We adopt this setting for fair comparison. ?: fail to run due to out of memory. ?: official model implementation not supported by TensorRT</title>
	</analytic>
	<monogr>
		<title level="m">One big table of all networks referred in this work</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
