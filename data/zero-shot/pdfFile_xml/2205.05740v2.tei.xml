<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Surface Representation for Point Clouds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxi</forename><surname>Ran</surname></persName>
							<email>ranhaoxi@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Northeastern University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Tencent Youtu Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Tencent Youtu Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Surface Representation for Point Clouds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most prior work represents the shapes of point clouds by coordinates. However, it is insufficient to describe the local geometry directly. In this paper, we present RepSurf (representative surfaces), a novel representation of point clouds to explicitly depict the very local structure. We explore two variants of RepSurf, Triangular RepSurf and Umbrella RepSurf inspired by triangle meshes and umbrella curvature in computer graphics. We compute the representations of RepSurf by predefined geometric priors after surface reconstruction. RepSurf can be a plug-and-play module for most point cloud models thanks to its free collaboration with irregular points. Based on a simple baseline of PointNet++ (SSG version), Umbrella RepSurf surpasses the previous state-of-the-art by a large margin for classification, segmentation and detection on various benchmarks in terms of performance and efficiency. With an increase of around 0.008M number of parameters, 0.04G FLOPs, and 1.12ms inference time, our method achieves 94.7% (+0.5%) on ModelNet40, and 84.6% (+1.8%) on ScanObjectNN for classification, while 74.3% (+0.8%) mIoU on S3DIS 6-fold, and 70.0% (+1.6%) mIoU on ScanNet for segmentation. For detection, previous state-of-the-art detector with our RepSurf obtains 71.2% (+2.1%) mAP 25 , 54.8% (+2.0%) mAP 50 on ScanNetV2, and 64.9% (+1.9%) mAP 25 , 47.7% (+2.5%) mAP 50 on SUN RGB-D. Our lightweight Triangular RepSurf performs its excellence on these benchmarks as well. The code is publicly available at https:// github.com/hancyran/RepSurf.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Learning from raw point clouds has drawn considerable attention for its advantages in various applications, like autonomous driving, augmented reality, and robotics. However, it can be difficult for the irregularity of point clouds.</p><p>To handle irregular points, the pioneering work Point-Net <ref type="bibr" target="#b39">[40]</ref> adopts point-wise multi-layer perceptrons (MLP) * corresponding author <ref type="figure" target="#fig_1">Figure 1</ref>. An overview of point cloud classification with RepSurf. Given one point (blue) in the airplane point cloud, we indicate its global position by the coordinate xi. Different from the prior works, we further explicitly describe its local geometry through Triangular RepSurf ti extracted from the reconstructed triangle or Umbrella RepSurf ui learned from the reconstructed umbrella surface. By combining positional and geometric information, point representation can be more expressive. After concatenating xi and ti/ui as input, we predict the category of the point cloud via MLPs followed by a pooling operation.</p><p>to learn from points independently and utilizes a symmetric function to obtain the global information. PointNet++ <ref type="bibr" target="#b41">[42]</ref> further introduces set abstraction (SA) to capture the local information of point clouds. However, both methods learn from standalone points and take no notice of local shape awareness <ref type="bibr" target="#b29">[30]</ref>.</p><p>Local shapes are vital for the learning of point clouds. To learn from the local structural information, some prior works learn from grids <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b51">52]</ref>, relations <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b42">43]</ref>, or graphs <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b63">64]</ref>. However, these methods learn from shapes indirectly by attaching more ingredients (like Euclidean distances, attention mechanism) or applying various transformations (like graph construction, voxelization). These may lead to complex preprocessing and significant computations. These sophisticated hand-crafted components learn from implicit local shape representations in general. We argue that it may lead to an omission of information when pre-defining the ingredients, or a loss of geometry during transformation.</p><p>Taylor Series <ref type="bibr" target="#b50">[51]</ref> expresses a local curve by derivatives. We simplify it by considering the second derivative only.</p><p>Thus, we can roughly represent the local curve, or what we call the "surface" in 3D point clouds, by its corresponding tangent.</p><p>To this end, inspired by Taylor Series, we propose Rep-Surf (representative surfaces) to explicitly represent the local shape of point clouds (shown in <ref type="figure" target="#fig_1">Fig. 1</ref>). To complement Cartesian coordinates in a point set with geometric information, we define RepSurf with three properties: discreteness, explicit locality, and curvature sensitivity. These properties allow RepSurf to express local geometry in free collaboration with irregular points. For a simple version of Rep-Surf, we propose Triangular RepSurf inspired by triangle meshes in computer graphics. We reconstruct a triangle for each point by querying its two neighbors and compute the triangle feature (i.e., normal vector, surface position, normalized coordinate) as RepSurf. To enlarge the perceptive field of RepSurf, we further propose Umbrella RepSurf inspired by umbrella curvature <ref type="bibr" target="#b9">[10]</ref>. Umbrella RepSurf can be an extension of Triangular RepSurf since it is computed from the triangles of an umbrella surface. Different from Triangular RepSurf, we reconstruct an umbrella surface after searching K nearest neighbors and sorting the neighbors counterclockwise. For expressive representations, we feed the K triangular features of an umbrella surface into a learnable transformation function followed by aggregation. Moreover, we present several delicate designs (i.e., polar auxiliary, channel de-differentiation) to further improve RepSurf.</p><p>Our key contributions are manifold:</p><p>? A novel triangle-based representation, Triangular Rep-Surf for point clouds.</p><p>? A novel multi-surface representation, Umbrella Rep-Surf for point clouds.</p><p>? A high-efficiency plug-and-play module based on Rep-Surf for point cloud models.</p><p>? Our method achieves state-of-the-art on numerous point cloud benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Learning on Point Clouds</head><p>Multi-view methods <ref type="bibr">[9, 14-16, 41, 61]</ref> or voxel-based methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b58">59]</ref> describe 3D objects with multiple views (i.e., converting 3D shape to 2D images <ref type="bibr" target="#b49">[50]</ref> and latttice space <ref type="bibr" target="#b48">[49]</ref>) or by voxelization (Oc-tree based networks O-CNN <ref type="bibr" target="#b54">[55]</ref> and OctNet <ref type="bibr" target="#b43">[44]</ref>, efficient submanifold sparse convolution <ref type="bibr" target="#b12">[13]</ref>). However, these transformation methods may lead to significant computations as well as a loss of shape information due to occlusion or lower resolution.</p><p>Point-based methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b34">35]</ref> have recently attracted great attention to directly process point clouds. PointNet <ref type="bibr" target="#b39">[40]</ref> learns from global information through multi-layer perceptrons and max-pooling operation. PointNet++ <ref type="bibr" target="#b41">[42]</ref> introduces set abstraction to capture the features from the local point sets, and farthest point sampling (FPS) to uniformly downsample between two set abstractions. Recent works explore local aggregator via convolutions <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b71">72]</ref>, relations <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b72">73]</ref>, and graphs <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b73">74]</ref>. PointCNN <ref type="bibr" target="#b23">[24]</ref> applies traditional convolution on point clouds after transforming neighboring points to the canonical order. RS-CNN <ref type="bibr" target="#b29">[30]</ref> predefines geometric relations between points and their neighbors for local aggregation. DGCNN <ref type="bibr" target="#b56">[57]</ref> computes the local graphs dynamically to extract geometric information. However, the methods are commonly based on some assumptions of implicit local geometry, which may result in missing geometric information in the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Detection on Point Clouds</head><p>Some early methods detect 3D objects by convolution after converting point clouds to 2D grids <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b66">67]</ref> or 3D voxels <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b74">75]</ref>. Recent works focus on 3D detection of raw point clouds <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b70">71]</ref>. VoteNet <ref type="bibr" target="#b37">[38]</ref> adopts PointNet++ as the backbone for feature extraction and designs a component to group points corresponding to the voted centroids. <ref type="bibr" target="#b31">[32]</ref> removes the hand-crafted operation of grouping by introducing Transformers <ref type="bibr" target="#b53">[54]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Graphics-related Surface Representation</head><p>In computer graphics, triangle meshes are commonly adopted to represent 3D models. To obtain meshes from point clouds, previous works propose various methods for surface reconstruction. Ball-Pivoting Algorithm <ref type="bibr" target="#b2">[3]</ref> forms a triangle if a specific-radius ball touches three points without containing other points. <ref type="bibr" target="#b19">[20]</ref> defines the spatial Poisson formulation for surface reconstruction.</p><p>Curvature can further present the local geometry on 3D point clouds. <ref type="bibr" target="#b68">[69]</ref> estimates the local curvature of the point cloud surface by Least Square Fitting. <ref type="bibr" target="#b9">[10]</ref> constructs an umbrella surface based on the homogeneous neighbors and calculates the umbrella curvature through the neighbors' normal vectors and unit direction vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Surface Representation</head><p>In this section, we first reveal the background for the design of our Representative Surfaces (RepSurf) in Sec. 3.1. Secondly, we introduce several properties of RepSurf as inspiration in Sec. 3.2. Next, we propose two variants of RepSurf, Triangular and Umbrella RepSurf in Sec. 3.3 and Sec. 3.4, respectively. Finally, we implement RepSurf on PointNet++ (SSG version) and provide several exquisite designs to further improve the performance of RepSurf. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Background</head><p>Local shapes are essential to represent point clouds. Prior works learn from shapes indirectly by utilizing extra ingredients or through different transformations. These operations may give some hints to express the local sets of point clouds, but cannot reflect the local shapes explicitly. We argue that the additional information leads to significant computations but contributes little to point cloud representations. Some may even cause the loss of geometric information. Therefore, we have to rethink on how to represent the local geometry.</p><p>We can describe a very local part centered on point (t, f (t)) of a 2D curve f (?) by Talyor series <ref type="bibr" target="#b50">[51]</ref>:</p><formula xml:id="formula_0">f (x) = ? n=0 f (n) (t) n! (x ? t) n , |x ? t| &lt; ?<label>(1)</label></formula><p>To simplify the calculation, we approximate this equation by :</p><formula xml:id="formula_1">f (x) ? f (t) global position + f ? (t) local orientation (x ? t),<label>(2)</label></formula><p>where (t, f (t)) is the global position on curve f (?), and the first derivative f ? (t) can intuitively indicate the local orientation near point (t, f (t)). To further express the local curve ( <ref type="figure" target="#fig_0">Fig. 2 left)</ref>, we represent the local orientation by its corresponding tangent:</p><formula xml:id="formula_2">a i (x ? x i ) + b i (y ? y i ) = 0 ? a i x + b i y ? (a i x i + b i y i ) = 0,<label>(3)</label></formula><p>where x i = t, y i = f (t), and ai bi = ?f ? (a). (a i , b i ) is the normal vector of the tangent, where a 2 i + b 2 i = 1. To conclude, a rough description of the local curve can be defined as: <ref type="figure">Figure 3</ref>. Visualization of a table on curvature sensitivity. We visualize a point cloud by the values of coordinates (above) and normals (below) in each of three dimensions. Intuitively, normal vectors can reflect the local shapes numerically to some extent.</p><formula xml:id="formula_3">c i = (x i , y i , a i , b i , a i x i + b i y i ) .<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Properties of RepSurf</head><p>PointNet <ref type="bibr" target="#b39">[40]</ref> is inspired by three main properties of point sets in R N ?3 from an Euclidean space: 1) unordered, 2) interaction among points and 3) invariance under transformations. It can handle the unordered point sets and alleviate the problem from rigid transformation. However, the ability to interact among points is still underexplored.</p><p>In 3D computer graphics, triangle meshes are a common representation of 3D models. Regularly, a triangle mesh consists of a set of triangles connected by their common edges or corners. Thus, triangles can flexibly present continuous and sophisticated 3D shapes for this characteristic. However, triangle meshes may not match the data structure of point clouds due to irregularity. A direct conversion from point cloud to triangle mesh may lead to significant computation as well as loss of point cloud characteristics (like flexibility from unorderness, scalability from the nature of sets). Therefore, we design our RepSurf inspired by the following properties:</p><p>? Discreteness. Ideally, RepSurf should be a set to collaborate with the related point set. It means that each of N points has a corresponding RepSurf feature.</p><p>? Explicit Locality. Unlike prior works describing local structure by learning (implicit locality), RepSurf shows the explicit locality of a part of point clouds numerically.</p><p>? Curvature Sensitivity. Coordinates can hardly depict the local shapes of 3D point clouds. RepSurf should be eligible to intuitively highlight edges and local shapes. An illustration is shown in <ref type="figure">Fig. 3</ref>. </p><formula xml:id="formula_4">v i = (a i , b i , c i ) and a point x i = (x i , y i , z i ),</formula><p>the surface can be defined as:</p><formula xml:id="formula_5">a i (x ? x i ) + b i (y ? y i ) + c i (z ? z i ) = 0 ? a i x + b i y + c i z ? (a i x i + b i y i + c i z i ) = 0.<label>(5)</label></formula><p>We define the surface position as</p><formula xml:id="formula_6">p i = a i x i + b i y i + c i z i , with the range of [? ? 3r, ? 3r]</formula><p>. r means the edge length of a cube exactly covering the point set. For example, we utilize the normalized point clouds within the range of [?1, 1] as input, so r = 1 here. Note that p i can also express the directed distance between the origin and the surface. Then, we compute v i by cross product. However, the computed v i is unoriented -v i can be pointing either inside or outside of the surface. To handle this problem, prior works <ref type="bibr" target="#b1">[2]</ref> adopt some time-costing methods. Considering efficiency, we simplify this case by keeping a i positive and augmenting the normals by instance-level random inverse with a probability of 50%. Thus, we define Triangular RepSurf as:</p><formula xml:id="formula_7">t i = (a i , b i , c i , p i ) .<label>(6)</label></formula><p>We define a set of Triangular RepSurf as T = {t 1 , . . . , t n } ? R N ?4 . To feed point clouds into models, we replace X with our re-computed centroids X ? of the triangles. Then the input can be the concatenation of X ? and T. A simple illustration and the implementation of Triangular RepSurf is presented in <ref type="figure" target="#fig_1">Fig. 1</ref> and Algorithm 1, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Umbrella RepSurf</head><p>Triangular RepSurf is a lightweight method to represent the local geometry of a point cloud. However, due to limited perceptive field, it may also lead to unstable local representations. To handle this drawback, we expand the perceptive field by proposing Umbrella RepSurf inspired by umbrella curvature <ref type="bibr" target="#b9">[10]</ref>. Denote the number of neighbors as K, the centroids and triangular features of the neighbor triangles as</p><formula xml:id="formula_8">X ? i = {x ? i1 , . . . , x ? iK } ? R K?3 and T i = {t i1 , . . . , t iK } ? R K?4 .</formula><p>In <ref type="bibr" target="#b9">[10]</ref>, the unsigned scalar of umbrella curvature is defined as:</p><formula xml:id="formula_9">u i = K j n ij = K j x ? ij x ? ij ? n i ,<label>(7)</label></formula><p>where n i is the given normal vector of the i-th point. However, n i is commonly unknown in the point set X. This makes umbrella curvature unpractical in the real scenes. Furthermore, we argue that a scalar curvature cannot fully express the local geometry. In this case, we propose Umbrella RepSurf to express the local geometry without any given normals. Moreover, different from umbrella curvature which is defined based on homogeneous neighbors, our Umbrella RepSurf can handle heterogeneous neighbors for its position sensitivity. An illustration is shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. The Umbrella RepSurf u i of point x i is defined as:</p><formula xml:id="formula_10">u i = A T [x ? ij , t ij ] , ?j ? {1, . . . , K} ,<label>(8)</label></formula><p>where A is an aggregation function (i.e., summation), T is a transformation function, and x ? ij is the normalized coordinate according to its centroid x i . To calculate t i? , we construct adjacent triangles counterclockwise from 0 ? (xaxis) to 359 ? on the xy-plane. Thus, the number of triangles in a umbrella surface is exactly K. Note that, to keep local consistency of the normals' orientation, we compute these normals by counterclockwise cross product. (An example when reconstructing a umbrella surface unorderedly in <ref type="figure" target="#fig_3">Fig. 4</ref>.) To simplify the definition of the global normals' orientation, different from Triangular RepSurf, we keep a i1 of t i1 positive and the orientation of other normals changes accordingly. Therefore, though the orientation is consistent locally, the normals can be unoriented from a global perspective. Similar to Triangular RepSurf, we augment the normals of an umbrella surface n i? by random inverse. Instead of a predefined transformation function, we adopt a learnable function (a combination of linear functions and non-linearity) for T . The implementation of Umbrella Rep-Surf is shown in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Implementation</head><p>We implement our RepSurf on the single-scale grouping (SSG) version of PointNet++ <ref type="bibr" target="#b41">[42]</ref> in a simple manner of concatenation. For each set abstraction, we input RepSurf along with point features. An illustration of the input flow is shown in <ref type="figure" target="#fig_4">Fig. 5</ref>. Furthermore, we propose two designs to further improve our RepSurf.</p><p>Polar auxiliary. For simplicity, previous point-based models widely adopt Cartesian coordinates as input. However, they cannot fully express the relationships between a centroid and its neighbors. Unlike Cartesian coordinate system, the polar coordinate systems present a point coordinate by distance and angles according to the origin. The polar systems (i.e., Spherical system, Cylindrical system) can be a supplement for its distance and direction sensitivity. In this paper, we explore a practical application of the polar systems for point-based models. We take Spherical system as an example. After querying the neighbors of a point x i , we re-define the position of the j-th neighbor by including its spherical position:</p><formula xml:id="formula_11">x ? ij = (x ? ij , y ? ij , z ? ij , ? ij , ? ij , ? ij ),<label>(9)</label></formula><p>where x ? ij , y ? ij , z ? ij are the values of three dimensions of the normalized Cartesian coordinate.</p><formula xml:id="formula_12">? ij = x ?2 ij + y ?2 ij + z ?2 ij , ? ij = arccos z ? ij ?ij , ? ij = atan2(y ? ij , x ? ij )</formula><p>. For more details of the implementation on polar auxiliary, please refer to the supplementary material.</p><p>Channel de-differentiation. Inspired by <ref type="bibr" target="#b67">[68]</ref>, we observe that different types of inputs (i.e., coordinate, normal vectors, point features) have significant differences in data distribution. In order to process different inputs equally and to train our models stably, we explore solutions for dedifferentiation along the channel dimension. In this paper, we apply Post-CD (performing batch normalization after linear function) to our method. For more details of the implementation on channel de-differentiation, please refer to the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We evaluate both of our Triangular RepSurf and Umbrella RepSurf on three main tasks: classification, segmentation, and detection. Furthermore, we conduct ablation studies to assess the effectiveness of our designed modules. Please refer to the supplementary material for more experimental details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Classification</head><p>3D object classification is a basic task to prove the effectiveness of methods. We perform experiments on Mod-elNet40 <ref type="bibr" target="#b58">[59]</ref>, a human-made object dataset, and ScanOb-jectNN <ref type="bibr" target="#b52">[53]</ref>, a dataset retrieved from the real scenes.</p><p>Human  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Segmentation</head><p>Scene segmentation can be more challenging due to outliers and noise. We evaluate our RepSurf on two large-scale scene datasets, S3DIS <ref type="bibr" target="#b0">[1]</ref> and ScanNet V2 <ref type="bibr" target="#b7">[8]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Detection</head><p>3D detection can further prove the superiority of our method at the application level. We conduct experiments on two widely adopted 3D object detection datasets: Scan-Net V2 <ref type="bibr" target="#b7">[8]</ref> and SUN RGB-D <ref type="bibr" target="#b46">[47]</ref>. We adopt a powerful method <ref type="bibr" target="#b31">[32]</ref> for pipeline and replace the backbone with our RepSurf to perform all experiments on this task. Our experiments are mainly based on the codebase 11 of <ref type="bibr" target="#b31">[32]</ref> as well.</p><p>Detection on ScanNet. ScanNet V2 <ref type="bibr" target="#b7">[8]</ref> can be adopted for 3D detection as well, consisting of 1513 indoor scenes and 18 object classes. We follow the standard evaluation protocol in <ref type="bibr" target="#b37">[38]</ref> by utilizing mean Average Precision under the thresholds of 0.25 (mAP@0.25) and 0.5 (mAP@0.5), without considering the orientation of bounding boxes. As shown in Tab. 3, with almost no increase in computational cost (?0.01M parameters and ?1ms inference speed), our RepSur-U boosts the performance of previous state-of-theart <ref type="bibr" target="#b31">[32]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation study</head><p>We ablate some vital designs of our method on Model-Net40 for an insightful exploration.</p><p>Types of RepSurf. Shown in Tab. 4, we compare different types of input (given normals, RepSurf-T, RepSurf-U). We further discuss on when to compute RepSurf. Regularly, we obtain the input point clouds after a process of sampling (i.e., 10000 ? 1024 points). Before this process (precomputed), we will derive RepSurf from high-resolution point clouds, which means RepSurf approximates the cor-  <ref type="table">Table 5</ref>. Ablation study on the design of Umbrella RepSurf block.</p><p>(N: normal vector (ai, bi, ci), P: surface position pi, C: centroid</p><formula xml:id="formula_13">position (x ? ij , y ? ij , z ? ij ), CP: centroid position (x ? ij , y ? ij , z ? ij )</formula><p>with polar auxiliary (?ij, ?ij, ?ij)), #channels: number of input channels, BN: applying batch normalization, bias: applying learnable bias in the first layer, A: aggregation function, #layers: number of MLP layers for mapping, acc.: overall accuracy) responding tangent. However, empirical results show that post-computed works better than pre-computed. We additionally test on the designs of surface position and random inverse, both of which slightly improve RepSurf.</p><p>Design of RepSurf block. Shown in Tab. 5, we explore the design of Umbrella RepSurf in terms of input, transformation function T , and aggregation function A. Empirically, a combination of normal vector, surface position, normalized coordinate and the corresponding polar coordinates outperforms other combinations. Furthermore, prohibition of batch norm, usage of bias for the first layer, sum-pooling, and three-layer MLP perform better than other options.</p><p>Group size. We explore the group size of Umbrella We test the speed of Umbrella RepSurf block only. When k=2, Umbrella RepSurf will degenerate to a learnable version of Triangular RepSurf. There is almost no difference in speed when k is in the range of <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12]</ref>. For a trade-off between performance and speed, we consider k=8 an ideal choice. Furthermore, when we study on larger group sizes (i.e., 24), a vanishing gradient problem exists. We argue that larger umbrella surfaces may become more indistinguishable and lead to the problem, but this is still an open issue.</p><p>Polar auxiliary. We study on the design of our polar auxiliary in different versions: Here ?, a part of spherical polar auxiliary, means the distance between a centroid and its neighbors. We discuss that <ref type="figure">Figure 6</ref>. Bad case of a reconstructed umbrella surface when the neighbors are extremely messy.</p><formula xml:id="formula_14">PN2</formula><p>Spherical system can better express the geometric relations between the centroids and their neighbors, an auxiliary of Cartesian system. Empirical results verify this hypothesis.</p><p>Channel Here Pre-CD means that batch normalization performs before linear function, and Post-CD is the opposite. We argue Post-CD performs better than Pre-CD, since Pre-CD may blur the original semantics of external input (i.e., coordinates, RepSurf features).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>Limitation. Though simple and effective, RepSurf may suffer from noises while surface reconstruction due to the noise-sensitive algorithm kNN. Furthermore, we argue that Umbrella RepSurf may be vulnerable to extremely messy points. Thus, when we query more neighbors of a point, in general the distribution of its neighbors would become messy and results in a distorted surface. An example of bad case is shown in <ref type="figure">Fig. 6</ref>.</p><p>Conclusion. We present two variants of RepSurf, Triangular and Umbrella RepSurf, to explore the surface representation on point clouds. We evaluate our simple baseline on various tasks, including shape classification, scene segmentation and detection. The evaluation results show its astonishing efficiency and performance, superior to the previous state-of-the-art on different benchmarks.</p><p>We hope our work can inspire the community and evoke the rethinking on the explicit representation of point clouds. We believe that RepSurf deserves further exploration for different fields (i.e., autonomous driving) or on larger-scale point clouds, since RepSurf is eligible to handle numerous background points in the real scenes. RepSurf may also be helpful for point cloud sampling by its ability on geometry sensitivity. It would be worthy of solving the above limitations of RepSurf as well. <ref type="figure">Figure 7</ref>. An example of the distributions of the mapped cooridnates (second-half channels, e.g., 64?128 for the left images) and the mapped features (first-half channels, e.g., 0?64 for the left images) before element-wise summation during matrix multiplication in the first layer of each stage. For an obvious comparison, we put these two modalities together in each plot, which does not mean that we perform concatenation in our CD. Note that, for the first layer of each stage, PointNet++ w/o CD performs BN after the summation of the mapped coordinates and features (the status like the above three images), while PointNet++ w/ CD performs BN before the summation (the status like the below three images). The problem of distribution imbalance will weaken the importance of one of the two kinds of input, and CD can alleviate this problem in a simple manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Details of Channel De-differentiation</head><p>We propose channel de-differentiation to handle the obvious distribution imbalance between the maaped cooridnates and the mapped last-stage features in each stage of set abstraction (SA) in a PointNet++ <ref type="bibr" target="#b41">[42]</ref> model. An illustration is shown in <ref type="figure">Fig. 7</ref>. This may lead to an ignorance of the input of coordinates in the last few layers of MLPs. We consider this is mainly caused by the difference of the distributions of various types of input (like coordinates and high-level features).</p><p>Intuitively, we adopt batch normalization to alleviate the difference of these distributions. In the first MLP of each SA, the fused feature f 1 i of the i-th point can be rewrite as:</p><formula xml:id="formula_15">f 1 i = ? 1 ([x i , f i ]) = ? 1 x (x i ) + ? 1 f (f i ),<label>(13)</label></formula><p>where ? 1 is a linear function, the concatenation of the weights of ? 1</p><p>x and ? 1 f equals to the weights of ? 1 .</p><p>x i and f i corresponds to the coordinate and the high-level feature from the last stage of the i-th point, respectively.</p><p>Commonly, when we add the normalization and nonlinearity to this formula, the feature can be presented as:</p><formula xml:id="formula_16">f 1 i = ReLU (BatchN orm(? 1 x (x i ) + ? 1 f (f i ))).<label>(14)</label></formula><p>Empirically, the point-based models benefit from separate application of batch normalization to x i and f i as follows:</p><formula xml:id="formula_17">f 1 i = ReLU (BatchN orm x (? 1 x (x i ))+ BatchN orm f (? 1 f (f i ))).<label>(15)</label></formula><p>This tiny modification can significantly boost the performance of point-based models as well. For our RepSurf, x i may contain polar coordinates, and f i may be the features of RepSurf, RGB information. An illustration of our Channel De-differentiation is shown in <ref type="figure" target="#fig_5">Fig. 8</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Computation of FLOPs</head><p>To explore the efficiency of various models, we adopt the same formulas of complexity for the calculation of FLOPs. Since prior works are based on different versions of CUDA point cloud operations or non-CUDA ones, it may lead to an unfair comparison of efficiency based on FLOPs. Therefore, we treat the point cloud operations, including farthest point sampling, indexing, ball querying, knn querying, the same for the final estimation of FLOPs of different models. Following the common rules of FLOPs calculation, We count for the addition and multiplication of float points only.</p><p>For other basic operations, such as Convolution, ReLU, MLP, we adopt the default settings of THOP 2 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Computation of Speed</head><p>We test all methods with one V100 GPU and four cores Intel Xeon @ 2.50GHz CPU. The speed may vary with different sizes of input due to the parallelism of GPU. In this case, we set the batch size to 16 for all methods on the tasks of classification and segmentation. For detection, we set the batch size to 1 on the same experimental workstation in <ref type="bibr" target="#b31">[32]</ref>.</p><p>The FLOPs of one model can present the efficiency radically and theoretically. For an overall view of the efficiency, we adopt the practical method by testing the speed during the process of training and inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Implementation details</head><p>Classification. We implement Triangular and Umbrella RepSurf on PointNet++ <ref type="bibr" target="#b41">[42]</ref> (SSG version). For both the datasets of ModelNet and ScanObjectNN, we set the initial learning rate to 0.001 with a decay rate of 0.7 for every 20 iterations. We use Adam for optimization. We apply data augmentation (including random scale, random shift, random dropout) when training on ModelNet, while we do not apply any augmentation methods for ScanObjectNN. Considering the quality of surface reconstruction, we sample 1024 points with farthest point sampling (FPS) method before input. We normalize the point clouds into the range of [?1, 1] for ModelNet. We apply label smoothing with a ratio of 0.1.</p><p>Segmentation. We implement RepSurf on PointNet++ <ref type="bibr" target="#b41">[42]</ref> (SSG segmentation version). For both the datasets of S3DIS and ScanNet, we set the initial learning rate to 0.5, with a decay rate of 0.1 on the 60th and 80th iteration. We use SGD, with a weight decay of 1e ?4 for optimization. We apply data augmentation (including point cloud scaling, color contrasting, color shifting, and color jittering) when training on S3DIS and ScanNet. Considering the quality of surface reconstruction, we sample points with grid sampling method before input. We weight the loss with the ratio of classes.</p><p>Detection. We implement RepSurf on ScanNet V2 and SUN RGB-D following the practice of GroupFree <ref type="bibr" target="#b31">[32]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Detailed Experimental Results</head><p>We reveal the details of detection on the datasets of Scan-Net V2 (mAP@0.25 in Tab. 6 and mAP@0.5 in Tab. 7) and SUN RGB-D (mAP@0.25 in Tab. 8 and mAP@0.5 in Tab. 9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Visualization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.1. Surface Reconstruction of RepSurf</head><p>We visualize the results after the process of surface reconstruction in <ref type="figure" target="#fig_6">Fig. 9</ref>. Different from prior methods, we only need to reconstruct discrete surfaces before calculating the features of Triangular and Umbrella RepSurf.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.2. Geometry Sensitivity on Triangular RepSurf</head><p>We visualize the output of each channel of Triangular RepSurf on ScanObjectNN in <ref type="figure" target="#fig_1">Fig 10.</ref> Triangular RepSurf is eligible to perceive the local geometries numerically. Thus, <ref type="figure" target="#fig_1">Figure 10</ref>. Visualization of the values of 3 channels from the normal vectors of Triangular RepSurf. the points on a flat shape have similar color, while the color of points on an edge changes obviously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.3. Geometry Sensitivity on Umbrella RepSurf</head><p>We visualize the output of each channel of Umbrella RepSurf on ScanObjectNN in <ref type="figure" target="#fig_1">Fig 11.</ref> Intuitively, Umbrella RepSurf can recognize the local geometries, including the edges and the planes of objects. <ref type="figure" target="#fig_1">Figure 11</ref>. Visualization of the values of 10 channels from Umbrella RepSurf.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Local shape representation of a 2D curve (left) and a 3D surface (right) through the corresponding tangents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1</head><label>1</label><figDesc>Pytorch-Style Pseudocode of Triangular RepSurf # B: batch size, N: number of points # points: coordinates of a point set pairs = kNN(points, k=2)-points # [B,N,2,3] centroids = mean(pairs, dim=2) # [B,N,3] normals = cross_product(pairs) # [B,N,3] normals = normals/norm(normals, dim=-1) # [B,N,3] pos_mask = (normals[..., 0]&gt;0) * 2-1 # [B,N,1] normals = normals * pos_mask # [B,N,3] normals = random_inverse(normals) # [B,N,3] positions = sum(normals * centroids, dim=2)/sqrt(3) # [B,N,1] out = concat([centroids, normals, positions], dim=2) # [B,N,7] return out3.3. Triangular RepSurfDenote a point set as X = {x 1 , . . . , x n } ? R N ?3 . Analogous to a 2D curve in Sec 3.1, we define a 3D tangent surface(Fig. 2 right)by point-normal equation. Given a normal vector</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 2</head><label>2</label><figDesc>Pytorch-Style Pseudocode of Umbrella RepSurf # B: batch size, N: number of points # K: number of neighbors, C: output channels # points: coordinates of a point set neighbors = kNN(points, k=K)-points # [B,N,K,3] edges = sort_by_clock(neighbors) # [B,N,K,3] edges = unsqueeze(neighbors, dim=-2) # [B,N,K,1,3] pairs = concat([edges, edges.roll(-1, 2)], dim=-2) # [B,N,K,2,3] centroids = mean(pairs, dim=3) # [B,N,K,3] normals = cross_product(pairs) # [B,N,K,3] normals = normals/norm(normals, dim=-1) # [B,N,K,3] pos_mask = (normals[..., 0, 0]&gt;0) * 2-1 # [B,N,1,1] normals = normals * pos_mask # [B,N,K,3] normals = random_inverse(normals) # [B,N,K,3] positions = sum(normals * centroids, dim=3)/sqrt(3) # [B,N,K,1] features = concat([centroids, normals, positions], dim=2) # [B,N,K,7] features = MLPs(features, out_channel=C) #[B,N,K,C] features = pooling(features, dim=2) # [B,N,C] out = concat([centroids, features], dim=2) # [B,N,3+C] return out</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Examples of reconstructed umbrella surfaces. We present each surface with a regular view (above) and a top view (below). From left to right, we show two surfaces reconstructed from homogeneous neighbors, one from heterogeneous neighbors, and one reconstructed without sorting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>An overview of the input flow of RepSurf on Point-Net++ for classification. xi, ti, ui are the coordinate, Triangular RepSurf, Umbrella RepSurf of the i-th point of input, respectively. f 1 i , f 2 i , f 3 i are the i-th output feature of the first, second, third set abstraction (SA), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Illustration of our Channel De-differentiation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Visualization of surface reconstruction for RepSurf.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>-made Object Classification. ModelNet40<ref type="bibr" target="#b58">[59]</ref> contains 9843 training models and 2468 test models, divided into 40 categories. In Tab. 1, we compare our Triangular RepSurf (RepSurf-T) and Umbrella RepSurf (RepSurf-U) with prior methods. Equipped with RepSurf-T and RepSurf-U, the performance of PointNet++ (SSG version) is considerably boosted by 3.7% and 4.1%. For a fair comparison with other methods<ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b62">63]</ref>, we apply the strategy of multi-scale inference from<ref type="bibr" target="#b29">[30]</ref> for further improvement. Though the results on ModelNet40 tend to be saturated, our RepSurf-U achieves 94.7%, surpassing Cur-veNet<ref type="bibr" target="#b59">[60]</ref> by a large margin of 0.5%. In addition, RepSurf-U is 5.4? and 4.0? faster than CurveNet in terms of training and inference speed, respectively.Real-world Object Classification. For the saturation of ModelNet40, we further verify our RepSurf on the hardest variant (PB T50 RS variant) of ScanObjectNN<ref type="bibr" target="#b58">[59]</ref>, a Performance of classification on ModelNet40 and ScanObjectNN. We evaluate different methods in terms of overall accuracy (OA, %), mean per-class accuracy (mAcc, %), number of parameters (#Params), FLOPs, training speed (duration per input sample), and inference speed (duration per input sample). We consider OA the principle evaluation metric. Bold means the result outperforms prior state-of-the-art method on corresponding dataset. Green means an improvement from our RepSurf compared with the original model. We test the speed of all methods with one NVIDIA Tesla V100 GPU and four cores of Intel Xeon @2.50GHz CPU. The batch size is set to 16.</figDesc><table><row><cell>Method</cell><cell>Input</cell><cell></cell><cell cols="2">ModelNet40 OA mAcc</cell><cell cols="3">ScanObjectNN OA mAcc</cell><cell cols="2">#Params FLOPs</cell><cell>Train Speed</cell><cell>Infer Speed</cell></row><row><cell>PointNet [40]</cell><cell>1k pnts</cell><cell></cell><cell>89.2</cell><cell>86.0</cell><cell>68.2</cell><cell></cell><cell>63.4</cell><cell cols="3">3.47M 0.45G 1.76ms 0.81ms</cell></row><row><cell>DGCNN [57]</cell><cell>1k pnts</cell><cell></cell><cell>92.9</cell><cell>90.2</cell><cell>78.1</cell><cell></cell><cell>73.6</cell><cell cols="2">1.82M 2.43G</cell><cell>-</cell><cell>-</cell></row><row><cell>RS-CNN  ? [30]</cell><cell>1k pnts</cell><cell></cell><cell>93.6</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell cols="2">2.38M 1.16G</cell><cell>-</cell><cell>-</cell></row><row><cell>KPConv [52]</cell><cell>?7k pnts</cell><cell></cell><cell>92.9</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell>14.3M</cell><cell>-</cell><cell>218.7ms 543.7ms</cell></row><row><cell>PointASNL [66]</cell><cell>1k pnts  *</cell><cell></cell><cell>93.2</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell cols="2">10.1M 1.80G</cell><cell>-</cell><cell>-</cell></row><row><cell>Grid-GCN [64]</cell><cell>1k pnts  *</cell><cell></cell><cell>93.1</cell><cell>91.3</cell><cell>-</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>42.20ms</cell></row><row><cell>PointTrans. [73]</cell><cell>1k pnts  *</cell><cell></cell><cell>93.7</cell><cell>90.6</cell><cell>-</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MVTN [15]</cell><cell>multi-view</cell><cell></cell><cell>93.8</cell><cell>92.0</cell><cell>82.8</cell><cell></cell><cell>-</cell><cell cols="2">4.24M 1.78G</cell><cell>-</cell><cell>-</cell></row><row><cell>PAConv  ? [60]</cell><cell>1k pnts</cell><cell></cell><cell>93.9</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell cols="2">2.44M 1.68G</cell><cell>-</cell><cell>-</cell></row><row><cell>RPNet [43]</cell><cell>1k pnts  *</cell><cell></cell><cell>94.1</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell cols="2">2.70M 3.90G</cell><cell>-</cell><cell>-</cell></row><row><cell>CurveNet  ? [60]</cell><cell>1k pnts</cell><cell></cell><cell>94.2</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell cols="3">2.14M 0.66G 22.04ms 12.34ms</cell></row><row><cell>PointNet++  ? [42]</cell><cell>1k pnts</cell><cell></cell><cell>90.7</cell><cell>88.4</cell><cell>77.9</cell><cell></cell><cell>75.4</cell><cell cols="3">1.475M 0.77G 2.75ms 1.98ms</cell></row><row><cell>RepSurf-T (ours)</cell><cell>1k pnts</cell><cell></cell><cell>94.0 ?3.3</cell><cell>91.1 ?2.7</cell><cell cols="2">84.1 ?6.2</cell><cell cols="4">81.2 ?5.8 1.479M 0.79G 3.33ms 2.47ms</cell></row><row><cell>RepSurf-T  ? (ours)</cell><cell>1k pnts</cell><cell></cell><cell>94.2 ?3.5</cell><cell>91.3 ?2.9</cell><cell cols="2">84.3 ?6.4</cell><cell cols="4">81.6 ?6.2 1.479M 0.79G 3.33ms 2.47ms</cell></row><row><cell>RepSurf-U (ours)</cell><cell>1k pnts</cell><cell></cell><cell>94.4 ?3.7</cell><cell>91.4 ?3.0</cell><cell cols="2">84.3 ?6.4</cell><cell cols="4">81.3 ?5.9 1.483M 0.81G 4.08ms 3.10ms</cell></row><row><cell>RepSurf-U  ? (ours)</cell><cell>1k pnts</cell><cell></cell><cell>94.7 ?4.0</cell><cell>91.7 ?3.3</cell><cell cols="2">84.6 ?6.7</cell><cell cols="4">81.9 ?6.5 1.483M 0.81G 4.08ms 3.10ms</cell></row><row><cell cols="2">RepSurf-U  ?? (ours) 1k pnts</cell><cell></cell><cell>-</cell><cell>-</cell><cell>86.0</cell><cell></cell><cell>83.1</cell><cell cols="2">6.806M 2.43G</cell><cell>-</cell><cell>-</cell></row><row><cell>Method</cell><cell>mIoU</cell><cell cols="2">S3DIS 6-fold mAcc</cell><cell>OA</cell><cell>mIoU</cell><cell cols="2">S3DIS Area-5 mAcc</cell><cell>OA</cell><cell cols="2">ScanNet #Params FLOPs mIoU</cell></row><row><cell>PointNet [40]</cell><cell>47.6</cell><cell></cell><cell>66.2</cell><cell>78.5</cell><cell>41.1</cell><cell></cell><cell>48.9</cell><cell>-</cell><cell>-</cell><cell>1.7M 4.1G</cell></row><row><cell>PointWeb [72]</cell><cell>66.7</cell><cell></cell><cell>76.2</cell><cell>87.3</cell><cell>60.2</cell><cell></cell><cell>66.6</cell><cell>86.9</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>KPConv [52]</cell><cell>70.6</cell><cell></cell><cell>79.1</cell><cell>-</cell><cell>67.1</cell><cell></cell><cell>72.8</cell><cell>-</cell><cell>68.4</cell><cell>14.9M</cell><cell>-</cell></row><row><cell>PointASNL [66]</cell><cell>68.7</cell><cell></cell><cell>79.0</cell><cell>88.8</cell><cell>62.6</cell><cell></cell><cell>68.5</cell><cell>87.7</cell><cell>63.0</cell><cell>22.4M 19.1G</cell></row><row><cell>PAConv [60]</cell><cell>69.3</cell><cell></cell><cell>78.6</cell><cell>-</cell><cell>66.5</cell><cell></cell><cell>73.0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1.3G</cell></row><row><cell>RPNet [43]</cell><cell>70.8</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell>-</cell><cell>68.2</cell><cell>2.4M 5.1G</cell></row><row><cell>PointTrans. [73]</cell><cell>73.5</cell><cell></cell><cell>81.9</cell><cell>90.2</cell><cell>70.4</cell><cell></cell><cell>76.5</cell><cell>90.8</cell><cell>-</cell><cell>4.9M 2.8G</cell></row><row><cell>PointNet++  ? [42]</cell><cell>59.9</cell><cell></cell><cell>66.1</cell><cell>87.5</cell><cell>56.0</cell><cell></cell><cell>61.2</cell><cell>86.4</cell><cell>-</cell><cell>0.969M 1.00G</cell></row><row><cell>RepSurf-U (ours)</cell><cell cols="2">74.3?14.4</cell><cell>82.6?16.5</cell><cell>90.8?3.3</cell><cell cols="2">68.9?12.9</cell><cell>76.0?14.8</cell><cell>90.</cell><cell></cell></row></table><note>?: single-scale grouping (SSG) version, ?: multi-scale inference from [30], * : w/ normal vector, ?: PointNet++ (SSG) with double channels and deeper networks.2?3.8 70.0 0.976M 1.04G ?: single-scale grouping (SSG) version, * : w/ normal vector.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Bold means the result outperforms prior state-of-the-art method on corresponding dataset. Green means an improvement from our RepSurf compared with the previous reported results of the original model.</figDesc><table><row><cell>more challenging dataset considering occlusion and back-</cell></row><row><cell>ground. It is composed of 2902 point clouds categorized</cell></row><row><cell>into 15 classes. In Tab. 1, our RepSurf-T and RepSurf-U</cell></row><row><cell>achieve 84.3% and 84.6%, outperforming prior state-of-the-</cell></row><row><cell>art MVTN [15] by 1.5% and 1.8%, with around 1.8? fewer</cell></row><row><cell>parameters and 1.2? fewer FLOPs.</cell></row></table><note>Performance of semantic segmentation on S3DIS (evaluation by 6-fold or on Area 5) and ScanNet V2. We evaluate different methods in terms of mean per-class IoU (mIoU, %), mean per-class accuracy (mAcc, %), overall point accuracy (OA, %), number of parameters (#Params), and FLOPs.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Semantic Segmentation on S3DIS. S3DIS<ref type="bibr" target="#b0">[1]</ref> contains 271 scenes from 6 indoor areas. Each point is categorized into 13 types of semantic labels. In Tab. 2, we evaluate our RepSurf on S3DIS by 6-fold and on Area-5. Our RepSurf-U significantly improves PointNet++ by 14.4% mIoU and 12.9% mIoU on S3DIS 6-fold and S3DIS Area-5, respectively. Furthermore, our RepSur-U outperforms previous state-of-the-art, Point Transformer<ref type="bibr" target="#b72">[73]</ref> by 0.8% mIoU on S3DIS 6-fold, and achieves comparable performance on S3DIS Area-5 as well. Simultaneously, our RepSurf-U has 4.0? fewer parameters and 1.7? fewer FLOPs with a com-</figDesc><table><row><cell>Method</cell><cell>Backbone</cell><cell cols="2">ScanNetV2 mAP@0.25 mAP@0.5</cell><cell cols="2">SUN RGB-D mAP@0.25 mAP@0.5</cell><cell>#Params</cell><cell>Infer Speed</cell></row><row><cell>VoteNet [38]</cell><cell>PointNet++</cell><cell>62.9</cell><cell>39.9</cell><cell>59.1</cell><cell>35.8</cell><cell>-</cell><cell>-</cell></row><row><cell>ImVoteNet [37]</cell><cell>PointNet++</cell><cell>-</cell><cell>-</cell><cell>63.4  *</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>H3DNet [71]</cell><cell>PointNet++</cell><cell>64.4</cell><cell>43.4</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>H3DNet [71]</cell><cell>4?PointNet++</cell><cell>67.2</cell><cell>48.1</cell><cell>60.1</cell><cell>39.0</cell><cell>-</cell><cell>266ms</cell></row><row><cell>3DETR [34]</cell><cell>Transformer</cell><cell>65.0</cell><cell>47.0</cell><cell>59.1</cell><cell>32.7</cell><cell>-</cell><cell>-</cell></row><row><cell>BRNet [6]</cell><cell>PointNet++</cell><cell>66.1</cell><cell>50.9</cell><cell>61.1</cell><cell>43.7</cell><cell>-</cell><cell>-</cell></row><row><cell>GroupFree 6,256</cell><cell>PointNet++</cell><cell>67.3</cell><cell>48.9</cell><cell>63.0</cell><cell>45.2</cell><cell>11.49M</cell><cell>149ms</cell></row><row><cell>GroupFree 6,256</cell><cell>RepSurf-T</cell><cell>68.4 ?1.1</cell><cell>50.3 ?0.4</cell><cell>63.9 ?0.9</cell><cell>45.6 ?0.4</cell><cell>11.50M</cell><cell>149ms</cell></row><row><cell>GroupFree 6,256</cell><cell>RepSurf-U</cell><cell>68.8 ?1.5</cell><cell>50.5 ?0.6</cell><cell>64.3 ?1.3</cell><cell>45.9 ?0.7</cell><cell>11.50M</cell><cell>150ms</cell></row><row><cell>GroupFree 12,512</cell><cell>PointNet++ 2</cell><cell>69.1</cell><cell>52.8</cell><cell>-</cell><cell>-</cell><cell>23.60M</cell><cell>193ms</cell></row><row><cell>GroupFree 12,512</cell><cell>RepSurf-T 2</cell><cell>70.4 ?1.3</cell><cell>54.6 ?1.8</cell><cell>64.2</cell><cell>47.1</cell><cell>23.60M</cell><cell>194ms</cell></row><row><cell>GroupFree 12,512</cell><cell>RepSurf-U 2</cell><cell>71.2 ?2.1</cell><cell>54.8 ?2.0</cell><cell>64.9</cell><cell>47.7</cell><cell>23.61M</cell><cell>195ms</cell></row><row><cell cols="8">* : w/ RGB as input, Model 2 : Model with doubled channels for each MLP, 4?PointNet++: four individual PointNet++ (SSG) in [71], GroupFree a,b :</cell></row><row><cell cols="4">GroupFree model [32] with a a-layer decoder and b object candidates.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Performance of object detection on ScanNet V2 and SUN RGB-D. We evaluate different methods in terms of mAP@0.25, mAP@0.5, number of parameters (#Params), and inference speed (duration per input sample). Bold means the result outperforms prior state-of-the-art method on corresponding dataset. Green means an improvement from our RepSurf compared with the original model. We test the speed of all methods with one NVIDIA Titan-XP GPU and four cores of Intel Xeon @2.50GHz CPU. parison of Point Transformer. Semantic Segmentation on ScanNet. ScanNet V2 [8] consists of 1513 indoor training point clouds and 100 test point clouds. It marks each point with 21 categories. In Tab. 2, the performance of RepSurf-U exceeds prior stateof-the-art KPConv [52] by 1.6%. Moreover, our method has 14.3? fewer parameters compared with KPConv.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>by 2.1% mAP@0.25 and 2.0% mAP@0.25.</figDesc><table><row><cell>type</cell><cell cols="3">X -computed w/ p i w/ inverse</cell><cell>acc.</cell></row><row><cell>given</cell><cell>-</cell><cell>?</cell><cell>?</cell><cell>94.08</cell></row><row><cell>given</cell><cell>-</cell><cell>?</cell><cell>?</cell><cell>93.39</cell></row><row><cell>given</cell><cell>-</cell><cell>?</cell><cell>?</cell><cell>93.95</cell></row><row><cell>triangular</cell><cell>pre</cell><cell>?</cell><cell>?</cell><cell>93.57</cell></row><row><cell>triangular</cell><cell>post</cell><cell>?</cell><cell>?</cell><cell>93.62</cell></row><row><cell>triangular</cell><cell>post</cell><cell>?</cell><cell>?</cell><cell>94.02</cell></row><row><cell>umbrella</cell><cell>pre</cell><cell>?</cell><cell>?</cell><cell>93.06</cell></row><row><cell>umbrella</cell><cell>post</cell><cell>?</cell><cell>?</cell><cell>93.90</cell></row><row><cell>umbrella</cell><cell>post</cell><cell>?</cell><cell>?</cell><cell>94.46</cell></row><row><cell cols="5">Table 4. Ablation study on the types of RepSurf. (given: normal</cell></row><row><cell cols="5">vectors given from the dataset, triangular: Triangular RepSurf,</cell></row><row><cell cols="5">umbrella: Umbrella RepSurf, X -computed: computing RepSurf</cell></row><row><cell cols="5">before (pre-computed) or after (post-computed) sampling, w/ pi:</cell></row><row><cell cols="5">with surface position pi input, w/ inverse: augmenting RepSurf by</cell></row><row><cell cols="3">random inverse, acc.: overall accuracy)</cell><cell></cell><cell></cell></row><row><cell cols="5">U improves GroupFree 6,256 ( [32] with a 6-layer en-</cell></row><row><cell cols="5">coder and 256 object candidates) by 1.3% mAP@0.25 and</cell></row><row><cell cols="5">0.7% mAP@0.5. Without RGB as input, GroupFree 12,512</cell></row><row><cell cols="5">equipped with RepSurf-U even outperforms prior state-of-</cell></row><row><cell cols="4">the-art ImVoteNet [37] by 1.5% mAP@0.25.</cell><cell></cell></row><row><cell>Detection on SUN RGB-D. SUN RGB-D [47] is a</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>single-view RGB-D dataset for 3D scene analysis, includ-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ing around 5K indoor RGB and depth images. Follow-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ing [38], we adopt mean Average Precision on 10 most</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>common categories for evaluation. In Tab. 3, RepSurf-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>11 https://github.com/zeliu98/Group-Free-3D</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>?0.15 93.89 ?0.08 94.46 ?0.49</figDesc><table><row><cell>w/o aux.</cell><cell>w/ ?</cell><cell>w/ cylinder w/ sphere</cell></row><row><cell cols="2">acc. 93.97 94.12</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>?0.36 94.08 ?0.93 triangular 93.22 92.49 ?0.73 94.02 ?0.80 umbrella 93.50 92.63 ?0.87 94.46 ?0.96</figDesc><table><row><cell cols="4">de-differentiation. We test the design of chan-</cell></row><row><cell cols="4">nel de-differentiation (CD) on three versions of PointNet++,</cell></row><row><cell cols="4">including the original (vanilla), Triangular RepSurf (trian-</cell></row><row><cell cols="3">gular), and Umbrella RepSurf (umbrella):</cell><cell></cell></row><row><cell>PN2</cell><cell>none</cell><cell>Pre-CD</cell><cell>Post-CD</cell></row><row><cell>vanilla</cell><cell cols="2">93.15 92.70</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/Lyken17/pytorch-OpCounter</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Preliminaries: Taylor Series for 2D curves</head><p>Talyor series <ref type="bibr" target="#b50">[51]</ref> on the point (a, f (a)) of curve f (?) presents as follows:</p><p>which can be simplified as:</p><p>where f (n) (a) is the n-th derivative of the curve f (?) at the point (a, f (a)).</p><p>We present the assumption that the formulation of Taylor Series can depict the local curve. Based on this assumption, we further develop an extension to 3D space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Preliminaries: Two-Variate Taylor Series for 3D surfaces</head><p>Taylor Series depending on two variables can be defined as:</p><p>where ?g ?x and ?g ?y are the partial derivatives. This formulation presents two-variant taylor series on point (a, b, g(a, b)) of surface g(?, ?).</p><p>This formulation reveals the basis of RepSurf. To simply the calculation, we consider the terms of the first and second partial derivatives. Triangular RepSurf can be an instantiation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Details of Polar Auxiliary</head><p>We present two types of polar auxiliary, spherical and cylindrical ones based on Spherical Polar System and Cylindrical Polar System, respectively.</p><p>For a given point (x, y, z), spherical polar auxiliary provides the corresponding polar coordinate</p><p>For stable training, we normalize the polar coordinate by ? s divided by ? and ? s divided by 2?. Though ? s has no upper bound in theory, ? s is commonly limited within [0, r], where r is the radius of ball query function <ref type="bibr" target="#b41">[42]</ref>. Furthermore, to prevent the generation of NaN, we set ? s to 0 when ? s is 0. The pseudo-code of spherical polar auxiliary is presented in Algorithm 3.</p><p>Accordingly x 2 + y 2 ? [0, r], ? s = atan2(y, x) ? (??, ?), z c = z ? [?r, r], r is the given radius of ball query function <ref type="bibr" target="#b41">[42]</ref>. Similarly, we normalize ? s and z c into the range of [0, 1]. We implement polar auxiliary by concatenation of the Cartesian coordinate (x, y, z) and (? s , ? s , ? s ) or (? c , ? c , z c ). The pseudo-code of cylindrical polar auxiliary in Algorithm 4.</p><p>Though extremely simple, our design of polar auxiliary is not an incremental method and can be insightful. Polar auxiliary is mainly relied upon the prerequisite that the models learn the local shapes within the queried balls. This prerequisite allows spherical polar coordinate to work with Cartesian coordinate more reasonably. We argue that a Cartesian coordinate is efficient to represent the location of a point numerically according to the origin or the centroid. However, it cannot obviously discriminate the locations of two neighbors. When the two points are very close, Cartesian coordinates show few clues to tell both. In this case, ? s and ? s can intuitively magnify the difference between the two points numerically. Furthermore, ? s is an additional ingredient to express the relationship between a neighbor point and its centroid. Both empirical results and theoretical analysis prove the effectiveness of our design of polar auxiliary.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ioannis Brilakis, Martin Fischer, and Silvio Savarese. 3d semantic parsing of large-scale indoor spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Amir R Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1534" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey of surface reconstruction from point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Tagliasacchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Seversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gael</forename><surname>Alliez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">A</forename><surname>Guennebaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><forename type="middle">T</forename><surname>Sharf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="301" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The ball-pivoting algorithm for surface reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fausto</forename><surname>Bernardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Mittleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holly</forename><surname>Rushmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Taubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="349" to="359" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A hierarchical graph network for 3d object detection on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jintai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biwen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danny</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="392" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-view 3d object detection network for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1907" to="1915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Back-tracing representative points for votingbased 3d object detection in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">4d spatio-temporal convnets: Minkowski convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3075" to="3084" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scannet: Richly-annotated 3d reconstructions of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gvcnn: Group-view convolutional neural networks for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xibin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="264" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Umbrella curvature: a new curvature estimation method for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foorginejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Technology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural implicit embedding for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kent</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taiichi</forename><surname>Hashimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="11734" to="11743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multiresolution tree networks for 3d point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matheus</forename><surname>Gadelha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="103" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">3d semantic segmentation with submanifold sparse convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Engelcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9224" to="9232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-view 3d object retrieval with deep embedding network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyun</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinqiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5526" to="5537" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mvtn: Multi-view transformation network for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdullah</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Giancola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Seqviews2seqlabels: Learning 3d global features via aggregating sequential views by rnn with attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyang</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Man</forename><surname>Vong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Shen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zwicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cl Philip</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="658" to="672" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Monte carlo convolution for learning on non-uniformly sampled point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Hermosilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Ritschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pere-Pau</forename><surname>V?zquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?lvar</forename><surname>Vinacua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Ropinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Randla-net: Efficient semantic segmentation of large-scale point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhai</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11108" to="11117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hierarchical point-edge interaction network for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10433" to="10441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Poisson surface reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Bolitho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth Eurographics symposium on Geometry processing</title>
		<meeting>the fourth Eurographics symposium on Geometry processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Joint 3d proposal generation and object detection from view aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Mozifian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungwook</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Harakeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">L</forename><surname>Waslander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Samplenet: Differentiable point cloud sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itai</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asaf</forename><surname>Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7578" to="7588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Going deeper with lean point networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric-Tuan</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niloy J</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9503" to="9512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pointcnn: Convolution on x-transformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="820" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep continuous fusion for multi-sensor 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="641" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fpconv: Learning local flattening for point convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuguang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4293" to="4302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Convolution in the cloud: Learning deformable kernels in 3d graph convolution networks for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Yu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1800" to="1809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Point2sequence: Learning the shape representation of 3d point clouds with an attention-based sequence to sequence network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Shen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zwicker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8778" to="8785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Densepoint: Learning densely contextual representation for efficient point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5239" to="5248" />
		</imprint>
	</monogr>
	<note>Shiming Xiang, and Chunhong Pan</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Relation-shape convolutional neural network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="8895" to="8904" />
		</imprint>
	</monogr>
	<note>Bin Fan, Shiming Xiang, and Chunhong Pan</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A closer look at local aggregation operators in point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="326" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Group-free 3d object detection via transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.00678</idno>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Voxnet: A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="922" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An end-toend transformer model for 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Girdhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adaptive hierarchical down-sampling for point cloud classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Nezhadarya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Taghavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Razani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12956" to="12964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Differentiable convolution search for point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunlei</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhong</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7437" to="7446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Imvotenet: Boosting 3d object detection in point clouds with image votes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep hough voting for 3d object detection in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Frustum pointnets for 3d object detection from rgbd data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="918" to="927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="652" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Volumetric and multi-view cnns for object classification on 3d data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Nie?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyuan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5648" to="5656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning innergroup relations on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxi</forename><surname>Ran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="15477" to="15487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Octnet: Learning deep 3d representations at high resolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Osman Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3577" to="3586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Pv-rcnn: Pointvoxel feature set abstraction for 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoxu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10529" to="10538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pointrcnn: 3d object proposal generation and detection from point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="770" to="779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Sun rgb-d: A rgb-d scene understanding benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Lichtenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="567" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep sliding shapes for amodal 3d object detection in rgb-d images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="808" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Splatnet: Sparse lattice networks for point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2530" to="2539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Evangelos Kalogerakis, and Erik Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="945" to="953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brook</forename><surname>Taylor</surname></persName>
		</author>
		<title level="m">Methodus incrementorum directa et inversa. Innys, 1717. 1</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Kpconv: Flexible and deformable convolution for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Emmanuel</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatriz</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="6411" to="6420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikaela</forename><forename type="middle">Angelina</forename><surname>Uy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quang-Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binh-Son</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai-Kit</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1588" to="1597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">O-cnn: Octree-based convolutional neural networks for 3d shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Shuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deep parametric continuous convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chiu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Pokrovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2589" to="2597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Transactions On Graphics (tog)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Pointconv: Deep convolutional networks on 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fuxin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9621" to="9630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Walk in the cloud: Learning curves for point clouds shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiange</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Cai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.01288</idno>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Deepshape: Deep-learned shape descriptor for 3d shape retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoxian</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1335" to="1345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Multi-level fusion based 3d object detection from monocular images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2345" to="2353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Paconv: Position adaptive convolution with dynamic kernel assembling on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Grid-gcn for fast and scalable point cloud learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiangeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Ying</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panqu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="5661" to="5670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Spidercnn: Deep learning on point sets with parameterized convolutional filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="87" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Pointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoda</forename><surname>Xu Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Pixor: Realtime 3d object detection from point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7652" to="7660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Cn: Channel normalization for point cloud recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zetong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="600" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Curvature estimation of 3d point cloud surfaces through the fitting of normal section curvatures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongjun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanglin</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of ASIAGRAPH</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="23" to="26" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Shellnet: Efficient point cloud convolutional neural networks using concentric shells statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Binh-Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai-Kit</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1607" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">H3dnet: 3d object detection using hybrid geometric primitives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaiwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Pointweb: Enhancing local neighborhood features for point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Point transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Adaptive graph convolution for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yidan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingqiang</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="4965" to="4974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">methods backbone cab bed chair sofa tabl door wind bkshf pic cntr desk curt fridg showr toil sink bath ofurn mAP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4490" to="4499" />
		</imprint>
	</monogr>
	<note>Voxelnet: End-to-end learning for point cloud based 3d object detection</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">GroupFree</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">256</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">GroupFree</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">256</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">GroupFree</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">52</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Performance of mAP@0.25 for each category on the ScanNet V2 dataset. methods backbone cab bed chair sofa tabl door wind bkshf pic cntr desk curt fridg showr toil sink bath ofurn mAP VoteNet</title>
		<idno>GroupFree 12,512 RepSurf-U 2 54.6 94.0 96.2 90.5 73.2 62.7 55.7 64.5 18.6 60.9</idno>
		<imprint/>
	</monogr>
	<note>1 69.9 49.4 78.4 99.4 74.5 97.6 58.3 71.2 Table 6. 38] PointNet++ 14.6 77.8 73.1 80.5 46.5 25.1 16.0 41.8 2.5 22.3 33.3 25.0 31.0 17.6 87.8 23.0 81.6 18.7 39.9</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">GroupFree</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">256</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">GroupFree</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">256</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">GroupFree</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">57</biblScope>
		</imprint>
	</monogr>
	<note>2 28.5 83.5 84.8 72.6 64.0 43.6 28</note>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
				<title level="m">Performance of mAP@0.5 for each category on the ScanNet V2 dataset</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Performance of mAP@0.5 for each category on the SUN RGB-D validation set</title>
		<imprint/>
	</monogr>
	<note>Table 9</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
