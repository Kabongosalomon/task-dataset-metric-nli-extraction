<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PIDNet: A Real-time Semantic Segmentation Network Inspired from PID Controller</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacong</forename><surname>Xu</surname></persName>
							<email>jiacong.xu@tamu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Texas A&amp;M University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixiang</forename><surname>Xiong</surname></persName>
							<email>zixiang-xiong@tamu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Texas A&amp;M University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shankar</forename><forename type="middle">P</forename><surname>Bhattacharyya</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Texas A&amp;M University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PIDNet: A Real-time Semantic Segmentation Network Inspired from PID Controller</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Two-branch network architecture has shown its efficiency and effectiveness for real-time semantic segmentation tasks. However, direct fusion of low-level details and high-level semantics will lead to a phenomenon that the detailed features are easily overwhelmed by surrounding contextual information, namely overshoot in this paper, which limits the improvement of the accuracy of existed two-branch models. In this paper, we bridge a connection between Convolutional Neural Network (CNN) and Proportional-Integral-Derivative (PID) controller and reveal that the two-branch network is nothing but a Proportional-Integral (PI) controller, which inherently suffers from the similar overshoot issue. To alleviate this issue, we propose a novel threebranch network architecture: PIDNet, which possesses three branches to parse the detailed, context and boundary information (derivative of semantics), respectively, and employs boundary attention to guide the fusion of detailed and context branches in final stage. The family of PIDNets achieve the best trade-off between inference speed and accuracy and their test accuracy surpasses all the existed models with similar inference speed on Cityscapes, CamVid and COCO-Stuff datasets. Especially, PIDNet-S achieves 78.6% mIOU with inference speed of 93.2 FPS on Cityscapes test set and 80.1% mIOU with speed of 153.7 FPS on CamVid test set.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Proportional-Integral-Derivative (PID) Controller is a traditional concept proposed in last century and has been widely applied in modern dynamic systems or processes such as robotic manipulation <ref type="bibr" target="#b2">[3]</ref>, chemical process <ref type="bibr" target="#b24">[25]</ref>, power system <ref type="bibr" target="#b25">[26]</ref>. Even though many advanced control strategies with better control performance have been developed in recent years, PID controller is still the first choice for most of the industry applications due to its simple but robust characteristics. A classic concept in one scientific area could be extended to many other areas. For example, the underlying <ref type="figure">Figure 1</ref>. The trade-off between inference speed and accuracy (reported) for real-time models on the test set of Cityscapes. Blue stars refer to our models while green triangles represent other models. methodology of PID controller were introduced to image denoising <ref type="bibr" target="#b31">[32]</ref>, stochastic gradient decent <ref type="bibr" target="#b0">[1]</ref> and numerical optimization <ref type="bibr" target="#b49">[49]</ref> and achieved great improvement over original methods. In this paper, we design a deep neural network architecture for real-time semantic segmentation tasks by employing the basic concept of PID controller and the performance of this novel model surpasses all the previous networks and thereby achieves the best trade-off between inference speed and accuracy as <ref type="figure">Figure 1</ref> shows.</p><p>Semantic segmentation is a fundamental task for visual scene parsing and its objective is to assign a specific class label to each pixel in given images. With the gradual increasing of demand of intelligence, accurate semantic segmentation has become the basic perception component for many applications such as autonomous driving <ref type="bibr" target="#b16">[17]</ref>, medical imaging diagnosis <ref type="bibr" target="#b1">[2]</ref> and remote sensing imagery <ref type="bibr" target="#b53">[53]</ref>. Starting from FCN <ref type="bibr" target="#b30">[31]</ref>, who achieved great improvement over traditional methods, deep learning approaches gradually dominated the semantic segmentation field and many representative models were proposed <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b47">47,</ref><ref type="bibr" target="#b57">57,</ref><ref type="bibr" target="#b58">58]</ref>. The development of these learning models indicates that a network architectures with satisfactory segmentation performance must possess the capability of learning the contextual dependencies between pixels in large scale without losing important detailed information. Even though these models achieved encouraging segmentation accuracy, too much space and time complexity was introduced as sacrifice, which significantly restricted their application to real-time cases, such as autonomous vehicle <ref type="bibr" target="#b16">[17]</ref> and robot-assisted surgery <ref type="bibr" target="#b43">[43]</ref>.</p><p>To satisfy the real-time or mobile requirements, researchers came up with many efficient and effective models. Specifically, ENet <ref type="bibr" target="#b34">[35]</ref> achieved great improvement on inference speed by adopting lightweight decoder and downsampling the feature maps in early stages. ICNet <ref type="bibr" target="#b56">[56]</ref> encoded the small-size input in complex and deep path to parse the semantics and utilized simple and shallow path to encode the details from the large-size inputs. MobileNetv2 <ref type="bibr" target="#b41">[41]</ref> replaced the traditional convolutions with depthwise separable convolutions to reduce the overall model complexity and proposed an inverted residual block to alleviate regularization effect; These earlier works made huge contribution to reducing the latency and memory usage of segmentation models, but their low accuracy significantly limits their real-world application. Recently, some brilliant models based on two-branch network were proposed and achieved state-of-art performance regarding speed and accuracy <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b50">50,</ref><ref type="bibr" target="#b51">51]</ref>.</p><p>In this paper, we deeply analyze the basic architectures of two-branch networks from the prospective of PID controller and point out that the two-branch network is nothing but a PI controller and suffers from the overshoot issue inherently, which is illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>. To alleviate this problem, we establish a novel three-branch network architecture, namely Proportional-Integral-Derivative Network (PIDNet), which possesses one more branch for boundary detection. Then, we compare the performance of PIDNet with other stateof-art models on Cityscapes <ref type="bibr" target="#b12">[13]</ref>, CamVid <ref type="bibr" target="#b4">[5]</ref> and COCO-Stuff <ref type="bibr" target="#b5">[6]</ref> benchmarks to demonstrate its superiority. Also, ablation study and feature visualization is provided for better understanding of the functionality of each elaborated module. The code and pretrained models could be accessed via: https://github.com/XuJiacong/PIDNet</p><p>The main contribution of this paper is three-fold:</p><p>? We bridge a connection between deep learning models with PID controller and propose a family of threebranch networks based on PID controller architecture.</p><p>? A selective-learning-based connection, a fast context aggregation module and a boundary-guided fusion module are proposed to boost the performance of PIDNets.</p><p>? Our models achieve the best trade-off between inference speed and accuracy among all the existed models. In particular, PIDNet-S achieves 78.6% mIOU with speed of 93.2 FPS and PIDNet-L achieves 80.6% mIOU (highest in real-time domain) with speed of 31.1 FPS on Cityscapes test set without acceleration tools. Step responses of PI and PID controllers for a second-order system; | Right: From the first row to the last row, the images are cropped from ground truth, outputs of DDRNet-23 <ref type="bibr" target="#b21">[22]</ref> and ADB-Bag-DDRNet-23 (ours), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Since the network design philosophies for real-time and ordinary cases are quite different, we provide a concise introduction to some representative architectures in both cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">High-accuracy Semantic Segmentation</head><p>Most of the early deep learning approaches for semantic segmentation were based on encoder-decoder architecture <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b38">39]</ref>, where the encoder gradually enlarges its receptive field by cascading strided convolutions or pooling operations and the decoder recovers the detailed information from high-level semantics using deconvolutions or upsampling. However, spatial details could be easily ignored in the process of downsampling for encoder-decoder network. Towards this issue, dilated convolution <ref type="bibr" target="#b52">[52]</ref> was proposed, which could enlarge field-of-view without reducing the spatial resolution. Based on this, DeepLab series <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref> achieved great improvement over previous works by integrating the dilated convolutions with different dilation rates in the network. A critical problem for DeepLabs is that the dilated convolution is not suitable for current hardware due to its numerous non-contiguous memory accesses. To mitigate this problem, PSPNet <ref type="bibr" target="#b57">[57]</ref> introduced a Pyramid Pooling Module (PPM) to parse multi-scale context information and HRNet <ref type="bibr" target="#b47">[47]</ref> adopted multiple paths and bilateral connections to learn and fuse different scale representations. Inspired from the context aggregation power of self-attention mechanism <ref type="bibr" target="#b46">[46]</ref> in machine translation, non-local operation <ref type="bibr" target="#b48">[48]</ref> was introduced into computer vision and triggered many meaningful works for semantic segmentation <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b54">54</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Real-time Semantic Segmentation</head><p>To achieve the best trade-off between inference speed and accuracy, researchers contributed lots of effort to redesign the network architectures, which could be summarized as: lightweight encoder and decoder (convolution factorization or group convolution), multi-scale input and two-branch network. Specifically, SwiftNet <ref type="bibr" target="#b33">[34]</ref> employed one lowresolution input to obtain the high-level semantics and another high-resolution input to provide sufficient details for its lightweight decoder. DFANet <ref type="bibr" target="#b27">[28]</ref> introduced a light-weight backbone by modifying the architecture of Xception <ref type="bibr" target="#b11">[12]</ref>, which was based on depth-wise separable convolution, and reduced the input size for faster inference speed. Shuffle-Seg <ref type="bibr" target="#b18">[19]</ref> adopted ShuffleNet <ref type="bibr" target="#b55">[55]</ref>, which combined channel shuffling and group convolution, as its backbone to reduce computational cost. However, most of these networks are still in the form of encoder-decoder architecture and require the information flow go through the deep encoder and then reverse back to pass the decoder, which introduces much latency for these models. Besides, since the optimization for depthwise separable convolution on GPU is not mature, traditional convolution presents faster speed even though it has more FLOPs and parameters <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Two-branch Network Architecture</head><p>As the discussion in previous sections, contextual dependency could be extracted by large receptive field, and spatial details are vital for precise boundary delineation and small-scale object recognition. With this consideration, BiSeNet <ref type="bibr" target="#b51">[51]</ref> proposed a two-branch network architecture, which contains two branches with different depths for context embedding and detail parsing along with a Feature Fusion Module (FFM) to fuse the context and detailed information. Then, several works based on this architecture were proposed to boost its representation ability or reduce the model complexity <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b50">50]</ref>. Especially, DDRNet <ref type="bibr" target="#b21">[22]</ref> introduced bilateral connections to enhance the information exchange between context and detailed branches and achieved the state-of-art result in real-time semantic segmentation. Nevertheless, the output size for detailed branch is 8 times of context branch in DDRNet (4 times in BiSeNet) and direct fusion of them will inevitably leads to a phenomenon that the object boundary are easily corroded by its surrounding pixels and the small-scale object could be overwhelmed by its adjacent large objects, namely overshoot in this paper, which is shown in <ref type="figure" target="#fig_0">Figure 2</ref>. To alleviate the overshoot issue, we borrowed the PID concept from automation engineering field and proposed a three-branch network architecture: PIDNet, which simply supplements an additional branch for boundary extraction and leverages the boundary to supervise the fusion of context and detailed features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>PID controller contains three components with complementary capabilities: Proportional (P) controller represents current error, Integral (I) controller accumulates previous error and Derivative (D) controller predicts future change of error, as shown in <ref type="figure" target="#fig_1">Figure 3</ref>. Thus, the output of PID con- troller is generated based on the error in the entire time domain. Usually, PI controller could satisfy most of setpoint control scenarios but it suffers from the overshoot issue inherently <ref type="bibr" target="#b14">[15]</ref>. For better dynamic response, researchers introduced Derivative controller to make prediction and adjust the control output before overshoot happens. In two-branch network, the context branch constantly aggregate the semantic information from local to global area by cascading strided convolution or pooling layers to parse the long-range dependencies between pixels, while the detailed branch maintains high-resolution feature maps to preserve the semantic and localization information for each individual pixel. Thus, the detailed and context branch could be seen as Proportional and Integral controllers in spatial domain, which explains the underlying reason for the overshoot issue of segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">PIDNet: A Novel Three-branch Network</head><p>To mitigate the overshoot issue, we propose to provide an Auxiliary Derivative Branch (ADB) for two-branch network and fully mimic the PID controller in spatial domain. The semantics for pixels inside each object are consistant and only become inconsistant along the boundary of adjacent objects, so the derivative of semantics is nonzero only at the object boundary and the function of ADB should be boundary detection. Accordingly, we establish a new three-branch real-time semantic segmentation architecture, namely Proportional-Integral-Derivative Network (PIDNet), which is shown in <ref type="figure" target="#fig_2">Figure 4</ref>. PIDNet possesses three branches with complementary responsibilities: Proportional (P) branch parses and preserves the detailed information in its high-resolution feature maps; Integral (I) branch aggregates context information locally and globally to parse long-range dependencies; Derivative (D) branch extracts the high-frequency features to predict the boundary regions. The entire network are de-  <ref type="bibr" target="#b45">[45]</ref>. Dashed lines and associate blocks will be ignored in inference stage.</p><p>veloped following <ref type="bibr" target="#b21">[22]</ref>, which adopted cascaded residual blocks <ref type="bibr" target="#b20">[21]</ref> as backbone, for hardware-friendly architecture. Besides, the depths for P, I and D branches are scheduled to be moderate, deep and shallow for efficient implementation considering the complexity for corresponding task. Also, a family of PIDNets (PIDNet-S, PIDNet-M and PIDNet-L) are generated by deepening and widening the model.</p><p>Following <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b50">50]</ref>, we place a semantic head at the output of the first Pag module to generate the extra semantic loss l 0 for better optimization of entire network. Instead of dice loss <ref type="bibr" target="#b13">[14]</ref>, weighted binary cross entropy loss l 1 is adopted to deal with the imbalanced problem of boundary detection since coarse boundary is preferred to highlight the boundary region and enhance the features for small objects. l 2 and l 3 represents the CE loss, while we utilize the boundary-awareness CE loss <ref type="bibr" target="#b45">[45]</ref> for l 3 using the output of Boundary head to coordinate semantic segmentation and boundary detection tasks and enhance the function of Bag module, which could be written as:</p><formula xml:id="formula_0">l 3 = ? ? i,c {1 : b i &gt; t}(s i,c log? i,c )<label>(1)</label></formula><p>where t refers to predefined threshold and b i , s i,c and? i,c are the output of boundary head, segmentation ground-truth and prediction result of the i-th pixel for class c, respectively. Therefore, the final loss for PIDNet could be summarized as:</p><formula xml:id="formula_1">Loss = ? 0 l 0 + ? 1 l 1 + ? 2 l 2 + ? 3 l 3<label>(2)</label></formula><p>Empirically, we set the parameters for the training loss of PIDNet as ? 0 = 0.4, ? 1 = 20, ? 2 = 1, ? 3 = 1 and t = 0.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pag: Selective Learning High-level Semantics</head><p>The lateral connection utilized in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b47">47]</ref> enhances the information transmission between different feature maps and improves the representation ability of their models. In PIDNet, the rich and accurate semantic information provided by I branch is crucial for detail parsing of P branch, which contains relatively less layers and channels. Thus, we could treat I branch as the backup for other two branches and enable it to provide required information to them. Different from D branch that directly adds the provided feature maps, we introduce a Pixel-attention-guided fusion module (Pag), which is shown in <ref type="figure">Figure 5</ref>, for P branch to selectively learn the useful semantic features from I branch without being overwhelmed. Basically, the underlying concept for Pag is <ref type="figure">Figure 5</ref>. Illustration of Pag module in lateral connection. Sum refers to the element summation along channels; ? denotes the output of Sigmoid function; Up is for bilinear upsampling. borrowed from self-attention mechanism <ref type="bibr" target="#b46">[46]</ref> but Pag computes the attention locally for real-time requirement. Define the vectors for the corresponding pixels in feature maps provided by P branch and I branch as v p and v i , respectively, then the output of Sigmoid function will become:</p><formula xml:id="formula_2">? = Sigmoid( f p ( v p ) ? f i ( v i ))<label>(3)</label></formula><p>where ? represents the possibility of these two pixels are from the same object. If ? is high, we trust v i more since I branch is semantically accurate, and vise versa. Thus, the output of the Pag module could be written as:</p><formula xml:id="formula_3">Out Pag = ? v i + (1 ? ? ) v p<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">PAPPM: Fast Aggregation of Contexts</head><p>For better global scene prior construction, Spatial Pyramid Pooling (SPP) <ref type="bibr" target="#b19">[20]</ref> was adopted in SwiftNet <ref type="bibr" target="#b33">[34]</ref> to parse the global dependencies. Also, PSPNet <ref type="bibr" target="#b57">[57]</ref> introduced a Pyramid Pooling Module (PPM), which concatenates multiscale pooling maps before convolution layer to form local and global context representations. Deep Aggregation PPM (DAPPM) proposed by <ref type="bibr" target="#b21">[22]</ref> further improved the context embedding ability of PPM and showed superior performance. However, the computation of DAPPM cannot be parallelized regarding its depth, which is time-consuming and DAPPM contains too many channels for each scale, which surpasses the representation ability of lightweight models. Thus, we slightly change the connections in DAPPM to make it parallelized, which is shown in <ref type="figure" target="#fig_3">Figure 6</ref>, and reduce the number of channels for each scale from 128 to 96. This new context harvesting module is called Parallel Aggregation PPM (PAPPM) and is applied in PIDNet-M and PIDNet-S to improve their speeds. For our deep model: PIDNet-L, we still choose the DAPPM considering its depth but change its number of channels for each scale from 128 to 112.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Bag: Balancing the Details and Contexts</head><p>Given the boundary features extracted by ADB, our proposal is to employ the boundary attention to guide the fusion of detailed (P) and context (I) representations. Therefore, we design a Boundary-attention-guided fusion module (Bag) to fuse the features provides by three branches. Note that the context branch is semantically rich and could presents more accurate semantics but it loses too much spatial and geometric details especially for the boundary region and small object. Thanks to the detailed branch, which preserves the spatial details better, we force the model to trust the detailed branch more along the boundary region and utilize the context features to fill the area inside object, which could be accomplished by Bag in <ref type="figure" target="#fig_4">Figure 7</ref>. Define the vectors for the </p><formula xml:id="formula_4">? = Sigmoid( v d )<label>(5)</label></formula><p>Out</p><formula xml:id="formula_5">bag = f out ((1 ? ? ) ? v i + ? ? v p )<label>(6)</label></formula><p>Out</p><formula xml:id="formula_6">light = f p ((1 ? ? ) ? v i + v p ) + f i (? ? v p + v i ) (7)</formula><p>where f refers to the composition of convolutions, batch normalizations and ReLUs. Even though we replaced the 3 ? 3 convolution in Bag by two 1 ? 1 convolutions in Light-Bag, the functionalities of Bag and Light-Bag are similar, that is when ? &gt; 0.5 the model trusts more on detailed features, otherwise context information is preferred.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment</head><p>To validate the superiority of our proposed methods, we train our models on Cityscapes, CamVid and COCO-Stuff benchmark datasets and compare their test accuracy and inference speed with other state-of-art real-time networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>Cityscapes. Cityscapes <ref type="bibr" target="#b12">[13]</ref> is one of the most well-known urban scene parsing datasets, which contains 5000 fine annotated images collected from the car perspective in different cities. These images are divided into sets with numbers of 2975, 500, and 1525 for training, validation and test. The annotation contains 30 classes but only 19 of them are utilized for semantic segmentation. The image size for all the data is 2048?1024, which is challenging for real-time segmentation. Here, we only use the fine annotated dataset to train our models for fair comparison with other networks. CamVid. CamVid <ref type="bibr" target="#b4">[5]</ref> provides 701 images of driving scenes, which is partitioned into 367, 101 and 233 for training, validation and testing. The image resolution is of 960?720 and the number of annotated categories is 32, of which 11 classes are used for semantic segmentation. Pixels outside these 11 classes are ignored for fair comparison with others. COCO-Stuff. We choose the 10K version of the COCO-Stuff <ref type="bibr" target="#b5">[6]</ref> dataset, which is also exploited in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b50">50]</ref>. This dataset consists of 10K densely annotated images and is divided into 9K for training and 1K for testing. The complex categories of COCO-Stuff is challenging for every segmentation model, which includes 91 thing and 91 stuff classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>Pretraining. Before training our models on three datasets, we firstly pretrain these models by ImageNet <ref type="bibr" target="#b39">[40]</ref> considering pretraining is crucial for lateral connections in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b33">34]</ref>. We remove the D branch and follow the same merging method as DDRNet <ref type="bibr" target="#b21">[22]</ref> in finaly stage to construct the classification models. The total number of training epoches is 90 and the learning rate is scheduled to be 0.1 initially and multiplied by 0.1 at epoch 30 and 60. CE loss and SGD with momentum of 0.9 and weight decay of 1e ?4 are used to optimize the networks. The images are randomly cropped into 224?224 and flipped horizontally for data augmentation. Training. For fair comparison, our training protocols are almost the same as previous works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b50">50,</ref><ref type="bibr" target="#b51">51]</ref>. Specifically, we adopt the poly learning rate strategy to update the learning rate in each iteration. Also, random cropping, random horizontal flipping and random scaling in the range of [0.5, 2.0] are employed for data augmentation. The number of training epochs, the initial learning rate, weight decay, cropped size and batch size for Cityscapes, CamVid and COCO-Stuff could be summarized as [484, 1e ?2 , 5e ?4 , 1024?1024, 12], [200, 1e ?3 , 5e ?4 , 960?720, 12] and [180, 5e ?3 , 1e ?4 , 640?640, 16], respectively. Following <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b50">50]</ref>, we finetune the models pretrained by Cityscapes for CamVid and early stop training process to avoid overfit. Inference. Before being evaluated on test set, our models are trained by both train and validation set for Cityscapes and CamVid. We measure the inference speed on the platform consists of single RTX 3090, PyTorch 1.8, CUDA 11.2, cuDNN 8.0 and Anaconda environment. Using the speed measurement protocol proposed by <ref type="bibr" target="#b10">[11]</ref> and following <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b44">44]</ref>, we integrate the batch normalization into the convolutional layers and set the batch size to be 1 and the input image size to be 2048?1024, 960?720 and 640?640 for Cityscapes, CamVid and COCO-Stuff, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>ADB for Two-branch Networks. To demonstrate the effectiveness of ADB, we borrow the ADB and Bag from PIDNet and combine them with existed models. Here, two representative two-branch networks: BiSeNet <ref type="bibr" target="#b51">[51]</ref> and DDRNet <ref type="bibr" target="#b21">[22]</ref> equipped with ADB and Bag are implemented and achieve higher accuracy on Cityscapes val set compared with their original models, which is shown in <ref type="table">Table 1</ref>. However, additional computation significantly slow down their inference speed, which then triggers us to establish PIDNet. Collaboration of Pag and Bag. Element-wise summation is a traditional way to merge features in lateral connection. Instead of direct adding up the feature maps, we provided P branch with the Pag module to assist it to learn useful information from I branch without being overwhelmed. Besides, the Bag module was introduced to guide the fusion of detailed and context features using boundary attention in the final stage. As <ref type="table">Table 2</ref> shows, lateral connection could significantly improve the model accuracy and pretraining could further boost its performance. In our scenario, the com-  of the collaboration of Pag and Bag (or Light-Bag). The visualization of feature maps in <ref type="figure" target="#fig_5">Figure 8</ref> shows that the small objects become much darker compared with large objects in the Sigmoid map for second Pag, where I branch loses more detailed information. Also, the features in boundary regions and small objects are greatly enhanced in the output of Bag module, which is illustrated in <ref type="figure" target="#fig_6">Figure 9</ref> and explains the reason why we choose coarse boundary detection. Efficiency of PAPPM. For real-time models, a heavy context aggregation module could drastically slow down the inference speed and may surpass the representation ability of the network. Thus, we proposed the PAPPM, which is constituted by parallel structure and small number of parameters. The experimental results in <ref type="table">Table 3</ref> show that PAPPM achieves the same accuracy as DAPPM <ref type="bibr" target="#b21">[22]</ref> but presents a speed-up of 9.5 FPS for our light-weight model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PPM</head><p>Extra Loss OHEM mIOU l 0 l 1 l 3 78.6 78.8 79.9 80.5 80.9 <ref type="table">Table 4</ref>. Ablation study of extra losses and OHEM for PIDNet-L.</p><p>Effectiveness of Extra losses. Three extra losses were intro- duced to PIDNet to boost the optimization of entire network and emphasize the functionality for each components. According to <ref type="table">Table 4</ref>, boundary loss l 1 and boundary-awareness loss l 3 are necessary for better performance of PIDNet, especially the boundary loss (+1.1% mIOU), which strongly proves the necessity of D branch, and Online Hard Example Mining (OHEM) <ref type="bibr" target="#b42">[42]</ref> further improves the accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Comparison</head><p>CamVid. For CamVid <ref type="bibr" target="#b4">[5]</ref> dataset, only the accuracy of DDR-Net is comparable with our models, which is shown in <ref type="table" target="#tab_3">Table  5</ref>, so we test its speed on our platform with the same setting for fair comparison considering our platform is more advanced than theirs. The experimental results show that the Model mIOU #FPS GPU MSFNet <ref type="bibr" target="#b44">[44]</ref> 75.4 91.0 GTX 2080Ti PP-LiteSeg-T <ref type="bibr" target="#b35">[36]</ref> 75.0 154.8 GTX 1080Ti TD2-PSP50 <ref type="bibr" target="#b22">[23]</ref> 76.0 11.0 TITAN X BiSeNetV2 ? <ref type="bibr" target="#b50">[50]</ref> 76.7 124.0 GTX 1080Ti BiSeNetV2-L ? <ref type="bibr" target="#b50">[50]</ref> 78.5 33.0 GTX 1080Ti HyperSeg-S <ref type="bibr" target="#b32">[33]</ref> 78  <ref type="table">Table 6</ref>. Comparison of speed and accuracy on Cityscapes. The models pretrained by other segmentation datasets are marked with ?; The inference speeds for models marked with * are tested on our platform. The GFLOPs for PIDNet is derived based on input size of 2048?1024.</p><p>S surpasses previous state-of-art model: DDRNet-23-S by 1.5% mIOU with only around 1 ms latency increase. Cityscapes. Previous real-time works treat Cityscapes <ref type="bibr" target="#b12">[13]</ref> as the standard benchmark. As shown in <ref type="table">Table 6</ref>, only SFNet and DDRNet present similar accuracy with our models, so we test their speeds on the same platform as PIDNets for fair comparison. The experimental results shows that PID-Nets achieve the best trade-off between inference speed and accuracy. Specifically, PIDNet-L surpasses SFNet(ResNet-18) and DDRNet-39 in terms of speed and accuracy and becomes the most accurate model in real-time domain by rising the test accuracy from 80.4% to 80.6% mIOU. PIDNet-M and PIDNet-S also provide much higher accuracy compared with the models with similar inference speeds. Especially, PIDNet-S becomes the fastest one amoung all the models with accuracy higher than 77.5% mIOU, which will satisfy most of the applications with strict latency and accuracy requirements. See <ref type="figure" target="#fig_7">Figure 10</ref> for actual performance. COCO-Stuff. The (17,8)-Avg-pooling path in PAPPM is removed since the image size is too small in COCO-Stuff <ref type="bibr" target="#b5">[6]</ref>. Even though the annotations for COCO-Stuff along the boundary region are not as precise as previous two datasets, our models still achieve competitive performance regarding efficiency compared with others, as shown in <ref type="table" target="#tab_4">Table 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper proposes a series of three-branch networks: PIDNets for real-time semantic segmentation tasks. PID-Nets achieve the best trade-off between inference time and accuracy, which is demonstrated by extensive experiments. However, since PIDNets utilize the boundary prediction to balance the detailed and context information, precise annotation around boundary is required for better performance. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Overshoot issue for dynamic system (left |) and image segmentation (| right). Left |:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>The analogy between PID controller and two-branch network architecture. TBN denotes Two-Branch Network and ADB is our proposed Auxiliary Derivative Branch. P, I and D refer to detailed, context and boundary branches, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>An overview of the basic architecture of our proposed Proportional-Integral-Derivative Network (PIDNet). S and B denote semantic and boundary, and Add and Up refer to element-wise summation and bilinear Upsampling operation, respectively; BAS-Loss represents the boundary-awareness CE loss</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>The parallel structure of PAPPM. (5,2)-Avg-Pooling means average pooling with kernel size of 5?5 and strides of 2. Biliear upsampling is used for the Upsample operations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>The implementations of (a) Bag and (b) Light-Bag modules. P, I and D refer to the outputs of detailed, context and boundary branches, respectively. ? denotes the output of Sigmoid function. corresponding pixels in the output of P, I and D branches as v p , v i and v d , respectively, then the outputs of Sigmoid , Bag and Light-Bag could be represented as:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Feature visualization of Pag module. The maps in the first row from left to right are the original input image, P input, I input and output of Sigmoid function for the first Pag; The maps in the second row are groudtruth, P, I inputs and Sigmoid output for the second Pag; The third and fourth rows are for another image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Feature visualization of Bag module. The maps in the first row from left to right are the original input image, P, I and D input for Light-Bag; The maps in the second row are groudtruth, P + (1 ? ? ) ? I, I + ? ? P and final output for Light-Pag; The third and fourth rows are for another image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 .</head><label>10</label><figDesc>An illustration of the segmentation performance of PIDNets on Cityscapes Val set. The four columns from left to right refer to input images, predictions of PIDNet-S and PIDNet-L and ground truth, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc>Comparison of speed and accuracy on CamVid. The models pretrained by Cityscapes<ref type="bibr" target="#b12">[13]</ref> are marked with ?; The inference speeds for models marked with * are tested on our platform.</figDesc><table><row><cell></cell><cell>.4</cell><cell cols="2">38.0 GTX 1080Ti</cell></row><row><cell>HyperSeg-L [33]</cell><cell>79.1</cell><cell cols="2">16.6 GTX 1080Ti</cell></row><row><cell>DDRNet-23-S  ?* [22]</cell><cell>78.6</cell><cell>182.4</cell><cell>RTX 3090</cell></row><row><cell>DDRNet-23  ?* [22]</cell><cell>80.6</cell><cell>116.8</cell><cell>RTX 3090</cell></row><row><cell>PIDNet-S  ?</cell><cell>80.1</cell><cell>153.7</cell><cell>RTX 3090</cell></row><row><cell>PIDNet-M  ?</cell><cell>82.0</cell><cell>85.6</cell><cell>RTX 3090</cell></row><row><cell cols="4">accuracy of our lightweight models exceeds 80% mIOU and</cell></row><row><cell cols="4">PIDNet-M achieves the highest accuracy with a big margin</cell></row><row><cell cols="4">ahead of previous models, which strongly demonstrates the</cell></row><row><cell cols="4">superiority of our models. Besides, the accuracy of PIDNet-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 7 .</head><label>7</label><figDesc>Comparison of speed and accuracy on COCO-Stuff. The speeds for models marked with * are tested on our platform.</figDesc><table><row><cell>Model</cell><cell cols="3">mIOU pixAcc #FPS</cell></row><row><cell>ICNet [56]</cell><cell>29.1</cell><cell>-</cell><cell>35.7</cell></row><row><cell>BiSeNetV2 [50]</cell><cell>25.2</cell><cell>60.5</cell><cell>87.9</cell></row><row><cell cols="2">BiSeNetV2-L [50] 28.7</cell><cell>63.5</cell><cell>42.5</cell></row><row><cell cols="2">DDRNet-23 * [22] 32.1</cell><cell>64.7</cell><cell>145.2</cell></row><row><cell cols="2">DDRNet-39 * [22] 34.8</cell><cell>66.6</cell><cell>96.7</cell></row><row><cell>PIDNet-S</cell><cell>29.2</cell><cell>62.6</cell><cell>151.6</cell></row><row><cell>PIDNet-M</cell><cell>33.5</cell><cell>65.9</cell><cell>113.7</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A pid controller approach for stochastic optimization of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangpeng</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qionghai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8522" to="8531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep semantic segmentation of natural and medical images: a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kumar</forename><surname>Saeid Asgari Taghanaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">Paul</forename><surname>Abhishek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghassan</forename><surname>Cohen-Adad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hamarneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="137" to="178" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Tuning of pid controller based on a multiobjective genetic algorithm applied to a robotic manipulator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helon</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hultmann</forename><surname>Ayala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leandro</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santos</forename><surname>Coelho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="8968" to="8974" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic object classes in video: A high-definition ground truth database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Brostow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Fauqueur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cocostuff: Thing and stuff classes in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1209" to="1218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Semantic image segmentation with deep convolutional nets and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7062</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="834" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05587</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fasterseg: Searching for faster real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.10917</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1251" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning to predict crisp boundaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoxi</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengjun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huibing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinru</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="562" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Analytical design of PID controllers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangjin</forename><surname>Iv?n D D?az-Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bhattacharyya</surname></persName>
		</author>
		<imprint>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Rethinking bisenet for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyuan</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenqi</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junshi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junfeng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="9716" to="9725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep multi-modal object detection and semantic segmentation for autonomous driving: Datasets, methods, and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Haase-Sch?tz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinz</forename><surname>Hertlein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudius</forename><surname>Glaeser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Timm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Wiesbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Dietmayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1341" to="1360" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dual attention network for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijie</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3146" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Gamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mennatullah</forename><surname>Siam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moemen</forename><surname>Abdel-Razek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03816</idno>
		<title level="m">Shuffleseg: Real-time semantic segmentation network</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1904" to="1916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Deep dual-resolution networks for real-time and accurate semantic segmentation of road scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanduo</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weichao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisong</forename><surname>Jia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06085</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Temporally distributed networks for fast video semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Caba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Perazzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8818" to="8827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ccnet: Criss-cross attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="603" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Genetic algorithm based pid controller tuning approach for continuous stirred tank reactor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jayachitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinodha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Artificial Intelligence (16877470)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A new pid controller design for automatic generation control of hydro power systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khodabakhshian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hooshmand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Electrical Power &amp; Energy Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cabinet: efficient context aggregation network for low-latency semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saumya</forename><surname>Kumaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Nex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Ying</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13517" to="13524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dfanet: Deep feature aggregation for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqiang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9522" to="9531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semantic flow for fast and accurate scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangtai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ansheng</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houlong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maoke</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhai</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="775" to="793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Partial order pruning: for best speed/accuracy trade-off in neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9145" to="9153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Towards fast and robust real image denoising with attentive neural network and pid controller</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengming</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Hyperseg: Patchwise hypernetwork for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Nirkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Hassner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="4061" to="4070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">In defense of pre-trained imagenet architectures for real-time semantic segmentation of road-driving images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marin</forename><surname>Orsic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Kreso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petra</forename><surname>Bevandic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinisa</forename><surname>Segvic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="12607" to="12616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Enet: A deep neural network architecture for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Chaurasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangpil</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugenio</forename><surname>Culurciello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02147</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Pp-liteseg: A superior real-time semantic segmentation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncai</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuying</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lutao</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guowei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zewu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiliang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02681</idno>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Contextnet: Exploring context and detail for semantic segmentation in real-time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ujwal</forename><surname>Poudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Bonde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04554</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Fastscnn: Fast semantic segmentation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Poudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cipolla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.04502</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<publisher>Andrej Karpathy</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Training region-based object detectors with online hard example mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="761" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Automatic instrument segmentation in robot-assisted surgery using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alexey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Shvets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rakhlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alexandr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">I</forename><surname>Kalinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iglovikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th IEEE International Conference on Machine Learning and Applications (ICMLA)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="624" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Real-time semantic segmentation via multiply spatial fusion network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyang</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifan</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.07217</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Gated-scnn: Gated shape cnns for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Towaki</forename><surname>Takikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Acuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5229" to="5238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Attention is all you need. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="3349" to="3364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A pid controller architecture inspired enhancement to the pso algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Future of Information and Communication Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="587" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Bisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changxin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nong</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3051" to="3068" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Bisenet: Bilateral segmentation network for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changxin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nong</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="325" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07122</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A review of deep learning methods for semantic segmentation of remote sensing imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichuan</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">114417</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Objectcontextual representations for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="173" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Shufflenet: An extremely efficient convolutional neural network for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengxiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6848" to="6856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Icnet for real-time semantic segmentation on high-resolution images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="405" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sixiao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zekun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yabiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6881" to="6890" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
