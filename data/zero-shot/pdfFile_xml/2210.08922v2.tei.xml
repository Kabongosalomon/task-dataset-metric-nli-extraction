<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Multilingual Knowledge Graph Completion and Alignment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinh</forename><surname>Tong</surname></persName>
							<email>1vinh.tong@ipvs.uni-stuttgart.de</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Stuttgart</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Quoc Nguyen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">VinAI Research</orgName>
								<address>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trung</forename><forename type="middle">Thanh</forename><surname>Huynh</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">EPFL</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tam</forename><forename type="middle">Thanh</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Griffith University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Viet</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Griffith University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Stuttgart</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Joint Multilingual Knowledge Graph Completion and Alignment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge graph (KG) alignment and completion are usually treated as two independent tasks. While recent work has leveraged entity and relation alignments from multiple KGs, such as alignments between multilingual KGs with common entities and relations, a deeper understanding of the ways in which multilingual KG completion (MKGC) can aid the creation of multilingual KG alignments (MKGA) is still limited. Motivated by the observation that structural inconsistencies -the main challenge for MKGA models -can be mitigated through KG completion methods, we propose a novel model for jointly completing and aligning knowledge graphs. The proposed model combines two components that jointly accomplish KG completion and alignment. These two components employ relation-aware graph neural networks that we propose to encode multi-hop neighborhood structures into entity and relation representations. Moreover, we also propose (i) a structural inconsistency reduction mechanism to incorporate information from the completion into the alignment component, and (ii) an alignment seed enlargement and triple transferring mechanism to enlarge alignment seeds and transfer triples during KGs alignment. Extensive experiments on a public multilingual benchmark show that our proposed model outperforms existing competitive baselines, obtaining new state-of-the-art results on both MKGC and MKGA tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graphs (KGs) represent facts about real-world entities as triples of the form (head_entity, relation_type, tail_entity). KGs are widely used in numerous applications and research domains such as dialogue systems <ref type="bibr" target="#b7">(Jung et al., 2020)</ref>, machine translation <ref type="bibr" target="#b39">(Zhao et al., 2020)</ref>, and electronic medical records <ref type="bibr" target="#b19">(Rotmensch et al., 2017)</ref>. Almost all KGs, however, even those at the scale of billions of triples, are far from being complete. This motivates KG completion <ref type="bibr">(KGC)</ref> which aims to derive missing triples from an incomplete knowledge graph <ref type="bibr" target="#b0">(Bordes et al., 2013;</ref><ref type="bibr" target="#b31">Wang et al., 2014;</ref><ref type="bibr" target="#b29">Trouillon et al., 2016;</ref><ref type="bibr" target="#b12">Liu et al., 2017;</ref><ref type="bibr" target="#b3">Dettmers et al., 2018;</ref><ref type="bibr" target="#b17">Nguyen, 2020;</ref><ref type="bibr">Ji et al., 2021;</ref><ref type="bibr">Tong et al., 2021)</ref>.</p><p>Most popular KGs such as YAGO <ref type="bibr" target="#b23">(Suchanek et al., 2007)</ref>, BabelNet <ref type="bibr" target="#b14">(Navigli and Ponzetto, 2010)</ref>, and DBpedia <ref type="bibr" target="#b10">(Lehmann et al., 2015)</ref>, are multilingual, that is, they contain sets of triples constructed from sources in different languages. Fortunately, these KGs often complement each other since a KG in one language might be more comprehensive in some domains compared to a KG in a different language, and vice versa, while still sharing a large number of entities and relation types <ref type="bibr" target="#b24">(Sun et al., 2020a)</ref>. Especially KGs for low-resource languages could benefit from triples contained in KGs for high-resource languages. Although numerous approaches to KGC have been proposed in recent years <ref type="bibr" target="#b0">(Bordes et al., 2013;</ref><ref type="bibr" target="#b3">Dettmers et al., 2018;</ref><ref type="bibr">Vashishth et al., 2020)</ref>, most of these only operate on one KG at a time. Treating KGs independently, however, might lead to poor performance due to the sparseness of low-resource languages. Motivated by this observation, some methods have tried to improve multilingual KG completion (MKGC) using multilingual KG alignment (MKGA) <ref type="bibr">(Chen et al., 2020;</ref><ref type="bibr" target="#b22">Singh et al., 2021;</ref><ref type="bibr" target="#b5">Huang et al., 2022)</ref>.</p><p>The alignment problem is challenging due to the varying levels of completeness of monolingual KGs <ref type="bibr" target="#b26">(Sun et al., 2020c)</ref>. The resulting structural inconsistency between KGs leads to the problem of corresponding entities in two KGs having vastly different embeddings <ref type="bibr" target="#b36">(Xu et al., 2018)</ref>. <ref type="figure" target="#fig_1">Figure 1</ref> illustrates that, in principle, MKGC and MKGA should be mutually beneficial. Given the alignment seed set {(E, E * ), (D, D * ), (B, B * )}, the task here is to find corresponding entities for A and C which are A * and C * , respectively. The two KGs share a similar structure but the triple (B * , r4, A * ) in KG * has no corresponding triple in KG. This causes   <ref type="figure">B, r4, A)</ref>) might lead to a wrong alignment prediction (i.e. both A and C are predicted to be aligned to C * ). If A and A * were aligned, however, the missing triple (B, r4, A) in KG could be found by transferring triple (B * , r4, A * ) from KG * . the embeddings of entities A and A * to differ and, thus, makes it difficult to identify the alignment between A and A * . Indeed, A is more likely to be aligned to C * as they share a comparable local structure (similar degree and 1-hop neighbor set). Thus, completing missing triples is crucial to improve the alignment quality. Indeed, if one aligned A to A * , one could recover (B, r4, A) by transferring (B * , r4, A * ) from KG * .</p><p>Motivated by these observations, we propose JMAC, a method for Joint Multilingual KG Completion and Alignment, consisting of two interdependent Completion and Alignment components. Both components employ relation-aware graph neural networks (GNNs) to encode multihop neighborhood information into entity and relation embeddings. The Completion component is trained to reconstruct missing triples using the TransE translation-based loss <ref type="bibr" target="#b0">(Bordes et al., 2013)</ref> and an additional loss term that incorporates information about the already known alignments. While we learn separate embeddings for the Alignment and Completion components, the embeddings of the Completion component are used within the Alignment component, mitigating the aforementioned problem of structural inconsistencies. In addition, we propose a mechanism for estimating the alignment entropy which is used to adaptively and iteratively grow the alignment seed set. Finally, we also propose a method for transferring triples based on the currently derived alignments.</p><p>Our contributions are as follows:</p><p>? We propose JMAC, a two-component architecture consisting of Completion and Alignment components for joint multilingual KG completion and alignment.</p><p>? We propose a relation-aware GNN for KG embeddings, which learns representations for alignment and completion tasks.</p><p>? We introduce a structural inconsistency reduction mechanism that fuses embeddings from the Completion component with those of the Alignment component.</p><p>? We propose an alignment seed enlargement and triple transfer mechanism.</p><p>? We conduct extensive experiments using the public multilingual benchmark DBP-5L <ref type="bibr">(Chen et al., 2020)</ref> and show that our model outperforms existing competitive baselines and achieves state-of-the-art results on both MKGC and MKGA tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition and Related Work</head><p>Let G = (E, R, T ) denote a KG, where E, R and T denote the sets of entities, relations, and triples, respectively. A triple (e h , r, e t ) ? T is an atomic unit, which represents some relation r ? R between a head entity e h ? E and a tail entity e t ? E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multilingual KG completion (MKGC)</head><p>Given a KG G = (E, R, T ), the KG completion (KGC) task aims to predict missing triples (e h , r, e t ), that is, to predict the missing tail entity e t ? E of an incomplete triple (e h , r, ?) or the missing head entity e h ? E of an incomplete triple (?, r, e t ), where ? denotes the missing element. Embedding models for KG completion have been proven to give state-of-the-art results, representing entities and relation types with latent feature vectors, matrices, and/or third-order tensors <ref type="bibr" target="#b17">(Nguyen, 2020;</ref><ref type="bibr">Ji et al., 2021)</ref>. These models define a score function f and are trained to make the score f (e h , r, e t ) of a correct triple (e h , r, e t ) larger than the score f (e h , r , e t ) of an incorrect or not known to be correct triple (e h , r , e t ). The earliest instances of these embedding models use shallow neural networks with translation-based score functions <ref type="bibr" target="#b0">(Bordes et al., 2013;</ref><ref type="bibr" target="#b31">Wang et al., 2014;</ref><ref type="bibr" target="#b11">Lin et al., 2015)</ref>. Recently, KGC approaches using deep embedding models and more complex scoring functions have been proposed, such as CNN-based models <ref type="bibr" target="#b3">(Dettmers et al., 2018;</ref><ref type="bibr" target="#b15">Nguyen et al., 2018)</ref>, RNN-based models <ref type="bibr" target="#b12">(Liu et al., 2017;</ref><ref type="bibr" target="#b4">Guo et al., 2018)</ref>, and GNN-based models <ref type="bibr" target="#b20">(Schlichtkrull et al., 2018;</ref><ref type="bibr" target="#b21">Shang et al., 2019;</ref><ref type="bibr">Vashishth et al., 2020;</ref><ref type="bibr">Nguyen et al., 2022)</ref>.</p><p>The MKGC task is to perform the KGC task on a KG given the availability of other KGs in different languages <ref type="bibr">(Chen et al., 2020;</ref><ref type="bibr" target="#b5">Huang et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multilingual KG alignment (MKGA)</head><p>MKGA, which is also known as cross-lingual entity alignment, aims to match entities with their counterparts from KGs in different languages <ref type="bibr" target="#b1">(Chen et al., 2017;</ref><ref type="bibr" target="#b32">Wang et al., 2018;</ref><ref type="bibr" target="#b33">Wu et al., 2019;</ref><ref type="bibr" target="#b25">Sun et al., 2020b)</ref>. Without loss of generalization, we define the alignment between a source graph G = (E, R, T ) and a target graph G * = (E * , R * , T * ). For each entity e ? E, the MKGA task is now to find e * ? E * (if any).</p><p>Existing models compute an alignment matrix whose elements represent the similarity score between any two entities e ? E and e * ? E * across two KGs. The models then employ a greedy matching algorithm <ref type="bibr" target="#b9">(Kollias et al., 2011)</ref> to infer matching entities from the alignment matrix. The models typically require an alignment seed set L of prealigned entity pairs (e, e * ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Joint MKGC and MKGA</head><p>The joint MKGC and MKGA problem aims to infer both, new triples for each KG and new aligned entity pairs for each pair of KGs. Performing two tasks jointly might be beneficial: missing triples (e h , r, e t ) in one KG could be recovered by crosschecking another KG via the alignment, which, in turn, could be boosted by the newly added triples.</p><p>Despite the obvious benefit to complete and align KGs jointly, there has not been much work addressing the problem. A notable exception is the application of multi-task learning to the problem <ref type="bibr" target="#b22">(Singh et al., 2021)</ref>. The proposed multi-task model, however, is not able to capture local neighborhood information. Another limitation is the missing robustness to the previously described issue of structural inconsistencies between the KGs during training. <ref type="figure" target="#fig_2">Figure 2</ref> illustrates the architecture of JMAC which consists of the Completion and Alignment components, respectively. Each component uses a relation-aware GNN to encode multi-hop neighborhood information into entity and relation embeddings. The use of two GNN encoders is beneficial as embeddings that are suitable for the alignment might differ from those that are most beneficial for the completion problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">JMAC: Joint Multilingual Alignment and Completion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Relation-aware graph neural network</head><p>To better capture relation information, we propose a GNN architecture that uses relation-aware messages and relation-aware attention scores. We unify heterogeneous information from KGs using a GNN with K layers. For the k-th layer (denoted by the superscript k ), we update the representation a k+1 e of each entity e ? E as:</p><formula xml:id="formula_0">a k+1 e = g ? ? (e ,r)?N (e) ? k e,e ,r m k e ,r + a k e ? ? (1)</formula><p>where a k e ? R n is the vector representation of entity e at the k-th layer; N (e) = {(e , r)|(e, r, e ) ? T ? (e , r, e) ? T } is the neighbor set of entity e; and the vector m k e ,r ? R n denotes the message passed from neighbor entity e to entity e through relation r. Here, ? k e,e ,r represents the attention weight that regulates the importance of the message m k e ,r for entity e; and g(.) is a linear transformation followed by a Tanh function.</p><p>The innovations of our GNN-based model, which we describe in more detail in the following two sections, are (i) we make the message-passing NN to be relation-aware by learning the relation embedding a k r ? R n for each relation r ? R and by integrating it into the entity message passing scheme m k e ,r and (ii) we introduce an attention weight ? k e,e ,r to further enhance the relation-aware capability of our GNN-based embeddings.</p><p>Relation-aware message Unlike existing GNNbased approaches that infer relation embeddings from learned entity embeddings <ref type="bibr" target="#b25">(Sun et al., 2020b)</ref>, our approach allows entity and relation embeddings to be learned jointly and, thus, to both contribute to the message passing neural network. This is achieved through an entity-relation composition operation. The message m k e ,r in Equation 1 is defined as:</p><formula xml:id="formula_1">m k e ,r = a k e ? MLP k comp a k r<label>(2)</label></formula><p>where MLP k comp : R n ? R n is a two-layer MLP with the LeakyReLU activation function.</p><p>Here, the relation embedding is updated by</p><formula xml:id="formula_2">a k+1 r = MLP k rel a k r<label>(3)</label></formula><p>where MLP k rel : R n ? R n maps relations to a new embedding space and allows them to be utilized in the next layer. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation-aware attention</head><p>where MLP k att : R 2?n ? R; and ? denotes the vector concatenation operator. As the message vector m k e ,r contains the information of not only neighbor entity e but also neighbor relation r, our attentive score ? k e,e ,r can capture the importance of the message coming from entity e to entity e conditioned on relation r connecting them.</p><p>Notation extension Recall that we use two different relation-aware GNN encoders as illustrated in <ref type="figure" target="#fig_2">Figure 2</ref>: one for the Completion and one for the Alignment component. To distinguish these two encoders, we use c and a to denote the embedding representations used for the Completion and Alignment components, respectively. In particular, a k e and a k r are now the corresponding embeddings of entity e and relation r at the k-th layer of the relation-aware GNN in the Alignment component. Furthermore, c k e and c k r are the corresponding embeddings of entity e and relation r at the k-th layer of the relation-aware GNN in the Completion component (computed as those of the Alignment component defined in equations 1 and 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Completion component</head><p>The Completion component works similarly to KG embedding models <ref type="bibr" target="#b17">(Nguyen, 2020;</ref><ref type="bibr">Ji et al., 2021)</ref> which compute a score f (e h , r, e t ) for each triple (e h , r, e t ). Our score function f is based on TransE <ref type="bibr" target="#b0">(Bordes et al., 2013)</ref> and is computed across all hidden layers of the relation-aware GNN encoder in the Completion component as follows:</p><p>triples constructed by corrupting either the head or the tail entity the correct triple (e h , r, e t ) ? T . Also, given the availability of the alignment seed set L of pre-aligned entity pairs (e, e * ) among KGs as mentioned in Section 2.2, we additionally compute the following alignment constraint loss:</p><formula xml:id="formula_4">L c_2 = k (e,e * )?L d cos c k e , c k e *<label>(8)</label></formula><p>where d cos denotes the cosine distance.</p><p>To incorporate alignment information into the Completion component, our MKGC loss is computed as the sum of the two losses L c_1 and L c_2 :</p><formula xml:id="formula_5">L c = L c_1 + L c_2 (9)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Alignment component</head><p>The Alignment component is to perform the MKGA task as defined in Section 2.2. We propose to incorporate a structural inconsistency reduction inherited from the Completion into the Alignment component. We also introduce a mechanism to enlarge the alignment seed set L.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural inconsistency reduction (SIR)</head><p>The different completeness levels of KGs lead to structural inconsistencies that might cause incorrect alignment predictions. Fortunately, entity and relation embeddings in the Completion component (i.e. c k e and c k r ) could help reconstruct missing triples, reducing the structural inconsistencies between KGs. To this end, we propose to incorporate the Completion component embeddings at the k-th layer of the relation-aware GNN in the Alignment component as follows:</p><formula xml:id="formula_6">a k e = MLP k a_1 c k e ? a k e ?e (10) a k r = MLP k a_2 c k r ? a k r ?r<label>(11)</label></formula><p>where MLP k a_1 : R 2?n ? R n ; and MLP k a_2 : R 2?n ? R n . The transformed embeddings then will be used as input for the next layer following equations 1 and 3. This allows the structural inconsistency reduction to take place at every GNN layer of the two components, enabling their deep integration.</p><p>Final entity and relation embeddings for MKGA We compute the final embeddings for entities and relations for this Alignment component as follows:</p><formula xml:id="formula_7">a e = MLP a_3 a 0 e ? a 1 e ? ... ? a K e (12) a r = MLP a_4 a 0 r ? a 1 r ? ... ? a K r<label>(13)</label></formula><p>where MLP a_3 : R (K+1)?n ? R n ; and MLP a_4 :</p><formula xml:id="formula_8">R (K+1)?n ? R n .</formula><p>Alignment seed enlargement and Triple transferring (EnTr) As mentioned in Section 2.2, existing alignment models require an alignment seed set L of pre-aligned entity pairs for training. An intuitive approach to improve alignment results is to iteratively increase the size of L during training. The number of alignments by which the size of L is increased should depend on some notion of certainty the Alignment component has in its predictions. For example, in the early stages of the alignment process, when the KGs are still sparsely connected, L should be smaller. The more confident the Alignment component is in its predictions, the larger should L be. Hence, we propose EnTr, a method to enlarge the alignment seed set. EnTr estimates an optimal number of new entity pairs to be added to L according to a measure of alignment certainty. At each training epoch, EnTr first computes an alignment matrix A, where each element is the cosine similarity between any two entity embeddings of the two KGs, that is, A(e, e * ) = 1 ? d cos (a e , a e * ). EnTr then computes the Shannon entropy of the softmax distribution over this alignment matrix:</p><p>P(e * |e) = exp (A(e, e * )) e ?E * exp (A(e, e ))</p><p>H(A) = ? e?E e * ?E * P(e * |e) log P(e * |e) <ref type="formula">(15)</ref> Since the entropy measures the uncertainty of the alignment predictions -lower entropy corresponds to a smaller alignment uncertainty -EnTr implements an uncertainty-mediated estimation of the size q of L as follows:</p><formula xml:id="formula_10">q = ? ? H( A) ? H(A) H( A) ? min(|E|, |E * |) (16)</formula><p>where A is the alignment matrix before training and ? ? [0, 1] is a hyper-parameter controlling the number of new entity pairs to generate. EnTr then chooses the q entity pairs with the q highest cosine similarity scores from A and sets L to contain these entity pairs. EnTr also performs transfer of triples between  the KGs that logically follow from the existing alignments. In particular, for each two aligned entity pairs (e, e * ) and (e , e * ), if r is a relation connecting e and e , EnTr connects e * and e * by r as well. This allows the two KGs' structures to become gradually more similar over time.</p><p>Optimization The learning objective is to minimize the distance between correctly aligned entity pairs while maximizing the distance between negative entity pairs using a margin-based pairwise ranking loss:</p><formula xml:id="formula_11">L a = (e,e * )?L (e,e * )?L</formula><p>[? a +d cos (a e , a e * )?d cos (a e , a e * )] + (17) where ? a &gt; 0 is the margin hyper-parameter; and L is the set of negative entity pairs, which is constructed by replacing one entity of each correctly aligned pair by its nearest entities <ref type="bibr" target="#b33">(Wu et al., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Model training</head><p>We optimize the losses L c and L a iteratively, using two optimizers respectively for the Completion and Alignment losses. In particular, we hold the Alignment component's parameters fixed and optimize only the loss L c . Then we hold the Completion component's parameters fixed and only optimize the loss L a . We keep iterating this process in each training epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>Following previous work <ref type="bibr" target="#b22">(Singh et al., 2021;</ref><ref type="bibr" target="#b5">Huang et al., 2022)</ref>, we conduct experiments using the benchmark DBP-5L 1 <ref type="bibr">(Chen et al., 2020)</ref>, publicly available for both MKGC and MKGA tasks. 2 DBP-5L consists of 1,392 relations, 56,590 entities, and 225,831 triples across the five languages</p><p>Greek (EL), Japanese (JA), French (FR), Spanish (ES), and English (EN). <ref type="table" target="#tab_2">Table 1</ref> presents statistics for each DBP-5L language. Here, each language is referred to as a KG. The DBP-5L benchmark is created for MKGC evaluation. However, each language pair also has pre-aligned entity pairs as the alignment seeds. In particular, on average, about 40% of the entities in each KG have their counterparts at other KGs. Thus, it can also be used for MKGA evaluation <ref type="bibr" target="#b22">(Singh et al., 2021)</ref>. Similar to prior works, we use the same split of training, validation, and test data, for MKGC available in DBP-5L for each KG. For MKGA, we use the same 50-50 split of the alignment seeds for training and test, as used in AlignKGC <ref type="bibr" target="#b22">(Singh et al., 2021)</ref>. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation protocol</head><p>For MKGC, and following previous work <ref type="bibr">(Chen et al., 2020;</ref><ref type="bibr" target="#b22">Singh et al., 2021;</ref><ref type="bibr" target="#b5">Huang et al., 2022)</ref>, each correct test triple (e h , r, e t ) is corrupted by replacing the tail entity e t with each of the other entities in turn, and then the correct test triple and corrupted ones are ranked in descending order of their score. Similar to the previous work, before ranking, we also applied the "Filtered" setting protocol <ref type="bibr" target="#b0">(Bordes et al., 2013)</ref>. We employ standard evaluation metrics, including the mean reciprocal rank (MRR), Hits@1 (i.e. the proportion of correct test triples that are ranked first) and Hits@10 (i.e. the proportion of correct test triples that are ranked in the top 10 predictions). Here, a higher score reflects better prediction result.</p><p>For MKGA, and following previous work <ref type="bibr" target="#b1">(Chen et al., 2017;</ref><ref type="bibr" target="#b33">Wu et al., 2019;</ref><ref type="bibr" target="#b25">Sun et al., 2020b;</ref><ref type="bibr" target="#b22">Singh et al., 2021)</ref>, each correct test pair (e, e * ), where e ? E and e * ? E * , is corrupted by replacing entity e * with each of the other entities from E * in turn, and then the correct test pair and corrupted ones are ranked in descending order of their similarity score. We also employ the evaluation metrics MRR, Hits@1 and Hits@10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Align.</head><p>Greek Japanese French Spanish English H@1 H@10 MRR H@1 H@10 MRR H@1 H@10 MRR H@1 H10 MRR H1 H@10 MRR   <ref type="bibr">(Chen et al., 2020)</ref> and SS-AGA <ref type="bibr" target="#b5">(Huang et al., 2022)</ref> are proposed for MKGC only, employing all alignment seeds, i.e. their "Align." rate is 100%. Results of TransE <ref type="bibr" target="#b0">(Bordes et al., 2013)</ref>, RotatE <ref type="bibr" target="#b27">(Sun et al., 2019)</ref>, KG-BERT <ref type="bibr" target="#b38">(Yao et al., 2019)</ref>, KenS and SS-AGA are taken from <ref type="bibr" target="#b5">Huang et al. (2022)</ref>, that are reported only with surface information (w/ SI). Results of AlignKGC <ref type="bibr" target="#b22">(Singh et al., 2021)</ref> are taken from <ref type="bibr" target="#b22">Singh et al. (2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation details</head><p>The availabilty of surface information (SI) such as entity names makes the alignment problem less challenging <ref type="bibr" target="#b34">(Xiang et al., 2021)</ref>. When surface information is not used by the methods (denoted as w/o SI), the entity and relation embeddings are randomly initialized. When surface information is used (denoted as w/ SI), initial entity and relation embeddings are obtained from pre-trained text embedding models <ref type="bibr" target="#b22">(Singh et al., 2021;</ref><ref type="bibr" target="#b5">Huang et al., 2022)</ref>. Therefore, we also evaluate these two problems and refer to them as JMAC w/o SI and JMAC w/ SI. We implement our model using Pytorch <ref type="bibr" target="#b18">(Paszke et al., 2019)</ref>. We iteratively train our JMAC components up to 30 epochs with two Adam optimizers <ref type="bibr" target="#b8">(Kingma and Ba, 2014)</ref>. We use a grid search to choose the number of GNN hidden layers K ? {1, 2, 3}, the initial Adam learning rates ? ? 1e ?4 , 5e ?4 , 1e ?3 , the controllable hyper-parameter ? ? {0.1, 0.2, 0.3} from Equation 16, the margin hyper-parameters ? c and ? a ? {0, 5, 10}, and the input dimension and MLP hidden sizes n ? {128, 256, 512}. The test set results for the two tasks are reported for the model checkpoint which obtains the highest MRR on the validation set of the MKGC task. <ref type="table" target="#tab_4">Table 2</ref> lists MKGC results for JMAC and other strong baselines on the DBP-5L test sets. Overall, the multilingual models perform better than the monolingual ones. It is not surprising that JMAC and AlignKGC without surface information (w/o SI) obtain lower numbers than their counterparts using SI (w/ SI). For example, with SI information, JMAC achieves an average improvement of about 8% points for Hits@10. Note that, our "JMAC w/o SI" still produces higher Hits@10 results than "AlignKGC w/ SI" on all KGs, and in general, performs better than "AlignKGC w/o SI". Compared to SS-AGA that uses both SI and all available alignment seeds for training, our "JMAC w/o SI" Hits@10 results are about 30% better for Greek, 20% better for Japanese, French and English, and 10% better for Spanish. We find that our "JMAC w/ SI" obtains the highest results across all KGs on all evaluation metrics, producing new state-of-the-art performances (except the second-highest Hits@1 scores on Greek, Spanish and English where "AlignKGC w/ SI" produces the highest Hits@1 scores). <ref type="table">Table 3</ref>   <ref type="table">Table 3</ref>: Ablation study for the MKGC task. (i) w/o RA-GNN: Without using the relation-aware message (Equation 2) and relation-aware attention <ref type="figure">(Equation 4</ref>), here we replace our proposed RA-GNNs by the graph isomorphism networks <ref type="bibr" target="#b35">(Xu et al., 2019)</ref>. (ii) w/ 1-GNN: Both the Completion and Alignment components share the same relation-aware GNN encoder, also leading to "w/o SIR". (iii) w/o SIR: Without using the structural inconsistency reduction mechanism described in Section 3.3, i.e. equations 10 and 11 are not used. (iv) w/o EnTr: Without using the alignment seed enlargement and triple transferring mechanism described in Section 3.3. relation-aware messages and attention (w/o RA-GNN) also demonstrate the importance of the twocomponent architecture design and the relationware message passing scheme. Although the structural inconsistency reduction mechanism aims to improve the alignment performance, we find that without it (w/o SIR), the MKGC performance also declines. This shows that the improvement in the MKGA task can lead to direct improvements in the MKGC task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Main Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">MKGC results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact of alignment seeds</head><p>To have a better insight into how much MKGA can aid MKGC, we evaluate the MKGC task when using alignment seeds with a sampling percentage ranging from 0% to 100% (i.e. using all pre-aligned entity pairs). <ref type="figure" target="#fig_3">Figure 3</ref> shows the MRR scores obtained for this experiment. Overall, our JMAC is improved when using more alignment seeds. The surface information (SI), e.g. entity names, provides informative clues about the similarity between entities across KGs (e.g. two entities with similar names are more likely to be an alignment pair). It is therefore not surprising that "JMAC w/ SI" performs better than "JMAC w/o SI" in all scenarios, especially when the used sampling percentage of alignment seeds is small (i.e. SI becomes more valuable). In addition, the completion performance gradually closer as the sampling percentage approaches 100%. The reason is possibly that when the set of used alignment seeds is large enough, there is not much for surface information to contribute to the alignment performance, which aids the completion performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">MKGA results</head><p>Comparison results <ref type="table" target="#tab_7">Table 4</ref> presents the overall results of different models on the MKGA task. We refer the reader to the Appendix for results on each language pair. Overall, JMAC performs the best in both the "w/ SI" and "w/o SI" categories. Although SS-AGA performs well in the MKGC task, it performs much worse on the alignment task. Specifically, although using SI, it produces the lowest Hits@10. AlignKGC, on the other hand, achieves the third-best results in both categories. However, it is still outperformed by pure KGA models such as AliNet (obtaining 11.1% points higher Hits@1 than AlignKGC in the "w/o SI" cat-   <ref type="bibr" target="#b22">Singh et al. (2021)</ref>. We report our results for other baselines including MTransE <ref type="bibr" target="#b1">(Chen et al., 2017)</ref>, AliNet <ref type="bibr" target="#b25">(Sun et al., 2020b)</ref>, SS-AGA, PSR <ref type="bibr" target="#b13">(Mao et al., 2021)</ref> and RDGCN <ref type="bibr" target="#b33">(Wu et al., 2019)</ref>, employing their publicly released implementations. See the Appendix for the training protocols of these baselines. SS-AGA is originally proposed and evaluated for MKGC only. However, it also computes and defines an alignment matrix, thus we can also evaluate SS-AGA for the MKGA task using this matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variants</head><p>Overall <ref type="formula">Hits@1</ref>   egory) and RDGCN (obtaining 4.5% points higher Hits@1 than AlignKGC in the "w/ SI" category).</p><p>Ablation study <ref type="table" target="#tab_9">Table 5</ref> shows the ablation results on the MKGA task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We proposed JMAC, a method for joint multilingual knowledge graph completion and alignment. JMAC consists of a Completion and Alignment component and uses a new class of relationaware GNNs for learning entity and relation embeddings suitable for both the completion and alignment tasks. We also propose a structural inconsistency reduction mechanism that fuses entity and relation embeddings from the Completion component with those of the Alignment component. We also introduce another mechanism to enlarge alignment seeds and transfer triples among KGs during training. Extensive experiments using the benchmark DBP-5L <ref type="bibr">(Chen et al., 2020)</ref> show that JMAC performs better than previous strong baselines, producing state-of-the-art results. We publicly release the implementation of our JMAC at https://github.com/vinhsuhi/JMAC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>Our experimental results demonstrate that our JMAC model effectively solves the structural inconsistency problem. However, our model works based on the assumption that the surface information (SI), i.e. entity name, of an entity across different KG languages is the same or similar. In fact, some entities might have very different SI compared to their versions across different KGs, due to incorrect annotations during KGs construction or different description caused by the language barrier. We refer this issue to as SI inconsistency. When the level of SI inconsistency is high, using SI information might have reversed impacts on the model performance. A robust model should be able to decide how much it can rely on the SI. Our model has no mechanism to perform that at the moment.      <ref type="bibr" target="#b26">Sun et al. (2020c)</ref>. Here, RDGCN is the best performing model among 12 different models experimented by <ref type="bibr" target="#b26">Sun et al. (2020c)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>The incompleteness of KG (missing triple (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>The overall architecture of JMAC</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>(v) w/o Align.: Model variant containing only the Completion component without the Alignment one. MKGC MRR results w.r.t different sampling percentages of alignment seed pairs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>We define the weight ? k e,e ,r in Equation 1 to be relation-aware as:</figDesc><table><row><cell>? k e,e ,r =</cell><cell>exp MLP k att a k e ? m k e ,r exp MLP k att a k e ? m k e",r"</cell></row><row><cell></cell><cell>(e",r")?N (e)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics of DBP-5L.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>MKGC results. All metrics are reported in %. Here, H@1 and H@10 abbreviate Hits@1 and Hits@10, respectively. "Align." denotes the percentage of alignment seeds used by each model when training. The first three models are monolingual baselines (i.e. equivalent to the "Align." rate of 0%), while the remaining models are multilingual ones. KenS</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>MRR H@1 H@10 MRR H@1 H@10 MRR H@1 H@10 MRR H@1 H@10 MRR JMAC w/ SI 55.2 97.5 71.7 53.3 91.4 66.8 49.3 91.3 64.5 45.4 88.2 61.0 29.5 72.7 44.6 (i) w/o RA-GNN 53.3 95.3 70.6 49.1 90.7 63.8 46.4 88.7 61.0 43.6 85.4 59.3 27.1 71.1 42.3</figDesc><table><row><cell cols="2">Greek H@1 H@10 (ii) w/ 1-GNN Variants 51.1 92.4 64.2 49.1 90.3 63.1 46.1 87.1 60.8 41.4 82.4 56.1 27.2 68.3 41.6 Japanese French Spanish English</cell></row><row><cell>(iii) w/o SIR</cell><cell>54.8 96.8 71.1 50.9 91.1 64.3 48.2 90.3 63.6 44.9 86.3 60.5 28.4 71.4 43.3</cell></row><row><cell>(iv) w/o EnTr</cell><cell>41.5 87.1 57.3 39.7 80.6 54.4 40.5 80.3 54.2 36.3 76.3 50.5 27.2 67.3 39.3</cell></row><row><cell>(v) w/o Align.</cell><cell>35.3 83.4 52.1 35.3 75.8 48.8 35.3 76.8 49.9 29.3 69.1 46.3 23.5 55.8 34.8</cell></row><row><cell></cell><cell>presents ablation results.</cell></row><row><cell></cell><cell>Removing or replacing any component or mech-</cell></row><row><cell></cell><cell>anism decreases the model's performance. The</cell></row><row><cell></cell><cell>largest decrease is observed without the use of</cell></row><row><cell></cell><cell>the Alignment component (w/o Align.) where the</cell></row><row><cell></cell><cell>MRR scores drop about 15% points on average.</cell></row><row><cell></cell><cell>The model also performs substantially poorer when</cell></row><row><cell></cell><cell>it is not using the alignment seed enlargement and</cell></row><row><cell></cell><cell>triple transferring mechanism (w/o EnTr). Here,</cell></row><row><cell></cell><cell>the model's Hits@10 scores decrease about 10% in</cell></row><row><cell></cell><cell>Greek, Japanese, French and Spanish. The perfor-</cell></row><row><cell></cell><cell>mance drops incurred by using the same relation-</cell></row><row><cell></cell><cell>aware GNN encoder (w/ 1-GNN) or not using</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>MKGA results. Results for AlignKGC are taken from</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Ablation study for the MKGA task. (v) w/o Comple.: Model variant containing only the Alignment component without the Completion one.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>The EnTr mechanism improves the model Hits@10 by about 2% points (w/o EnTr 95.6% ? 97.5%). In the absence of SIR (w/o SIR), the alignment performance suffers a drop in each evaluation metric (2.1% points for Hits@1, 3.2% points for Hits@10, and 2.5% points for MRR).</figDesc><table><row><cell>The model performance drops by about 5.3% points in Hits@10 without the relation-aware messages and attention (w/o RA-GNN), confirming that the relation-aware mecha-nism is a crucial part of our model. Using only one GNN encoder (w/ 1-GNN) for both Completion and Alignment components performs worse. This indicates that combining the objective functions and using the same feature for multiple tasks might not be optimal. This indicates that the structural inconsistency re-duction improves alignment performance. As the Completion component only aids the Alignment component through the SIR mechanism, the model variant without Completion component (w/o Com-ple.) has the same alignment performance as the model variant "w/o SIR".</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>MKGA MRR results. Singh et al. (2021) do not report the MRR results for AlignKGC.</figDesc><table><row><cell>Variants</cell><cell cols="11">EL-EN EL-ES EL-FR EL-JA EN-FR ES-EN ES-FR JA-EN JA-ES JA-FR Overall</cell></row><row><cell>JMAC w/ SI</cell><cell>93.1</cell><cell>92.8</cell><cell>92.4</cell><cell>93.8</cell><cell>94.5</cell><cell>93.3</cell><cell>94.5</cell><cell>94.7</cell><cell>91.9</cell><cell>93.1</cell><cell>93.4</cell></row><row><cell cols="2">(i) w/o RA-GNN 89.0</cell><cell>89.4</cell><cell>85.1</cell><cell>89.3</cell><cell>91.4</cell><cell>89.6</cell><cell>90.7</cell><cell>90.4</cell><cell>87.3</cell><cell>88.2</cell><cell>89.3</cell></row><row><cell>(ii) w/ 1-GNN</cell><cell>60.3</cell><cell>72.1</cell><cell>63.6</cell><cell>66.8</cell><cell>59.1</cell><cell>67.1</cell><cell>71.0</cell><cell>52.3</cell><cell>56.8</cell><cell>63.8</cell><cell>62.4</cell></row><row><cell>(iii) w/o SIR</cell><cell>90.1</cell><cell>90.4</cell><cell>87.8</cell><cell>91.7</cell><cell>92.9</cell><cell>91.3</cell><cell>92.6</cell><cell>92.5</cell><cell>89.9</cell><cell>90.8</cell><cell>91.3</cell></row><row><cell>(iv) w/o EnTr</cell><cell>92.6</cell><cell>92.1</cell><cell>88.9</cell><cell>93.5</cell><cell>94.0</cell><cell>93.1</cell><cell>94.1</cell><cell>93.9</cell><cell>91.2</cell><cell>92.9</cell><cell>92.9</cell></row><row><cell>(v) w/o Comple.</cell><cell>90.1</cell><cell>90.4</cell><cell>87.8</cell><cell>91.7</cell><cell>92.9</cell><cell>91.3</cell><cell>92.6</cell><cell>92.5</cell><cell>89.9</cell><cell>90.8</cell><cell>91.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>Ablation Hits@1 results for the MKGA task.</figDesc><table><row><cell>Variants</cell><cell cols="11">EL-EN EL-ES EL-FR EL-JA EN-FR ES-EN ES-FR JA-EN JA-ES JA-FR Overall</cell></row><row><cell>JMAC w/ SI</cell><cell>97.5</cell><cell>97.8</cell><cell>96.8</cell><cell>97.6</cell><cell>97.8</cell><cell>97.7</cell><cell>97.8</cell><cell>98.2</cell><cell>95.8</cell><cell>97.6</cell><cell>97.5</cell></row><row><cell cols="2">(i) w/o RA-GNN 91.3</cell><cell>92.1</cell><cell>91.6</cell><cell>93.3</cell><cell>92.7</cell><cell>93.4</cell><cell>92.5</cell><cell>93.1</cell><cell>90.8</cell><cell>91.3</cell><cell>92.2</cell></row><row><cell>(ii) w/ 1-GNN</cell><cell>63.3</cell><cell>76.4</cell><cell>65.2</cell><cell>69.3</cell><cell>64.3</cell><cell>71.1</cell><cell>73.3</cell><cell>55.2</cell><cell>57.8</cell><cell>65.3</cell><cell>65.4</cell></row><row><cell>(iii) w/o SIR</cell><cell>94.1</cell><cell>95.3</cell><cell>93.6</cell><cell>94.1</cell><cell>95.2</cell><cell>95.0</cell><cell>94.2</cell><cell>95.1</cell><cell>92.3</cell><cell>94.4</cell><cell>94.3</cell></row><row><cell>(iv) w/o EnTr</cell><cell>95.6</cell><cell>95.9</cell><cell>94.9</cell><cell>95.0</cell><cell>95.8</cell><cell>96.1</cell><cell>95.8</cell><cell>96.2</cell><cell>94.2</cell><cell>96.4</cell><cell>95.6</cell></row><row><cell>(v) w/o Comple.</cell><cell>94.1</cell><cell>95.3</cell><cell>93.6</cell><cell>94.1</cell><cell>95.2</cell><cell>95.0</cell><cell>94.2</cell><cell>95.1</cell><cell>92.3</cell><cell>94.4</cell><cell>94.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>Ablation Hits@10 results for the MKGA task.Variants EL-EN EL-ES EL-FR EL-JA EN-FR ES-EN ES-FR JA-EN JA-ES JA-FR Overall JMAC w/ SITable 11: Ablation MRR results for the MKGA task.</figDesc><table><row><cell></cell><cell>95.3</cell><cell>95.0</cell><cell>94.6</cell><cell>95.2</cell><cell>94.6</cell><cell>95.7</cell><cell>96.0</cell><cell>96.3</cell><cell>93.3</cell><cell>95.3</cell><cell>95.1</cell></row><row><cell cols="2">(i) w/o RA-GNN 90.1</cell><cell>91.1</cell><cell>90.3</cell><cell>92.4</cell><cell>91.6</cell><cell>91.3</cell><cell>91.4</cell><cell>91.7</cell><cell>89.7</cell><cell>89.3</cell><cell>90.9</cell></row><row><cell>(ii) w/ 1-GNN</cell><cell>61.4</cell><cell>73.7</cell><cell>64.6</cell><cell>67.3</cell><cell>60.1</cell><cell>68.4</cell><cell>72.6</cell><cell>53.7</cell><cell>57.6</cell><cell>64.4</cell><cell>64.0</cell></row><row><cell>(iii) w/o SIR</cell><cell>93.2</cell><cell>93.1</cell><cell>91.4</cell><cell>91.6</cell><cell>92.4</cell><cell>93.6</cell><cell>92.7</cell><cell>93.5</cell><cell>90.3</cell><cell>93.6</cell><cell>92.6</cell></row><row><cell>(iv) w/o EnTr</cell><cell>95.0</cell><cell>94.6</cell><cell>93.2</cell><cell>93.5</cell><cell>94.3</cell><cell>95.5</cell><cell>94.8</cell><cell>95.3</cell><cell>92.3</cell><cell>95.2</cell><cell>94.5</cell></row><row><cell>(v) w/o Comple.</cell><cell>93.2</cell><cell>93.1</cell><cell>91.4</cell><cell>91.6</cell><cell>92.4</cell><cell>93.6</cell><cell>92.7</cell><cell>93.5</cell><cell>90.3</cell><cell>93.6</cell><cell>92.6</cell></row><row><cell>KG Pairs</cell><cell>KGs</cell><cell cols="10">V1 #Entity #Relation #Triple #Entity #Relation #Triple V2</cell></row><row><cell>EN-FR-15K</cell><cell>EN FR</cell><cell cols="2">15,000 15,000</cell><cell>267 210</cell><cell cols="3">47,334 15,000 40,864 15,000</cell><cell></cell><cell>193 166</cell><cell>96,318 80,112</cell><cell></cell></row><row><cell>EN-DE-15K</cell><cell>EN DE</cell><cell cols="2">15,000 15,000</cell><cell>215 131</cell><cell cols="3">47,676 15,000 50,419 15,000</cell><cell></cell><cell>169 96</cell><cell>84,867 92,632</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12 :</head><label>12</label><figDesc>Statistics of bilingual KG pairs from the OpenEA 15K benchmark DBP1.0.</figDesc><table><row><cell>KG Pairs</cell><cell>Metric</cell><cell cols="6">w/o SI MTransE AliNet JMAC RDGCN PSR JMAC w/ SI</cell></row><row><cell></cell><cell>Hits@1</cell><cell>24.7</cell><cell>38.8</cell><cell>58.8</cell><cell>75.4</cell><cell>76.5</cell><cell>90.0</cell></row><row><cell>EN-FR-15K V1</cell><cell>Hits@10</cell><cell>56.3</cell><cell>82.9</cell><cell>83.2</cell><cell>88.1</cell><cell>93.2</cell><cell>98.0</cell></row><row><cell></cell><cell>MRR</cell><cell>35.2</cell><cell>48.5</cell><cell>67.4</cell><cell>80.1</cell><cell>82.3</cell><cell>93.0</cell></row><row><cell></cell><cell>Hits@1</cell><cell>24.1</cell><cell>58.1</cell><cell>70.9</cell><cell>84.7</cell><cell>92.5</cell><cell>97.1</cell></row><row><cell>EN-FR-15K V2</cell><cell>Hits@10</cell><cell>24.0</cell><cell>87.8</cell><cell>89.0</cell><cell>93.4</cell><cell>98.4</cell><cell>99.6</cell></row><row><cell></cell><cell>MRR</cell><cell>33.7</cell><cell>69.2</cell><cell>77.7</cell><cell>88.0</cell><cell>94.3</cell><cell>98.1</cell></row><row><cell></cell><cell>Hits@1</cell><cell>30.8</cell><cell>61.0</cell><cell>73.2</cell><cell>83.0</cell><cell>88.2</cell><cell>94.3</cell></row><row><cell>EN-DE-15K V1</cell><cell>Hits@10</cell><cell>61.1</cell><cell>83.1</cell><cell>90.9</cell><cell>91.4</cell><cell>95.5</cell><cell>99.0</cell></row><row><cell></cell><cell>MRR</cell><cell>41.0</cell><cell>68.2</cell><cell>79.5</cell><cell>85.6</cell><cell>91.4</cell><cell>96.1</cell></row><row><cell></cell><cell>Hits@1</cell><cell>19.4</cell><cell>81.5</cell><cell>89.8</cell><cell>83.4</cell><cell>96.5</cell><cell>97.8</cell></row><row><cell>EN-DE-15K V2</cell><cell>Hits@10</cell><cell>43.2</cell><cell>93.0</cell><cell>97.1</cell><cell>93.6</cell><cell>99.1</cell><cell>99.5</cell></row><row><cell></cell><cell>MRR</cell><cell>27.4</cell><cell>85.6</cell><cell>92.5</cell><cell>86.1</cell><cell>97.7</cell><cell>98.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 13 :</head><label>13</label><figDesc>DBP1.0 test set results. We report our results for AliNet and PSR using their publicly released implementations. Results for MTransE and RDGCN are taken from</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">f k (e h , r, e t ) = ? c k e h + c k r ? c k et 1 (5) f (e h , r, e t ) = k f k (e h , r, e t )(6)We use a margin-based pairwise ranking loss<ref type="bibr" target="#b0">(Bordes et al., 2013)</ref> across all hidden layers:Lc_1 = k (e h ,r,e t )?T (e h ,r,e t )?T [?c ? f k (e h , r, et) + f k (e h , r, et)]+ (7)where [x] + = max(0, x); ? c &gt; 0 is the margin hyper-parameter; and T is the set of incorrect</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/stasl0217/KEnS/ tree/main/data 2<ref type="bibr" target="#b5">Huang et al. (2022)</ref> create another multilingual benchmark named E-PKG (to be released at https://github. com/amzn/ss-aga-kgc), however, it is not yet available as of 24/06/2022, EMNLP 2022's submission deadline.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">JMAC can perform KGA on a benchmark that is purely constructed for the KGA task. We show state-of-the-art results obtained for JMAC on a KGA benchmark in the Appendix.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Training protocols for baselines</head><p>For the baseline alignment models listed in <ref type="table">Table 4</ref>, we apply the same training protocol as detailed in Section 4.3 w.r.t. the optimizer, the hidden layers, the initial learning rate values and the number of training epochs. For GNN-based alignment models AliNet, SS-AGA, PSR and RDGCN, we also search their number of GNN layers from {1, 2, 3}. For their other hyper-parameters, we use their implementation's default values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 MKGA results on the DBP-5L dataset</head><p>Tables 6-11 detail alignment results of experimental models as well as ablation results of our JMAC for all language pairs in the DBP-5L dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Additional results for the KGA task</head><p>Note that our JMAC can perform KGA on a benchmark that is purely constructed for the KGA task.</p><p>To further demonstrate the effectiveness of our JMAC, we conduct an additional KGA experiment using bilingual KG pairs from the OpenEA 15K benchmark DBP1.0 <ref type="bibr" target="#b26">(Sun et al., 2020c)</ref>. Each KG pair consists of two versions V1 and V2 which are the sparse and dense ones, respectively. The alignment seeds are divided into 20%, 10%, and 70% for training, validation and test, respectively. Statistics of the bilingual KG pairs from the OpenEA 15K benchmark DBP1.0 are presented in <ref type="table">Table 12</ref>. For this entity alignment experiment, training protocols of JMAC and baselines are the same as described in Sections 4.3 and A.1. Here, the test set results are reported for the model checkpoint which obtains the highest MRR on the validation set. <ref type="table">Table 13</ref> reports obtained alignment results on the test sets, where our JMAC performs better than the baselines in both the "w/ SI" and "w/o SI" categories, obtaining new state-of-the-art performances.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Translating Embeddings for Modeling Multi-Relational Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Dur?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multilingual Knowledge Graph Embeddings for Cross-Lingual Knowledge Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ankith Uppunda, Yizhou Sun, and Carlo Zaniolo. 2020. Multilingual Knowledge Graph Completion via Ensemble Knowledge Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuelu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changjun</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<title level="m">Convolutional 2D Knowledge Graph Embeddings. In AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">DSKG: A deep sequential model for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingbing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyi</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCKS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multilingual Knowledge Graph Completion with Self-Supervised Adaptive Graph Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoming</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Subbian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoxiong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pekka</forename><surname>Marttinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">2021. A Survey on Knowledge Graphs: Representation, Acquisition, and Applications. TNNLS</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">AttnIO: Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehun</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bokyung</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwon</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Network Similarity Decomposition (NSD): A Fast and Scalable Approach to Network Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Kollias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahin</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananth</forename><surname>Grama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>TKDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
		</author>
		<title level="m">DBpedia -A Large-scale, Multilingual Knowledge Base Extracted from Wikipedia. SWJ</title>
		<meeting><address><addrLine>Mohamed Morsey, Patrick van Kleef, S?ren Auer</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning Entity and Relation Embeddings for Knowledge Graph Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Analogical Inference for Multi-Relational Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Are Negative Samples Necessary in Entity Alignment? An Approach with High Performance, Scalability and Robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ba-belNet: Building a Very Large Multilingual Semantic Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Novel Embedding Model for Knowledge Base Completion Based on Convolutional Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><forename type="middle">Dinh</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dinh Phung, and Dat Quoc Nguyen. 2022. Node Co-occurrence based Graph Neural Networks for Knowledge Graph Link Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinh</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A survey of embedding models of entities and relationships for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dat Quoc Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>In TextGraphs</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Learning a Health Knowledge Graph from Electronic Medical Records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Rotmensch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoni</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdulhakim</forename><surname>Tlimat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Horng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Scientific Reports</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Modeling Relational Data with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michael Sejr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESWC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">End-toend Structure-Aware Convolutional Networks for Knowledge Base Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinbo</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multilingual Knowledge Graph Completion with Joint Relation and Entity Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harkanwar</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prachi</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AKBC</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">YAGO: A Core of Semantic Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dual Attention Network for Cross-lingual Entity Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood Aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Benchmarking Study of Embedding-Based Entity Alignment for Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farahnaz</forename><surname>Akrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Two-view Graph Neural Networks for Knowledge Graph Completion</title>
		<idno type="arXiv">arXiv:2112.09231</idno>
		<editor>Vinh Tong, Dai Quoc Nguyen, Dinh Phung, and Dat Quoc Nguyen. 2021</editor>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Th?o</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Vikram Nitin, and Partha Talukdar. 2020. Composition-based Multi-Relational Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Vashishth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Knowledge Graph Embedding by Translating on Hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingsong</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Relation-Aware Entity Alignment for Heterogeneous Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuting</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">OntoEA: Ontology-guided Entity Alignment via Joint Knowledge Graph Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuejia</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaoyan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenxi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yefeng</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of ACL</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">How Powerful are Graph Neural Networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Representation Learning on Graphs with Jumping Knowledge Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengtao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomohiro</forename><surname>Sonobe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken-Ichi</forename><surname>Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Embedding Entities and Relations for Learning and Inference in Knowledge Bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">KG-BERT: BERT for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengsheng</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.03193</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Knowledge Graph Enhanced Neural Machine Translation via Multi-task Learning on Sub-entity Granularity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
		<editor>COLING. Method EL -EN EL -ES EL -FR EL -JA EN -FR ES -EN ES -FR JA -EN JA -ES JA -FR Overall w/o SI AlignKGC ----------</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">MKGA Hits@1 results</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">El -En El -Es El -Fr El -Ja En -Fr Es -En Es -Fr Ja -En Ja -Es Ja -Fr</forename><surname>Method</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Overall W/</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">SI AlignKGC ----------</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<title level="m">MKGA Hits@10 results</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">El -En El -Es El -Fr El -Ja En -Fr Es -En Es -Fr Ja -En Ja -Es Ja -Fr</forename><surname>Method</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SI MTransE</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
