<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Video Polyp Segmentation: A Deep Learning Perspective</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge-Peng</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research School of Engineering</orgName>
								<orgName type="institution">Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guobao</forename><surname>Xiao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer and Control Engineering</orgName>
								<orgName type="institution">Minjiang University</orgName>
								<address>
									<settlement>Fuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Cheng</forename><surname>Chou</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng-Ping</forename><surname>Fan</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Z?rich</orgName>
								<address>
									<settlement>Z?rich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Radiological Sciences</orgName>
								<orgName type="institution">UCLA</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geng</forename><surname>Chen</surname></persName>
							<affiliation key="aff5">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">NPU</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><forename type="middle">Van</forename><surname>Gool</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Z?rich</orgName>
								<address>
									<settlement>Z?rich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Video Polyp Segmentation: A Deep Learning Perspective</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Springer Nature 2021 L A T E X template Project Page: https://github.com/GewelsJI/VPS.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Video polyp segmentation</term>
					<term>dataset</term>
					<term>self-attention</term>
					<term>colonoscopy</term>
					<term>abdomen</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present the first comprehensive video polyp segmentation (VPS) study in the deep learning era. Over the years, developments in VPS are not moving forward with ease due to the lack of a large-scale dataset with fine-grained segmentation annotations. To address this issue, we first introduce a high-quality frame-by-frame annotated VPS dataset, named SUN-SEG, which contains 158,690 colonoscopy video frames from the well-known SUN-database. We provide additional annotation covering diverse types, i.e., attribute, object mask, boundary, scribble, and polygon. Second, we design a simple but efficient baseline, named PNS+, which consists of a global encoder, a local encoder, and normalized self-attention (NS) blocks. The global and local encoders receive an anchor frame and multiple successive frames to extract long-term and short-term spatial-temporal representations, which are then progressively refined by two NS blocks. Extensive experiments show that PNS+ achieves the best performance and real-time inference speed (170fps), making it a promising solution for the VPS task. Third, we extensively evaluate 13 representative polyp/object segmentation models on our SUN-SEG dataset and provide attribute-based comparisons. Finally, we discuss several open issues and suggest possible research directions for the VPS community.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As the second most deadly cancer and the third most common malignancy, colorectal cancer (CRC) is estimated to cause millions of incidence ? Equal contribution. Corresponding author.</p><p>cases and deaths yearly. The survival rate of CRC patients is over 95% at the first stage of the disease but dramatically decreases to lower than 35% at the fourth and fifth stages <ref type="bibr" target="#b0">[1]</ref>. Therefore, early diagnosis of positive CRC cases through screening techniques, such as colonoscopy and sigmoidoscopy, is vital in increasing the survival rate. For prevention purposes, physicians can remove the colon polyps that risk turning into cancer. However, this process highly depends on the physicians' experience and suffers from a high polyp missing rate, i.e., 22% ? 28% <ref type="bibr" target="#b1">[2]</ref>.</p><p>Recently, artificial intelligence (AI) techniques are applied to the automatic detection of candidate lesion polyps during colonoscopy for physicians. However, developing AI models with a satisfactory detection rate is still challenging due to two problems: (a) Limited Annotated Data. Deep learning models are often hungry for a large-scale video dataset with densely-annotated labels. Moreover, a community-agreed benchmark is missing for evaluating the approaches' actual performance. (b) Dynamic Complexity. The colonoscopy usually involves less ideal conditions of camera-moving acquisition, such as the diversity of colon polyps (e.g., boundary contrast, shape, orientation, shooting angle), internal artifacts (e.g., water flow, residue), and imaging degradation (e.g., color distortion, specular reflection). To this end, we present a systematic study to facilitate the development of deep learning models for video polyp segmentation (VPS). The main contributions of this work are summarized as follows:</p><p>? VPS Dataset. We elaborately introduce a large-scale VPS dataset termed SUN-SEG, containing 158, 690 frames selected from the SUNdatabase <ref type="bibr" target="#b3">[3]</ref>. We provide a variety of labels, including attribute, object mask, boundary, scribble, and polygon. These labels can further support the development of colonoscopy diagnosis, localization, and derivative tasks. ? VPS Baseline. We design a simple but efficient VPS baseline, named PNS+, which consists of a global encoder, a local encoder, and two normalized self-attention (NS) blocks. The global and local encoders extract longand short-term spatial-temporal representations from the first anchor frame and multiple successive frames, respectively. The NS block dynamically updates the receptive field when coupling attentive cues among extracted features. Experiments show that PNS+ achieves the best performance on challenging SUN-SEG dataset. ? VPS Benchmark. To comprehensively understand VPS development, we conduct the first large-scale benchmark by evaluating 13 cuttingedge polyp/object segmentation approaches. Based on the benchmarking results (i.e., five image-based and eight video-based), we argue that the VPS task is not well undertaken and leaves plenty of room for further exploration.</p><p>A preliminary version of this work was presented in <ref type="bibr" target="#b4">[4]</ref>. In this extended work, we introduce three different contributions.</p><p>? In Sec. 3, we introduce a high-quality denselyannotated VPS dataset, SUN-SEG, with five extended labels, i.e., attribute, object mask, boundary, scribble, and polygon. ? Based on the normalized self-attention block as in <ref type="bibr" target="#b4">[4]</ref>, we propose a global-to-local learning paradigm to realize the modeling of both longterm and short-term dependencies. This part is detailed in Sec. 4.3. ? As shown in Sec. 5, we construct the first large-scale benchmark on the VPS task, which contains 13 the latest polyp/object segmentation competitors. We highlight several potential research directions based on the above benchmark results and progress in the VPS field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>This section reviews the recent efforts in computer-aided polyp diagnosis from the following two aspects: colonoscopy-related datasets (Sec. 2.1) and approaches (Sec. 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Colonoscopy-Related Datasets</head><p>Recently, several datasets have been collected for the examination of human colonoscopy. As shown in <ref type="table" target="#tab_0">Table 1</ref>, we summarize some key statistics of 20 popular datasets and our SUN-SEG dataset. In light of the task definition, we categorize them into three main-stream partitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Classification</head><p>There are four popular datasets for the initial purpose of identifying gastrointestinal lesions. ColonoscopicDS <ref type="bibr" target="#b7">[7]</ref> collects 76 regular colonoscopy videos with three types of gastrointestinal lesions, including hyperplasic, serrated, and adenoma lesions. Kvasir <ref type="bibr" target="#b14">[13]</ref> contains 8 types of anatomical landmarks (i.e., polyps, esophagitis, ulcerative colitis, z-line, pylorus, cecum, dyed polyp, and </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Detection</head><p>There are five widely-accepted video datasets mainly used for the detection task. CVC-ClinicVideoDB <ref type="bibr" target="#b9">[9]</ref>, as the early video dataset, comprises 18 videos with a total number of 11, 954 frames in which 10, 025 frames contain at least a polyp. As for the largest denselyannotated video polyp detection dataset, SUNdatabase <ref type="bibr" target="#b3">[3]</ref> consists of 49, 136 positive samples with their bounding boxes acquired from 99 patients. More recently, two video datasets (i.e., Kvasir-Capsule <ref type="bibr" target="#b19">[18]</ref> and KUMC <ref type="bibr" target="#b22">[21]</ref>) are applied for both detection and classification tasks. Especially, the former provides 47, 238 bounding box labels from 14 lesion classes, and the latter has 37, 899 frames with bounding box labels. Unlike the above datasets, LDPolypVideo <ref type="bibr" target="#b21">[20]</ref> includes 40, 266 frames with circular annotations from 160 colonoscopy videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Segmentation</head><p>As for the video datasets, the early benchmark CVC-EndoSceneStill <ref type="bibr" target="#b10">[10]</ref> opts for the combination of CVC-ColonDB <ref type="bibr" target="#b0">[1]</ref> and CVC-ClinicDB <ref type="bibr" target="#b6">[6]</ref>. ETIS-Larib <ref type="bibr" target="#b5">[5]</ref> provides 196 labeled samples from 32 colonoscopy videos, containing about five frames for each sequence. EDD2020 <ref type="bibr" target="#b15">[14]</ref> contains 386 endoscopy images from five different institutions and multiple gastrointestinal organs. They provide annotations for disease detection, localization, and segmentation. PICCOLO <ref type="bibr" target="#b18">[17]</ref> also samples 3, 433 frames from 40 videos with sparse annotations. As such, the above five video datasets adopt the sampling annotation strategy, which still lacks per-frame masks on each video sequence due to the labor-intensive annotation process. Being the pioneering video dataset with densely-annotated masks, ASU-Mayo <ref type="bibr" target="#b8">[8]</ref> contains 36, 458 continuous frames from 38 videos, while it only provides 3, 856 labels for 10 positive videos. Recently, PolypGen <ref type="bibr" target="#b23">[22]</ref> has collected a multi-centre dataset incorporating more than 300 patients, including single and continuous frames with 3, 788 annotated segmentation masks and bounding box labels. Unlike existing works, we introduce SUN-SEG, the first high-quality densely-annotated dataset for the VPS task, which contains rich annotated labels, such as object mask, boundary, scribble, polygon, and attribute. We hope that this work could fuel the development of colonoscopy diagnosis, localization, and derivative tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Colonoscopy-Related Methods</head><p>Early solutions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">[23]</ref><ref type="bibr" target="#b26">[24]</ref><ref type="bibr" target="#b27">[25]</ref> have been dedicated to identifying colon polyps via mining hand-crafted patterns, such as color, shape, texture, and superpixel. However, they usually suffer from low accuracy due to the limited capability of representing heterogeneous polyps, as well as the close resemblance between polyps and hard mimics <ref type="bibr" target="#b28">[26]</ref>. In contrast, data-driven AI techniques can handle these challenging conditions with better learning ability. This section mainly focuses on tracking the latest image/video polyp segmentation techniques <ref type="bibr" target="#b29">[27]</ref>, while leaving the systematic review of polyp classification <ref type="bibr" target="#b30">[28,</ref><ref type="bibr" target="#b32">29]</ref> and detection <ref type="bibr" target="#b33">[30,</ref><ref type="bibr" target="#b34">31]</ref> in our future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Image Polyp Segmentation (IPS)</head><p>Several methods have been proposed to locate the pixel-level polyp regions from the colonoscopy images. They can be grouped into two major categories. (a) CNN-based Approaches. Brandao et al. <ref type="bibr" target="#b35">[32]</ref> adopted a fully convolutional network (FCN) with a pre-trained model to segment polyps. Later, Akbari et al. <ref type="bibr" target="#b37">[33]</ref> introduced a modified FCN to improve the segmentation accuracy. Inspired by the vast success of UNet <ref type="bibr" target="#b38">[34]</ref> in biomedical image segmentation, UNet++ <ref type="bibr" target="#b39">[35]</ref> and ResUNet <ref type="bibr" target="#b40">[36]</ref> were employed for polyp segmentation for improved performance. Furthermore, PolypSeg <ref type="bibr" target="#b41">[37]</ref>, ACS <ref type="bibr" target="#b43">[38]</ref>, ColonSegNet <ref type="bibr" target="#b44">[39]</ref> and SCR-Net <ref type="bibr" target="#b45">[40]</ref> explore the effectiveness of UNetenhanced architecture on adaptively learning semantic contexts. As the newly-proposed methods, SANet <ref type="bibr" target="#b46">[41]</ref> and MSNet <ref type="bibr" target="#b47">[42]</ref> design the shallow attention module and subtraction unit, respectively, to achieve precise and efficient segmentation. Additionally, several works opt for introducing additional constraints via three main-stream manners: exerting explicit boundary supervision <ref type="bibr" target="#b48">[43]</ref><ref type="bibr" target="#b49">[44]</ref><ref type="bibr" target="#b50">[45]</ref><ref type="bibr" target="#b52">[46]</ref><ref type="bibr" target="#b53">[47]</ref>, introducing implicit boundary-aware representation <ref type="bibr" target="#b54">[48]</ref><ref type="bibr" target="#b55">[49]</ref><ref type="bibr" target="#b57">[50]</ref>, and exploring uncertainty for the ambiguous regions <ref type="bibr" target="#b58">[51]</ref>. (b) Transformerbased Approaches. Recently, Transformers <ref type="bibr" target="#b59">[52]</ref> have been gaining popularity thanks to their powerful modeling ability. TransFuse <ref type="bibr" target="#b60">[53]</ref> combines the Transformer and CNN, termed the parallel-inbranch scheme, for capturing global dependencies and low-level spatial details. Besides, A BiFusion module was designed to fuse multi-level features from both branches. Segtran <ref type="bibr" target="#b61">[54]</ref> proposes a squeezed attention block that regularizes selfattention, and the expansion block learns diversified representations. A positional encoding scheme was proposed to impose an inductive continuity bias. Based on PVT <ref type="bibr" target="#b62">[55]</ref>, Dong et al. <ref type="bibr" target="#b63">[56]</ref> introduced a model with three tight components, i.e., cascaded fusion, camouflage identification, and similarity aggregation modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Video Polyp Segmentation (VPS)</head><p>Despite their progress, existing IPS methods suffer from an inherent limitation of overlooking the valuable temporal cues in the colonoscopy videos. Therefore, efforts have been dedicated to combining spatial-temporal features among consecutive video frames. A hybrid 2/3D CNN framework <ref type="bibr" target="#b1">[2]</ref> was proposed to aggregate spatial-temporal correlations and achieves better segmentation results. However, the kernel size restricts the spatial correlation between frames, restricting the accurate segmentation of fast movements of polyps. To alleviate the above problem, PNSNet <ref type="bibr" target="#b4">[4]</ref> introduces a normalized self-attention (NS) block to learn spatial-temporal representations with neighborhood correlations effectively. In this paper, we delve deeper into a more effective global-tolocal learning strategy based on NS block, which can fully leverage both long-term and short-term spatial-temporal dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">VPS Dataset</head><p>We describe the introduced SUN-SEG dataset's details in terms of data collection/re-organization (Sec. 3.1), professional annotations (Sec. 3.2), and dataset statistics (Sec. 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Organization</head><p>The colonoscopy videos in our SUN-SEG are from Showa University and Nagoya University database (also named SUN-database <ref type="bibr" target="#b3">[3]</ref>), the largest video polyp dataset for the detection task. There are two advantages of adopting the SUN-database as our data source. The origin SUN-database has 113 colonoscopy videos, including 100 positive cases with 49, 136 polyp frames and 13 negative cases with 109, 554 non-polyp frames 1 . We manually trim them into 378 positive and 728 negative clips while maintaining their consecutive intrinsic relationship. Such data pre-processing ensures that each clip has around 3?11s duration at a real-time frame rate (i.e., 30 fps), promoting the fault-tolerant margin for various algorithms and devices. To this end, the re-organized SUN-SEG contains 1, 106 short video clips with 158, 690 video frames totally, offering a solid foundation to build such a representative benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Professional Annotations</head><p>Following <ref type="bibr" target="#b64">[57]</ref>, we adopt a similar annotation pipeline. According to the origin bounding box labels of the SUN-database <ref type="bibr" target="#b3">[3]</ref>, ten experienced annotators are instructed to offer various labels using Adobe Photoshop. Then, three colonoscopyrelated researchers re-verify the quality and correctness of these initial annotations. <ref type="figure" target="#fig_0">Fig. 1</ref> shows two typical samples under the restricted quality controls (i.e., rejected and passed). In addition to the original pathological materials provided by SUN-database, such as pathological pattern (e.g., low-grade adenoma, hyperplastic  polyp, etc), shape (e.g., pedunculated, subpedunculated, etc), and location (e.g., cecum, ascending colon, etc), we further extend them with diversified annotations in our SUN-SEG. The newlyextended annotations consist of the following five hierarchies: visual attribute ? object mask ? boundary ? scribble ? polygon. Selected samples and corresponding annotations could be found in <ref type="figure" target="#fig_2">Fig. 2</ref> and their illustrations 2 are as follows.</p><p>? Visual Attribute. According to the visual characteristics of videos, we provide ten visual attributes at the video level, whose classification criteria are detailed in <ref type="table" target="#tab_1">Table 2</ref>. ? Object Mask. Correctly parsing lesion areas is helpful for a clinician. Therefore, as shown in <ref type="figure" target="#fig_2">Fig. 2</ref> (a), we provide pixel-wise object masks for each frame. We further refine the coordinates of the original bounding box based on the object mask to tighten the target, offering more reliable localization labels. ? Boundary. <ref type="figure" target="#fig_2">Fig. 2</ref> (b) shows the polyp boundary generated by calculating the gradient of the object mask. ? Scribble. Besides, we offer two weak labels to facilitate the research under data-insufficient conditions. As for the scribble labels in <ref type="figure" target="#fig_2">Fig. 2</ref> (c), we use two high-degree curves to indicate the foreground (purple curve) and background (white curve), respectively. To ensure the objectivity of various annotators, we adopt linear or quadratic functions to randomly create the above curves in the positive/negative region. ? Polygon. Similarly, in <ref type="figure" target="#fig_2">Fig. 2 (d)</ref>, we randomly deploy the Douglas-Peucker algorithm <ref type="bibr" target="#b65">[58]</ref> to Ghosting. Object has anomaly RGB-colored boundary due to fast moving or insufficient refresh rate. FM Fast-motion. The average per-frame object motion in a clip, computed as the Euclidean distance of polyp centroids between consecutive frames, is larger than 20 pixels. SO Small Object. The average ratio between the object size and the image area in a clip is smaller than 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LO</head><p>Large Object. The average ratio between the object size and the image area in a clip is larger than 0.15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OC</head><p>Occlusion. Polyp object becomes partially or fully occluded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OV</head><p>Out-of-view. Polyp object is partially clipped by the image boundaries. SV Scale-variation. The average area ratio among any pair of bounding boxes enclosing the target object in a clip is smaller than 0.5. find the circumscribed or inscribed polygons that fit the object boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUN-SEG-Train</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dataset Statistics</head><p>This section discusses several vital statistics of our three SUN-SEG sub-datasets for better illustration. More details about the data split of SUN-SEG refer to Sec. 4.4.1.</p><p>? Center Bias. Unlike general object detection, medical images usually share a higher center bias since the targets are often not in the center of an image. To depict the degree of center bias <ref type="bibr" target="#b66">[59]</ref>, we compute the average distribution of each dataset's overall ground truth map. <ref type="figure" target="#fig_3">Fig. 3</ref> and <ref type="figure">Fig. 4</ref> (top) show that the three subdatasets of SUN-SEG have lower a center bias than CVC-300 and CVC-612 datasets. ? Polyp Size. Colonoscopy is an ego-motion situation instead of shooting moving targets (i.e., stuff and things) through fixed cameras in the general domain. As a result, the scale variation of polyps and the irregular movement of the camera causes the different sizes of polyps.</p><p>The polyps partly or even fully disappear in the view. <ref type="figure">Fig. 4</ref> (bottom-left) shows the comparison of polyp scales at five different VPS datasets.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VPS Baseline</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task Formulation</head><p>We mainly focus on the task of video polyp segmentation, which could be defined as a binaryclass video object segmentation task, i.e., identifying polyp and non-polyp areas. Specifically, our goal is to render a model to assign a probability prediction (i.e., a non-binary mask ranging from 0 to 1) for every pixel of each frame. Besides, we leave other types of tasks for future exploration, such as video polyp detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Normalized Self-attention Block</head><p>Recently, the self-attention mechanism <ref type="bibr" target="#b68">[61]</ref> has been widely exploited in many popular computer vision tasks. Our initial studies found that introducing the original self-attention mechanism to the VPS task does not achieve satisfactory results (high accuracy and speed) due to the multiscale property of polyps that are captured at various shooting angles and speeds. Directly utilizing the naive self-attention scheme, such as the non-local network <ref type="bibr" target="#b68">[61]</ref>, incurs a high computational cost, limiting the inference speed. As shown in <ref type="figure" target="#fig_5">Fig. 5</ref> (right), we propose a normalized self-attention (NS) block, which is motivated by the fact that dynamically updating the receptive field is important for self-attention-based networks. The NS block involves five key steps, which are detailed as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Enhanced Rules</head><p>Motivated by the recent video salient object detection model <ref type="bibr" target="#b69">[62]</ref>, we utilize three strategies, i.e., channel split, query-dependent, and normalization, to reduce the computational cost and improve the accuracy.</p><p>(a) Channel Split Rule. Specifically, given three candidate features (i.e., query feature Q, key feature K, and value feature V ) with the size of R T ?H?W ?C , we utilize three linear embedding functions ?(?), ?(?), and g(?) to generate the corresponding attention features. These functions can be implemented by a convolutional layer with a kernel size of 1?1?1 <ref type="bibr" target="#b68">[61]</ref>. Note that T , H, W and C denote the number of frames, height, width, and channels of the given feature, respectively. This rule can be expressed as:</p><formula xml:id="formula_0">Q i = F G ?(Q) , K i = F G ?(K) , V i = F G g(V ) ,<label>(1)</label></formula><p>where the function F G denotes the operation that we split each attention feature into N groups along the channel dimension, resulting in three disparate features: query Q i , key K i , and value V i , where i = {1, 2, ? ? ? , N }. Thus, the shape of the above three split features is</p><formula xml:id="formula_1">R T ?H?W ? C N . (b) Query-Dependent Rule.</formula><p>To model the spatial-temporal relationship among consecutive frames, we need to measure the similarity between the split query features {Q i } N i=1 and split key fea-</p><formula xml:id="formula_2">tures {K i } N i=1</formula><p>. Inspired by <ref type="bibr" target="#b69">[62]</ref>, we introduce N relevance measuring (i.e., query-dependent rule) blocks to compute the spatial-temporal affinity matrix for the constrained neighborhood of the target pixel. Rather than computing the response between a query position and a key feature at all positions, as done in <ref type="bibr" target="#b68">[61]</ref>, the relevance measuring block can capture more relevance regarding the target object within T frames. More specifically, we get the corresponding constrained neighborhood in K i for query pixel X q of Q i in position (x, y, z), which can be obtained by a point sampling function F S . This is formulated as:</p><formula xml:id="formula_3">F S X q , K i = ? x+kdi m=x?kdi ? y+kdi n=y?kdi ? T t=1 K i (m, n, t),<label>(2)</label></formula><formula xml:id="formula_4">where 1 ? x ? H, 1 ? y ? W , and 1 ? z ? T and F S X q , K i ? R T (2k+1) 2 ? C N .</formula><p>Thus, the size of the constrained neighborhood will depend on the various spatial-temporal receptive fields with different kernel sizes k, dilation rate d i at the i-th group, and frame number T , respectively. (c) Normalization Rule. However, the internal covariate shift problem <ref type="bibr" target="#b70">[63]</ref> exists in the feedforward of input Q i , incurring that the layer parameters cannot dynamically adapt to the next mini-batch. Thus, we maintain a fixed distribution for Q i via:Q</p><formula xml:id="formula_5">i = Norm(Q i ),<label>(3)</label></formula><p>where Norm(?) is implemented by layer normalization <ref type="bibr" target="#b72">[64]</ref> operation along the temporal dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Relevance Measuring</head><p>The affinity matrix M A i measures the similarity of target pixels and their surrounding spatialtemporal contents in an adaptive point sampling manner (refer to Equ. <ref type="formula" target="#formula_3">(2)</ref>). It is defined as:</p><formula xml:id="formula_6">M A i = Softmax(Q i F S X q , K i C/N ), whenX q ?Q i ,<label>(4)</label></formula><p>where M A i ? R T HW ?T (2k+1) 2 . C/N is a scaling factor to balance the multi-head attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Spatial-Temporal Aggregation</head><p>Similar to relevance measuring, we also compute the spatial-temporally aggregated features M T i ? R T HW ? C N within the constrained neighborhood during temporal aggregation. It is calculated by:</p><formula xml:id="formula_7">M T i = M A i F S X a , V i , when X a ? M A i . (5)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Soft-Attention</head><p>We utilize a soft-attention block to synthesize features from the group of affinity matrices M A i and aggregated features M T i . During the synthesis process, relevant spatial-temporal patterns should be enhanced while less relevant ones should be suppressed. We first concatenate a group of affinity matrices M A i along the channel dimension to generate M A . The soft-attention map M S is computed by:</p><formula xml:id="formula_8">M S ? R T HW ?1 = Max(M A ),<label>(6)</label></formula><p>where M A ? R T HW ?T (2k+1) 2 N and the Max(?) function computes the channel-wise maximum value. We then concatenate a group of the spatialtemporally aggregated features M T i along the channel dimension to generate M T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5">Normalized Self-attention</head><p>Finally, our normalized self-attention block, i.e., the function NS(?, ?, ?), is defined as:</p><formula xml:id="formula_9">Y ? R T ?H?W ?C = NS(Q, K, V ) = (M T W T ) M S ,<label>(7)</label></formula><p>where W T is the learnable weight and denotes the channel-wise Hadamard product.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Global-to-Local Learning</head><p>Observation. By establishing the non-local connections for the given features, the proposed NS block, as in Sec. 4.2, shows the promising potential for learning short-term spatial-temporal dependencies. However, this mechanism still struggles in modeling long-term spatial-temporal dependencies due to limited computational resources, i.e., the network can only process a piece of frames within a limited time span. In contrast to our conference version, PNSNet <ref type="bibr" target="#b4">[4]</ref>, we propose a novel global-to-local learning paradigm, which realizes both long-and short-term spatial-temporal propagation at an arbitrary temporal distance, yielding a simple but efficient framework, PNS+. Specifically, it appends a spatial-temporal learning pathway at a global temporal level, naturally introducing longterm dependencies into the network. We describe this strategy via the following five steps: a global encoder (Sec </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Global Encoder</head><p>Our strategy employs the first frame I 1 ? R H ?W ?3 as an anchor (i.e., global reference). The dependency will be calculated between the anchor frame and the sampled consecutive frames within a sliding window. Following PraNet <ref type="bibr" target="#b54">[48]</ref>, we use the same backbone, Res2Net-50 <ref type="bibr" target="#b73">[65]</ref>, to extract the feature at the conv4 6 layer. To alleviate the computational burden, we adopt an RFB-like <ref type="bibr" target="#b74">[66]</ref> module to reduce the channel dimension of extracted feature and generate the anchor feature</p><formula xml:id="formula_10">A h ? R H h ?W h ?C h .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Local Encoder</head><p>The local encoder takes a piece of consecutive frames I ? ={I s } t+? s=t ? R H ?W ?3 (t&gt;1) from a sliding window as input. Similar to the global encoder, we leverage Res2Net-50 backbone to extract two groups of short-term features from the conv3 4 and conv4 6 layers and use channel reduction to generate the low-level {X l s } t+? s=t ?R H l ?W l ?C l and high-level</p><formula xml:id="formula_11">{X h s } t+? s=t ?R H h ?W h ?C h short-term features. We set H l = H 4 , W l = W 4 , C l = 24, H h = H 8 , W h = W 8</formula><p>, and C h = 32 as the default implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Global Spatial-Temporal Modeling</head><p>As shown in <ref type="figure" target="#fig_5">Fig. 5</ref>, we leverage the first NS block to model the long-term relationship at an arbitrary temporal distance, which requires a fourdimensional temporal feature as input; therefore we have:</p><formula xml:id="formula_12">X h ? R ??H h ?W h ?C h ? {X h s } t+? s=t ? R H h ?W h ?C h , A h ? R 1?H h ?W h ?C h ? A h ? R H h ?W h ?C h ,<label>(8)</label></formula><p>where ? denotes reshaping the candidate features into the temporal form to yield a four-dimensional tensor. Then, as for the first NS block formulated in Equ. <ref type="bibr" target="#b7">(7)</ref>, we employ the anchor feature as a query entry (i.e., Q g =? h ) and the highlevel short-term feature as the key and value entries (i.e., K g =X h &amp; V g =X h ). Intuitively, we aim to build the pixel-wise similarities between the anchor and high-level short-term features, which could be viewed as the modeling of global spatial-temporal dependencies. It is defined as:</p><formula xml:id="formula_13">Z g ? R ??H h ?W h ?C h = NS(? h ,X h ,X h ) ?X h ,<label>(9)</label></formula><p>where ? denotes the element-wise addition of residual operation <ref type="bibr" target="#b75">[67]</ref>. This operation provides better convergence stability of interior gradient propagation within the first NS block, allowing it to easily be plugged into the pre-trained networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Global-to-Local Propagation</head><p>Furthermore, we desire to propagate the long-term dependency Z g into a local neighborhood (i.e., frames in a sliding window). Thus, we serve Z g as the input entries of the second NS block as in Equ. <ref type="formula" target="#formula_9">(7)</ref>, i.e., query Q l = Z g , key K l = Z g , and value V l = Z g . We have:</p><formula xml:id="formula_14">Z l = NS(Z g , Z g , Z g ) ? Z g ?X h .<label>(10)</label></formula><p>In this way, the introduced two residual connections can maintain the interior gradient stability (i.e., ?Z g ) and exterior gradient stability (i.e., ?X h ) of the second NS block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.5">Decoder and Objectiveness</head><p>Finally, we combine the low-level short-term feature X l s from the local encoder and the spatialtemporal feature Z l from the second NS block with a two-stage UNet-alike decoder F D . Before the combination, we recover the feature Z l back to the spatial form, i.e., {Z l s } t+? s=t . The prediction from the decoder is computed with:</p><formula xml:id="formula_15">P ? = {P s } t+? s=t = F D {X l s } t+? s=t , {Z l s } t+? s=t .<label>(11)</label></formula><p>To this end, given a prediction P s and corresponding ground-truth (GT) G s at timestamp s, we utilize a binary cross-entropy loss for optimization, which is formulated as:</p><formula xml:id="formula_16">L bce = ? [G s log(P s ) + (1 ? G s ) log(1 ? P s ))].<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Implementation Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Datasets</head><p>We split 40% SUN-SEG data for training, i.e., SUN-SEG-Train with 112 clips (19, 544 frames). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Training Details</head><p>We train our model using the SUN-SEG-Train dataset on the server platform equipped with an Intel Xeon (R) CPU E5-2690v4?24 and four NVIDIA Tesla V100 GPUs with 16 GB memory per one. The ImageNet pre-trained weights of Res2Net-50 <ref type="bibr" target="#b73">[65]</ref> are loaded before training, and other newly-added layers are with Kaiming initialization. We set the batch size to 24, which takes about 5 hours to reach convergence after 15 epochs. For each mini-batch of data, we select the first frame of a video clip as an anchor, randomly sample five consecutive frames (?=5) from the same clip, and resize them to 256?448. The Adam optimizer's initial learning rate and weight decay are set to 3e-4 and 1e-4, respectively. We set the number of attention groups to N =4 as default.</p><p>For the first NS block, we set kernel size k=3 and dilation rate d i ={3, 4, 3, 4} to capture more longterm representations with a larger receptive field. For the second one, we set kernel size k=3 and reduce dilation rate d i ={1, 2, 1, 2} to mainly focus on short-term relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Inference Stage</head><p>We evaluate PNS+ on SUN-SEG-Easy and SUN-SEG-Hard with both seen and unseen scenarios. Similar to the training phase, during inference, we select the first frame as an anchor, sample five video frames (?=5) from a video clip, and resize them to 256?448. For the final prediction, we use the network's output P ? followed by a Sigmoid function. The proposed PNS+ achieves a super real-time inference speed of 170fps on a single <ref type="bibr" target="#b3">3</ref> Seen denotes that the samples in the testing dataset are from the same case in the training set, whereas the unseen indicates that the scenario do not exist in the training set.</p><p>V100 GPU without any heuristic post-processing techniques, such as DenseCRF <ref type="bibr" target="#b76">[68]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">VPS Benchmark</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation Protocols</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Competitors</head><p>We elaborately select eight typical video-based object/polyp segmentation methods, including COSNet <ref type="bibr" target="#b77">[69]</ref>, MAT <ref type="bibr" target="#b78">[70]</ref>, PCSA <ref type="bibr" target="#b69">[62]</ref>, 2/3D <ref type="bibr" target="#b1">[2]</ref>, AMD <ref type="bibr" target="#b79">[71]</ref>, DCF <ref type="bibr" target="#b80">[72]</ref>, FSNet <ref type="bibr" target="#b82">[73]</ref>, and PNSNet <ref type="bibr" target="#b4">[4]</ref>. We also add five image-based object/polyp segmentation methods to validate the effectiveness of per-frame prediction ability, including UNet <ref type="bibr" target="#b38">[34]</ref>, UNet++ <ref type="bibr" target="#b39">[35]</ref>, ACSNet <ref type="bibr" target="#b43">[38]</ref>, PraNet <ref type="bibr" target="#b54">[48]</ref>, and SANet <ref type="bibr" target="#b46">[41]</ref>. For a fair comparison, all the competitors utilize the same dataset as our PNS+ and reach the convergence under their default training settings. Of note, this paper only focuses on the positive cases in our SUN-SEG dataset and left negative cases (no polyp) for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Evaluation Metrics</head><p>To provide deeper insight into the model performance, we use the following six different metrics for model evaluation between prediction P s and ground-truth G s at timestamp s, including: (a) Dice coefficient (Dice = 2?|Ps?Gs| |Ps?Gs| ) measures the similarity between prediction and ground truth mask and penalizes for the false-positive/-negative predictions. The operators ?, ?, and | ? | denote the intersection, union, and the number of pixels in an area, respectively. (b) Pixel-wise sensitivity (Sen = |Ps?Gs| |Gs| ) is used to evaluate the true positive prediction of overall lesion areas. Since the goal of colonoscopy is to screen the polyps with a low polyp missing rate, people who have the polyps should be highly likely to be identified. As a result, penalizing the false-negative prediction can be done by adopting sensitivity which refers to the method's ability to correctly detect polyps. (c) Being the harmonic mean of precision and recall that is weighted by ?, Fmeasure <ref type="bibr" target="#b84">[74]</ref> (F ? = (1+? 2 )?Prc?Rcl ? 2 ?(Prc+Rcl) ) is widely used in measuring binary masks by combining precision (Prc = |Ps?Gs| |Ps| ) and recall (Rcl = |Ps?Gs| |Gs| ) for more comprehensive evaluation. (d) Suggested by <ref type="bibr" target="#b85">[75,</ref><ref type="bibr" target="#b86">76]</ref>, weighted F-measure <ref type="bibr" target="#b87">[77]</ref> (F w ? = <ref type="table">Table 3</ref> Quantitative comparison on two testing sub-datasets with seen colonoscopy scenarios. (1+? 2 )?Prc w ?Rcl w ? 2 ?(Prc w +Rcl w ) ): amend the "Equal-importance flaw" in Dice and F ? , providing more reliable evaluation results. Following <ref type="bibr" target="#b88">[78]</ref>, we set the factor ? 2 of F ? and F w ? as 0.3 and 1, respectively. (e) Different from the above pixel-wise metrics, structure measure <ref type="bibr" target="#b89">[79]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUN-SEG-Easy (Seen</head><formula xml:id="formula_17">(S ? = ? ? S o (P s , G s ) + (1 ? ?) ? S r (P s , G s ))</formula><p>: is used to measure the structural similarity at object-aware S o and region-aware S r , respectively. We use the factor ? = 0.5 as default. (f) Fan et al. proposed a human visual perceptionbased metric, enhanced-alignment measure <ref type="bibr" target="#b90">[80]</ref>:</p><formula xml:id="formula_18">E ? = 1 W ?H W x H y ?(P s (x, y), G s (x, y)),</formula><p>where ? is the enhanced-alignment matrix. W and H are the width and height of ground-truth G s . This metric is inherently suitable for assessing polyps' heterogeneous location and shape in colonoscopy.</p><p>As mentioned in Sec. 4.1, the models generate continuous floating predictions; thus, we need to threshold the floating value into binary ones ranging from 0 to 255. Specifically, we provide the maximum value of Dice and mean value of E ? , F ? , and Sen under different thresholds for the binary metrics. Furthermore, we obtain the videolevel score by averaging the evaluated results per image at a video clip. Then, we take the average video-level scores as the performance on the whole dataset. One-key evaluation toolbox is available at https://github.com/GewelsJI/VPS/tree/ main/eval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Quantitative Comparison</head><p>Based on the protocols mentioned in Sec. 5.1, we conduct a comprehensive VPS benchmark on two testing sub-datasets (i.e., SUN-SEG-Easy and SUN-SEG-Hard), which include the following three aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Learning Ability</head><p>Notably, the image-based models are trained and inferred frame-by-frame. To better unveil the spatial-temporal learning ability on the colonoscopy videos, we conduct two groups of experiments to validate video-based competitors' ability on two seen sub-datasets. For these subdatasets shown in <ref type="table">Table 3</ref>, our PNS+ also outperforms top-1 video-based approaches, e.g., Dice score on SUN-SEG-Easy (Seen): PNSNet (0.861) vs. PNS+(0.888) and F mn ? score on SUN-SEG-Hard (Seen): PNSNet (0.892) vs. PNS+(0.929). The above results suggest that our model has a strong learning ability to accurately segment polyps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Generalization Capability</head><p>To validate the model's generalizability, we conduct the experiments on two testing sub-datasets with unseen colonoscopy scenarios. As shown in <ref type="table">Table 4</ref>, we present the performance comparison with the other latest image-and videobased competitors in six metrics. It shows that our PNS+ achieves significant improvements by a large margin in comparison with top imageand video-based approaches, e.g., Dice score on SUN-SEG-Easy (Unseen): ACSNet (0.713) vs. 2/3D (0.722) vs. PNS+ (0.756) and F w ? score on SUN-SEG-Hard (Unseen): ACSNet (0.636) vs. 2/3D (0.634) vs. PNS+ (0.653). Interestingly, we observe that PNSNet drops dramatically on two unseen datasets, which is a side show of better generalizability attributed to our newly-proposed global-to-local learning strategy, especially on a clip with a larger time span.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Attribute-based Performance</head><p>Finally, we analyze the visual attribute-based comparison presented in <ref type="table" target="#tab_1">Table 2</ref>. In terms of S ? score, <ref type="table">Table 5</ref> unveils that our PNS+ consistently outperforms other rivals on four attributes (i.e., IB, GH, FM, and SV). More specifically, as shown in <ref type="table">Table 5</ref>, most methods can not address the VPS tasks with IB attribute since the colon polyps always have fuzzy boundaries. In contrast, PNS+ achieves the best score (S ? = 0.667) on this challenging IB attribute of SUN-SEG-Easy (Unseen). This discovery is also consistent with the results shown in <ref type="figure">Fig. 6</ref>. Similarly, the SO <ref type="table">Table 4</ref> Quantitative comparison of two testing sub-datasets with unseen colonoscopy scenarios. 'R/T' means to retrain the private model using the code provided by the author. The best values are highlighted in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUN-SEG-Easy (Unseen) SUN-SEG-Hard (Unseen) Model</head><p>Publish</p><formula xml:id="formula_19">Code S? E mn ? F w ? F mn ? Dice Sen S? E mn ? F w ? F mn ?</formula><p>Dice Sen  <ref type="table">Table 5</ref> Visual attributes-based performance on SUN-SEG-Easy/-Hard (Unseen) in terms of structure measure (S?) score. attributes also present the lower scores (e.g., SUN-SEG-Easy (Unseen): S ? =0.667), which indicates these two attributes are the most challenging issues in colonoscopy. On the contrary, HO and LO attribute consistently sustain higher scores than other attributes, making polyp easier to detect. This phenomenon meets our expectations since the less distribution bias for these relatively easy scenarios. We refer the readers to Sec. 5.5 for a more visualized analysis of challenging cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Qualitative Comparison</head><p>As shown in <ref type="figure">Fig. 6</ref>, we present visual results on three video clips of four typical models (i.e., PNSNet, 2/3D, MAT, ACSNet) and our PNS+. In the last four rows, the competitors fail to generate complete segmentation results for the polyps that share the same camouflaged texture with the background. In contrast, in the 3 rd row, our model can accurately locate and segment polyps in a challenging situation, i.e., polyps with different sizes and homogeneous textures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation Studies</head><p>To validate the effectiveness of our core designs, we conduct extensive ablation studies and summarize the results in <ref type="table" target="#tab_4">Table 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Contribution of Base Network</head><p>We initialize an UNet-like variant #01 via leveraging the Res2Net-50 <ref type="bibr" target="#b73">[65]</ref> backbone, which can be viewed as an image-based approach to generate per frame predictions. We observe that #OUR significantly improves the performance (S ? : +7.7%) on SUN-SEG-Easy (Unseen).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Contribution of Channel Split</head><p>To discover the best setting for the channel split rule as in Equ.(1), we instantiate four variants with four different channel split numbers: #02 (N =1), #03 (N =2), #04 (N =4), and #05 (N =8). These results show that small (#02 &amp; #03) and large (#05) channel split numbers may harm the channel-level information by collapsing  <ref type="figure">Fig. 6</ref> Qualitative visualization of the proposed PNS+ and four representative competitors on three sequences (from left to right: case14 3, case30, and case3 2). The red boxes indicates the wrong or missing predictions. We refer the readers to the project page for completed dynamic comparison.</p><p>the knowledge in a different channel. In contrast, we adopt the moderate scale (#04: N =4) with the best performance on SUN-SEG-Hard (Unseen) (e.g., Dice: 2.7%?) when compared to variant #05. Such a trade-off scale would exert our model focusing on the polyp-related attention while suppressing the irrelevant information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.3">Contribution of Soft-attention</head><p>We further ablate soft-attention and observe that #04 with the soft-attention block is generally better than #06 without it on SUN-SEG-Easy (Unseen): 1.9%? in terms of Dice score. Such improvement suggests that introducing the softattention operation to synthesize the relationship between aggregation feature and affinity matrix is necessary for increasing performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.4">Effectiveness of Normalization</head><p>We also study the improvement of the normalization operation by comparing #04 with #07. We observe that #04 generally outperforms #07 on SUN-SEG-Hard (Unseen) (e.g., Dice: 4.1%?). It shows that the layer normalization along the temporal dimension could alleviate the internal covariate shift problem by fixing the distribution of query entries in the attention mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.5">Different Learning Strategies</head><p>Finally, we examine the effectiveness of the proposed learning strategy, as proposed in Sec. 4.3, by deriving three variants, including #08 (L?L: local-to-local), #09 (L?G: local-to-global), #10 (G?G: global-to-global), and #OUR (G?L: global-to-local). For example, variant #09 combines local spatial-temporal cues and introduces global ones, termed a local-to-global (L?G) strategy. #08 will dramatically decrease on SUN-SEG-Easy (Unseen) (S ? : 5.8%?) when focusing on the local cues due to a lack of global context. On the other hand, if only focusing on the global information, the performance of variant #10 will drop on SUN-SEG-Hard (Unseen), e.g., F w ? : 5.4%?. In contrast, #OUR with the global-to-local strategy outperforms variant #09 on SUN-SEG-Hard (Unseen), e.g., F w ? : 3.5%?, since propagating longterm cues into short-term neighbors.</p><p>We further validate the effectiveness of the global-to-local learning strategy via visualizing the key dataflows. As shown in <ref type="figure" target="#fig_10">Fig. 7</ref>, the first and second columns present the anchor feature A h extracted from the global encoder and the spatial-temporal feature Z l from the second NS block, respectively. Note that the current frame I s is randomly selected from consecutive frames I ? . It shows that our PNS+ can propagate the longterm dependency with the assistance of the anchor frame I 1 , though the current frame I s is hard to recognize due to indefinable boundaries (i.e., IB attribute). Of note, as in the rightmost column of <ref type="figure">Fig. 6</ref>, the PNSNet fails to locate the polyp since it does not use a global-to-local learning strategy. Compared to it, our PNS+ successfully detects the polyp by exploiting the global reference of the anchor frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Issues and Challenges</head><p>This section discusses some common issues within challenging attributes, whose visualization results are presented in <ref type="figure" target="#fig_11">Fig. 8</ref>. Of note, VPS is a newly-emerging and challenging track in medical imaging, and its overall accuracy is not high enough. We observe that existing cutting-edge models (i.e., ACSNet and 2/3D) and our baseline model (PNS+) still lack sufficient robustness in particular cases in LO, HO, SI, GH, and SV attributes. As for the HO (3 rd column) and LO (8 th column) attributes, three models fail to capture the whole polyp due to significant appearance changes. Besides, the false-positive/-negative predictions (marked with red boxes) on the surgical instrument (1 st column) and the optical flares (4 th column) indicate that these models could not learn semantics without perceiving the accurate polyp-related representation in such a hard case. Moreover, the misidentifications for the SV attribute (last column) are caused by the insufficient diversity of polyp sizes in the training set. The aforementioned drawbacks inspire us to explore more robust learning paradigms to improve the accuracy of VPS.</p><p>We also observe that three models consistently fail to locate lesion regions that share a similar color with the intestinal wall or are too small to be detected. Thus, there is a large room for improving the detection ability in IB and SO attributes via camouflaged pattern discovery techniques <ref type="bibr" target="#b91">[81,</ref><ref type="bibr" target="#b92">82]</ref>. Last but not least, lacking temporal-wise understanding will lead to the false prediction in the FM, OV, and OC attributes. Taking OV and OC, for example, exploiting temporal cues more thoroughly should mitigate the performance degradation results from the occlusion of the intestinal wall or the image boundary since the occlusion is not continuous in the entire video clip. To sum up, these challenging cases are the common difficulties other methods face and cause a severe performance degradation that deserves further exploration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Potential Directions</head><p>This section highlights several potential trends for promoting colonoscopy research in the deep era.</p><p>? High-precision Diagnosis. As shown in <ref type="table">Table 4</ref>, we observe that the leading approaches are still unsatisfactory in our SUN-SEG-Hard (e.g., sensitivity score &lt; 0.63). We argue that the high-precision VPS algorithm would steer clinical medicine in boosting auxiliary diagnostic technologies. ? Data-insufficient Learning. It is promising to explore efficient learning strategies <ref type="bibr" target="#b93">[83,</ref><ref type="bibr" target="#b94">84]</ref> under limited conditions in specific clinical applications, such as weakly-/un-/selfsupervised learning and knowledge distillation. ? Privacy-preserving AI. Intelligent VPS systems must safeguard data through the entire life cycle from training to production and governance, which fuels fundamental techniques like federal learning. ? Trustworthy AI. How AI-guided decisions are made and what determining factors are involved play a crucial role in understanding the insights of deep networks. In other words, the VPS model should be causal, transparent, explainable, and interactive, which inspires more trusted developments, such as <ref type="bibr" target="#b95">[85]</ref>.</p><p>The above possible directions listed are still far from being solved for the VPS. Fortunately, several famous works can be served as references, providing it a potential basis to be transferred to our community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper presents the first comprehensive study on video polyp segmentation (VPS) from a deep learning perspective. We first introduce a large-scale VPS dataset SUN-SEG via extending the famous SUN-database with diversified annotations, i.e., attribute, object mask, boundary, scribble, and polygon. We then design a simple but efficient baseline, dubbed PNS+, to segment colon polyps from the colonoscopy video. Based on the normalized self-attention block, PNS+ fully exploits long-term and shortterm spatial-temporal cues via a novel globalto-local learning strategy. We further contribute the first comprehensive benchmark containing 13 cutting-edge polyp/object segmentation approaches. Extensive results show that PNS+ achieves the best performance against all these competitors. We conclude by outlining several potential directions for future colonoscopyrelated research in the deep learning era. We hope this work will spur advancements in other closely related medical video analyses.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>(a) Challenging Scenarios: The videos are captured by the high-definition endoscope (CF-HQ290ZI &amp; CF-H290ECI, Olympus) and video recorder (IMH-10, Olympus), providing videos of various polyp sizes at dynamic scenarios, such as imaging at different focusing distances High-criteria control for data annotation. For instance, we reject case (a), where the boundary is not consistent with the polyp, and case (b), where the water overlapping area is falsely annotated. and speeds. (b) Reliable Pathological Localization: The initial classification information and bounding box annotations are provided by three research assistants and examined by two expert endoscopists with professional domain knowledge.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>time</head><label></label><figDesc>Frame (a) Object Mask (b) Boundary (c) Scribble (d) Polygon</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2</head><label>2</label><figDesc>Diversified annotations for each video frame in our SUN-SEG dataset including object mask (a), boundary (b), and two weak labels, i.e., scribble (c) and polygon (d).More details refer to Sec. 3.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3</head><label>3</label><figDesc>The calculation of center bias [59] on CVC-300, CVC-612, and our SUN-SEG-Train/-Easy/-Hard.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>612 Fig. 4</head><label>6124</label><figDesc>Contrast Distribution Global Contrast (Dashed line) Local Contrast (Solid line) SUN-SEG-Train SUN-SEG-Easy SUN-SEG-Hard CVC-300 CVC-Statistic curves among existing VPS datasets (CVC-300 &amp; CVC-612) and our SUN-SEG-Train/-Easy/-Hard. Note that the horizontal and vertical axes denote the frequency and their statistic values, respectively. These curves present the diversity of our dataset.? Global/Local Contrast. To demonstrate how difficult a colon polyp is to identify, inFig. 4(bottom-right), we describe it quantitatively using the global and local contrast strategy<ref type="bibr" target="#b67">[60]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5</head><label>5</label><figDesc>The pipeline of the proposed (a) PNS+ network, which is based on (b) the normalized self-attention (NS) block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>. 4.3.1), a local encoder (Sec. 4.3.2), the global spatial-temporal modeling (Sec. 4.3.3), the global-to-local propagation (Sec. 4.3.4), and the decoder/objectiveness (Sec. 4.3.5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>845 0.836 0.727 0.804 0.785 0.772 0.626 0.725 MAT 0.879 0.861 0.731 0.833 0.840 0.821 0.652 0.776 PCSA 0.852 0.835 0.681 0.779 0.772 0.759 0.566 0.679 2/3D 0.895 0.909 0.819 0.856 0.849 0.868 0.753 0.809 AMD 0.471 0.526 0.114 0.245 0.480 0.536 0.115 0.231 DCF 0.572 0.591 0.357 0.398 0.603 0.602 0.385 0.443 FSNet 0.890 0.895 0.818 0.873 0.848 0.859 0.755 0.828 PNSNet 0.906 0.910 0.836 0.861 0.870 0.892 0.787 0.823 PNS+ 0.917 0.924 0.848 0.888 0.887 0.929 0.806 0.855</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>IMAGE UNet [ 34 ]</head><label>34</label><figDesc>MICCAI15 Link 0.669 0.677 0.459 0.528 0.530 0.420 0.670 0.679 0.457 0.527 0.542 0.429 UNet++ [35] TMI18 Link 0.684 0.687 0.491 0.553 0.559 0.457 0.685 0.697 0.480 0.544 0.554 0.467 ACSNet [38] MICCAI20 Link 0.782 0.779 0.642 0.688 0.713 0.601 0.783 0.787 0.636 0.684 0.708 0.618 PraNet [48] MICCAI20 Link 0.733 0.753 0.572 0.632 0.621 0.524 0.717 0.735 0.544 0.607 0.598 0.512 SANet [41] MICCAI21 Link 0.720 0.745 0.566 0.634 0.649 0.521 0.706 0.743 0.526 0.580 0.598 0.505 VIDEO COSNet [69] TPAMI19 Link 0.654 0.600 0.431 0.496 0.596 0.359 0.670 0.627 0.443 0.506 0.606 0.380 MAT [70] TIP20 Link 0.770 0.737 0.575 0.641 0.710 0.542 0.785 0.755 0.578 0.645 0.712 0.579 PCSA [62] AAAI20 Link 0.680 0.660 0.451 0.519 0.592 0.398 0.682 0.660 0.442 0.510 0.584 0.415 2/3D [2] MICCAI20 R/T 0.786 0.777 0.652 0.708 0.722 0.603 0.786 0.775 0.634 0.688 0.706 0.607 AMD [71] NeurIPS21 Link 0.474 0.533 0.133 0.146 0.266 0.222 0.472 0.527 0.128 0.141 0.252 0.213 DCF [72] ICCV21 Link 0.523 0.514 0.270 0.312 0.325 0.340 0.514 0.522 0.263 0.303 0.317 0.364 FSNet [73] ICCV21 Link 0.725 0.695 0.551 0.630 0.702 0.493 0.724 0.694 0.541 0.611 0.699 0.491 PNSNet [4] MICCAI21 Link 0.767 0.744 0.616 0.664 0.676 0.574 0.767 0.755 0.609 0.656 0.675 0.579 PNS+ OURS22 Link 0.806 0.798 0.676 0.730 0.756 0.630 0.797 0.793 0.653 0.709 0.737 0.623</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>SUN-SEG-Easy (Unseen) SUN-SEG-Hard (Unseen) SI IB HO GH FM SO LO OC OV SV SI IB HO GH FM SO LO OC OV SV UNet 0.675 0.548 0.768 0.715 0.633 0.593 0.648 0.670 0.643 0.620 0.618 0.619 0.663 0.676 0.713 0.689 0.633 0.658 0.659 0.658 UNet++ 0.701 0.542 0.782 0.739 0.647 0.591 0.678 0.683 0.665 0.617 0.654 0.604 0.665 0.696 0.714 0.681 0.660 0.676 0.677 0.678 ACSNet 0.789 0.612 0.896 0.820 0.704 0.663 0.787 0.770 0.759 0.705 0.770 0.681 0.828 0.795 0.817 0.738 0.810 0.828 0.806 0.759 PraNet 0.745 0.585 0.821 0.772 0.673 0.611 0.722 0.722 0.703 0.653 0.673 0.635 0.725 0.720 0.755 0.691 0.666 0.714 0.708 0.703 SANet 0.724 0.582 0.854 0.760 0.676 0.615 0.703 0.701 0.711 0.680 0.658 0.565 0.738 0.709 0.760 0.692 0.733 0.729 0.727 0.693 COSNet 0.663 0.531 0.786 0.684 0.610 0.549 0.637 0.648 0.613 0.617 0.641 0.593 0.727 0.668 0.690 0.637 0.694 0.707 0.666 0.625 MAT 0.772 0.664 0.873 0.789 0.706 0.691 0.755 0.738 0.746 0.715 0.772 0.701 0.801 0.776 0.782 0.780 0.791 0.795 0.789 0.750 PCSA 0.676 0.563 0.759 0.708 0.628 0.610 0.634 0.662 0.656 0.616 0.656 0.591 0.692 0.683 0.706 0.671 0.612 0.677 0.665 0.663 2/3D 0.809 0.625 0.899 0.835 0.728 0.667 0.8200.783 0.778 0.719 0.768 0.662 0.865 0.784 0.797 0.737 0.853 0.827 0.808 0.765 AMD 0.476 0.461 0.471 0.481 0.484 0.466 0.447 0.467 0.442 0.498 0.471 0.468 0.447 0.473 0.468 0.469 0.453 0.487 0.462 0.481 DCF 0.465 0.485 0.479 0.505 0.541 0.495 0.362 0.484 0.492 0.495 0.441 0.508 0.422 0.498 0.587 0.556 0.351 0.470 0.494 0.540 FSNet 0.719 0.603 0.810 0.752 0.694 0.632 0.686 0.711 0.691 0.665 0.662 0.648 0.743 0.713 0.774 0.723 0.701 0.728 0.728 0.694 PNSNet 0.789 0.592 0.871 0.820 0.723 0.619 0.768 0.749 0.751 0.705 0.746 0.631 0.803 0.780 0.778 0.743 0.805 0.790 0.794 0.758 PNS+ 0.8190.667 0.883 0.8440.738 0.690 0.796 0.782 0.7980.734 0.770 0.703 0.817 0.8010.8230.793 0.792 0.808 0.807 0.795</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7</head><label>7</label><figDesc>Anchor frame I1 (b) Current frame Is (c) Ground truth Gs (d) Anchor feature A h (e) Spatial-temporal feature Z l (f) Prediction Ps Feature visualization of key dataflows. The red arrow denotes using the anchor feature A h to guide the representation of spatial-temporal frame Z l . More details refer to Sec. 5.4.5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 8</head><label>8</label><figDesc>Challenging samples were taken from ten visual attributes. More analyses can be referred to Sec. 5.5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Statistics of existing 20 datasets for human colonoscopy. #IMG = number of images. #VID = number of video sequences. DL = densely labeling. CLS = classification label. BBX = bounding box. PM = pixel-level mask.</figDesc><table /><note>dyed resection margins), and each type has 1, 000 images. Hyper-Kvasir [15] further collects 110, 079 samples from 374 colonoscopy videos, containing three types of annotations: 10, 662 class labels with 23 different lesion findings and 1, 000 images with segmented masks and bounding box labels. Notably, all the segmented masks in Hyper-Kvasir are selected from Kvasir-SEG [15]. Recently, CP- CHILD-A &amp; -B [19] record the colonoscopy data from children, including two classes (i.e., colon polyp, normal or other pathological images) for the classification task.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>List of ten types of visual attributes (ATTR.) and their descriptions. ATTR. DESCRIPTION SI Surgical Instruments. The endoscopic surgical procedures involve the positioning of instruments, such as snares, forceps, knives, and electrodes. IB Indefinable Boundaries. The foreground and background areas around the object have similar color. HO Heterogeneous Object. Object regions have distinct colors. GH</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>This section first clarifies the formulation of VPS task in Sec. 4.1. Then, we describe the details of PNS+, including the normalized self-attention block (Sec. 4.2), global-to-local learning strategy (Sec. 4.3), and implementation details (Sec. 4.4).</figDesc><table><row><cell></cell><cell>Anchor Anchor</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Frame Frame</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Soft-Attention</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Global Encoder</cell><cell cols="4">Global-to-Local Learning Strategy ( Sec. 4.3 )</cell><cell></cell><cell>Prediction</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Frame</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Affinity Matrix</cell><cell cols="2">Spatial-Temporal Aggregation</cell><cell></cell></row><row><cell>Sliding Window</cell><cell>Frames Frame</cell><cell>Local Encoder</cell><cell>{X h s } t+? s=t</cell><cell>NS Block</cell><cell>{X h s } t+? s=t</cell><cell>NS Block</cell><cell>Decoder</cell><cell>Prediction Prediction</cell><cell>Relevance Measuring Linear Linear Norm</cell><cell>N</cell><cell>Linear</cell><cell>Channel Split</cell></row><row><cell></cell><cell>Frame</cell><cell></cell><cell>{X l s } t+? s=t</cell><cell></cell><cell></cell><cell>{X h s } t+? s=t</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(a) PNS+ Network</cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) NS Block</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>The rest data are all used for testing, including SUN-SEG-Easy with 119 clips (17, 070 frames) and SUN-SEG-Hard with 54 clips (12, 522 frames) according to difficulty levels in each pathological category. Specifically, two colonoscopy scenarios (i.e., seen and unseen 3 ) are included in the above</figDesc><table><row><cell>two testing dataset: SUN-SEG-Easy (seen: 33 clips</cell></row><row><cell>&amp; unseen: 86 clips) and SUN-SEG-Hard (seen: 17</cell></row><row><cell>clips &amp; unseen: 37 clips) for more fine-grained</cell></row><row><cell>experimental analyses.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>Ablation studies for the core designs of the proposed PNS+. See Sec. 5.4 for the detailed analyses.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">VARIANTS</cell><cell></cell><cell cols="4">SUN-SEG-Easy (Unseen)</cell><cell cols="4">SUN-SEG-Hard (Unseen)</cell></row><row><cell>No.</cell><cell>Base</cell><cell>N</cell><cell>Soft</cell><cell>Norm</cell><cell>Strategy</cell><cell>S?</cell><cell>E mn ?</cell><cell>F w ?</cell><cell>Dice</cell><cell>S?</cell><cell>E mn ?</cell><cell>F w ?</cell><cell>Dice</cell></row><row><cell>#01</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.729</cell><cell>0.718</cell><cell>0.571</cell><cell>0.616</cell><cell>0.726</cell><cell>0.720</cell><cell>0.559</cell><cell>0.603</cell></row><row><cell>#02</cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell>L</cell><cell>0.782</cell><cell>0.766</cell><cell>0.631</cell><cell>0.722</cell><cell>0.783</cell><cell>0.775</cell><cell>0.629</cell><cell>0.715</cell></row><row><cell>#03</cell><cell></cell><cell>2</cell><cell></cell><cell></cell><cell>L</cell><cell>0.773</cell><cell>0.760</cell><cell>0.625</cell><cell>0.720</cell><cell>0.785</cell><cell>0.784</cell><cell>0.631</cell><cell>0.719</cell></row><row><cell>#04</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell>L</cell><cell>0.786</cell><cell>0.777</cell><cell>0.651</cell><cell>0.741</cell><cell>0.792</cell><cell>0.789</cell><cell>0.649</cell><cell>0.735</cell></row><row><cell>#05</cell><cell></cell><cell>8</cell><cell></cell><cell></cell><cell>L</cell><cell>0.774</cell><cell>0.762</cell><cell>0.627</cell><cell>0.724</cell><cell>0.775</cell><cell>0.774</cell><cell>0.619</cell><cell>0.708</cell></row><row><cell>#06</cell><cell></cell><cell>4</cell><cell>-</cell><cell></cell><cell>L</cell><cell>0.782</cell><cell>0.775</cell><cell>0.639</cell><cell>0.722</cell><cell>0.785</cell><cell>0.786</cell><cell>0.637</cell><cell>0.715</cell></row><row><cell>#07</cell><cell></cell><cell>4</cell><cell></cell><cell>-</cell><cell>L</cell><cell>0.755</cell><cell>0.752</cell><cell>0.587</cell><cell>0.705</cell><cell>0.754</cell><cell>0.751</cell><cell>0.579</cell><cell>0.694</cell></row><row><cell>#08</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell>L?L</cell><cell>0.748</cell><cell>0.717</cell><cell>0.577</cell><cell>0.705</cell><cell>0.760</cell><cell>0.741</cell><cell>0.587</cell><cell>0.693</cell></row><row><cell>#09</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell>L?G</cell><cell>0.788</cell><cell>0.780</cell><cell>0.645</cell><cell>0.741</cell><cell>0.776</cell><cell>0.768</cell><cell>0.618</cell><cell>0.715</cell></row><row><cell>#10</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell>G?G</cell><cell>0.778</cell><cell>0.763</cell><cell>0.627</cell><cell>0.726</cell><cell>0.767</cell><cell>0.753</cell><cell>0.599</cell><cell>0.694</cell></row><row><cell>#OUR</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell>G?L</cell><cell>0.806</cell><cell>0.798</cell><cell>0.676</cell><cell>0.756</cell><cell>0.797</cell><cell>0.793</cell><cell>0.653</cell><cell>0.737</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>time</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>time</cell><cell></cell><cell></cell><cell></cell><cell>time</cell></row><row><cell>Frame</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>PNS+</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>PNSNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2/3D</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MAT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ACSNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">These statistic data come from this website, which is different from the data reported in the original paper<ref type="bibr" target="#b3">[3]</ref>. Besides, the SUN-database is available for only non-commercial use in research or educational purpose, which could be freely accessed with permission from authors.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The descriptions of complete annotations refer to https://github.com/GewelsJI/VPS/blob/main/docs/ DATA DESCRIPTION.md.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank the anonymous reviewers and editor for their helpful comments on Springer Nature 2021 L A T E X template this manuscript. Besides, we thank Huazhu Fu for his insightful feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of Interests</head><p>The authors declared that they have no conflicts of interest in this work. We declare that we do not have any commercial or associative interest that represents a conflict of interest in connection with the work submitted.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards automatic polyp detection with a polyp appearance model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vilarino</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1016/j.patcog.2012.03.002</idno>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3166" to="3182" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Endoscopic polyp segmentation using a hybrid 2d/3d cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Puyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brandao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">F</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lovat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mountney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Lima, Peru</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-59725-2_29</idno>
		<idno>DOI: 10.1007/ 978-3-030-59725-2 29</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="295" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Development of a computer-aided detection system for colonoscopy and a publicly accessible large colonoscopy video database (with video)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Misawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ohtsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Matsuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ishida</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1016/j.gie.2020.07.060</idno>
	</analytic>
	<monogr>
		<title level="j">Gastrointestinal endoscopy</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="960" to="967" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Progressively normalized self-attention network for video polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-87193-2_14</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention. Strasbourg</title>
		<meeting><address><addrLine>France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="142" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Toward embedded detection of polyps in wce images for early diagnosis of colorectal cancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Histace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Romain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Granado</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/s11548-013-0926-3</idno>
		<idno>DOI: 10. 1007/s11548-013-0926-3</idno>
	</analytic>
	<monogr>
		<title level="j">International journal of computer assisted radiology and surgery</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="283" to="293" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Wm-dova maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fern?ndez-Esparrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vilari?o</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1016/j.compmedimag.2015.02.007</idno>
		<idno>DOI: 10.1016/ j.compmedimag.2015.02.007</idno>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Computer-aided classification of gastrointestinal lesions in regular colonoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mesejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pizarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abergel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Rouquette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Beorchia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Poincloux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TMI.2016.2547947</idno>
		<idno>DOI: 10.1109/ TMI.2016.2547947</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2051" to="2063" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automated polyp detection in colonoscopy videos using shape and context information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Gurudu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TMI.2015.2487997</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="630" to="644" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Gastrointestinal Image ANAlysis (GIANA) Challenge</title>
		<ptr target="https://endovissub2017-giana.grand-challenge.org/home/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A benchmark for endoluminal scene segmentation of colonoscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>V?zquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fern?ndez-Esparrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Drozdzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1155/2017/4037190</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Healthcare Engineering</title>
		<imprint>
			<biblScope unit="volume">2017</biblScope>
			<biblScope unit="page">4037190</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Kid project: an internetbased digital video atlas of capsule endoscopy for research purposes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koulaouzidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Iakovidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rondonotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kopylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Plevris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Eliakim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Marlicz</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1055/s-0043-105488</idno>
	</analytic>
	<monogr>
		<title level="j">Endoscopy International Open</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">477</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Iakovidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Georgakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vasilakakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koulaouzidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Detecting and locating gastrointestinal anomalies using deep learning and iterative cluster unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Plagianakos</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TMI.2018.2837002</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2196" to="2210" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Kvasir: A multi-class image dataset for computer aided gastrointestinal disease detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pogorelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Randel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Griwodz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Eskeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1145/3083187.3083212</idno>
	</analytic>
	<monogr>
		<title level="m">Multimedia Systems Conference</title>
		<meeting><address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="164" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Endoscopy disease detection challenge 2020</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ghatwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Braden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lamarque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Realdon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cannizzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rittscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Daul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>East</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2003.03376" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hyperkvasir, a comprehensive multi-class image and video dataset for gastrointestinal endoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Borgli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Thambawita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Eskeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Randel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pogorelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T D</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1038/s41597-020-00622-y</idno>
		<idno>DOI: 10.1038/ s41597-020-00622-y</idno>
	</analytic>
	<monogr>
		<title level="j">Scientific Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Kvasir-seg: A segmented polyp dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-37734-2_37</idno>
		<idno>DOI: 10.1007/ 978-3-030-37734-2 37</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia Modeling</title>
		<meeting><address><addrLine>Daejeon, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Piccolo white-light and narrow-band imaging colonoscopic dataset: A performance comparative of models and datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>S?nchez-Peralta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Pagador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pic?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><forename type="middle">J</forename><surname>Calder?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Polo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Andraka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bilbao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Saratxaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>S?nchez-Margallo</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.3390/app10238501</idno>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page">8501</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Kvasir-capsule, a video capsule endoscopy dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Thambawita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gjestang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">O</forename><surname>Nedrejord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Naess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Borgli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J D</forename><surname>Berstad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Eskeland</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1038/s41597-021-00920-z</idno>
		<idno>DOI: 10.1038/ s41597-021-00920-z</idno>
	</analytic>
	<monogr>
		<title level="j">Scientific Data</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An improved deep learning approach and its applications on colonic polyp images detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1186/s12880-020-00482-3</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ldpolypvideo benchmark: A largescale colonoscopy video dataset of diverse polyps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-87240-3_37</idno>
		<idno>DOI: 10.1007/ 978-3-030-87240-3 37</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Strasbourg, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="387" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Colonoscopy polyp detection and classification: Dataset creation and comparative evaluations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Fathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1371/journal.pone.0255809</idno>
		<idno>DOI: 10.1371/ journal.pone.0255809</idno>
	</analytic>
	<monogr>
		<title level="j">Plos one</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">255809</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Polypgen: A multi-center polyp detection and segmentation dataset for generalisability assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ghatwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Realdon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cannizzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">E</forename><surname>Salem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lamarque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Daul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Anonsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2106.04463" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Analysis of abnormality in endoscopic images using combined hsi color space and watershed segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Dhandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hegadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hangarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Malemath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">China</forename></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/ICPR.2006.268</idno>
		<imprint>
			<date type="published" when="2006" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="695" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automated polyp detection in colon capsule endoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Mamonov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">N</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><forename type="middle">R</forename><surname>Tsai</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TMI.2014.2314959</idno>
		<idno>DOI: 10.1109/ TMI.2014.2314959</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1488" to="1502" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Superpixel based segmentation and classification of polyps in wireless capsule endoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">H</forename><surname>Maghsoudi</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/SPMB.2017.8257027</idno>
	</analytic>
	<monogr>
		<title level="m">Signal Processing in Medicine and Biology Symposium. Philadelphia</title>
		<meeting><address><addrLine>PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Integrating online and offline threedimensional deep learning for automated polyp detection in colonoscopy videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/JBHI.2016.2637004</idno>
		<idno>DOI: 10.1109/ JBHI.2016.2637004</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="75" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Artificial intelligence for colonoscopy: Past, present, and future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tavanapong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Khaleel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mitta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>De Groen</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/JBHI.2022.3160098</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Two-stream deep feature modelling for automated video endoscopy data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gammulle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Lima, Peru</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-59716-0_71</idno>
		<idno>DOI: 10.1007/ 978-3-030-59716-0 71</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="742" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep learning uncertainty and confidence calibration for the five-class polyp classification from colonoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Z C T</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Burt</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1016/j.media.2020.101653</idno>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page">101653</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Polyp detection during colonoscopy using a regression-based convolutional neural network with a tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lau</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1016/j.patcog.2018.05.026</idno>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="209" to="219" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-frame collaboration for effective endoscopic video polyp detection via spatialtemporal feature transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-87240-3_29</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Strasbourg, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="302" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fully convolutional neural networks for polyp segmentation in colonoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brandao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mazomenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ciuti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cali?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Menciassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dario</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koulaouzidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arezzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Computer-Aided Diagnosis</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">L</forename><surname>Orlando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Usa:</forename><surname>Spie</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1117/12.2254361</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="101" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Polyp segmentation in colonoscopy images using fully convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Akbari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohrekesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nasr-Esfahani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Soroushmehr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Najarian</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/EMBC.2018.8512197</idno>
	</analytic>
	<monogr>
		<title level="m">Engineering in Medicine and Biology Society</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="69" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">U-Net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-319-24574-4_28</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unet++: Redesigning skip connections to exploit multiscale features in image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M R</forename><surname>Siddiquee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TMI.2019.2959609</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1856" to="1867" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Resunet++: An advanced architecture for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">De</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/ISM46123.2019.00049</idno>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Multimedia</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="225" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Polypseg: An efficient contextaware network for polyp segmentation from colonoscopy videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Lima, Peru</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-59725-2_28</idno>
		<idno>DOI: 10.1007/ 978-3-030-59725-2 28</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="285" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Adaptive context selection for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-59725-2_25</idno>
		<idno>DOI: 10. 1007/978-3-030-59725-2 25</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Lima, Peru</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Real-time polyp detection, localization and segmentation in colonoscopy using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Tomar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rittscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/ACCESS.2021.3063716</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="40" to="496" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Precise yet efficient semantic calibration and refinement in convnets for realtime polyp segmentation from colonoscopy videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2916" to="2924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Shallow attention network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cui</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-87193-2_66</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention. Strasbourg</title>
		<meeting><address><addrLine>France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="699" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Automatic polyp segmentation via multi-scale subtraction network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-87193-2_12</idno>
		<idno>DOI: 10.1007/ 978-3-030-87193-2 12</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Strasbourg, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="120" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Psi-Net: Shape and boundary aware joint multi-task deep network for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Murugesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sarveswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Shankaranarayana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sivaprakasam</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/EMBC.2019.8857339</idno>
	</analytic>
	<monogr>
		<title level="j">Engineering in Medicine and Biology Society. Germany</title>
		<imprint>
			<biblScope unit="page" from="7223" to="7226" />
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Boundary-aware context neural network for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1016/j.media.2022.102395</idno>
		<idno>DOI: 10. 1016/j.media.2022.102395</idno>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page">102395</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-Y</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Selective feature aggregation network with area-boundary constraints for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tong</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-32239-7_34</idno>
		<idno>DOI: 10.1007/ 978-3-030-32239-7 34</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Shenzhen, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="302" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Hrenet: A hard region enhancement network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Q</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-H</forename><surname>Meng</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-87193-2_53</idno>
		<idno>DOI: 10.1007/ 978-3-030-87193-2 53</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Strasbourg, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="559" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Fast camouflaged object detection via edgebased reversible re-calibration network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhuge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patcog.2021.108414</idno>
		<ptr target="https://doi.org/10.1016/j.patcog.2021.108414" />
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page">108414</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Pranet: Parallel reverse attention network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59725-2_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59725-226" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Lima, Peru</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="263" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Ccbanet: Cascading context and balancing attention for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-H</forename><surname>Diep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-H</forename><surname>Tran-Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">France</forename><surname>Strasbourg</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-87193-2_60</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="633" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Learnable oriented-derivative network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-87193-2_68</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<meeting><address><addrLine>Strasbourg, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="720" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Uacanet: Uncertainty augmented context attention for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1145/3474085.3475375</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ACM</publisher>
			<biblScope unit="page" from="2167" to="2175" />
			<pubPlace>Multimedia. Chengdu, China</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Transformers in medical imaging: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shamshad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2201.09873" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Transfuse: Fusing transformers and cnns for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-87193-2_2</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention. Strasbourg</title>
		<meeting><address><addrLine>France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="14" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Medical image segmentation using squeeze-and-expansion transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S M</forename><surname>Goh</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.24963/ijcai.2021/112</idno>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<meeting><address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Pvt v2: Improved baselines with pyramid vision transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/s41095-022-0274-8</idno>
		<idno>DOI: 10. 1007/s41095-022-0274-8</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Visual Media</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="415" to="424" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Polyp-pvt: Polyp segmentation with pyramid vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2108.06932" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Camouflaged object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/CVPR42600.2020.00285</idno>
		<idno>DOI: 10.1109/ CVPR42600.2020.00285</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2777" to="2787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">An iterative procedure for the polygonal approximation of plane curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Ramer</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1016/S0146-664X(72)80017-0</idno>
		<idno>DOI: 10. 1016/S0146-664X(72</idno>
	</analytic>
	<monogr>
		<title level="j">Computer graphics and image processing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="80017" to="80017" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Salient objects in clutter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TPAMI.2022.3166451</idno>
	</analytic>
	<monogr>
		<title level="m">Transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Rethinking rgb-d salient object detection: Models, data sets, and large-scale benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TNNLS.2020.2996406</idno>
	</analytic>
	<monogr>
		<title level="m">Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2075" to="2089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/CVPR.2018.00813</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Pyramid constrained self-attention network for fast video salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-P</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1609/aaai.v34i07.6718</idno>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="10" to="869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Normalized and geometry-aware self-attention network for image captioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on computer vision and pattern recognition</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Seattle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Usa</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/CVPR42600.2020.01034</idno>
		<idno>DOI: 10.1109/ CVPR42600.2020.01034</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE</publisher>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="page" from="10" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Layer normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2016 Deep Learning Symposium</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Res2net: A new multi-scale backbone architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TPAMI.2019.2938758</idno>
	</analytic>
	<monogr>
		<title level="m">Transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="652" to="662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Receptive field block net for accurate and fast object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/978-3-030-01252-6_24</idno>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<meeting><address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="385" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/CVPR.2016.90</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Efficient inference in fully connected crfs with gaussian edge potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<meeting><address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">See more, know more: Unsupervised video object segmentation with coattention siamese networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/CVPR.2019.00374</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3623" to="3632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Matnet: Motion-attentive transition network for zero-shot video object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TIP.2020.3013162</idno>
		<idno>DOI: 10. 1109/TIP.2020.3013162</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="8326" to="8338" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">The emergence of objectness: Learning zero-shot segmentation from videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Dynamic context-sensitive filtering network for video salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Piao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on computer vision</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title/>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/ICCV48922.2021.00158</idno>
		<idno>DOI: 10.1109/ ICCV48922.2021.00158</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="1553" to="1563" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Full-duplex strategy for video object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>International conference on computer vision. [Online</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title/>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/ICCV48922.2021.00488</idno>
		<idno>DOI: 10.1109/ ICCV48922.2021.00488</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="4922" to="4933" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Frequency-tuned salient region detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hemami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Estrada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/CVPR.2009.5206596</idno>
		<idno>DOI: 10. 1109/CVPR.2009.5206596</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Miami, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1597" to="1604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Cognitive vision inspired object segmentation metric and loss function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1155/2017/4037190</idno>
	</analytic>
	<monogr>
		<title level="m">SCIEN-TIA SINICA Informationis</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Structuremeasure: A new way to evaluate foreground maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/s11263-021-01490-8</idno>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2622" to="2638" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">How to evaluate foreground maps?&quot; in Conference on computer vision and pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Margolin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tal</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/CVPR.2014.39</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="248" to="255" />
			<pubPlace>Columbus, OH, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Salient object detection: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TIP.2015.2487833</idno>
		<idno>DOI: 10.1109/ TIP.2015.2487833</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5706" to="5722" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Structure-measure: A new way to evaluate foreground maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/ICCV.2017.487</idno>
		<idno>DOI: 10.1109/ ICCV.2017.487</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on computer vision</title>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4548" to="4557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Enhanced-alignment measure for binary foreground map evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.24963/ijcai.2018/97</idno>
		<idno>DOI: 10.24963/ ijcai.2018/97</idno>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<meeting><address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>IJCAI</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="698" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Transactions on pattern analysis and machine intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TPAMI.2021.3085766</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
	<note>Concealed object detection</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Deep gradient learning for efficient camouflaged object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Liniger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Intelligence Research</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Semanticoriented labeled-to-unlabeled distribution translation for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1109/TMI.2021.3114329</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="434" to="445" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Supervised and semi-supervised methods for abdominal organ segmentation: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">B</forename><surname>Senkyire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">file:/localhost/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/zero-shot/arxiv_pdf/10.1007/s11633-021-1313-0</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Automation and Computing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="887" to="914" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Tbrats: Trusted brain tumor segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2206.09309" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
