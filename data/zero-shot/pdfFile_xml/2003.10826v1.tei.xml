<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DeepFit: 3D Surface Fitting via Neural Network Weighted Least Squares</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhak</forename><surname>Ben-Shabat</surname></persName>
							<email>yizhak.benshabat@anu.edu.au</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Australian Centre for Robotic Vision</orgName>
								<orgName type="institution">The Australian National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
							<email>stephen.gould@anu.edu.au</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Australian Centre for Robotic Vision</orgName>
								<orgName type="institution">The Australian National University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DeepFit: 3D Surface Fitting via Neural Network Weighted Least Squares</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Normal estimation</term>
					<term>surface fitting</term>
					<term>least squares</term>
					<term>unstruc- tured 3D point clouds</term>
					<term>3D point cloud deep learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a surface fitting method for unstructured 3D point clouds. This method, called DeepFit, incorporates a neural network to learn point-wise weights for weighted least squares polynomial surface fitting. The learned weights act as a soft selection for the neighborhood of surface points thus avoiding the scale selection required of previous methods. To train the network we propose a novel surface consistency loss that improves point weight estimation. The method enables extracting normal vectors and other geometrical properties, such as principal curvatures, the latter were not presented as ground truth during training. We achieve state-of-the-art results on a benchmark normal and curvature estimation dataset, demonstrate robustness to noise, outliers and density variations, and show its application on noise removal.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Commodity 3D sensors are rapidly becoming an integral component of autonomous systems. These sensors, e.g., RGB-D cameras or LiDAR, provide a 3D point cloud representing the geometry of the scanned objects and surroundings. This raw representation, however, is challenging to process since it lacks connectivity information or structure, and is often incomplete, noisy and contains point density variations. In particular, processing it by means of convolutional neural networks (CNNs)-highly effective for images-is problematic because CNNs require structured, grid-like data as input.</p><p>When available, additional local geometric information, such as the surface normal and principal curvatures at each point, induces a partial local structure and improves performance of different tasks for interpreting the scene, such as over-segmentation <ref type="bibr" target="#b0">[1]</ref>, classification <ref type="bibr" target="#b17">[18]</ref> and surface reconstruction <ref type="bibr" target="#b8">[9]</ref>.</p><p>Estimating the normals and curvatures from a raw point cloud with no additional information is a challenging task due to difficulties associated with sampling density, noise, outliers, and detail level. The common approach is to specify a neighborhood around a point and then fit a local basic geometric surface (e.g., a plane) to the points in this neighborhood. The normal at the point under consideration is estimated from the fitted geometric surface. <ref type="bibr">The</ref>  of the neighborhood introduces an unavoidable trade-off between robustness to noise and accuracy of fine details. A large neighborhood over-smooths sharp corners and small details but is otherwise robust to noise. A small neighborhood, on the other hand, may reproduce the normals more accurately around small details but is more sensitive to noise. Evidently, a robust, scale-independent, data-driven surface fitting approach should improve normal estimation performance. We propose a surface fitting method for unstructured 3D point clouds. It features a neural network for point-wise weight prediction for weighted least squares fitting of polynomial surfaces. This approach removes the multi-scale requirement entirely and significantly increases robustness to different noise levels, outliers, and varying levels of detail. Moreover, the approach enables extracting normal vectors and additional geometric properties without the need for retraining or additional ground truth information. The main contributions of this paper are:</p><p>-A method for per-point weight estimation for weighted least squares fitting using deep neural networks. -A scale-free method for robust surface fitting and normal estimation.</p><p>-A method for principal curvature and geometric properties estimation without using ground truth labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Deep learning for unstructured 3D point clouds</head><p>The point cloud representation of a 3D scene is challenging for deep learning methods because it is both unstructured and unordered. In addition, the number of points in the point cloud varies for different scenes. Several methods have been proposed to overcome these challenges. Voxel-based methods embed the point cloud into a voxel grid but suffer from several accuracy-complexity tradeoffs <ref type="bibr" target="#b13">[14]</ref>. The PointNet approach <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref> applies a symmetric, order-insensitive, function on a high-dimensional representation of individual points. The Kd-Network <ref type="bibr" target="#b11">[12]</ref> imposes a kd-tree structure on the points and uses it to learn shared weights for nodes in the tree. The recently proposed 3D modified fisher vectors (3DmFV) <ref type="bibr" target="#b1">[2]</ref> represents the points by their deviation from a Gaussian Mixture Model (GMM) whose Gaussians are uniformly positioned on a coarse grid. In this paper we use a PoinNet architecture for estimating point-wise weights for weighted least squares surface fitting. We chose PointNet since it operates directly on the point cloud, does not require preprocessing, representation conversion or structure, and contains a relatively low number of parameters,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Normal Estimation</head><p>A classic method for estimating normals uses principal component analysis (PCA) <ref type="bibr" target="#b9">[10]</ref>. Here a neighborhood of points within some fixed scale is chosen and PCA regression used to estimate a tangent plane. Variants that fit local spherical surfaces <ref type="bibr" target="#b7">[8]</ref> or Jets <ref type="bibr" target="#b5">[6]</ref> (truncated Taylor expansion) have also been proposed. Further detail on Jet fitting is given in Section 2.3. To be robust to noise, these methods usually choose a large-scale neighborhood, leading them to smooth sharp features and fail to estimate normals near 3D edges. Computing the optimal neighborhood size can decrease the estimation error <ref type="bibr" target="#b14">[15]</ref> but requires the (usually unknown) noise standard deviation value and a costly iterative process to estimate the local curvature and additional density parameters.</p><p>A few deep learning approaches have been proposed to estimate normal vectors from unstructured point clouds. Boulch and Marlet proposed to transform local point cloud patches into a 2D Hough space accumulator by randomly selecting point triplets and voting for that plane's normal. Then, the normal is estimated from the accumulator by designing explicit criteria <ref type="bibr" target="#b3">[4]</ref> for bin selection or, more recently, by training a 2D CNN <ref type="bibr" target="#b4">[5]</ref> to estimate it continuously as a regression problem. This method does not fully utilize available 3D information since it loses information during the transformation stage. Another method, named PCPNnet <ref type="bibr" target="#b8">[9]</ref>, uses a PointNet <ref type="bibr" target="#b16">[17]</ref> architecture over local neighborhoods at multiple scales. It achieves good normal estimation performance and has been extended to estimating principal curvatures. However, it processes the multi-scale point clouds jointly and requires selecting a predefined set of scales. A more recent work, Nesti-Net <ref type="bibr" target="#b2">[3]</ref> tries to predict the appropriate scale using a mixture of experts network and a local representation for different scales. It achieves high accuracy but suffers from high computation time due to the multiple scale computations. Nesti-Net shares PCPNet's drawback of requiring a predefined set of scales. A contemporary work <ref type="bibr" target="#b12">[13]</ref> uses an iterative plane fitting approach which tries to predict all normals of a local neighborhood and iteratively adjusts the point weights to best fit the plane.</p><p>In this paper we propose a novel approach for normal estimation by learning to fit an n-order Jet while predicting informative points' weights. Our approach removes the need of predefined scales and optimal scale selection since the informative points are extracted at any given scale. Our method generalizes the contemporary method proposed by Lenssen et. al. <ref type="bibr" target="#b12">[13]</ref>, avoids the iterative process, and enables the computation of additional geometric properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Jet fitting using least squares and weighted least squares</head><p>We now provide background and mathematical notation for truncated Taylor expansion surface fitting using least-squares (LS) and weighted least-squares (WLS). We refer the interested reader to Cazals and Pouget <ref type="bibr" target="#b5">[6]</ref> for further detail.</p><p>Any regular embedded smooth surface can be locally written as the graph of a bi-variate "height function" with respect to any z-direction that does not belong to the tangent space <ref type="bibr">[19]</ref>. We adopt the naming convention of Cazals and Pouget <ref type="bibr" target="#b5">[6]</ref> and refer to the truncated Taylor expansion as a degree n jet or n-jet for short. An n-jet of the height function over a surface is given by:</p><formula xml:id="formula_0">f (x, y) = J ?,n (x, y) = n k=0 k j=0 ? k?j,j x k?j y j<label>(1)</label></formula><p>Here ? is the jet coefficients vector that consists of N n = (n + 1)(n + 2)/2 terms. In this work we wish to fit a surface to a set of N p 3D points. For clarity, we move to the matrix notation and specify the Vandermonde matrix M = (1, x i , y i , ..., x i y n?1 i , y n i ) i=1,...,Np ? R Np?Nn and the height function vector B = (z 1 , z 2 , ...z Np ) T ? R N p representing the sampled points. We require that every point satisfy Eq. 1, yielding the system of linear equations:</p><formula xml:id="formula_1">M ? = B<label>(2)</label></formula><p>When N n &gt; N p the system is over-determined and an exact solution may not exist. Therefore we use an LS approximation that minimizes the sum of square errors between the value of the jet and the height function over all points:</p><formula xml:id="formula_2">? = arg min z?R Nn M z ? B 2<label>(3)</label></formula><p>It is well known that the solution can be expressed in closed-form as:</p><formula xml:id="formula_3">? = (M T M ) ?1 M T B<label>(4)</label></formula><p>Typically the sampled points include noise and outliers that heavily reduce the fitting accuracy. To overcome this, the formulation given in Eq. 4 can be extended to a weighted least square problem. In this setting, some points have more influence on the fitted model than others. Let W ? R Np?Np be a diagonal weight matrix W = diag(w 1 , w 2 , ..., w Np ). Each element in the matrix's diagonal w i corresponds to the weight of that point. The optimization problem becomes:</p><formula xml:id="formula_4">? = arg min z?R Nn W 1/2 (M z ? B) 2 = arg min z?R Nn Np i=1 w i ? ? Nn j=1 M ij z j ? B i ? ? 2</formula><p>and its solution:</p><formula xml:id="formula_5">? = (M T W M ) ?1 M T W B<label>(5)</label></formula><p>In this work, we choose to focus on n-jet fitting because any order n differential quantity can be computed from the n-jet. This is one of the main advantages of our method. That is, our method is trained for estimating normal vectors but is then able to estimate other differential quantities, e.g., principal curvatures, depending on the jet order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DeepFit</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Learning point-wise weights</head><p>The full pipeline for our method is illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>. Given a 3D point cloud S and a query point q i ? S we first extract a local subset of points S i using k-nearest neighbors. We then use a neural network to estimate the weight of each point in the neighborhood, which will subsequently be used for weighted least squares surface fitting. Specifically, we feed S i into a PointNet <ref type="bibr" target="#b16">[17]</ref> network, which outputs a global point cloud representation G(S i ). Additionally, we extract local representations from an intermediate layer for each of the points p j ? S i separately to give g(p j ). These representations are then concatenated and fed into a multi-layer perceptron h(?) followed by a sigmoid activation function. We choose a sigmoid in order to limit the output values to be between 0 and 1. The output of this network is a weight per point that is used to construct the diagonal point-weight matrix, W = diag(w j ) with</p><formula xml:id="formula_6">w j = sigmoid(h(G(S i ), g(p ij ))) +<label>(6)</label></formula><p>For numerical stability, we add a constant small in order to avoid the degenrate case of a zero or poorly conditioned matrix. This weight matrix is then used to solve the WLS problem of Eq. 5 and approximate the n-jet coefficients ?. All parts of the network are differentiable and therefore it is trained end-to-end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Geometric quantities estimation</head><p>Given the n-jet coefficients ? several geometric quantities can be easily extracted:</p><p>Normal estimation. The estimated normal vector is given by:</p><formula xml:id="formula_7">N i = (?? 1 , ?? 2 , 1) (?? 1 , ?? 2 , 1) 2 (7)</formula><p>Shape operator and principal curvatures. For the second order information we compute the Weingarten map of the surface by multiplying the inverse of the first fundamental form and the second fundamental form. Its eigenvalues are the principal curvatures (k 1 , k 2 ), and its eigenvectors are the principal directions. The computation is done in the tangent space associated with the parametrization.</p><formula xml:id="formula_8">M Weingarten = ? 1 ? 2 1 + ? 2 2 + 1 1 + ? 2 1 ? 1 ? 2 ? 1 ? 2 1 + ? 2 2 ?1 2? 3 ? 4 ? 4 2? 5<label>(8)</label></formula><p>Generally, the principal curvatures can be used as ground truth in training, however, due to the eigenvalue decomposition, with the high probability of outputting two zero principal curvatures (planes) it suffers from numerical issues when computing the gradients for backpropagation <ref type="bibr" target="#b6">[7]</ref>. Therefore, we compute the curvatures only at test time. Note that Monge basis and higher order Monge coefficients can also be computed, similar to <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Consistency loss</head><p>In order to learn point-wise weights, we introduce a local consistency loss L con . This loss is composed of two terms, the weighted normal difference term and a regularization term. The weighted normal difference term computes a weighted average of the sine of the angle between the ground truth normal and the estimated normal at every local neighborhood point. These normals are computed analytically by converting the n-jet to the implicit surface form of F (x, y, z) = 0. Therefore, for every query point q i and its local neighborhood S i we can compute the normal at each neighboring point p j ? S i using:</p><formula xml:id="formula_9">N j = ?F ?F pj = (?? i ?M ?x T , ? i ?M ?y T , 1) ?F pj<label>(9)</label></formula><p>Note that this formulation assumes all points to lie on the surface, for points that are not on the surface, the normal error will be large, therefore that points weight will be encouraged to be small. This term can easily converge to an undesired local minimum by setting all weights to zero. In order to avoid that, we add a regularization term which computes the negative average log of all weights. In summary, the consistency loss for a query point q i is then given by:</p><formula xml:id="formula_10">L con = 1 N qi ? ? ? Nq i j=1 log(w j ) + Nq i j=1 w j |N GT ? N j | ? ?<label>(10)</label></formula><p>In contrast to Lenssen et. al. <ref type="bibr" target="#b12">[13]</ref>, this formulation allows us to avoid solving multiple linear systems iteratively for each point in the local neighborhood.</p><p>In total, to train the network, we sum several loss terms: The sin loss between the estimated unoriented normal and the ground truth normal at the query point, the consistency loss, and PointNet's transformation matrix regularization terms</p><formula xml:id="formula_11">L reg = I ? AA T . L tot = |N GT ? N i | + ? 1 L con + ? 2 L reg<label>(11)</label></formula><p>Here, ? 1 , and ? 2 are weighting factors, chosen empirically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Implementation notes</head><p>In our experiments we report results using DeepFit with the following configuration, unless otherwise stated. A four layer MLP with sizes 512, 256, 128, and 1; a neighborhood size of 256 points, and a 3-order jet. In order to avoid numerical issues, simplify the notation, and reduce the linear algebra operations, we perform the following pre-processing stages on every local point cloud:</p><p>1. Normalization: we translate the point cloud to position the query point in the origin and scale the point cloud to fit a unit sphere. 2. Basis extraction: we perform principal component analysis (PCA) on the point cloud. We then use the resulting three orthonormal eigenvectors as the fitting basis so that the vector associated with the smallest eigenvalue is the last vector of the basis. 3. Coordinate frame transformation: We perform a change of coordinates to move the points into the coordinate system of the fitting basis. 4. Preconditioning: we precondition the Vandermonde matrix by performing column scaling. Each monomial x k i y l i is divided by h k+l . That is, M = M D ?1 with D the diagonal matrix D = diag(1, h, h 2 , ..., h n ). We use the mean of the norm (x i , y i ) as h. The new system is then M (D?) = B and</p><formula xml:id="formula_12">? = D ?1 (M T W M ) ?1 M T W B.</formula><p>Note that after the normal is estimated we apply the inverse transform to output the result in the original coordinate frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset and training details</head><p>For training and testing we used the PCPNet shape dataset <ref type="bibr" target="#b8">[9]</ref>. The training set consists of eight shapes: four CAD objects (fandisk, boxunion, flower, cup) and four high quality scans of figurines (bunny, armadillo, dragon and turtle). All shapes are given as triangle meshes and densely sampled with 100k points. The data is augmented by introducing i.i.d. Gaussian noise for each point's spacial location with a standard deviation of 0.012, 0.006, 0.00125 w.r.t the bounding box size. This yields a set with 3.2M training examples. The test set consists of 22 shapes, including figurines, CAD objects, and analytic shapes. For evaluation we use the same 5000 point subset per shape as in Guerrero et al. <ref type="bibr" target="#b8">[9]</ref>.</p><p>All variations of our method were trained using 32,768 (1024 samples by 32 shapes) random subsets of the 3.2M training samples at each epoch. We used a batch size of 256, the Adam optimizer and a learning rate of 10 ?3 . The implementation was done in PyTorch and trained on a single Nvidia RTX 2080 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Normal estimation performance</head><p>We use the RMSE metric for comparing the proposed DeepFit to other deep learning based methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b12">13]</ref> and classical geometric methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b5">6]</ref>. Additionally, we analyze robustness for two types of data corruption:</p><p>-Point density-applying two sampling regimes for point subset selection: gradient, simulating effects of distance from the sensor, and stripes, simulating local occlusions. -Point perturbations-adding Gaussian noise to the points coordinates with three levels of magnitude specified by ?, given as a percentage of the bounding box.</p><p>For the geometric methods, we show results for three different scales: small, medium and large, which correspond to 18, 112, 450 nearest neighbors. For the deep learning based methods we show the results for the single-scale (ss) and multi-scale (ms) versions. <ref type="table" target="#tab_1">Table 1</ref> shows the unoriented normal RMSE results for the methods detailed above. It can be seen that our method slightly outperforms all other methods for low, medium and no noise augmentation and for gradient density augmentation. For high noise, and striped occlusion augmentation we are a close second to the contemporary work of Lenssen et al. <ref type="bibr" target="#b12">[13]</ref> which only estimates the normal vectors while DeepFit also estimates other geometric properties, e.g., principal curvatures. The results also show that all method's performance deteriorate as the noise level rises. In this context, both PCA and Jet perform well for specific noise-scale pairs. In addition, for PCPNet, using a multiple scales only mildly improves performance. Nesti-Net's mixture of experts mitigate the scale-accuracy tradeoff well at the cost of computational complexity. DeepFit's soft point selection process overcomes this tradeoff. In the supplemental materials we perform additional evaluation using the percentage of good points (PGP?) metric. <ref type="figure" target="#fig_1">Figure 2a</ref> depicts a visualization of DeepFit's results on three point clouds. Here the normal vectors are mapped to the RGB cube. It shows that for complex shapes (pillar, liberty) with high noise levels, the general direction of the normal vector is predicted correctly, but, the fine details and exact normal vector are not obtained. For a basic shape (Boxysmooth) the added noise does not affect the results substantially. Most notably, DeepFit shows robustness to point density corruptions. <ref type="figure" target="#fig_1">Figure 2b depicts</ref>   for the different methods using a heat map. For the Jet method <ref type="bibr" target="#b5">[6]</ref> we display the results for medium scale. For all methods, it can be seen that more errors occur in regions with small details, high curvature e.g. edges and corners, and complex geometry. DeepFit suffers the least from this effect due to its point-wise weight estimation, which allows it to adapt to the different local geometryand disregard irrelevant points in the fitting process. <ref type="figure">Figure 3</ref> qualitatively visualizes the performance of DeepFit's point-wise weight prediction network. The colors of the points correspond to weight magnitude, mapped to a heatmap ranging from 0 to 1 i.e. red points highly affect the fit while blue points have low influence. It shows that the network learns to adapt well to corner regions (column n = 1), assigning high weights to points on one plane and excluding points on the perpendicular one. Additionally, it shows how the network adapted the weight to achieve a good fit for complex geometries (column n = 2, 3, 4). <ref type="figure">Fig. 4</ref> shows the unoriented normal RMSE results for different parameter choices of our method. We explore different Jet orders n = 1, 2, 3, 4, and a different number of neighboring points k = 64, 128, 256, It shows that using a large neighborhood size highly improves the performance in high noise cases while only minimally affecting the performance in low noise. It also shows that all jet orders are comparable with a small advantage for order 1-jet (plane) and order 3-jet which is an indication for a bias in the dataset towards low curvature geometry. Additional ablation results, including more augmentations and the PGP? metric are provided in the supplemental material.</p><p>Timing and efficiency performance are provided in the supplemental material. DeepFit is faster and has fewer parameters than PCPNet and Nesti-Net and has the potential of only being slightly slower than CGAL implementation of Jet  fitting because the forward pass for weight estimation is linear with respect to the number of points and the network weights. For quantitative evaluation we use the normalized RMSE metric curvature estimation evaluation proposed in Guerrero et. al. <ref type="bibr" target="#b8">[9]</ref> and given in Eq. 12, for comparing the proposed method to other deep learning based <ref type="bibr" target="#b8">[9]</ref> and geometric methods <ref type="bibr" target="#b5">[6]</ref>. <ref type="table" target="#tab_3">Table 2</ref> summarizes the results and shows an average error reduction of 35% and 13.7% for maximum and minimum curvatures respectively. We analyze robustness for the same types of data corruptions as in normal estimation i.e. point perturbation and density. DeepFit significantly outperforms all other methods for maximum principal curvature k 1 . For the minimum principal curvature k 2 DeepFit outperforms all methods for low and no noise augmentation in addition to gradient and striped density augmentation, however PCPNet has a small advantage for medium and high noise levels. The results for the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Principal curvature estimation performance</head><formula xml:id="formula_13">|k i |) + ?(|k i |)), ?(|k i |) + ?(|k i |)]| i=1,2 .</formula><p>minimum curvature are very sensitive since most values are close to zero.</p><formula xml:id="formula_14">D kj = k j ? k GT max{|k GT |, 1}</formula><p>, for j = 1, 2.</p><p>The normalized RMSE metric is visualized in <ref type="figure" target="#fig_5">Fig. 6</ref> for DeepFit and PCPNet as the magnitude of the error vector mapped to a heatmap. It can be seen that more errors occur near edges, corners and small regions with a lot of detail and high curvature. These figures show that for both simple and complex geometric shapes DeepFit is able to predict the principal curvatures reliably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Surface reconstruction and noise removal</head><p>We further investigate the effectiveness of our surface fitting in the context of two subsequent applications-Poisson surface reconstruction <ref type="bibr" target="#b10">[11]</ref> and noise removal.</p><p>Surface reconstruction. <ref type="figure" target="#fig_6">Fig. 7a</ref> shows the results for the classical Jet fitting and our DeepFit approach. Since the reconstruction requires oriented normals, we orient the normals, in both methods, according to the ground truth normal. It shows that using DeepFit, the poisson reconstruction is moderately more satisfactory by being smoother overall, and crispier near corners. It also retains small details (liberty crown, cup rim).</p><p>Noise removal. The point-wise weight prediction network enables a better fit by reducing the influence of neighboring points. This weight can also be interpreted as the network's confidence of that point to lie on the object's surface. Therefore, we can use the weight to remove points with low confidence. We first Aug.    aggregate the weights by summing all of its weight prediction from all of its neighbors. Then we compute the mean and standard deviation of the aggregateed weights and remove points under a threshold of ?( w i ) ? ?( w i ). The output point cloud contains less points than the original one and the removed points are mostly attributed to outliers or noise. The results are depicted in <ref type="figure" target="#fig_6">Fig. 7b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Summary</head><p>In this paper we presented a novel method for deep surface fitting for unstructured 3D point clouds. The method consists of estimating point-wise weights for solving a weighted least square fitting of an n-jet surface. Our model is fully differentiable and can be trained end-to-end. The estimated weights (at test time) can be interpreted as the a confidence measure for every point in the point cloud and used for noise removal. Moreover, the formulation enables the computation of normal vectors and higher order geometric quantities like principal curvatures. The approach demonstrates high accuracy, robustness and efficiency compared to state-of-the-art methods. This is attributed to its ability to adaptively select the neighborhood of points through a learned model while leveraging classic robust surface fitting approaches, allowing the network to achieve high accuracy with a low number of parameters and computation time.</p><p>19. Michael D Spivak. A comprehensive introduction to differential geometry. Publish or perish, 1970.</p><p>6 Supplementary Material 6.1 Normal and principal curvature estimation performance Performance on real data. We qualitatively evaluate the performance of our method on the NYU Depth V2 dataset <ref type="bibr" target="#b15">[16]</ref>. This dataset was captured using a Kinect v1 RGBD camera and contains indoor scene environment and includes missing data and a noise pattern that is significantly different than the PCPNet dataset. Specifically, the noise often has the same magnitude as some of the features. Most importantly, this dataset, much like other real-world datasets, does not have ground truth normals. <ref type="figure" target="#fig_7">Fig. 8</ref> and <ref type="figure" target="#fig_8">Fig. 9</ref> show the performance of DeepFit's normal and principal curvature estimation respectively compared to Jet. DeepFit was trained with 256 points, however, since the network's weights are shared between the points it can be used with any neighborhood size. In these results we show the performance for 128, 256, 512, 1024 neighboring points. It shows that DeepFit is less sensitive to noise and is able to overcome the oversmoothing affect commonly attributed to using a large neighborhood while also preserving fine details.</p><p>Additional normal estimation results. We evaluate the normal estimation performance on the PCPNet datast using the percentage of good points (PGP ?) metric. <ref type="figure" target="#fig_0">Fig 10 shows</ref> the results of different learning based methods for increasing ? values . It shows that for low and medium noise levels, DeepFit is comparable to Lenssen et.al. <ref type="bibr" target="#b12">[13]</ref> while in all other categories their performance is better. This is most likely attributed to the dataset bias towards flat and low curvature surfaces, in which case, our method does not pose an advantage. DeepFit main advantage is in curvy surfaces where an n-jet yields a better fit than a plane. We evaluate DeepFit's normal estimation performance using RMSE for different n-jet orders and number of points in the neighborhood. The results are shown in <ref type="figure" target="#fig_0">Fig. 11</ref>. It shows that the increase in the number of neighboring points slightly decreases the performance in the no noise augmentation however it significantly improves the performance in high noise. This is mainly attributed to the weight estimation network that softly selects the most relevant points for the fit. It also shows that 1-jet (planes) perform well, however higher order jets have an advantage in the low and medium noise augmentation categories. In theory, the higher order jets have the capacity to fit planes, however in practice it is not always the case. <ref type="figure" target="#fig_0">Fig. 12</ref> depicts a visualization of DeepFit's results on PCPNet point clouds. Here the normal vectors are mapped to the RGB cube. <ref type="figure" target="#fig_0">Fig. 13</ref> depicts a visualization of the angular error in each point for the PCPNet dataset. Here, the points' color correspond to angular difference, mapped to a heatmap ranging from 0-60 degrees. It shows that for complex shapes with high noise levels, the general direction of the normal vector is predicted correctly, but, the fine details and exact normal vector are not obtained. For basic shapes the added noise does not affect the results substantially. Most notably, DeepFit shows robustness to point density corruptions.   . Additional principal curvature estimation results. <ref type="figure" target="#fig_0">Fig. 14 qualitatively</ref> depicts DeepFit's results on the PCPNet dataset. For visualization, the principal curvatures are mapped to RGB values according to the commonly used mapping given in <ref type="figure" target="#fig_3">Fig. 5</ref> i.e. both positive (dome) are red, both negative (bowl) are blue, one positive and one negative (saddle) are green, both zero (plane) are white, and one zero and one positive/negative (cylinder) are yellow/cyan. For consistency in color saturation we map each model differently according to the mean and standard deviation of the principal curvatures. Note that the curvature sign is determined by the ground truth normal orientation. DeepFit's normalized RMSE metric is visualized in <ref type="figure" target="#fig_0">Fig. 15</ref> as the magnitude of the error vector mapped to a heatmap. It can be seen that more errors occur near edges, corners and small regions with a lot of detail and high curvature. Moreover, these visualizations show that for low noise levels, the principal curvature estimation is reliable, as expected, the reliability declines with the insertion of high magnitude noise. <ref type="table" target="#tab_5">Table 3</ref> shows a comparison between the number of parameters and run time between different deep learning based normal estimation methods. It can be seen that DeepFit has a significantly lower number of parameters compared to Nesti-Net and PCPNet and more parameters than Lenssen et. al.. This gap in the number of parameters can be explained by the lack of point structure in our method while Lessen et. al. construct a graph. Constructing a graph introduces a limitation with respects to the number of neighboring points, i.e. training and testing has to be done on the same neighborhood size, using a PointNet architecture allows to train and test on different sizes of neighborhoods. DeepFit's , number of parameters is mainly attributed to the PointNet transformation subnetworks. The reported run time is the average run time for a batch of size 64 (i.e. computing normals for 64 points simultaneously). We chose a batch of 64 in order to fairly compare to the more resource intensive methods (Nesti-Net). Most methods, including ours, can compute in larger batches for faster performance, particularly Lenssen et. al. that are able to fit a full size point cloud (100k points) in a single batch on the GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Efficiency</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Our DeepFit Nesti-Net <ref type="bibr">[</ref>      </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>chosen size (or scale) arXiv:2003.10826v1 [cs.CV] 23 Mar 2020 DeepFit pipeline for normal and principal curvature estimation. For each point in a given point cloud, we compute a global and local representation and estimate a point-wise wight. Then, we fit an n-jet by solving a weighted least squares problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>(a) DeepFit's normal estimation results for different noise levels (columns 1-4), and density distortions (columns 5-6). The colors of the points are normal vectors mapped to RGB. (b) Normal estimation error visualization results of DeepFit compared to other methods for three types of point clouds without noise. The colors of the points correspond to angular difference, mapped to a heatmap ranging from 0-60 degrees.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :Fig. 4 :</head><label>34</label><figDesc>DeepFit point-wise weight prediction. Three views of different n-jet surface fits. The colors of the points correspond to weight magnitude , mapped to a heatmap ranging from 0 to 1; see color bar on the right i.e. red points highly affect the fit while blue points have low influence. Normal estimation RMSE results for DeepFit ablations for (a) no noise and (b) high noise augmentations. Comparing the effect of number of neighboring points and jet order.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5</head><label>5</label><figDesc>qualitatively depicts DeepFit's results on five point clouds. For visualization, the principal curvatures are mapped to RGB values according to the commonly used mapping given in its bottom right corner i.e. both positive (dome) are red, both negative (bowl) are blue, one positive and one negative (saddle) are green, both zero (plane) are white, and one zero and one positive/negative (cylinder) are yellow/cyan. For consistency in color saturation we map each model differently according to the mean and standard deviation of the principal curvatures. Note that the curvature sign is determined by the ground truth normal orientation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Curvature estimation results visualization. The colors of the points corresponds to the mapping of k 1 , k 2 to the color map given in the bottom right. Values in the range [?(?(</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 :</head><label>6</label><figDesc>Curvature estimation error results for DeepFit compared PCPNet. The numbers under each point cloud are its normalized RMSE errors in the format (k 1 , k 2 ). The color corresponds to the L2 norm of the error vector mapped to a heatmap ranging from 0-5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 :</head><label>7</label><figDesc>DeepFit performance in two subsequent application pipelines: (a) Poisson surface reconstruction using estimated normal vectors from the classical Jet fitting and the proposed DeepFit. (b) Noise removal results using DeepFit predicted weights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 :</head><label>8</label><figDesc>Normal estimation results for DeepFit and Jet on NYU Depth V2 dataset for different neighborhoods sizes (128, 256, 512, 1024). The colors of the points are normal vectors mapped to RGB and projected to the image plane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 :</head><label>9</label><figDesc>Principal curvature estimation results for DeepFit and Jet on NYU Depth V2 dataset for different neighborhoods sizes (128, 256, 512, 1024). The colors of the points correspond to their principal curvature values using the colormap in the bottom-left corner and projected to the image plane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 :Fig. 11 :</head><label>1011</label><figDesc>Comparison of the percentage of good points (PGP) metric for unoriented normal estimation of the proposed DeepFit to other deep learning methods (PCPNet<ref type="bibr" target="#b8">[9]</ref>, Nesti-Net<ref type="bibr" target="#b2">[3]</ref>, Lenssen et. al.<ref type="bibr" target="#b12">[13]</ref>). Here, ? is the threshold for measuring the percentage of good points. Comparison of the angle RMSE metric for different DeepFit variants. Ablations include different n-jet order<ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4)</ref> and number of neighboring points (64, 128, 256).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 :</head><label>12</label><figDesc>DeepFit's normal estimation results for different noise levels (columns 1-4), and density distortions (columns 5-6). The colors of the points are normal vectors mapped to RGB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 :</head><label>13</label><figDesc>Normal estimation error visualization for different noise levels (columns 1-4), and density distortions (columns 5-6). The colors of the points correspond to angular difference, mapped to a heatmap ranging from 0-60 degrees. The number above each point cloud is the RMSE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 14 :</head><label>14</label><figDesc>Curvature estimation results visualization. The colors of the points corresponds to the mapping of k 1 , k 2 to the color map given in Fig 5. Values in the range [?(?(|k i |) + ?(|k i |)), ?(|k i |) + ?(|k i |)]| i=1,2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 :</head><label>15</label><figDesc>Curvature estimation error results. The numbers under each point cloud are its RMSE and normalized RMSE. The color corresponds to the L2 norm of the error vector mapped to a heatmap ranging from 0-5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>a visualization of the angular error in each point</figDesc><table><row><cell>Aug.</cell><cell>Our Deep-Fit</cell><cell>PCA [10]</cell><cell>Jet [6]</cell><cell cols="2">PCPNet [9]</cell><cell>Len-ssen [13] et. al</cell><cell>Nesti-Net</cell></row><row><cell>scale</cell><cell>ss</cell><cell cols="3">small med large small med large ss</cell><cell>ms</cell><cell cols="2">ss ms (MoE)</cell></row><row><cell>None</cell><cell cols="6">6.51 8.31 12.29 16.77 7.60 12.35 17.35 9.68 9.62 6.72</cell><cell>6.99</cell></row><row><cell>Noise ?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.00125</cell><cell cols="6">9.21 12.00 12.87 16.87 12.36 12.84 17.42 11.46 11.37 9.95</cell><cell>10.11</cell></row><row><cell>0.006</cell><cell cols="6">16.72 40.36 18.38 18.94 41.39 18.33 18.85 18.26 18.87 17.18</cell><cell>17.63</cell></row><row><cell>0.012</cell><cell cols="6">23.12 52.63 27.5 23.5 53.21 27.68 23.41 22.8 23.28 21.96</cell><cell>22.28</cell></row><row><cell>Density</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Gradient 7.31 9.14 12.81 17.26 8.49 13.13 17.8 13.42 11.7 7.73</cell><cell>9.00</cell></row><row><cell>Stripes</cell><cell cols="6">7.92 9.42 13.66 19.87 8.61 13.39 19.29 11.74 11.16 7.51</cell><cell>8.47</cell></row><row><cell cols="7">average 11.8 21.97 16.25 18.87 21.95 16.29 19.02 14.56 14.34 11.84</cell><cell>12.41</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Comparison of the RMSE angle error for unoriented normal vector estimation of our DeepFit method to classical geometric methods (PCA [10] and Jet [6] -for three scales small, med, and large corresponding to k = 18, 122, 450), and deep learning methods (PCPNet [9], Lenssen et. al [13], and Nesti-Net [3])</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison of normalized RMSE for (left) maximal (k 1 ) and (right) minimal (k 2 ) principal curvature estimation of our DeepFit method to the classic Jet<ref type="bibr" target="#b5">[6]</ref> with three scales, and PCPNet<ref type="bibr" target="#b8">[9]</ref> </figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Number of parameters and execution time performance for deep learning normals estimation methods. Run time is averaged for batches of size 64.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Graph based over-segmentation methods for 3d point clouds. Computer Vision and Image Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhak</forename><surname>Ben-Shabat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamar</forename><surname>Avraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lindenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anath</forename><surname>Fischer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Threedimensional point cloud classification in real-time using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhak</forename><surname>Ben-Shabat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lindenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anath</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3145" to="3152" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Nesti-net: Normal estimation for unstructured 3d point clouds using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhak</forename><surname>Ben-Shabat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lindenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anath</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10112" to="10120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast and robust normal estimation for point clouds with sharp features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renaud</forename><surname>Marlet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1765" to="1774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep learning for robust normal estimation in unstructured point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renaud</forename><surname>Marlet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="281" to="290" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Estimating differential quantities using polynomial fitting of osculating jets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Cazals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pouget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Aided Geometric Design</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="146" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Eigendecomposition-free training of deep networks with zero eigenvaluebased losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang Moo</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinlin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="768" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Algebraic point set surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ga?l</forename><surname>Guennebaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pcpnet learning local shape properties from raw point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanir</forename><surname>Kleiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niloy J</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="75" to="85" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Surface reconstruction from unorganized points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Derose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Duchampt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Stuetzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Poisson surface reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Bolitho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth Eurographics symposium on Geometry processing</title>
		<meeting>the fourth Eurographics symposium on Geometry processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Escape from cells: Deep kd-networks for the recognition of 3d point cloud models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Klokov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
			<biblScope unit="page" from="863" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Differentiable iterative surface normal estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Osendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07172</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Voxnet: A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="922" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Estimating surface normals in noisy point cloud data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Niloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">An</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth Annual Symposium on Computational geometry</title>
		<meeting>the Nineteenth Annual Symposium on Computational geometry</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="322" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Indoor segmentation and support inference from RGBD images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Pushmeet Kohli Nathan Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="746" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5099" to="5108" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
