<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongkwon</forename><surname>Jin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonhui</forename><surname>Park</surname></persName>
							<email>whpark@mcl.korea.ac.kr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seong-Gyun</forename><surname>Jeong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyeon</forename><surname>Kwon</surname></persName>
							<email>heeyeon.kwon@42dot.ai</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Su</forename><surname>Kim</surname></persName>
							<email>changsukim@korea.ac.kr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Korea</forename><surname>University</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ai</surname></persName>
						</author>
						<title level="a" type="main">Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A novel algorithm to detect road lanes in the eigenlane space is proposed in this paper. First, we introduce the notion of eigenlanes, which are data-driven descriptors for structurally diverse lanes, including curved, as well as straight, lanes. To obtain eigenlanes, we perform the best rank-M approximation of a lane matrix containing all lanes in a training set. Second, we generate a set of lane candidates by clustering the training lanes in the eigenlane space. Third, using the lane candidates, we determine an optimal set of lanes by developing an anchor-based detection network, called SIIC-Net. Experimental results demonstrate that the proposed algorithm provides excellent detection performance for structurally diverse lanes. Our codes are available at https://github.com/dongkwonjin/Eigenlanes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Lane detection is essential for understanding driving environments, in which autonomous or human drivers should abide by traffic rules. To control vehicle maneuvers, boundaries of road lanes and sidewalks should be detected reliably. There are various challenging factors to interfere with the detection of those lanes. For example, lanes may be unobvious or even invisible due to weather and illumination conditions or due to the occlusion by nearby vehicles, as illustrated in <ref type="figure" target="#fig_0">Figure 1(a)</ref>.</p><p>For lane detection, traditional methods extract handcrafted features, such as image gradients or color features <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b8">10,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b33">35]</ref>. This feature engineering may fail to discriminate actual lanes from noisy ones. Recently, various CNNbased techniques have been developed to detect lanes in real environments more reliably. Most such techniques adopt the semantic segmentation framework <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b11">13,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b32">34]</ref>, in which each pixel in an image is dichotomized into either lane or no-lane category. To preserve continuous lane structure in detection results, several attempts have been made, including curve fitting <ref type="bibr" target="#b19">[21]</ref>, polynomial regression <ref type="bibr" target="#b30">[32]</ref>, and adversarial training <ref type="bibr" target="#b3">[5]</ref>. However, even these algorithms may fail to detect less visible lanes in cluttered scenes, because they use only local features and may miss parts of lanes. Meanwhile, the anchor-based detection framework, which has been used extensively in object detection <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b26">28]</ref>, has been recently adopted for lane detection <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b28">30]</ref>. These anchor-based algorithms consider straight lines as anchors (or lane candidates). Then, they declare each anchor as a lane or not. By exploiting longrange contextual information, they can detect implied lanes effectively. However, because of the straight lane assumption, it may not deal with complicated lanes, such as curved and winding ones in <ref type="figure" target="#fig_0">Figure 1</ref>(b). In this paper, we propose a novel algorithm to detect structurally diverse road lanes in the eigenlane space. It enables to process curved, as well as straight, lanes reliably in the anchor-based detection framework. First, we introduce the notion of eigenlanes, which are data-driven lane descriptors. To obtain eigenlanes, we approximate a lane matrix, which contains all lanes in a training set, based on the lowrank approximation property of singular value decomposition (SVD) <ref type="bibr" target="#b2">[4]</ref>. Then, each lane is represented by a linear combination of M eigenlanes. Second, we generate a set of lane candidates, including complicated and curved ones, by clustering the training lanes in the eigenlane space. Third, we develop an anchor-based detector, called SIIC-Net, to detect lanes from the candidates. It consists of two modules: self-lane identification (SI) module and inter-lane correlation (IC) module. SI computes the classification probability and regression offset of each candidate, while IC estimates the compatibility between each pair of lanes. Extensive experiments show that the proposed algorithm provides competitive results on existing datasets <ref type="bibr">[1,</ref><ref type="bibr" target="#b20">22]</ref> and outperforms the state-of-the-art techniques <ref type="bibr" target="#b28">[30,</ref><ref type="bibr" target="#b32">34]</ref> on a new dataset, called SDLane, containing structurally more diverse lanes.</p><p>This work has the following major contributions:</p><p>? We propose the notion of eigenlanes, which are datadriven lane descriptors, to represent structurally diverse lanes compactly in the eigenlane space.</p><p>? We develop SIIC-Net to detect and regress road lanes in the eigenlane space effectively and efficiently. It yields outstanding performances on various datasets.</p><p>? We construct the SDLane dataset to represent structurally diverse and complicated lanes in real driving environments more faithfully than the existing datasets do. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In autonomous driving systems, it is required to detect boundaries of road lanes, sidewalks, or crosswalks precisely and reliably. Whereas early methods <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b8">10,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b33">35]</ref> adopted hand-crafted low-level features, several CNN-based lane detectors have been developed recently to cope with complicated road scenes using deep features. Most of these techniques are based on the semantic segmentation framework <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b11">13,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b32">34]</ref>, in which pixel-wise classification is performed to decide whether each pixel belongs to a lane or not. In <ref type="bibr" target="#b20">[22]</ref>, Pan et al. developed a convolutional network to propagate spatial information between pixels through message passing. Zheng et al. <ref type="bibr" target="#b32">[34]</ref> passed the information more efficiently using a recurrent feature aggregation module. In <ref type="bibr" target="#b11">[13]</ref>, Hou et al. proposed a self-attention distillation mechanism to train the network more effectively. Also, Hou et al. <ref type="bibr" target="#b10">[12]</ref> employed teacher and student networks to transfer structural relationships between lanes by constructing an inter-region affinity graph. To maintain long-range consistency of segmented results, Ghafoorian et al. <ref type="bibr" target="#b3">[5]</ref> used a discriminator to refine prediction results of a generator through adversarial training. In <ref type="bibr" target="#b19">[21]</ref>, Neven et al. applied a perspective transformation to segmented pixels of each lane and used the transformed points for polynomial fitting.</p><p>Alternative approaches, different from the segmentation framework, also have been developed. In <ref type="bibr" target="#b22">[24]</ref>, a network predicts the probability that vertically neighboring pixels belong to the same lane. Then, through greedy iterations, trajectories of pixels are concatenated to form a full lane.  In <ref type="bibr" target="#b30">[32]</ref>, a three-branched network regresses polynomial coefficients of each lane and estimates its starting and ending points. In <ref type="bibr" target="#b23">[25]</ref>, for computational efficiency, a network selects the location of each lane on a predefined set of rows only. In <ref type="bibr" target="#b31">[33]</ref>, a unified network blends multi-scale features and combines prediction results at different levels. Qu et al. <ref type="bibr" target="#b24">[26]</ref> estimated multiple keypoints and associated them to reconstruct actual lanes. Meanwhile, an anchor-based detection framework was employed for lane detection <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b28">30]</ref>. These anchor-based techniques consider straight lines as lane candidates (or anchors) and generate a predefined set of candidates. Then, they classify and regress each candidate by estimating the lane probability and offset vectors. Despite providing promising results, they may fail to detect highly curved lanes. The proposed algorithm is also anchorbased but can deal with such complicated lanes successfully by employing eigenlane descriptors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Algorithm</head><p>We propose a novel algorithm to detect structurally diverse road lanes in the eigenlane space. <ref type="figure" target="#fig_1">Figure 2</ref> shows an overview of the proposed algorithm. First, the eigenlane space is constructed by performing the low-rank approximation of lanes in a training set. Second, lane candidates are generated by clustering lanes in the eigenlane space. Third, given an image, an optimal set of lanes are determined from the lane candidates by SIIC-Net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Eigenlanes -Formulation</head><p>SVD and principal component analysis (PCA) are used in various fields to represent data compactly <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b14">16]</ref>. A wellknown such application is face recognition using eigenfaces <ref type="bibr" target="#b29">[31]</ref>. Also, in this conference, eigencontours <ref type="bibr" target="#b21">[23]</ref> are proposed to describe object boundaries. In this paper, we use SVD to represent road lanes. Specifically, we adopt a datadriven approach and exploit the distribution of lanes in a training set, instead of employing parametric curves such as polynomials <ref type="bibr" target="#b27">[29]</ref> or splines <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b4">6]</ref>, to represent lanes.  is the x-coordinate of the ith sample and N is the number of samples. We construct a lane matrix A = [x 1 , x 2 , ? ? ? , x L ] from a training set containing L lanes. Then, we apply SVD to the lane matrix A by</p><formula xml:id="formula_0">A = U?V (1) where U = [u 1 , ? ? ? , u N ] and V = [v 1 , ? ? ? , v L ] are or- thogonal matrices and ? is a diagonal matrix, composed of singular values ? 1 ? ? 2 ? ? ? ? ? ? r &gt; 0. Here, r is the rank of A. It is known that A M = [x 1 , ? ? ? ,x L ] = ? 1 u 1 v 1 + ? ? ? + ? M u M v M (2)</formula><p>is the best rank-M approximation of A in that the Frobenius norm A ? A M F is minimized <ref type="bibr" target="#b2">[4]</ref>. Also, the sum of squared lane approximation errors is given by</p><formula xml:id="formula_1">A ? A M 2 F = L i=1 x i ?x i 2 = r i=M +1 ? 2 i . (3)</formula><p>In <ref type="formula">(2)</ref>, each approximate lanex i is given by a linear combination of the first M left singular vectors u 1 , ? ? ? , u M . In other words,x</p><formula xml:id="formula_2">i = U M c i = [u 1 , ? ? ? , u M ]c i .<label>(4)</label></formula><p>We refer to these u 1 , ? ? ? , u M as eigenlanes, because they are eigenvectors of AA . They can be regarded as principal components in PCA. However, strictly speaking, this is not PCA, since the mean lane is not removed in constructing A <ref type="bibr" target="#b14">[16]</ref>. We do not remove the mean (or center the data) because we are interested in the best low-rank approximation, instead of finding the best fitting subspace <ref type="bibr" target="#b2">[4]</ref>. We call the space spanned by {u 1 , ? ? ? , u M } as the eigenlane space. Given a lane x, we project it onto the eigenlane space to obtain the approximatio?</p><formula xml:id="formula_3">x = U M c<label>(5)</label></formula><p>where the coefficient vector c is given by</p><formula xml:id="formula_4">c = U M x.<label>(6)</label></formula><p>Algorithm 1 Lane candidate generation in eigenlane space Input: Set of training lanes {x 1 , x 2 , ? ? ? , x L }, M = # of eigenlanes, K = # of lane candidates 1: Construct the lane matrix A and perform SVD in (1) 2: Transform each lane x i to c i via (6) 3: Apply the K-means algorithm <ref type="bibr" target="#b6">[8]</ref> to {c 1 , c 2 , ? ? ? , c L } to obtain K centroids c 1 , ? ? ? , c K . 4: Generate the lane candidate l k = U M c k by inversely transforming each centroid c k via (5) Output: Set of lane candidates {l 1 , ? ? ? , l K } Thus, in the eigenlane space, a lane x is approximately represented by the M -dimensional vector c in <ref type="bibr" target="#b4">(6)</ref>. Also, the approximate x can be reconstructed from c via <ref type="bibr" target="#b3">(5)</ref>. Detection and regression in eigenlane space: Let {x 1 , . . . ,x L } be the set of training lanes, which are already approximated via <ref type="bibr" target="#b2">(4)</ref>. By clustering these lanes, we obtain a finite number of lane candidates (or anchors) for lane detection. However, instead of the original lane space of dimension N , we perform the clustering in the eigenlane space of dimension M , as illustrated in <ref type="figure" target="#fig_3">Figure 3</ref>. This is possible because the transform U M is length-preserving;</p><formula xml:id="formula_5">x i ?x j = c i ? c j .<label>(7)</label></formula><p>Also, M &lt; N . The clustering in the lower-dimensional space is more effective and more efficient. Algorithm 1 summarizes the process of lane candidate generation. Suppose that a lane candidate l = U M c is detected. Then, we refine it to</p><formula xml:id="formula_6">l + ?l = U M (c + ?c),<label>(8)</label></formula><p>by finding an offset vector ?c using a regressor. This is also done in the eigenlane space, since ?l = ?c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Eigenlanes -Image examples</head><p>Eigenlanes in image space: In this example, we use the TuSimple dataset [1] to determine eigenlanes. Here, each lane is represented by a 50D vector, i.e. N = 50. Because u 1 achieves the best rank-1 approximation of these lanes, it is also slanted. By weighting u 1 , we can represent straight road lanes in an image. Next, u 2 is slightly curved at the top side (far from the cameras), and u 3 is curvier. These eigenlanes are required to represent simply curved lanes. Finally, u 4 has an inflection point and is used to describe highly complicated lanes.</p><p>In <ref type="figure">Figure 4</ref>(b), the straight line parts of the left and middle lanes are slanted to the right, whereas u 1 is slanted to   the left. Thus, the coefficients for u 1 for these two lanes are negative. For all lanes, the coefficients for u 2 and u 3 are not negligible because the lanes are curved. They are, however, not complicated, so their 4th coefficients are insignificant.</p><p>Rank-M approximation: <ref type="figure">Figure 5</ref> shows examples of original lanes and their rank-M approximations. In (b), using only one eigenlane u 1 , the rank-1 approximation yields line parts of the lanes. In (c), the rank-2 approximation reconstructs curved parts additionally. To represent the curved parts more faithfully, the rank-3 approximation in (d) is required, which matches well the ground-truth in (a).</p><p>Lane candidates: As mentioned previously, we generate lane candidates for detection, by grouping training lanes in the eigenlane space using the K-means algorithm. <ref type="figure">Figure 6</ref> shows such generated candidates according to K. Being the centroids, they are representative of all training lanes. Notice that the proposed SDLane dataset contains many curved lanes with high curvatures, whereas the existing CULane dataset <ref type="bibr" target="#b20">[22]</ref> consists of mainly straight lanes. TuSimple contains curved lanes, which, however, lack diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">SIIC-Net</head><p>Using the K lane candidates {l 1 , ? ? ? , l K }, the proposed SIIC-Net detects road lanes. In <ref type="figure" target="#fig_7">Figure 7</ref>, SIIC-Net consists of the encoder-decoder part, SI module, and IC module. After the SI module, the non-maximum suppression (NMS) is performed to filter out redundant candidates. Also, after the IC module, the maximum weight clique selection (MWCS) is done to determine an optimal set of lanes.</p><p>Encoder-decoder part: We adopt ResNet50 <ref type="bibr" target="#b7">[9]</ref> as the en- <ref type="figure">Figure 6</ref>. Lane candidates, generated by the K-means clustering, for the TuSimple [1], CULane <ref type="bibr" target="#b20">[22]</ref>, and SDLane datasets. In (d), only curved lanes are shown among 500 candidates. In CULane, there are only 8 curved lanes among those 500 candidates.</p><formula xml:id="formula_7">TuSimple CULane SDLane (a) K=4 (b) K=8 (c) K=16 (d) K=500</formula><p>coder to extract features and employ the auxiliary branch <ref type="bibr" target="#b23">[25]</ref> as the decoder to yield a binary segmentation map of lanes. From an image, we extract multi-scale feature maps and aggregate the three lowest-level maps. To this end, we match the resolutions of the two smaller maps to the finest one via bilinear interpolation. Let X a = [X 1 a , X 2 a , . . . , X C1 a ] ? R H?W ?C1 be the aggregated feature map, where H, W , and C 1 are the feature height, the feature width, and the number of channels. Then, we squeeze X a using convolutional layers to yield X s ? R H?W ?C2 . The decoder processes X s to produce the segmentation map. We use the decoder part in the training phase only, as in <ref type="bibr" target="#b23">[25]</ref>. Self-lane identification (SI) module: For each lane candidate l k , we estimate the lane probability, the positional offset, and the height of the topmost point using the SI module, the structure of which is in <ref type="figure" target="#fig_8">Figure 8(a)</ref>. The SI module employs a line pooling layer <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b15">17]</ref>. From the squeezed feature map X s , it obtains the lane feature map</p><formula xml:id="formula_8">Y s = [Y 1 s , Y 2 s , . . . , Y C2 s ] ? R K?C2 by averaging the fea- tures of pixels along l k ; Y c s (k) = 1 |l k | p?l k X c s (p)<label>(9)</label></formula><p>for 1 ? k ? K and 1 ? c ? C 2 , where |l k | denotes the number of pixels in l k . Then, two probability vectors and a lane offset matrix are obtained by</p><formula xml:id="formula_9">P = ?(f 1 (Y )), H = ?(f 2 (Y )), O = f 3 (Y )<label>(10)</label></formula><p>where f 1 and f 2 are fully-connected layers of sizes C 2 ? 2 and C 2 ?R for classification, f 3 is a fully-connected layer of size C 2 ?M for regression, and ?(?) is the softmax function. For lane candidate l k , P k informs the probabilities that it is a lane or not, H k represents the probabilities that its ending point is located at one of R pre-defined heights, and O k = ?c k is an offset vector in (8) for lane refinement. NMS: Many redundant lanes tend to be detected around an actual one. We filter out those overlapping ones through  an NMS process after the SI module. We select the most reliable lane l i by i = arg max i P i .</p><p>Then, we remove overlapping lanes, whose the intersection over union (IoU) ratios with the selected lane are higher than a threshold. We perform this process T times to select the T reliable lanes. The default T is 10. Note that we focus on reducing false negatives, rather than false positives. <ref type="figure" target="#fig_9">Figure 9</ref>(b) shows 10 selected lanes after the NMS process.</p><p>Inter-lane correlation (IC) module: In general, adjacent lanes are equally distanced in road environments. Also, under the perspective projection, lanes intersect at a vanishing point in a 2D image. Because of these structural constraints, lanes are highly correlated with one another. To exploit this correlation, we design the IC module, which estimates the relation score between every pair of selected lanes. <ref type="figure" target="#fig_8">Figure 8(b)</ref> shows the structure of the IC module. Given the aggregated feature map X a , IC yields a lane feature map Y a similarly to <ref type="bibr" target="#b7">(9)</ref>. Y a is a T ? C 1 matrix, in which each row contains the C 1 -dimensional feature vector for a selected lane. Then, it obtains the relation matrix </p><formula xml:id="formula_11">R = ? 1 (Y a ) ? ? 2 (Y a )<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MWCS:</head><p>We determine an optimal set of lanes by employing MWCS <ref type="bibr" target="#b12">[14]</ref>, which is a graph optimization technique. We first construct a complete graph G = (V, E). . Let ? denote a clique, represented by the index set of member nodes. We define the compatibility E compatible (?) of clique ? as</p><formula xml:id="formula_12">E compatible (?) = i?? j??,j&gt;i w(v i , v j ).<label>(13)</label></formula><p>We then select the maximal weight clique ? by</p><formula xml:id="formula_13">? = arg max ? E compatible (?)<label>(14)</label></formula><p>subject to a constraint w(v i , v j ) &gt; ? for all edges in the clique, where ? is a threshold. If there is no clique satisfying the constraint, we select the maximal single-node clique ? = {i }, where i = arg max i P vi .</p><p>Next, we refine each lane in the optimal clique ? by U(c vi +?c vi ), where ?c vi is the offset vector in the eigenlane space, predicted by the SI module. Moreover, we refine the vertical height of each lane, by removing sampled points whose y-coordinates are bigger than H vi . <ref type="figure" target="#fig_9">Figure 9</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>TuSimple [1]: It consists of 6,408 images only, which are split into 3,268 training, 358 validation, and 2,782 test images. For each image, lanes are annotated by the 2D coordinates of sampling points with a uniform height interval of 10 pixels. It contains both straight and curved lanes, whose shapes are, however, simple and similar to one another. CULane <ref type="bibr" target="#b20">[22]</ref>: It is a rich dataset with about 130K images. Its 34,680 test images are classified into 9 categories. In some categories, lanes are highly implied or even invisible. For each image, pixel-wise masks for up to 4 road lanes are provided. Most lanes are straight lines. SDLane: We construct a structurally diverse lane dataset SDLane. It contains highly curved and complicated lanes, as illustrated in <ref type="figure" target="#fig_0">Figure 10</ref>. We collect 43K images, which are split into about 39K training and 4K testing images, and annotate the actual lanes manually. As mentioned in Section 3.2 and <ref type="figure">Figure 6</ref>, SDLane contains more curved lanes than CULane and more diverse lanes than TuSimple. The structural diversity of SDLane is discussed in detail in the supplemental document (Section B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation metrics</head><p>In TuSimple, a lane point is regarded as correctly located if its distance to the ground-truth point is shorter than a threshold [1]. Then, the accuracy is defined as Nc N , where N is the number of ground-truth lane points, and N c is the number of correctly predicted lane points. Also, the false positive rate (FPR) and the false negative rate (FNR) are</p><formula xml:id="formula_14">FPR = F pred N pred , FNR = M pred Ngt<label>(15)</label></formula><p>where F pred is the number of incorrectly predicted lanes, N pred is that of predicted lanes, M pred is that of missed lanes, and N gt is that of ground-truth lanes. In CULane and SDLane, each lane is regarded as a thin stripe with 30 pixel width <ref type="bibr" target="#b20">[22]</ref>. A predicted lane is declared to be correct if its IoU ratio with the ground-truth is greater than 0.5. The precision and the recall are computed by Accuracy FPR FNR LaneNet <ref type="bibr" target="#b19">[21]</ref> 96.38 0.0780 0.0244 SCNN <ref type="bibr" target="#b20">[22]</ref> 96.53 0.0617 0.0180 SAD <ref type="bibr" target="#b11">[13]</ref> 96.64 0.0602 0.0205 UFast <ref type="bibr" target="#b23">[25]</ref> 95.82 0.1905 0.0392 RESA <ref type="bibr" target="#b32">[34]</ref> 96.82 0.0363 0.0248 LaneATT <ref type="bibr" target="#b28">[30]</ref> 95.63 0.0353 0.0292 Proposed 95.62 0.0320 0.0399 where TP is the number of correctly detected lanes, FP is that of false positives, and FN is that of false negatives. Then, the F-measure is computed by</p><formula xml:id="formula_15">Precision = TP TP+FP , Recall = TP TP+FN<label>(16)</label></formula><formula xml:id="formula_16">F-measure = 2?Precision?Recall Precision+Recall .<label>(17)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparative assessment</head><p>Comparison on TuSimple: <ref type="table" target="#tab_2">Table 1</ref> compares the proposed algorithm with the conventional road lane detectors <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b23">25]</ref> on TuSimple. The proposed algorithm yields a high FNR, resulting in a relatively low accuracy, but provides the best FPR performance. <ref type="figure" target="#fig_0">Figure 11</ref> shows some detection results. Most errors are caused by the lanes, which are far from the camera and thus short. Except for them, the proposed algorithm detects most lanes precisely, especially ego and alternative lanes, which are more important for driving. Comparison on CULane:    <ref type="figure" target="#fig_0">Figure 12</ref> shows some detection results in challenging scenarios. Although the lanes are extremely ambiguous, the proposed algorithm detects them reliably by exploiting the structural properties between the adjacent ones. Comparison on SDLane: It is challenging to detect highly curved lanes in the anchor-based detection framework, but the proposed algorithm provides excellent results on such curved lanes. To demonstrate this, on SDLane, we compare the proposed algorithm with the state-of-the-art techniques <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b32">34]</ref>. LaneATT <ref type="bibr" target="#b28">[30]</ref> is an anchor-based method considering straight lines as anchors, while RESA <ref type="bibr" target="#b32">[34]</ref> is based on the semantic segmentation framework. Recently, Cond-LaneNet <ref type="bibr" target="#b17">[19]</ref> was proposed, which yields an F-measure of 79.48% on CULane. We train these methods on SDLane using the publicly available source codes.</p><p>In <ref type="table" target="#tab_5">Table 3</ref>, we see that the proposed algorithm is superior to the existing methods. LaneATT poorly recalls highly curved lanes, because straight anchors deviate too much from such lanes. Although RESA yields a higher recall rate, it does not detect invisible lanes reliably. Cond-LaneNet achieves the highest precision score, but its recall rate is still low. <ref type="figure" target="#fig_0">Figure 13</ref> compares some detection results. LaneATT detects straight or mildly curved lanes precisely, but it fails to detect more complicated lanes, even though those lanes are visible in the images. RESA detects such complicated lanes better than LaneATT does. However, for invisible or unobvious lanes, it does not preserve the continuous lane structure in detection results. In contrast, the proposed algorithm is capable of detecting both straight and curved lanes precisely, as well as processing implicit lanes reliably. This is because the proposed algorithm generates diverse lane candidates and then localizes lanes effectively in the eigenlane space. The proposed algorithm yields an F-measure of 80.47% on SDLane, which is significantly higher than that on the 'Curve' category in CULane in <ref type="table" target="#tab_3">Table 2</ref>. This means that, with sufficiently big data, the proposed algorithm can deal with curved lanes effectively. More results are presented in the supplemental document (Section C) and video.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation studies</head><p>We conduct ablation studies to analyze the efficacy of eigenlane projection and SIIC-Net components on the SD-Lane dataset. Also, we analyze the runtime for each component of SIIC-Net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Efficacy of eigenlane projection:</head><p>In the anchor-based detection framework, it is important to generate a set of candidates (anchors) reliably. <ref type="table">Table 4</ref> compares alternative methods for lane candidate generation. Method I (proposed) clusters 1,000 lane candidates in the eigenlane space of dimension M = 6, while II does 1,000 candidates in the original lane space of N = 50. III and IV, respectively, obtain 1,000 and 10,000 straight lines as done in <ref type="bibr" target="#b28">[30]</ref>. The mean intersection over union (mIoU) scores are reported. For each lane in test data, the closest candidate in terms of IoU is found. Then, the average of these matching IoU's is computed. Between I and II, the scores are similar. However, method I can refine lane candidates more efficiently Image LaneATT <ref type="bibr" target="#b28">[30]</ref> RESA <ref type="bibr" target="#b32">[34]</ref> Proposed Ground-truth <ref type="figure" target="#fig_0">Figure 13</ref>. Comparison of lane detection results on the SDLane dataset. using compact offset vectors (M &lt; N ). III yields poor results. By requiring 10 times more candidates, IV performs better than III does, but the gap with I is still high. This is because III and IV do not consider curved lanes. In contrast, the proposed notion of eigenlanes enables the systematic generation of curved lane candidates. Efficacy of components in SIIC-Net: <ref type="table">Table 5</ref> compares several ablated methods. Method I does not use regression offsets. In Method II, height classification results are not used. Method III uses the SI module and NMS only to detect road lanes. In Method III, we modify NMS as follows. First, we stop the iteration if the probability is lower than 0.5. Second, we optimize the threshold for removing redundant lanes empirically. Compared with the full SIIC-Net in IV, Method I degrades performances severely, indicating that SIIC-Net estimates regression offsets accurately to refine detected lines. Also, from II and IV, note that the height classification improves the performance by adjusting the ending points of lanes. Last, compared with IV, III still yields lower performances in terms of all metrics even with those modifications <ref type="table">Table 6</ref>. Analysis of running times of the proposed SIIC-Net. The processing times in seconds per frame are reported.</p><p>Encoding SI+NMS IC+MWCS Total 0.0036s 0.0042s 0.0021s 0.0099s of NMS. This means that the IC module with MWCS is required to detect lanes more precisely and more reliably. Runtime: <ref type="table">Table 6</ref> shows the runtime for each stage of SIIC-Net. SI+NMS takes the longest time among the three stages, for it should perform feature pooling for all lane candidates. After the NMS process, IC+MWCS considers significantly fewer lanes, so it demands the lowest computational cost. Overall, the processing speed is about 101 frames per second, which is sufficiently fast for practical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We proposed a novel algorithm to detect road lanes in the eigenlane space. First, we introduced the notion of eigenlanes, which are data-driven lane descriptors. Second, we generated a set of lane candidates by clustering training lanes in the eigenlane space. Third, we detected road lanes, by developing an anchor-based detection network SIIC-Net, from the lane candidates. Furthermore, we developed the structurally diverse dataset, containing highly curved and complicated lanes in real driving environments. Experimental results showed that the proposed algorithm provides excellent performances, especially on curved lanes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>There are two challenging factors in lane detection. First, in (a), lanes may be implicit due to adverse weather conditions or occlusion by nearby vehicles. Second, in (b), it is difficult to design lane anchors due to the structural diversity of lanes. The ground-truth lanes are shown in cyan within the insets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Overview of the proposed algorithm. It is recommended to watch the accompanying video of the proposed algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Definition of eigenlane space: A lane can be represented by 2D points sampled uniformly in the vertical direction. Specifically, let x = [x 1 , x 2 , . . . , x N ] be a lane, where x i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>(a) 1,000 training lanes sampled from the TuSimple dataset [1] are visualized in the 3D eigenlane space. (b) These lanes are clustered using the K-means algorithm with K = 16. Each cluster is in a different color, and the centroids are depicted by red triangles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 4(a) shows the four eigenlanes u 1 , u 2 , u 3 , u 4 , which are sufficient to represent all TuSimple lanes faithfully. The first eigenlane u 1 is a slanted line, instead of a vertical line. Most lanes are slanted from the viewpoint of a driving car.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 . 3 Figure 5 .</head><label>435</label><figDesc>(a) The first four eigenlanes u1, u2, u3, u4 for the TuSimple dataset. (b) Three example lanes are approximated by linear combinations of the four eigenlanes. (a) Original lanes (b) M = 1 (c) M = 2 (d) M = Rank-M approximation: original lanes in (a) are reconstructed by the first (b) one, (c) two, and (d) three eigenlanes, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>The architecture of the proposed SIIC-Net: Given an image, the encoder extracts two types of feature maps and the decoder yields a segmentation map. Then, the self-lane identification module (SI) and the inter-lane correlation (IC) module process the feature maps. After the SI module, NMS removes redundant lane candidates. After the IC module, MWCS determines an optimal set of lanes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>Block diagrams of the SI and IC modules.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 .</head><label>9</label><figDesc>of size T ? T . Here, ? 1 and ? 2 are feature transforms, implemented by convolution layers and the l 2 -normalization. Thus, each element of R is a score in [?1, 1], representing how compatible the corresponding pair of lanes are. An example of the lane detection by SIIC-Net: (a) input image, (b) 10 selected lanes after NMS, (c) optimal lanes determined by MWCS, and (d) refined lanes using the regression offsets from the SI module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>The node set V = {v 1 , v 2 , . . . , v T } represents the T selected lanes from NMS. Every pair of lanes are connected by an edge in the edge set E = {(v i , v j ) : i = j}. Each edge is assigned weight w(v i , v j ) = R(i,j)+R(j,i) 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>(c) and (d) show the MWCS results and their refined ones.The supplemental document (Section A) describes the training process and the architecture of SIIC-Net in detail.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 .</head><label>10</label><figDesc>Example images and ground-truth lanes in the SDLane dataset. Since crossroad images are included in SDLane, some lanes for left or right turns are highly curved and implicit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 11 .</head><label>11</label><figDesc>Detection results of the proposed algorithm on the TuSimple dataset. Detected lanes are depicted in green, while false negatives are in red.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 12 .</head><label>12</label><figDesc>Detection results of the proposed algorithm on five challenging categories in the CULane dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>SDLane is available at https://www.42dot.ai/akit/dataset.</figDesc><table><row><cell cols="4">Construction of eigenlane space</cell><cell>Lane candidate generation</cell></row><row><cell>?</cell><cell cols="3">Lane matrix construction</cell><cell>Eigenlane space</cell></row><row><cell></cell><cell></cell><cell>SVD</cell></row><row><cell></cell><cell cols="3">Low-rank approximation</cell></row><row><cell>Training set</cell><cell></cell><cell></cell><cell>Eigenlanes</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Clustering</cell></row><row><cell></cell><cell cols="2">SIIC-Net</cell><cell>Image space</cell></row><row><cell></cell><cell>SI module</cell><cell>NMS</cell></row><row><cell>Lane candidates</cell><cell></cell><cell>IC module</cell><cell>MWCS</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Straight</cell><cell>Curve</cell></row></table><note>1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Comparison on TuSimple. Only the algorithms with publicly available source codes are compared.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>compares the F-measure</cell></row><row><cell>performances on CULane, whose lanes are divided into 9</cell></row><row><cell>categories. The proposed algorithm outperforms all conven-</cell></row><row><cell>tional algorithms. Especially, the proposed algorithm yields</cell></row><row><cell>excellent results on the challenging categories of 'Night,'</cell></row><row><cell>'No line,' and 'Dazzle' in which lanes are highly implicit or</cell></row><row><cell>even invisible. This indicates that the proposed algorithm</cell></row><row><cell>can detect challenging lanes by considering the correlation</cell></row><row><cell>or compatibility among detected lanes. The performance</cell></row><row><cell>gap against LaneATT [30] is marginal. But, when the same</cell></row><row><cell>backbone of ResNet18 is used for both algorithms, the gap</cell></row><row><cell>increases further. On the 'Curve' category, the proposed al-</cell></row><row><cell>gorithm is inferior to the other methods. However, it does</cell></row><row><cell>not mean that the proposed algorithm is not capable of de-</cell></row><row><cell>tecting curved lanes. Since the proportion of curved lanes</cell></row><row><cell>is only 1.2%, the CULane training data are not enough</cell></row><row><cell>to generate curved lane candidates in the eigenlane space.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Comparison of the F-measure performances (%) on the CULane dataset, whose lanes are classified into 9 categories. For the 'Crossroad' category, only FP is reported. * means that the encoder backbone is ResNet18.</figDesc><table><row><cell>Category</cell><cell cols="2">Normal Crowded</cell><cell>Night</cell><cell>No line</cell><cell>Shadow</cell><cell>Arrow</cell><cell>Dazzle</cell><cell>Curve</cell><cell cols="2">Crossroad Total</cell></row><row><cell>SCNN [22]</cell><cell>90.6</cell><cell>69.7</cell><cell>66.1</cell><cell>43.4</cell><cell>66.9</cell><cell>84.1</cell><cell>58.5</cell><cell>65.7</cell><cell>1990</cell><cell>71.6</cell></row><row><cell>SAD [13]</cell><cell>90.7</cell><cell>70.0</cell><cell>66.3</cell><cell>43.5</cell><cell>67.0</cell><cell>84.4</cell><cell>59.9</cell><cell>65.7</cell><cell>2052</cell><cell>71.8</cell></row><row><cell>UFast [25]</cell><cell>90.7</cell><cell>70.2</cell><cell>66.7</cell><cell>44.4</cell><cell>69.3</cell><cell>85.7</cell><cell>59.5</cell><cell>69.7</cell><cell>2037</cell><cell>72.3</cell></row><row><cell>Curve-Nas [33]</cell><cell>90.7</cell><cell>72.3</cell><cell>68.9</cell><cell>49.4</cell><cell>70.1</cell><cell>85.8</cell><cell>67.7</cell><cell>68.4</cell><cell>1746</cell><cell>74.8</cell></row><row><cell>RESA [34]</cell><cell>92.1</cell><cell>73.1</cell><cell>69.9</cell><cell>47.7</cell><cell>72.8</cell><cell>88.3</cell><cell>69.2</cell><cell>70.3</cell><cell>1503</cell><cell>75.3</cell></row><row><cell>LaneATT* [30]</cell><cell>91.1</cell><cell>73.0</cell><cell>69.0</cell><cell>48.4</cell><cell>70.9</cell><cell>85.5</cell><cell>65.7</cell><cell>63.4</cell><cell>1170</cell><cell>75.1</cell></row><row><cell>LaneATT [30]</cell><cell>91.7</cell><cell>76.2</cell><cell>70.8</cell><cell>50.5</cell><cell>76.3</cell><cell>86.3</cell><cell>69.5</cell><cell>64.1</cell><cell>1264</cell><cell>77.0</cell></row><row><cell>Proposed*</cell><cell>91.5</cell><cell>74.8</cell><cell>71.4</cell><cell>51.1</cell><cell>72.3</cell><cell>87.7</cell><cell>69.7</cell><cell>62.0</cell><cell>1507</cell><cell>76.5</cell></row><row><cell>Proposed</cell><cell>91.7</cell><cell>76.0</cell><cell>71.8</cell><cell>52.2</cell><cell>74.1</cell><cell>87.7</cell><cell>69.8</cell><cell>62.9</cell><cell>1509</cell><cell>77.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Comparison on SDLane.</figDesc><table><row><cell></cell><cell>Precision</cell><cell>Recall</cell><cell>F-measure</cell></row><row><cell>LaneATT [30]</cell><cell>85.78</cell><cell>64.28</cell><cell>73.49</cell></row><row><cell>RESA [34]</cell><cell>82.35</cell><cell>72.46</cell><cell>77.09</cell></row><row><cell>CondLaneNet [19]</cell><cell>87.59</cell><cell>67.08</cell><cell>75.97</cell></row><row><cell>Proposed</cell><cell>86.04</cell><cell>75.58</cell><cell>80.47</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .Table 5 .</head><label>45</label><figDesc>Ablation studies for the proposed eigenlane projection on the SDLane dataset. mIoU scores are reported. Ablation studies for the components of SIIC-Net on the SDLane dataset.</figDesc><table><row><cell></cell><cell>I (proposed)</cell><cell>II</cell><cell>III</cell><cell>IV</cell></row><row><cell>mIoU</cell><cell>0.814</cell><cell>0.815</cell><cell>0.691</cell><cell>0.738</cell></row><row><cell></cell><cell></cell><cell>Precision</cell><cell>Recall</cell><cell>F-measure</cell></row><row><cell>I. w/o offsets</cell><cell></cell><cell>43.86</cell><cell>38.53</cell><cell>41.02</cell></row><row><cell>II. w/o heights</cell><cell></cell><cell>80.27</cell><cell>70.52</cell><cell>75.08</cell></row><row><cell>III. w/o IC+MWCS</cell><cell></cell><cell>82.98</cell><cell>74.82</cell><cell>78.69</cell></row><row><cell>IV. SIIC-Net</cell><cell></cell><cell>86.04</cell><cell>75.58</cell><cell>80.47</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real time detection of lane markers in urban streets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Aly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">An Introduction to Splines for Use in Computer Graphics and Geometric Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Bartels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">A</forename><surname>Beatty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Foundations of Data Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avrim</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravindran</forename><surname>Kannan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Embedding loss driven generative adversarial networks for lane detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Ghafoorian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cedric</forename><surname>Nugteren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N?ra</forename><surname>Baka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Booij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>El-Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV Workshops</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">B-spline curves and surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">F</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Riesenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Aided Geometric Design</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="126" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep Hough transform for semantic line detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV, 2020</title>
		<meeting>ECCV, 2020</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A K-means clustering algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hartigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series C (Applied Statistics)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="108" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Color-based road detection in urban traffic scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghua</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="309" to="318" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Recent progresss in road and lane detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aharon</forename><surname>Bar Hillel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronen</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Levi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Raz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Vis. Appl</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="727" to="745" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Inter-region affinity distillation for road marking segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuenan</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tak-Wai</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning lightweight lane detection CNNs by self attention distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuenan</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Harmonious semantic line detection via maximal weight clique selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongkwon</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonhui</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seong-Gyun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Su</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">CornerNet: Detecting objects as paired keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hei</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Linear Algebra and Its Applications. Pearson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">C</forename><surname>Lay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semantic line detection and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Tae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han-Ul</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chul</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Su</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Line-CNN: End-to-end traffic line detection with line proposal unit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="248" to="258" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cond-LaneNet: A top-to-down lane detection framework based on conditional convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">SSD: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Towards end-to-end lane detection: An instance segmentation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davy</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><forename type="middle">De</forename><surname>Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Spatial as deep: Spatial CNN for traffic scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Eigencontours: Novel contour descriptors based on low-rank approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonhui</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongkwon</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Su</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Addressing the long tail of lane detection by adapting a sequential prediction network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonah</forename><surname>Philion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fastdraw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ultra fast structureaware deep lane detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Focus on Local: Detecting lane marker from bottom up via key point</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhan</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Smoothing and differentiation of data by simplified least squares procedures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Savitzky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><forename type="middle">Je</forename><surname>Golay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analytical Chemistry</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1627" to="1639" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Keep your eyes on the lane: Real-time attention-guided lane detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Tabelini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Berriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thiago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudine</forename><surname>Paixao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto F De</forename><surname>Badue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thiago</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliveira-Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Face recognition using eigenfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">P</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Polynomial regression network for variable-number lane detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingke</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV, 2020</title>
		<meeting>ECCV, 2020</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">CurveLane-NAS: Unifying lanesensitive architecture search and adaptive point blending</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoju</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyue</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV, 2020</title>
		<meeting>ECCV, 2020</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">RESA: Recurrent feature-shift aggregator for lane detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A novel lane detection based on geometrical model and gabor filter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanhua</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqiang</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
