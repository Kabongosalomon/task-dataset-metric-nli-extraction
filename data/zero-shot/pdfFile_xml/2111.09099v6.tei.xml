<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolae-C?t?lin</forename><surname>Ristea</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University Politehnica of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">MBZ University of Artificial Intelligence</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neelu</forename><surname>Madan</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Aalborg University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><forename type="middle">Tudor</forename><surname>Ionescu</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<addrLine>5 SecurifAI</addrLine>
									<country>Romania, Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Nasrollahi</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Aalborg University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Milestone Systems</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">MBZ University of Artificial Intelligence</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Link?ping University</orgName>
								<address>
									<settlement>Sweden</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">B</forename><surname>Moeslund</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Aalborg University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<region>US</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T19:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Anomaly detection is commonly pursued as a one-class classification problem, where models can only learn from normal training samples, while being evaluated on both normal and abnormal test samples. Among the successful approaches for anomaly detection, a distinguished category of methods relies on predicting masked information (e.g. patches, future frames, etc.) and leveraging the reconstruction error with respect to the masked information as an abnormality score. Different from related methods, we propose to integrate the reconstruction-based functionality into a novel self-supervised predictive architectural building block. The proposed self-supervised block is generic and can easily be incorporated into various state-of-the-art anomaly detection methods. Our block starts with a convolutional layer with dilated filters, where the center area of the receptive field is masked. The resulting activation maps are passed through a channel attention module. Our block is equipped with a loss that minimizes the reconstruction error with respect to the masked area in the receptive field. We demonstrate the generality of our block by integrating it into several state-of-the-art frameworks for anomaly detection on image and video, providing empirical evidence that shows considerable performance improvements on MVTec AD, Avenue, and ShanghaiTech. We release our code as open source at: https://github.com/ ristea/sspcab.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Anomaly detection is an important task with a broad set of applications ranging from industrial inspection (finding defects of objects or materials on industrial production lines) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b75">76]</ref> to public security (detecting abnormal events such as traffic accidents, fights, explosions, etc.) <ref type="bibr">[12, 13, 17-19, 27, 28, 33, 39, 41, 47-50, 52, 67, 72, 73, 77, 78]</ref>. The task is typically framed as a one-class classification (outlier detection) problem, where methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b48">49</ref>-* corresponding author: raducu.ionescu@gmail.com <ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b81">82</ref>] learn a familiarity model from normal training samples, labeling unfamiliar examples (outliers) as anomalies, at inference time. Since abnormal samples are available only at test time, supervised learning methods are not directly applicable to anomaly detection. To this end, researchers turned their attention to other directions such as reconstruction-based approaches <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b70">71]</ref>, dictionary learning methods <ref type="bibr">[7-9, 14, 40, 55]</ref>, distance-based models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b69">70]</ref>, change detection frameworks <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b47">48]</ref>, and probabilistic models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b73">74]</ref>.</p><p>A distinguished subcategory of reconstruction methods relies on predicting masked information, leveraging the reconstruction error with respect to the masked information as an abnormality score. The masked information can come in different forms, e.g. superpixels <ref type="bibr" target="#b35">[36]</ref>, future frames <ref type="bibr" target="#b36">[37]</ref>, middle bounding boxes <ref type="bibr" target="#b16">[17]</ref>, among others. Methods in this subcategory mask some part of the input and employ a deep neural network to predict the missing input information. Different from such methods, we propose to integrate the capability of reconstructing the masked information into a neural block. Introducing the reconstruction task at a core architectural level has two important advantages: (i) it allows us to mask information at any layer in a neural network (not only at the input), and (ii) it can be integrated into a wide range of neural architectures, thus being very general.</p><p>We design our reconstruction block as a self-supervised predictive block formed of a dilated convolutional layer and a channel attention mechanism. The dilated filters are based on a custom receptive field, where the center area of the kernel is masked. The resulting convolutional activation maps are then passed through a channel attention module <ref type="bibr" target="#b23">[24]</ref>. The attention module ensures the block does not simply learn to reconstruct the masked region based on linearly interpolating contextual information. Our block is equipped with a loss that minimizes the reconstruction error between the final activation maps and the masked information. In other words, our block is trained to predict the masked information in a self-supervised manner. Our self-supervised  <ref type="figure">Figure 1</ref>. Our self-supervised predictive convolutional attentive block (SSPCAB). For each location where the dilated convolutional filter is applied, the block learns to reconstruct the masked area using contextual information. A channel attention module performs feature recalibration by using global information to selectively emphasize or suppress reconstruction maps. Best viewed in color. predictive convolutional attentive block (SSPCAB) is illustrated in <ref type="figure">Figure 1</ref>. For each location where the dilated convolutional filter is applied, the block learns to reconstruct the masked area using contextual information. Meanwhile, the dilation rate becomes a natural way to control the context level (from local to global), as required for the specific application.</p><p>We integrate SSPCAB into various state-of-the-art anomaly detection frameworks <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b78">79]</ref> and conduct comprehensive experiments on the MVTec AD <ref type="bibr" target="#b4">[5]</ref>, Avenue <ref type="bibr" target="#b39">[40]</ref> and ShanghaiTech <ref type="bibr" target="#b42">[43]</ref> data sets. Our empirical results show that SSPCAB can bring significant performance improvements, e.g. the region-based detection criterion (RBDC) of Liu et al. <ref type="bibr" target="#b38">[39]</ref> on Avenue increases from 41% to 62% by adding SSPCAB. Moreover, with the help of SSPCAB, we are able to report new state-of-the-art performance levels on Avenue and ShanghaiTech. Additionally, we show extra results on the Avenue data set, indicating that the masked convolutional layer can also increase performance levels, all by itself.</p><p>In summary, our contribution is twofold: ? We introduce a novel self-supervised predictive convolutional attentive block that is inherently capable of performing anomaly detection. ? We integrate the block into several state-of-the-art neural models <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b78">79]</ref> for anomaly detection, showing significant performance improvements across multiple models and benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>As anomalies are difficult to anticipate, methods are typically trained only on normal data, while being tested on both normal and abnormal data <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b48">49]</ref>. Therefore, outlier detection <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b52">53]</ref> and self-supervised learning <ref type="bibr">[17-19, 34, 39, 41, 49, 79]</ref> approaches are extensively used to address the anomaly detection task. Anomaly detection methods can be classified into: dictionary learning methods <ref type="bibr">[7-9, 14, 40, 55]</ref>, change detection frameworks <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b47">48]</ref>, probability-based methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b73">74]</ref>, distance-based models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b69">70]</ref>, and reconstruction-based methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b78">79]</ref>.</p><p>Dictionary-based methods learn the normal behavior by constructing a dictionary, where each entry in the dictionary represents a normal pattern. Ren et al. <ref type="bibr" target="#b54">[55]</ref> extended dictionary learning methods by considering the relation among different entries. Change-detection frameworks detect anomalies by quantifying changes across the video frames, i.e. a significant deviation from the immediately preceding event marks the beginning of an abnormal event. After quantifying the change, approaches such as unmasking <ref type="bibr" target="#b25">[26]</ref> or ordinal regression <ref type="bibr" target="#b47">[48]</ref> can be used to segregate anomalies. Probability-based methods build upon the assumption that anomalies occur in a low probability region. These methods estimate the probability density function (PDF) of the normal data and evaluate the test samples based on the PDF. For example, Mahadevan et al. <ref type="bibr" target="#b43">[44]</ref> used a Mixture of Dynamic Textures (MDTs) to model the distribution of the spatio-temporal domain, while Rudolph et al. <ref type="bibr" target="#b55">[56]</ref> employed normalizing flow to represent the normal distribution. Distance-based methods learn a distance function based on the assumption that normal events occur in the close vicinity of the learned feature space, while the abnormal events are far apart from the normal data. For instance, Ramachandra et al. <ref type="bibr" target="#b50">[51]</ref> employed a Siamese network to learn the distance function. Reconstruction-based methods rely on the assumption that the normal examples can be reconstructed more faithfully from the latent manifold. Our new block belongs to the category of reconstruction-based anomaly detection methods, particularly siding with meth-ods that predict or reconstruct missing (or masked) information <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>Reconstruction-based methods. In the past few years, reconstruction-based methods became prevalent in anomaly detection. Such methods typically use auto-encoders <ref type="bibr" target="#b20">[21]</ref> and generative adversarial networks (GANs) <ref type="bibr" target="#b36">[37]</ref>, as these neural models enable the learning of powerful reconstruction manifolds via using normal data only. However, the generalization capability of neural networks sometimes leads to reconstructing abnormal frames with low error <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18]</ref>, affecting the discrimination between abnormal and normal frames. To address this issue, researchers have tried to improve the latent manifold by diversifying the architecture and training methodologies. Some works focusing on transforming the architectures include memory-based autoencoders <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49]</ref>, which memorize the normal prototypes in the training data, thus increasing the discrimination between normal and abnormal samples. Other works remodeled the reconstruction manifold via training the models with pseudo-abnormal samples <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b78">79]</ref>. The adversarial training proposed in <ref type="bibr" target="#b16">[17]</ref> applies gradient ascent for outof-domain pseudo-abnormal samples and gradient descent for normal data, thus learning a more powerful discriminative manifold for video anomaly detection. Zavrtanik et al. <ref type="bibr" target="#b78">[79]</ref> created pseudo-abnormal samples by adding random noise patches on normal images for image anomaly detection. Some variants of auto-encoders, such as Variational Auto-Encoders (VAEs), have been proposed in <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b82">83]</ref> for the anomaly detection task. These works are based on the assumption that VAEs can only reconstruct the normal images. Liu et al. <ref type="bibr" target="#b38">[39]</ref> used a conditional VAE, conditioning the image prediction on optical flow reconstruction, thus accumulating the error from the optical flow reconstruction task with the image prediction. However, this approach can only be applied to video anomaly detection, due to the presence of motion information in the form of optical flow.</p><p>Reconstruction of masked information. A surrogate task for many anomaly detection approaches <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b76">77]</ref> is to erase some information from the input, while making neural networks predict the erased information. Haselmann et al. <ref type="bibr" target="#b21">[22]</ref> framed anomaly detection as an inpainting problem, where patches from images are masked randomly, using the pixel-wise reconstruction error of the masked patches for surface anomaly detection. Fei et al. <ref type="bibr" target="#b14">[15]</ref> proposed the Attribute Restoration Network (ARNet), which includes an attribute erasing module (AEM) to disorient the model by erasing certain attributes from an image, such as color and orientation. In turn, ARNet learns to restore the original image and detect anomalies based on the assumption that normal images can be restored properly. The Cloze task <ref type="bibr" target="#b41">[42]</ref> is about learning to complete a video when certain frames are removed, being recently employed by Yu et al. <ref type="bibr" target="#b76">[77]</ref> for anomaly detection. In a similar direc-tion, Georgescu et al. <ref type="bibr" target="#b16">[17]</ref> proposed middle frame masking as one of the auxiliary tasks for video anomaly detection. Both approaches are based on the assumption that an erased frame can be reconstructed more accurately for regular motion. Future frame prediction <ref type="bibr" target="#b33">[34]</ref> utilizes past frames to predict the next frame in the video. The anomaly, in this case, is detected through the prediction error. Another approach based on GANs <ref type="bibr" target="#b58">[59]</ref> learns to erase patches from an image, while the discriminator identifies if patches are normal or irregular.</p><p>Unlike existing approaches, we are the first to introduce the reconstruction-based functionality as a basic building block for neural architectures. More specifically, we design a novel block based on masked convolution and channel attention to reconstruct a masked part of the convolutional receptive field. As shown in the experiments, our block can be integrated into a multitude of existing anomaly detection frameworks <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b78">79]</ref>, almost always bringing significant performance improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>Convolutional neural networks (CNNs) <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref> are widely used across a broad spectrum of computer vision tasks, also being prevalent in anomaly detection <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49]</ref>. CNNs are formed of convolutional layers equipped with kernels which learn to activate on discriminative local patterns, in order to solve a desired task. The local features extracted by a convolutional layer are combined into more complex features by the subsequent convolutional layers. From this learning process, a hierarchy of features emerges, ranging from low-level features (corners, edges, etc.) to high-level features (car wheels, bird heads, etc.) <ref type="bibr" target="#b79">[80]</ref>. While this hierarchy of features is extremely powerful, CNNs lack the ability to comprehend the global arrangement of such local features, as noted by Sabour et al. <ref type="bibr" target="#b59">[60]</ref>.</p><p>In this paper, we introduce a novel self-supervised predictive convolutional attentive block (SSPCAB) that is purposed at learning to predict (or reconstruct) masked information using contextual information. To achieve highly accurate reconstruction results, our block is forced to learn the global structure of the discovered local patterns. Thus, it addresses the issue pointed out in <ref type="bibr" target="#b59">[60]</ref>, namely the fact that CNNs do not grasp the global arrangement of local features, as they do not generalize to novel viewpoints or affine transformations. To implement this behavior, we design our block as a convolutional layer with dilated masked filters, followed by a channel attention module. The block is equipped with its own loss function, which is aimed at minimizing the reconstruction error between the masked input and the predicted output.</p><p>We underline that our design is generic, as SSPCAB can be integrated into just about any CNN architecture, being able to learn to reconstruct masked information, while offer- ing useful features for subsequent neural layers. Although the capability of learning and using global structure might make SSPCAB useful for a wide range of tasks, we conjecture that our block has a natural and direct applicability in anomaly detection, as explained next. When integrated into a CNN trained on normal training data, SSPCAB will learn the global structure of normal examples only. When presented with an abnormal data sample at inference time, our block will likely provide a poor reconstruction. We can thus measure the quality of the reconstruction and employ the result as a way to differentiate between normal and abnormal examples. In Section 4, we provide empirical evidence to support our claims. SSPCAB is composed of a masked convolutional layer activated by Rectified Linear Units (ReLU) <ref type="bibr" target="#b45">[46]</ref>, followed by a Squeeze-and-Excitation (SE) module <ref type="bibr" target="#b23">[24]</ref>. We next present its components in more details. Masked convolution. The receptive field of our convolutional filter is depicted in <ref type="figure" target="#fig_1">Figure 2</ref>. The learnable parameters of our masked convolution are located in the corners of the receptive field, being denoted by the sub-kernels K i ? R k ?k ?c , ?i ? {1, 2, 3, 4}, where k ? N + is a hyperparameter defining the sub-kernel size and c is the number of input channels. Each kernel K i is located at a distance (dilation rate) d ? N + from the masked region in the center of our receptive field, which is denoted by M ? R 1?1?c . Consequently, the spatial size k of our receptive field can be computed as follows: k = 2k + 2d + 1.</p><p>Let X ? R h?w?c be the input tensor of our masked convolutional layer, where c is the number of channels, and h and w are the height and width, respectively. The convolutional operation performed with our custom kernel in a certain location of the input X only considers the input values from the positions where the sub-kernels K i are located, the other information being ignored. The results of the convolution operations between each K i and the corresponding inputs are summed into a single number, as if the sub-kernels K i belong to a single convolutional ker-nel. The resulting value denotes a prediction located at the same position as M . Naturally, applying the convolution with one filter produces a single activation map. Hence, we would only be able to predict one value from the masked vector M , at the current location. To predict a value for every channel in M , we introduce a number of c masked convolutional filters, each predicting the masked information from a distinct channel. As we aim to learn and predict the reconstruction for every spatial location of the input, we add zero-padding of k + d pixels around the input and set the stride to 1, such that every pixel in the input is used as masked information. Therefore, the spatial dimension of the output tensor Z is identical to that of the input tensor X. Finally, the output tensor is passed through a ReLU activation. We underline that the only configurable hyperparameters of our custom convolutional layer are k and d. Channel attention module. Next, the output of the masked convolution is processed by a channel attention module, which computes an attention score for each channel. Knowing that each activation map in Z is predicted by a separate filter in the presence of masked information, we infer that the masked convolution might end up producing activation maps containing disproportionate (uncalibrated) values across channels. Therefore, we aim to exploit the relationships between channels, with the goal of scaling each channel in Z in accordance with the quality of the representations produced by the masked convolutional layer. To this end, we employ the channel attention module proposed by Hu et al. <ref type="bibr" target="#b23">[24]</ref>. The SE module <ref type="bibr" target="#b23">[24]</ref> provides a mechanism that performs adaptive recalibration of channel-wise feature responses. Through this mechanism, it can learn to use global information to selectively emphasize or suppress reconstruction maps, as necessary. Another motivation to use attention is to increase the modeling capacity of SSP-CAB and enable a non-linear processing between the input and output of our block.</p><p>Formally, the channel attention block reduces Z to a vector z ? R c through a global pooling performed on each channel. Subsequently, the vector of scale factors s ? R c is computed as follows:</p><formula xml:id="formula_0">s = ? (W 2 ? ? (W 1 ? z)) ,<label>(1)</label></formula><p>where ? is the sigmoid activation, ? is the ReLU activation, and W 1 ? R c r ?c and W 2 ? R c? c r represent the weight matrices of two consecutive fully connected (FC) layers, respectively. The first FC layer consists of c r neurons, squeezing the information by a reduction ratio of r.</p><p>Next, the vector s is replicated in the spatial dimension, generating a tensor S of the same size as Z. Our last step is the element-wise multiplication between S and Z, producing the final tensorX ? R h?w?c containing recalibrated features maps. Reconstruction loss. We add a self-supervised task consist-ing of reconstructing the masked region inside our convolutional receptive field, for every location where the masked filters are applied. To this end, our block should learn to provide the corresponding reconstructions as the outputX. Let G denote the SSPCAB function. We define the selfsupervised reconstruction loss as the mean squared error (MSE) between the input and the output, as follows:</p><formula xml:id="formula_1">L SSPCAB (G, X) = (G(X) ? X) 2 = X ? X 2 .<label>(2)</label></formula><p>When integrating SSPCAB into a neural model F having its own loss function L F , our loss can simply be added to the respective loss, resulting in a new loss function that comprises both terms:</p><formula xml:id="formula_2">L total = L F + ? ? L SSPCAB ,<label>(3)</label></formula><p>where ? ? R + is a hyperparameter that controls the importance of our loss with respect to L F . We adopt this procedure when incorporating SSPCAB into various neural architectures during our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Sets</head><p>MVTec AD. The MVTec AD <ref type="bibr" target="#b4">[5]</ref> data set is a standard benchmark for evaluating anomaly detection methods on industrial inspection images. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation Metrics</head><p>Image anomaly detection. On MVTec AD, we evaluate methods in terms of the average precision (AP) and the area under the receiver operating characteristic curve (AUROC). The ROC curve is obtained by plotting the true positive rate (TPR) versus the false positive rate (FPR). We consider both localization and detection performance rates. For the detection task, the TPR and FPR values are computed at the image level, i.e. TPR is the percentage of anomalous images that are correctly classified, while FPR is the percentage of normal images mistakenly classified as anomalous.</p><p>For the localization (segmentation) task, TPR is the percentage of abnormal pixels that are correctly classified, whereas FPR is the percentage of normal pixels wrongly classified as anomalous. To determine the segmentation threshold for each method, we follow the approach described in <ref type="bibr" target="#b4">[5]</ref>. Video anomaly detection. We evaluate abnormal event detection methods in terms of the area under the curve (AUC), which is computed by marking a frame as abnormal if at least one pixel inside the frame is abnormal. Following <ref type="bibr" target="#b17">[18]</ref>, we report both the macro and micro AUC scores. The micro AUC is computed after concatenating all frames from the entire test set, while the macro AUC is the average of the AUC scores on individual videos. The frame-level AUC can be an unreliable evaluation measure, as it may fail to evaluate the localization of anomalies <ref type="bibr" target="#b49">[50]</ref>. Therefore, we also evaluate models in terms of the region-based detection criterion (RBDC) and track-based detection criterion (TBDC), as proposed by Ramachandra et al. <ref type="bibr" target="#b49">[50]</ref>. RBDC takes each detected region into consideration, marking a detected region as true positive if the Intersection-over-Union with the ground-truth region is greater than a threshold ?. TBDC measures whether abnormal regions are accurately tracked across time. It considers a detected track as true positive if the number of detections in a track is greater than a threshold ?. Following <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b49">50]</ref>, we set ? = 0.1 and ? = 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Implementation Choices and Tuning</head><p>For the methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b78">79]</ref> chosen to serve as underlying models for SSPCAB, we use the official code from the repositories provided by the corresponding authors, inheriting the hyperparameters, e.g. the number of epochs and learning rate, from each method. Unless specified otherwise, we replace the penultimate convolutional layer with SSPCAB in all underlying models.</p><p>In a set of preliminary trials with a basic auto-encoder on Avenue, we tuned the hyperparameter ? from Eq. (3), representing the weight of the SSPCAB reconstruction error, considering values between 0.1 and 1, at a step of 0.1. Based on these preliminary trials, we decided to use ? = 0.1 across all models and data sets. However, we observed that ? = 0.1 gives a higher than necessary magnitude to our loss for the framework of Liu et al. <ref type="bibr" target="#b38">[39]</ref>. Hence, for Liu et al. <ref type="bibr" target="#b38">[39]</ref>, we reduced ? to 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Preliminary Results</head><p>We performed preliminary experiments on Avenue to decide the hyperparameters of our masked convolution, i.e. the kernel size k and dilation rate d. We consider values in {1, 2, 3} for k , and values in {0, 1, 2} for d. In addition, we consider two alternative loss functions, namely the Mean Absolute Error (MAE) and Mean Squared Error (MSE), and several types of attention to be added after the masked convolution, namely channel attention (CA), spatial attention (SA), and both (CA+SA). For the preliminary experiments, we take the appearance convolutional auto-encoder from <ref type="bibr" target="#b17">[18]</ref> as our baseline, stripping out the additional components such as optical flow, skip connections, adversarial training, mask reconstruction and binary classifiers. Our aim is to test various SSPCAB configurations on top of a basic architecture, without trying to overfit the configuration to a specific framework, such as that of Georgescu et al. <ref type="bibr" target="#b17">[18]</ref>. To this end, we decided to remove the aforementioned components, thus using only a plain auto-encoder in our preliminary experiments.</p><p>The preliminary results are presented in <ref type="table" target="#tab_1">Table 1</ref>. Upon adding the masked convolutional layer based on the MAE loss on top of the basic architecture, we observe significant performance gains, especially for k = 1 and d = 1. The performance further increases when we replace the MAE loss function with MSE. We performed extensive experiments with different combinations of k and d, obtaining better results with k = 1 and d = 1. We therefore decided to fix the loss to MSE, the sub-kernel size k to 1, and the dilation rate d to 1, for all subsequent experiments. Next, we introduced various attention modules after our masked convolution. Among the considered attention modules, we observe that channel attention is the one that better compliments our masked convolutional layer, providing the highest performance gains for three of the metrics: 5.9% for the micro AUC, 2.2% for the macro AUC, and 4.6% for TBDC. Accordingly, we selected the channel attention module for the remaining experiments. Upon choosing to use channel attention, we test additional reduction rates (r = 4 and r = 16), without observing any improvements. As such, we keep the reduction rate of the SE module to r = 8, whenever we integrate SSPCAB into a neural model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Anomaly Detection in Images</head><p>Baselines. We choose two recent models for image anomaly detection, i.e. CutPaste <ref type="bibr" target="#b33">[34]</ref> and DRAEM <ref type="bibr" target="#b78">[79]</ref>.</p><p>Li et al. <ref type="bibr" target="#b33">[34]</ref> proposed CutPaste, a simple data augmentation technique that cuts a patch from an image and pastes it to a random location. The CutPaste architecture is built on top of GradCAM <ref type="bibr" target="#b63">[64]</ref>. The model is based on a selfsupervised 3-way classification task, learning to classify samples into normal, CutPaste and CutPaste-Scar, where a scar is a long and thin mark of a random color. Li et al. <ref type="bibr" target="#b33">[34]</ref> also used an ensemble of five 3-way CutPaste models trained with different random seeds to improve results.</p><p>Zavrtanik et al. <ref type="bibr" target="#b78">[79]</ref> introduced DRAEM, a method based on a dual auto-encoder for anomaly detection and localization on MVTec AD. We introduce SSPCAB into both the localization and detection networks. Results. We present the results on MVTec AD in <ref type="table">Table 2</ref>. Considering the detection results, we observe that SSPCAB brings consistent performance improvements on most categories for both CutPaste <ref type="bibr" target="#b33">[34]</ref> and DRAEM <ref type="bibr" target="#b78">[79]</ref>. Moreover, the overall performance gains in terms of detection AUROC are close to 1%, regardless of the underlying model. Given that the baselines are already very good, we consider the improvements brought by SSPCAB as noteworthy.</p><p>Considering the localization results, it seems that SSP-CAB is not able to improve the overall AUROC score of DRAEM <ref type="bibr" target="#b78">[79]</ref>. However, the more challenging AP metric tells a different story. Indeed, SSPCAB increases the overall AP of DRAEM [79] by 1.5%, from 68.4% to 69.9%.</p><p>In <ref type="figure" target="#fig_2">Figure 3</ref>, we illustrate a few anomaly localization examples where SSPCAB introduces significant changes to the anomaly localization contours of DRAEM <ref type="bibr" target="#b78">[79]</ref>, showing a higher overlap with the ground-truth anomalies. We believe that these improvements are a direct effect induced  <ref type="table">Table 2</ref>. Localization AUROC/AP and detection AUROC (in %) of state-of-the-art methods on MVTec AD, before and after adding SSPCAB. The best result for each before-versus-after pair is highlighted in bold. by the reconstruction errors produced by our novel block. We provide more anomaly detection examples in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Abnormal Event Detection in Video</head><p>Baselines. We choose four recently introduced methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49]</ref> attaining state-of-the-art performance levels in video anomaly detection, as candidates for integrating SSPCAB. We first reproduce the results using the official implementations provided by the corresponding authors <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49]</ref>. We refrain from making any modifi-cation to the hyperparameters of the chosen baselines. Despite using the unmodified code from the official repositories, we were not able to exactly reproduce the results of Liu et al. <ref type="bibr" target="#b38">[39]</ref> and Park et al. <ref type="bibr" target="#b48">[49]</ref>, but our numbers are very close. As we add SSPCAB into the reproduced models, we consider the reproduced results as reference. We underline that, for Georgescu et al. <ref type="bibr" target="#b17">[18]</ref>, we integrate SSPCAB into the auto-encoders, not in the binary classifiers. We report RBDC and TBDC results whenever possible, computing the scores using the implementation provided by Georgescu et al. <ref type="bibr" target="#b17">[18]</ref>.</p><p>Results. We report the results on Avenue and ShanghaiTech in <ref type="table">Table 3</ref>. First, we observe that the inclusion of SSPCAB in the framework of Liu et al. <ref type="bibr" target="#b36">[37]</ref> brings consistent improvements over all metrics on both benchmarks. Similarly, we observe consistent performance gains when integrating SSPCAB into the model of Park et al. <ref type="bibr" target="#b48">[49]</ref>. We note that the method of Park et al. <ref type="bibr" target="#b48">[49]</ref> does not produce anomaly localization results, preventing us from computing the RBDC and TBDC scores for their method. SSPCAB also brings consistent improvements for Liu et al. <ref type="bibr" target="#b38">[39]</ref>, the only exception being the macro AUC on Avenue. For this baseline <ref type="bibr" target="#b38">[39]</ref>, we observe a remarkable increase of 21.22% in terms of the RBDC score on Avenue. Finally, we notice that SSPCAB also improves the performance of the approach proposed by Georgescu et al. <ref type="bibr" target="#b17">[18]</ref> for almost all metrics, the exceptions being the TBDC on Avenue and RBDC on ShanghaiTech. In summary, we conclude that integrating SSPCAB is beneficial, regardless of the underlying model. Moreover, due to the integration of SSPCAB, we are able  <ref type="table">Table 3</ref>. Micro-averaged frame-level AUC, macro-averaged frame-level AUC, RBDC, and TBDC scores (in %) of various state-of-the-art methods on Avenue and ShanghaiTech. Among the existing models, we select four models <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49]</ref> to show results before and after including SSPCAB. The best result for each before-versus-after pair is highlighted in bold. The top score for each metric is shown in red.</p><p>to report new state-of-the-art results on Avenue and Shang-haiTech, for several metrics. In <ref type="figure" target="#fig_3">Figure 4</ref>, we compare the frame-level anomaly scores on test video 18 from Avenue, before and after integrating SSPCAB into the method of Liu et al. <ref type="bibr" target="#b36">[37]</ref>. On this video, SSPCAB increases the AUC by more than 5%. We observe that the approach based on SSPCAB can precisely localize and detect the abnormal event (person walking in the wrong direction). We provide more anomaly detection examples in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we introduced SSPCAB, a novel neural block composed of a masked convolutional layer and a channel attention module, which predicts a masked region in the convolutional receptive field. Our neural block is trained in a self-supervised manner, via a reconstruction loss of its own. To show the benefit of using SSP-CAB in anomaly detection, we integrated our block into a series of image and video anomaly detection methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b78">79]</ref>. Our empirical results indicate that SSPCAB brings performance improvements in almost all cases. The preliminary results show that both the masked convolution and the channel attention contribute to the performance gains. Furthermore, with the help of SSPCAB, we are able to obtain new state-of-the-art levels on Avenue and ShanghaiTech. We consider this as a major achievement.</p><p>In future work, we aim to extend SSPCAB by replacing the masked convolution with a masked 3D convolution. In addition, we aim to consider other application domains besides anomaly detection. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Supplementary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Ablation Study</head><p>In the main article, we mention that we generally replace the penultimate convolutional layer with SSPCAB in underlying models <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b78">79]</ref>. Ideally, for optimal performance gains, the integration place and the number of SSPCAB modules should be tuned on a validation set for each framework. However, anomaly detection data sets do not have a validation set and there is no way to obtain one from the training set, as the training contains only normal examples. In this context, to fairly demonstrate the generality and utility of SSPCAB, we only used a single configuration (one block, closer to the output) across all existing frameworks. However, adding more modules could be beneficial. To test various configurations, we perform an ablation study on the number of SSPCAB modules and the places where these modules can be integrated in a plain auto-encoder. In <ref type="table">Table 4</ref>, we present the corresponding experiments on the Avenue data set. We observe that SSPCAB improves the results, regardless of the place of integration or the number of blocks. The improvements seem larger when SSPCAB is integrated closer to the output. Integrating more blocks can sometimes help.</p><p>Another hyperparameter that could be tuned is the size of the masked kernel M . In our experiments, we kept M to a size of 1 ? 1 for simplicity and speed. To study the effect of increasing the size of M , we have tested the size of 3 ? 3 with the plain auto-encoder on Avenue. We report the corresponding results in <ref type="table" target="#tab_4">Table 5</ref>. When comparing the results with masked kernels of 1 ? 1 or 3 ? 3 components, we do not observe significant differences.</p><p>An additional aspect that can suffer multiple reconfigurations, given a validation set, is the pattern of the proposed kernel. In our experiments, we tried a simple pattern where the mask is placed in the center and the reception field is connected to the four corner sub-kernels denoted by K i , ?i ? {1, 2, 3, 4}. We designed this pattern while trying to extrapolate the idea from middle frame prediction (which was shown to provide somewhat better results than future frame prediction) to a 2D kernel. Of course, other patterns are possible and are likely to work equally well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Qualitative Anomaly Detection Results</head><p>Anomaly detection in images. In <ref type="figure" target="#fig_4">Figure 5</ref>, we present additional qualitative results produced by DRAEM <ref type="bibr" target="#b78">[79]</ref> on the MVTec AD benchmark. The displayed examples illustrate the benefit of integrating SSPCAB, which is much better at segmenting the anomalies compared to the baseline DRAEM. We show improvements in terms of the pixellevel annotation for both objects and textures. Anomaly detection in videos. In <ref type="figure" target="#fig_5">Figure 6</ref>, we show a com-  parison of the frame-level anomaly scores on test video 10 from the Avenue data set, before and after integrating SSP-CAB into the method of Liu et al. <ref type="bibr" target="#b36">[37]</ref>. On this video, SSP-CAB increases the AUC by nearly 4%. After introducing SSPCAB, we observe higher frame-level anomaly scores for the first abnormal event. The anomaly localization results depict a person throwing a backpack and a person walking in the wrong direction.</p><p>In <ref type="figure" target="#fig_6">Figures 7 and 8</ref>, we illustrate similar comparisons for test videos 01 0054 and 01 0130 from the ShanghaiTech  data set, before and after adding SSPCAB into the framework of Georgescu et al. <ref type="bibr" target="#b17">[18]</ref>. For test video 01 0054, SSP-CAB increases the AUC by more than 10%. For test video 01 0130, the baseline framework seems to detect the abnormal event too early, but SSPCAB seems capable of shifting the detection towards the correct moment. As a result, SSP-CAB increases the frame-level AUC score by almost 6%. We observe a similar AUC improvement from SSPCAB in <ref type="figure" target="#fig_8">Figure 9</ref>, where we compare the frame-level anomaly scores on test video 07 0047 from the ShanghaiTech data set. For</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Time (ms)</head><p>Relative (%) Baseline +SSPCAB Liu et al. <ref type="bibr" target="#b36">[37]</ref> 2.1 2.4 14.2 Georgescu et al. <ref type="bibr" target="#b17">[18]</ref> 1.5 1.7 13.3 <ref type="table">Table 6</ref>. Inference times (in milliseconds) and relative time expansions (in %) for two frameworks <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b36">37]</ref>, before and after integrating SSPCAB. The running times are measured on an Nvidia GeForce GTX 3090 GPU with 24 GB of VRAM.</p><p>this video, we underline that the frame-level scores are visibly more correlated to the ground-truth anomalies. Moreover, in all three ShanghaiTech videos, we observe that the approach based on SSPCAB can precisely localize and detect the abnormal events (person pulling a lever cart, car inside pedestrian area, people fighting, people running).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Inference Time</head><p>Regardless of the underlying framework <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b78">79]</ref>, we add only one instance of SSPCAB, usually replacing the penultimate convolutional layer. As such, we expect the running time to increase. To assess the amount of extra time added by SSPCAB, we present the running times before and after integrating SSPCAB into two state-of-theart frameworks <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b36">37]</ref> in <ref type="table">Table 6</ref>. The reported times show time expansions lower than 0.3 ms for both frameworks. Hence, we consider that the accuracy gains brought by SSP-CAB outweigh the marginal running time expansions observed in <ref type="table">Table 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Discussion</head><p>Although SSPCAB belongs to an existing family of anomaly detection methods, i.e. reconstruction-based frameworks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b70">71]</ref>, we would like to underline that we are the first to integrate the reconstruction functionality at the block level. Unlike other reconstruction approaches, our contribution is more flexible, as it can be integrated in existing and future reconstruction methods. Moreover, SSPCAB can also be used to introduce reconstruction-based anomaly detection in other frameworks, which do not rely on reconstruction. We thus believe that our generic and effective approach will help ease future research in anomaly detection.</p><p>An important aspect that must be noted is that, due to the masked convolution, our block will not reconstruct the input exactly. Except for the degenerate case where the input is constant, this scenario should not occur in the real world, which means that the reconstruction performed by SSPCAB is not trivial. However, our foremost intuition about the usefulness of SSPCAB is different: our block provides a better reconstruction for normal convolutional features than for abnormal convolutional features. If the features representing normal versus abnormal examples are different at any layer of a neural architecture, it should result in greater differences at the final output of the architecture. This idea is also supported by the experiments presented in <ref type="table">Table 4</ref>.</p><p>Further looking at the results shown in <ref type="table">Table 4</ref>, we observe that SSPCAB does not bring significant gains when the block is placed near the input. We aim to further investigate this limitation in future work. Aside from this small issue, we did not observe other limitations of SSPCAB during our experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Our masked convolutional kernel. The visible area of the receptive field is denoted by the regions Ki, ?i ? {1, 2, 3, 4}, while the masked area is denoted by M . A dilation factor d controls the local or global nature of the visible information with respect to M . Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Anomaly localization examples of DRAEM<ref type="bibr" target="#b78">[79]</ref> (blue) versus DRAEM+SSPCAB (green) on MVTec AD. The groundtruth anomalies are marked with a red mask. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Frame-level anomaly scores for Liu et al. [37] before (baseline) and after (ours) integrating SSPCAB, for test video 18 from Avenue. Anomaly localization results correspond to the model based on SSPCAB. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Additional anomaly localization examples of DRAEM [79] (blue) versus DRAEM+SSPCAB (green) on MVTec AD. The ground-truth anomalies are marked with a red mask. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Frame-level anomaly scores for Liu et al. [37] before (baseline) and after (ours) integrating SSPCAB, for test video 10 from Avenue. Anomaly localization results correspond to the model based on SSPCAB. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Frame-level anomaly scores for Georgescu et al.<ref type="bibr" target="#b17">[18]</ref> before (baseline) and after (ours) integrating SSPCAB, for test video 01 0054 from ShanghaiTech. Anomaly localization results correspond to the model based on SSPCAB. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Frame-level anomaly scores for Georgescu et al. [18] before (baseline) and after (ours) integrating SSPCAB, for test video 01 0130 from ShanghaiTech. Anomaly localization results correspond to the model based on SSPCAB. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Frame-level anomaly scores for Georgescu et al.<ref type="bibr" target="#b17">[18]</ref> before (baseline) and after (ours) integrating SSPCAB, for test video 07 0047 from ShanghaiTech. Anomaly localization results correspond to the model based on SSPCAB. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>Method</cell><cell cols="2">Loss d k r type</cell><cell>Attention type</cell><cell>AUC Micro Macro</cell><cell>RBDC TBDC</cell></row><row><cell></cell><cell>-</cell><cell>---</cell><cell>-</cell><cell cols="2">80.0 83.4 49.98 51.69</cell></row><row><cell></cell><cell></cell><cell>0 1 -</cell><cell>-</cell><cell cols="2">83.3 84.1 47.46 52.11</cell></row><row><cell></cell><cell>MAE</cell><cell>1 1 -</cell><cell>-</cell><cell cols="2">83.9 84.6 49.05 52.21</cell></row><row><cell></cell><cell></cell><cell>2 1 -</cell><cell>-</cell><cell cols="2">83.2 84.3 48.56 52.03</cell></row><row><cell></cell><cell></cell><cell>0 1 -</cell><cell>-</cell><cell cols="2">83.6 84.2 47.86 52.21</cell></row><row><cell></cell><cell>MSE</cell><cell>1 1 -</cell><cell>-</cell><cell cols="2">84.2 84.9 49.22 52.29</cell></row><row><cell>Plain auto-encoder</cell><cell>MSE MSE</cell><cell>2 1 -0 2 -1 2 -2 2 -0 3 -1 3 -2 3 -</cell><cell>-------</cell><cell cols="2">83.6 84.3 48.44 51.98 83.7 84.0 47.41 53.02 84.0 85.1 48.22 51.84 82.7 83.1 46.94 50.22 82.6 83.7 48.28 51.91 82.9 84.7 48.13 52.07 83.1 83.8 47.13 49.96</cell></row><row><cell></cell><cell></cell><cell>1 1 8</cell><cell>CA</cell><cell cols="2">85.9 85.6 53.81 56.33</cell></row><row><cell></cell><cell>MSE</cell><cell>1 1 -</cell><cell>SA</cell><cell cols="2">84.3 84.4 53.31 53.41</cell></row><row><cell></cell><cell></cell><cell cols="4">1 1 8 CA+SA 85.7 85.6 53.98 54.11</cell></row><row><cell></cell><cell>MSE</cell><cell>1 1 4 1 1 16</cell><cell>CA CA</cell><cell cols="2">85.6 85.3 53.83 55.99 84.4 84.9 53.28 54.37</cell></row></table><note>. Micro AUC, macro AUC, RBDC and TBDC scores (in %) obtained on the Avenue data set with different hyperparameter configurations, i.e. kernel size (k ), dilation rate (d), reduction ra- tio (r), loss type, and attention type, for our SSPCAB. Results are obtained by introducing SSPCAB into a plain auto-encoder that follows the basic architecture designed by Georgescu et al. [18]. Best results are highlighted in bold.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>93.5 41.05 86.18 74.2 83.2 44.41 83.86 CVPR 2022 Liu et al. [39] + SSPCAB 90.9 92.2 62.27 89.28 75.5 83.7 45.45 84.50 TPAMI 2021 Georgescu et al. [18] 92.3 90.4 65.05 66.85 82.7 89.3 41.34 78.79 CVPR 2022 Georgescu et al. [18] + SSPCAB 92.9 91.9 65.99 64.91 83.6 89.5 40.55 83.46</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Avenue</cell><cell></cell><cell></cell><cell cols="2">ShanghaiTech</cell><cell></cell></row><row><cell>Venue</cell><cell>Method</cell><cell>AUC</cell><cell></cell><cell cols="2">RBDC TBDC</cell><cell cols="2">AUC</cell><cell cols="2">RBDC TBDC</cell></row><row><cell></cell><cell></cell><cell cols="2">Micro Macro</cell><cell></cell><cell></cell><cell cols="2">Micro Macro</cell><cell></cell><cell></cell></row><row><cell>BMVC 2018</cell><cell>Liu et al. [38]</cell><cell>84.4</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>CVPR 2018</cell><cell>Sultani et al. [66]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>76.5</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">ICASSP 2018 Lee et al. [32]</cell><cell>87.2</cell><cell></cell><cell>-</cell><cell>-</cell><cell cols="2">76.2</cell><cell>-</cell><cell>-</cell></row><row><cell>WACV 2019</cell><cell>Ionescu et al. [27]</cell><cell>88.9</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>ICCV 2019</cell><cell>Nguyen et al. [47]</cell><cell>86.9</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>CVPR 2019</cell><cell>Ionescu et al. [25]</cell><cell cols="8">87.4 90.4 15.77 27.01 78.7 84.9 20.65 44.54</cell></row><row><cell cols="2">TNNLS 2019 Wu et al. [73]</cell><cell>86.6</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>TIP 2019</cell><cell>Lee et al. [33]</cell><cell>90.0</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">ACMMM 2020 Yu et al. [77]</cell><cell>89.6</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>74.8</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>WACV 2020</cell><cell>Ramachandra et al. [50]</cell><cell>72.0</cell><cell></cell><cell cols="2">35.80 80.90</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>WACV 2020</cell><cell>Ramachandra et al. [51]</cell><cell>87.2</cell><cell></cell><cell cols="2">41.20 78.60</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PRL 2020</cell><cell>Tang et al. [69]</cell><cell>85.1</cell><cell></cell><cell>-</cell><cell>-</cell><cell cols="2">73.0</cell><cell>-</cell><cell>-</cell></row><row><cell>Access 2020</cell><cell>Dong et al. [12]</cell><cell>84.9</cell><cell></cell><cell>-</cell><cell>-</cell><cell cols="2">73.7</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">CVPRW 2020 Doshi et al. [13]</cell><cell>86.4</cell><cell></cell><cell>-</cell><cell>-</cell><cell cols="2">71.6</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">ACMMM 2020 Sun et al. [67]</cell><cell>89.6</cell><cell></cell><cell>-</cell><cell>-</cell><cell cols="2">74.7</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">ACMMM 2020 Wang et al. [72]</cell><cell>87.0</cell><cell></cell><cell>-</cell><cell>-</cell><cell cols="2">79.3</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">ICCVW 2021 Astrid et al. [4]</cell><cell>84.7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>73.7</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>BMVC 2021</cell><cell>Astrid et al. [3]</cell><cell>87.1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>75.9</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>CVPR 2021</cell><cell>Georgescu et al. [17]</cell><cell cols="8">91.5 92.8 57.00 58.30 82.4 90.2 42.80 83.90</cell></row><row><cell>CVPR 2018</cell><cell>Liu et al. [37]</cell><cell cols="8">85.1 81.7 19.59 56.01 72.8 80.6 17.03 54.23</cell></row><row><cell>CVPR 2022</cell><cell>Liu et al. [37] + SSPCAB</cell><cell cols="8">87.3 84.5 20.13 62.30 74.5 82.9 18.51 60.22</cell></row><row><cell>CVPR 2020</cell><cell>Park et al. [49]</cell><cell cols="2">82.8 86.8</cell><cell>-</cell><cell>-</cell><cell cols="2">68.3 79.7</cell><cell>-</cell><cell>-</cell></row><row><cell>CVPR 2022</cell><cell>Park et al. [49] + SSPCAB</cell><cell cols="2">84.8 88.6</cell><cell>-</cell><cell>-</cell><cell cols="2">69.8 80.2</cell><cell>-</cell><cell>-</cell></row><row><cell>ICCV 2021</cell><cell>Liu et al. [39]</cell><cell>89.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Micro-averaged frame-level AUC, macro-averaged frame-level AUC, RBDC, and TBDC scores (in %) on Avenue, while varying the size of the masked kernel M .</figDesc><table><row><cell cols="4">Location of SSPCAB Early Middle Late Micro Macro AUC</cell><cell>RBDC TBDC</cell></row><row><cell></cell><cell></cell><cell>80.0</cell><cell>83.4</cell><cell>49.98 51.69</cell></row><row><cell>Plain auto-encoder</cell><cell></cell><cell>81.1 84.2 85.9 82.7 83.2 86.1</cell><cell>83.6 85.0 85.6 83.8 84.1 85.7</cell><cell>50.86 52.44 52.73 54.02 53.81 56.33 50.54 52.70 52.33 53.01 54.03 56.07</cell></row><row><cell></cell><cell></cell><cell>85.3</cell><cell>85.4</cell><cell>53.11 56.64</cell></row><row><cell cols="5">Table 4. Micro-averaged frame-level AUC, macro-averaged</cell></row><row><cell cols="5">frame-level AUC, RBDC, and TBDC scores (in %) on Avenue,</cell></row><row><cell cols="5">while integrating SSPCAB into an auto-encoder, at different lo-</cell></row><row><cell cols="5">cations. SSPCAB improves the results regardless of the integra-</cell></row><row><cell cols="5">tion place or the number of blocks. The option highlighted in red</cell></row><row><cell cols="5">is used throughout the experiments presented in the main article.</cell></row><row><cell cols="3">Best results are highlighted in bold.</cell><cell></cell></row><row><cell>Size of M</cell><cell cols="2">AUC Micro Macro</cell><cell cols="2">RBDC TBDC</cell></row><row><cell></cell><cell>80.0</cell><cell>83.4</cell><cell cols="2">49.98 51.69</cell></row><row><cell>1 ? 1</cell><cell>85.9</cell><cell>85.6</cell><cell cols="2">53.81 56.33</cell></row><row><cell>3 ? 3</cell><cell>85.9</cell><cell>85.5</cell><cell cols="2">53.93 56.31</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The research leading to these results has received funding from the EEA Grants 2014-2021, under Project contract no. EEA-RO-NO-2018-0496. This work has also been funded by the Milestone Research Programme at AAU, SecurifAI, and the Romanian Young Academy, which is funded by Stiftung Mercator and the Alexander von Humboldt Foundation for the period 2020-2022.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust Real-Time Unusual Event Detection Using Multiple Fixed-Location Monitors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilan</forename><surname>Shimshoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daviv</forename><surname>Reinitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="555" to="560" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Video parsing for abnormality detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borislav</forename><surname>Antic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="2415" to="2422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning not to reconstruct anomalies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Astrid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Zaigham</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae-Yeong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung-Ik</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Synthetic Temporal Anomaly Guided End-to-End Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Astrid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Zaigham</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung-Ik</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCVW</title>
		<meeting>ICCVW</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="207" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MVTec AD -A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="9592" to="9600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4183" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Defect Detection in SEM Images of Nanofibrous Materials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Carrera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Manganini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giacomo</forename><surname>Boracchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ettore</forename><surname>Lanzarone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="551" to="561" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Video anomaly detection and localization using hierarchical feature representation and Gaussian process regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yie-Tarng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Hsien</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2909" to="2917" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sparse reconstruction cost for abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="3449" to="3456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">PaDiM: A patch distribution modeling framework for anomaly detection and localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Defard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Setkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelique</forename><surname>Loesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romaric</forename><surname>Audigier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICPR</title>
		<meeting>ICPR</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="475" to="489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Discriminative Framework for Anomaly Detection in Large Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allison</forename><surname>Del Giorno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Andrew</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="334" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dual Discriminator Generative Adversarial Network for Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiushan</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="88170" to="88176" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Any-Shot Sequential Anomaly Detection in Surveillance Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keval</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasin</forename><surname>Yilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPRW</title>
		<meeting>CVPRW</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="934" to="935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Online Detection of Abnormal Events Using Incremental Coding Length</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jayanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonny</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3755" to="3761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Attribute Restoration Framework for Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoqin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Jinkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning deep event models for crowd anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yachuang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">219</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="548" to="556" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Anomaly Detection in Video via Self-Supervised and Multi-Task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariana-Iuliana</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Barbalau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tudor</forename><surname>Radu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="12742" to="12752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Background-Agnostic Framework with Adversarial Training for Abnormal Event Detection in Video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariana</forename><forename type="middle">Iuliana</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Moussa Reda Mansour, Svetha Venkatesh, and Anton Van Den Hengel. Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingqiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vuong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Budhaditya</forename><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongming</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helei</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.14430</idno>
		<title level="m">Xiaofei He, and Xiansheng Hua. Discriminative-Generative Dual Memory Video Anomaly Detection</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning temporal regularity in video sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmudul</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghyun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Roy-Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Anomaly detection using deep learning based image completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Haselmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><forename type="middle">P</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tabatabai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICMLA</title>
		<meeting>ICMLA</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1237" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Joint Detection and Recounting of Abnormal Events by Learning Deep Generic Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Hinami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin&amp;apos;ichi</forename><surname>Satoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3639" to="3647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Squeeze-and-Excitation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Object-Centric Auto-Encoders and Dummy Anomalies for Abnormal Event Detection in Video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Radu Tudor Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariana-Iuliana</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="7842" to="7851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unmasking the abnormal events in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sorina</forename><surname>Radu Tudor Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Smeureanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Alexe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2895" to="2903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Detecting abnormal events in video using Narrowed Normality Clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sorina</forename><surname>Radu Tudor Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Smeureanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alexe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">TAM-Net: Temporal Enhanced Appearance-to-Motion Generative Network for Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangli</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bairong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuesheng</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNN</title>
		<meeting>IJCNN</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Observe locally, infer globally: A space-time MRF for detecting abnormal activities with incremental updates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaechul</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2921" to="2928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ImageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pattrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">STAN: Spatio-temporal adversarial networks for abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Man</forename><surname>Hak Gu Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1323" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">BMAN: Bidirectional Multi-Scale Aggregation Networks for Abnormal Event Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Man</forename><surname>Hak Gu Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">CutPaste: Self-Supervised Learning for Anomaly Detection and Localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsung</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Anomaly detection and localization in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="32" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Superpixel Masking and Inpainting for Self-Supervised Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaitao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Future Frame Prediction for Anomaly Detection -A New Baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongze</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Classifier Two-Sample Test for Video Anomaly Detections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusha</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barnaba?s</forename><surname>P?czos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow-Guided Frame Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongwei</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjiang</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiqing</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Abnormal Event Detection at 150 FPS in MATLAB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Few-Shot Scene-Adaptive Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="125" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Video Cloze Procedure for Self-Supervised Spatio-Temporal Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dezhao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongbao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiping</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11701" to="11708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Revisit of Sparse Coding Based Anomaly Detection in Stacked RNN Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Anomaly Detection in Crowded Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Wei-Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viral</forename><surname>Bhalodia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Abnormal crowd behavior detection using social force model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramin</forename><surname>Mehran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="935" to="942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Rectified Linear Units Improve Restricted Boltzmann Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Anomaly Detection in Video Sequence With Appearance-Motion Correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Trong-Nguyen Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Self-trained Deep Ordinal Regression for End-to-End Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guansong</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="12173" to="12182" />
		</imprint>
	</monogr>
	<note>Anton van den Hengel, and Xiao Bai</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning Memory-guided Normality for Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongyoun</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bumsub</forename><surname>Ham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Street Scene: A new dataset and evaluation protocol for video anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharathkumar</forename><surname>Ramachandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2569" to="2578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning a distance function with a Siamese network to localize anomalies in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharathkumar</forename><surname>Ramachandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranga</forename><surname>Vatsavai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2598" to="2607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A Survey of Single-Scene Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharathkumar</forename><surname>Ramachandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranga Raju</forename><surname>Vatsavai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Plug-and-Play CNN for Crowd Motion Analysis: An Application in Abnormal Event Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdyar</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moin</forename><surname>Nabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enver</forename><surname>Sangineto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1689" to="1698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Abnormal Event Detection in Videos using Generative Adversarial Nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdyar</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moin</forename><surname>Nabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enver</forename><surname>Sangineto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucio</forename><surname>Marcenaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Regazzoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICIP</title>
		<meeting>ICIP</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Unsupervised Behavior-Specific Dictionary Learning for Abnormal Event Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Huamin Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Soren Ingvor Olsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">B</forename><surname>Escalera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moeslund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="28" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Same Same But DifferNet: Semi-Supervised Defect Detection with Normalizing Flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1907" to="1916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deep-Cascade: Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localization in Crowded Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmood</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Klette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deep-anomaly: Fully convolutional neural network for fast anomaly detection in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmood</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Moayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Klette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="88" to="97" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">AVID: Adversarial Visual Irregularity Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masoud</forename><surname>Pourreza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahim</forename><surname>Entezari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmood</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACCV</title>
		<meeting>ACCV</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="488" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Dynamic Routing Between Capsules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3859" to="3869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Object-Centric Anomaly Detection by Attribute-Based Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Babak</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Elgammal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="787" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Multiresolution Knowledge Distillation for Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadreza</forename><surname>Salehi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niousha</forename><surname>Sadjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soroosh</forename><surname>Baselizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">H</forename><surname>Rohban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><forename type="middle">R</forename><surname>Rabiee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Video anomaly detection based on local statistical aggregates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Saligrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2112" to="2119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Grad-CAM: Visual Explanations From Deep Networks via Gradient-Based Localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramprasaath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Deep Appearance Features for Abnormal Behavior Detection in Video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sorina</forename><surname>Smeureanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tudor</forename><surname>Radu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alexe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICIAP</title>
		<meeting>ICIAP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">10485</biblScope>
			<biblScope unit="page" from="779" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Real-World Anomaly Detection in Surveillance Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waqas</forename><surname>Sultani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6479" to="6488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Scene-Aware Context Reasoning for Unsupervised Abnormal Event Detection in Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Che</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunde</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACMMM</title>
		<meeting>ACMMM</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="184" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Online growing neural gas for anomaly detection in changing surveillance scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">C</biblScope>
			<biblScope unit="page" from="187" to="201" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Integrating prediction and reconstruction for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Anomaly Detection using a Convolutional Winner-Take-All Autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hogg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Attention guided anomaly localization in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashanka</forename><surname>Venkataramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuan-Chuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rajat Vikram Singh, and Abhijit Mahalanobis</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings of ECCV</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Cluster Attention Contrast for Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexian</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACMMM</title>
		<meeting>ACMMM</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2463" to="2471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2609" to="2622" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Chaotic Invariants of Lagrangian Particle Trajectories for Anomaly Detection in Crowded Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shandong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2054" to="2060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Detecting Anomalous Events in Videos by Learning Deep Representations of Appearance and Motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="127" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Patch SVDD: Patch-level SVDD for Anomaly Detection and Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihun</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACCV</title>
		<meeting>ACCV</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="375" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Cloze Test Helps: Effective Video Anomaly Detection via Learning to Complete Video Events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiping</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">En</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanfu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACMMM</title>
		<meeting>ACMMM</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="583" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Old is Gold: Redefining the Adversarially Learned One-Class Classifier Training Paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Ha</forename><surname>Muhammad Zaigham Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung-Ik</forename><surname>Astrid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14183" to="14193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">DRAEM -A Discriminatively Trained Reconstruction Embedding for Surface Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitjan</forename><surname>Zavrtanik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danijel</forename><surname>Skocaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Visualizing and Understanding Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Video Anomaly Detection and Localization using Motion-field Shape Description and Homogeneity Testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiulong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weishan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">107394</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Online Detection of Unusual Events in Videos via Dynamic Sparse Coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3313" to="3320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Context-encoding Variational Autoencoder for Unsupervised Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zimmerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MIDL</title>
		<meeting>MIDL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
