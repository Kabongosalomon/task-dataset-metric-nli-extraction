<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Task Transformer Network for Joint MRI Reconstruction and Super-Resolution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Mei</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Shenzhen Key Laboratory of Visual Object Detection and Recognition</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>shenzhen</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Inception Institute of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunlu</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Shenzhen Key Laboratory of Visual Object Detection and Recognition</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>shenzhen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huazhu</forename><surname>Fu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Inception Institute of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chen</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">First Affiliated Hospital with</orgName>
								<orgName type="institution">Nanjing Medical University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Shenzhen Key Laboratory of Visual Object Detection and Recognition</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>shenzhen</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Task Transformer Network for Joint MRI Reconstruction and Super-Resolution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>/chunmeifeng/T2Net</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Multi-task learning ? MRI reconstruction ? Super-resolution</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The core problem of Magnetic Resonance Imaging (MRI) is the trade off between acceleration and image quality. Image reconstruction and super-resolution are two crucial techniques in Magnetic Resonance Imaging (MRI). Current methods are designed to perform these tasks separately, ignoring the correlations between them. In this work, we propose an end-to-end task transformer network (T 2 Net) for joint MRI reconstruction and super-resolution, which allows representations and feature transmission to be shared between multiple task to achieve higher-quality, super-resolved and motion-artifacts-free images from highly undersampled and degenerated MRI data. Our framework combines both reconstruction and super-resolution, divided into two sub-branches, whose features are expressed as queries and keys. Specifically, we encourage joint feature learning between the two tasks, thereby transferring accurate task information. We first use two separate CNN branches to extract task-specific features. Then, a task transformer module is designed to embed and synthesize the relevance between the two tasks. Experimental results show that our multi-task model significantly outperforms advanced sequential methods, both quantitatively and qualitatively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>for this, where the former accelerates MRI by reducing the k-space sampling rate, and the latter achieves a high-resolution (HR) image by restoring a single degenerated low-resolution (LR) image <ref type="bibr" target="#b5">[6]</ref>.</p><p>Outstanding contributions have been made in both areas <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b6">7]</ref>. Specifically, compressed sensing (CS) <ref type="bibr" target="#b12">[13]</ref>, low-rank <ref type="bibr" target="#b24">[25]</ref>, dictionary learning <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b30">31]</ref>, and manifold fitting <ref type="bibr" target="#b19">[20]</ref> techniques utilize various priors to overcome aliasing artifacts caused by the violation of the Shannon-Nyquist sampling theorem for MRI reconstruction. With the renaissance of deep neural networks, different convolutional neural network (CNN) approaches have also been developed for fast MRI reconstruction <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b7">8]</ref>. Typical examples include model-based unrolling methods, e.g., VN-Net <ref type="bibr" target="#b9">[10]</ref>, which generalizes the CS formulation to a variational model, and ADMM-Net, which is derived from the iterative procedures <ref type="bibr" target="#b29">[30]</ref>; end-to-end learning methods, e.g., using U-Net as the basic framework to solve the problem of MRI reconstruction <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b10">11]</ref>; and generative adversarial networks (GANs) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b18">19]</ref>. In addition to various network structures, series of convolutions based on the characteristics of MRI data have also been designed to solve the problem of MRI reconstruction <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b25">26]</ref>. For MRI SR, iterative algorithms (e.g., low rank or sparse representation) take image priors into account as regularization items and try to obtain a higher-quality image from a single LR image <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b32">33]</ref>. Similarly, CNN approaches have achieved state-of-the-art performance in SR <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17]</ref>. For example, residual learning can be used to extract multi-scale information and obtain higher-quality images <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b20">21]</ref>. GAN-based methods have also been used to recover HR details from an LR input <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b17">18]</ref>.</p><p>However, these works are designed to perform one specific function, i.e., train a single model to carry out the desired task. While acceptable performance can be achieved in this way, information that might help the model perform better in certain metrics is often ignored, since too much focus is given to one single task. In the real world, a network that can perform multiple tasks simultaneously is far preferable to a set of independent networks, as it can provide a more complete visual system. Since related tasks often share features, real-world tasks tend to have strong dependencies. Recently, multi-task learning has been successfully applied to various fields, including natural language processing <ref type="bibr" target="#b3">[4]</ref>, speech recognition <ref type="bibr" target="#b11">[12]</ref> and computer vision <ref type="bibr" target="#b14">[15]</ref>. By sharing representations between related tasks, the model can better generalize to the original task. Compared with standard single-task learning, multi-task models can express both shared and task-specific characteristics. In natural images, multi-task learning has been widely used for image enhancement <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b31">32]</ref>. However, current models directly incorporate different tasks into the network in a sequential manner, without exploring the features shared across the tasks.</p><p>Inspired by the powerful visual capabilities of transformer and multi-task learning, we propose an end-to-end task transformer network, named T 2 Net, for multi-task learning, which integrates both MRI reconstruction and SR. Our contributions are three-fold: First, to the best of our knowledge, we are the first to introduce the transformer framework into multi-task learning for MRI reconstruction and SR. Our network allows representations to be shared between the two tasks, leveraging knowledge from one task to speed up the learning process in the other and increase the flexibility for sharing complementary features. Second, we develop a framework with two branches for expressing task-specific features and a task transformer module for transferring shared features. More specifically, the task transformer module includes relevance embedding, transfer attention and soft attention, which enable related tasks to share visual features. Third, we demonstrate that our multi-task model generates superior results compared to various sequential combinations of state-of-the-art MRI reconstruction and super-resolution models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Task Transformer Network</head><p>Let y be the complex-valued, fully sampled k-space. The corresponding fully sampled HR image with a size of h ? w can be obtained by x = F ?1 (y), where F ?1 is the inverse 2D fast Fourier transform (FFT). To accelerate the MRI acquisition, a binary mask operator M defining the Cartesian acquisition trajectory is used to select a subset of the k-space points. Therefore, the undersampled k-space is obtained by? = M y, where denotes element-wise multiplication. Accordingly, the zero-filled image can be expressed asx = F ?1 (?). In MRI super-resolution, to obtain the LR image x LR with a size of h s ? w s (s is the scale factor), we follow <ref type="bibr" target="#b2">[3]</ref>, first downgrading the resolution by truncating the outer part of y with a desired factor to obtain y LR , and then applying F to it. Therefore, if we apply downgrading tox, we will obtain the undersampled, degenerated MRI data for our multi-task inputx LR .</p><p>To effectively achieve higher-quality, motion-artifact-free images from highly undersampled and degenerated MRI datax LR , we propose a simple and effective end-to-end framework, named the Task Transformer Network (T 2 Net). As shown in <ref type="figure">Fig. 1</ref>, our multi-task framework consists of three parts: an SR branch, a reconstruction (Rec) branch and a task transformer module. The first two branches are used to extract task-specific features, providing our network the ability to learn features tailored to each task. The task transformer module is then used to learn shared features, encouraging the network to learn a generalizable representation. As can be seen, the input of the two branches is the undersampled, degenerated MRI datax LR , which contains motion artifacts and blurring effects. The output of the Rec branch is the LR motion-free image x LR , while the output of the SR branch is our final desired high-quality, superresolved and motion-free image x . Our framework can be approximated using neural networks by minimizing an 1 loss function:</p><formula xml:id="formula_0">? = arg min ? 1 ,? 2 N j ? x j ? f SR cnn x j LR | ?1 1 + ? x j LR ? f Rec cnn x j LR | ?2 1 ,<label>(1)</label></formula><p>where f SR cnn and f Rec cnn represent the mapping functions of the SR and Rec branches with parameters ? 1 and ? 2 , respectively, and ? and ? are used to balance the </p><formula xml:id="formula_1">xLR x LR x H RB SR 1 H RB SR 2 H RB SR N H RB Rec 1 H RB Rec 2 H RB Rec N H tt 1 H tt 2 H tt N F 0 SR F 0 Rec F 1 SR F 1 Rec F 2 SR F 2 Rec F N SR F N Rec F 1 T T F 2 T T F N T T Fig. 1.</formula><p>Overview of the proposed multi-task framework, including an SR branch, a reconstruction (Rec) branch, and a task transformer module.</p><p>weights of the two branches. Note that with sufficient training data {x j ,x j LR } and the SGD algorithm, we can obtain well-trained weights?.</p><p>SR Branch. Our SR branch is used to enlarge the image from an undersampled and degenerated inputx LR . As shown in <ref type="figure">Fig. 1</ref>, for an input image of size h s ? w s with artifacts, a convolutional layer is used to extract the shallow feature F 0 SR of the SR branch. Then we send it to the backbone of EDSR <ref type="bibr" target="#b13">[14]</ref> to extract the SR features:</p><formula xml:id="formula_2">F 1 SR = H RB SR1 F 0 SR , where H RB SR1</formula><p>represents the first Resblock in the SR branch. To enhance features from different tasks, we propose a task transformer module H tt ( ?2.2), which transfers the motion-artifacts-free representation to the SR branch. Formally, we have</p><formula xml:id="formula_3">F i T T = H tt i F i SR + F i Rec , i = 1, 2, . . . , N,<label>(2)</label></formula><p>where N is the number of H tt , F i Rec is the feature from the Rec branch (see Eq. (4)), and F i SR represents the i-th feature of the SR branch. The learned motion-artifacts-free representation F i T T is then sent to the following Resblock:</p><formula xml:id="formula_4">F i+1 SR = H RB SRi+1 F i T T .<label>(3)</label></formula><p>Finally, a sub-pixel convolution U ? is used as the upsampling module to generate the output x of scale h?w:</p><formula xml:id="formula_5">x = U ? F N SR + F 0 SR .</formula><p>The whole branch is trained under the supervision of the fully sampled HR image x.</p><p>Reconstruction Branch. As discussed above, only relying on the SR module is not sufficient for recovering a high-resolution and motion-corrected image when starting from an LR image with artifacts as input. Reconstruction, on the other hand, can restore a clear image with correct anatomical structure from an input with motion artifactsx LR , because it is trained under the supervision of x LR . This means that reconstruction can effectively remove the artifacts introduced by the undersampled k-space, which is helpful for our final multi-task goal. By comparing the input and output of the Rec branch in <ref type="figure">Fig. 1</ref>, we can easily see that the Rec branch is more powerful in eliminating artifacts. For this branch, as shown in <ref type="figure">Fig. 1</ref>, we employ the same design as the SR branch to reduce the computational cost and generate high-quality results. We first use a convolutional layer to extract the shallow feature F 0 Rec from the Rec branch. Then a series of H RB Reci is used to extract the deep motion-corrected features</p><formula xml:id="formula_6">F i Rec = H RB Reci F i?1 Rec , i = 1, 2, . . . , N,<label>(4)</label></formula><p>where H RB Reci represents the i-th Resblocks, and F i Rec represents the i-th feature of the Rec branch. The Rec branch is trained under the supervision of the LR motion-artifacts-free image x LR , aiming to remove the artifacts from the input. In our multi-task framework, the output of this branch is fused to the SR branch to obtain the final super-resolved, motion-artifact-free image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Task Transformer Module</head><p>Since the Rec branch contains a stronger artifact removal capacity than the SR branch, we introduce a task transformer module to guide the SR branch to learn SR motion-artifacts-free representation from the Rec branch. Our task transformer module consists of three parts: a relevance embedding, a transfer attention for feature transfer and a soft attention for feature synthesis. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, the features F i SR and F i Rec inherited from the SR and Rec branches are expressed as the query (Q) and key (K). The value (V ) is the feature F i Rec ?? obtained by sequentially applying upsampling ? and downsampling ? on F i Rec to make it domain-consistent with Q <ref type="bibr" target="#b27">[28]</ref>.</p><p>Relevance Embedding. Relevance embedding aims to embed the relevance information from the Rec branch by estimating the similarity between Q and K. To calculate the relevance r i,j between these two branches, we have</p><formula xml:id="formula_7">r i,j = q i q i , k j k j ,<label>(5)</label></formula><p>where q i i ? 1, h s ? w s and k j j ? 1, h s ? w s are the patches of Q and K, respectively.</p><p>Transfer Attention. Our transfer attention module aims to transfer anatomical structure features from the Rec branch to the SR branch. Different from the traditional attention mechanism, we do not take a weighted sum of the reconstruction features for each query q i , because this would result in blurred images for image restoration. To transfer features from the most relevant positions in the Rec branch for each q i , we obtain a transfer attention map T from the relevance r i,j :</p><formula xml:id="formula_8">t i = arg max j (r i,j ), where t i i ? 1, h 2 ? w 2</formula><p>is the i-th element in T . We use the value of t i to represent the position in the Rec branch most relevant to the i-th position in the SR branch.</p><p>To obtain the anatomical structure features C without artifacts transferred from the Rec branch, an index selection operation is applied to the unfolded patches of V using t i as the index: c i = v ti , where c i represents the value of C in the i-th position, which is equal to the t i -th position of V .</p><p>Soft Attention. To synthesize the features from the two branches in our model, we first concatenate Q and C, and send them to a convolutional layer Z = Conv z <ref type="figure">(Concat(C, Q)</ref>). Then, we use a soft attention module to aggregate the synthetic features Z and Q. To enhance the transferred anatomical structure information, we compute the soft attention map S from r i,j to represent the confidence of the transferred structure features for each position in C: s i = max j (r i,j ), where s i is the i-th position of the soft attention map S. To leverage more information from the SR branch, we first combine the synthetic feature Z with the original feature of the SR branch Q. Then, the final output of the task transformer module is obtained as follows:</p><formula xml:id="formula_9">F TT = Q Conv out (Z) S,<label>(6)</label></formula><p>where denotes the element-wise summation, denotes the element-wise multiplication, and F TT represents the final output of the task transformer module, which will be sent to the SR branch to restore a higher-quality, SR and motionartifact-free image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Datasets. We employ the public IXI dataset and a clinical brain MRI dataset to evaluate our method. The clinical dataset is scanned with fully sampling using a clinical 3T Siemens Magnetom Skyra system on 155 patients. The imaging protocol is as follows: matrix size 320?320?20, TR = 4511 ms, TE = 112.86 ms, field of view (FOV) = 230?200 mm 2 , turbo factor/echo train length TF = 16. For the IXI dataset, we exclude the first few slices of each volume since the frontal slices are much noisier than the others, making their distribution different. More details on the IXI dataset can be obtained from http://brain-development. org/ixi-dataset/. We split each dataset patient-wise into a ratio of 7:1:2 for training/validation/testing.  Experimental Setup. For fair comparison, we implement four methods (two MRI reconstruction methods, ADMMNet <ref type="bibr" target="#b29">[30]</ref> and MICCAN <ref type="bibr" target="#b10">[11]</ref>, and two MRI SR methods, MGLRL <ref type="bibr" target="#b23">[24]</ref> and Lyu et al. <ref type="bibr" target="#b15">[16]</ref>) with various sequential combinations, which we consider as baselines. These include: is used to remove artifacts, while the second is used to obtain higher-quality images. We implement our model in PyTorch using Adam with an initial learning rate of 5e-5, and train it on two NVIDIA Tesla V100 GPUs with 32GB of memory per card, for 50 epochs. Parameters ? and ? are empirically set to 0.2 and 0.8, respectively. We use N = 8 residual groups in our network. All the compared methods are retrained using their default parameter settings.</p><p>Experimental Results. We evaluate our multi-task model under 6? Cartesian acceleration with 2? and 4? enlargement, respectively. In <ref type="table" target="#tab_0">Table 1</ref>, we report the average PSNR, SSIM and NMSE scores with respect to the baselines on the two datasets, where w/o Rec and w/o H tt will discussed in the ablation study. On the IXI dataset, our T 2 Net achieves a PSNR of up to 29.397 dB under 2? enlargement. Further, compared to the best sequential combination, we improve the PSNR from 21.895 to 28.659 dB under 4? enlargement. Moreover, with higher enlargement, the sequential combinations obtain worse scores, while our T 2 Net still preserves excellent results. On the clinical dataset, our T 2 Net again achieves significantly better results than all combinations, under both enlargement scales. This suggests that our model can effectively transfer anatomical structure features to the SR branch, and that this is beneficial to multi-task learning.</p><p>We provide visual comparison results with corresponding error maps in <ref type="figure" target="#fig_4">Figure 3</ref>. The first two rows show the restored images and error maps from the IXI dataset with 6? Cartesian acceleration and 2? enlargement, while the last two rows are the results for the clinical dataset with 6? Cartesian acceleration and 4? enlargement. As we can see, the input has significant aliasing artifacts and loss of anatomical details. The sequential combination methods can improve the image quality, but are less effective than our multi-task methods. Our methods are obviously robust to aliasing artifacts and structural loss in the input. More importantly, at a high enlargement scale, our multi-task methods achieve much better results than the sequential combination methods.</p><p>Ablation Study. We evaluate the effectiveness of the two branches and the task transformer module in our multi-task network. Without loss of generality, the restoration results of two key components, including the Rec branch and task transformer module, are evaluated under 6? acceleration and 2? as well as 4? enlargement. We summarize the component analysis in <ref type="table" target="#tab_0">Table 1</ref>, where w/o Rec indicates that only the SR branch is employed, while w/o H tt indicates that both branches are used but the task transformer module H tt is removed. As we can observe, w/o Rec obtains the worst results, which indicates the importance of both branches in our method, as each contains task-specific features for the target image restoration. Moreover, we can also see that w/o H tt outperforms w/o Rec, demonstrating that transferring anatomical structure features to the target SR branch is necessary to achieve complementary representations. More importantly, our full T 2 Net further improves the results on both datasets and all settings. This demonstrates the powerful capability of our H tt and two-branch structure in multi-task learning, which increases the model's flexibility to share complementary features for the restoration of higher-quality, super-resolved, and motion-artifacts-free images from highly undersampled and degenerated MRI data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we focus on the multi-task learning of MRI reconstruction and super-resolution. For this purpose, we propose a novel end-to-end task transformer network (T 2 Net) to transfer shared structure information to the taskspecific branch for higher-quality and super-resolved reconstructions. Specifically, our model consists of two task-specific branches, i.e., a target branch for SR and auxiliary branch for reconstruction, together with a task transformer module to transfer anatomical structure information to the target branch. The proposed task transformer consists of a feature embedding, hard attention and soft attention to transfer and synthesize the final reconstructions with correct anatomical structure, whilst maintaining fine details and producing less blurring and artifacts. In the future, we will design a network to automatically learn the loss weights.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Architecture of the proposed task transformer module. Q and K are the features inherited from the SR and Rec branches, respectively. V is the feature from the Rec branch with sequential upsampling and downsampling applied to it.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Com-A 27 .T 2</head><label>272</label><figDesc>541 0.801 0.041 21.111 0.705 0.178 27.031 0.764 0.065 26.169 0.742 0.079 Com-B 28.439 0.847 0.033 21.323 0.687 0.170 28.750 0.816 0.044 27.539 0.803 0.058 Com-C 27.535 0.802 0.041 21.696 0.731 0.156 28.781 0.765 0.064 26.197 0.751 0.079 Com-D 28.426 0.847 0.033 21.895 0.710 0.149 28.839 0.817 0.043 27.700 0.815 0.056 w/o Rec 28.400 0.809 0.035 25.952 0.789 0.091 28.932 0.802 0.045 28.601 0.819 0.044 w/o H tt 28.700 0.856 0.031 26.692 0.7730 0.089 29.510 0.817 0.037 29.528 0.821 0.037 Net 29.397 0.872 0.027 28.659 0.850 0.032 30.400 0.841 0.030 30.252 0.840 0.031</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Com-A: ADMMNet-MGLRL, Com-B: ADMMNet-Lyu et al., Com-C: MICCAN-MGLRL, and Com-D: MICCAN-Lyu et al.. The first model in each combination</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Visual comparison with error maps of different methods on the two datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative results on the two datasets under different enlargement scales.</figDesc><table><row><cell>Dataset</cell><cell>IXI dataset</cell><cell></cell><cell>clinical dataset</cell><cell></cell></row><row><cell>Scale</cell><cell>2?</cell><cell>4?</cell><cell>2?</cell><cell>4?</cell></row><row><cell></cell><cell cols="4">PSNR SSIM NMSE PSNR SSIM NMSE PSNR SSIM NMSE PSNR SSIM NMSE</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fcsr-gan: Joint face completion and superresolution via multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biometrics, Behavior, and Identity Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="121" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Super-resolution musculoskeletal mri using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Hargreaves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic resonance in medicine</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2139" to="2154" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient and accurate mri super-resolution using a generative adversarial network and 3d multilevel densely connected network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Christodoulou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-contrast mri super-resolution via a multi-stage integration network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Brain mri super-resolution using coupled-projection residual network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Accelerated multi-modal mr imaging with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">2106</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dual-octave convolution for accelerated parallel mr image reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 35th AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Donet: Dual-octave network for fast mr image reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning a variational network for reconstruction of accelerated mri data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Klatzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kobler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Sodickson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Knoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic resonance in medicine</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3055" to="3071" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mri reconstruction via cascaded channel-wise attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Biomedical Imaging</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1622" to="1626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Joint ctc-attention based end-to-end speech recognition using multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4835" to="4839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image reconstruction of compressed sensing mri using graph-based redundant wavelet transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="93" to="104" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Enhanced deep residual networks for single image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mu Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition workshops</title>
		<meeting>the IEEE conference on computer vision and pattern recognition workshops</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">End-to-end multi-task learning with attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Johns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1871" to="1880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mri super-resolution with ensemble learning and complementary priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Imaging</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="615" to="624" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Super-resolution mri and ct through gan-circle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">p. 111130X. International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">11113</biblScope>
		</imprint>
	</monogr>
	<note>Developments in X-Ray Tomography XII</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Image super-resolution using progressive generative adversarial networks for medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahapatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bozorgtabar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="30" to="39" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep generative adversarial neural networks for compressive sensing mri</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mardani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Vasanawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zaharchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Pauly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="167" to="179" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A kernel-based low-rank (klr) model for low-dimensional manifold recovery in highly accelerated dynamic mri</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Nakarmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ying</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2297" to="2307" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multi-input cardiac image super-resolution using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Oktay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>De Marvao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>O&amp;apos;regan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="246" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Convolutional recurrent neural networks for dynamic mr image reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schlemper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="280" to="290" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mr image reconstruction from highly undersampled k-space data by dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravishankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bresler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1028" to="1041" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Super-resolution reconstruction of mr image with a novel residual learning network algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics in Medicine &amp; Biology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">85011</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Calibrationless parallel imaging reconstruction based on structured low-rank matrix completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Ohliger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Vigneron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lustig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic resonance in medicine</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="959" to="970" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deepcomplexmri: Exploiting deep residual network for fast parallel mr imaging with complex convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic Resonance Imaging</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="136" to="147" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sparse representation-based mri super-resolution reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Roddick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Measurement</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="946" to="953" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning texture transformer network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5791" to="5800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dagan: Deep de-aliasing generative adversarial networks for fast compressed sensing mri reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Slabaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Dragotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Keegan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1310" to="1321" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep admm-net for compressive sensing mri</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th international conference on neural information processing systems</title>
		<meeting>the 30th international conference on neural information processing systems</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fast multiclass dictionaries learning with geometrical directions in mri reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on biomedical engineering</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1850" to="1861" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Joint license plate super-resolution and recognition in one multi-task gan framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1443" to="1447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Application of tikhonov regularization to super-resolution reconstruction of brain mri images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Y</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Imaging and Informatics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="51" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Image reconstruction by domain-transform manifold learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Cauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Rosen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">555</biblScope>
			<biblScope unit="issue">7697</biblScope>
			<biblScope unit="page" from="487" to="492" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
