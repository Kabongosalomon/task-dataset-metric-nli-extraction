<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Open Intent Classification with Adaptive Decision Boundary</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanlei</forename><surname>Zhang</surname></persName>
							<email>zhang-hl20@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Beijing National Research Center for Information Science and Technology (BNRist)</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Xu</surname></persName>
							<email>xuhua@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Beijing National Research Center for Information Science and Technology (BNRist)</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-En</forename><surname>Lin</surname></persName>
							<email>ting-en.lte@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Beijing National Research Center for Information Science and Technology (BNRist)</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Open Intent Classification with Adaptive Decision Boundary</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Open intent classification is a challenging task in dialogue systems. On the one hand, it should ensure the quality of known intent identification. On the other hand, it needs to detect the open (unknown) intent without prior knowledge. Current models are limited in finding the appropriate decision boundary to balance the performances of both known intents and the open intent. In this paper, we propose a postprocessing method to learn the adaptive decision boundary (ADB) for open intent classification. We first utilize the labeled known intent samples to pre-train the model. Then, we automatically learn the adaptive spherical decision boundary for each known class with the aid of well-trained features. Specifically, we propose a new loss function to balance both the empirical risk and the open space risk. Our method does not need open intent samples and is free from modifying the model architecture. Moreover, our approach is surprisingly insensitive with less labeled data and fewer known intents. Extensive experiments on three benchmark datasets show that our method yields significant improvements compared with the state-of-the-art methods. The codes are released at https://github.com</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Identifying the user's open intent plays a significant role in dialogue systems. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, we have two known intents for specific purposes, such as book flight and restaurant reservation. However, there are also utterances with irrelevant or unsupported intents that our system cannot handle. It is necessary to distinguish these utterances from the known intents as much as possible. On the one hand, effectively identifying the open intent can improve customer satisfaction by reducing false-positive error. On the other hand, we can use the open intent to discover potential user needs.</p><p>We regard open intent classification as an (n+1)-class classification task as suggested in <ref type="bibr" target="#b29">(Shu, Xu, and Liu 2017;</ref><ref type="bibr" target="#b15">Lin and Xu 2019a)</ref>, and group open classes into the (n+1) th class . Our goal is to classify the n-class known intents into their corresponding classes correctly while identifying the (n+1) th class open intent. To solve this problem, Scheirer  <ref type="bibr" target="#b7">Fei and Liu (2016)</ref> reduce the open space risk by learning the closed boundary of each positive class in the similarity space. However, they fail to capture high-level semantic concepts with SVM. <ref type="bibr" target="#b1">Bendale and Boult (2016)</ref> manage to reduce the open space risk through deep neural networks (DNNs), but need to sample open classes for selecting the core hyperparameters. <ref type="bibr" target="#b9">Hendrycks and Gimpel (2017)</ref> use the softmax probability as the confidence score, but also need to select the confidence threshold with negative samples. <ref type="bibr" target="#b29">Shu, Xu, and Liu (2017)</ref> replace softmax with the sigmoid activation function, and calculate the confidence thresholds of each class based on statistics. However, the statistics-based thresholds can not learn the essential differences between known classes and the open class. <ref type="bibr" target="#b15">Lin and Xu (2019a)</ref> propose to learn the deep intent features with the margin loss and detect the unknown intent with local outlier factor <ref type="bibr" target="#b2">(Breunig et al. 2000)</ref>. However, it has no specific decision boundaries for distinguishing the open intent, and needs model architecture modification.</p><p>Most of the existing methods need to design specific classifiers for identifying the open class <ref type="bibr" target="#b1">(Bendale and Boult 2016;</ref><ref type="bibr" target="#b29">Shu, Xu, and Liu 2017;</ref><ref type="bibr" target="#b15">Lin and Xu 2019a)</ref>, and perform poorly with the common classifier <ref type="bibr" target="#b9">(Hendrycks and Gimpel 2017</ref> fication largely depends on the decision conditions. Most of these methods need negative samples for determining the suitable decision conditions <ref type="bibr" target="#b26">(Scheirer et al. 2013;</ref><ref type="bibr" target="#b7">Fei and Liu 2016;</ref><ref type="bibr" target="#b9">Hendrycks and Gimpel 2017;</ref><ref type="bibr" target="#b14">Liang, Li, and Srikant 2018)</ref>. It is also a complicated and time-consuming process to manually select the optimal decision condition, which is not applicable in real scenarios.</p><p>To solve these problems, we use known intents as prior knowledge, and propose a novel post-processing method to learn the adaptive decision boundary (ADB) for open intent classification. As illustrated in <ref type="figure">Figure 2</ref>, we first extract intent representations from BERT <ref type="bibr" target="#b5">(Devlin et al. 2019</ref>). Then, we pre-train the model under the supervision of the softmax loss. We define centroids for each known class and suppose intent features of each known class are constrained in a closed ball area. Next, we aim to learn the radius of the spherical area to obtain the decision boundaries. Specifically, we initialize the boundary parameters with standard normal distribution and use a learnable activation function as a projection to get the radius of each decision boundary.</p><p>The suitable decision boundaries should satisfy two conditions. On the one hand, they should be broad enough to surround known intent samples as much as possible. On the other hand, they need to be tight enough to prevent the open intent samples from being identified as known intents. To address these issues, we propose a new loss function, which optimizes the boundary parameters by balancing both the open space risk and the empirical risk <ref type="bibr" target="#b26">(Scheirer et al. 2013</ref>). The decision boundaries can automatically learn to adapt to the intent feature space with the boundary loss until balance. We find our post-processing method can learn discriminative decision boundaries for detecting the open intent even without modifying the original model architecture.</p><p>We summarize our contribution as follows. Firstly, we propose a novel post-processing method for open classification, with no need for prior knowledge of the open intent. Secondly, we propose a new loss function to automatically learn tight decision boundaries adaptive to the feature space. To the best of our knowledge, this is the first attempt to adopt deep neural networks to learn the adaptive decision boundaries for open classification. Thirdly, extensive experiments conducted on three challenging datasets show that our approach yields consistently better and more robust results compared with the state-of-the-art methods.</p><p>The Proposed Approach</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intent Representation</head><p>We use the BERT model to extract deep intent features. Given i th input sentence s i , we get all its token embeddings [CLS, T 1 , ? ? ? , T N ] ? R (N +1)?H from the last hidden layer of BERT. As suggested in <ref type="bibr" target="#b17">(Lin, Xu, and Zhang 2020)</ref>, we perform mean-pooling on these token embeddings to synthesize the high-level semantic features in one sentence, and get the averaged representation x i ? R H :</p><formula xml:id="formula_0">x i = mean-pooling([CLS, T 1 , ? ? ? , T N ]),<label>(1)</label></formula><p>where CLS is the vector for text classification, N is the sequence length and H is the hidden layer size. To further strengthen feature extraction capability, we feed x i to a dense layer h to get the intent representation z i ? R D :</p><formula xml:id="formula_1">z i = h(x i ) = ?(W h x i + b h ),<label>(2)</label></formula><p>where D is the dimension of the intent representation, ? is a ReLU activation function, W h ? R H?D and b h ? R D respectively denote the weights and the bias term of layer h. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-training</head><p>As the decision boundaries learn to adapt to the intent feature space, we need to learn intent representations at first. Due to lack of open intent samples, we use known intents as prior knowledge to pre-train the model. In order to reflect the effectiveness of the learned decision boundary, we use the simple softmax loss L s to learn the intent feature z i :</p><formula xml:id="formula_2">L s = ? 1 N N i=1 log exp(?(z i ) yi ) K j=1 exp(?(z i ) j ) ,<label>(3)</label></formula><p>where ?(?) is a linear classifier and ?(?) j are the output logits of the j th class. Then, we use the pre-trained model to extract intent features for learning decision boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adaptive Decision Boundary Learning</head><p>In this section, we propose our approach to learning the adaptive decision boundary (ADB) for open intent classification. First, we introduce the formulation of the decision boundary. Then, we propose our boundary learning strategy for optimization. Finally, we use the learned decision boundary to perform open classification.</p><p>Decision Boundary Formulation It has been shown the superiority of the spherical shape boundary for open classification <ref type="bibr" target="#b7">(Fei and Liu 2016)</ref>. Compared with the half-space binary linear classifier <ref type="bibr" target="#b28">(Sch?lkopf et al. 2001)</ref> or two parallel hyper-planes <ref type="bibr" target="#b26">(Scheirer et al. 2013)</ref>, the bounded spherical area greatly reduces the open space risk. Inspired by this, we aim to learn the decision boundary of each class constraining the known intents within a ball area. Let S = {(z i , y i ), . . . , (z N , y N )} be the known intent examples with their corresponding labels. S k denotes the set of examples labeled with class k. The centroid c k ? R D is the mean vector of embedded samples in S k :</p><formula xml:id="formula_3">c k = 1 |S k | (zi,yi)?S k z i ,<label>(4)</label></formula><p>where |S k | denotes the number of examples in S k . We define ? k as the radius of the decision boundary with respect to the centroid c k . For each known intent z i , we aim to satisfy the following constraints:</p><formula xml:id="formula_4">?z i ? S k , z i ? c k 2 ? ? k ,<label>(5)</label></formula><p>where z i ?c k 2 denotes the Euclidean distance between z i and c k . That is, we hope examples belonging to class k are constrained in the ball area with centroid c k and radius ? k . As radius ? k needs to be adaptive to the intent feature space, we use the deep neural network to optimize the learnable boundary parameter ? k ? R. As suggested in <ref type="bibr" target="#b31">(Tapaswi, Law, and Fidler 2019)</ref>, we use Softplus activation function as the mapping between ? k and ? k :</p><formula xml:id="formula_5">? k = log 1 + e ? k .<label>(6)</label></formula><p>The Softplus activation function has the following advantages. First, it is totally differentiable with different ? k ? R. Second, it can ensure the learned radius ? k is above zero. Finally, it achieves linear characteristics like ReLU and allows for bigger ? k if necessary.</p><p>Boundary Learning The decision boundaries should be adaptive to the intent feature space to balance both empirical and open space risk <ref type="bibr" target="#b0">(Bendale and Boult 2015)</ref>. For example, if z i ? c yi 2 &gt; ? yi , the known intent samples are outside their corresponding decision boundaries, which may introduce more empirical risk. Therefore, the decision boundaries need to expand to contain more samples from known classes. If z i ? c yi 2 &lt; ? yi , though more known intent samples are likely to be identified with broader decision boundaries, it may introduce more open intent samples and increase the open space risk. Thus, we propose the boundary loss L b :</p><formula xml:id="formula_6">L b = 1 N N i=1 [? i ( z i ? c yi 2 ? ? yi ) + (1 ? ? i ) (? yi ? z i ? c yi 2 )] ,<label>(7)</label></formula><p>where y i is the label of the i th sample and ? i is defined as:</p><formula xml:id="formula_7">? i := 1, if z i ? c yi 2 &gt; ? yi , 0, if z i ? c yi 2 ? ? yi .<label>(8)</label></formula><p>Then, we update the boundary parameter ? k regarding to L b as follows:</p><formula xml:id="formula_8">? k := ? k ? ? ?L b ? ? k ,<label>(9)</label></formula><p>where ? is the learning rate of the boundary parameters ?</p><formula xml:id="formula_9">and ?L b ? ? k is computed by: ?L b ? ? k = N i=1 ? (y i = k) ? (?1) ?i N i=1 ? (y i = k) ? 1 1 + e ? ? k ,<label>(10)</label></formula><p>where ? (y i = k) = 1 if y i = k and ? (y i = k) = 0 if not. We only update the radius ? yi belonging to class k in a mini-batch, which ensures the denominator is not zero. With the boundary loss L b , the boundaries can adapt to the intent feature space and learn suitable decision boundaries. The learned decision boundaries can not only effectively surround most of the known intent samples, but also not be far away from each known class centroid, which is effective to identify the open intent samples.  <ref type="table">Table 2</ref>: Results of open classification with different known class proportions (25%, 50% and 75%) on BANKING, OOS and StackOverflow datasets. "Accuracy" and "F1-score" respectively denote the accuracy score and macro F1-score over all classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open Classification with Decision Boundary</head><p>After training, we use the centroids and the learned decision boundaries of each known class for inference. We sup- </p><formula xml:id="formula_10">y = open, if d(z i , c k ) &gt; ? k , ?k ? Y; arg min k?Y d(z i , c k ), otherwise,<label>(11)</label></formula><p>where d(z i , c k ) denotes the Euclidean distance between z i and c k . Y = {1, 2, ? ? ? , K} denote the known intent labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Datasets</head><p>We conduct experiments on three challenging real-world datasets to evaluate our approach. The detailed statistics are shown in <ref type="table">Table 1</ref>.</p><p>BANKING A fine-grained dataset in the banking domain <ref type="bibr" target="#b4">(Casanueva et al. 2020)</ref>. It contains 77 intents and 13,083 customer service queries.</p><p>OOS A dataset for intent classification and out-of-scope prediction <ref type="bibr" target="#b13">(Larson et al. 2019)</ref>. It contains 150 intents, 22,500 in-domain queries and 1,200 out-of-domain queries.</p><p>StackOverflow A dataset published in Kaggle.com. It contains 3,370,528 technical question titles. We use the processed dataset <ref type="bibr" target="#b34">(Xu et al. 2015)</ref>, which has 20 different classes and 1,000 samples for each class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines</head><p>We compare our method with the following state-of-the-art open classification methods: OpenMax (Bendale and Boult 2016), MSP (Hendrycks and Gimpel 2017), DOC <ref type="bibr" target="#b29">(Shu, Xu, and Liu 2017)</ref> and DeepUnk <ref type="bibr" target="#b15">(Lin and Xu 2019a)</ref>. As OpenMax is an open set detection method in computer vision, we adapt it for open intent classification. We firstly use the softmax loss to train a classifier on known intents, then fit a Weibull distribution to the classifier's output logits. Finally, we recalibrate the confidence scores with the Open-Max Layer. Due to lack of open intent for tuning, we adopt default hyperparameters of OpenMax. We use the same confidence threshold (0.5) as in <ref type="bibr" target="#b15">(Lin and Xu 2019a)</ref> for MSP. For a fairness comparison, we replace the backbone network of these methods with the same BERT model as ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>Following previous work <ref type="bibr" target="#b29">(Shu, Xu, and Liu 2017;</ref><ref type="bibr" target="#b15">Lin and Xu 2019a)</ref>, we regard all the open classes as one rejected class. To evaluate the overall performance, we use accuracy score (Accuracy) and macro F1-score (F1-score) as metrics. They are calculated over all classes (known classes and open class). We also calculate macro F1-score over known classes and open class respectively, which better evaluates the finegrained performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Settings</head><p>Following the same settings as in <ref type="bibr">(Shu, Xu, and</ref>   <ref type="table">Table 3</ref>: Results of open classification with different known class ratios (25%, 50% and 75%) on BANKING, OOS and StackOverflow datasets. "Open" and "Known" denote the macro f1-score over open class and known classes respectively. For each known class ratio, we report the average performance over ten runs of experiments.</p><p>We employ the BERT model (bert-uncased, with 12-layer transformer) implemented in PyTorch <ref type="bibr" target="#b33">(Wolf et al. 2019</ref>) and adopt most of its suggested hyperparameters for optimization. To speed up the training procedure and achieve better performance, we freeze all but the last transformer layer parameters of BERT. The training batch size is 128, and the learning rate is 2e-5. For the boundary loss L b , we employ Adam <ref type="bibr" target="#b12">(Kingma and Ba 2014)</ref> to optimize the boundary parameters at a learning rate of 0.05. <ref type="table">Table 2</ref> and <ref type="table">Table 3</ref> show the performances of all compared methods, where the best results are highlighted in bold. Firstly, we observe the overall performance. <ref type="table">Table 2</ref> shows accuracy score and macro F1-score over all classes. With 25%, 50%, and 75% known classes, our approach consistently achieves the best results and outperforms other baselines by a significant margin. Compared with the best results of all baselines, our method improves accuracy score (Accuracy) on BANKING by 14.64%, 6.13%, and 2.56%, on OOS by 6.16%, 3.19%, and 2.61%, on StackOverflow by 38.88%, 27.42%, and 10.45% in 25%, 50% and 75% settings respectively, which demonstrates the priority of our method. Secondly, we notice that the improvements on StackOverflow are much more drastic than the other two datasets. We suppose the improvements mainly depend on the characteristics of datasets. Most baselines lack explicit or suitable decision boundaries for identifying the open intent, so they are more sensitive to different datasets. For example, they are limited to distinguish difficult semantic intents (e.g., technical question titles in StackOverflow) without prior knowledge. By contrast, our method learns specific and tight decision boundaries for each known class, which is more effective for open intent classification.  <ref type="figure">Figure 5</ref>: Influence of the labeled ratio on three datasets with different known class proportions (25%, 50%, 75%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Thirdly, we observe the fine-grained performance. <ref type="table">Table 3</ref> shows the macro F1-score on open intent and known intents respectively. We notice that our method not only achieves substantial improvements on open class, but also largely enhances the performances on known classes compared with baselines. That is because our method can learn specific and tight decision boundaries for detecting open class while ensuring the quality of known intent classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Boundary Learning Process <ref type="figure" target="#fig_2">Figure 3</ref> shows the decision boundary learning process. At first, most parameters are assigned small values near zero after initialization, which leads to small radius with the Softplus activation function. As the initial radius is too small, the empirical risk plays a dominant role. Therefore, the radius of each decision boundary expands to contain more known intent samples belonging to its class. As the training process goes on, the radius of the decision boundary learns to be large enough to contain most of the known intents. However, the large radius will also introduce redundant open intent samples. In this case, the open space risk plays a dominant role, which prevents the radius from en-larging. Finally, the decision boundaries converge with a balance between empirical risk and open space risk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Decision Boundary</head><p>To verify the effectiveness of the learned decision boundary, we use different ratios of ? as boundaries during testing. As shown in <ref type="figure" target="#fig_3">Figure 4</ref>, ADB achieves the best performance with ? among all assigned decision boundaries, which verifies the tightness of the learned decision boundary. Moreover, we notice that the performance of open classification is sensitive to the size of the decision boundaries. Overcompact decision boundaries will increase the open space risk by misclassifying more known intent samples to the open intent. Correspondingly, overrelaxed decision boundaries will increase the empirical risk by misclassifying more open intent samples as known intents. As shown in <ref type="figure" target="#fig_3">Figure 4</ref>, both of these two cases perform worse compared with ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Labeled Data</head><p>To investigate the influence of labeled data, we vary the labeled ratio in the training set in the range of 0.2, 0.4, 0.6, 0.8 and 1.0. We use Accuracy as the score to evaluate the performance. As shown in <ref type="figure">Figure 5</ref>, ADB outperforms all the other baselines on three datasets on almost all settings. Besides, it keeps a more robust performance under different labeled ratios compared with other methods.</p><p>Notably, the statistic-based methods (e.g., MSP and DOC) show better performances with less labeled data. We suppose the reason is that the predicted scores are in low-confidence with less prior knowledge for training, which is helpful to reject the open intent with the threshold. However, as the number of labeled data increases, these methods tend to be biased towards the known intents, with the aid of strong feature extraction capability of DNNs <ref type="bibr" target="#b21">(Nguyen, Yosinski, and Clune 2015)</ref>. Therefore, the performances drop dramatically.</p><p>In addition, we notice that OpenMax and DeepUnk are two competitive baselines. We suppose the reason is that they both leverage the characteristics of intent feature distribution to detect the open class. However, OpenMax computes centroids of each known class with only corrective positive training samples. The qualities of centroids are easily influenced by the number of training samples. DeepUnk adopts a density-based novelty detection algorithm to perform open classification, which is also limited to the prior knowledge of labeled data. Thus, their performances all drop dramatically with less labeled data, as shown in <ref type="figure">Figure 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Known Classes</head><p>We vary the known class ratio between 25%, 50% and 75%, and show the results in <ref type="table">Table 2 and Table 3</ref>. Firstly, we observe the overall performance in <ref type="table">Table 2</ref>. Compared with other methods, our method achieves huge improvements on all settings of three datasets. All baselines drop dramatically as the known class ratio decreases. By contrast, our method still achieves robust results on accuracy score with fewer training samples.</p><p>Then, we observe the fine-grained performance in Table 3. We notice that all baselines achieve high scores on known classes, but they are limited to identify the open intent and suffer poor performance. However, our method still yields the best results on both known classes and the open class. It further demonstrates that the suitable learned decision boundaries are helpful to both balance the empirical risk and the open space risk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intent Detection</head><p>There are many works for intent detection in dialogue systems in recent years <ref type="bibr" target="#b18">(Min et al. 2020;</ref><ref type="bibr" target="#b22">Qin et al. 2020;</ref><ref type="bibr" target="#b37">Zhang et al. 2019;</ref><ref type="bibr" target="#b6">E et al. 2019;</ref><ref type="bibr" target="#b23">Qin et al. 2019)</ref>. Nevertheless, they all make assumptions of closed world classification without the open intent. <ref type="bibr" target="#b30">Srivastava, Labutov, and Mitchell (2018)</ref> perform intent detection with the zero-shot learning (ZSL) method. However, ZSL is different from our task because it only contains novel classes during testing.</p><p>Unknown intent detection is a specific task for detecting the unknown intent. <ref type="bibr" target="#b3">Brychcin and Kr?l (2017)</ref> propose an unsupervised approach to modeling intents, but fail to utilize the prior knowledge of known intents. <ref type="bibr" target="#b11">Kim and Kim (2018)</ref> jointly train the in-domain (ID) classifier and outof-domain (OOD) detector but need to sample OOD utter-ances. <ref type="bibr" target="#b36">Yu et al. (2017)</ref> adopt adversarial learning to generate positive and negative samples for training the classifier. <ref type="bibr" target="#b25">Ryu et al. (2018)</ref> use a generative adversarial network (GAN) to train on the ID samples and detect the OOD samples with the discriminator. However, it has been shown that deep generative models fail to capture high-level semantics on realworld data <ref type="bibr" target="#b20">(Nalisnick et al. 2019;</ref><ref type="bibr" target="#b19">Mundt et al. 2019</ref>). Recent methods try to learn friendly features for detecting the unknown intent <ref type="bibr" target="#b15">(Lin and Xu 2019a;</ref><ref type="bibr" target="#b8">Gangal et al. 2020;</ref><ref type="bibr" target="#b35">Yan et al. 2020</ref>), but they need to modify the model architecture, and fail to construct specific decision boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open World Classification</head><p>At first, researchers use SVM to solve open set problems. One-class classifiers <ref type="bibr" target="#b28">(Sch?lkopf et al. 2001;</ref><ref type="bibr" target="#b32">Tax and Duin 2004)</ref> find the decision boundary based on the positive training data. For multi-class open classification, One-vs-all SVM <ref type="bibr" target="#b24">(Rifkin and Klautau 2004)</ref> trains the binary classifier for each class and treats the negative classified samples as the open class. <ref type="bibr" target="#b26">Scheirer et al. (2013)</ref> extend the method to computer vision and introduce the concept of open space risk. <ref type="bibr" target="#b10">Jain, Scheirer, and Boult (2014)</ref> estimate the unnormalized posterior probability of inclusion for open set problems. They fit the probability distributions to statistical Extreme Value Theory (EVT) by using a Weibull-calibrated multiclass SVM. <ref type="bibr" target="#b27">Scheirer, Jain, and Boult (2014)</ref> propose a Compact Abating Probability (CAP) model, which further improves the performance of Weibull-calibrated SVM by truncating the abating probability. However, all these methods need negative samples for selecting the decision boundary or probability threshold. Moreover, SVM cannot capture advanced semantic features of intents <ref type="bibr" target="#b16">(Lin and Xu 2019b)</ref>.</p><p>Recently, researchers use deep neural networks for open classification. OpenMax <ref type="bibr" target="#b1">(Bendale and Boult 2016)</ref> fits Weibull distribution to the outputs of the penultimate layer, but still needs negative samples for selecting the best hyperparameters. MSP (Hendrycks and Gimpel 2017) calculates the softmax probability of known samples and rejects the low confidence unknown samples with the threshold. ODIN <ref type="bibr" target="#b14">(Liang, Li, and Srikant 2018)</ref> uses temperature scaling and input preprocessing to enlarge the differences between known and unknown samples. However, both of them <ref type="bibr" target="#b9">(Hendrycks and Gimpel 2017;</ref><ref type="bibr" target="#b14">Liang, Li, and Srikant 2018)</ref> need unknown samples to select the confidence threshold artificially. DOC <ref type="bibr" target="#b29">(Shu, Xu, and Liu 2017)</ref> uses the sigmoid function and calculates the confidence threshold based on Gaussian statistics, but it performs worse when the output probabilities are not discriminative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we propose a novel post-processing method for open intent classification. After pre-training the model with labeled samples, our model can automatically learn specific and tight decision boundaries adaptive to the known intent feature space. Our method has no require for open intent or model architecture modification. Extensive experiments on three benchmark datasets show that our method yields significant improvements over the compared baselines, and is more robust with less labeled data and fewer known intents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An example of open intent classification. Book flight and Restaurant reservation are two known intents. We should identify them correctly while detecting the sentences with the open intent. et al. (2013) propose the concept of open space risk as the measure of open classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>pose known intent samples are constrained in the closed ball area produced by their corresponding centroids and decision boundaries. On the contrary, the open intent samples are outside any of the bounded spherical areas. Specifically, we perform open intent classification as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The boundary learning process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Influence of the learned decision boundary.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>). Moreover, the performance of open classi-Next, we propose the boundary loss to learn tight decision boundaries adaptive to the known intent feature space. Finally, we perform open classification with the learned decision boundaries to both identify known classes and detect the open class.</figDesc><table><row><cell></cell><cell cols="2">Dense Layer</cell><cell>Pre-training</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell></row><row><cell></cell><cell cols="2">Mean Pooling</cell><cell>BERT Embedding</cell><cell>2 ?</cell><cell>Boundary Adaption</cell></row><row><cell cols="3">Transformer Layers 12</cell><cell></cell><cell>?1</cell><cell>c 1</cell></row><row><cell></cell><cell>??</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Transformer Layers 1</cell><cell>Open Class</cell><cell>? 1 ? 2</cell><cell>c 2</cell></row><row><cell>[CLS]</cell><cell>Tok 1</cell><cell>?.</cell><cell>Tok N</cell><cell>?</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Known</cell><cell>? ?1</cell></row><row><cell></cell><cell cols="2">Inputs</cell><cell>Classes</cell><cell>?</cell></row></table><note>Figure 2: The model architecture of our approach. Firstly, we use BERT to extract intent features and pre-train the model with labeled samples. Then, we initialize the centroids {c i }K i=1 and the radius of decision boundaries {? i }K i=1 for each known class.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Statistics of BANKING, OOS and StackOverflow datasets. # indicates the total number of sentences.</figDesc><table><row><cell>Dataset</cell><cell>Classes</cell><cell>#Training</cell><cell>#Validation</cell><cell>#Test</cell><cell>Vocabulary Size</cell><cell>Length (max / mean)</cell></row><row><cell>BANKING</cell><cell>77</cell><cell>9,003</cell><cell>1,000</cell><cell>3,080</cell><cell>5,028</cell><cell>79 / 11.91</cell></row><row><cell>OOS</cell><cell>150</cell><cell>15,000</cell><cell>3,000</cell><cell>5,700</cell><cell>8,376</cell><cell>28 / 8.31</cell></row><row><cell>StackOverflow</cell><cell>20</cell><cell>12,000</cell><cell>2,000</cell><cell>6,000</cell><cell>17,182</cell><cell>41 / 9.18</cell></row><row><cell>Table 1:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Liu 2017; Lin and Xu 2019a), we keep some classes as unknown (open) and integrate them back during testing. All datasets are divided into training, validation and test sets. The number of known classes are varied with the proportions of 25%, 50%, and 75% in the training set. The remaining classes are regarded as one open class and removed from the training set. Both known classes and open class are used for testing.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">BANKING</cell><cell>OOS</cell><cell></cell><cell cols="2">StackOverflow</cell></row><row><cell></cell><cell>Methods</cell><cell>Open</cell><cell>Known</cell><cell>Open</cell><cell>Known</cell><cell>Open</cell><cell>Known</cell></row><row><cell></cell><cell>MSP</cell><cell>41.43</cell><cell>50.55</cell><cell>50.88</cell><cell>47.53</cell><cell>13.03</cell><cell>42.82</cell></row><row><cell></cell><cell>DOC</cell><cell>61.42</cell><cell>57.85</cell><cell>81.98</cell><cell>65.96</cell><cell>41.25</cell><cell>49.02</cell></row><row><cell>25%</cell><cell>OpenMax</cell><cell>51.32</cell><cell>54.28</cell><cell>75.76</cell><cell>61.62</cell><cell>36.41</cell><cell>47.89</cell></row><row><cell></cell><cell>DeepUnk</cell><cell>70.44</cell><cell>60.88</cell><cell>87.33</cell><cell>70.73</cell><cell>49.29</cell><cell>52.60</cell></row><row><cell></cell><cell>ADB</cell><cell>84.56</cell><cell>70.94</cell><cell>91.84</cell><cell>76.80</cell><cell>90.88</cell><cell>78.82</cell></row><row><cell></cell><cell>MSP</cell><cell>41.19</cell><cell>71.97</cell><cell>57.62</cell><cell>70.58</cell><cell>23.99</cell><cell>66.91</cell></row><row><cell></cell><cell>DOC</cell><cell>55.14</cell><cell>73.59</cell><cell>79.00</cell><cell>78.25</cell><cell>25.44</cell><cell>66.58</cell></row><row><cell>50%</cell><cell>OpenMax</cell><cell>54.33</cell><cell>74.76</cell><cell>81.89</cell><cell>80.54</cell><cell>45.00</cell><cell>70.49</cell></row><row><cell></cell><cell>DeepUnk</cell><cell>69.53</cell><cell>77.74</cell><cell>85.85</cell><cell>82.11</cell><cell>43.01</cell><cell>70.51</cell></row><row><cell></cell><cell>ADB</cell><cell>78.44</cell><cell>80.96</cell><cell>88.65</cell><cell>85.00</cell><cell>87.34</cell><cell>85.68</cell></row><row><cell></cell><cell>MSP</cell><cell>39.23</cell><cell>84.36</cell><cell>59.08</cell><cell>82.59</cell><cell>33.96</cell><cell>80.88</cell></row><row><cell></cell><cell>DOC</cell><cell>50.60</cell><cell>83.91</cell><cell>72.87</cell><cell>83.69</cell><cell>16.76</cell><cell>78.95</cell></row><row><cell>75%</cell><cell>OpenMax</cell><cell>50.85</cell><cell>84.64</cell><cell>76.35</cell><cell>73.13</cell><cell>44.87</cell><cell>82.11</cell></row><row><cell></cell><cell>DeepUnk</cell><cell>58.54</cell><cell>84.75</cell><cell>81.15</cell><cell>86.27</cell><cell>37.59</cell><cell>81.00</cell></row><row><cell></cell><cell>ADB</cell><cell>66.47</cell><cell>86.29</cell><cell>83.92</cell><cell>88.58</cell><cell>73.86</cell><cell>86.80</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported by seed fund of Tsinghua University (Department of Computer Science and Technology)-Siemens Ltd., China Joint Research Center for Industrial Intelligence and Internet of Things.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards Open World Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1893" to="1902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards open set deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1563" to="1572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LOF: identifying density-based local outliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Breunig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM sigmod record</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised Dialogue Act Induction using Gaussian Mixtures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brychcin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kr?l</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="485" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient Intent Detection with Dual Sentence Encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Temcinas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gerz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vulic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL WorkShop</title>
		<meeting>ACL WorkShop</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Novel Bidirectional Interrelated Model for Joint Intent Detection and Slot Filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5467" to="5471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Breaking the Closed World Assumption in Text Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="506" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Likelihood Ratios and Generative Classifiers for Unsupervised Out-of-Domain Detection in Task Oriented Dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gangal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Einolghozati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7764" to="7771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-Class Open Set Recognition Using Probability of Inclusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Scheirer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Joint Learning of Domain Classification and Out-of-Domain Detection with Dynamic Class Weighting for Satisficing False Acceptance Rates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-B</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="556" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An Evaluation Dataset for Intent Classification and Out-of-Scope Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mahendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Peper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Laurenzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-IJCNLP</title>
		<meeting>EMNLP-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1311" to="1316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep Unknown Intent Detection with Margin Loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-E</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5491" to="5496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A post-processing method for detecting unknown intent of dialogue system via pre-trained deep neural network classifier. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-E</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="page">104979</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Discovering New Intents via Constrained Deep Adaptive Clustering with Cluster Refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-E</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8360" to="8367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dialogue State Induction Using Neural Latent Variable Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3845" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Open Set Recognition Through Deep Neural Network Uncertainty: Does Out-of-Distribution Detection Require Generative Classifiers?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mundt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pliushch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV Workshops</title>
		<meeting>ICCV Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Do Deep Generative Models Know What They Don&apos;t Know?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gorur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep neural networks are easily fooled: High confidence predictions for unrecognizable images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="427" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">DCR-Net: A Deep Co-Interactive Relation Network for Joint Dialog Act Recognition and Sentiment Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8665" to="8672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Stack-Propagation Framework with Token-Level Intent Detection for Spoken Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2078" to="2087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">In Defense of One-Vs-All Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Rifkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klautau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="101" to="141" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Outof-domain Detection based on Generative Adversarial Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="714" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Toward Open Set Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Scheirer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>De Rezende Rocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sapkota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">35</biblScope>
			<biblScope unit="page" from="1757" to="1772" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Probability Models for Open Set Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Scheirer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Estimating the support of a high-dimensional distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1443" to="1471" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">DOC: Deep Open Classification of Text Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2911" to="2916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Zero-shot Learning of Classifiers from Natural Language Quantification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="306" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Video Face Clustering with Unknown Number of Clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5026" to="5035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Support Vector Data Description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="45" to="66" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brew</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<title level="m">HuggingFace&apos;s Transformers: Stateof-the-art Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Short Text Clustering via Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="62" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unknown Intent Detection Using Gaussian Mixture Model with an Application to Zero-shot Intent Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1050" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Open-Category Classification by Adversarial Sample Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3357" to="3363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Joint Slot Filling and Intent Detection via Capsule Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5259" to="5267" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
