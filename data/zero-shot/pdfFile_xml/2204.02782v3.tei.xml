<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GemNet-OC: Developing Graph Neural Networks for Large and Diverse Molecular Simulation Datasets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-09-30">30 Sep 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Gasteiger</surname></persName>
							<email>johannes.gasteiger@tum.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Shuaibi</surname></persName>
							<email>mshuaibi@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuroop</forename><surname>Sriram</surname></persName>
							<email>anuroops@fb.comfair@metaai</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
							<email>stephan.guennemann@tum.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ulissi</surname></persName>
							<email>zulissi@andrew.cmu.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
							<email>zitnick@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meta</forename><surname>Fair</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Ai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Das</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University ? FAIR</orgName>
								<address>
									<settlement>Meta</settlement>
									<region>AI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Technical University of Munich</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">GemNet-OC: Developing Graph Neural Networks for Large and Diverse Molecular Simulation Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-09-30">30 Sep 2022</date>
						</imprint>
					</monogr>
					<note>Published in Transactions on Machine Learning Research (09/2022) Technical University of Munich Work partially done during an internship at FAIR, Meta AI. FAIR, Meta AI Reviewed on OpenReview: https: // openreview. net/ forum? id= u8tvSxm4Bs 1 Published in Transactions on Machine Learning Research (09/2022)</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent years have seen the advent of molecular simulation datasets that are orders of magnitude larger and more diverse. These new datasets differ substantially in four aspects of complexity: 1. Chemical diversity (number of different elements), 2. system size (number of atoms per sample), 3. dataset size (number of data samples), and 4. domain shift (similarity of the training and test set). Despite these large differences, benchmarks on small and narrow datasets remain the predominant method of demonstrating progress in graph neural networks (GNNs) for molecular simulation, likely due to cheaper training compute requirements. This raises the question -does GNN progress on small and narrow datasets translate to these more complex datasets? This work investigates this question by first developing the GemNet-OC model based on the large Open Catalyst 2020 (OC20) dataset Chanussot et al. (2021). GemNet-OC outperforms the previous state-of-the-art on OC20 by 16 % while reducing training time by a factor of 10. We then compare the impact of 18 model components and hyperparameter choices on performance in multiple datasets. We find that the resulting model would be drastically different depending on the dataset used for making model choices. To isolate the source of this discrepancy we study six subsets of the OC20 dataset that individually test each of the above-mentioned four dataset aspects. We find that results on the OC-2M subset correlate well with the full OC20 dataset while being substantially cheaper to train on. Our findings challenge the common practice of developing GNNs solely on small datasets, but highlight ways of achieving fast development cycles and generalizable results via moderately-sized, representative datasets such as OC-2M and efficient models such as GemNet-OC. Our code and pretrained model weights are open-sourced at github.com/Open-Catalyst-Project/ocp.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine learning models for molecular systems have recently experienced a leap in accuracy with the advent of graph neural networks (GNNs) <ref type="bibr" target="#b23">(Gilmer et al., 2017;</ref><ref type="bibr">Gasteiger et al., 2020b;</ref><ref type="bibr" target="#b6">Batzner et al., 2021;</ref><ref type="bibr">Ying et al., 2021)</ref>. However, this progress has predominantly been demonstrated on datasets covering a limited set of systems <ref type="bibr" target="#b31">(Ramakrishnan et al., 2014)</ref> -sometimes even just single molecules ). To scale this success to large and diverse atomic datasets and real-world chemical experiments, models need to demonstrate their abilities along four orthogonal aspects: chemical diversity, system size, dataset size, and test set difficulty. The critical question then becomes: Do model improvements demonstrated on small and limited datasets generalize to large and diverse molecular systems?</p><p>Some results suggest that they should indeed generalize. GNN architectures for molecular simulations usually generalize between systems and datasets <ref type="bibr" target="#b41">(Unke &amp; Meuwly, 2019)</ref>. Moreover, models have been found to scale well with training set size <ref type="bibr" target="#b9">(Bornschein et al., 2020)</ref>. However, other works found that model changes can indeed break this behavior, albeit positing that this is limited to singular model properties <ref type="bibr" target="#b6">(Batzner et al., 2021)</ref>. It is generally accepted that certain hyperparameters should be adapted to each dataset, e.g. the learning rate, batch size, embedding size. However, there is no qualitative reason why only these "special" properties would be affected by the underlying dataset, while other aspects of model components would be unaffected. Changes in model trends between datasets have already been seen in other fields, e.g. in computer vision <ref type="bibr" target="#b28">(Kornblith et al., 2019)</ref>.</p><p>In this work, we set out to directly test the performance of model components and hyperparameters between datasets. We focus on changes around one baseline model instead of separate GNN architectures, since this most closely matches the fine-grained changes that are typical for model development. We develop the GemNet-OC baseline model based on the Open Catalyst 2020 dataset (OC20) <ref type="bibr" target="#b12">(Chanussot et al., 2021)</ref>, which is the largest molecular dataset to date. The resulting GemNet-OC model is 10 times cheaper to train than previous models and outperforms the previous state-of-the-art by 16 %. It incorporates optimizations that enable the calculation of quadruplet interactions and dihedral angles even in large systems, and introduces an interaction hierarchy to better model long-range interactions.</p><p>We analyze these new model components, as well as previously proposed components and hyperparameters, on two narrow datasets (MD17  and COLL <ref type="bibr">(Gasteiger et al., 2020a)</ref>), the large-scale OC20 dataset, and six OC20 subsets that isolate the effects of the aforementioned four dataset properties. We find that model components can indeed have substantially different effects on different datasets, and that all four dataset properties can cause such differences. Large and diverse datasets like OC20 thus pose a learning challenge that is qualitatively different from the smaller chemical spaces and structures represented in most prior molecular datasets.</p><p>Testing a model that can generalize well to the large diversity of chemistry thus requires a sufficiently large and diverse dataset. However, model development on large datasets like OC20 is excessively expensive due to long training times. As a case in point, the analyses and models presented in this work required more than 16 000 GPU days of training overall. To solve this issue, we identify a small data subset on which model trends correlate well with OC20: OC-2M. We provide multiple baseline results for OC-2M to enable its use in future work. Together, GemNet-OC and OC-2M enable state-of-the-art model development even on a single GPU. Our code and pretrained model weights are open-sourced at github.com/Open-Catalyst-Project/ocp. Concretely, our contributions are:</p><p>? We propose GemNet-OC, a GNN that achieves state-of-the-art results on all OC20 tasks while training is 10 times faster than previous large models. ? Through carefully-controlled experiments on a variety of datasets, we demonstrate the discrepancy between modeling decisions on small and limited vs. large and diverse datasets. ? We identify OC-2M, a small data subset that provides generalizable model insights, and publish a range of baseline results to enable its use in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and related work</head><p>Learning atomic interactions. A model for molecular simulations takes N atoms, their atomic numbers z = {z 1 , . . . , z N }, and positions X ? R N ?3 and predicts the system's energy E and the forces F ? R N ?3 acting on each atom. Note that these models usually do not use further auxiliary input information such as bond types, since these might be ill-defined in certain states. The force predictions are then used in a simulation to calculate the atoms' accelerations during a time step. Alternatively, we can find low-energy or relaxed states of the system by performing geometric optimization based on the atomic forces. More concretely, the atomic forces F are the energy's gradient, i.e. F i = ? ? ?xi E. The forces are thus conservative, which is important for the stability of long molecular dynamics simulations since it ensures energy conservation and path independence. However, in some cases we can ignore this requirement and predict forces directly, which considerably speeds up the model <ref type="bibr" target="#b29">(Park et al., 2021)</ref>. Classical approaches for molecular machine learning models use hand-crafted representations of the atomic neighborhood <ref type="bibr" target="#b3">(Bart?k et al., 2013)</ref> with Gaussian processes <ref type="bibr" target="#b2">(Bart?k et al., 2010;</ref> or neural networks <ref type="bibr" target="#b7">(Behler &amp; Parrinello, 2007;</ref><ref type="bibr" target="#b37">Smith et al., 2017)</ref>. However, these approaches have recently been surpassed consistently by graph neural networks (GNNs), in both low-data and large-data regimes <ref type="bibr" target="#b6">(Batzner et al., 2021;</ref><ref type="bibr" target="#b22">Gasteiger et al., 2021)</ref>.</p><p>Graph neural networks. GNNs represent atomic systems as graphs G = (V, E), with atoms defining the node set V. The edge set E is typically defined as all atoms pairs within a certain cutoff distance, e.g. 5 ?. The first models resembling modern GNNs were proposed by <ref type="bibr" target="#b39">Sperduti &amp; Starita (1997)</ref>; <ref type="bibr" target="#b5">Baskin et al. (1997)</ref>. However, they only became popular after multiple works demonstrated their potential for a wide range of graph-related tasks <ref type="bibr" target="#b11">(Bruna et al., 2014;</ref><ref type="bibr" target="#b27">Kipf &amp; Welling, 2017;</ref><ref type="bibr" target="#b19">Gasteiger et al., 2019)</ref>. Molecules have always been a major application for GNNs <ref type="bibr" target="#b5">(Baskin et al., 1997;</ref><ref type="bibr" target="#b17">Duvenaud et al., 2015)</ref>, and molecular simulation is no exception. Modern examples include SchNet <ref type="bibr">), PhysNet (Unke &amp; Meuwly, 2019</ref>, <ref type="bibr">Cormorant (Anderson et al., 2019)</ref>, DimeNet <ref type="bibr">(Gasteiger et al., 2020b)</ref>, PaiNN <ref type="bibr" target="#b42">(Sch?tt et al., 2021</ref><ref type="bibr">), SpookyNet (Unke et al., 2021</ref>, and SpinConv . Notably, MXMNet <ref type="bibr" target="#b46">(Zhang et al., 2020)</ref> proposes a two-level message passing scheme. Similarly, <ref type="bibr">Alon &amp; Yahav (2021)</ref> propose a global aggregation mechanism to fix a bottleneck caused by GNN aggregation. GemNet-OC extends these two-level schemes to a multi-level interaction hierarchy, and leverages both edge and atom embeddings.</p><p>Model trends between datasets. Previous work often found that models scale equally well with training set size <ref type="bibr" target="#b24">(Hestness et al., 2017)</ref>. This lead to the hypothesis that model choices on subsets of a dataset translate well to the full dataset <ref type="bibr" target="#b9">(Bornschein et al., 2020)</ref>. In contrast, we find that model choices can have different effects on small and large datasets, which implies different scaling for different model variants. Similarly, <ref type="bibr">Brigato &amp; Iocchi (2020)</ref> found that simple models work better than state-of-the-art architectures in the extremely small dataset regime, and <ref type="bibr" target="#b28">Kornblith et al. (2019)</ref> observed differences in model trends between datasets for computer vision. Note that we observe differences for subsets of the same dataset, and our findings do not require a dataset reduction to a few dozen samples -we observe qualitative differences even beyond 200 000 samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Datasets</head><p>Datasets for molecular simulation. Training a model for molecular simulation requires a dataset with the positions and atomic numbers of all atoms for the model input and the forces and energy as targets for its output. The energy is either the total inner energy, i.e. the energy needed to separate all electrons and nuclei, or the atomization energy, i.e. the energy needed to separate all atoms. Note that the energy is actually not necessary for learning a consistent force field. Most works weight the forces much higher than the energy or even train only on the forces. Many molecular datasets have been proposed in recent years, often with the goal of supporting model development for specific use cases. Arguably the most prominent, publicly available datasets are MD17 , ISO17 , S N 2 (Unke &amp; Meuwly, 2019), ANI-1x <ref type="bibr" target="#b38">(Smith et al., 2020)</ref>, QM7-X <ref type="bibr" target="#b25">(Hoja et al., 2020)</ref>, COLL <ref type="bibr">(Gasteiger et al., 2020a)</ref>, and OC20 <ref type="bibr" target="#b12">(Chanussot et al., 2021)</ref>. <ref type="table">Table 1</ref> gives an overview of these datasets. Note that datasets such as QM9 <ref type="bibr" target="#b31">(Ramakrishnan et al., 2014)</ref> or OQMD <ref type="bibr" target="#b33">(Saal et al., 2013)</ref> cannot be used for learning molecular simulations since they only contain systems at equilibrium, where all forces are zero. Other datasets such as DES370k <ref type="bibr" target="#b16">(Donchev et al., 2021)</ref> and OrbNet Denali <ref type="bibr" target="#b15">(Christensen et al., 2021)</ref> Table 1: Common molecular simulation datasets. Datasets prior to OC20 only cover (1) a narrow range of elements (and molecules), and consequently a low number of neighbor pairs (defined as distinct element pairs within 5 ?), and (2) small systems. Furthermore, they (3) provide far fewer samples and (4) often use a test set that is correlated with the training set since they consist of data from the same simulation trajectories. We investigate six OC20 subsets to isolate these effects. contain out-of-equilibrium systems but do not provide force labels. This makes them ill-suited for this task as well, since energies only provide one label per sample while forces provide 3N labels <ref type="bibr" target="#b14">(Christensen &amp; Lilienfeld, 2020)</ref>. In this work we focus on the OC20 dataset, which consists of single adsorbates (small molecules) physically binding to the surfaces of catalysts. The simulated cell of N atoms uses periodic boundary conditions to emulate the behavior of a crystal surface.</p><p>Dataset aspects. The difficulty and complexity of molecular datasets can largely be divided into four aspects: chemical diversity, system size, dataset size, and domain shift. Chemical diversity (number of atom types or interacting pairs) and system size (number of independent atoms) determine the data's complexity and thus the expressive power a model needs to fit this data. The dataset size determines the amount of data from which the model can learn. Note that a large dataset might still need a very sample-efficient model if the underlying data is very complex and diverse. Finally, we look at the test set's domain shift to determine its difficulty. The learning task might be significantly easier than expected if the test set is very similar to the training set. Note that many dataset aspects are not covered by these four properties, such as the method used for calculating the molecular data or the types of systems. OC20 has multiple details that fall into this category: It consists of periodic systems of a bulk material with an adsorbate on its surface, and has a canonical z-axis and orientation. These details also affect the importance of modeling choices, such as rotation invariance . We chose to focus on the above four properties since they are easy to quantify, apply to every dataset, and have a large effect by themselves.</p><p>Data complexity. Chemical diversity and system size determine the complexity of the underlying data: How many different atomic environments does the model need to fit? Are there long-range interactions or collective many-body effects caused by large systems? To quantify a dataset's chemical diversity we count the number of elements and the element pairs that occur within a range of 5 ? ("neighbor pairs"). However, note that these proxies are not perfect. For example, COLL only contains three elements but samples a significantly larger region of conformational space than QM7-X. Subsequently, SchNet only achieves a force MAE of 172 eV/? on COLL, but 53.7 eV/? on QM7-X (same trajectory). Still, these proxies do illustrate the stark difference between OC20 and other datasets: OC20 has 70? more neighbor pairs than other datasets <ref type="table">(Table 1)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset size.</head><p>Dataset size determines how much information is available for a model to learn from. Note that larger systems also increase the effective dataset size since each atom provides one force label. Usually, the dataset size should just be appropriately chosen to reach good performance for a given dataset complexity. <ref type="table">Table 1</ref> thus lists the official or a typical training set size for each dataset, and not the total dataset size. An extreme outlier in this respect is MD17. In principle it has 3 611 115 samples, i.e. 450 000 samples per each of the 8 molecule trajectories on average. This is extremely large for the simple task of fitting single small molecules close to their equilibrium. Most recent works thus only train on 1000 MD17 samples per molecule, i.e. less than 1 % of the dataset. Even in this setting, modern models fit the DFT data more closely than the DFT method fits the ground truth <ref type="bibr">(Gasteiger et al., 2020b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain shift.</head><p>A dataset's test set is another important aspect that determines a dataset's difficulty and how well it maps to real-world problems. In practice we apply a trained model to a new simulation, i.e. a different simulation trajectory than it was trained on. We might even want to apply it to a different, out-of-distribution (OOD) system. For example, the OC20 dataset contains OOD test sets with unseen adsorbates (ads.), catalysts (cat.) and both (ads.+cat.). However, many datasets are created by running a set of simulations and then randomly splitting up the data into the training and test sets. The data is thus taken from the same trajectories, which leads to strongly correlated training and test data: the test samples will never be significantly far away from the training samples. To properly decorrelate test samples, we have to either let enough simulation time pass between the training and test samples or use a separate simulation trajectory (sep. traj.</p><p>). An extreme case in this aspect is again MD17: its test samples are taken from the same, single trajectory and the same, single molecule as the training set. MD17 thus only measures minor generalization across conformational space, not chemical space. This severly limits the significance of results on MD17. Moreover, improvements demonstrated on MD17 might not even be useful due to the data's limited accuracy. The most likely reason for MD17's pervasiveness is that its small size makes model development fast and efficient, coupled with the hypothesis that discovered model improvements would work equally well on more complex datasets. Unfortunately, we found this hypothesis to be incorrect, as we show in more detail below. This raises the question: Which dataset aspect changes model performance between benchmarks? Answering this would allow us to create a dataset that combines the best of both worlds: fast development cycles and results that generalize to realistic challenges like OC20.</p><p>OC20 subsets. We investigate six subsets of the OC20 dataset to isolate the effects of each dataset aspect.</p><p>Comparing subsets of the same dataset ensures that the observed differences are only due to these specific aspects, and not due to other dataset properties. OC-Rb and OC-Sn reduce chemical diversity by restricting the dataset to a limited set of catalyst materials. We chose rubidium and tin since they are among the most frequent catalyst elements in OC20. We would expect similar results for other catalyst elements. OC-sub30 isolates the effect of small systems by only allowing up to 30 atoms per system. Note that this does not influence the number of neighbors per atom, since OC20 uses periodic boundary conditions. It does, however, impact its effective training size and might skew the selection of catalysts. OC-200k and OC-2M use random subsets of OC20, thus isolating the effect of dataset size. Finally, OC-XS investigates the combined effect of restricting the system size to 30 independent atoms and only using Rubidium catalysts. This also naturally decreases the dataset size. We apply these subsets to both the OC20 training and validation set in the same way. To investigate the effect of test set choice we additionally investigate OOD validation splits by taking the respective subsets of the OC20 OOD dataset as well. We use OOD catalysts and adsorbates ("OOD both") for OC-sub30, OC-200k, and OC-2M, and only OOD adsorbates for OC-Rb, OC-Sn, and OC-XS, since no OOD catalysts are available for these subsets. Additionally, we introduce a third validation set for OC-XS by splitting out random samples of the training trajectories. This selection mimicks the easier "same trajectory" test sets used e.g. by MD17  and COLL <ref type="bibr">(Gasteiger et al., 2020a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GemNet-OC</head><p>We investigate the effect of datasets on model choices by first developing a GNN on OC20, starting from the geometric message passing neural network (GemNet) <ref type="bibr" target="#b22">(Gasteiger et al., 2021)</ref>. While regular message passing neural networks (MPNNs) only embed each atom a as h a ? R H <ref type="bibr" target="#b23">(Gilmer et al., 2017)</ref>, GemNet additionally embeds the directed edges between atoms as m (ba) ? R Hm . Both embeddings are then updated in multiple learnable layers using neighboring atom and edge embeddings and the full geometric informationthe distances between atoms x ba , the angles between neighboring edges ? cab , and the dihedral angles defined via triplets of edges ? cabd . We call our new model GemNet-OC. GemNet-OC is well representative of previous models. It uses a similar architecture and the atomwise force errors are well correlated: The Spearman rank correlation to SchNet's force errors is 0.44, to DimeNet ++ 0.50, to SpinConv 0.46, and to GemNet 0.59. It is just slightly higher for a separately trained GemNet-OC model, at 0.66. We next describe the components we propose and investigate in GemNet-OC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model: Interaction: Message passing: A/T/Q-MP:</head><p>x ca denotes the layer's input, concatenation, ? a non-linearity, and yellow a layer with weights shared across interaction blocks. Numbers denote embedding sizes. Whether the input or output of the MP-block are atom or edge embeddings depends on the type of message passing. Difference between different variants (AA, AE, EA, AA, Q-MP) are shown via colors and dashed lines. Note that triplet components are also included in quadruplet interactions.</p><formula xml:id="formula_0">e (ca) RBF CBF x ca ? cab e (cab) CBF SBF x ca ? cab ? cabd e (cabd) SBF z Embedding Interaction Interaction Interaction Interaction ?(W ? ) Residual Residual ?(W ? ) h out,a 1 E ?(W ? ) Residual Residual ?(W ? ) m out,ca 1 ? x ca F a m (l?1) ca h (l?1) a Message passing Residual Residual Residual Atom emb + ?(W ) Residual + Atom emb + Residual Residual e CBF e SBF e RBF h a h c m (l) ca h (l) out,a m (l) out,ca h (l) a m (l?1) ca h (l?1) a ?(W ) EA-MP EE-MP Q-MP + Residual + AE-MP AA-MP + m (l) ca h (l) a W W ?(W ) m (l?1) db/ba / h b e (db) (ba) RBF ?(W ? ) W W e (abd) (cab) CBF T W W e (cabd) SBF d,b ?(W ? ) ?(W ? ) m ca + ca ? ac m ac m ca / h a</formula><p>Neighbors instead of cutoffs. GNNs for molecules typically construct an interatomic graph by connecting all atoms within a cutoff of 5 ? to 6 ?. Distances are then usually represented using a radial basis, which is multiplied with an envelope function to ensure a twice continuously differentiable function at the cutoff <ref type="bibr">(Gasteiger et al., 2020b)</ref>. This is required for well-defined force training if the forces are predicted via backpropagation. However, when we face the large chemical diversity of a dataset like OC20 there are systems where atoms are typically farther apart than 6 ?, and other systems where all neighboring atoms are closer than 3 ?. Using one fixed cutoff can thus cause a disconnected graph in some cases, which is detrimental for energy predictions, and an excessively dense graph in others, which is computationally expensive. To solve this dilemma, we propose to construct a graph from a fixed number of nearest neighbors instead of using a distance cutoff. This might initially seem problematic since it breaks differentiability for forces F = ? ? ?x E if two atoms switch order by moving some small ?. However, we found that this is not an issue in practice. The nearest neighbor graph leads to the same or better accuracy, triples GemNet-OC's throughput, provides easier control of computational and memory requirements, and ensures a consistent, fixed neighborhood size. <ref type="bibr">Gasteiger et al. (2020b)</ref>, GemNet represents distances x ba using spherical Bessel functions j l ( z ln cint x ba ) of order l, with the interaction cutoff c int and the Bessel function's n-th root z ln , and angular information using real spherical harmonics Y (l) m (? cab , ? cabd ) of degree l and order m. Note that the radial basis order l is coupled to the angular basis degree l. This basis thus requires calculating nl radial and lm angular functions. This becomes expensive for large systems with a large number of neighbors. If we embed k emb edges per atom and compute dihedral angles for k qint neighbors, we need to calculate O(N k qint k 2 emb ) basis functions. To reduce the basis's computational cost, we first decouple the radial basis from the angular basis by using Gaussian or 0-order Bessel functions, independent of the spherical harmonics. We then streamline the spherical harmonics by instead using an outer product of order 0 spherical harmonics, which simplify to Legendre polynomials Y</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simplified basis functions. As proposed by</head><formula xml:id="formula_1">(l) 0 (? cab )Y (m) 0 (? cabd ) = P l (cos ? cab )P m (cos ? cabd )</formula><p>. This only requires the normalized inner product of edge directions, not the angle. These simplified basis functions increase throughput by 29 %, without hurting accuracy.</p><p>Tractable quadruplet interactions. Next, we tackle GemNet's dihedral angle-based interactions for large systems. These 'quadruplet interactions' are notoriously expensive, since they scale as O(N k qint k 2 emb ). However, we observed that quadruplet interactions are mostly relevant for an atom's closest neighbors. Their benefits quickly flatten out as we increase k qint . We thus choose a low k qint = 8. This is substantially lower than our k emb = 30, since we found model performance to be rather sensitive to k emb . This is opposite to the original GemNet, where the quadruplet cutoff was larger than the embedding cutoff. Quadruplet interactions only cause an overhead of 31 % thanks to these optimizations, instead of the original 330 % <ref type="bibr" target="#b22">(Gasteiger et al., 2021)</ref>.</p><p>Interaction hierarchy. Using a low number of quadruplet interactions essentially introduces a hierarchy of expensive short-distance quadruplet interactions and cheaper medium-distance edge-to-edge interactions. We propose to extend this interaction hierarchy further by passing messages between the atom embeddings h a directly. This update has the same structure as GemNet's message passing, but only uses the distance between atoms. This atom-to-atom interaction is very cheap due to its complexity of O(N k emb ). We can thus use a long cutoff of 12 ? without any neighbor restrictions. To complement this interaction, we also introduce atom-to-edge and edge-to-atom message passing. These interactions also follow the structure of GemNet's original message passing. Each adds an overhead of roughly 10 %.</p><p>Further architectural improvements. We make three architectural changes to further improve GemNet-OC. First, we output an embedding instead of directly generating a separate prediction per interaction block. These embeddings are then concatenated and transformed using multiple learnable layers (denoted as MLP) to generate the overall prediction. This allows the model to better leverage and combine the different pieces of information after each interaction block. Second, we improve atom embeddings by adding a learnable MLP in each interaction block. This block is beneficial due to the new atom-to-atom, edge-to-atom, and atom-to-edge interactions, which directly use the atom embeddings. Third, we improve the usage of atom embeddings further by adding them to the embedding in each energy output block. This creates a direct path from atom embeddings to the energy prediction, which improves the information flow. These model changes add less than 2 % computational overhead. See <ref type="figure" target="#fig_0">Fig. 1</ref> for an overview of the GemNet-OC model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results on OC20</head><p>OC20 tasks. In the OC20 benchmark, predicting energies and forces is the first of three tasks, denoted as structure to energy and forces (S2EF). There are two important additional scores for this task besides the energy and force MAEs. The force cosine determines how correct the predicted force directions are and energy and forces within threshold (EFwT) measures how many structures are predicted "correctly", i.e. have predicted energies and forces sufficiently close to the ground-truth. The second task is initial structure to relaxed structure (IS2RS). In IS2RS we perform energy optimization from an initial structure using our model's force predictions as gradients. After the optimization process we measure whether the distance between our final relaxed structure and the true relaxed structure is below a variety of thresholds (average distance within threshold, ADwT), and whether additionally the structure's true forces are close to zero (average force below threshold, AFbT). The third task, initial structure to relaxed energy (IS2RE), is to predict the energy of this relaxed structure. An alternative to this relaxation-based approach is the so-called direct IS2RE approach. Direct models learn and predict energies directly using only the initial structures. This approach is much cheaper, but also less accurate. Our work focuses on the regular relaxation-based approach, which is centered around S2EF data and models. <ref type="table" target="#tab_1">Table 2</ref> we provide test results for all three OC20 tasks, as well as S2EF validation results, averaged over the in-distribution (ID), OOD-adsorbate, OOD-catalyst, and OOD-both datasets. To facilitate and accelerate future research, we provide multiple new baseline results on the smaller OC-2M subset for SchNet , DimeNet ++ <ref type="bibr">(Gasteiger et al., 2020a)</ref>, SpinConv , and GemNet-dT <ref type="bibr" target="#b22">(Gasteiger et al., 2021)</ref>. OC-2M is smaller but still well-representative of model choices on full OC20, as we will discuss in Sec. 6. We use the same OC20 test set for both the OC-2M and OC20 training sets. On full OC20 we additionally compare to CGCNN <ref type="bibr" target="#b43">(Xie &amp; Grossman, 2018)</ref>, ForceNet , </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results. In</head><formula xml:id="formula_2">- GemNet-OC-L-F+E - - - - - - - - - - - 348</formula><p>PaiNN <ref type="bibr" target="#b42">(Sch?tt et al., 2021)</ref>, and GemNet-XL <ref type="bibr">(Sriram et al., 2022)</ref>. Note that PaiNN uses our independent reimplementation of the original PaiNN architecture with the difference that forces are predicted directly from vectorial features via a gated equivariant block instead of gradients of the energy output. This breaks energy conservation but is essential for good performance on OC20. GemNet-Q <ref type="bibr" target="#b22">(Gasteiger et al., 2021)</ref> runs out of memory when training on OC20. GemNet-OC outperforms all previous models on both the OC-2M and OC20 training sets. GemNet-OC on OC-2M even performs on par with GemNet-dT on OC20, while using 70 times less training data. It also performs better than all previously proposed direct IS2RE models, such as 3D-Graphormer <ref type="bibr">(Ying et al., 2021)</ref>, which achieves an IS2RE MAE of 472.2 meV. Direct models have seen a lot of interest due to their fast training and development. The OC-2M S2EF dataset provides a similarly fast development method for relaxation-based models. After model selection, we can scale the model up to larger training sets and model sizes. We demonstrate this with the GemNet-OC-L model, which was trained on both the full OC20 and the OC-MD datasets. OC-MD complements the regular OC20 dataset with data points from molecular dynamics. We trained one model focussing on energy predictions (GemNet-OC-L-E) and a second one for force predictions (GemNet-OC-L-F). For IS2RE we then combined both in the GemNet-OC-L-F+E model. These models set the state of the art for all OC20 tasks. GemNet-OC even outperforms GemNet-XL, despite GemNet-XL being substantially larger and slower to train. Training time. <ref type="figure" target="#fig_1">Fig. 2</ref> shows that GemNet-OC surpasses the accuracy of GemNet-dT after 600 GPU hours. It is 40 % slower per sample than a performance-optimized version of GemNet-dT. However, if we consider that GemNet-OC uses four interaction blocks instead of three as in GemNet-dT, we see that the GemNet-OC architecture is roughly as fast as GemNet-dT overall. GemNet-OC-L is roughly 4.5 times slower per sample but still converges faster, surpassing regular GemNet-OC after 2800 GPU hours. GemNet-OC-L reaches the final accuracy of GemNet-XL in 10 times fewer GPU hours, and continues to improve further. Combined with GemNet-OC's good results on the OC-2M dataset, this fast convergence allows for much faster model development.</p><p>Overall, GemNet-OC shows that we can substantially improve a model like GemNet if we focus development on the Most datasets are insensitive to the batch size above a certain size. Large datasets strongly benefit from large models, while small datasets exhibit optima at small sizes. target dataset. However, this does not yet answer the question of how its model choices would change if we focused on another dataset. We will investigate this question in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Model trends across datasets</head><p>For the purpose of comparing model choices between datasets we run all ablations and senstivity analyses on the Aspirin molecule of MD17, the COLL dataset, the full OC20 dataset, and the OC-Rb, OC-Sn, OC-sub30, OC-200k, OC-2M, and OC-XS data subsets. For consistency we use the same training procedure on all datasets, varying only the batch size. If not noted otherwise, we present results on the separate validation trajectories for Open Catalyst datasets. To simplify the discussion we primarily focus on force mean absolute error (MAE), and show changes as relative improvements compared to the GemNet-OC baseline MAE GemNet-OC MAE ? 1. We additionally report median relative improvements in throughput (samples per GPU second). We train the baseline model five times for every dataset, but train each ablation only once due to computational restrictions. We assume that the ablations have the same standard deviation as the baseline, and show uncertainties based on the 68 % confidence intervals, calculated using the student's t-distribution for the baseline mean, the standard deviation for the ablations, and appropriate propagation of uncertainty. For further details see App. A.</p><p>Model width and depth. In general, we would expect larger models to perform better since all investigated settings lie well inside the over-parametrization regime <ref type="bibr" target="#b8">(Belkin et al., 2019)</ref>. However, the edge embedding size (model width) and the number of blocks (depth) in <ref type="figure" target="#fig_2">Fig. 3</ref> actually exhibit optima for most datasets instead of a strictly increasing trend. Importantly and perhaps unsurprisingly, these optima differ between datasets. MD17 exhibits a clear optimum at a low width and depth, and also COLL, OC-200k and OC-sub30 exhibit shallow optima at low width. These optima appear to be mostly present for datasets with a low number of samples compared to its high data complexity and a dissimilar validation set (see <ref type="figure" target="#fig_0">Fig. 11</ref> for results on the OOD validation set). Accordingly, we observe the greatest benefit from model size for the largest datasets and in-distribution molecules. We observe a similar effect for other embedding sizes such as the projection size of basis functions. Increasing the projection size yields minor improvements only for OC20 (see <ref type="figure" target="#fig_0">Fig. 10</ref>). Overall, we notice that increasing the model size further only leads to modest accuracy gains, especially for OOD data. This suggest that molecular machine learning cannot be solved by scaling models alone. Note that this result might be impacted by model initialization <ref type="bibr" target="#b44">(Yang et al., 2021)</ref>.</p><p>Batch size. In <ref type="figure" target="#fig_2">Fig. 3</ref> we see that most datasets exhibit optima around a batch size of 32 to 128. However, there are substantial differences between datasets. MD17 has a particularly low optimal batch size, as do OOD validation sets (see <ref type="figure" target="#fig_0">Fig. 11</ref>). MD17 and OOD sets might thus benefit from the regularization effect caused by a small batch size. We also observed that convergence speed is fairly consistent across batch sizes if we focus on the number of samples seen during training, not the number of gradient steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neighbors and cutoffs.</head><p>The first two sections of <ref type="figure">Fig. 4</ref> shows the impact of the cutoff, the number of neighbors and the number of quadruplets. Their trends are mostly consistent between datasets, albeit with wildly different impact strengths. For the small molecules in MD17 and COLL the large default cutoff causes a fully-connected interatomic graph, which performs substantially better. Importantly, the default nearest neighbor-based graph performs better than cutoffs on OC20. The number of quadruplets has a surprisingly small impact on model performance on all datasets. We observe a small improvement only for 20 quadruplets, which is likely not worth the associated 20 % runtime overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basis functions.</head><p>An intruiging trend emerges when comparing 6 and 32 Bessel functions with the default 128 Gaussian basis functions (third section of <ref type="figure">Fig. 4)</ref>: Bessel functions perform substantially better on datasets with small chemical diversity, such as MD17, OC-XS, OC-Rb, and OC-Sn. However, this trend completely reverses on large datasets such as OC20. Multi-order Bessel functions also fit within this trend, as shown in the fourth section of <ref type="figure">Fig. 4</ref>. 6 multi-order Bessel functions perform somewhere between 6 and 32 Bessel functions, since they provide more information than regular 0-order Bessel functions. However, they are significantly slower and thus not recommended. Simplifying the spherical basis part has a similar effect: The outer product of Legendre polynomials is faster and works as well as spherical Harmonics across all datasets.</p><p>Ablation studies. In <ref type="figure">Fig. 5</ref>  OC-2M gives the most similar results to OC20.</p><p>consistent impact across datasets. The additional interactions in GemNet-OC show little to no impact on in-distribution OC20, but are beneficial for OC20 out-of-distribution data (see <ref type="figure" target="#fig_0">Fig. 13</ref>). The atom-to-edge and edge-to-atom interactions furthermore lead to faster convergence, as shown in <ref type="figure">Fig. 6</ref>. Importantly, the impact of these interactions is different on each dataset, varying between significantly negative to significantly positive results. Similarly, the proposed architectural improvements usually have either no or a small positive effect at convergence, but drastically hurt performance on COLL. Predicting forces via backpropagation is another model choice that works well on small datasets (MD17, COLL), but does not benefit the full OC20 dataset. Unfortunately, training GemNet-OC on OC20 with backpropagated forces is too unstable to train reliably and report here.</p><p>Correlation between datasets. To quantify the overall similarity of model performance between datasets we calculate the Kendall rank correlation coefficient of the force MAEs on one dataset to each other dataset. Each model variant represents one data point in this calculation. We exclude the batch size experiments since this result seems too obvious. We additionally show a hierarchical clustering based on the nearest point algorithm. <ref type="figure">Fig. 7</ref> shows that OC-2M provides the most similar results to OC20. Interestingly, OC-2M is roughly as similar to OC20 as early stopping or the OOD test set (see <ref type="figure">Fig. 9</ref>). This good correlation is due to OC-2M capturing the same chemical diversity and test difficulty thanks to uniform sampling. It is not an outlier in this respect: We independently sampled five 2M subsets and observed a standard deviation in GemNet-OC force MAE of merely 0.9 %. We furthermore observe that MD17 is especially different from OC20. The OOD validation set <ref type="figure" target="#fig_0">(Fig. 14)</ref> shows similar results. Note that these aggregate results hide the fact that some model choices, such as using quadruplets, are very consistent between datasets, while others are very different, such as the choice of radial basis. Based on these results we conclude that a dataset should cover the same chemical diversity to be reflective of a large and diverse dataset. Both the less diverse systems in OC-Rb and OC-Sn and the smaller systems in OC-sub30 show a larger difference in model choices. And these differences add up: Results on OC-XS are even more different. We can preserve this diversity by uniformly subsampling the dataset (OC-2M), but this still breaks down if we reduce the dataset too much . The choice of test set also seems to play a critical role. For example, the OC20 OOD validation set is only slightly closer to in-distribution than OC-2M, and the OC-XS "same trajectory" validation set is very different to regular OC-XS. Note that domain shift appears to make tasks particularly difficult. This is indicated by the (absolute) force MAE: 99.1 meV/? for OOD on OC-XS, 16.0 meV/? for separate trajectories (regular validation set), and 3.2 meV/? for same trajectories.</p><p>Overall, it appears that correlated model choices require datasets to have comparable difficulty and complexity, as given by chemical diversity, domain shift, and sufficient training set size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work we studied the effect of developing GNNs on a large dataset instead of small benchmarks. We proposed the GemNet-OC model, which is substantially faster to train than previous models and sets the state of the art on all OC20 tasks. We then investigated how model choices in GemNet-OC differ between datasets. We found that model components and hyperparameters can have disparate or even opposite effects between datasets, even within the single task of force predictions. We studied the source of this effect by selecting data subsets that individually change four main data complexity aspects. This resulted in two insights: First, consistent model choices require datasets with comparable difficulty and complexity, as given by their chemical diversity, domain shift, and a sufficiently large training set. Second, we can create a well-correlated proxy dataset by uniformly sampling a sufficiently large data subset. The resulting OC-2M dataset allows model development for the massive OC20 dataset at a fraction of the computational cost. To support future model research we provide a range of baseline results for this dataset. Overall, this case study highlights that researchers should exercise caution during model development, since model choices can vary drastically when changing relevant dataset properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Training and hyperparameters</head><p>All dataset and model ablations used the same base model hyperparameters detailed in <ref type="table" target="#tab_3">Table 3</ref>. Base effective batch sizes (see <ref type="table" target="#tab_4">Table 4</ref>) varied across dataset ablations in order to reach convergence in a reasonable amount of time across the large dataset size differences. MD17 and COLL ablations used a learning rate scheduler consistent with that of <ref type="bibr" target="#b22">Gasteiger et al. (2021)</ref> -linear warmup, exponential decay, and reduce on plateau. OC ablations only used reduce on plateau, with evaluations performed after a fixed number of steps (1k or 5k) instead of after each epoch. MD17, COLL, OC-Rb, OC-XS, and OC-200k were trained on 40GB NVIDIA A100 cards with the remaining datasets trained on 32GB NVIDIA V100 cards. We provide the hyperparameters for our best performing model variant, GemNet-OC-Large in <ref type="table" target="#tab_3">Table 3</ref>.</p><p>OC energies were standardized by subtracting the mean energy of the dataset and dividing by the standard deviation. Forces were divided by the same energy standard deviation in order to ensure consistency with their physical relationship: F = ?dE dx . For MD17 and COLL, only the mean energy was subtracted <ref type="bibr" target="#b22">Gasteiger et al. (2021)</ref>. All models were trained within the ocp repository and optimized to the following loss function (1)</p><formula xml:id="formula_3">L(X, z) = ? f ? (X, z) ??(X, z) + ? N N n=1 3 ?=1 g ?,n? (X, z) ?F n? (X, z) 2 ,<label>(1)</label></formula><p>where ? corresponds to the energy coefficient, ? corresponds to the force coefficient, X are the atom coordinates, z are the atomic numbers, f ? and g ? are learnable functions with shared parameters ?,? is the ground-truth energy, andF are the ground-truth forces. All model ablations make direct force predictions. Although models on the MD17 and COLL datasets generally perform better with gradient-based force predictions g ?,n? (X, z) = ?f ? (X,z) ?xn? , the same is not true for OC20 datasets. Gradient-based models on this dataset often run into numerical instabilities and hit NaNs very early in training. All models were optimized using AMSGrad <ref type="bibr" target="#b32">Reddi et al. (2018)</ref> and trained for a max number of epochs (4) or until the learning rate has been exhaustively stepped, whichever comes first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional experimental results</head><p>Early stopping. To obtain model results faster one might be tempted to stop model training early and draw conclusions from early model performance. However, as shown in <ref type="figure">Fig. 6</ref>, early results can be misleading and often do not reflect final performance. <ref type="figure">Fig. 8</ref> shows that early stopping also has a strong effect on the choice of basis function, similar to chemical diversity. While a large Bessel basis works substantially better early in training, this trend reverses when the model approaches convergence. Overall, results only become well-correlated with final OC20 accuracy late in training (see <ref type="figure">Fig. 9</ref>. Stopping training early should thus not be considered as a way of accelerating model development).</p><p>Complementary results. Complementary to the results in the main paper, Figs. 11 to 14 visualize similar plots across the out-of-distribution splits of the proposed datasets. Tables 5 to 8 separately show the test results for each OC20 test split.    Rel. improvement (%)</p><formula xml:id="formula_4">OC-XS OC-Rb OC-Sn OC-sub30 OC-200k</formula><p>OC-2M OC20 <ref type="figure" target="#fig_0">Figure 12</ref>: Impact of cutoffs, neighbors, and basis functions on force MAE for the OOD validation set. The Bessel basis performs signficantly better on datasets with small chemical diversity, but worse on OC20consistent with the in-distribution trends.       </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Main parts of the GemNet-OC architecture. Changes are highlighted in orange .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Convergence of GemNet-OC and previous models. GemNet-OC surpasses GemNet-dT after 600 GPU hours, and is ?12x faster than GemNet-XL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Effect of batch size, edge embedding size, and number of blocks on force MAE and throughput.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Impact of cutoffs, neighbors, and basis functions on force MAE and training throughput compared to the baseline using a cutoff of 12 ?, 30 neighbors, 8 quadruplets, Legendre polynomials as angular, and Gaussians as radial basis. Notably, the radial Bessel basis performs significantly better on datasets with small chemical diversity, but worse on full OC20.c a li n g fa c t o r s N o s y m m e t r ic M P N o q u a d r u p le t in t . N o a t o m -a t o m in t . N o a t o m -e d g e in t . N o e d g e -a t o m in t . N o g lo b a l o u t p u t M L P N o a t o m e m b . in o Ablation studies of various components proposed by GemNet and GemNet-OC for force MAE and throughput. Some model changes show consistent improvements (e.g. the quadruplet interaction), while others have very different effects for different datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Convergence of model ablations for OC20. Atom-edge and edge-atom interactions, and the global output MLP improve convergence, while atom-atom interactions, the atom MLP, and atom embeddings in the output have no positive effect. Note that step-like improvements are due to adaptive learning rate steps. Kendall rank correlation of model force MAEs between datasets and resulting hierarchical clustering. Results vary strongly between datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 10 :</head><label>10</label><figDesc>Impact of basis projection sizes on force MAE. Large projection sizes have a minor beneficial effect on OC20, while being detrimental on almost all smaller datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 11 :</head><label>11</label><figDesc>Effect of batch size, edge embedding size, and number of blocks on force MAE for the OOD validation set. Model size optima emerge on most datasets as we move to the OOD dataset. Note that OC-XS, OC-Rb, and OC-Sn use in-distribution catalysts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 14 :</head><label>14</label><figDesc>Kendall rank correlation of model force MAEs and resulting hierarchical clustering of datasets and different validation sets. Positive correlations are annotated. OC-2M is the most correlated to OC20, both in-and out-of-distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Training throughput and results for the validation set and the three test tasks of OC20, averaged across all four splits. GemNet-OC-L outperforms prior models by 16 %. GemNet-OC trained on OC-2M outperforms all pre-GemNet models trained on the full OC20 dataset (?134 M samples).</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Throughput</cell><cell></cell><cell cols="2">S2EF validation</cell><cell></cell><cell></cell><cell>S2EF test</cell><cell></cell><cell></cell><cell></cell><cell>IS2RS</cell><cell>IS2RE</cell></row><row><cell cols="2">Train</cell><cell></cell><cell cols="11">Samples / Energy MAE Force MAE Force cos EFwT Energy MAE Force MAE Force cos EFwT AFbT ADwT Energy MAE</cell></row><row><cell cols="3">set Model</cell><cell>GPU sec. ?</cell><cell>meV ?</cell><cell>meV/? ?</cell><cell>?</cell><cell>% ?</cell><cell>meV ?</cell><cell>meV/? ?</cell><cell>?</cell><cell cols="3">% ? % ? % ?</cell><cell>meV ?</cell></row><row><cell></cell><cell></cell><cell>SchNet</cell><cell>-</cell><cell>1400</cell><cell>78.3</cell><cell>0.109</cell><cell>0.00</cell><cell>1370</cell><cell>77.1</cell><cell>0.116</cell><cell>0.00</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>OC-2M</cell><cell></cell><cell>DimeNet ++ SpinConv GemNet-dT</cell><cell>---</cell><cell>805 406 358</cell><cell>65.7 36.2 29.5</cell><cell>0.217 0.479 0.557</cell><cell>0.01 0.13 0.61</cell><cell>761 401 323</cell><cell>63.0 35.5 28.1</cell><cell>0.222 0.475 0.559</cell><cell cols="3">0.01 0.13 0.69 16.7 54.8 ----</cell><cell>--438</cell></row><row><cell></cell><cell></cell><cell>GemNet-OC</cell><cell>-</cell><cell>286</cell><cell>25.7</cell><cell cols="2">0.598 1.06</cell><cell>274</cell><cell>24.3</cell><cell cols="4">0.603 1.25 19.6 56.4</cell><cell>407</cell></row><row><cell></cell><cell></cell><cell>CGCNN</cell><cell>-</cell><cell>590</cell><cell>74.0</cell><cell>0.142</cell><cell>0.01</cell><cell>608</cell><cell>73.3</cell><cell>0.146</cell><cell>0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>SchNet</cell><cell>-</cell><cell>549</cell><cell>56.8</cell><cell>0.297</cell><cell>0.06</cell><cell>540</cell><cell>54.7</cell><cell>0.302</cell><cell>0.06</cell><cell>-</cell><cell>14.4</cell><cell>764</cell></row><row><cell></cell><cell></cell><cell>ForceNet-large</cell><cell>15.3</cell><cell>-</cell><cell>33.5</cell><cell>0.515</cell><cell>-</cell><cell>-</cell><cell>32.0</cell><cell>0.516</cell><cell cols="3">0.01 12.7 49.6</cell><cell>-</cell></row><row><cell>OC20</cell><cell></cell><cell>DimeNet ++ -L-F+E PaiNN SpinConv</cell><cell>4.6 60.0 6.0</cell><cell>515 -371</cell><cell>32.8 -41.2</cell><cell>0.541 -0.473</cell><cell>0.00 -0.05</cell><cell>480 341 336</cell><cell>31.3 33.1 29.7</cell><cell>0.544 0.491 0.539</cell><cell cols="3">0.00 21.7 51.7 0.46 11.7 48.5 0.45 16.7 53.6</cell><cell>559 471 437</cell></row><row><cell></cell><cell></cell><cell>GemNet-dT</cell><cell>25.8</cell><cell>315</cell><cell>27.2</cell><cell>0.594</cell><cell>0.54</cell><cell>292</cell><cell>24.2</cell><cell>0.616</cell><cell cols="3">1.20 27.6 58.7</cell><cell>400</cell></row><row><cell></cell><cell></cell><cell>GemNet-XL</cell><cell>1.5</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>270</cell><cell>20.5</cell><cell>0.660</cell><cell cols="3">1.81 30.8 62.7</cell><cell>371</cell></row><row><cell></cell><cell></cell><cell>GemNet-OC</cell><cell>18.3</cell><cell>244</cell><cell>21.7</cell><cell cols="2">0.662 2.07</cell><cell>233</cell><cell>20.7</cell><cell cols="4">0.666 2.50 35.3 60.3</cell><cell>355</cell></row><row><cell>OC20+</cell><cell>OC-MD</cell><cell>GemNet-OC-L-E GemNet-OC-L-F</cell><cell>7.5 3.2</cell><cell>239 252</cell><cell>22.1 20.0</cell><cell cols="2">0.662 0.687 2.51 2.30</cell><cell>230 241</cell><cell>21.0 19.0</cell><cell cols="4">0.665 0.691 2.97 40.6 60.4 2.80 --</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Model hyperparameters for the baseline configuration and our GemNet-OC-Large model.</figDesc><table><row><cell>Hyperparameters</cell><cell>Base</cell><cell>GemNet-OC-Large</cell></row><row><cell>No. spherical basis</cell><cell>7</cell><cell>7</cell></row><row><cell>No. radial basis</cell><cell>128</cell><cell>128</cell></row><row><cell>No. blocks</cell><cell>4</cell><cell>6</cell></row><row><cell>Atom embedding size</cell><cell>256</cell><cell>256</cell></row><row><cell>Edge embedding size</cell><cell>512</cell><cell>1024</cell></row><row><cell>Triplet edge embedding input size</cell><cell>64</cell><cell>64</cell></row><row><cell>Triplet edge embedding output size</cell><cell>64</cell><cell>128</cell></row><row><cell>Quadruplet edge embedding input size</cell><cell>32</cell><cell>64</cell></row><row><cell>Quadruplet edge embedding output size</cell><cell>32</cell><cell>32</cell></row><row><cell>Atom interaction embedding input size</cell><cell>64</cell><cell>64</cell></row><row><cell>Atom interaction embedding output size</cell><cell>64</cell><cell>64</cell></row><row><cell>Radial basis embedding size</cell><cell>16</cell><cell>32</cell></row><row><cell>Circular basis embedding size</cell><cell>16</cell><cell>16</cell></row><row><cell>Spherical basis embedding size</cell><cell>32</cell><cell>64</cell></row><row><cell>No. residual blocks before skip connection</cell><cell>2</cell><cell>2</cell></row><row><cell>No. residual blocks after skip connection</cell><cell>2</cell><cell>2</cell></row><row><cell>No. residual blocks after concatenation</cell><cell>1</cell><cell>4</cell></row><row><cell>No. residual blocks in atom embedding blocks</cell><cell>3</cell><cell>3</cell></row><row><cell>No. atom embedding output layers</cell><cell>3</cell><cell>3</cell></row><row><cell>Cutoff</cell><cell>12.0</cell><cell>12.0</cell></row><row><cell>Quadruplet cutoff</cell><cell>12.0</cell><cell>12.0</cell></row><row><cell>Atom edge interaction cutoff</cell><cell>12.0</cell><cell>12.0</cell></row><row><cell>Atom interaction cutoff</cell><cell>12.0</cell><cell>12.0</cell></row><row><cell>Max interaction neighbors</cell><cell>30</cell><cell>30</cell></row><row><cell>Max quadruplet interaction neighbors</cell><cell>8</cell><cell>8</cell></row><row><cell>Max atom edge interaction neighbors</cell><cell>20</cell><cell>20</cell></row><row><cell>Max atom interaction neighbors</cell><cell>1000</cell><cell>1000</cell></row><row><cell>Radial basis function</cell><cell>Gaussian</cell><cell>Gaussian</cell></row><row><cell>Circular basis function</cell><cell cols="2">Spherical harmonics Spherical harmonics</cell></row><row><cell>Spherical basis function</cell><cell>Legendre Outer</cell><cell>Legendre Outer</cell></row><row><cell>Quadruplet interaction</cell><cell>True</cell><cell>True</cell></row><row><cell>Atom edge interaction</cell><cell>True</cell><cell>True</cell></row><row><cell>Edge atom interaction</cell><cell>True</cell><cell>True</cell></row><row><cell>Atom interaction</cell><cell>True</cell><cell>True</cell></row><row><cell>Direct forces</cell><cell>True</cell><cell>True</cell></row><row><cell>Activation</cell><cell>Silu</cell><cell>Silu</cell></row><row><cell>Optimizer</cell><cell>AdamW</cell><cell>AdamW</cell></row><row><cell>Force coefficient</cell><cell>100</cell><cell>100</cell></row><row><cell>Energy coefficient</cell><cell>1</cell><cell>1</cell></row><row><cell>EMA decay</cell><cell>0.999</cell><cell>0.999</cell></row><row><cell>Gradient clip norm threshold</cell><cell>10</cell><cell>10</cell></row><row><cell>Learning rate</cell><cell>0.001</cell><cell>0.0005</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Training hyperparameters across all proposed datasets.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="8">OC-20 OC-2M OC-200k OC-sub30 OC-XS OC-Rb OC-Sn MD17 COLL</cell></row><row><cell cols="4">Effective batch size 128</cell><cell>64</cell><cell>64</cell><cell>64</cell><cell></cell><cell>16</cell><cell>64</cell><cell>16</cell><cell>1</cell><cell>32</cell></row><row><cell cols="2">No. GPUs</cell><cell></cell><cell>16</cell><cell>8</cell><cell>4</cell><cell>2</cell><cell></cell><cell>1</cell><cell>4</cell><cell>2</cell><cell>1</cell><cell>1</cell></row><row><cell cols="2">Max epochs</cell><cell></cell><cell>80</cell><cell>80</cell><cell>50</cell><cell>50</cell><cell></cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>10000 1000</cell></row><row><cell>Rel. improvement (%)</cell><cell>?40 ?20 0 20 40 60</cell><cell>10 7</cell><cell cols="2">10 8 OC20, 6 Bessel OC20, 32 Bessel OC-2M, 6 Bessel OC-2M, 32 Bessel</cell><cell></cell><cell>Kendall rank correlation</cell><cell>0.2 0.4 0.6 0.8 1.0</cell><cell cols="3">10 7 OC-2M to OC20 OC20 to OC20 OC-2M to OC20, OOD OC20 to OC20, OOD</cell><cell>10 8</cell></row><row><cell></cell><cell cols="4">Seen training samples</cell><cell>Converged</cell><cell></cell><cell></cell><cell cols="3">Training samples seen</cell><cell>Converged</cell></row><row><cell cols="6">Figure 8: Effect of radial basis functions during train-</cell><cell cols="5">Figure 9: Kendall rank correlation of model force</cell></row><row><cell cols="6">ing on force MAE. Bessel functions work best on OC20</cell><cell cols="5">MAEs during training to the final result. The correla-</cell></row><row><cell cols="6">early in training, but this trend reverses at conver-</cell><cell cols="5">tion shows a drop early in training, which is likely due</cell></row><row><cell cols="6">gence. OC-2M exhibits a more consistent behavior.</cell><cell cols="5">to the variance caused by the learning rate (LR) decay</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">on plateau schedule. Correlation then increases again</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">during late training. We found that LR variance has</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">no impact on final converged results. Note that the</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">converged OC-2M points have seen 56 M samples on</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">average, putting it roughly on par with early stopping.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Ablation studies for various components proposed by GemNet and GemNet-OC, based on force MAE on the OOD validation set. Some model changes are fairly consistent across OC20 datsets (e.g. symmetric message passing, quadruplet interaction), while others have varying effects across datasets.</figDesc><table><row><cell>OC-XS</cell><cell></cell><cell>.52</cell><cell>.39</cell><cell>.11</cell><cell>.04</cell><cell></cell><cell></cell><cell>.07</cell><cell>.00</cell><cell></cell><cell>.08</cell><cell>.26</cell><cell>.14</cell><cell>.14</cell><cell>.09</cell><cell>.07</cell><cell></cell></row><row><cell>OC-Sn</cell><cell>.52</cell><cell></cell><cell>.74</cell><cell>.24</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.03</cell><cell></cell><cell></cell><cell>.16</cell><cell>.14</cell><cell>.14</cell><cell></cell><cell></cell><cell></cell></row><row><cell>OC-Sn, OOD</cell><cell>.39</cell><cell>.74</cell><cell></cell><cell>.26</cell><cell>.00</cell><cell></cell><cell></cell><cell>.08</cell><cell>.10</cell><cell></cell><cell></cell><cell>.14</cell><cell>.24</cell><cell>.14</cell><cell>.00</cell><cell>.07</cell><cell>.02</cell><cell>0.6</cell></row><row><cell>OC-XS, OOD</cell><cell>.11</cell><cell>.24</cell><cell>.26</cell><cell></cell><cell>.13</cell><cell>.20</cell><cell>.38</cell><cell>.02</cell><cell>.11</cell><cell>.09</cell><cell>.11</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>OC-Rb, OOD</cell><cell>.04</cell><cell></cell><cell>.00</cell><cell>.13</cell><cell></cell><cell>.52</cell><cell>.40</cell><cell>.31</cell><cell>.17</cell><cell></cell><cell>.07</cell><cell></cell><cell>.03</cell><cell></cell><cell>.06</cell><cell></cell><cell></cell></row><row><cell>MD17</cell><cell></cell><cell></cell><cell></cell><cell>.20</cell><cell>.52</cell><cell></cell><cell>.59</cell><cell>.29</cell><cell>.15</cell><cell></cell><cell>.04</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.4</cell></row><row><cell>OC-sub30, OOD</cell><cell></cell><cell></cell><cell></cell><cell>.38</cell><cell>.40</cell><cell>.59</cell><cell></cell><cell>.18</cell><cell>.32</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>COLL</cell><cell>.07</cell><cell></cell><cell>.08</cell><cell>.02</cell><cell>.31</cell><cell>.29</cell><cell>.18</cell><cell></cell><cell>.33</cell><cell>.26</cell><cell>.31</cell><cell>.14</cell><cell>.22</cell><cell>.17</cell><cell>.36</cell><cell>.30</cell><cell>.35</cell></row><row><cell>OC-sub30</cell><cell>.00</cell><cell>.03</cell><cell>.10</cell><cell>.11</cell><cell>.17</cell><cell>.15</cell><cell>.32</cell><cell>.33</cell><cell></cell><cell>.17</cell><cell>.17</cell><cell>.09</cell><cell>.26</cell><cell>.22</cell><cell>.32</cell><cell>.38</cell><cell>.32</cell><cell>0.2</cell></row><row><cell>OC-200k</cell><cell></cell><cell></cell><cell></cell><cell>.09</cell><cell></cell><cell></cell><cell></cell><cell>.26</cell><cell>.17</cell><cell></cell><cell>.70</cell><cell>.16</cell><cell>.20</cell><cell>.23</cell><cell>.48</cell><cell>.30</cell><cell>.33</cell></row><row><cell>OC-200k, OOD</cell><cell>.08</cell><cell></cell><cell></cell><cell>.11</cell><cell>.07</cell><cell>.04</cell><cell></cell><cell>.31</cell><cell>.17</cell><cell>.70</cell><cell></cell><cell>.21</cell><cell>.18</cell><cell>.20</cell><cell>.52</cell><cell>.30</cell><cell>.32</cell></row><row><cell>OC-XS, same trj</cell><cell>.26</cell><cell>.16</cell><cell>.14</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.14</cell><cell>.09</cell><cell>.16</cell><cell>.21</cell><cell></cell><cell>.39</cell><cell>.37</cell><cell>.46</cell><cell>.40</cell><cell>.35</cell><cell>0.0</cell></row><row><cell>OC-Rb</cell><cell>.14</cell><cell>.14</cell><cell>.24</cell><cell></cell><cell>.03</cell><cell></cell><cell></cell><cell>.22</cell><cell>.26</cell><cell>.20</cell><cell>.18</cell><cell>.39</cell><cell></cell><cell>.54</cell><cell>.35</cell><cell>.46</cell><cell>.28</cell></row><row><cell>OC-2M</cell><cell>.14</cell><cell>.14</cell><cell>.14</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.17</cell><cell>.22</cell><cell>.23</cell><cell>.20</cell><cell>.37</cell><cell>.54</cell><cell></cell><cell>.57</cell><cell>.60</cell><cell>.38</cell></row><row><cell>OC-2M, OOD</cell><cell>.09</cell><cell></cell><cell>.00</cell><cell></cell><cell>.06</cell><cell></cell><cell></cell><cell>.36</cell><cell>.32</cell><cell>.48</cell><cell>.52</cell><cell>.46</cell><cell>.35</cell><cell>.57</cell><cell></cell><cell>.60</cell><cell>.58</cell><cell>?0.2</cell></row><row><cell>OC20</cell><cell>.07</cell><cell></cell><cell>.07</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.30</cell><cell>.38</cell><cell>.30</cell><cell>.30</cell><cell>.40</cell><cell>.46</cell><cell>.60</cell><cell>.60</cell><cell></cell><cell>.66</cell></row><row><cell>OC20, OOD</cell><cell></cell><cell></cell><cell>.02</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.35</cell><cell>.32</cell><cell>.33</cell><cell>.32</cell><cell>.35</cell><cell>.28</cell><cell>.38</cell><cell>.58</cell><cell>.66</cell><cell></cell></row><row><cell cols="2">Figure 13: OC-XS</cell><cell>OC-Sn</cell><cell>OC-Sn, OOD</cell><cell>OC-XS, OOD</cell><cell>OC-Rb, OOD</cell><cell>MD17</cell><cell>OC-sub30, OOD</cell><cell>COLL</cell><cell>OC-sub30</cell><cell>OC-200k</cell><cell>OC-200k, OOD</cell><cell>OC-XS, same trj</cell><cell>OC-Rb</cell><cell>OC-2M</cell><cell>OC-2M, OOD</cell><cell>OC20</cell><cell>OC20, OOD</cell><cell>OC-XS OC-Rb OC-Sn OC-sub30 OC-200k OC-2M OC20</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Results for the OC20 in-distribution (ID, also called "separate trajectories") validation set and the three test tasks.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">S2EF validation</cell><cell></cell><cell></cell><cell>S2EF test</cell><cell></cell><cell></cell><cell></cell><cell>IS2RS</cell><cell>IS2RE</cell></row><row><cell cols="2">Train</cell><cell></cell><cell cols="10">Energy MAE Force MAE Force cos EFwT Energy MAE Force MAE Force cos EFwT AFbT ADwT Energy MAE</cell></row><row><cell cols="3">set Model</cell><cell>meV ?</cell><cell>meV/? ?</cell><cell>?</cell><cell>% ?</cell><cell>meV ?</cell><cell>meV/? ?</cell><cell>?</cell><cell cols="3">% ? % ? % ?</cell><cell>meV ?</cell></row><row><cell></cell><cell></cell><cell>SchNet</cell><cell>1360</cell><cell>73.7</cell><cell>0.112</cell><cell>0.00</cell><cell>1370</cell><cell>73.6</cell><cell>0.117</cell><cell>0.00</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>OC-2M</cell><cell></cell><cell>DimeNet ++ SpinConv GemNet-dT</cell><cell>737 360 275</cell><cell>59.2 32.8 25.5</cell><cell>0.229 0.485 0.574</cell><cell>0.02 0.23 1.15</cell><cell>738 357 271</cell><cell>59.2 32.7 25.5</cell><cell>0.227 0.479 0.571</cell><cell cols="3">0.01 0.22 1.19 20.0 55.1 ----</cell><cell>--435</cell></row><row><cell></cell><cell></cell><cell>GemNet-OC</cell><cell>226</cell><cell>22.5</cell><cell cols="2">0.610 1.89</cell><cell>226</cell><cell>22.5</cell><cell cols="4">0.610 1.94 22.4 56.5</cell><cell>405</cell></row><row><cell></cell><cell></cell><cell>CGCNN</cell><cell>504</cell><cell>68.4</cell><cell>0.155</cell><cell>0.01</cell><cell>511</cell><cell>68.3</cell><cell>0.154</cell><cell>0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>SchNet</cell><cell>447</cell><cell>49.3</cell><cell>0.319</cell><cell>0.13</cell><cell>442</cell><cell>49.3</cell><cell>0.318</cell><cell>0.11</cell><cell>-</cell><cell>15.2</cell><cell>709</cell></row><row><cell></cell><cell></cell><cell>ForceNet-large</cell><cell>-</cell><cell>28.1</cell><cell>0.534</cell><cell>-</cell><cell>-</cell><cell>31.2</cell><cell>0.520</cell><cell cols="3">0.01 14.8 50.6</cell><cell>-</cell></row><row><cell>OC20</cell><cell></cell><cell>DimeNet ++ -L-F+E PaiNN SpinConv</cell><cell>360 -287</cell><cell>28.1 -37.0</cell><cell>0.564 -0.479</cell><cell>0.00 -0.09</cell><cell>359 248 261</cell><cell>28.0 29.3 26.9</cell><cell>0.564 0.511 0.548</cell><cell cols="3">0.00 25.6 52.4 0.88 15.6 49.5 0.82 21.1 53.7</cell><cell>502 442 424</cell></row><row><cell></cell><cell></cell><cell>GemNet-dT</cell><cell>242</cell><cell>22.8</cell><cell>0.613</cell><cell>1.13</cell><cell>226</cell><cell>21.0</cell><cell>0.637</cell><cell cols="3">2.40 33.8 59.2</cell><cell>390</cell></row><row><cell></cell><cell></cell><cell>GemNet-XL</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>212</cell><cell>18.1</cell><cell>0.676</cell><cell cols="3">3.30 34.6 62.7</cell><cell>376</cell></row><row><cell></cell><cell></cell><cell>GemNet-OC</cell><cell>172</cell><cell>17.9</cell><cell cols="2">0.685 4.59</cell><cell>168</cell><cell>17.9</cell><cell cols="4">0.686 4.70 40.7 60.6</cell><cell>348</cell></row><row><cell>OC20+</cell><cell>OC-MD</cell><cell>GemNet-OC-L-E GemNet-OC-L-F GemNet-OC-L-F+E</cell><cell>153 170 -</cell><cell>17.8 16.3 -</cell><cell cols="2">0.688 0.711 5.35 5.30 --</cell><cell>150 163 -</cell><cell>17.8 16.3 -</cell><cell cols="4">0.688 0.711 5.47 47.4 60.8 5.44 ------</cell><cell>--331</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Results for the OC20 out-of-distribution adsorbates validation set and the three test tasks.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">S2EF validation</cell><cell></cell><cell></cell><cell>S2EF test</cell><cell></cell><cell></cell><cell></cell><cell>IS2RS</cell><cell>IS2RE</cell></row><row><cell cols="2">Train</cell><cell></cell><cell cols="10">Energy MAE Force MAE Force cos EFwT Energy MAE Force MAE Force cos EFwT AFbT ADwT Energy MAE</cell></row><row><cell cols="3">set Model</cell><cell>meV ?</cell><cell>meV/? ?</cell><cell>?</cell><cell>% ?</cell><cell>meV ?</cell><cell>meV/? ?</cell><cell>?</cell><cell cols="3">% ? % ? % ?</cell><cell>meV ?</cell></row><row><cell></cell><cell></cell><cell>SchNet</cell><cell>1410</cell><cell>77.3</cell><cell>0.108</cell><cell>0.00</cell><cell>1340</cell><cell>74.1</cell><cell>0.114</cell><cell>0.00</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>OC-2M</cell><cell></cell><cell>DimeNet ++ SpinConv GemNet-dT</cell><cell>806 375 309</cell><cell>67.0 35.6 29.3</cell><cell>0.203 0.479 0.560</cell><cell>0.00 0.05 0.21</cell><cell>694 350 269</cell><cell>61.0 33.7 26.5</cell><cell>0.215 0.466 0.557</cell><cell cols="3">0.01 0.09 0.59 15.9 50.5 ----</cell><cell>--442</cell></row><row><cell></cell><cell></cell><cell>GemNet-OC</cell><cell>258</cell><cell>25.2</cell><cell cols="2">0.600 0.45</cell><cell>235</cell><cell>22.9</cell><cell cols="4">0.597 1.09 19.5 52.2</cell><cell>416</cell></row><row><cell></cell><cell></cell><cell>CGCNN</cell><cell>599</cell><cell>74.6</cell><cell>0.132</cell><cell>0.00</cell><cell>632</cell><cell>72.8</cell><cell>0.137</cell><cell>0.00</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>SchNet</cell><cell>497</cell><cell>57.4</cell><cell>0.286</cell><cell>0.00</cell><cell>486</cell><cell>52.9</cell><cell>0.295</cell><cell>0.04</cell><cell>-</cell><cell>12.8</cell><cell>774</cell></row><row><cell></cell><cell></cell><cell>ForceNet-large</cell><cell>-</cell><cell>32.0</cell><cell>0.520</cell><cell>-</cell><cell>-</cell><cell>28.3</cell><cell>0.521</cell><cell cols="3">0.01 12.2 45.2</cell><cell>-</cell></row><row><cell>OC20</cell><cell></cell><cell>DimeNet ++ -L-F+E PaiNN SpinConv</cell><cell>450 -314</cell><cell>31.8 -40.0</cell><cell>0.550 -0.471</cell><cell>0.00 -0.03</cell><cell>402 280 275</cell><cell>28.9 30.0 27.7</cell><cell>0.550 0.499 0.535</cell><cell cols="3">0.00 20.7 48.5 0.43 12.2 44.3 0.38 15.7 48.9</cell><cell>543 480 442</cell></row><row><cell></cell><cell></cell><cell>GemNet-dT</cell><cell>247</cell><cell>25.4</cell><cell>0.605</cell><cell>0.30</cell><cell>210</cell><cell>21.9</cell><cell>0.624</cell><cell cols="3">1.15 26.8 54.6</cell><cell>391</cell></row><row><cell></cell><cell></cell><cell>GemNet-XL</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>198</cell><cell>18.6</cell><cell>0.664</cell><cell cols="3">1.62 30.3 58.6</cell><cell>368</cell></row><row><cell></cell><cell></cell><cell>GemNet-OC</cell><cell>189</cell><cell>19.6</cell><cell cols="2">0.681 1.27</cell><cell>171</cell><cell>18.2</cell><cell cols="4">0.674 2.57 36.1 56.6</cell><cell>350</cell></row><row><cell>OC20+</cell><cell>OC-MD</cell><cell>GemNet-OC-L-E GemNet-OC-L-F GemNet-OC-L-F+E</cell><cell>178 195 -</cell><cell>19.5 17.9 -</cell><cell cols="2">0.685 0.707 1.70 1.66 --</cell><cell>152 174 -</cell><cell>18.1 16.6 -</cell><cell cols="4">0.678 3.21 0.700 3.18 40.4 56.4 ------</cell><cell>--336</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Results for the OC20 out-of-distribution catalysts validation set and the three test tasks.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">S2EF validation</cell><cell></cell><cell></cell><cell>S2EF test</cell><cell></cell><cell></cell><cell></cell><cell>IS2RS</cell><cell>IS2RE</cell></row><row><cell cols="2">Train</cell><cell></cell><cell cols="10">Energy MAE Force MAE Force cos EFwT Energy MAE Force MAE Force cos EFwT AFbT ADwT Energy MAE</cell></row><row><cell cols="3">set Model</cell><cell>meV ?</cell><cell>meV/? ?</cell><cell>?</cell><cell>% ?</cell><cell>meV ?</cell><cell>meV/? ?</cell><cell>?</cell><cell cols="3">% ? % ? % ?</cell><cell>meV ?</cell></row><row><cell></cell><cell></cell><cell>SchNet</cell><cell>1330</cell><cell>72.7</cell><cell>0.105</cell><cell>0.00</cell><cell>1340</cell><cell>71.7</cell><cell>0.114</cell><cell>0.00</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>OC-2M</cell><cell></cell><cell>DimeNet ++ SpinConv GemNet-dT</cell><cell>738 399 374</cell><cell>58.9 33.6 27.3</cell><cell>0.223 0.461 0.533</cell><cell>0.02 0.20 0.97</cell><cell>745 398 341</cell><cell>58.0 33.5 26.8</cell><cell>0.219 0.460 0.536</cell><cell cols="3">0.01 0.16 0.76 15.3 54.8 ----</cell><cell>--454</cell></row><row><cell></cell><cell></cell><cell>GemNet-OC</cell><cell>288</cell><cell>24.0</cell><cell cols="2">0.576 1.68</cell><cell>279</cell><cell>23.3</cell><cell cols="4">0.584 1.44 19.8 56.7</cell><cell>416</cell></row><row><cell></cell><cell></cell><cell>CGCNN</cell><cell>525</cell><cell>67.9</cell><cell>0.146</cell><cell>0.00</cell><cell>520</cell><cell>67.0</cell><cell>0.149</cell><cell>0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>SchNet</cell><cell>545</cell><cell>52.0</cell><cell>0.297</cell><cell>0.10</cell><cell>528</cell><cell>50.9</cell><cell>0.296</cell><cell>0.06</cell><cell>-</cell><cell>14.6</cell><cell>767</cell></row><row><cell></cell><cell></cell><cell>ForceNet-large</cell><cell>-</cell><cell>32.7</cell><cell>0.491</cell><cell>-</cell><cell>-</cell><cell>30.9</cell><cell>0.494</cell><cell cols="3">0.01 12.2 49.8</cell><cell>-</cell></row><row><cell>OC20</cell><cell></cell><cell>DimeNet ++ -L-F+E PaiNN SpinConv</cell><cell>541 -397</cell><cell>31.5 -39.7</cell><cell>0.511 -0.454</cell><cell>0.00 -0.05</cell><cell>504 366 350</cell><cell>31.2 32.7 28.5</cell><cell>0.512 0.460 0.519</cell><cell cols="3">0.00 20.1 50.9 0.40 8.93 47.8 0.46 15.9 53.9</cell><cell>578 486 457</cell></row><row><cell></cell><cell></cell><cell>GemNet-dT</cell><cell>357</cell><cell>26.9</cell><cell>0.561</cell><cell>0.64</cell><cell>340</cell><cell>24.5</cell><cell>0.581</cell><cell cols="3">0.93 24.7 58.7</cell><cell>434</cell></row><row><cell></cell><cell></cell><cell>GemNet-XL</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>308</cell><cell>20.6</cell><cell>0.631</cell><cell cols="3">1.72 29.3 62.6</cell><cell>402</cell></row><row><cell></cell><cell></cell><cell>GemNet-OC</cell><cell>272</cell><cell>22.3</cell><cell cols="2">0.621 2.08</cell><cell>266</cell><cell>21.4</cell><cell cols="4">0.632 1.95 33.0 60.6</cell><cell>377</cell></row><row><cell>OC20+</cell><cell>OC-MD</cell><cell>GemNet-OC-L-E GemNet-OC-L-F GemNet-OC-L-F+E</cell><cell>278 287 -</cell><cell>23.1 20.7 -</cell><cell cols="2">0.617 0.646 2.51 1.86 --</cell><cell>282 284 -</cell><cell>22.1 20.0 -</cell><cell cols="4">0.628 0.656 2.29 37.4 60.8 1.82 ------</cell><cell>--379</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Results for the OC20 out-of-distribution both (adsorbate and catalyst) validation set and the three test tasks.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">S2EF validation</cell><cell></cell><cell></cell><cell>S2EF test</cell><cell></cell><cell></cell><cell></cell><cell>IS2RS</cell><cell>IS2RE</cell></row><row><cell cols="2">Train</cell><cell></cell><cell cols="10">Energy MAE Force MAE Force cos EFwT Energy MAE Force MAE Force cos EFwT AFbT ADwT Energy MAE</cell></row><row><cell cols="3">set Model</cell><cell>meV ?</cell><cell>meV/? ?</cell><cell>?</cell><cell>% ?</cell><cell>meV ?</cell><cell>meV/? ?</cell><cell>?</cell><cell cols="3">% ? % ? % ?</cell><cell>meV ?</cell></row><row><cell></cell><cell></cell><cell>SchNet</cell><cell>1490</cell><cell>89.6</cell><cell>0.110</cell><cell>0.00</cell><cell>1440</cell><cell>89.1</cell><cell>0.117</cell><cell>0.00</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>OC-2M</cell><cell></cell><cell>DimeNet ++ SpinConv GemNet-dT</cell><cell>940 492 475</cell><cell>77.5 42.8 36.0</cell><cell>0.214 0.492 0.559</cell><cell>0.00 0.03 0.11</cell><cell>867 500 413</cell><cell>73.7 42.1 33.5</cell><cell>0.226 0.494 0.573</cell><cell cols="3">0.00 0.05 0.23 15.7 58.8 ----</cell><cell>--420</cell></row><row><cell></cell><cell></cell><cell>GemNet-OC</cell><cell>370</cell><cell>31.0</cell><cell cols="2">0.606 0.23</cell><cell>355</cell><cell>28.5</cell><cell cols="4">0.620 0.52 16.6 60.3</cell><cell>391</cell></row><row><cell></cell><cell></cell><cell>CGCNN</cell><cell>731</cell><cell>85.2</cell><cell>0.134</cell><cell>0.01</cell><cell>768</cell><cell>85.1</cell><cell>0.144</cell><cell>0.00</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>SchNet</cell><cell>705</cell><cell>68.5</cell><cell>0.285</cell><cell>0.00</cell><cell>706</cell><cell>65.5</cell><cell>0.299</cell><cell>0.01</cell><cell>-</cell><cell>14.8</cell><cell>806</cell></row><row><cell></cell><cell></cell><cell>ForceNet-large</cell><cell>-</cell><cell>41.2</cell><cell>0.516</cell><cell>-</cell><cell>-</cell><cell>37.5</cell><cell>0.530</cell><cell cols="3">0.00 11.5 52.9</cell><cell>-</cell></row><row><cell>OC20</cell><cell></cell><cell>DimeNet ++ -L-F+E PaiNN SpinConv</cell><cell>711 -487</cell><cell>39.6 -48.2</cell><cell>0.539 -0.486</cell><cell>0.00 -0.01</cell><cell>655 470 459</cell><cell>37.1 40.5 35.6</cell><cell>0.552 0.493 0.555</cell><cell cols="3">0.00 20.6 54.9 0.13 10.1 52.2 0.14 14.0 58.0</cell><cell>612 474 425</cell></row><row><cell></cell><cell></cell><cell>GemNet-dT</cell><cell>415</cell><cell>33.5</cell><cell>0.596</cell><cell>0.10</cell><cell>394</cell><cell>29.6</cell><cell>0.622</cell><cell cols="3">0.30 25.1 62.2</cell><cell>384</cell></row><row><cell></cell><cell></cell><cell>GemNet-XL</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>362</cell><cell>24.5</cell><cell>0.670</cell><cell cols="3">0.61 29.0 66.7</cell><cell>338</cell></row><row><cell></cell><cell></cell><cell>GemNet-OC</cell><cell>344</cell><cell>27.1</cell><cell cols="2">0.659 0.36</cell><cell>326</cell><cell>25.2</cell><cell cols="4">0.671 0.79 31.3 63.5</cell><cell>342</cell></row><row><cell>OC20+</cell><cell>OC-MD</cell><cell>GemNet-OC-L-E GemNet-OC-L-F GemNet-OC-L-F+E</cell><cell>347 357 -</cell><cell>27.9 25.1 -</cell><cell cols="2">0.658 0.685 0.50 0.38 --</cell><cell>336 343 -</cell><cell>25.9 23.1 -</cell><cell cols="4">0.669 0.696 0.93 37.1 63.7 0.74 ------</cell><cell>--344</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Published in Transactions onMachine Learning Research (09/2022)   </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Brandon Wood for helpful discussions on performance and scaling aspects and the Open Catalyst team for their support, feedback, and discussions and for providing the foundational codebase for this project <ref type="bibr" target="#b12">(Chanussot et al., 2021)</ref>. We furthermore acknowledge PyTorch <ref type="bibr" target="#b30">(Paszke et al., 2019)</ref> and PyTorch Geometric <ref type="bibr" target="#b18">(Fey &amp; Lenssen, 2019)</ref>.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the Bottleneck of Graph Neural Networks and its Practical Implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eran</forename><surname>Yahav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cormorant: Covariant Molecular Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Truong-Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Hy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kondor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Gaussian Approximation Potentials: The Accuracy of Quantum Mechanics, without the Electrons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><forename type="middle">P</forename><surname>Bart?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><forename type="middle">C</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?bor</forename><surname>Cs?nyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page">136403</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On representing chemical environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><forename type="middle">P</forename><surname>Bart?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?bor</forename><surname>Cs?nyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review B</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page">184115</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Machine learning unifies the modeling of materials and molecules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><forename type="middle">P</forename><surname>Bart?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandip</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Poelking</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Kermode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?bor</forename><surname>Cs?nyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Ceriotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1701816</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Neural Device for Searching Direct Correlations between Structures and Properties of Chemical Compounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><forename type="middle">I</forename><surname>Baskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">A</forename><surname>Palyulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolai</forename><forename type="middle">S</forename><surname>Zefirov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Computer Sciences</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="715" to="721" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">SE(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate Interatomic Potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Batzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tess</forename><forename type="middle">E</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">P</forename><surname>Mailoa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mordechai</forename><surname>Kornbluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Molinari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Kozinsky</surname></persName>
		</author>
		<idno>arXiv, 2101.03164</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Behler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Parrinello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page">146401</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reconciling modern machine-learning practice and the classical bias-variance trade-off</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumik</forename><surname>Mandal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="15849" to="15854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Small Data, Big Decisions: Model Selection in the Small-Data Regime</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorg</forename><surname>Bornschein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Visin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Close Look at Deep Learning with Small Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Brigato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Iocchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Spectral Networks and Deep Locally Connected Networks on Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Open Catalyst 2020 (OC20) Dataset and Community Challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lowik</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Shuaibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgane</forename><surname>Riviere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Heras-Domingo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caleb</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aini</forename><surname>Palizhati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuroop</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwoong</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ulissi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS Catalysis</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>document</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Machine learning of accurate energy-conserving molecular force fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Chmiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huziel</forename><forename type="middle">E</forename><surname>Sauceda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Poltavsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kristof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>Sch?tt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the role of gradients for machine learning of molecular energies and forces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><forename type="middle">S</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Anatole Von Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning: Science and Technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">45018</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">OrbNet Denali: A machine learning potential for biological and organic chemistry with semi-empirical cost and DFT accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><forename type="middle">S</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><surname>Sai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoran</forename><surname>Sirumalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">B</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feizhi</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Animashree</forename><surname>Bygrave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><forename type="middle">R</forename><surname>Welborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Manby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page">204103</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Quantum chemical benchmark databases of gold-standard dimer interaction energies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Donchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Taube</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Decolvenaere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cory</forename><surname>Hargus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">T</forename><surname>Mcgibbon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ka-Hei</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brent</forename><forename type="middle">A</forename><surname>Gregersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Je-Luen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Palmo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Siva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bergdorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">L</forename><surname>Klepeis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">E</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Data</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Convolutional Networks on Graphs for Learning Molecular Fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dougal</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Aguilera-Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>G?mez-Bombarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al?n</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast Graph Representation Learning with PyTorch Geometric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Representation Learning on Graphs and Manifolds, ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Predict then Propagate: Graph Neural Networks Meet Personalized PageRank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Gasteiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Gasteiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shankari</forename><surname>Giri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><forename type="middle">T</forename><surname>Margraf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Molecules Workshop</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Directional Message Passing for Molecular Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Gasteiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janek</forename><surname>Gro?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">GemNet: Universal Directional Graph Neural Networks for Molecules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Gasteiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural Message Passing for Quantum Chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Hestness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Newsha</forename><surname>Ardalani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Kianinejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md Mostofa Ali</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<idno>1712.00409</idno>
	</analytic>
	<monogr>
		<title level="j">Deep Learning Scaling is Predictable</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">QM7-X: A comprehensive dataset of quantum-mechanical properties spanning the chemical space of small organic molecules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><forename type="middle">Medrano</forename><surname>Sandonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">G</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Vazquez-Mayagoitia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Distasio</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Tkatchenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Shuaibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuroop</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<title level="m">ForceNet: A Graph Neural Network for Large-Scale Quantum Calculations. arXiv</title>
		<imprint>
			<date type="published" when="1436" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<title level="m">Do Better ImageNet Models Transfer Better? In CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Accurate and scalable graph neural network force field and molecular dynamics with direct force architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheol Woo</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mordechai</forename><surname>Kornbluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Vandermause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Wolverton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Kozinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">P</forename><surname>Mailoa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Materials</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>K?pf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Quantum chemistry structures and properties of 134 kilo molecules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghunathan</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pavlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Dral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anatole Von Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the Convergence of Adam and Beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sashank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satyen</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Materials Design and Discovery with High-Throughput Density Functional Theory: The Open Quantum Materials Database (OQMD)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">E</forename><surname>Saal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Kirklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muratahan</forename><surname>Aykol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryce</forename><surname>Meredig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wolverton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOM</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1501" to="1509" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">SchNet: A continuous-filter convolutional neural network for modeling quantum interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristof</forename><surname>Sch?tt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huziel Enoc Sauceda</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Chmiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Equivariant message passing for the prediction of tensorial properties and molecular spectra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kristof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><forename type="middle">T</forename><surname>Sch?tt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Unke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gastegger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML, 2021</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Shuaibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adeesh</forename><surname>Kolluru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuroop</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ulissi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<title level="m">Rotation Invariant Graph Neural Networks using Spin Convolutions. arXiv</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Isayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Roitberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemical Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3192" to="3203" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The ANI-1ccx and ANI-1x data sets, coupled-cluster and density functional theory properties for molecules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Zubatyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Nebgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Lubbers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kipton</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><forename type="middle">E</forename><surname>Roitberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olexandr</forename><surname>Isayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Tretiak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">134</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Supervised neural networks for the classification of structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sperduti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Starita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="714" to="735" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuroop</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<idno>ICLR, 2022. 5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">PhysNet: A Neural Network for Predicting Energies, Forces, Dipole Moments, and Partial Charges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Unke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meuwly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Theory and Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Unke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Chmiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gastegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kristof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huziel</forename><forename type="middle">E</forename><surname>Sch?tt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>Sauceda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>M?ller</surname></persName>
		</author>
		<title level="m">SpookyNet: Learning Force Fields with Electronic Degrees of Freedom and Nonlocal Effects. arXiv, 2105.00304</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">C</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page">145301</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szymon</forename><surname>Sidor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Farhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Pachocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Do Transformers Really Perform Badly for Graph Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxuan</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianle</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuxin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolin</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanming</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2021</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Molecular Mechanics-Driven Graph Neural Network with Multiplex Graph for Molecular Structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Molecules Workshop</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
