<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Equilibrium Optical Flow Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
							<email>shaojieb@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Geng</surname></persName>
							<email>zhengyanggeng@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Savani</surname></persName>
							<email>ysavani@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zico Kolter</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Bosch Center for AI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Equilibrium Optical Flow Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>* Equal contribution. Our code is available.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T18:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>nstep = 1, EPE = 23.35 DEQ-RAFT nstep = 3, EPE = 10.33 DEQ-RAFT nstep = 7, EPE = 2.95 DEQ-RAFT nstep = 10, EPE = 2.15 DEQ-RAFT nstep = 11, EPE = 2.08 DEQ-RAFT Frame nstep = 1, EPE = 30.81 RAFT nstep = 3, EPE = 14.61 RAFT nstep = 7, EPE = 3.81 RAFT nstep = 10, EPE = 2.75 RAFT nstep = 11, EPE = 2.58 RAFT Ground Truth Figure 1. A deep equilibrium (DEQ) flow estimator directly models the flow as a path-independent, "infinite-level" fixed-point solving process. We propose to use this implicit framework to replace the existing recurrent approach to optical flow estimation. The DEQ flows converge faster, require less memory, are often more accurate, and are compatible with prior model designs like RAFT [1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Many recent state-of-the-art (SOTA) optical flow models use finite-step recurrent update operations to emulate traditional algorithms by encouraging iterative refinements toward a stable flow estimation. However, these RNNs impose large computation and memory overheads, and are not directly trained to model such "stable estimation". They can converge poorly and thereby suffer from performance degradation. To combat these drawbacks, we propose deep equilibrium (DEQ) flow estimators, an approach that directly solves for the flow as the infinite-level fixed point of an implicit layer (using any black-box solver) [2], and differentiates through this fixed point analytically (thus requiring O(1) training memory). This implicit-depth approach is not predicated on any specific model, and thus can be applied to a wide range of SOTA flow estimation model designs (e.g., RAFT [1] and GMA <ref type="bibr" target="#b2">[3]</ref>). The use of these DEQ flow estimators allows us to compute the flow faster using, e.g., fixed-point reuse and inexact gradients, consumes 4 ? 6? less training memory than the recurrent counterpart, and achieves better results with the same computation budget. In addition, we propose a novel, sparse fixed-point correction scheme to stabilize our DEQ flow estimators, which addresses a longstanding challenge for DEQ models in general. We test our approach in various realistic settings and show that it improves SOTA methods on Sintel and KITTI datasets with substantially better computational and memory efficiency. * Equal contribution. Our code is available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Optical flow estimation is the classic computer vision task of predicting the pixel-level motions between video frames <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>. Learning-based approaches to this problem, which outperformed classical approaches, proposed the use of conventional deep convolutional networks to learn a flow estimate <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>. Recent progress has shown that finite-step, unrolled and recurrent update operations significantly improve the estimation performance, exemplified by the emergence of the RAFT <ref type="bibr" target="#b0">[1]</ref> method. Contemporary optical flow models that employ this approach typically rely on a Gated Recurrent Unit (GRU) <ref type="bibr" target="#b8">[9]</ref> to iteratively refine the optical flow estimate. This approach was motivated to emulate traditional optimization-based methods, and the update operators defined accordingly have become the standard design for state-of-the-art flow models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b11">[11]</ref><ref type="bibr" target="#b12">[12]</ref>.</p><p>Despite their superior performance, these rolled-out recurrent networks suffer from a few drawbacks. First, training these models involves tracking a long hidden-state history in the backpropagation-through-time (BPTT) algorithm <ref type="bibr" target="#b13">[13]</ref>, which yields a significant computational and memory burden. Therefore, these models tend to scale poorly with larger images and more iterations. Second, although these models were designed to emulate traditional optimization approaches which solve for a "stable estimate" with as many steps as needed, the recurrent networks do not directly model such a minimum-energy optima state. Rather, they stop after a predefined L update steps, and are still trained in a pathdependent way using BPTT. We also show later in <ref type="figure" target="#fig_1">Fig. 3</ref> that the GRUs frequently oscillate instead of converging.</p><p>In this work, we introduce deep equilibrium (DEQ) flow estimators based on recent progresses in implicit deep learning, represented by DEQ models <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">[14]</ref><ref type="bibr" target="#b15">[15]</ref><ref type="bibr" target="#b16">[16]</ref><ref type="bibr" target="#b17">[17]</ref>. Our method functions as a superior and natural framework to replace the existing recurrent, unrolling-based flow estimation approach.</p><p>There are multiple reasons why this method is preferable. First, instead of relying on the na?ve iterative layer stacking, DEQ models define their outputs as the fixed points of a single layer f ? using the input x, i.e., z * = f ? (z * , x), modeling an "infinite-layer" equilibrium representation. We can directly solve for the fixed point using specialized black-box solvers, e.g., quasi-Newton methods <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b19">19]</ref>, in a spirit much more consistent with the traditional optimization-based perspective <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">20]</ref>. This approach expedites the stable flow estimation process while often yielding better results. Second, we no longer need to perform BPTT. Instead, DEQ models can directly differentiate through the final fixed point z * without having to store intermediary states during the forward computation, considerably lowering the training memory cost. Third, this fixed-point formulation justifies numerous implicit network enhancements such as 1) fixed-point reuse from adjacent video frames; and 2) inexact gradients <ref type="bibr" target="#b21">[21]</ref><ref type="bibr" target="#b22">[22]</ref><ref type="bibr" target="#b23">[23]</ref>. The former helps avoid redundant computations, thus substantially accelerating flow estimations; and the latter makes the backward pass computationally almost free! Fourth, the DEQ approach is not predicated on any specific structure for f ? . Therefore, DEQ is a framework that applies to a wide range of these SOTA flow estimation model designs (e.g., RAFT <ref type="bibr" target="#b0">[1]</ref>, GMA <ref type="bibr" target="#b2">[3]</ref>, and Depthstillation <ref type="bibr" target="#b24">[24]</ref>), and we can obtain the aforementioned computational and memory benefits with even additional gain based on the specific structure of f ? .</p><p>In addition to suggesting DEQ flow estimators as a superior replacement to the existing recurrent approach, we also tackle the longstanding instability challenge of training DEQ networks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b26">26]</ref>. Inspired by the RAFT model, we propose a novel, sparse fixed-point correction scheme that substantially stabilizes our DEQ flow estimators.</p><p>The contributions of this paper are as follows. First, we propose the deep equilibrium (DEQ) approach as a new natural starting point for formulating optical flow methods. A DEQ approach directly models and substantially accelerates the fixed-point convergence of the flow estimation process, avoids redundant computations across video frames, and comes with an almost-free backward pass. Second, we show that the DEQ approach is orthogonal to, and thus compatible with, the prior modeling efforts (which focus on the model design and feature extraction) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref> and datarelated efforts <ref type="bibr" target="#b9">[10]</ref>. With DEQ, these prior arts are now more computationally and memory efficient as well as more accurate. For instance, on KITTI-15 <ref type="bibr" target="#b27">[27]</ref> (train) a zero-shot DEQ-based RAFT model further reduces the state-of-the-art F1-all measure by 21.0% while using the underlying RAFT design. Third, we introduce a sparse fixed-point correction scheme that significantly stabilizes DEQ models on optical flow problems while only adding minimal cost, and show that on flow estimation tasks this approach is superior to the recently proposed Jacobian-based regularization <ref type="bibr" target="#b26">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Iterative Optical Flow. Although optical flow is a classic problem, there has recently been substantial progress in the area. Earlier methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b28">[28]</ref><ref type="bibr" target="#b29">[29]</ref><ref type="bibr" target="#b30">[30]</ref><ref type="bibr" target="#b31">[31]</ref> formulated the optical flow prediction as an energy minimization problems using continuous optimization with different objective terms. This perspective inspired multiple improvements that used discrete optimization to model optical flows, i.e., those based on conditional random fields <ref type="bibr" target="#b32">[32]</ref>, global optimization <ref type="bibr" target="#b33">[33]</ref>, and inference on the global 4D cost volume <ref type="bibr" target="#b34">[34]</ref>. More recently, with the advancement of deep learning, there have been an explosion of efforts trying to emulate these optimization steps via deep neural networks. For example, a number of optical flow methods are based on deep architectures that rely on coarse-to-fine pyramids <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b35">[35]</ref><ref type="bibr" target="#b36">[36]</ref><ref type="bibr" target="#b37">[37]</ref><ref type="bibr" target="#b38">[38]</ref><ref type="bibr" target="#b39">[39]</ref>. Specifically, recent research efforts have turned to iterative refinements, which typically involves stacking multiple direct flow prediction modules <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b40">40]</ref>. The RAFT model <ref type="bibr" target="#b0">[1]</ref>, which inspired this work, first showed they could achieve state-of-the-art performance on optical flow estimation using a global correlation volume and a ConvGRU update operator that mimics the behavior of traditional optimizers, which tends to converge to a stable flow estimate. Built on top of this recurrent unrolling framework of RAFT, Jiang et al. <ref type="bibr" target="#b2">[3]</ref>, and Zhang et al. <ref type="bibr" target="#b41">[41]</ref> introduced additional attention-style modules prior to the recurrent stage to improve the modeling of occlusions and textureless areas. Another contemporary work, AutoFlow <ref type="bibr" target="#b9">[10]</ref>, exploits bilevel optimization to automatically render and augment training data for optical flow. Finally, Jiang et al. <ref type="bibr" target="#b42">[42]</ref> proposes to speed up these flow estimators by replacing the dense correlation volume with a sparse alternative.</p><p>The focus of this paper is on a direction that is largely orthogonal to and thus complementary to these modeling efforts. We challenge and improve the "default" recurrent, unrolled formulation of training flow estimators themselves. With the help of the recent progress in implicit deep learning (see below), we can maintain the same convergent flow estimation formulation while paying substantially less computation and memory costs. Implicit deep learning. Recent research has proposed a new class of deep learning architectures that do not have prescribed computation graphs or hierarchical layer stacking like conventional networks. Instead, the output of these implicit networks is typically defined to be the solution of an underlying dynamical system <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b44">44]</ref>. For example, Neural ODEs <ref type="bibr" target="#b25">[25]</ref> model infinitesimal steps of a residual block as an ODE flow. A deep equilibrium (DEQ) network <ref type="bibr" target="#b1">[2]</ref> (which primarily inspired this work) is another class of implicit model that directly solves for a fixed-point representation of a shallow layer f ? (e.g., , a Transformer block) and differentiates through this fixed point without storing intermediate states in the forward pass. This allows one to train implicit networks with constant memory, while fully decoupling the forward and backward passes of training. However, it is known that these implicit models suffer from a few serious issues that have been studied by later works, such as computational inefficiency <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b45">45]</ref>, instability <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b26">26]</ref>, and lack of theoretical convergence guarantees <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b16">16]</ref>. On a positive note, followup works have also shown that DEQ-based models can achieve competitive results on challenging tasks such as language modeling <ref type="bibr" target="#b1">[2]</ref>, generative modeling <ref type="bibr" target="#b46">[46]</ref>, semantic segmentation <ref type="bibr" target="#b14">[14]</ref>, etc. However, to the best of our knowledge, these implicit models have not been applied to the task of optical flow estimation. In this paper, we show that this task could substantially benefit from the DEQ formulation as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>We start by introducing some preliminaries of existing flow estimators. These modules are typically applied directly on raw image pairs, with the extracted representations then passed into the iterative refinement stage. We use RAFT <ref type="bibr" target="#b0">[1]</ref> as the illustrative example here while noting that cuttingedge flow estimators generally share similar structure (i.e., , for context extraction and correlation computations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminaries</head><p>Given an RGB image pair p 1 , p 2 ? R 3?H?W , an optical flow estimator aims to learn a correspondence f ? R 2?H?W between two coordinate grids c 1 , c 2 (i.e., f = c 2 ? c 1 ), which describes the per-pixel motion between consecutive frames in the horizontal (dx) and vertical (dy) directions. To process the matched image pair, we first encode features u 1 , u 2 ? R C?H?W of p 1 , p 2 , and produce a context embedding q from the first image p 1 . Then, we construct a group of pyramid global correlation tensors C = C 0 , ? ? ? , C p?1 , where C k ? R H?W ?H/2 k ?W/2 k is found by first calculating the inner product between all pairs of hyperpixels in u 1 and u 2 as C 0 , i.e.,</p><formula xml:id="formula_0">C 0 ijmn = d u 1 ijd u 2 mnd<label>(1)</label></formula><p>followed by downsampling the last two dimensions to produce C k (k &gt; 0). The correlation pyramid C and context embedding q, which allow the model to infer large motions and displacements in a global sense, are then passed as inputs into the iterative refinement stage.</p><p>In this work, we keep the correlation and context computation part intact (see <ref type="figure" target="#fig_0">Fig. 2</ref>) and concentrate on the iterative refinement stage. We refer interested readers to Teed and Deng <ref type="bibr" target="#b0">[1]</ref> for a more detailed description of the feature extraction process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Deep Equilibrium Flow Estimator</head><p>Due to the inherent challenges of the flow estimation task, prior works have shown that explicit neural networks struggle to predict the flow accurately, requiring a prohibitively large number of training iterations <ref type="bibr" target="#b5">[6]</ref>. Recent works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b24">24]</ref> have resorted to mimicking the flavor of traditional optimization-based algorithms <ref type="bibr" target="#b4">[5]</ref> with RNNs (e.g., convGRUs). However, these methods are still quite different from the traditional methods in a few ways. For example, optimization-based methods 1) have an adaptive and well-defined stopping criteria (e.g., whenever they reach the optima); 2) are agnostic to the choice of solver (e.g., first-or second-order methods); and 3) are essentially path-independent (i.e., the output alone is the only thing we should need). None of these properties are directly characterized by the finite-step unrolling of recurrent networks.</p><p>We propose to close this gap with a DEQ-based approach. Specifically, given the context embedding q and the pyramid correlation tensor C, a DEQ flow estimator simultaneously solves for the fixed-point convergence of two alternate streams: 1) a latent representation h, which constructs the flow updates; and 2) the flow estimate f itself, whose updates are generically related as follows:</p><formula xml:id="formula_1">h [t+1] = H(h [t] , f [t] , q, C) f [t+1] = F(h [t+1] , f [t] , q, C).<label>(2)</label></formula><p>This formulation captures the form of prominent flow estimator model designs like RAFT <ref type="bibr" target="#b0">[1]</ref> or GMA <ref type="bibr" target="#b2">[3]</ref>. Formally, the input x = (q, C) and model parameters f ? = (H, F) jointly define a dynamical system that the DEQ flow model can directly solve the fixed point for using the following flow update equation in its forward pass:</p><formula xml:id="formula_2">(h * , f * ) = z * = f ? (z * , x) = f ? ((h * , f * ), x) . (3)</formula><p>Intuitively, this corresponds to an "infinite-depth" feature representation z * where, if we perform one more flow update step f ? , both flow estimation f and latent state h will not change (thus reaching a fixed point, i.e., an "equilibrium"). Importantly, we can leverage much more advanced root solving methods like quasi-Newton methods (e.g., Broyden's method <ref type="bibr" target="#b18">[18]</ref> or Anderson mixing <ref type="bibr" target="#b19">[19]</ref>) to find the fixed point. These methods guarantee a much faster (superlinear) and better-quality convergence than if we perform infinitely many na?ve unrolling steps (as do recurrent networks but only up to a finite number of steps due to computation and memory constraints). Moreover, we note that prior works</p><formula xml:id="formula_3">Frame i Frame i Frame i + 1 h?, ?i 4D Correlation Volumes C k u i+1 u i q i Context Network Feature Network Correlation + Context Modules ) . . . L-step ConvGRU . . . f [L] h [L] L(f [L] , f gt ) f ? h ? = z ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anderson solver</head><p>Broyden solver Na?ve solver (? 1-step ConvGRU)</p><p>Newton solver</p><formula xml:id="formula_4">L(f ? , f gt ) z [0] = f [0] h [0]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DEQ Flow (ours)</head><p>Forward pass Backward pass</p><formula xml:id="formula_5">f [0] h [0]</formula><p>Recurrent (Unrolled) Flow (e.g., RAFT) In contrast, a recurrent flow estimator has to be unrolled for many steps, and needs to perform BPTT, which is costly in both computation and memory.</p><formula xml:id="formula_6">Deep supervision: L(f [t] ,</formula><p>on implicit networks have shown that the exact structure of f ? subsumes a wide variety of model designs, such as a Transformer block <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b47">47]</ref>, a residual block <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b48">48]</ref>, or a graph layer <ref type="bibr" target="#b49">[49]</ref><ref type="bibr" target="#b50">[50]</ref><ref type="bibr" target="#b51">[51]</ref>. Similarly, for the deep equilibrium flow estimator, Eq. (2) engulfs exactly the designs of state-of-theart optical flow models, which we follow and use without modification. For example, for RAFT <ref type="bibr" target="#b0">[1]</ref>,</p><formula xml:id="formula_7">x = Conv2d [q, f * , C(f * + c 0 )] h * = ConvGRU (h * , [x, q]) f * = f * + Conv2d (h * ) ,<label>(4)</label></formula><p>where C(f * + c 0 ) stands for the correlation lookup as in RAFT <ref type="bibr" target="#b0">[1]</ref>. We also show in Appendix that GMA <ref type="bibr" target="#b2">[3]</ref> can be easily written in a similar update form.</p><p>The key question is, how do we update and train a DEQ flow estimator. It turns out that we can directly differentiate through this "infinite-level" flow state, (h * , f * ), without any knowledge of the forward fixed-point trajectory:</p><p>Theorem 1. (Implicit Function Theorem (IFT) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b52">52]</ref>) Given the fixed-point flow representation z * = (h * , f * ), the corresponding flow loss L(h * , f * , f gt ) and input x = (q, C), the gradient of DEQ flow is given by</p><formula xml:id="formula_8">?L ?? = ?L ?z * I ? ?f ? ?z * ?1 ?f ? (z * , x) ??<label>(5)</label></formula><p>For the proof, see Bai et al. <ref type="bibr" target="#b1">[2]</ref>. Importantly, this theorem enables us to decouple the forward and backward passes of a DEQ flow estimator; i.e., to perform gradient update, we only need the final output z * and do not need to run backpropagation-through-time (BPTT). It means a huge memory reduction: whereas an L-step recurrent flow estimator takes O(L) memory to perform BPTT, a DEQ estimator reduces the overhead by a factor of L to be O(1) (e.g., RAFT uses L = 12 for training, so using a DEQ flow can theoretically reduce the iterative refinement memory cost by 12?).</p><p>To summarize, a DEQ flow's forward pass directly solves a fixed-point flow-update equation via black-box solvers; and its backward pass relies only on the final optimum z * , which make this flow estimation process much more akin to the optimization-based perspective <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Accelerating DEQ Flows</head><p>Formulating optical flow estimation as a deep equilibrium solution also enables us to fully exploit the toolkit from implicit deep learning. We elaborate below on examples of how this equilibrium formulation can substantially help us improve the forward and backward pipeline and significantly simplify the overall overhead of modern flow estimators. Inexact Gradients for Training DEQs. Despite the niceness of the implicit function theorem (IFT), inverting the Jacobian term could quickly become intractable as we deal with high-dimensional feature maps. To combat this, Bai et al. <ref type="bibr" target="#b1">[2]</ref> proposed exploiting fast vector-Jacobian products and solving a linear fixed-point system g ? = g ? ?f ? ?z * + ?L ?z * . However, this approach is still iterative in nature, and in practice, it is no cheaper than the forward flow solving process.</p><p>Recent works on implicit networks' backward dynamics <ref type="bibr" target="#b21">[21]</ref><ref type="bibr" target="#b22">[22]</ref><ref type="bibr" target="#b23">[23]</ref> suggest that they can typically be trained, and even benefit from, simple approximations of the IFT, while still modeling an "infinite-depth" representation through the fixed-point forward pass. That is, we do not need the exact solution to Thm. 1 to train these networks. Instead we use</p><formula xml:id="formula_9">?L ?? ? ?L ?? = ?L ?z * A ?f ? (z * , x) ??<label>(6)</label></formula><p>where A is a Jacobian (inverse) approximation term. For example, <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b22">22]</ref> proposes to use A = I (i.e., , 1-step gradient), which simplifies the backward pass of a DEQ flow estimator to ?L ?? ? ?L</p><formula xml:id="formula_10">?z * ?f ? (z * ,x) ??</formula><p>. Therefore, unlike the BPTT-based recurrent framework used by existing flow estimators, a DEQ flow estimator's backward pass that uses inexact gradient consists of a single step (and thus is almost free)! Empirically, since we almost eliminate the backward pass cost, the inexact gradients significantly reduce the total training time for DEQ flow estimator further by a factor of almost 2?. The capability of using inexact gradients is a</p><formula xml:id="formula_11">0 . . . 0 z ? 0 = [h ? 0 |f ? 0 ] = z [0] 0 = [h [0] 0 |f [0] 0 ] = h ? 0 f ? 0 h ? 0 f ? 0 z [0] 1 = . . . h ? 1 f ? 1 z [0] 2 = h ? 1 f ? 1 . . . h ? 2 f ? 2 z [0] 3 = h ? 2 f ? 2 Solver trajectory .</formula><p>. .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solver trajectory Solver trajectory</head><p>h</p><formula xml:id="formula_12">? 3 f ? 3 z [0] 4 = h ? 3 f ? 3 . . . h ? 4 f ? 4</formula><p>... and much faster subsequent frames Slower frame 0... direct and unique consequence of the fixed-point formulation and assumes a certain level of stability for the underlying dynamics <ref type="bibr" target="#b21">[21]</ref><ref type="bibr" target="#b22">[22]</ref><ref type="bibr" target="#b23">[23]</ref><ref type="bibr" target="#b26">26]</ref>. We discuss an additional approach that further improves the stability of these estimates next.</p><p>Sparse fixed-point correction of DEQ flows. A longstanding challenge in training implicit networks is the growing instability problem <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b53">53]</ref>. In short, since DEQ flow estimators have no discrete layers, they struggle to converge during training. In other words, the stable flow estimate z * = (h * , f * ) could become computationally expensive to reach. This suggests that the optical flow estimation process gets slower during training.</p><p>In this work, we propose sparsely applying a fixed-point correction term to stabilize the DEQ flow convergence. Formally, suppose the black-box solver (e.g., Broyden's method) yields a convergence path (z [0] , . . . ,</p><formula xml:id="formula_13">z [i] , . . . z * ), where z [0]</formula><p>is the initial guess and z * is the final flow estimate. We then randomly pick z</p><formula xml:id="formula_14">[i] = (h [i] , f [i]</formula><p>) on this path (e.g., can be uniformly spaced), and define our total loss to be</p><formula xml:id="formula_15">L total = L main +L cor = ?f * ? f gt ? 2 2 main loss +? ?f [i] ? f gt ? 2 2</formula><p>fixed-point correction <ref type="bibr" target="#b6">(7)</ref> where ? &lt; 1 is a loss weight hyperparameter. This was inspired by the dense step-wise deep supervision used by conventional flow estimators like RAFT <ref type="bibr" target="#b0">[1]</ref>. However, our application here differs in two significant ways. First, we apply this in a sparse manner, with our primary goal being correcting instability. Second, unlike in RAFT, which performs costly BPTT through the RNN chain, this fixedpoint correction loss is still path-independent and can be understood as a coarse-grained fixed-point estimate. Therefore, we could also perform inexact gradient updates on this correction loss as well; i.e.,</p><formula xml:id="formula_16">?L cor ?? ? ? ?L cor ?z [i] ?f ? (z [i] , x) ?? .<label>(8)</label></formula><p>Empirically, we find this significantly stabilizes the DEQ flow estimator while having no noticeable negative impact on performance. This result is in sharp contrast to existing stabilization methods like Jacobian regularization <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b54">54]</ref> which 1) apply only locally to z * ; and 2) usually hurt model performance (see the ablation study in Sec. 4). Moreover, due to the inexact gradient in Eq. <ref type="formula" target="#formula_16">(8)</ref>, our method adds almost no extra computation or memory cost. While our scope is limited to flow estimation here, we believe this approach suggests a potentially valuable and lightweight solution to the generic instability issue of implicit models, which we leave for future work.</p><p>Fixed-point reuse for better initialization. The DEQ flow estimator's unique formulation also inherits many useful properties from the general optimization framework. One of these nice properties is the ability to perform fixed-point reuse to further accelerate flow estimation convergence. The motivation for this comes from the fact that consecutive frames of a video are typically highly correlated. For instance, perhaps only a few objects are moving in the foreground, while most of the other content and background are nearly identical across these adjacent frames. More formally, if p i , p i+1 , and p i+2 are 3 consecutive video frames, then the ground-truth optical flow f i (between p i and p i+1 ) is usually highly correlated to the next ground-truth optical flow f i+1 . Thus, when we perform real-time flow estimation with conventional networks like FlowNet <ref type="bibr" target="#b5">[6]</ref> and RAFT <ref type="bibr" target="#b0">[1]</ref>, we frequently perform a lot of redundant computations. In contrast, with a DEQ flow, we can recycle the fixed-point solution z * i of the previous frame, which estimates f i , as the initial guess z i+1 for the subsequent frame's fixed-point solver. Intuitively, these DEQ flows are able to automatically adjust their forward optimization by exploiting this more informed initial guess, which facilitates convergence speed. It amortizes the cost of flow estimation over long video sequences, since only frame 0 requires full fixed-point solving while the remaining frames can all recycle their predecessor's flow. We note that such reuse is related to, but still different from the warm-up scheme of RAFT <ref type="bibr" target="#b0">[1]</ref>, which only applies to f , excludes h, and still has to be unrolled for many steps. In our case, because a DEQ flow directly models a fixed point, such an adaptive computation by exploiting the inductive bias of video data is well-justified. <ref type="figure" target="#fig_1">Fig. 3</ref> shows the practicality of fixed-point reuse on Sintel video sequences. By re-using the fixed point, we can further accelerate the DEQ flow estimator's inference speed by a factor of about 1.6?. Interestingly, while RAFT's iterative unrolling aims to mimic the iterative convergence, we find its activations usually oscillate at a relatively high level after about 15 update iterations.</p><p>To summarize, while a conventional recurrent flow estimator like RAFT needs to be unrolled for some finite L steps and back-propagated through the same L-step chain, a deep equilibrium flow estimator: 1) leverages the IFT and requires only O(1) training memory, 2) uses inexact gradients to reduce the backward pass to O(1) computation, and 3) can take advantage of correlation between adjacent frames to amortize the flow estimation cost across a long sequence, thus significantly accelerating the forward pass.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We present the results of our experiments in this section. Specifically, we highlight the computational and memory efficiency of DEQ flow estimators and analyze how the fixed-point correction improves the DEQ flow. Our method achieves state-of-the-art zero-shot performance on both the MPI Sintel <ref type="bibr" target="#b55">[55]</ref> dataset and the KITTI 2015 <ref type="bibr" target="#b27">[27]</ref> dataset, with an astonishing 21.0% error reduction in the F1-all measure and 14.9% improvement in EPE for KITTI-15 (while still using a similar training budget to RAFT <ref type="bibr" target="#b0">[1]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results</head><p>Our quantitative evaluation is presented in Tab. 1. Following previous work <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref>, we first pretrain the DEQ flow model on the FlyingChairs <ref type="bibr" target="#b5">[6]</ref> and FlyingThings3D <ref type="bibr" target="#b56">[56]</ref> datasets. We then test the model on the training set of MPI Sintel <ref type="bibr" target="#b55">[55]</ref> and KITTI 2015 <ref type="bibr" target="#b27">[27]</ref> datasets. This model is denoted "C + T"; it evaluates the zero-shot generalization of the DEQ flow model. Then, we fine-tune the DEQ flow estimator on FlyingThings3D <ref type="bibr" target="#b56">[56]</ref>, MPI-Sintel <ref type="bibr" target="#b55">[55]</ref>, KITTI 2015 <ref type="bibr" target="#b27">[27]</ref>, and HD1K <ref type="bibr" target="#b57">[57]</ref> for the test submission.</p><p>The models are of exactly the same size as RAFT (5.3M) <ref type="bibr" target="#b0">[1]</ref> and GMA (5.9M) <ref type="bibr" target="#b2">[3]</ref> except they use DEQ flow formulation instead of recurrent updates. They are denoted as DEQ-RAFT-B and DEQ-GMA-B, respectively. Exploiting the memory efficiency of the DEQ flow model (see Sec. 4.2), we can fit much larger models into the same compute budget of two 11 GB 2080Ti GPUs. To this end, we also trained DEQ-RAFT-L (8.4M) and DEQ-RAFT-H (12.8M) by increasing the the width of hidden layers inside the equilibrium module f ? . As shown in <ref type="figure" target="#fig_5">Fig. 5</ref>, even the largest DEQ-RAFT-H model only consumes less than half of the flow estimation memory used by a standard-sized RAFT model, while achieving significantly better accuracy (4.38 AEPE and 14.9 F1-all score on KITTI-15, see Tab. 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Performance-Compute Tradeoff</head><p>We further verify the aforementioned computational and memory benefits of the DEQ flow model on the Sintel (clean) <ref type="bibr" target="#b55">[55]</ref> dataset with a RAFT-based update operator (see Eq. (4)) trained on FlyingChairs <ref type="bibr" target="#b5">[6]</ref> and FlyingTh-ings3D <ref type="bibr" target="#b56">[56]</ref>. The results are shown in <ref type="figure" target="#fig_5">Fig. 5</ref>. Specifically, when training the DEQ flow estimator on Sintel with a batch size of 3 per GPU (the maximum that RAFT can fit with a 11 GB GPU), we observe that the memory cost of the flow estimation process reduces by a factor of over 4? (red bars). Note that since we keep the rest of the model intact (e.g., correlation pyramid and context extraction; see Sec. 3.1), the DEQ flow estimator does not improve those parts of the memory burden, which now becomes the new dominant source of memory overhead. In addition, when we use the model for inference, we follow Teed and Deng [1] using 32 recurrent steps for RAFT (with warm-start), and the Anderson solver for DEQ-RAFT (with reuse), which stops if relative residual falls below ? = 10 ?3 . Our results suggest that the DEQ flow converges to an accurate solution, and it is in practice about 20% faster than the RAFT models with the same structure and size (blue bars). Finally, we show that we can exploit such memory savings to build even larger and more accurate flow estimators (DEQ-RAFT-H), while still staying well within the compute and memory budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>In this subsection, we aim to answer the following questions: 1) How useful is the fixed-point correction compared with canonical IFT in performance, stability, and speed? 2) How does the convergence of a DEQ flow correlate with the quality of the flow estimation? As in Sec. 4.2, we use the model design from RAFT <ref type="bibr" target="#b0">[1]</ref> to instantiate our DEQ flow. By default, we conduct the ablation experiments on the FlyingChairs <ref type="bibr" target="#b5">[6]</ref> dataset using the default training hyperparameters of RAFT and report the Average End Point Error (AEPE) on its validation split.</p><p>Stabilizing DEQ by Fixed-Point Correction. As mentioned in Sec. 3.3, unregularized canonical DEQ models (as well as other implicit networks like Neural ODEs <ref type="bibr" target="#b25">[25]</ref>) typically suffer from a growing instability issue typically symptomized by an increasingly costly forward fixed-point solving process. We perform an ablation experiment to study how our proposed sparse fixed-point correction scheme could help alleviate this issue. To understand the scheme's effect, we train a DEQ flow model using both an Anderson <ref type="bibr" target="#b19">[19]</ref> and a Broyden <ref type="bibr" target="#b18">[18]</ref> solver with 36 and 24 forward iterations, respectively. For simplicity, we equally divide the solver convergence trajectory into r + 1 segments (where r is the frequency in <ref type="figure" target="#fig_4">Fig. 4)</ref>   <ref type="table">Table 1</ref>. Evaluation on Sintel and KITTI 2015 datasets. We report the Average End Point Error (AEPE), F1-fg (%), and F1-all (%) (lower is better). "C+T" refers to results that are pre-trained on the Chairs and Things datasets. "S+K+H" refers to methods that are fine-tuned on the Sintel, KITTI, and HD1K datasets. The bold font stands for the best result and the underlined results ranks 2nd. ? corresponds to the results using a 3-step phantom gradient <ref type="bibr" target="#b23">[23]</ref>. DEQ flow achieves SOTA zero-shot generalization results even w/o attention.  each trajectory clip. As mentioned in Sec. 3.3, we apply the 1-step gradient <ref type="bibr" target="#b21">[21]</ref><ref type="bibr" target="#b22">[22]</ref><ref type="bibr" target="#b23">[23]</ref> to the correction loss.</p><p>We visualize results of DEQ flow models trained with 3 different settings: 1) a DEQ flow trained by IFT directly without an auxiliary correction loss; 2) a DEQ flow trained by 1-step gradient without an auxiliary correction loss; and 3) DEQ flows trained by 1-step gradient as well as 1-3 fixedpoint correction terms. Our results are reported in terms of AEPE (which measures performance) and absolute fixedpoint residual error ?f ? (z * ; x) ? z * ? 2 (which measures sta-bility). As shown in <ref type="figure" target="#fig_4">Fig. 4</ref>, our proposed fixed-point correction significantly outperforms the standard IFT training protocol by about 9%, and reduces the fixed-point error by a conspicuous margin, e.g., over 60%. Moreover, we find that the significant improvement in stability quickly diminishes as we apply more corrections, which suggests a sparse correction scheme. Together with the inexact 1-step gradient, the total training time can be streamlined over 45% compared with the IFT training schedule, while the backward pass of a DEQ flow is still almost free.   <ref type="figure">Figure 6</ref>. Correlation between convergence and performance. We also observe that harder examples (e.g., those with large motion) typically lead to more challenging fixed-point convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correlation between Performance and Convergence.</head><p>A potential question is whether better fixed-point convergence can lead to better performance. To tackle this, we evaluate the DEQ flow model trained using the standard "C+T" training protocol (see Sec. 4.1) on the KITTI-15 <ref type="bibr" target="#b27">[27]</ref> training set. We visualize the per-frame EPE and the convergence (measured by the absolute fixed point error) in Sec. 4.3 and dye the scatter plot with the average norm of per-pixel flow across the frame, which can be understood as an indicator of hardness due to the large displacements. The Pearson correlation coefficient between the fixed-point error and EPE is over 0.86 (see <ref type="figure" target="#fig_7">Fig. 7</ref>) supporting the claim that convergence is strongly correlated with the flow performance. From <ref type="figure" target="#fig_7">Fig. 7</ref>, we see that hard flows with large motions are also challenging for a naive solver. This demonstrates the necessity of advanced solvers in DEQ flow estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitations</head><p>The improved performance and efficiency of our approach comes at the cost of a slightly more complex training pipeline. Implementing the na?ve unrolled flow es-  timation as presented in Teed and Deng <ref type="bibr" target="#b0">[1]</ref> and Jiang et al. <ref type="bibr" target="#b2">[3]</ref> is simple using most libraries equipped with automatic differentiation that directly handle BPTT. On the other hand, our approach involves some finagling of the training protocol (e.g., fixed-point solvers, IFT, inexact gradients, etc .). To help alleviate this complexity and promote the use of DEQ flows, we release our code at https://github.com/locuslab/deq-flow.</p><formula xml:id="formula_17">AEPE ||f gt || ||f(z) z|| A E P E | | f g t | | | | f ( z ) z | |</formula><p>In addition, while DEQ flows provide a novel and more efficient framework to train and use these flow estimators, we still occasionally need to be careful about the stability of this approach. For example, what would happen if the solver converges poorly (or even diverges) on a dynamical system? In such case, the behavior of the DEQ flow estimation would not be well-defined. In practice, we rarely observe such instability (as long as we spend enough solver steps); but as we analyzed in Sec. <ref type="bibr" target="#b3">4</ref>, harder examples also typically lead to more lengthy convergence path. We leave a more thorough study of estimation stability to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we introduce a new framework for modeling optical flow estimation. A deep equilibrium (DEQ) flow directly models and solves a fixed-point stable flow estimate, and offers a set of tools that make these flow models' training and inference process highly efficient (e.g., they enjoy an almost-free backward pass). Moreover, the use of such equilibrium formulation is largely orthogonal to, and thus complements, the prior modeling and data efforts. We empirically show that it is possible to integrate the DEQ flow estimator with these model designs and achieve better performance on realistic optical flow datasets. This implicit framework provides a strong (drop-in) replacement for existing recurrent update operators used by most cutting-edge flow estimators. The DEQ flows are both more powerful and lightweight -both computationally and memory-wise. We believe this suggests an exciting direction for building more efficient, large-scale and accurate flow models in the future. Relative Ratio  size and mixed-precision training, which is not a concern for DEQ-GMA due to the implicit modeling framework.</p><p>We use an Anderson acceleration <ref type="bibr" target="#b19">[19]</ref> solver with up to 40 forward steps for the base model (DEQ-RAFT-B). For larger models (DEQ-RAFT-L, DEQ-RAFT-H, DEQ-GMA-B, and DEQ-GMA-L), we use a Broyden <ref type="bibr" target="#b18">[18]</ref> solver with up to 36 forward steps. For the pretraining on Chairs, we introduce 1-3 correction terms accordingly. We adopt the 1-step gradient <ref type="bibr" target="#b21">[21]</ref><ref type="bibr" target="#b22">[22]</ref><ref type="bibr" target="#b23">[23]</ref> for training, which suggests almostfree backward passes. All the above experiments can be conducted on two 11 GB GPUs (NVIDIA 2080Ti).</p><p>For DEQ-RAFT-H ? , we employ a Broyden <ref type="bibr" target="#b18">[18]</ref> solver with 36 forward steps and 5 uniformly spaced correction terms. We apply phantom gradient <ref type="bibr" target="#b23">[23]</ref> of 3 steps to DEQ-RAFT-H ? and average the best results of 3 runs under a 5k-step evaluation gap to report the "C+T" schedule performance. The memory budget for this experiment can be two 16 GB GPUs or three 11 GB GPUs, while mixed-precision can further reduce the memory cost.</p><p>Note that we do not manually select the damping factor ? [23] but adopt the gating function from ConvGRU as the adaptive ?, which waives the hyperparameter tuning for the phantom gradient. The fixed point solvers are based on that of Bai et al. <ref type="bibr" target="#b1">[2]</ref>. In all those cases, the fixed-point solvers stop either when the iterations reach the limit, or if the absolute residual error falls below 0.001.</p><p>Our results suggest that, with minimal tuning, these settings are sufficient to achieve state-of-the-art results (while imposing much lower compute and memory cost). Empirically, we note that a DEQ flow model trained using a stronger solver (e.g., the Broyden solver) and with more steps typically leads to slightly better performance. This implies the prospect of potentially further boosting the DEQ-flow performance by more precise fixed-point solving, while noting that recent progress on using neural solvers might suggest an interesting perspective <ref type="bibr" target="#b59">[59]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. DEQ Flows with Fixed-point Correction</head><p>The growing instability problem has been a longstanding challenge in training implicit neural networks like DEQs. One of the contributions of this paper is also the introduction of fixed-point correction term to stabilize the DEQ flow estimation convergence. Specifically, previous methods rely on more constrained regularization settings such as Jacobianbased losses <ref type="bibr" target="#b26">[26]</ref>, i.e., penalizing the upper bound of Jacobian spectral radius,</p><formula xml:id="formula_18">?(J f ? (z * )) ? ?J f ? (z * )? F = tr(J ? f ? J f ? ),</formula><p>where J f ? (z * ) ? R d?d denotes the Jacobian of f ? at z * , ? corresponds to the spectral radius of a square matrix. By the stochastic Hutchinson trace estimator <ref type="bibr" target="#b60">[60]</ref>, we have</p><formula xml:id="formula_19">tr(J ? f ? J f ? ) = E ??p(?) ? ? J ? f ? J f ? ? ? ??p(?) ?J f ? ?? 2 2 ,</formula><p>where p(?) can be the Gaussian distribution N (0, I d ) or the Rademacher distribution. Different from prior works, we advocate for exploiting the benefit of IFT and inexact gradient to sparsely apply a fixed-point correction scheme to the convergence path.</p><p>In this section, we present an ablation study on Fly-ingChairs <ref type="bibr" target="#b5">[6]</ref> that compare the stability and generalization performance of DEQ flow models trained in three different settings: 1) standard implicit differentiatio (i.e., IFT); 2) standard IFT with Jacobian regularization <ref type="bibr" target="#b26">[26]</ref>; and 3) our proposed fixed-point correction scheme with a single correction term. As mentioned previously, we perform 1-step inexact gradient on the correction loss as well. For the purpose of this ablation, we run the forward fixed-point solver for a limited compute budget of <ref type="bibr">16 Anderson [19]</ref> steps in all three settings, and analyze their convergence behavior accordingly.</p><p>As shown in <ref type="figure" target="#fig_9">Fig. 8</ref>, the model trained using the standard implicit function theorem (IFT) suffers from the "growing instability" issue (see red curve in <ref type="figure" target="#fig_9">Fig. 8 (a)</ref>), as described in prior works indeed <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b26">26]</ref>. While strong enough Jacobian regularization can indeed stabilize the training process and lead to good overall convergence (see orange curve in <ref type="figure" target="#fig_9">Fig. 8 (a)</ref>), we observe that it is usually at a heavy cost of optical flow estimation accuracy (see <ref type="figure" target="#fig_9">Fig. 8 (b)</ref>). This agrees with the conclusion of Bai et al. <ref type="bibr" target="#b26">[26]</ref>. In contrast, we find it suffices to use a single fixed-point correction term in DEQ flow to achieve the same stabilizing effect (see blue curve in <ref type="figure" target="#fig_9">Fig. 8 (a)</ref>) at no extra cost to the average EPE on the validation set. We hypothesize that such a fixed-point correction method may suggest an elegant and lightweight solution to the growing instability problem in the broader implicit deep learning community beyond the scope of optical flow estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Qualitative Results</head><p>We visualize the flow estimation by the DEQ flow model in <ref type="figure" target="#fig_0">Fig. 9, Fig. 10, Fig. 11, Fig. 12, Fig. 13</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>fgt) for t &lt; L (Forward: Any solver; Backward: IFT (+inexact gradient) (Forward: Iterative unrolling; Backward: BPTT x = (q, C) x = (q, C) A visual comparison of the DEQ flow estimator and the recurrent unrolled flow estimator. After the correlation and context modules (see Sec. 3.1), a DEQ flow uses a fast, black-box fixed-point solver (e.g., Anderson) to directly solve for a stable (fixed-point) flow z * = (h * , f * ), and differentiate through z ? with a cheap inexact gradient. This makes a DEQ flow's backward pass almost free.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>(Left) By reusing fixed-point z * from the previous frame's flow estimation, we can "jump start" the subsequent equilibrium solving, essentially amortizing the solver cost and speeding up convergence. (Right) Comparing forward convergence of DEQ and recurrent flow estimators on Sintel videos (50 frames). "DS" stands for deep supervision used by RAFT<ref type="bibr" target="#b0">[1]</ref>. DEQ flow with fixed-point reuse converges best; and overall, DEQ flows converge faster than RAFT<ref type="bibr" target="#b0">[1]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Performance and convergence stability (measured by absolute residual error) of the DEQ flow. Frequency indicates how many correction terms we pick, with 0 meaning no correction. See the comparison with Jacobian Regularization<ref type="bibr" target="#b26">[26]</ref> in the Appendix. DEQ flows trained with our proposed correction enjoy superior performance and stability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Comparing the training memory, inference speed and performance on Sintel (clean) with image size 436 ? 1024. The same model design (based on RAFT) consumes much less memory and computes much quicker than the recurrent counterpart. All results are benchmarked on a single Quadro RTX 8000 GPU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Pearson correlation coefficient across per-frame EPE, fixed-point error, and the magnitude of flow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>Comparison of IFT, Jacobian Regularization and Fixed-Point Correction. Given a limited forward solver budget, the fixed-point correction protocol successfully stabilizes training and shows accelerated fixed-point convergence with visible performance improvements over Jacobian Regularization<ref type="bibr" target="#b26">[26]</ref> for DEQ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>15 Figure 9 .Figure 10 . 28 Figure 11 . 28 Figure 12 .Figure 13 .Figure 14 .</head><label>15910281128121314</label><figDesc>Visualization on the Sintel test set, ambush_1 sequence of the clean split. (a) Frame 34 (b) Frame 35 (c) Frame 36 (d) Frame 37 Visualization on the Sintel test set, cave_3 sequence of the clean split. Visualization on the Sintel test set, market_1 sequence of the clean split. Visualization on the Sintel test set, bamboo_3 sequence of the final split. (a) Frame 25 (b) Frame 26 (c) Frame 27 (d) Frame 28 Visualization on the Sintel test set, temple_1 sequence of the final split. Visualization on the KITTI test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>, and Fig. 14 using consecutive frames of the MPI Sintel [55] test set and KITTI [27] test set. Flow estimation errors are downloaded from the leaderboard.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/princeton-vl/RAFT</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Algorithm 1 DEQ flow (PyTorch-style). Note that we reuse the fixed point and perform fixed-point correction.</p><p># solver: fixed-point solver, e.g., Broyden <ref type="bibr" target="#b18">[18]</ref> # func: layer f ? that defines dynamic system # dist: loss function for fixed point correction # x: input information xt = (qt, Ct) of frame t # z: fixed-point flow estimation z * t # f: ground truth optical flow f # freq: frequency of correction # gamma: coefficient of correction # prev_z: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Pseudo Code</head><p>We provide a PyTorch-style <ref type="bibr" target="#b58">[58]</ref> pseudo-code for the DEQ flow in Alg. 1. Besides fixed-point reuse and an inexact (one-step) gradient as shown previously, we also include the fixed-point correction loss (applied with freq). In practice, we can set freq= 1, and use either Broyden's method <ref type="bibr" target="#b18">[18]</ref> or Anderson acceleration <ref type="bibr" target="#b19">[19]</ref> as solver. This sparse fixedpoint correction scheme encourages stable training dynamics, which we analyze further in <ref type="figure">Fig. 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiment Settings</head><p>In this section, we present the detailed experiment settings for training and inference with the DEQ flow estimators. The code will be made publicly available upon acceptance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Model Design</head><p>As mentioned previously, a deep equilibrium (DEQ) flow estimator subsumes a wide variety of model designs, and can be integrated with the latest, cutting-edge update operators. We show the integration of two of the most prominent designs that have achieved state-of-the-art optical flow results below, while noting in general that other alternatives are also possible.</p><p>DEQ flow by RAFT. Without any modification to the original design of RAFT <ref type="bibr" target="#b0">[1]</ref>, we can instantiate a DEQ-RAFT by defining the equilibrium system as follows,</p><p>where C(f * + c 0 ) stands for the correlation lookup as in RAFT <ref type="bibr" target="#b0">[1]</ref>, Conv2d stands for 2D convolutional layers with ReLU activations, and ConvGRU represents a GRU-style gated activation following convolutions, respectively. We refer the readers to Teed and Deng <ref type="bibr" target="#b0">[1]</ref> and the code base 1 for more details.</p><p>DEQ flow by GMA. More recently, Jiang et al. <ref type="bibr" target="#b2">[3]</ref> show that we can improve on the formulation of RAFT above by adding an attention module to better model the occlusion scenarios in video frames. Specifically, we also provide an instantiation of such Global Motion Aggregation (GMA) update operator <ref type="bibr" target="#b2">[3]</ref> in the context of DEQ flows, where we solve for the equilibrium z * = (h * , f * ) that satisfies</p><p>where Attention is the attention module, see <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b47">47]</ref>.</p><p>Model Hyperparameters For the base models, DEQ-RAFT-B and DEQ-GMA-B, we employ the exact same architecture and hyperparameter choice for the equilibrium module f ? as originally used by RAFT <ref type="bibr" target="#b0">[1]</ref> and GMA <ref type="bibr" target="#b2">[3]</ref>. We merely replace the recurrent (and BPTT-based) formulation with a fixed-point system-based one (and the backward pass with IFT or inexact gradients). For the Large models and Huge models, i.e., DEQ-RAFT-L, DEQ-GMA-L, and DEQ-RAFT-H, we use the same designs as the backbone models while increasing the number of hidden dimensions by a factor of 1.5? and 2?, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Training Details</head><p>Following the settings of prior work <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref>, we apply a four-stage training protocol using the default hyperparameters unless specified otherwise. First, we train DEQ-RAFT-L, DEQ-RAFT-H, and DEQ-RAFT-H ? on FlyingChairs <ref type="bibr" target="#b5">[6]</ref> for 120k iterations and then on FlyingThings <ref type="bibr" target="#b56">[56]</ref> for another 120k iterations. In addtion, we also train the DEQ-GMA instantiation on FlyingChairs <ref type="bibr" target="#b5">[6]</ref> using a batch size of 10 and a learning rate of 4e-4, with the same setting as RAFT <ref type="bibr" target="#b0">[1]</ref>. We note that the original recurrent GMA model quickly exhausts the memory budget even with a much smaller batch</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Raft: Recurrent all-pairs field transforms for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Teed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep equilibrium models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to estimate hidden motions with global motion aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kanade</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Determining optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Berthold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">G</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Flownet: Learning optical flow with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eddy</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Hausser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caner</forename><surname>Hazirbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Smagt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Asymmetric feature matching with learnable occlusion mask</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">I</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tak-Wai</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.07414</idno>
		<title level="m">A lightweight optical flow cnn-revisiting data fidelity and regularization</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Vlasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Krainin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiwen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramin</forename><surname>Zabih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>William</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Autoflow: Learning a better training set for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="10088" to="10097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Normalized convolution upsampling for refined optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Eldesokey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Felsberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.06979</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning optical flow from a few matches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">I</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="16587" to="16595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Backpropagation through time: what it does and how to do it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiscale Deep Equilibrium Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Monotone operator equilibrium networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ezra</forename><surname>Winston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J. Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Kawaguchi</surname></persName>
		</author>
		<idno>2020. 3</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep implicit layers tutorial -neural ODEs, deep equilibirum models, and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems Tutorial</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Charles G Broyden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Class of Methods for Solving Nonlinear Simultaneous Equations. Mathematics of computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">92</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Iterative procedures for nonlinear integral equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">G</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="1965-10-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of mathematical models in computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="237" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Is Attention Better Than Matrix Decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng-Hao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Howard</forename><surname>Samy Wu Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuwei</forename><surname>Heaton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><forename type="middle">J</forename><surname>Mckenzie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wotao</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12803</idno>
		<title level="m">Fixed Point Networks: Implicit Depth Models with Jacobian-Free Backprop</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On training implicit models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin-Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<idno>abs/2111.05177</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning optical flow from still images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filippo</forename><surname>Aleotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Poggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Mattoccia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural ordinary differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tian Qi Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">K</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Stabilizing Equilibrium Models by Jacobian Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Vision meets robotics: The kitti dataset. The International</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A framework for the robust estimation of optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padmanabhan</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anandan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1993 (4th) International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="231" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A duality based approach for realtime tv-l1 optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAGM-Symposium</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An improved algorithm for tv-l 1 optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Wedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical and Geometrical Approaches to Visual Motion Analysis</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Large displacement optical flow: Descriptor matching in variational motion estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="500" to="513" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discrete optimization for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Heipke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GCPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Full flow: Optical flow estimation by global optimization over regular grids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4706" to="4714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Accurate optical flow via direct cost volume processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren?</forename><surname>Ranftl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5807" to="5815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pwc-net: Cnns for optical flow using pyramid, warping, and cost volume</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Models matter, so does training: An empirical study of cnns for optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05571</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Liteflownet: A lightweight convolutional neural network for optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tak-Wai</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8981" to="8989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Flownet 2.0: Evolution of optical flow estimation with deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eddy</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaus</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margret</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Volumetric correspondence networks for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gengshan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Optical flow estimation using a spatial pyramid network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4161" to="4170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Separable flow: Learning motion cost volumes for optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feihu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><forename type="middle">J</forename><surname>Woodford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">H S</forename><surname>Victor Adrian Prisacariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning optical flow from a few matches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="16592" to="16600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">OptNet: Differentiable optimization as a layer in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J. Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangda</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Travacca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armin</forename><surname>Askari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.06315</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Implicit deep learning</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Augmented neural ODEs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilien</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Implicit normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongxuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<idno>2021. 3</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangda</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somayeh</forename><surname>Sojoudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.06211,2020.4</idno>
		<title level="m">Implicit graph neural networks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyun</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinkyoo</forename><surname>Park</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.01680</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">Convergent graph solvers. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">EIGNN: Efficient infinite-depth graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Kawaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">The implicit function theorem: History, theory, and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harold R Parks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning differential equations that are easy to solve</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">James</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">A stochastic estimator of the trace of the influence matrix for laplacian smoothing splines. Communications in Statistics-Simulation and Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hutchinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1059" to="1076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A naturalistic open source movie for optical flow evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaus</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eddy</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Hausser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">The hci benchmark suite: Stereo and flow ground truth with uncertainties for urban autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kondermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Honauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Krispin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Andrulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burkhard</forename><surname>Gussefeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Rahimimoghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claus</forename><surname>Brenner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR Workshop</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-performance Deep Learning Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<editor>Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala</editor>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Neural deep equilibrium solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">A stochastic estimator of the trace of the influence matrix for laplacian smoothing splines. Communications in Statistics-Simulation and Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hutchinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1059" to="1076" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
