<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
							<email>antti.tarvainen@aalto.fi</email>
							<affiliation key="aff0">
								<orgName type="institution">The Curious AI Company and Aalto University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">The Curious AI Company</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The recently proposed Temporal Ensembling has achieved state-of-the-art results in several semi-supervised learning benchmarks. It maintains an exponential moving average of label predictions on each training example, and penalizes predictions that are inconsistent with this target. However, because the targets change only once per epoch, Temporal Ensembling becomes unwieldy when learning large datasets. To overcome this problem, we propose Mean Teacher, a method that averages model weights instead of label predictions. As an additional benefit, Mean Teacher improves test accuracy and enables training with fewer labels than Temporal Ensembling. Without changing the network architecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250 labels, outperforming Temporal Ensembling trained with 1000 labels. We also show that a good network architecture is crucial to performance. Combining Mean Teacher and Residual Networks, we improve the state of the art on CIFAR-10 with 4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labels from 35.24% to 9.11%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep learning has seen tremendous success in areas such as image and speech recognition. In order to learn useful abstractions, deep learning models require a large number of parameters, thus making them prone to over-fitting ( <ref type="figure" target="#fig_0">Figure 1a</ref>). Moreover, adding high-quality labels to training data manually is often expensive. Therefore, it is desirable to use regularization methods that exploit unlabeled data effectively to reduce over-fitting in semi-supervised learning.</p><p>When a percept is changed slightly, a human typically still considers it to be the same object. Correspondingly, a classification model should favor functions that give consistent output for similar data points. One approach for achieving this is to add noise to the input of the model. To enable the model to learn more abstract invariances, the noise may be added to intermediate representations, an insight that has motivated many regularization techniques, such as Dropout <ref type="bibr" target="#b27">[28]</ref>. Rather than minimizing the classification cost at the zero-dimensional data points of the input space, the regularized model minimizes the cost on a manifold around each data point, thus pushing decision boundaries away from the labeled data points <ref type="figure" target="#fig_0">(Figure 1b</ref>).</p><p>Since the classification cost is undefined for unlabeled examples, the noise regularization by itself does not aid in semi-supervised learning. To overcome this, the ? model <ref type="bibr" target="#b20">[21]</ref> evaluates each data point with and without noise, and then applies a consistency cost between the two predictions. In this case, the model assumes a dual role as a teacher and a student. As a student, it learns as before; as a teacher, it generates targets, which are then used by itself as a student for learning. Since the model itself generates targets, they may very well be incorrect. If too much weight is given to the generated targets, the cost of inconsistency outweighs that of misclassification, preventing the learning of new arXiv:1703.01780v6 [cs.NE] <ref type="bibr" target="#b15">16</ref> Apr 2018 (e) An ensemble of models gives an even better expected target. Both Temporal Ensembling and the Mean Teacher method use this approach.</p><p>information. In effect, the model suffers from confirmation bias ( <ref type="figure" target="#fig_0">Figure 1c</ref>), a hazard that can be mitigated by improving the quality of targets.</p><p>There are at least two ways to improve the target quality. One approach is to choose the perturbation of the representations carefully instead of barely applying additive or multiplicative noise. Another approach is to choose the teacher model carefully instead of barely replicating the student model. Concurrently to our research, Miyato et al. <ref type="bibr" target="#b15">[16]</ref> have taken the first approach and shown that Virtual Adversarial Training can yield impressive results. We take the second approach and will show that it too provides significant benefits. To our understanding, these two approaches are compatible, and their combination may produce even better outcomes. However, the analysis of their combined effects is outside the scope of this paper.</p><p>Our goal, then, is to form a better teacher model from the student model without additional training. As the first step, consider that the softmax output of a model does not usually provide accurate predictions outside training data. This can be partly alleviated by adding noise to the model at inference time <ref type="bibr" target="#b3">[4]</ref>, and consequently a noisy teacher can yield more accurate targets ( <ref type="figure" target="#fig_0">Figure 1d</ref>). This approach was used in Pseudo-Ensemble Agreement <ref type="bibr" target="#b1">[2]</ref> and has lately been shown to work well on semi-supervised image classification <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b22">23]</ref>. Laine &amp; Aila <ref type="bibr" target="#b12">[13]</ref> named the method the ? model; we will use this name for it and their version of it as the basis of our experiments.</p><p>The ? model can be further improved by Temporal Ensembling <ref type="bibr" target="#b12">[13]</ref>, which maintains an exponential moving average <ref type="table">(</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Mean Teacher</head><p>To overcome the limitations of Temporal Ensembling, we propose averaging model weights instead of predictions. Since the teacher model is an average of consecutive student models, we call this the Mean Teacher method ( <ref type="figure" target="#fig_1">Figure 2</ref>). Averaging model weights over training steps tends to produce a Both the student and the teacher model evaluate the input applying noise (?, ? ) within their computation. The softmax output of the student model is compared with the one-hot label using classification cost and with the teacher output using consistency cost. After the weights of the student model have been updated with gradient descent, the teacher model weights are updated as an exponential moving average of the student weights. Both model outputs can be used for prediction, but at the end of the training the teacher prediction is more likely to be correct. A training step with an unlabeled example would be similar, except no classification cost would be applied. more accurate model than using the final weights directly <ref type="bibr" target="#b18">[19]</ref>. We can take advantage of this during training to construct better targets. Instead of sharing the weights with the student model, the teacher model uses the EMA weights of the student model. Now it can aggregate information after every step instead of every epoch. In addition, since the weight averages improve all layer outputs, not just the top output, the target model has better intermediate representations. These aspects lead to two practical advantages over Temporal Ensembling: First, the more accurate target labels lead to a faster feedback loop between the student and the teacher models, resulting in better test accuracy. Second, the approach scales to large datasets and on-line learning.</p><p>More formally, we define the consistency cost J as the expected distance between the prediction of the student model (with weights ? and noise ?) and the prediction of the teacher model (with weights ? and noise ? ).</p><formula xml:id="formula_0">J(?) = E x,? ,? f (x, ? , ? ) ? f (x, ?, ?) 2</formula><p>The difference between the ? model, Temporal Ensembling, and Mean teacher is how the teacher predictions are generated. Whereas the ? model uses ? = ?, and Temporal Ensembling approximates f (x, ? , ? ) with a weighted average of successive predictions, we define ? t at training step t as the EMA of successive ? weights:</p><formula xml:id="formula_1">? t = ?? t?1 + (1 ? ?)? t</formula><p>where ? is a smoothing coefficient hyperparameter. An additional difference between the three algorithms is that the ? model applies training to ? whereas Temporal Ensembling and Mean Teacher treat it as a constant with regards to optimization.</p><p>We can approximate the consistency cost function J by sampling noise ?, ? at each training step with stochastic gradient descent. Following Laine &amp; Aila <ref type="bibr" target="#b12">[13]</ref>, we use mean squared error (MSE) as the consistency cost in most of our experiments.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>To test our hypotheses, we first replicated the ? model <ref type="bibr" target="#b12">[13]</ref> in TensorFlow <ref type="bibr" target="#b0">[1]</ref> as our baseline. We then modified the baseline model to use weight-averaged consistency targets. The model architecture is a 13-layer convolutional neural network (ConvNet) with three types of noise: random translations and horizontal flips of the input images, Gaussian noise on the input layer, and dropout applied within the network. We use mean squared error as the consistency cost and ramp up its weight from 0 to its final value during the first 80 epochs. The details of the model and the training procedure are described in Appendix B.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Comparison to other methods on SVHN and CIFAR-10</head><p>We ran experiments using the Street View House Numbers (SVHN) and CIFAR-10 benchmarks <ref type="bibr" target="#b16">[17]</ref>. Both datasets contain 32x32 pixel RGB images belonging to ten different classes. In SVHN, each example is a close-up of a house number, and the class represents the identity of the digit at the center of the image. In CIFAR-10, each example is a natural image belonging to a class such as horses,  <ref type="bibr" target="#b15">[16]</ref> performs even better than Mean Teacher on the 1000-label SVHN and the 4000-label CIFAR-10. As discussed in the introduction, VAT and Mean Teacher are complimentary approaches. Their combination may yield better accuracy than either of them alone, but that investigation is beyond the scope of this paper.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">SVHN with extra unlabeled data</head><p>Above, we suggested that Mean Teacher scales well to large datasets and on-line learning. In addition, the SVHN and CIFAR-10 results indicate that it uses unlabeled examples efficiently. Therefore, we wanted to test whether we have reached the limits of our approach.  <ref type="table" target="#tab_4">Table 3</ref> shows the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis of the training curves</head><p>The training curves on <ref type="figure" target="#fig_2">Figure 3</ref> help us understand the effects of using Mean Teacher. As expected, the EMA-weighted models (blue and dark gray curves in the bottom row) give more accurate predictions than the bare student models (orange and light gray) after an initial period.</p><p>Using the EMA-weighted model as the teacher improves results in the semi-supervised settings. There appears to be a virtuous feedback cycle of the teacher (blue curve) improving the student (orange) via the consistency cost, and the student improving the teacher via exponential moving averaging. If this feedback cycle is detached, the learning is slower, and the model starts to overfit earlier (dark gray and light gray).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ablation experiments</head><p>To assess the importance of various aspects of the model, we ran experiments on SVHN with 250 labels, varying one or a few hyperparameters at a time while keeping the others fixed.</p><p>Removal of noise <ref type="figure" target="#fig_3">(Figures 4(a) and 4(b)</ref>). In the introduction and <ref type="figure" target="#fig_0">Figure 1</ref>, we presented the hypothesis that the ? model produces better predictions by adding noise to the model on both sides. But after the addition of Mean Teacher, is noise still needed? Yes. We can see that either input augmentation or dropout is necessary for passable performance. On the other hand, input noise does not help when augmentation is in use. Dropout on the teacher side provides only a marginal benefit over just having it on the student side, at least when input augmentation is in use.</p><p>Sensitivity to EMA decay and consistency weight <ref type="figure" target="#fig_3">(Figures 4(c) and 4(d)</ref>). The essential hyperparameters of the Mean Teacher algorithm are the consistency cost weight and the EMA decay ?. How sensitive is the algorithm to their values? We can see that in each case the good values span roughly an order of magnitude and outside these ranges the performance degrades quickly. Note that EMA decay ? = 0 makes the model a variation of the ? model, although somewhat inefficient one because the gradients are propagated through only the student path. Note also that in the evaluation runs we used EMA decay ? = 0.99 during the ramp-up phase, and ? = 0.999 for the rest of the training. We chose this strategy because the student improves quickly early in the training, and thus the teacher should forget the old, inaccurate, student weights quickly. Later the student improvement slows, and the teacher benefits from a longer memory.</p><p>Decoupling classification and consistency <ref type="figure" target="#fig_3">(Figure 4(e)</ref>). The consistency to teacher predictions may not necessarily be a good proxy for the classification task, especially early in the training. So far our model has strongly coupled these two tasks by using the same output for both. How would decoupling the tasks change the performance of the algorithm? To investigate, we changed the model to have two top layers and produce two outputs. We then trained one of the outputs for classification and the other for consistency. We also added a mean squared error cost between the output logits, and then varied the weight of this cost, allowing us to control the strength of the coupling. Looking at the results (reported using the EMA version of the classification output), we can see that the strongly coupled version performs well and the too loosely coupled versions do not. On the other hand, a moderate decoupling seems to have the benefit of making the consistency ramp-up redundant. Changing from MSE to KL-divergence <ref type="figure" target="#fig_3">(Figure 4</ref>(f)) Following Laine &amp; Aila <ref type="bibr" target="#b12">[13]</ref>, we use mean squared error (MSE) as our consistency cost function, but KL-divergence would seem a more natural choice. Which one works better? We ran experiments with instances of a cost function family ranging from MSE (? = 0 in the figure) to KL-divergence (? = 1), and found out that in this setting MSE performs better than the other cost functions. See Appendix C for the details of the cost function family and for our intuition about why MSE performs so well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Mean Teacher with residual networks on CIFAR-10 and ImageNet</head><p>In the experiments above, we used a traditional 13-layer convolutional architecture (ConvNet), which has the benefit of making comparisons to earlier work easy. In order to explore the effect of the model architecture, we ran experiments using a 12-block (26-layer) Residual Network <ref type="bibr" target="#b7">[8]</ref> (ResNet) with Shake-Shake regularization <ref type="bibr" target="#b4">[5]</ref> on CIFAR-10. The details of the model and the training procedure are described in Appendix B.2. As shown in <ref type="table" target="#tab_7">Table 4</ref>, the results improve remarkably with the better network architecture.</p><p>To test whether the methods scales to more natural images, we ran experiments on Imagenet 2012 dataset <ref type="bibr" target="#b21">[22]</ref> using 10% of the labels. We used a 50-block (152-layer) ResNeXt architecture <ref type="bibr" target="#b32">[33]</ref>, and saw a clear improvement over the state of the art. As the test set is not publicly available, we measured the results using the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related work</head><p>Noise regularization of neural networks was proposed by Sietsma &amp; Dow <ref type="bibr" target="#b25">[26]</ref>. More recently, several types of perturbations have been shown to regularize intermediate representations effectively in deep learning. Adversarial Training <ref type="bibr" target="#b5">[6]</ref> changes the input slightly to give predictions that are as different as possible from the original predictions. Dropout <ref type="bibr" target="#b27">[28]</ref> zeroes random dimensions of layer outputs. Dropconnect <ref type="bibr" target="#b30">[31]</ref> generalizes Dropout by zeroing individual weights instead of activations. Stochastic Depth <ref type="bibr" target="#b10">[11]</ref> drops entire layers of residual networks, and Swapout <ref type="bibr" target="#b26">[27]</ref> generalizes Dropout and Stochastic Depth. Shake-shake regularization <ref type="bibr" target="#b4">[5]</ref> duplicates residual paths and samples a linear combination of their outputs independently during forward and backward passes.</p><p>Several semi-supervised methods are based on training the model predictions to be consistent to perturbation. The Denoising Source Separation framework (DSS) <ref type="bibr" target="#b28">[29]</ref> uses denoising of latent variables to learn their likelihood estimate. The ? variant of Ladder Network <ref type="bibr" target="#b20">[21]</ref> implements DSS with a deep learning model for classification tasks. It produces a noisy student predictions and clean teacher predictions, and applies a denoising layer to predict teacher predictions from the student predictions. The ? model <ref type="bibr" target="#b12">[13]</ref> improves the ? model by removing the explicit denoising layer and applying noise also to the teacher predictions. Similar methods had been proposed already earlier for linear models <ref type="bibr" target="#b29">[30]</ref> and deep learning <ref type="bibr" target="#b1">[2]</ref>. Virtual Adversarial Training <ref type="bibr" target="#b15">[16]</ref> is similar to the ? model but uses adversarial perturbation instead of independent noise.</p><p>The idea of a teacher model training a student is related to model compression <ref type="bibr" target="#b2">[3]</ref> and distillation <ref type="bibr" target="#b8">[9]</ref>. The knowledge of a complicated model can be transferred to a simpler model by training the simpler model with the softmax outputs of the complicated model. The softmax outputs contain more information about the task than the one-hot outputs, and the requirement of representing this knowledge regularizes the simpler model. Besides its use in model compression, distillation can be used to harden trained models against adversarial attacks <ref type="bibr" target="#b17">[18]</ref>. The difference between distillation and consistency regularization is that distillation is performed after training whereas consistency regularization is performed on training time.</p><p>Consistency regularization can be seen as a form of label propagation <ref type="bibr" target="#b33">[34]</ref>. Training samples that resemble each other are more likely to belong to the same class. Label propagation takes advantage of this assumption by pushing label information from each example to examples that are near it according to some metric. Label propagation can also be applied to deep learning models <ref type="bibr" target="#b31">[32]</ref>. However, ordinary label propagation requires a predefined distance metric in the input space. In contrast, consistency targets employ a learned distance metric implied by the abstract representations of the model. As the model learns new features, the distance metric changes to accommodate these features. Therefore, consistency targets guide learning in two ways. On the one hand they spread the labels according to the current distance metric, and on the other hand, they aid the network learn a better distance metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Temporal Ensembling, Virtual Adversarial Training and other forms of consistency regularization have recently shown their strength in semi-supervised learning. In this paper, we propose Mean Teacher, a method that averages model weights to form a target-generating teacher model. Unlike Temporal Ensembling, Mean Teacher works with large datasets and on-line learning. Our experiments suggest that it improves the speed of learning and the classification accuracy of the trained network. In addition, it scales well to state-of-the-art architectures and large image sizes.</p><p>The success of consistency regularization depends on the quality of teacher-generated targets. If the targets can be improved, they should be. Mean Teacher and Virtual Adversarial Training represent two ways of exploiting this principle. Their combination may yield even better targets. There are probably additional methods to be uncovered that improve targets and trained models even further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Results without input augmentation</head><p>See <ref type="table" target="#tab_8">table 5</ref> for the results without input augmentation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Convolutional network models</head><p>We replicated the ? model of Laine &amp; Aila <ref type="bibr" target="#b12">[13]</ref> in TensorFlow <ref type="bibr" target="#b0">[1]</ref>, and added support for Mean Teacher training. We modified the model slightly to match the requirements of the experiments, as described in subsections B. <ref type="figure" target="#fig_0">1.1 and B.1.2</ref>. The difference between the original ? model described by Laine &amp; Aila <ref type="bibr" target="#b12">[13]</ref> and our baseline ? model thus depends on the experiment. The difference between our baseline ? model and our Mean Teacher model is whether the teacher weights are identical to the student weights or an EMA of the student weights. In addition, the ? models (both the original and ours) backpropagate gradients to both sides of the model whereas Mean Teacher applies them only to the student side. <ref type="table" target="#tab_9">Table 6</ref> describes the architecture of the convolutional network. We applied mean-only batch normalization and weight normalization <ref type="bibr" target="#b23">[24]</ref> on convolutional and softmax layers. We used Leaky ReLu <ref type="bibr" target="#b14">[15]</ref> with ? = 0.1 as the nonlinearity on each of the convolutional layers.</p><p>We used cross-entropy between the student softmax output and the one-hot label as the classification cost, and the mean square error between the student and teacher softmax outputs as the consistency cost. The total cost was the weighted sum of these costs, where the weight of classification cost was the expected number of labeled examples per minibatch, subject to the ramp-ups described below.</p><p>We trained the network with minibatches of size 100. We used Adam Optimizer <ref type="bibr" target="#b11">[12]</ref> for training with learning rate 0.003 and parameters ? 1 = 0.9, ? 2 = 0.999, and ? = 10 ?8 . In our baseline ? model we applied gradients through both teacher and student sides of the network. In Mean teacher model, the teacher model parameters were updated after each training step using an EMA with ? = 0.999. These hyperparameters were subject to the ramp-ups and ramp-downs described below.</p><p>We applied a ramp-up period of 40000 training steps at the beginning of training. The consistency cost coefficient and the learning rate were ramped up from 0 to their maximum values, using a sigmoid-shaped function e ?5(1?x) <ref type="bibr" target="#b1">2</ref> , where x ? [0, 1].</p><p>We used different training settings in different experiments. In the CIFAR-10 experiment, we matched the settings of Laine &amp; Aila <ref type="bibr" target="#b12">[13]</ref> as closely as possible. In the SVHN experiments, we diverged from Laine &amp; Aila <ref type="bibr" target="#b12">[13]</ref> to accommodate for the sparsity of labeled data. <ref type="table" target="#tab_10">Table 7</ref> summarizes the differences between our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1.1 ConvNet on CIFAR-10</head><p>We normalized the input images with ZCA based on training set statistics.</p><p>For sampling minibatches, the labeled and unlabeled examples were treated equally, and thus the number of labeled examples varied from minibatch to minibatch.</p><p>We applied a ramp-down for the last 25000 training steps. The learning rate coefficient was ramped down to 0 from its maximum value. Adam ? 1 was ramped down to 0.5 from its maximum value. The ramp-downs were performed using sigmoid-shaped function 1 ? e ?12.5x 2 , where x ? [0, 1]. These ramp-downs did not improve the results, but were used to stay as close as possible to the settings of Laine &amp; Aila <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1.2 ConvNet on SVHN</head><p>We normalized the input images to have zero mean and unit variance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1.3 The baseline ConvNet models</head><p>For training the supervised-only and ? model baselines we used the same hyperparameters as for training the Mean Teacher, except we stopped training earlier to prevent over-fitting. For supervisedonly runs we did not include any unlabeled examples and did not apply the consistency cost.</p><p>We trained the supervised-only model on CIFAR-10 for 7500 steps when using 1000 images, for 15000 steps when using 2000 images, for 30000 steps when using 4000 images and for 150000 steps when using all images. We trained it on SVHN for 40000 steps when using 250, 500 or 1000 labels, and for 180000 steps when using all labels.</p><p>We trained the ? model on CIFAR-10 for 60000 steps when using 1000 labels, for 100000 steps when using 2000 labels, and for 180000 steps when using 4000 labels or all labels. We trained it on SVHN for 100000 steps when using 250 labels, and for 180000 steps when using 500, 1000, or all labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Residual network models</head><p>We implemented our residual network experiments in PyTorch 1 . We used different architectures for our CIFAR-10 and ImageNet experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2.1 ResNet on CIFAR-10</head><p>For CIFAR-10, we replicated the 26-2x96d Shake-Shake regularized architecture described in <ref type="bibr" target="#b4">[5]</ref>, and consisting of 4+4+4 residual blocks.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Use of training, validation and test data</head><p>In the development phase of our work with CIFAR-10 and SVHN datasets, we separated 10% of training data into a validation set. We removed randomly most of the labels from the remaining training data, retaining an equal number of labels from each class. We used a different set of labels for each of the evaluation runs. We retained labels in the validation set to enable exploration of the results. In the final evaluation phase we used the entire training set, including the validation set but with labels removed.</p><p>On a real-world use case we would not possess a large fully-labeled validation set. However, this setup is useful in a research setting, since it enables a more thorough analysis of the results. To the best of our knowledge, this is the common practice when carrying out research on semi-supervised learning. By retaining the hyperparameters from previous work where possible we decreased the chance of over-fitting our results to validation labels.</p><p>In the ImageNet experiments we removed randomly most of the labels from the training set, retaining an equal number of labels from each class. For validation we used the given validation set without modifications. We used a different set of training labels for each of the evaluation runs and evaluated the results against the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Varying between mean squared error and KL-divergence</head><p>As mentioned in subsection 3.4, we ran an experiment varying the consistency cost function between MSE and KL-divergence (reproduced in <ref type="figure" target="#fig_5">Figure 5</ref>). The exact consistency function we used was C ? (p, q) = Z ? D KL (p ? q ? ), where Z ? = 2 N 2 ? 2 , p ? = ? p + 1 ? ? N , q ? = ? q + 1 ? ? N , ? ? (0, 1] and N is the number of classes. Taking the Taylor expansion we get</p><formula xml:id="formula_2">D KL (p i q i ) = i 1 2 ? 2 N (p i ? q i ) 2 + O N 2 ? 3</formula><p>where the zeroth-and first-order terms vanish. Consequently,</p><formula xml:id="formula_3">C ? (p, q) ? 1 N i (p i ? q i ) 2 when ? ? 0 C ? (p, q) = 2 N 2 D KL (p q) when ? = 1.</formula><p>The results in <ref type="figure" target="#fig_5">Figure 5</ref> show that MSE performs better than KL-divergence or C ? with any ? . We also tried other consistency cost weights with KL-divergence and did not reach the accuracy of MSE.</p><p>The exact reason why MSE performs better than KL-divergence remains unclear, but the form of C ? may help explain it. Modern neural network architectures tend to produce accurate but overly confident predictions <ref type="bibr" target="#b6">[7]</ref>. We can assume that the true labels are accurate, but we should discount the confidence of the teacher predictions. We can do that by having ? = 1 for the classification cost and ? &lt; 1 for the consistency cost. Then p ? and q ? discount the confidence of the approximations while Z ? keeps gradients large enough to provide a useful training signal. However, we did not perform experiments to validate this explanation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A sketch of a binary classification task with two labeled examples (large blue dots) and one unlabeled example, demonstrating how the choice of the unlabeled target (black circle) affects the fitted function (gray curve). (a) A model with no regularization is free to fit any function that predicts the labeled training examples well. (b) A model trained with noisy labeled data (small dots) learns to give consistent predictions around labeled data points. (c) Consistency to noise around unlabeled examples provides additional smoothing. For the clarity of illustration, the teacher model (gray curve) is first fitted to the labeled examples, and then left unchanged during the training of the student model. Also for clarity, we will omit the small dots in figures d and e. (d) Noise on the teacher model reduces the bias of the targets without additional training. The expected direction of stochastic gradient descent is towards the mean (large blue circle) of individual noisy targets (small blue circles).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The Mean Teacher method. The figure depicts a training batch with a single labeled example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Smoothened classification cost (top) and classification error (bottom) of Mean Teacher and our baseline ? model on SVHN over the first 100000 training steps. In the upper row, the training classification costs are measured using only labeled data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Validation error on 250-label SVHN over four runs per hyperparameter setting and their means. In each experiment, we varied one hyperparameter, and used the evaluation run hyperparameters ofTable 1for the rest. The hyperparameter settings used in the evaluation runs are marked with the bolded font weight. See the text for details.Mean Teacher uses unlabeled training data more efficiently than the ? model, as seen in the middle column. On the other hand, with 500k extra unlabeled examples (right column), ? model keeps improving for longer. Mean Teacher learns faster, and eventually converges to a better result, but the sheer amount of data appears to offset ? model's worse predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>When doing semi-supervised training, we used 1 labeled example and 99 unlabeled examples in each mini-batch. This was important to speed up training when using extra unlabeled data. After all labeled examples had been used, they were shuffled and reused. Similarly, after all unlabeled examples had been used, they were shuffled and reused. We applied different values for Adam ? 2 and EMA decay rate during the ramp-up period and the rest of the training. Both of the values were 0.99 during the first 40000 steps, and 0.999 afterwards. This helped the 250-label case converge reliably. We trained the network for 180000 steps when not using extra unlabeled examples, for 400000 steps when using 100k extra unlabeled examples, and for 600000 steps when using 500k extra unlabeled examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Copy of Figure 4(f) in the main text. Validation error on 250-label SVHN over four runs and their mean, when varying the consistency cost shape hyperparameter ? between mean squared error (? = 0) and KL-divergence (? = 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>EMA) prediction for each of the training examples. At each training step, all the EMA predictions of the examples in that minibatch are updated based on the new predictions. Consequently, the EMA prediction of each example is formed by an ensemble of the model's current version and those earlier versions that evaluated the same example. This ensembling improves the quality of the predictions, and using them as the teacher predictions improves results. However, since each target is updated only once per epoch, the learned information is incorporated into the training process at a slow pace. The larger the dataset, the longer the span of the updates, and in the case of on-line learning, it is unclear how Temporal Ensembling can be used at all. (One could evaluate all the targets periodically more than once per epoch, but keeping the evaluation span constant would require O(n 2 ) evaluations per epoch where n is the number of training examples.)</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Error rate percentage on SVHN over 10 runs (4 runs when using all labels). We use exponential moving average weights in the evaluation of all our models. All the methods use a similar 13-layer ConvNet architecture. SeeTable 5in the Appendix for results without input augmentation.</figDesc><table><row><cell></cell><cell>250 labels</cell><cell>500 labels</cell><cell>1000 labels</cell><cell>73257 labels</cell></row><row><cell></cell><cell>73257 images</cell><cell>73257 images</cell><cell>73257 images</cell><cell>73257 images</cell></row><row><cell>GAN [25]</cell><cell></cell><cell>18.44 ? 4.8</cell><cell>8.11 ? 1.3</cell><cell></cell></row><row><cell>? model [13]</cell><cell></cell><cell>6.65 ? 0.53</cell><cell>4.82 ? 0.17</cell><cell>2.54 ? 0.04</cell></row><row><cell cols="2">Temporal Ensembling [13]</cell><cell>5.12 ? 0.13</cell><cell>4.42 ? 0.16</cell><cell>2.74 ? 0.06</cell></row><row><cell>VAT+EntMin [16]</cell><cell></cell><cell></cell><cell>3.86 3.86 3.86</cell><cell></cell></row><row><cell>Supervised-only</cell><cell>27.77 ? 3.18</cell><cell>16.88 ? 1.30</cell><cell>12.32 ? 0.95</cell><cell>2.75 ? 0.10</cell></row><row><cell>? model</cell><cell>9.69 ? 0.92</cell><cell>6.83 ? 0.66</cell><cell>4.95 ? 0.26</cell><cell>2.50 ? 0.07</cell></row><row><cell>Mean Teacher</cell><cell>4.35 ? 0.50 4.35 ? 0.50 4.35 ? 0.50</cell><cell>4.18 ? 0.27 4.18 ? 0.27 4.18 ? 0.27</cell><cell>3.95 ? 0.19</cell><cell>2.50 ? 0.05 2.50 ? 0.05 2.50 ? 0.05</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell>1000 labels</cell><cell>2000 labels</cell><cell>4000 labels</cell><cell>50000 labels</cell></row><row><cell>50000 images</cell><cell>50000 images</cell><cell>50000 images</cell><cell>50000 images</cell></row><row><cell>GAN [25]</cell><cell></cell><cell>18.63 ? 2.32</cell><cell></cell></row></table><note>Error rate percentage on CIFAR-10 over 10 runs (4 runs when using all labels).? model [13] 12.36 ? 0.31 5.56 ? 0.10 Temporal Ensembling [13] 12.16 ? 0.31 5.60 ? 0.10 5.60 ? 0.10 5.60 ? 0.10 VAT+EntMin [16] 10.55 10.55 10.55 Supervised-only 46.43 ? 1.21 33.94 ? 0.73 20.66 ? 0.57 5.82 ? 0.15 ? model 27.36 ? 1.20 18.02 ? 0.60 13.20 ? 0.27 6.06 ? 0.11 Mean Teacher 21.55 ? 1.48 21.55 ? 1.48 21.55 ? 1.48 15.73 ? 0.31 15.73 ? 0.31 15.73 ? 0.31 12.31 ? 0.28 5.94 ? 0.15</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>cats, cars and airplanes. SVHN contains of 73257 training samples and 26032 test samples. CIFAR-10 consists of 50000 training samples and 10000 test samples.</figDesc><table /><note>Tables 1 and 2 compare the results against recent state-of-the-art methods. All the methods in the comparison use a similar 13-layer ConvNet architecture. Mean Teacher improves test accuracy over the ? model and Temporal Ensembling on semi-supervised SVHN tasks. Mean Teacher also improves results on CIFAR-10 over our baseline ? model. The recently published version of Virtual Adversarial Training by Miyato et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Error percentage over 10 runs on SVHN with extra unlabeled training data.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">500 labels</cell><cell></cell><cell cols="2">500 labels</cell><cell></cell><cell cols="2">500 labels</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">73257 images</cell><cell></cell><cell cols="2">173257 images</cell><cell cols="3">573257 images</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">? model (ours)</cell><cell cols="3">6.83 ? 0.66</cell><cell></cell><cell cols="2">4.49 ? 0.27</cell><cell></cell><cell cols="2">3.26 ? 0.14</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Mean Teacher</cell><cell></cell><cell cols="3">4.18 ? 0.27 4.18 ? 0.27 4.18 ? 0.27</cell><cell></cell><cell cols="2">3.02 ? 0.16 3.02 ? 0.16 3.02 ? 0.16</cell><cell></cell><cell cols="2">2.46 ? 0.06 2.46 ? 0.06 2.46 ? 0.06</cell></row><row><cell></cell><cell></cell><cell>10 1</cell><cell></cell><cell cols="4">73257 images and labels</cell><cell></cell><cell></cell><cell cols="4">73257 images and 500 labels</cell><cell></cell><cell cols="2">573257 images and 500 labels</cell></row><row><cell cols="2">classification cost</cell><cell>10 3 10 2 10 1 10 0</cell><cell></cell><cell cols="4">model (test set) Mean teacher (student, test set) model (training) Mean teacher (student, training)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>classification error</cell><cell cols="2">5% 10% 20% 50% 100%</cell><cell></cell><cell></cell><cell cols="3">model model (EMA) Mean teacher (student) Mean teacher (teacher)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2%</cell><cell>0k</cell><cell>20k</cell><cell>40k</cell><cell>60k</cell><cell cols="2">80k 100k</cell><cell>0k</cell><cell>20k</cell><cell>40k</cell><cell>60k</cell><cell>80k 100k</cell><cell>0k</cell><cell>20k</cell><cell>40k</cell><cell>60k</cell><cell>80k 100k</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Besides the primary training data, SVHN includes also an extra dataset of 531131 examples. We picked 500 samples from the primary training as our labeled training examples. We used the rest of the primary training set together with the extra training set as unlabeled examples. We ran experiments with Mean Teacher and our baseline ? model, and used either 0, 100000 or 500000 extra examples.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Error rate percentage of ResNet Mean Teacher compared to the state of the art. We report the test results from 10 runs on CIFAR-10 and validation results from 2 runs on ImageNet.</figDesc><table><row><cell></cell><cell>CIFAR-10</cell><cell>ImageNet 2012</cell></row><row><cell></cell><cell>4000 labels</cell><cell>10% of the labels</cell></row><row><cell>State of the art</cell><cell>10.55 [16]</cell><cell>35.24 ? 0.90 [20]</cell></row><row><cell>ConvNet Mean Teacher</cell><cell>12.31 ? 0.28</cell><cell></cell></row><row><cell>ResNet Mean Teacher</cell><cell>6.28 ? 0.15 6.28 ? 0.15 6.28 ? 0.15</cell><cell>9.11 ? 0.12 9.11 ? 0.12 9.11 ? 0.12</cell></row><row><cell>State of the art using all labels</cell><cell>2.86 [5]</cell><cell>3.79 [10]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Error rate percentage on SVHN and CIFAR-10 over 10 runs, including the results without input augmentation. We use exponential moving average weights in the evaluation of all our models. All the comparison methods use a 13-layer ConvNet architecture similar to ours and augmentation similar to ours, expect GAN, which does not use augmentation. ? 1.07 36.07 ? 0.90<ref type="bibr" target="#b23">24</ref>.47 ? 0.50 7.43 ? 0.06 ? model 32.18 ? 1.33 23.92 ? 1.07 17.08 ? 0.32 7.00 ? 0.20 Mean Teacher 30.62 ? 1.13 23.14 ? 0.46 17.74 ? 0.30 7.21 ? 0.24 a 4 runs b Salimans et al. [25] c Laine &amp; Aila [13] d Miyato et al. [16] e Only labeled examples and only classification cost</figDesc><table><row><cell>SVHN</cell><cell>250 labels</cell><cell>500 labels</cell><cell>1000 labels</cell><cell>all labels a</cell></row><row><cell>GAN b</cell><cell></cell><cell>18.44 ? 4.8</cell><cell>8.11 ? 1.3</cell><cell></cell></row><row><cell>? model c</cell><cell></cell><cell>6.65 ? 0.53</cell><cell cols="2">4.82 ? 0.17 2.54 ? 0.04</cell></row><row><cell>Temporal Ensembling c</cell><cell></cell><cell>5.12 ? 0.13</cell><cell cols="2">4.42 ? 0.16 2.74 ? 0.06</cell></row><row><cell>VAT+EntMin d</cell><cell></cell><cell></cell><cell>3.86 3.86 3.86</cell><cell></cell></row><row><cell>Ours</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Supervised-only e</cell><cell cols="2">27.77 ? 3.18 16.88 ? 1.30</cell><cell cols="2">12.32 ? 0.95 2.75 ? 0.10</cell></row><row><cell>? model</cell><cell>9.69 ? 0.92</cell><cell>6.83 ? 0.66</cell><cell cols="2">4.95 ? 0.26 2.50 ? 0.07</cell></row><row><cell>Mean Teacher</cell><cell>4.35 ? 0.50 4.35 ? 0.50 4.35 ? 0.50</cell><cell>4.18 ? 0.27 4.18 ? 0.27 4.18 ? 0.27</cell><cell cols="2">3.95 ? 0.19 2.50 ? 0.05 2.50 ? 0.05 2.50 ? 0.05</cell></row><row><cell>Without augmentation</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Supervised-only e</cell><cell cols="2">36.26 ? 3.83 19.68 ? 1.03</cell><cell cols="2">14.15 ? 0.87 3.04 ? 0.04</cell></row><row><cell>? model</cell><cell>10.36 ? 0.94</cell><cell>7.01 ? 0.29</cell><cell cols="2">5.73 ? 0.16 2.75 ? 0.08</cell></row><row><cell>Mean Teacher</cell><cell>5.85 ? 0.62</cell><cell>5.45 ? 0.14</cell><cell cols="2">5.21 ? 0.21 2.77 ? 0.09</cell></row><row><cell>CIFAR-10</cell><cell>1000 labels</cell><cell>2000 labels</cell><cell>4000 labels</cell><cell>all labels a</cell></row><row><cell>GAN b</cell><cell></cell><cell></cell><cell>18.63 ? 2.32</cell><cell></cell></row><row><cell>? model c</cell><cell></cell><cell></cell><cell cols="2">12.36 ? 0.31 5.56 ? 0.10 5.56 ? 0.10 5.56 ? 0.10</cell></row><row><cell>Temporal Ensembling c</cell><cell></cell><cell></cell><cell cols="2">12.16 ? 0.31 5.60 ? 0.10</cell></row><row><cell>VAT+EntMin d</cell><cell></cell><cell></cell><cell>10.55</cell><cell></cell></row><row><cell>Ours</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Supervised-only e</cell><cell cols="4">46.43 ? 1.21 33.94 ? 0.73 20.66 ? 0.57 5.82 ? 0.15</cell></row><row><cell>? model</cell><cell cols="4">27.36 ? 1.20 18.02 ? 0.60 13.20 ? 0.27 6.06 ? 0.11</cell></row><row><cell>Mean Teacher</cell><cell cols="4">21.55 ? 1.48 15.73 ? 0.31 15.73 ? 0.31 15.73 ? 0.31 12.31 ? 0.28 5.94 ? 0.15</cell></row><row><cell cols="2">Mean Teacher ResNet 10.08 ? 0.41 10.08 ? 0.41 10.08 ? 0.41</cell><cell></cell><cell>6.28 ? 0.15 6.28 ? 0.15 6.28 ? 0.15</cell><cell></cell></row><row><cell>Without augmentation</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Supervised-only e 48.38 B Experimental setup</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Source code for the experiments is available at https://github.com/CuriousAI/</cell></row><row><cell>mean-teacher.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>The convolutional network architecture we used in the experiments.</figDesc><table><row><cell>Layer</cell><cell>Hyperparameters</cell></row><row><cell>Input</cell><cell>32 ? 32 RGB image</cell></row><row><cell>Translation</cell><cell>Randomly {?x, ?y} ? [?2, 2]</cell></row><row><cell cols="2">Horizontal flip a Randomly p = 0.5</cell></row><row><cell cols="2">Gaussian noise ? = 0.15</cell></row><row><cell>Convolutional</cell><cell>128 filters, 3 ? 3, same padding</cell></row><row><cell>Convolutional</cell><cell>128 filters, 3 ? 3, same padding</cell></row><row><cell>Convolutional</cell><cell>128 filters, 3 ? 3, same padding</cell></row><row><cell>Pooling</cell><cell>Maxpool 2 ? 2</cell></row><row><cell>Dropout</cell><cell>p = 0.5</cell></row><row><cell>Convolutional</cell><cell>256 filters, 3 ? 3, same padding</cell></row><row><cell>Convolutional</cell><cell>256 filters, 3 ? 3, same padding</cell></row><row><cell>Convolutional</cell><cell>256 filters, 3 ? 3, same padding</cell></row><row><cell>Pooling</cell><cell>Maxpool 2 ? 2</cell></row><row><cell>Dropout</cell><cell>p = 0.5</cell></row><row><cell>Convolutional</cell><cell>512 filters, 3 ? 3, valid padding</cell></row><row><cell>Convolutional</cell><cell>256 filters, 1 ? 1, same padding</cell></row><row><cell>Convolutional</cell><cell>128 filters, 1 ? 1, same padding</cell></row><row><cell>Pooling</cell><cell>Average pool (6 ? 6 ? 1?1 pixels)</cell></row><row><cell>Softmax</cell><cell>Fully connected 128 ? 10</cell></row></table><note>a Not applied on SVHN experiments</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Differences in training settings between the ConvNet experiments after 210 epochs (when 1000 labels) or 350 epochs (when 4000 labels). We define epoch as one pass through all the unlabeled examples -each labeled example was included many times in one such epoch.</figDesc><table><row><cell></cell><cell>semi-supervised</cell><cell>supervised</cell><cell>semi-supervised</cell></row><row><cell>Aspect</cell><cell>SVHN</cell><cell>SVHN</cell><cell>CIFAR-10</cell></row><row><cell></cell><cell>zero mean,</cell><cell>zero mean,</cell><cell></cell></row><row><cell>image pre-processing</cell><cell>unit variance</cell><cell cols="2">unit variance ZCA</cell></row><row><cell></cell><cell></cell><cell></cell><cell>translation +</cell></row><row><cell>image augmentation</cell><cell>translation</cell><cell>translation</cell><cell>horizontal flip</cell></row><row><cell>number of labeled</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">examples per minibatch 1</cell><cell>100</cell><cell>varying</cell></row><row><cell>training steps</cell><cell>180000-600000</cell><cell>180000</cell><cell>150000</cell></row><row><cell>Adam ? 2 during</cell><cell></cell><cell></cell><cell></cell></row><row><cell>and after ramp-up</cell><cell>0.99, 0.999</cell><cell>0.99, 0.999</cell><cell>0.999, 0.999</cell></row><row><cell>EMA decay rate during</cell><cell></cell><cell></cell><cell></cell></row><row><cell>and after ramp-up</cell><cell>0.99, 0.999</cell><cell>0.99, 0.999</cell><cell>0.999, 0.999</cell></row><row><cell>Ramp-downs</cell><cell>No</cell><cell>No</cell><cell>Yes</cell></row><row><cell>have reached zero</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/pytorch/pytorch</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Samuli Laine and Timo Aila for fruitful discussions about their work, Phil Bachman, Colin Raffel, and Thomas Robert for noticing errors in the previous versions of this paper and everyone at The Curious AI Company for their help, encouragement, and ideas.</p><p>We trained the network on 4 GPUs using minibatches of 512 images, 124 of which were labeled. We sampled the images in the same way as described in the SVHN experiments above. We augmented the input images with 4x4 random translations (reflecting the pixels at borders when necessary) and random horizontal flips. (Note that following <ref type="bibr" target="#b4">[5]</ref> we used a larger translation size than on our earlier experiments.) We normalized the images to have channel-wise zero mean and unit variance over training data.</p><p>We trained the network using stochastic gradient descent with initial learning rate 0.2 and Nesterov momentum 0.9. We trained for 180 epochs (when training with 1000 labels) or 300 epochs (when training with 4000 labels), decaying the learning rate with cosine annealing <ref type="bibr" target="#b13">[14]</ref> so that it would</p><p>We used a total cost function consisting of classification cost and three other costs: We used the dual output trick described in subsection 3.4 and <ref type="figure">Figure 4</ref>(e) with MSE cost between logits with coefficient 0.01. This simplified other hyperparameter choices and improved the results. We used MSE consistency cost with coefficient ramping up from 0 to 100.0 during the first 5 epochs, using the same sigmoid ramp-up shape as in the experiments above. We also used an L2 weight decay with coefficient 2e-4. We used EMA decay value 0.97 (when 1000 labels) or 0.99 (when 4000 labels).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2.2 ResNet on ImageNet</head><p>On our ImageNet evaluation runs, we used a 152-layer ResNeXt architecture <ref type="bibr" target="#b32">[33]</ref> consisting of 3+8+36+3 residual blocks, with 32 groups of 4 channels on the first block.</p><p>We trained the network on 10 GPUs using minibatches of 400 images, 200 of which were labeled. We sampled the images in the same way as described in the SVHN experiments above. Following <ref type="bibr" target="#b9">[10]</ref>, we randomly augmented images using a 10 degree rotation, a crop with aspect ratio between 3/4 and 4/3 resized to 224x224 pixels, a random horizontal flip and a color jitter. We then normalized images to have channel-wise zero mean and unit variance over training data.</p><p>We trained the network using stochastic gradient descent with maximum learning rate 0.25 and Nesterov momentum 0.9. We ramped up the learning rate linearly during the first two epochs from 0.1 to 0.25. We trained for 60 epochs, decaying the learning rate with cosine annealing so that it would have reached zero after 75 epochs.</p><p>We used a total cost function consisting of classification cost and three other costs: We used the dual output trick described in subsection 3.4 and <ref type="figure">Figure 4</ref>(e) with MSE cost between logits with coefficient 0.01. We used a KL-divergence consistency cost with coefficient ramping up from 0 to 10.0 during the first 5 epochs, using the same sigmoid ramp-up shape as in the experiments above. We also used an L2 weight decay with coefficient 5e-5. We used EMA decay value 0.9997.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eugene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhifeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Craig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yangqing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lukasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Man?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rajat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Derek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mike</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Benoit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vijay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vi?gas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fernanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oriol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tensorflow</surname></persName>
		</author>
		<title level="m">Large-Scale Machine Learning on Heterogeneous Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ouais</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Precup</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1412.4864</idno>
		<idno>arXiv: 1412.4864</idno>
	</analytic>
	<monogr>
		<title level="j">Doina. Learning with Pseudo-Ensembles</title>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Alexandru. Model compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Bucilu?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="535" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1050" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Gastaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07485</idno>
		<idno>arXiv: 1705.07485</idno>
		<title level="m">Shake-Shake regularization</title>
		<imprint>
			<date type="published" when="2017-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Explaining and Harnessing Adversarial Examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On Calibration of Modern Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Geoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04599</idno>
		<idno>arXiv: 1706.04599</idno>
		<imprint>
			<date type="published" when="2017-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiangyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<idno>arXiv: 1512.03385</idno>
		<title level="m">Deep Residual Learning for Image Recognition</title>
		<imprint>
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<idno>arXiv: 1503.02531</idno>
		<title level="m">Distilling the Knowledge in a Neural Network</title>
		<imprint>
			<date type="published" when="2015-03" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Squeeze-And-Excitation</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Networks</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.01507</idno>
		<idno>arXiv: 1709.01507</idno>
		<imprint>
			<date type="published" when="2017-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.09382</idno>
		<idno>arXiv: 1603.09382</idno>
		<title level="m">Deep Networks with Stochastic Depth</title>
		<imprint>
			<date type="published" when="2016-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<idno>arXiv: 1412.6980</idno>
		<title level="m">A Method for Stochastic Optimization</title>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aila</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02242</idno>
		<idno>arXiv: 1610.02242</idno>
		<title level="m">Temporal Ensembling for Semi-Supervised Learning</title>
		<imprint>
			<date type="published" when="2016-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sgdr</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<idno>arXiv: 1608.03983</idno>
		<title level="m">Stochastic Gradient Descent with Warm Restarts</title>
		<imprint>
			<date type="published" when="2016-08" />
		</imprint>
	</monogr>
	<note>cs, math</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Awni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Virtual Adversarial Training: a Regularization Method for Supervised and Semi-supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Takeru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shin-Ichi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Ishii</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03976</idno>
		<idno>arXiv: 1704.03976</idno>
		<imprint>
			<date type="published" when="2017-04" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.04508</idno>
		<idno>arXiv: 1511.04508</idno>
		<imprint>
			<date type="published" when="2015-11" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Acceleration of Stochastic Approximation by Averaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Polyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Juditsky</surname></persName>
		</author>
		<idno type="DOI">10.1137/0330046</idno>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Control Optim</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="838" to="855" />
			<date type="published" when="1992-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchen</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chunyuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08976</idno>
		<idno>arXiv: 1609.08976</idno>
		<title level="m">Variational Autoencoder for Deep Learning of Images, Labels and Captions</title>
		<imprint>
			<date type="published" when="2016-09" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semisupervised Learning with Ladder Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Cortes, C., Lawrence, N. D., Lee, D. D., Sugiyama, M., and Garnett, R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3546" to="3554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sanjeev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhiheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0575</idno>
		<idno>arXiv: 1409.0575</idno>
		<title level="m">Li. ImageNet Large Scale Visual Recognition Challenge</title>
		<imprint>
			<date type="published" when="2014-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehran</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Lee, D. D., Sugiyama, M., Luxburg, U. V., Guyon, I., and Garnett, R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1163" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="901" to="901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wojciech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2226" to="2234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Creating artificial neural networks that generalize</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jocelyn</forename><surname>Sietsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="79" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saurabh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swapout</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.06465</idno>
		<idno>arXiv: 1605.06465</idno>
		<title level="m">Learning an ensemble of deep architectures</title>
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno>1532-4435</idno>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Denoising Source Separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>S?rel?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
		<idno>1533-7928</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="233" to="272" />
			<date type="published" when="2005-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Wager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1307.1493</idno>
		<idno>arXiv: 1307.1493</idno>
		<title level="m">Dropout Training as Adaptive Regularization</title>
		<imprint>
			<date type="published" when="2013-07" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Regularization of Neural Networks using DropConnect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sixin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Cun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1058" to="1066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep learning via semi-supervised embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ratle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fr?d?ric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the Trade</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="639" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Aggregated Residual Transformations for Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saining</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Piotr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05431</idno>
		<idno>arXiv: 1611.05431</idno>
		<imprint>
			<date type="published" when="2016-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Learning from labeled and unlabeled data with label propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
