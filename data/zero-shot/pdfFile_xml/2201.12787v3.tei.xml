<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GRPE: Relative Positional Encoding for Graph Transformer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonpyo</forename><surname>Park</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<addrLine>2 Standigm</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woonggi</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<addrLine>2 Standigm</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donggeon</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<addrLine>2 Standigm</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juntae</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<addrLine>2 Standigm</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung-Won</forename><surname>Hwang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<addrLine>2 Standigm</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GRPE: Relative Positional Encoding for Graph Transformer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a novel positional encoding for learning graph on Transformer architecture. Existing approaches either linearize a graph to encode absolute position in the sequence of nodes, or encode relative position with another node using bias terms. The former loses preciseness of relative position from linearization, while the latter loses a tight integration of node-edge and node-topology interaction. To overcome the weakness of the previous approaches, our method encodes a graph without linearization and considers both node-topology and node-edge interaction. We name our method Graph Relative Positional Encoding dedicated to graph representation learning. Experiments conducted on various graph datasets show that the proposed method outperforms previous approaches significantly.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Transformer <ref type="bibr" target="#b17">(Vaswani et al. 2017)</ref> built upon a self-attention module is permutation equivariant where an order of inputs does not affect corresponding outputs. Therefore, Transformer requires explicit representations of the position of inputs to effectively learn any structured data. In the case of natural language processing or computer vision, absolute positional encoding is widely adopted as each input has its own absolute position, e.g., n-th order of word in a sentence or coordinates of a patch within a grid. The positional embedding vector of the absolute position is added to the input before feeding to Transformer. However, adopting this absolute positional encoding on a graph is not trivial since nodes do not have absolute positions such as order. Therefore, representing the position of each node in a graph is a key challenge in designing a Transformer for a graph.</p><p>Several works have been proposed to incorporate positional information of graph on Transformer, and we categorize existing works into two: (a) linearizing graph to encode the absolute position of each node <ref type="bibr" target="#b7">(Dwivedi and Bresson 2020;</ref><ref type="bibr" target="#b13">Kreuzer et al. 2021</ref>) using techniques like graph Laplacian or singular value decomposition (b) encoding position relative to another node with bias terms <ref type="bibr" target="#b20">(Ying et al. 2021)</ref>. The former loses precision of position due to linearization, while the latter loses a tight integration of nodeedge and node-topology information. * These authors contributed equally.  <ref type="figure">Figure 1</ref>: How our method builds attention map a topology reflcting node-topology information, by interaction between node feature q, k and topology encoding P representing adjacency and shortest path. We illustrate with P 1 capturing relations within 1-hop distance, though we generalize for P l . Similarly, attention map a edge reflects diverse edge types, and interaction between node feature and edge encoding. We skip the illustration of node-edge information for simplification.</p><p>On the other hand, ours can be interpreted as overcoming the weakness of (a) and (b): <ref type="figure">Figure 1</ref> illustrates that our method reflects global topology as attention map, while incorporating node-topology interaction. More specifically, unlike conventional approaches (a) and (b), limited to encode graph only on either the initial input <ref type="figure">(Figure 2a</ref>) or attention map <ref type="figure">(Figure 2b)</ref>, our method encodes positional information when node features interact with each other on self-attention. <ref type="figure">Figure 2c</ref> shows our architecture where the topology and edge of a graph are encoded on both attention map and value.</p><p>To this end, we introduce two set of learnable positional encoding vectors which represent relative positional relation. The first is topology encoding to represent topological relation between nodes. The second is edge encoding to represent connection between nodes. Node features and the two encoding vectors interact to integrate both node-topology and node-edge interaction when building attention map. (a) <ref type="figure">Figure 2</ref>: Contrasting ours from previous approaches by where graph positional information is encoded, i.e., components marked in red. Existing works either (a) linearize a graph to obtain absolute positional encoding for initial inputs or (b) add bias terms for attention map. On the other hand, (c) our method encodes on both attention map and value, capturing node-topology and node-edge relations. We skip the illustration of edge encoding for simplification. thermore, we leverage the two positional encodings to incorporate graph on the hidden representations of self-attention. With these two positional encodings, topology of a graph can be represented in both attention map and value.</p><p>In terms of utilizing relative position between inputs and incorporating interaction between input feature and positional encoding, our work is related to the work of Shaw, Uszkoreit, and Vaswani. Its efficacy has been verified in sequences, e.g., natural language processing, but does not generalize to a graph. Our proposed relative positional encoding generalizes from 1D sequence structure to relative positions in the graph, dedicated to graph representation learning covering graph-specific properties.</p><p>We name our method for graph representation learning as Graph Relative Positional Encoding (GRPE). We extensively conducted experiments to validate the efficacy of our proposed method on various tasks, e.g., graph classification, graph regression and node classification. Models built with our relative positional encoding achieve state-of-the-art performance on various graph datasets, showing the efficacy of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Existing works leverage Transformer architecture to learn graph representation. We categorize those methods as follows.</p><p>Earlier models adopt Transformer without explicit encoding of positional information on a graph. Veli?kovi? et al. replace graph convolution operation with self-attention module where attention is only performed within neighboring nodes. Rong et al. stack self-attention module next to the graph convolutional networks iteratively to consider longrange interaction between nodes. In their method, affinity is considered only on the graph convolutional networks, and positional information is not given on self-attention.</p><p>Later works employ absolute positional encoding to explicitly encode positional information of graph on Transformer. Their main idea is to linearize a graph into a se-quence of nodes, and an absolute positional encoding is added to the input feature. Dwivedi and Bresson adopted graph Laplacian as a positional encoding, where each cell of encoding represents partitions after graph min-cut. Nodes sharing many partitions after graph min-cut would have similar graph Laplacian vectors. Kreuzer et al. employ a learnable positional encoding with a Transformer where its input is the Laplacian spectrum of a graph. Due to the linearization of a graph, those approaches lose the preciseness of position on the graph.</p><p>Meanwhile, encoding relative positional information has been studied to avoid losing the preciseness of position. Graphormer introduced by Ying et al. encodes relative position on scaled dot product attention map by adding bias terms. However, the bias terms are parameterized only relative position such as shortest path distance or edge type, and the interaction with node features is lost. On the other hand, Shaw, Uszkoreit, and Vaswani introduce relative positional encoding, for 1D sequence, on which we add relative position encoding, to capture the interaction between nodes and graph-specific properties such as edge and topology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background Notation</head><p>We denote a set of nodes on the graph {n i } i=1:N and a set of edges on the graph {e ij |j ? N i } i=1:N , where N is the number of nodes and N i is a set neighbors of a node n i . Both n i and e ij are positive integer numbers to index the type of nodes or edges, e.g., atom numbers or bond types of a molecule. ?(i, j) denotes a function encodes topological relationship between the node n i and n j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Self-attention</head><p>Transformer is built by stacking multiple self-attention layers. Self-attention maps a query and a set of key pairs to compute an attention map. Values are weighted summed with the weight on the attention map to output the hidden feature for the following layer.</p><p>Specifically, x i ? R dx denotes the input feature of the node n i , and z i ? R dz denotes the output feature of the self-attention module. The self-attention module computes query q, key k, and value v with independent linear transformations:</p><formula xml:id="formula_0">W query ? R dx?dz , W key ? R dx?dz and W value ? R dx?dz . q = W query x, k = W key x and v = W value x. (1)</formula><p>The attention map is computed by applying a scaled dot product between the queries and the keys.</p><formula xml:id="formula_1">a ij = q i ?k j ? d z and? ij = exp(a ij ) N k=1 exp(a ik )</formula><p>.</p><p>(2)</p><p>The self-attention module outputs the next hidden feature by applying weighted summation on the values.</p><formula xml:id="formula_2">z i = N j=1? ij v j .<label>(3)</label></formula><p>z is later fed into a feed forward neural network with a residual connection <ref type="bibr" target="#b9">(He et al. 2016</ref>). However, we defer detailed explanations since it is out of the scope of our paper. In practice, self-attention module with multi-head is adopted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph with Transformer</head><p>To encode graph topology in Transformer, previous methods focus on encoding graph information into either the attention map or input features fed to Transformer. Graphormer <ref type="bibr" target="#b20">(Ying et al. 2021</ref>) adopted two additional terms on the selfattention module to encode graph information on the attention map.</p><formula xml:id="formula_3">a Graphormer ij = q i ?k j ? d z + b ?(i,j) + E eij ? w.<label>(4)</label></formula><p>? represents the topological relation between n i and n j , which outputs the shortest path distance between the two nodes. Learnable scalar bias b ?(i,j) encodes topological relation between two nodes, e.g., b l is a bias representing two nodes that are l-hop apart. An embedding vector E eij is a feature representing edge between the node n i and the node n j , and w is a learnable vector. E eij ? w encodes edge between the two nodes. Moreover, Graphormer adds centrality encoding into the input x which represents the number of edges of a node. However, Graphormer encodes graphs on the attention map without considering node-topology and node-edge interaction, on the other hand GRPE considers the two. We will explain the details in later.</p><p>Dwivedi and Bresson and Kreuzer et al. utilize graph Laplacian <ref type="bibr" target="#b1">(Belkin and Niyogi 2003)</ref> ? ? R |N |?dx as positional encodings on the input feature x; ? are the top-d x smallest eigenvectors of I ?D ? 1 2 AD ? 1 2 where I is an identity matrix, A is an adjacency matrix and D is a degree matrix. Each cell of a graph Laplacian vector represents partitions after graph min-cut, and neighbouring nodes sharing the many partitions would have similar graph Laplacian. The graph Laplacian ? i represents the topology of a graph with respect to node n i .x  </p><formula xml:id="formula_4">i = x i + ? i .<label>(5</label></formula><formula xml:id="formula_5">x i = x i +? i wher? ? = f (?)</formula><p>. By adding the graph Laplacian into input x, graph information can be encoded in both the attention map and the hidden representations. Their methods lose relative positional information during the linearization of a graph to obtain absolute positional encoding. However, our method encodes a graph directly on the attention map without linearization, thus relative positional information is encoded without loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our Approach</head><p>Our distinction is twofold. First, we integrate interaction between node and graph structural information on the attention map. For that, we propose node-aware attention which considers the interactions existing in two pairs: node-topology relation and node-edge relation. Second, we also encode the topological information of a graph to the hidden representation of self-attention. For that, we propose graph-encoded values that directly encode relative positional information on the features of value by addition. Our node-aware attention applies the attention mechanism in a node-wise manner, while our graph-encoded value applies the attention mechanism in a channel-wise manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relative Positional Encoding for Graph</head><p>We define two encodings to represent relative positional relation between two nodes in a graph. The first is topology encoding P, and we define the encodings for query, key, and value respectively: P query , P key , P value ? R L?dz . Each vector of P represents the topological relation between two nodes, e.g., P l represents the topological relation of two nodes where their shortest path distance is l. L is the maximum shortest path distance that our method considers.</p><p>The second is edge encoding E, and we define the encodings for query, key, and value respectively: E query , E key , E value ? R E?dz . E eij is a vector representing edge between two nodes n i and n j . E is the number of types of edge. The topology encodings and the edge encodings are shared throughout all layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Node-Aware Attention</head><p>We propose two attention maps to encode a graph on selfattention. The first attention map is a topology . It encodes graph by considering interaction between node feature and topological relation of graph.</p><formula xml:id="formula_6">a topology ij = q i ?P query ?(i,j) + k j ?P key ?(i,j)<label>(6)</label></formula><p>The second attention map is a edge . It encodes graph by considering interaction between node feature and edge in graph.</p><formula xml:id="formula_7">a edge ij = q i ?E query eij + k j ?E key eij<label>(7)</label></formula><p>Finally, the two attention maps are added to scaled dot product attention map to encode graph information.</p><formula xml:id="formula_8">a ij = q i ?k j + a topology ij + a edge ij ? d z .<label>(8)</label></formula><p>Our two attention maps consider topology and edge type, as node-topology and node-edge relation. Meanwhile, Graphormer did not consider the interaction with node feature, such that two nodes with the same distance apart have the same bias b ?(i,j) on Eq 4. In contrast, our a topology enables to deploy different values according to the node features of query and key.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph-Encoded Value</head><p>Another distinction is that our method directly encodes graph information into the hidden features of value, as well. Specifically, we encode a graph to the hidden features of self-attention, where values are weighted summed with the attention map, for both topology and edge encoding via summation:</p><formula xml:id="formula_9">z i = N j=1? ij (v j + P value ?(i,j) + E value eij ).<label>(9)</label></formula><p>While the attention weight? is applied equally for all channels (node-wise attention), our graph-encoded value enriches the feature of each channel, and enables channel-wise attention as well. This relative positional encoding enables to encode relative position directly on hidden features, without previous approaches that encode position on input x with a linearized graph, as in <ref type="figure">Figure 1a</ref>, e.g., centrality encoding <ref type="bibr" target="#b20">(Ying et al. 2021)</ref> or graph Laplacian <ref type="bibr" target="#b13">(Kreuzer et al. 2021;</ref><ref type="bibr" target="#b7">Dwivedi and Bresson 2020)</ref>, where linearization sacrifices the preciseness of position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Complexity Analysis</head><p>A naive implementation of computing all pairs of a topology requires time complexity of O(N 2 d z ), since it requires performing the dot product between all node pairs. Instead, we pre-compute the dot product of all possible pairs of node features and topology encoding vectors P which requires time complexity of O(N Ld z ). Then we assign the pre-computed value according to the indices of node pairs. Likewise, for the a edge , we pre-compute the dot product of all possible pairs of node features and edge encoding vectors E query which requires time complexity of O(N Ed z ). The time complexity is reduced significantly with our implementation since L and E are much smaller than the number of nodes N .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Implementation Details</head><p>Virtual node Following Gilmer et al. and Ying et al., we adopt a special node called virtual node which is connected to all other nodes. The role of a virtual node is similar to special tokens such as a classification token <ref type="bibr" target="#b6">(Devlin et al. 2018)</ref>, where its output feature z is used as the input for the branch that predicts downstream tasks. We additionally define two encoding vectors to define both topology relation P VN and edge E VN for query, key and value respectively. Note that, the virtual node does not involve to find the shortest path between two nodes. Throughout all experiments, we add the virtual node to a graph to perform the downstream tasks. <ref type="figure" target="#fig_1">Figure 3</ref> illustrates how a virtual node is connected with other nodes.</p><p>Topological relation We utilize shortest path distance ?(i, j) to describe the topological relation between two nodes n i and n j . L is the maximum distance of the shortest path that we consider, and we utilize a special encoding vector P far for the node pairs with a distance more than L. For the nodes pairs that are unreachable, we utilize another special encoding vector P unreachable . Finally, for the pairs that are connected with the virtual node, we utilize another special encoding vector P VN . <ref type="figure" target="#fig_1">Figure 3</ref> illustrates how topological relation is processed.</p><p>Edge Some pair of nodes are not connected with edges. Therefore, we utilize a special encoding vector E no for the pairs of node that are not connected with any edges; {(n i , n j )|i = j and j / ? N i } i=1:|N | . For the pair of two identical nodes where i = j, we use a special embedding vector E self . Finally, for the pairs that are connected with the virtual node, we utilize another special encoding vector E VN . <ref type="figure" target="#fig_1">Figure 3</ref> illustrates how edges are processed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Classification and Regression</head><p>We summarize the model configurations of our experiments in <ref type="table" target="#tab_2">Table 1</ref>. For all results, ? indicates the models adopted Transformer for learning graph representation and text in bold indicates the best result.</p><p>We first validate our method on the tasks of the molecule property prediction such as OGBG-MolPCBA (MolPCBA) <ref type="bibr" target="#b10">(Hu et al. 2020)</ref>, OGBG-MolHIV (MolHIV) <ref type="bibr" target="#b10">(Hu et al. 2020)</ref>       <ref type="table">Table 6</ref>: Results on CLUSTER. The number of parameters is around 500K for all models. The higher the better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Weighted Accuracy GIN  64.716?1.553 GAT <ref type="bibr" target="#b18">(Veli?kovi? et al. 2017)</ref> 70.587?0.447 GCN <ref type="bibr" target="#b12">(Kipf and Welling 2016)</ref> 68.498?0.976 GatedGCN <ref type="bibr" target="#b2">(Bresson and Laurent 2017)</ref> 76.082?0.196 ?GT <ref type="bibr" target="#b7">(Dwivedi and Bresson 2020)</ref> 73.169?0.622 ?SAN <ref type="bibr" target="#b13">(Kreuzer et al. 2021)</ref> 76.691?0.650 ?Graphormer (slim) <ref type="bibr" target="#b20">(Ying et al. 2021)</ref> 74.660?0.236 <ref type="bibr">?EGT (Hussain et al. 2021)</ref> 79.232?0.348 ?GRPE-Small (Ours) 81. <ref type="bibr">586?0.190</ref> and ZINC <ref type="bibr" target="#b7">(Dwivedi et al. 2020)</ref>. MolPCBA consists of 437,929 graphs and the task is to predict multiple binary labels indicating various molecule properties. The evaluation metric is average precision (AP). MolHIV is a small dataset that consists of 41,127 graphs. The task is to predict a binary label indicating whether a molecule inhibits HIV virus replication or not. The evaluation metric is area under the curve (AUC). ZINC is also a small dataset that consists of 12,000 graphs, and the task is to regress a molecule property. The evaluation metric is mean absolute error (MAE). All experiments are conducted for 5 times, and we report the mean and the standard deviation of the experiments. We adopt the linear learning rate decay, and the learning rate starts from 2 * 10 ?4 and ends at 1 * 10 ?9 . We set L to 5. For ZINC dataset, we adopt GRPE-Small configuration with less than 500k parameters for a fair comparison. For MolHIV and MolPCBA datasets, we initialize the parameter of the models with the weight of a pretrained model trained on PCQM4M <ref type="bibr" target="#b10">(Hu et al. 2020</ref>) dataset. <ref type="table" target="#tab_3">Table 2</ref> shows the results on ZINC dataset, our model achieve state-of-the-art MAE score. <ref type="table" target="#tab_5">Table 4</ref> shows the results on MolPCBA dataset, our model achieves state-of-theart AP score. <ref type="table" target="#tab_4">Table 3</ref> shows the results on MolHIV dataset, our model achieves the state-of-the-art AUC with less parameters than Graphormer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Node Classification</head><p>We validate our method on the task of the node-wise classification such as PATTERN and CLUSTER <ref type="bibr" target="#b7">(Dwivedi et al. 2020)</ref>. PATTERN consists of 14,000 graphs and the task is to recognize graph pattern where each node belong, and the number of classes are two. CLUSTER consists of 12,000 graphs and the task is semi-supervised clustering where each node belong, and the number of classes are six. The evaluation metric is the average node-level accuracy weighted with respect to the class sizes, we follow the evaluation code pre-   3.8M 0.1203 0.1537 (0.1536 * ) 0.1678 * GCN-VN <ref type="bibr" target="#b12">(Kipf and Welling 2016)</ref> 4.9M 0.1225 0.1485 (0.1510 * ) 0.1579 * GIN-VN  6.7M 0.1150 0.1395 (0.1396 * ) 0.1487 * GINE-VN <ref type="bibr" target="#b3">(Brossard, Frigo, and Dehaene 2020)</ref> 13.2M 0.1248 0.1430 -DeeperGCN-VN <ref type="bibr" target="#b15">(Li et al. 2020)</ref> 25.5M 0.1059 0.1398 - ?GT <ref type="bibr" target="#b7">(Dwivedi and Bresson 2020)</ref> 0.6M 0.0944 0.1400 - ?GT-wide <ref type="bibr" target="#b7">(Dwivedi and Bresson 2020)</ref> 83.2M 0.0955 0.1408 - ?Graphormer (small) <ref type="bibr" target="#b20">(Ying et al. 2021)</ref> 12.5M 0.0778 0.1264 - ?Graphormer <ref type="bibr" target="#b20">(Ying et al. 2021)</ref> 47   <ref type="bibr" target="#b7">(Dwivedi et al. 2020)</ref>. We adopt the linear learning rate decay, and the learning rate starts from 2 * 10 ?4 and ends at 1 * 10 ?9 . We set L to 5. For both datasets, we adopt GRPE-Small with less than 500k parameters and adopt GRPE-Tiny with less than 100k parameters for a fair comparison. <ref type="table" target="#tab_6">Table 5</ref> shows the results on PATTERN, our models achieve state-of-the-art accuracy on 500k parameters. <ref type="table">Table 6</ref> shows the results on CLUS-TER, our models achieve state-of-the-art weighted accuracy with a significant improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OGB Large Scale Challenge</head><p>We validate our method on two datasets of OGB large scale challenge <ref type="bibr" target="#b10">(Hu et al. 2020</ref>). The two datasets aim to predict the DFT-calculated HOMO-LUMO energy gap of molecules given their molecular graphs. We conduct experiments on both the PCQM4M and PCQM4Mv2 datasets, which are currently the biggest molecule property prediction datasets containing about 4 million graphs in total. PCQM4Mv2 contains the DFT-calcuated 3D strcuture of molecules. For our experiments, we only utilize 2D molecular graphs not 3D structures. Throughout experiments, we set L to 5. We adopt a GRPE-Standard for fair comparisons with Graphormer. We linearly increase learning rate up to 2 * 10 ?4 for 3 epochs and linearly decay learning rate upto 1 * 10 ?9 for 400 epochs. We are unable to measure the test MAE of PCQM4M, because the test dataset is deprecated as PCQM4Mv2 is newly released. <ref type="table" target="#tab_7">Table 7</ref> shows the results on PCQM4M dataset. Our model achieves the second best validation MAE score, but with a very small gap with the best model of about 0.0001. <ref type="table">Table.</ref> 8 shows the results on PCQM4Mv2 dataset. Our large model achieves the best result on the validation dataset. We couldn't report the large model's test-dev MAE, since the evaluation server only allow one submission per week. We will make sure to report the result for the final draft. For the models with a similar number of parameters GRPE-Standard and EGT-Medium, we achieved competitive results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study on Components of GRPE</head><p>We validate the effect of components of GRPE on ZINC dataset. We adopt GRPE-Small. <ref type="table" target="#tab_11">Table 9</ref> shows the ablation study results. The first row is identical to the plain Transformer without any positional encodings, and it obviously shows the highest error. Adding either a topology or a edge lowers the error, and using them together further lowers the error. Finally, adding our Graph-Encoded Value does help to improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of Maximum Shortest Path Distance L</head><p>We validate the effects of the maximum shortest path distance L. We adopt GRPE-Standard, and the models are trained from scratch. <ref type="figure" target="#fig_2">Figure 5</ref> shows the ablation study result. Increasing L means that a model can identify the po- Figure 4: Visualization of adjacency matrix and average attention map (starting from third column) of each layer on molecule graph with various size. We added virtual node as the first node marked with zero index. For adjacency matrix, yellow and dark purple indicate the two nodes are connected and disconnected respectively. For attention map, brighter color (yellow) indicates higher attention and dark color indicates lower attention.  sition of nodes that are further away. The AUC consistently improves by increasing L from one to four, but L more than four does not further improve performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sharing Topology Encoding and Edge Encoding</head><p>We conduct ablation studies about the effects of sharing topology encoding P and edge encoding E for all layers. We adopt GRPE-Small. We conduct five independent runs. The results in <ref type="table" target="#tab_2">Table 10</ref> show that sharing two encodings does improve MAE but not significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Map of GRPE</head><p>We visualize attention map of each layer on molecules with various size. We take average over the attention map of 32 heads from GRPE-Standard trained on graph regression task on PCQM4Mv2 dataset. Note that, the first node is virtual node (with index zero), and its attention map and adjacency is represented at the first row and column. <ref type="figure">Figure 4</ref> shows that our method attend to neighboring nodes at lower layers. As layer goes deeper, attention map attends to virtual node with higher attention on the first column. This shows that each layer focuses on the entire graph rather than each node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We studied the problem of positional encoding for representing structural information of the given graph better, specifically, by adding node-topology and node-edge relations to the model. We validated the effectiveness of our approach, both quantitatively and qualitatively, in various tasks of diverse dataset sizes and characteristics, e.g., HIV replication prediction from molecule graphs (MolHIV) or semisupervised clustering on synthetic graphs (CLUSTER).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Illustration of how GRPE processes relative relation between nodes. We add virtual node n VN to represent entire graph. For topological relations, we adopt the shortest path distance between nodes. The virtual node is connected with all other nodes with a special edge VN and a special topological relation VN.Kreuzer et al. adopt an additional Transformer model f to produce learnable positional encoding:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Effects of the maximum shortest path distance L. The higher the better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>VN</cell><cell>1</cell><cell cols="2">2 3</cell><cell>4</cell></row><row><cell></cell><cell></cell><cell>VN</cell><cell>0</cell><cell>VN</cell><cell cols="3">VN VN VN</cell></row><row><cell>1</cell><cell></cell><cell>1 2</cell><cell>VN VN</cell><cell>0 1</cell><cell>0 1</cell><cell cols="2">1 1 2 2</cell></row><row><cell>1 Edge</cell><cell>VN</cell><cell>3 4</cell><cell>VN VN</cell><cell>2 2</cell><cell>1 1</cell><cell>0 2</cell><cell>0 2</cell></row><row><cell>2</cell><cell></cell><cell cols="6">Topological Relation ( , )</cell></row><row><cell>3</cell><cell></cell><cell></cell><cell>VN</cell><cell>1</cell><cell cols="2">2 3</cell><cell>4</cell></row><row><cell>4</cell><cell></cell><cell>VN 1</cell><cell>self VN</cell><cell cols="4">VN VN VN VN 1 self no no</cell></row><row><cell></cell><cell></cell><cell>2 3</cell><cell>VN VN</cell><cell>1 no</cell><cell>self 2</cell><cell cols="2">2 1 self no</cell></row><row><cell></cell><cell></cell><cell>4</cell><cell>VN</cell><cell>no</cell><cell>1</cell><cell>no</cell><cell>self</cell></row><row><cell>Graph</cell><cell></cell><cell></cell><cell cols="3">Edge</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Configurations of models that we utilize throughout our experiments.</figDesc><table><row><cell cols="6">Model Configurations # Params # Layers Hidden dim [d z ] FFN layer dim # Heads</cell></row><row><cell>GRPE-Tiny</cell><cell>106k</cell><cell>4</cell><cell>64</cell><cell>64</cell><cell>8</cell></row><row><cell>GRPE-Small</cell><cell>489k</cell><cell>12</cell><cell>80</cell><cell>80</cell><cell>8</cell></row><row><cell>GRPE-Standard</cell><cell>46.2M</cell><cell>12</cell><cell>768</cell><cell>768</cell><cell>32</cell></row><row><cell>GRPE-Large</cell><cell>118.3M</cell><cell>18</cell><cell>1024</cell><cell>1024</cell><cell>32</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Results on ZINC. * indicates a fine-tuned model. The lower the better.</figDesc><table><row><cell>Method</cell><cell>#Params</cell><cell>MAE</cell></row><row><cell>GIN (Xu et al. 2018)</cell><cell>510k</cell><cell>0.526?0.051</cell></row><row><cell>GAT (Veli?kovi? et al. 2017)</cell><cell>531k</cell><cell>0.384?0.007</cell></row><row><cell>GCN (Kipf and Welling 2016)</cell><cell>505k</cell><cell>0.367?0.011</cell></row><row><cell>GatedGCN (Bresson and Laurent 2017)</cell><cell>505k</cell><cell>0.214?0.006</cell></row><row><cell>MPNN  *  (sum) (Gilmer et al. 2017)</cell><cell>481k</cell><cell>0.145?0.007</cell></row><row><cell>PNA (Corso et al. 2020)</cell><cell>387k</cell><cell>0.142?0.010</cell></row><row><cell>?GT (Dwivedi and Bresson 2020)</cell><cell>589k</cell><cell>0.226?0.014</cell></row><row><cell>?SAN (Kreuzer et al. 2021)</cell><cell>509k</cell><cell>0.139?0.006</cell></row><row><cell>?Graphormer (slim) (Ying et al. 2021)</cell><cell>489k</cell><cell>0.122?0.006</cell></row><row><cell>?EGT (Hussain et al. 2021)</cell><cell>?500k</cell><cell>0.108?0.009</cell></row><row><cell>?GRPE-Small (Ours)</cell><cell>489k</cell><cell>0.094?0.002</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results on MolHIV.</figDesc><table><row><cell>Method</cell><cell>#Params</cell><cell>AUC (%)</cell></row><row><cell>GCN-GraphNorm (Cai et al. 2021)</cell><cell>526k</cell><cell>78.83?1.00</cell></row><row><cell>PNA (Corso et al. 2020)</cell><cell>326k</cell><cell>79.05? 1.32</cell></row><row><cell>PHC-GNN (Le et al. 2021)</cell><cell>111k</cell><cell>79.34? 1.16</cell></row><row><cell>DeeperGCN-FLAG (Li et al. 2020)</cell><cell>532k</cell><cell>79.42? 1.20</cell></row><row><cell>DGN (Beani et al. 2021)</cell><cell>114k</cell><cell>79.70? 0.97</cell></row><row><cell>GIN  *  (Xu et al. 2018)</cell><cell>3.3M</cell><cell>77.80? 1.82</cell></row><row><cell>?Graphormer-FLAG  *  (Ying et al. 2021)</cell><cell>47.0M</cell><cell>80.51?0.53</cell></row><row><cell>?EGT-Large  *  (Hussain et al. 2021)</cell><cell>110.8M</cell><cell>80.60?0.65</cell></row><row><cell>?GRPE-Standard  *  (Ours)</cell><cell>46.2M</cell><cell>81.39 ? 0.49</cell></row></table><note>* indicates a fine-tuned model. The higher the better.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Results on MolPCBA. * indicates a fine-tuned model. The higher the better.</figDesc><table><row><cell>Method</cell><cell>#Params</cell><cell>AP (%)</cell></row><row><cell>DeeperGCN+FLAG (Li et al. 2020)</cell><cell>5.6M</cell><cell>28.42? 0.43</cell></row><row><cell>DGN (Beani et al. 2021)</cell><cell>6.7M</cell><cell>28.85? 0.30</cell></row><row><cell>PHC-GNN (Le et al. 2021)</cell><cell>1.7M</cell><cell>29.47? 0.26</cell></row><row><cell>GINE (Brossard, Frigo, and Dehaene 2020)</cell><cell>6.1M</cell><cell>29.79? 0.30</cell></row><row><cell>GIN  *  (Xu et al. 2018)</cell><cell>3.4M</cell><cell>29.02? 0.17</cell></row><row><cell>?Graphormer-FLAG  *  (Ying et al. 2021)</cell><cell cols="2">119.5M 31.39? 0.32</cell></row><row><cell>?EGT-Large  *  (Hussain et al. 2021)</cell><cell cols="2">110.8M 29.61?0.24</cell></row><row><cell>?GRPE-Standard  *  (Ours)</cell><cell>46.2M</cell><cell>30.77? 0.07</cell></row><row><cell>?GRPE-Large  *  (Ours)</cell><cell cols="2">118.3M 31.50? 0.10</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Results on PATTERN. The higher the better.</figDesc><table><row><cell>Method</cell><cell cols="2">Weighted Accuracy</cell></row><row><cell></cell><cell>#Params</cell><cell>#Params</cell></row><row><cell></cell><cell>?100k</cell><cell>?500k</cell></row><row><cell>GIN (Xu et al. 2018)</cell><cell cols="2">85.590?0.011 85.387?0.136</cell></row><row><cell>GAT (Veli?kovi? et al. 2017)</cell><cell cols="2">75.824?1.823 78.271?0.186</cell></row><row><cell>GCN (Kipf and Welling 2016)</cell><cell cols="2">63.880?0.074 71.892?0.334</cell></row><row><cell cols="3">GatedGCN (Bresson and Laurent 2017) 84.480?0.122 86.508?0.085</cell></row><row><cell>PNA (Corso et al. 2020)</cell><cell>86.567?0.075</cell><cell>-</cell></row><row><cell>?GT (Dwivedi and Bresson 2020)</cell><cell>-</cell><cell>84.808?0.068</cell></row><row><cell>?SAN (Kreuzer et al. 2021)</cell><cell>-</cell><cell>86.581?0.037</cell></row><row><cell>?Graphormer (slim) (Ying et al. 2021)</cell><cell>-</cell><cell>86.650?0.033</cell></row><row><cell>?EGT (Hussain et al. 2021)</cell><cell cols="2">86.816?0.027 86.821?0.020</cell></row><row><cell>?GRPE (Ours)</cell><cell cols="2">83.105?0.045 87.020?0.042</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Results on PCQM4M. * indicates the results are from the official leaderboard. VN indicates that the model used virtual node. The lower the better.</figDesc><table><row><cell>Method</cell><cell cols="2">#Params Train MAE</cell><cell>Validate MAE</cell><cell>Test MAE</cell></row><row><cell>GCN (Kipf and Welling 2016)</cell><cell>2.0M</cell><cell>0.1318</cell><cell>0.1691 (0.1684  *  )</cell><cell>0.1838</cell></row></table><note>* GIN</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Results on PCQM4Mv2. VN indicates that the model used the virtual node. The lower the better.</figDesc><table><row><cell>Method</cell><cell cols="3">#Params Validate MAE Test-dev MAE</cell></row><row><cell>GCN (Kipf and Welling 2016)</cell><cell>2.0M</cell><cell>0.1379</cell><cell>0.1398</cell></row><row><cell>GIN (Xu et al. 2018)</cell><cell>3.8M</cell><cell>0.1195</cell><cell>0.1218</cell></row><row><cell>GCN-VN (Kipf and Welling 2016)</cell><cell>4.9M</cell><cell>0.1153</cell><cell>0.1152</cell></row><row><cell>GIN-VN (Xu et al. 2018)</cell><cell>6.7M</cell><cell>0.1083</cell><cell>0.1084</cell></row><row><cell>?EGT-Medium (Hussain et al. 2021)</cell><cell>47.4M</cell><cell>0.0881</cell><cell>-</cell></row><row><cell>?EGT-Large (Hussain et al. 2021)</cell><cell>89.3M</cell><cell>0.0869</cell><cell>0.0872</cell></row><row><cell>?GRPE-Standard (Ours)</cell><cell>46.2M</cell><cell>0.0890</cell><cell>0.0898</cell></row><row><cell>?GRPE-Large (Ours)</cell><cell>118.3M</cell><cell>0.0866</cell><cell>-</cell></row><row><cell>sented in the original work</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Effects of components of GRPE on ZINC dataset. The lower the better.</figDesc><table><row><cell cols="4">a topology a edge Graph-Encoded Value Test MAE</cell></row><row><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.668</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>0.267</cell></row><row><cell>-</cell><cell></cell><cell>-</cell><cell>0.218</cell></row><row><cell>-</cell><cell>-</cell><cell></cell><cell>0.116</cell></row><row><cell></cell><cell></cell><cell>-</cell><cell>0.147</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.093</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 :</head><label>10</label><figDesc>Effects of sharing topology encoding and edge encoding for all layers. We report MAE on ZINC dataset. The lower the better.</figDesc><table><row><cell cols="2">Is shared? #Params</cell><cell>MAE</cell></row><row><cell>yes</cell><cell>489k</cell><cell>0.094? 0.002</cell></row><row><cell>no</cell><cell>579k</cell><cell>0.101 ? 0.003</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Directional graph networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Beani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Passaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>L?tourneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="748" to="758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Laurent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.07553</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Residual gated graph convnets. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Frigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dehaene</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.15069</idno>
		<title level="m">Graph convolutions that can finally model local structure</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Graphnorm: A principled approach to accelerating graph neural network training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1204" to="1215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cavalleri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Beaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05718</idno>
		<title level="m">Principal neighbourhood aggregation for graph nets</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<idno>arXiv:2012.09699</idno>
	</analytic>
	<monogr>
		<title level="m">Dwivedi, V. P.; and Bresson, X. 2020. A generalization of transformer networks to graphs</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">P</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00982</idno>
		<title level="m">Benchmarking graph neural networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Open graph benchmark: Datasets for machine learning on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00687</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Zaki</publisher>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Edge-augmented graph transformers: Global self-attention is enough for graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2108.03348</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kreuzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Beaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>L?tourneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tossou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03893</idno>
		<title level="m">Rethinking Graph Transformers with Spectral Attention</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bertolini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>No?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-A</forename><surname>Clevert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.16584</idno>
		<title level="m">Parameterized hypercomplex graph neural networks for graph classification</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07739</idno>
		<title level="m">Deepergcn: All you need to train deeper gcns</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Self-supervised graph transformer on largescale molecular data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02835</idno>
		<idno>arXiv:1803.02155</idno>
	</analytic>
	<monogr>
		<title level="m">Selfattention with relative position representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Graph attention networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00826</idno>
		<title level="m">How powerful are graph neural networks? arXiv preprint</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.05234</idno>
		<title level="m">Do Transformers Really Perform Bad for Graph Representation? arXiv preprint</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
