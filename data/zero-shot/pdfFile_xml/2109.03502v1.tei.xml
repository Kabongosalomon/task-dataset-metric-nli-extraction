<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">R2-D2: A Modular Baseline for Open-Domain Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Fajcik</surname></persName>
							<email>ifajcik@fit.vutbr.cz</email>
							<affiliation key="aff0">
								<orgName type="institution">Brno University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Docekal</surname></persName>
							<email>idocekal@fit.vutbr.cz</email>
							<affiliation key="aff0">
								<orgName type="institution">Brno University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Ondrej</surname></persName>
							<email>ondrej@fit.vutbr.cz</email>
							<affiliation key="aff0">
								<orgName type="institution">Brno University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Smrz</surname></persName>
							<email>smrz@fit.vutbr.cz</email>
							<affiliation key="aff0">
								<orgName type="institution">Brno University of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">R2-D2: A Modular Baseline for Open-Domain Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work presents a novel four-stage opendomain QA pipeline R2-D2 (RANK TWICE, READ TWICE). The pipeline is composed of a retriever, passage reranker, extractive reader, generative reader and a mechanism that aggregates the final prediction from all system's components. We demonstrate its strength across three open-domain QA datasets: Natu-ralQuestions, TriviaQA and EfficientQA, surpassing state-of-the-art on the first two. Our analysis demonstrates that: (i) combining extractive and generative reader yields absolute improvements up to 5 exact match and it is at least twice as effective as the posterior averaging ensemble of the same models with different parameters, (ii) the extractive reader with fewer parameters can match the performance of the generative reader on extractive QA datasets 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Last year showed rapid progress in neural factoid open-domain question answering based on retriever-reader architecture (Open-QA). Such Open-QA systems <ref type="bibr" target="#b2">(Chen et al., 2017)</ref> seek evidence for answering the questions inside the knowledge source using the retriever and then extract the answer from the retrieved knowledge using the reader. The knowledge source is often a large corpus of short snippets of natural language, so-called passages (e.g., taken from an encyclopedia).</p><p>The progress can be attributed to advances in neural retrieval methods <ref type="bibr" target="#b10">(Karpukhin et al., 2020;</ref><ref type="bibr">Izacard and Grave, 2020;</ref><ref type="bibr">Khattab et al., 2020;</ref><ref type="bibr" target="#b14">Luan et al., 2021;</ref>, inter alia) that benefit from smarter negative sampling strategies or a better trade-off between complex question-passage interaction and its efficiency. It also can be attributed to reading methods that enable process-ing large quantities of retrieved passages <ref type="bibr">Izacard and Grave (2021)</ref>. They compensate for a certain amount of the retrieval error and enable early aggregation of answer's evidence between passages.</p><p>This work demonstrates the relative improvement of 23-32% compared to last year's state-ofthe-art DPR system <ref type="bibr" target="#b10">(Karpukhin et al., 2020)</ref>, while using the same knowledge source and the retriever. We propose a state-of-the-art Open-QA baseline composed of retriever, passage reranker, extractive reader, generative reader, and a novel component fusion approach. We follow the practice from information retrieval and show that our moderately sized reranker allows to reduce the passage count needed at the input of large reader models about four times. Our readers then take the best from both worlds. The extractive reader proposes a list of salient answer spans. The generative reader reranks these spans, seeing all the passages at once, or generates its own answer. The proposed pipeline is heterogeneous and modular, making it an ideal benchmark.</p><p>To sum up, our contributions are three-fold:</p><p>1. We present a simple novel approach to aggregate scores from all system components and show that combining extractive and generative approaches is superior to a posterior averaging ensemble of homogeneous models.</p><p>2. We show that the extractive reader can sometimes match the performance of the generative approaches without taking the advantage of the fusion between retrieved passages. This indicates that the evidence aggregation from multiple passages in the generative approaches is either not learned or not necessary to perform well on these datasets. triever as in the previous works <ref type="bibr" target="#b10">(Karpukhin et al., 2020;</ref><ref type="bibr">Izacard and Grave, 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Open-QA Pipeline</head><p>We propose the R2-D2 (RANK TWICE, READ TWICE), 4-stage pipelined system that can choose whether to generate or to extract an answer. The parameters of each component in pipeline are estimated separately. It is composed of DPR passage retriever <ref type="bibr" target="#b10">(Karpukhin et al., 2020)</ref>, passage reranker (see subsection 2.1), and two readers. <ref type="figure">Figure 1</ref> shows the diagram of our system. The first reader performs an extractive span-selection similar to <ref type="bibr">Fajcik et al. (2020)</ref>. The second reader is based on Fusion-In-Decoder (FiD) <ref type="bibr">(Izacard and Grave, 2021)</ref>. Formally, given a question q ? Q from the set of all possible questions Q and the corpus C = {p 1 , p 2 , ..., p n } composed of passages p i , the retriever learns a ranking function rank : Q?C ? R that assigns a score to each passage. We assume each passage contains its passage title (e.g., title from the Wikipedia article).</p><p>Taking a top-K scoring passages C r ? C, reranker again rescores C r scoring passages by learning a reranking function rerank : Q?C r ? R. Note that while rank and rerank have similar signatures, the computational cost of rerank over the same amount of passages is drastically higher, as it computes fine-grained interaction between tokens of question and passage.</p><p>Next, the rescored passages are passed to two readers: the extractive reader reads top-V passages C rr ? C r independently of each other and assigns the probability P e (a e |q, C rr ) to each span a e in the passages (see subsection 2.2). The FiD generative reader reads top-V 2 passages C rr ? C r jointly and generates an answer from probability space P g (a g |q, C rr ) via greedy search.</p><p>Finally, R2-D2 aggregates the outputs from all components using two fusions (described in subsection 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Passage Reranker</head><p>The proposed passage reranker is based on transformer cross-encoder similar to ; <ref type="bibr" target="#b14">Luan et al. (2021)</ref>. The input is the concatenation of question q ? Q and passage p ? C r with a special SEP token between them. The passage consists of a title and context that are prepended with special start tokens and concate-In which Czech city is the brewery of its largest beer exporter? where w ? R d is a trainable vector and CLS is the special token added at the start of an input sequence. Finally, we define the following formula 2 P rr (p|q, C r ) = softmax p?Cr (rerank (q, p)) p <ref type="formula">(2)</ref> to assign a probability to the case that passage p contains answer to the question q.</p><p>Training. The model input for each question is exactly one positive sample supplemented with hard negatives from the retriever. The ground truth passage, annotated the same way as in <ref type="bibr" target="#b10">Karpukhin et al. (2020)</ref>, is primarily used as a positive sample. If the ground truth is unknown, the positive sample is the best retriever passage containing the answer. The hard negatives are uniformly sampled from retriever's top-K results that do not contain the answer. The used loss function is the cross-entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Extractive Reader</head><p>Extractive reader estimates the probability P e (a e |q, C rr ). It is the probability of a span a e from top-V passage p ? C rr being an answer to a question q. We decompose the P e (a e |q, C rr ) into four probabilities of:</p><p>? token s being starting token of an answer span,</p><p>? token e being ending token of an answer span,</p><p>? tokens s and e being boundary tokens of an answer span (Fajcik et al., 2020),</p><p>? passage p containing an answer for the question q (inner reranker) as in <ref type="bibr" target="#b10">Karpukhin et al. (2020)</ref>.</p><p>To obtain the final probability used in test-time, we compute their product 3 . These probabilities are defined as:</p><formula xml:id="formula_0">P * ( * |q, C rr ) = softmax(s * ) i ,<label>(3)</label></formula><p>where * may stand for a start, end, joint, and a passage. The i is an index of a given element, and the s * is a vector of scores for each element among all passages in C rr . So the softmax normalization sum goes through all the passages. On the other hand, the s * scores are estimated by the model with just a single passage at its input <ref type="bibr">(Clark and Gardner, 2018)</ref>. The scores are as follows:</p><formula xml:id="formula_1">s i start = En(p, q)[s] w start (4) s i end = En(p, q)[e] w end<label>(5)</label></formula><formula xml:id="formula_2">s i joint = (W j En(p, q)[s] + b j ) En(p, q)[e] (6) s i passage = En(p, q)[CLS] w p .<label>(7)</label></formula><p>Where w * , b j ? R h , En(p, q)[?] ? R h , and W j ? R h?h are all trainable parameters. We omit the spans of a title and question for answer span selection. Therefore the final answer can be selected only from the context.</p><p>The following training objective with independently marginalized components is used:</p><formula xml:id="formula_3">? log s?starts(Crr) P start (s|q, C rr ) ? log e?ends(Crr) P end (e|q, C rr ) ? log j?boundaries(Crr) P joint (j|q, C rr ) ? log p?Crr P passage (p|q, C rr ) .<label>(8)</label></formula><p>The sums are going through target annotations (starts, ends, etc.) obtained by the distant supervision approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Component Fusion</head><p>To produce the final answer, R2-D2 aggregates the log-probabilities of all system components via linear combinations tuned on validation data.</p><p>Firstly, the log-probabilities of all system components for top-M answer spans proposed by the extractive reader are aggregated. Formally, assume the A q is the set of top-M answer spans from P e (a|q, C rr ) for question q. The generative model performs the answer reranking evaluating the logprobability of the answer spans</p><formula xml:id="formula_4">{log P g (a|q, C rr ) : a ? A q }.<label>(9)</label></formula><p>Next a logistic regression loss (11) is minimized to perform score aggregation. It combines the scores across the R2-D2 components to maximize the correct answer span probability over dataset D.</p><p>This dataset is composed of the top-M outputs of the extractive reader with the correct answer.</p><p>x(a) = [P e (a) P g (a) P r (p a ) P rr (p a )] (10)</p><formula xml:id="formula_5">? (Aq,gt)?D log softmax a?Aq w log x(a) + b gt (11)</formula><p>Here p a denotes the passage containing the answer span a, A q is a set of proposed answer spans, gt is the correct answer span, distribution dependencies are dropped for clarity and only the logistic regression parameters w, b are tuned in this step.</p><p>Finally, we theorized the correct answer span might not always be available in the passage set C rr , but the generative reader might be able to generate the answer from its parameters and the evidence given in passages. We introduce the binary classifier, which decides whether to select the best span answer from answer aggregation step or a free-form answer generated via FiD. Given that s agg (q) = max a?Aq w x(a) + b is the best span score and s * g (q) = log P g (a * q |q, C rr ) is the logprobability of the answer a * q obtained via greedy decoding for question q, a classifier is trained via binary cross-entropy BCE(l, t) with log-odds ratio l and target t to do the binary decision Here, the training dataset D contains only cases where either the extractive or the abstractive prediction is correct (but not both).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>Our models are implemented in PyTorch <ref type="bibr" target="#b24">(Paszke et al., 2019)</ref> using Transformers <ref type="bibr" target="#b31">(Wolf et al., 2020)</ref>. We use 12GB GPU to train the passage reranker, 48GB GPU for the generative reader, and 16x 32GB GPUs to train the extractive reader with V = 128 passages at its input. The inference runs on 12GB GPU. In all experiments, we used Adam optimizer with a decoupled weight decay <ref type="bibr" target="#b13">(Loshchilov and Hutter, 2019)</ref>. Our models are evaluated by two metrics:</p><p>Exact match (EM) measures the proportion of examples, for which the system prediction matched at least one annotated ground-truth answer. We use the script from <ref type="bibr">Lee et al. (2019) 4</ref> .</p><p>Accuracy@K measures the proportion of examples, for which the ground-truth answer string is present in top-K retrieved passages. We match the string exactly as Karpukhin et al. (2020) 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets and Data Pre-processing</head><p>We evaluate our models on three datasets. Their statistics are available in <ref type="table" target="#tab_3">Table 1</ref>. To train the reranker we filter out examples, which do not contain golden passage or exact match in top-K retrieved passages. To train the extractive reader, only examples with exact match in a golden passage or top-1 retrieved passage are kept. Both filtering strategies are closely described in Appendix C.</p><p>NQ-Open <ref type="bibr" target="#b6">(Kwiatkowski et al., 2019;</ref>  EfficientQA <ref type="bibr" target="#b17">(Min et al., 2021</ref>) is a dataset collected the same way as NQ-Open through 2019 and thus may contain more questions without evidence in our corpus than NQ-Open. We use the officially released dev set for testing 6 models trained on NQ-Open training data.</p><p>Additionally, we also report results according to train-test set overlaps discovered by <ref type="bibr" target="#b9">Lewis et al. (2021)</ref> in Appendix H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Models and Pipeline</head><p>Retriever. We use BERT-based DPR from the official checkpoint 7 . Each passage is represented via 768-dimensional embedding. We use a multiset checkpoint for TQ-Open, as the checkpoint for TQ directly isn't officially released. We use the same knowledge corpus containing 21,015,320 passages based on 12-20-2018 Wikipedia snapshot as <ref type="bibr" target="#b10">Karpukhin et al. (2020)</ref>. In inference time, the retriever passes K = 200 passages C r to reranker.  Passage reranker. We use the RoBERTa-base  and truncate the inputs to a maximum length of 256. The linear scheduler with 0.1 warmup proportion is used, the number of epochs is 5 and the model is validated every 40,000 optimization steps. We use learning rate 1.6 ? 10 ?4 and batch size 8. In training, the model reranks 24 passages per question with negatives uniformly sampled from top-400 passages retrieved by DPR. During the inference, top-K (K = 200) retriever passages are rescored and passed to readers.</p><p>Extractive reader. The extractive reader encoder is based on pre-trained ELECTRA-large. Its inputs are truncated if they are longer than the allowed maximum size (512 tokens). During the training phase, all spans from all p ? C r 8 that match 9 with at least one of the known answers are selected as target annotations. Therefore the annotations might appear in the wrong context. The extractive reader reads the top-V = 128 passages during the training phase and when it is used without the reranker. To demonstrate the effect of reranker, the reader reads only the top-V = 24 passages if the reranker is used. We use a linear scheduler with a warmup for the first 20,000 steps for all models. The maximum number of training steps is 200,000. The model is validated every 20,000 steps, and the best checkpoint among validations is selected. The learning rate is 2 ? 10 ?5 and the optimization step was done after each training example.</p><p>Generative reader. We utilize T5-large  and use a concatenation of question, passages and their respective titles at the Fusion-in-Decoder's input the same way as Izacard and Grave (2020). We truncate each passage to the length of 250 tokens for NQ. For TQ, as questions are significantly longer, we truncate whole inputs to the same size. Following FiD for TQ, we use only humangenerated answer. In training, the golden passage always comes first, if available, and we take the rest of passages as ranked by retriever up to V 2 passages. Izacard and Grave (2021) trained FiD with V 2 = 100 passages at its input. However, such approach requires tremendous amount of GPU memory, and thus requires employing speed-memory trade-offs such as gradient checkpointing <ref type="bibr" target="#b3">(Chen et al., 2016)</ref>. Unlike the original approach, we use only V 2 = 25 passages in our FiD. We note that in practice combining reranker with shorter-context FiD yields results similar to original implementation with much lower memory consumption and better throughput in the R2-D2 setting 10 . We analyze the speed of our implementation in Appendix I. Other hyperparameters are similar to the original work-batch size 64, learning rate 5 ? 10 ?5 but no learning rate schedule. In test time, we decode an answer via greedy decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Analysis</head><p>The effectiveness of our approach is compared with the state-of-the-art in <ref type="table" target="#tab_5">Table 2</ref>. Our system, composed of just the retriever and FiD reader R1-D1 (Generative), shows inferior performance compared to FiD-large. This is most likely caused by 4 times fewer passages at its input, as in <ref type="bibr">Izacard and Grave (2021)</ref>. In contrast, our ELECTRA based extractive reader R1-D1 (Extractive) shows large gains compared to extractive state-of-the-art, while having the same retriever as DPR. We hypothesize this may be caused by ELECTRA pre-training method, which shows strong performance through variety of tasks and we further show that it is also due to training and inference with large input size of 128 passages and better objective (discussed in Section 4.2 and Appendix G). Only system that matches the performance of our extractive reader is the concurrent work on UnitedQA-E <ref type="bibr">(Cheng et al., 2021)</ref>, which uses advanced regularization and Har-dEM techniques. We note that these are orthogonal to our approach and could potentially lead to further improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NQ TQ #?</head><p>Extractive BM25+BERT <ref type="bibr" target="#b15">(Mao et al., 2020)</ref> 37.7 60.1 110M Hard EM <ref type="bibr" target="#b18">(Min et al., 2019a)</ref> 28.1 50.9 110M Path Retriever <ref type="bibr" target="#b0">(Asai et al., 2020)</ref> 32.6 -447M Graph Retriever <ref type="bibr" target="#b19">(Min et al., 2019b)</ref> 34.5 56.0 110M ORQA  33.3 45.0 220M REALM <ref type="bibr">(Guu et al., 2020)</ref> 40.4 -660M ProQA <ref type="bibr" target="#b34">(Xiong et al., 2021)</ref> 34.3 -220M DPR <ref type="bibr" target="#b10">(Karpukhin et al., 2020)</ref> 41.5 56.8 220M RDR <ref type="bibr" target="#b35">(Yang and Seo, 2020)</ref> 42.1 57.0 110M GAR+DPR <ref type="bibr" target="#b15">(Mao et al., 2020)</ref> 43.8 -626M ColBERT <ref type="bibr">(Khattab et al., 2020)</ref> 48.2 63.2 ? 440M RIDER (GAR+DPR) <ref type="bibr" target="#b16">(Mao et al., 2021)</ref> 48.3 -626M UnitedQA-E <ref type="bibr">(Cheng et al., 2021)</ref> 51.8 68.9 440M Generative BM25+SSG <ref type="bibr" target="#b15">(Mao et al., 2020)</ref> 35.3 58.6 406M T51.1+SSM  35.2 61.6 11B RAG <ref type="bibr" target="#b10">(Lewis et al., 2020)</ref> 44.5 56.8 516M DPR+SSG <ref type="bibr" target="#b20">(Min et al., 2020)</ref> 42.  Finally, we find that our R2-D2 system with 21M passages corpus is competitive even with FiD++, which uses DPR retriever improved via knowledge distillation, and 26M passage corpus, which also includes lists. Additionally, we evaluate our model with a better retrieval model (HN-DPR) based on the DPR checkpoint where hard negatives are mined using the retrieval model itself 11 . Note that we do not compare EfficientQA with stateof-the-art, as the previous works didn't reported results on dev set we use for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reranker Performance</head><p>Next, we compare the performance of our retriever, reranker and reader with Accuracy@K in <ref type="figure" target="#fig_1">Figure 2</ref>. The passage reranker improves the accuracy consistently and we observe the same trend on other datasets (Appendix A). We also include analysis, where we rerank each passage p i according its s i passage score from extractive reader. We observe results similar or even better to reranker for K &lt; 10, indicating the extractive reader reranks well on its own. However, in subsequent experiments we do not replace the reranker with reader because: (i) passage reranker has fewer parameters, (ii) extractive reading can run in parallel  with reranking and generative reading as extractive reader is not benefiting from reranking, and (iii) passage reranking scores often improve results during score aggregation (see Section 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Extractive Reader Performance</head><p>In order to investigate the influence of the number of input passages on the extractive reader's performance, we trained multiple ELECTRA-base models, each with different input size. In test time, we evaluate each of them on various input sizes. <ref type="figure">Figure 3</ref> shows that increasing train/test input size has a positive influence on extractive reader's performance. However, input size 128 doesn't seem to increase the performance anymore.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablations</head><p>The ablations are listed in <ref type="table" target="#tab_8">Table 3</ref>. We ablate results without using passage reranker, with separate readers and their combination and with different   stages of component fusion. Namely, performing a naive answer re-ranking by generative reader means the system chooses the most probable answer span among the top-M spans provided by the extractive reader according to generative reader log-probabilities as shown in equation <ref type="formula" target="#formula_4">(9)</ref>. Analogously, the aggr fusion denotes that the system chooses the most probable answer span according to aggregated scores, as in equation <ref type="formula">(11)</ref>. Finally, the aggr+bd fusion denotes the binary decision, as shown in equation <ref type="formula">(12)</ref>.</p><p>As expected, we observe that reranker improves the results consistently for generative model in all cases. The gains are especially large for TQ-Open (over 3.7 EM, underscored in <ref type="table" target="#tab_8">Table 3</ref>). In fact, the results are comparable to Izacard and Grave (2021), suggesting that using the FiD reader with smaller context window and reranker is a reasonable alternative to memory inefficient FiD with large input size. Furthermore as expected, the extractive reader without reranker already has top-128 passages at the input, and improvements from the passage reranking are only negligible if any (less than 1 EM).</p><p>Finally, the results on NQ-Open and EfficientQA suggest applying the binary decision does not bring  large improvements over the score aggregation if any. However, notice that this is not the case for TQ-Open, where the generative reader performs significantly better compared to extractive reader, suggesting both component fusions play important role in the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Component Fusion</head><p>Furthermore, we analyze the performance of each component combination in the score aggregation and its impact on the component fusion via binary decision. Both fusions are tuned on validation data and reported on test data of the NQ-Open and TQ-Open datasets. See Appendix B for analysis on additional datasets. <ref type="table" target="#tab_9">Table 4</ref> shows all relevant combinations of ranker r, reranker rr, extractive reader e and generative reader g probabilities used in score aggregation. In overall, we observe that combining retriever and reranker scores with the reader leads to better or equal performance. On NQ-Open, we observe minor improvements up to~1 EM. However, there is no difference on TQ-Open.</p><p>The impact of adding a binary decision after the score aggregation is shown in  answer scores ({e} rows in both tables). However, fusing the generative and extractive reader via binary decision performs significantly worse on NQ-Open than fusing both readers together with score aggregation ({e} row in <ref type="table" target="#tab_11">Table 5</ref> vs. {e, g} row in <ref type="table" target="#tab_9">Table 4</ref>). As already noted in ablations, we find this to be quite the opposite for TQ-Open. We hypothesize that the binary decision is strong in cases, where generative reader performs better to extractive reader (the case of TQ-Open). We argue that if the generative reader is better, the abstractive answer should be used far more often, than when it's not. We support the hypothesis by analyzing the proportion of test samples, on which the binary decision component activated (i.e. an abstractive prediction was selected). On NQ-Open, the component almost never activated (only on 3.5% samples), but this proportion is much higher (26.6%) on TQ-Open.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Comparison with Posterior Averaging</head><p>Finally, we compare our score aggregation with the ensemble computed via posterior probability averaging. In particular, we train three extractive and generative base-sized models initialized with different random seed. We do not use reranker in this experiment, and set train/test input size of extractive reader to 32. We assess the predictions using the averaged posterior probabilities and compare their average performance with score aggregation in <ref type="table" target="#tab_13">Table 6</ref>. Concretely, we compare with average of all 2 model ensembles (2 models) and with an ensemble of all 3 checkpoints (3 models). We observe two to three times improvement of score aggregation over the posterior probability averaging on NQ-Open test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Passage reranking. Previous work in QA based on neural nets used Bi-LSTM encoders <ref type="bibr" target="#b28">(Wang et al., 2018;</ref><ref type="bibr" target="#b7">Lee et al., 2018</ref>) that score each document independently. Over time, Bi-LSTM were replaced by BERT-like transformer encoders <ref type="bibr" target="#b25">(Qiao et al., 2019;</ref><ref type="bibr" target="#b29">Wang et al., 2019a)</ref>. For document ranking,  proposed a multistage architecture. The first stage scores each document independently, and the second estimates the more relevant document from all document pairs. Another document ranking approach uses the seq2seq model to generate a true or false answer to the document's relevance to the query . Recent works have often focused on effective reranking. <ref type="bibr" target="#b32">Xin et al. (2020)</ref> achieved inference speedup using early exiting, Jang and Kim (2020) proposed a smaller and faster model, and <ref type="bibr" target="#b16">Mao et al. (2021)</ref> came up with a method which uses reader's predictions to rerank the passages. Our reranker is most similar to Nogueira and Cho (2019); <ref type="bibr" target="#b14">Luan et al. (2021)</ref>, except that unlike in IR, we assume there is just one correct passage and thus train our model via categorical cross-entropy.</p><p>Multipassage Reading Comprehension Related work considers generative and extractive approaches towards modeling the reader. The generative reader generates an answer while conditioned on question alone , or question with relevant passages <ref type="bibr" target="#b10">(Lewis et al., 2020;</ref><ref type="bibr" target="#b20">Min et al., 2020)</ref>. Izacard and Grave (2021) showed it suffices to concatenate the passages in the decoder of seq2seq model, increasing the amount of top-passages the model can depend on dramatically. The extractive reader used in Open-QA assumes that the answer is a continuous span string in located in retrieved paragraphs <ref type="bibr" target="#b2">(Chen et al., 2017)</ref>. Clark and Gardner <ref type="formula" target="#formula_3">(2018)</ref>   <ref type="bibr">Cheng et al. (2021)</ref> proposed hard voting ensembling scheme to combine the reader predictions. Firstly, each model from an ensemble produces its best prediction, then the votes for identical predictions are combined, omitting the scores produced by the individual models. The authors obtained best results using two FiD readers and single extractive reader, leading to 1.6 and 2.4 EM improvement on TQ-Open and NQ-Open, compared to their best single extractive or generative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This work proposed R2-D2, a novel state-of-the-art pipeline for open-domain QA based on 4 components: retriever, reranker, generative reader and extractive reader. We showed that employing a reranker is a reasonable alternative to using large passage counts at the input of both the extractive and the generative reader. Our results on NQ-Open and EfficientQA showed that the extractive and the generative reader could perform equally in Open-QA, although the generative reader is twice the size of the extractive reader. On the other hand, we observe the extractive reader underperforms on TQ-Open. We hypothesize, that the cause is (1) the complexity of trivia questions with many entities, which often require combining evidence from multiple passages -these are impossible to answer for the extractive reader by design -and (2) the expensive hyperparameter search, as we used NQ-Open hyperparameters also for TQ-Open. Contrary to belief based on the results on different datasets <ref type="bibr" target="#b30">Wang et al., 2019b;</ref><ref type="bibr">Izacard and Grave, 2021)</ref>, we found the extractive reader can also benefit from larger input sizes, both in training and test time. Finally, we proposed a component fusion, which allows merging the complementary behavior of generative and extractive approaches along with the ranking components and found it improves the results significantly. Due to its heterogenous and modular nature, our pipeline forms an ideal base for future research of component integration in modern Open-QA. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Accuracy@K Analysis</head><p>Analysis of Accuracy@K on NQ-Open development data in <ref type="figure" target="#fig_6">Figure 4a</ref>, on EfficientQA data is shown in <ref type="figure" target="#fig_6">Figure 4b</ref>, and on TQ-Open development data in <ref type="figure" target="#fig_6">Figure 4c</ref> and test data in <ref type="figure" target="#fig_6">Figure 4d</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Component Fusion Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Data Pre-processing</head><p>This section describes how the training datasets for reranker and extractive reader are filtered, and how the distant supervision labeling is generated. Note not each example contains golden passage, as not each example can be mapped to the used dump of Wikipedia. We use the same golden passage mapping as <ref type="bibr" target="#b10">Karpukhin et al. (2020)</ref>.</p><p>For passage reranking, the input must contain at least one positive example. We meet this condition either by adding a golden passage or searching for the passage with an answer in the top-400 results retrieved by DPR. In detail about the search, first the Simple tokenizer proposed in DrQA 12 tokenizes each passage and golden answer. The positive example is the best-scored tokenized passage that contains an exact match with one of the tokenized answers. Note the search proceeds in the same way as in DPR's Accuracy@K implementation 13 .</p><p>The extractive reader is trained only on samples which contain exact match to at least one of the annotated answers in the top-1 passage, or golden passage if it is available. The exact match is performed on the subword token level (i.e. in ELEC-TRA's tokenization).</p><p>Next, the span annotations are extracted from the passages at the reader's input. Note each sample may contain multiple answers. The annotations for each answer in each sample are obtained differently in retrieved passages and in the golden passage. For retrieved passages, we search for the answer's exact matches in passages, and use each match as target annotation. For golden passage, we also search for the answer's exact matches in it. If there is none, the answer is soft matched with single sub-sequence of golden passage, which yields highest non-zero F1 score. The F1 soft match is also performed on the subword token level. Therefore answers with zero highest F1 soft match with golden passage and no exact match in any of the reader's input passages are discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Upper Bound on F1 Matching</head><p>Because the brute-force computation of a span with the greatest nonzero F1 score is potentially very demanding, we found the length limit for spans that are worth searching (see Theorem C.2).</p><p>To compare brute-force with upper bound implementation, we run an experiment on 16,741 passages (retrieved for NQ-Open dev). The average time per passage for brute-force approach was 121 ms while it was only 9 ms for implementation that uses the upper bound optimization.</p><p>The soft match is described in Algorithm 1. It assumes that there is no exact match.      </p><p>Proof. To prove it by contradiction assume that</p><formula xml:id="formula_7">|t| &gt; |a| |t| + |a| ? s ta s ta ,<label>(14)</label></formula><p>then</p><formula xml:id="formula_8">s ta |t| &gt; |a||t| + |a||a| ? |a|s ta ,<label>(15)</label></formula><p>and also 0 &lt; s ta ? |a|, thus |a||a| ? |a|s ta ? 0. Therefore even if we assume that |a||a| ? |a|s ta = 0. We get</p><formula xml:id="formula_9">s ta |t| &gt; |a||t| s ta &gt; |a| ,<label>(16)</label></formula><p>which is in contradiction with 0 &lt; s ta ? |a|.</p><p>Theorem C.2. Let S be a set of non-empty spans, a an non-empty answer span, t non-empty trial span, 0 &lt; s ta ? |a| is number of shared tokens for t and a, and S b = {z|z ? S ? |z| ? |a| |t|+|a|?sta sta }. Then the theorem states that ?x ? S b <ref type="figure">(F1(x, a) ? F1(t, a)</ref>) .</p><p>(17)</p><p>Proof. To prove it by contradiction assume that <ref type="figure">F1(t, a)</ref>) .</p><formula xml:id="formula_10">?x ? S b (F1(x, a) &gt;</formula><p>F1 score can be expressed as: </p><formula xml:id="formula_12">F1(b, c) = 2s bc |b| + |c| ,<label>(19)</label></formula><p>which is in contradiction with x ? S b .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Softmax Notation</head><p>Usually, softmax function ? : R K ? R K is defined as:</p><formula xml:id="formula_14">?(v) i = e v i K j=1 e v j .<label>(22)</label></formula><p>However, some parts of this work used variant of softmax that is defined as follows:</p><formula xml:id="formula_15">softmax x?D f (x) y = e f (y) x?D e f (x) ,<label>(23)</label></formula><p>where D is the input set, f : D ? R, y ? D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Decoding the Distributions from the Extractive Reader</head><p>We analyzed the subsets of joint probability space over spans obtained via multiplication of distributions as explained in section 2.2 in <ref type="table" target="#tab_22">Table 9</ref>. The factors of this space are the distribution given by the outer product of independent probability distributions P start (.)P end (.) denoted as I, joint probability distribution P joint (.) denoted as J, and passage distribution P passage (.) denoted as C.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Passage Reranker Revision</head><p>In preliminary experiments of this work we used a Longformer encoder <ref type="bibr" target="#b1">(Beltagy et al., 2020)</ref> with concatenated passages at it's input to benefit from the early fusion between passages. In particular, the passages at the Longformer's input were shuffled and concatenated, and we used presoftmax score computed from the first Longformer's output representation of each passage as the rerank function. The passages were shuffled with a fixed seed in both, training and test time. Therefore each passage was scored not only according to the question but also according to other passages. However, we did not observe any significant benefits when we used the Longformer setup over a RoBERTa which scores each passage independently (see <ref type="table" target="#tab_3">Table 11</ref>).   </p><p>Where S = starts(C rr ), E = ends(C rr ) and distribution dependencies are dropped for clarity. Inter-passage combinations obviously do not correspond to a real answer. Even though that this loss does not reflect the task correctly, it achieves better results (see <ref type="table" target="#tab_3">Table 10</ref>) than the following loss ? log c?Crr ae?answers(c) P e (a e |q, C rr )</p><p>that marginalizes components jointly, and thus the summation is done only through intra-passage start-end combinations. Such results agree with previous work <ref type="bibr" target="#b5">(Cheng et al., 2020b)</ref>. <ref type="table" target="#tab_3">Table 10</ref> also shows that the joint component improves the independent loss variant, but not the other one that marginalizes jointly. We hypothesize that this is because the loss in equation 25 already considers only the intra-passage start-end pairs. Lastly, <ref type="table" target="#tab_3">Table 10</ref> shows that using just the joint and passage component is sufficient for NQ-Open, which agrees with Fajcik et al. <ref type="bibr">(2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Results According to Question and Answer Test-Train Overlap</head><p>In addition to evaluation on the TQ-Open and NQ-Open shown in <ref type="table" target="#tab_5">Table 2</ref>, we also report results on subsets of these datasets in <ref type="table" target="#tab_3">Table 12</ref>, as split by <ref type="bibr" target="#b9">Lewis et al. (2021)</ref>. We compare R2-D1 (retriever, reranker and extractive or generative reader, marked as gen and ext respectively) and R2-D2 (ext+gen) to official results on FiD (Izacard and Grave, 2021).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I Inference Speed of Our Implementation</head><p>While optimizing the R2-D2's inference speed was not the main focus of this paper, we show that even our unoptimized implementation can be used in practice in small scale. We analyze the speed of our implementation on NQ-Open test data in <ref type="table" target="#tab_3">Table 13</ref>. The times were measured on a workstation with Intel Xeon Silver 4214 48-core CPU, 188GB RAM and Nvidia 2080Ti 12GB GPU. <ref type="table">Table  columns</ref> show settings with and without passage reranker. <ref type="table">Table rows</ref> are split into two parts; intermediate rows show time spent by the pipeline's single component (e.g., row ext. reader shows what time the pipeline spent by running just the ext. reader), and total rows show the total time taken by the whole pipeline. The retriever and reranker infer with batch sizes 32 and 100 respectively, the readers run with batch size 1. We note that in retrieval, we do not use any approximate K-NN algorithm to facilitate retrieval of top-K nearest passages and instead do the dot product with the matrix of passages directly on the CPU. Secondly, we note that we do not parallelize the inference of generative reader and extractive reader. Thirdly, notice the difference in extractive reader's speed with and without passage reranker is caused by its different input size (see details of extractive reader's experiments setup in subsection 3.2). Finally, we compare the speed of our approach using FiD with 25 and 100 input passages, like in the original FiD implementation 15 . The ratios of our measurements are compared explicitly in <ref type="table" target="#tab_3">Table 14</ref>.   Setup ratios Modules only gen. ans. reranker gen pipe. ext+gen pipe. gen(100) / gen <ref type="formula" target="#formula_1">(25)</ref> 3.36x 3.75x 2.71x 2.62x rr+gen(25) / gen(25) * 1.00x * 1.00x 3.55x 1.01x gen(100) / rr+gen(25) * 3.36x * 3.75x 0.76x 2.58x <ref type="table" target="#tab_3">Table 14</ref>: Ratios of inference times on NQ-Open. First two columns compare the speed in stage of generating abstractive answer (only gen.) and answer reranking (ans. reranker). The subsequent columns compare speed of whole pipeline just with generative reader and no component fusion (gen pipe.) and full R2-D2 pipeline (ext+gen pipe.). Row gen(100)/gen(25) compares the speedup of pipeline when using just 25 passages in FiD's input (denoted as gen(25)) instead of 100 (denoted as gen <ref type="formula">(100)</ref>). Row rr+gen(25)/gen(25) shows speedup gained from not using passage reranker (denoted as rr). Row gen(100)/rr+gen(25) compares the speed of using rr and gen(25) instead of gen(100) (with no passage reranking). Results marked with * are not affected by passage reranking component, as they only measure speed of pipeline's individual component. For instance, table shows that doing answer reranking with generative reader with just 25 passages at its input runs 3.75x faster than doing answer reranking with generative reader that uses 100 passages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>[s agg (e); s * g (e)] + b, t). (12)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>11 https://cutt.ly/Ux5Yt4h Accuracy@K on test-data of NQ-Open.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Analysis of Accuracy@K on different datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>G</head><label></label><figDesc>Ablating the Extractive Reader's Objective Firstly let us demonstrate that start and end components in the used loss (see equation 8) perform summation over both inter-passage and intra-passage combinations of starts and ends: ? log s?S P start (s) ? log e?E P end (e) = = ? log s?S P start (s) e?E P end (e) = = ? log s?S,e?E P start (s)P end (e) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Retriever top-K passages 1. ... town of?esk? Bud?jovice, known as Budweis... 2. Czech Beer Festival is the biggest ... 3. Plze?, also called Pilsen is a city... Plze?, also called Pilsen is a city... 2. ... town of?esk? Bud?jovice, known as Budweis... 3. Czech Beer Festival is the biggest ...</figDesc><table><row><cell>passage rescoring as</cell><cell></cell></row><row><cell>rerank(q, p) = En(p, q)[CLS] w</cell><cell>(1)</cell></row><row><cell></cell><cell>index</cell></row><row><cell></cell><cell cols="2">Passage</cell></row><row><cell></cell><cell cols="2">reranker</cell></row><row><cell></cell><cell cols="2">top-K reranked passages</cell></row><row><cell></cell><cell>1. Extractive</cell><cell>Abstractive</cell></row><row><cell></cell><cell>reader</cell><cell>reader</cell></row><row><cell></cell><cell>top-M answer spans</cell><cell>top generated answer</cell></row><row><cell></cell><cell>1.?esk? Bud?jovice</cell><cell>1. Brno</cell></row><row><cell></cell><cell>2. Festival</cell></row><row><cell></cell><cell>3. Plze?</cell></row><row><cell></cell><cell>Abstractive</cell></row><row><cell></cell><cell>reader</cell></row><row><cell></cell><cell>top-M reranked spans</cell></row><row><cell></cell><cell>1. Plze?</cell></row><row><cell></cell><cell>2. Festival</cell></row><row><cell></cell><cell>3.?esk? Bud?jovice</cell></row><row><cell></cell><cell>Score</cell></row><row><cell></cell><cell>aggregation</cell></row><row><cell></cell><cell>top-M aggr. spans</cell></row><row><cell></cell><cell>1. Plze?</cell></row><row><cell></cell><cell>2.?esk? Bud?jovice</cell></row><row><cell></cell><cell>3. Festival</cell></row><row><cell></cell><cell cols="2">Binary decision</cell></row><row><cell></cell><cell cols="2">top answer</cell></row><row><cell></cell><cell>1. Plze?</cell></row><row><cell></cell><cell cols="2">Figure 1: R2-D2 pipeline.</cell></row><row><cell></cell><cell cols="2">Now we can define the reranking function for</cell></row></table><note>nated together. We denote the contextual repre- sentation of input token w obtained by the cross- encoder as En(p, q)[w] ? R d .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Dataset statistics. The filt. lines report how many examples are kept for training the reranker (filt. reranker) and extractive reader (filt. ext. reader). The lines w/ golden passage denote how many examples from the set contain golden passage annotation.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Comparison with the state-of-the-art in EM. #? denotes the estimated amount of model parameters. Symbol ? reports the result only for smaller system with 220M parameters.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>50.72 -0.06 65.01 65.46 0.45 47.00 47.56 0.56 gen -49.92 50.69 0.77 65.38 69.14 3.76 44.83 47.33 2.50 ext+gen naive 51.88 52.44 0.56 66.17 68.01 1.84 47.06 49.11 2.05 ext+gen aggr 54.13 54.90 0.77 67.42 68.66 1.24 50.44 52.00 1.56 ext+gen aggr+bd 54.07 54.99 0.92 67.37 69.94 2.57 49.72 52.22 2.50</figDesc><table><row><cell cols="2">Readers Fusion</cell><cell>ret.</cell><cell>NQ-Open +rr</cell><cell>?</cell><cell>ret.</cell><cell>TQ-Open +rr</cell><cell>?</cell><cell>EfficientQA ret. +rr</cell><cell>?</cell></row><row><cell>ext</cell><cell>-</cell><cell>50.78</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 :</head><label>3</label><figDesc>Ablation study. We report results for extractive (ext), generative (gen) and both readers (ext+gen) without (ret.) and with reranking (+rr). The ? column shows the exact match difference caused by passage reranking.</figDesc><table><row><cell></cell><cell>P  *</cell><cell>?</cell><cell>{r}</cell><cell>{rr} {r, rr}</cell></row><row><cell>NQ-Open</cell><cell cols="4">{e} {g} {e, g} 54.63 55.10 54.82 54.90 50.72 51.41 51.55 51.69 52.44 52.88 53.35 53.19</cell></row><row><cell>TQ-Open</cell><cell cols="4">{e} {g} {e, g} 68.45 68.57 68.66 68.66 65.54 65.64 65.60 65.61 68.25 68.17 68.21 68.26</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Results for different pipeline components used for score aggregation on NQ-Open a TQ-Open. See text for details.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 :</head><label>5</label><figDesc>Results for binary decision on NQ-Open and TQ-Open for different aggregated pipeline components fromTable 4.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 5 .</head><label>5</label><figDesc>Interestingly, the binary decision component significantly improves the performance only without rerankedReaders Ensemble EM ? ext ? gen</figDesc><table><row><cell></cell><cell>-</cell><cell>46.79</cell><cell>-</cell><cell>-</cell></row><row><cell>ext</cell><cell cols="3">2 models 48.30 1.51</cell><cell>-</cell></row><row><cell></cell><cell cols="3">3 models 48.59 1.80</cell><cell>-</cell></row><row><cell></cell><cell>-</cell><cell>45.00</cell><cell>-</cell><cell>-</cell></row><row><cell>gen</cell><cell cols="2">2 models 46.30</cell><cell>-</cell><cell>1.30</cell></row><row><cell></cell><cell cols="2">3 models 46.59</cell><cell>-</cell><cell>1.59</cell></row><row><cell>ext+gen</cell><cell>aggr</cell><cell cols="3">49.92 3.13 4.92</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>: Comparison between ensembling via posterior</cell></row><row><cell>averaging and score aggregation on NQ-Open.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>Our objective is similar to the last work, except that it uses joint component and also optimizes MML over relevant passages' probabilities.</figDesc><table><row><cell>objective. Component Fusion. Yang et al. (2019) also com-</cell></row><row><cell>bined BM25 ranker and reader scores via linear</cell></row><row><cell>combination. Our work can be seen as an exten-</cell></row><row><cell>sion of this idea to combining the scores of all</cell></row><row><cell>pipeline's components. Iyer et al. (2020) proposed</cell></row><row><cell>a system which directly learns to rerank question-</cell></row><row><cell>passage-answer triplets proposed via extractive</cell></row><row><cell>model. However, reranking answers from their</cell></row><row><cell>large extractive model via large reranker leads to~1</cell></row><row><cell>EM improvement absolute, whereas R2-D2s score</cell></row><row><cell>aggregation improves 4 to 5 EM w.r.t. the extractive</cell></row><row><cell>reader. Concurrently with our work,</cell></row><row><cell>proposed to ag-</cell></row><row><cell>gregate the probabilities of distantly supervised</cell></row><row><cell>answer matches via maximum marginal likelihood</cell></row><row><cell>(MML). Lin et al. (2018) proposed to denoise dis-</cell></row><row><cell>tantly supervised answer string matches in MML</cell></row><row><cell>via paragraph-ranker. Cheng et al. (2020a) experi-</cell></row><row><cell>mented with different assumptions for MML, show-</cell></row><row><cell>ing improvement when marginalizing over compo-</cell></row><row><cell>nents of span probability independently. Fajcik</cell></row><row><cell>et al. (2020) proposed to model joint span proba-</cell></row><row><cell>bility directly via compound objective, instead of</cell></row><row><cell>modeling the probability of span's start and end in-</cell></row><row><cell>dependently. Karpukhin et al. (2020) incorporated</cell></row><row><cell>an independent passage classifier loss to his MML</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5657-5667, Online. Association for Computational Linguistics. Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6769-6781, Online. Association for Computational Linguistics.</figDesc><table><row><cell></cell><cell>Vladimir Karpukhin,</cell></row><row><cell cols="2">Hao Cheng, Yelong Shen, Xiaodong Liu, Pengcheng</cell></row><row><cell cols="2">He, Weizhu Chen, and Jianfeng Gao. 2021. Unit-</cell></row><row><cell cols="2">edQA: A hybrid approach for open domain question</cell></row><row><cell cols="2">answering. In Proceedings of the 59th Annual Meet-</cell></row><row><cell cols="2">ing of the Association for Computational Linguistics</cell></row><row><cell cols="2">and the 11th International Joint Conference on Nat-</cell></row><row><cell cols="2">ural Language Processing (Volume 1: Long Papers),</cell></row><row><cell cols="2">pages 3080-3090, Online. Association for Computa-</cell></row><row><cell>tional Linguistics.</cell><cell></cell></row><row><cell cols="2">Christopher Clark and Matt Gardner. 2018. Simple</cell></row><row><cell cols="2">and effective multi-paragraph reading comprehen-</cell></row><row><cell cols="2">sion. In Proceedings of the 56th Annual Meeting of</cell></row><row><cell cols="2">the Association for Computational Linguistics (Vol-</cell></row><row><cell cols="2">ume 1: Long Papers), pages 845-855, Melbourne,</cell></row><row><cell cols="2">Australia. Association for Computational Linguis-</cell></row><row><cell>tics.</cell><cell></cell></row><row><cell cols="2">Martin Fajcik, Josef Jon, Santosh Kesiraju, and</cell></row><row><cell>Pavel Smrz. 2020.</cell><cell>Rethinking the objectives</cell></row><row><cell cols="2">of extractive question answering. arXiv preprint</cell></row><row><cell>arXiv:2008.12804.</cell><cell></cell></row><row><cell cols="2">Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-</cell></row><row><cell cols="2">pat, and Ming-Wei Chang. 2020. Realm: Retrieval-</cell></row><row><cell cols="2">augmented language model pre-training. arXiv</cell></row><row><cell cols="2">preprint arXiv:2002.08909.</cell></row><row><cell cols="2">Srinivasan Iyer, Sewon Min, Yashar Mehdad, and Wen-</cell></row><row><cell cols="2">tau Yih. 2020. RECONSIDER: re-ranking using</cell></row><row><cell cols="2">span-focused cross-attention for open domain ques-</cell></row><row><cell cols="2">tion answering. CoRR, abs/2010.10757.</cell></row><row><cell cols="2">Gautier Izacard and Edouard Grave. 2020. Distilling</cell></row><row><cell cols="2">knowledge from reader to retriever for question an-</cell></row><row><cell cols="2">swering. arXiv preprint arXiv:2012.04584.</cell></row><row><cell cols="2">Gautier Izacard and Edouard Grave. 2021. Leveraging</cell></row><row><cell cols="2">passage retrieval with generative models for open</cell></row><row><cell cols="2">domain question answering. In Proceedings of the</cell></row><row><cell cols="2">16th Conference of the European Chapter of the As-</cell></row><row><cell cols="2">sociation for Computational Linguistics: Main Vol-</cell></row><row><cell cols="2">ume, pages 874-880, Online. Association for Com-</cell></row><row><cell>putational Linguistics.</cell><cell></cell></row><row><cell cols="2">Gautier Izacard, Fabio Petroni, Lucas Hosseini, Nicola</cell></row><row><cell cols="2">De Cao, Sebastian Riedel, and Edouard Grave. 2020.</cell></row><row><cell cols="2">A memory efficient baseline for open domain ques-</cell></row><row><cell cols="2">tion answering. arXiv preprint arXiv:2012.15156.</cell></row><row><cell cols="2">Youngjin Jang and Harksoo Kim. 2020. Document re-</cell></row><row><cell cols="2">ranking model for machine-reading and comprehen-</cell></row><row><cell cols="2">sion. Applied Sciences, 10(21).</cell></row><row><cell cols="2">Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke</cell></row><row><cell cols="2">Zettlemoyer. 2017. TriviaQA: A large scale dis-</cell></row><row><cell cols="2">tantly supervised challenge dataset for reading com-</cell></row><row><cell cols="2">prehension. In Proceedings of the 55th Annual Meet-</cell></row><row><cell cols="2">ing of the Association for Computational Linguistics</cell></row><row><cell cols="2">(Volume 1: Long Papers), pages 1601-1611, Van-</cell></row><row><cell cols="2">couver, Canada. Association for Computational Lin-</cell></row><row><cell>guistics.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 7 :</head><label>7</label><figDesc>Score aggregation on validation data of NQ-Open, TQ-Open and EfficientQA.</figDesc><table><row><cell></cell><cell>P  *</cell><cell>?</cell><cell>{r}</cell><cell>{rr} {r, rr}</cell></row><row><cell>NQ-Open</cell><cell cols="4">{e} {g} {e, g} 52.24 52.29 52.27 52.07 50.65 51.24 51.01 51.17 50.36 50.91 50.68 50.90</cell></row><row><cell>TQ-Open</cell><cell cols="4">{e} {g} {e, g} 69.77 69.79 69.67 69.61 69.03 69.03 69.01 68.99 69.54 69.46 69.62 69.70</cell></row><row><cell>EfficientQA</cell><cell cols="4">{e} {g} {e, g} 50.78 51.83 50.94 52.22 48.33 50.06 49.39 49.67 48.94 49.50 50.06 49.72</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 8 :</head><label>8</label><figDesc>Binary decision on NQ-Open, TQ-Open and EfficientQA.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head></head><label></label><figDesc>Therefore s ta &lt; s xa , to satisfy the inequality (in equation 20), and we know that 0 &lt; s xa ? |a|. So let the s xa = |a|</figDesc><table><row><cell>thus</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2s xa |x| + |a|</cell><cell cols="2">&gt;</cell><cell cols="3">2s ta |t| + |a|</cell><cell>.</cell><cell>(20)</cell></row><row><cell cols="5">From Lemma C.1 |t| ? |x|. (the maximum) then</cell></row><row><cell cols="4">2|a| |x| + |a|</cell><cell>&gt;</cell><cell>2s ta |t| + |a|</cell></row><row><cell cols="6">|a|(|t| + |a|) &gt; s ta |x| + s ta |a|</cell></row><row><cell cols="2">|x| &lt; |a|</cell><cell cols="4">|t| + |a| ? s ta s ta</cell><cell>,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 9 :</head><label>9</label><figDesc>The results of the pipeline with different types of extractive reader's distribution used for decoding. See text for details.</figDesc><table><row><cell>marginalizes independently</cell><cell>joint comp.</cell><cell>start&amp;end comp.</cell><cell>EM</cell></row><row><cell>-</cell><cell>-</cell><cell></cell><cell>45.42</cell></row><row><cell>-</cell><cell></cell><cell></cell><cell>45.41</cell></row><row><cell></cell><cell>-</cell><cell></cell><cell>45.71</cell></row><row><cell></cell><cell></cell><cell>-</cell><cell>47.09</cell></row><row><cell></cell><cell></cell><cell></cell><cell>47.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 10 :</head><label>10</label><figDesc>Ablation of loss components on NQ-Open test dataset using ELECTRA-base model.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head></head><label></label><figDesc>48.38 -0.12 50.86 50.72 -0.14 65.41 65.46 -0.05 47.67 47.56 -0.11 gen -49.34 49.40 0.06 51.50 50.69 -0.81 68.85 69.14 -0.29 47.33 47.33 0.00 ext+gen naive 49.91 49.99 0.08 53.43 52.44 -0.99 67.82 68.01 -0.19 49.06 49.11 0.05 ext+gen aggr 52.05 51.80 -0.25 54.96 54.90 -0.06 68.49 68.66 -0.17 51.56 52.00 0.44 ext+gen aggr+bd 52.36 52.07 -0.29 55.01 54.99 -0.02 69.62 69.94 -0.32 51.06 52.22 1.16</figDesc><table><row><cell cols="2">Readers Fusion</cell><cell>NQ-Open (dev) Long. RoB. ?</cell><cell>NQ-Open (test) Long. RoB. ?</cell><cell>TQ-Open (test) Long. RoB. ?</cell><cell>EfficientQA Long. RoB.</cell><cell>?</cell></row><row><cell>ext</cell><cell>-</cell><cell>48.50</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 11 :</head><label>11</label><figDesc>Exact match comparison of Longformer (Long.) and RoBERTa (RoB.) based passage reranker.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table 12 :</head><label>12</label><figDesc>Results on the overlapping and non-overlapping parts of test sets for NQ and TQ. Total column corresponds to overall result on the whole dataset, as reported before, Question Overlap corresponds to samples with train-test question overlap and answer overlap, Answer Overlap Only corresponds to samples with answer overlap, but no question overlap, and No Overlap corresponds to samples with no overlap between train and test sets.</figDesc><table><row><cell></cell><cell>Modules</cell><cell>Rankers</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">retriever +reranker</cell></row><row><cell></cell><cell>retriever</cell><cell>0.21</cell><cell>0.21</cell></row><row><cell>intermediate</cell><cell>passage reranker ext. reader gen. reader (25) answer reranker (25)</cell><cell>-2.21 0.55 3.11</cell><cell>1.94 0.35 0.55 3.11</cell></row><row><cell></cell><cell>gen. reader (100)</cell><cell>1.85</cell><cell>-</cell></row><row><cell></cell><cell>answer reranker (100)</cell><cell>11.67</cell><cell>-</cell></row><row><cell></cell><cell>ext</cell><cell>2.41</cell><cell>2.19</cell></row><row><cell></cell><cell>gen (25)</cell><cell>0.76</cell><cell>2.70</cell></row><row><cell>total</cell><cell>ext+gen (25)</cell><cell>6.08</cell><cell>6.16</cell></row><row><cell></cell><cell>gen (100)</cell><cell>2.06</cell><cell>-</cell></row><row><cell></cell><cell>ext+gen (100)</cell><cell>15.94</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head>Table 13 :</head><label>13</label><figDesc>Inference times on NQ-Open in seconds per question. See text for details.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Our demo is available at http://r2d2.fit.vutbr.cz/. Code and preprocessed data are available at https://github.com/ KNOT-FIT-BUT/R2-D2.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">. We push the state-of-the-art for two large and popular datasets, demonstrating what is achievable with the proposed approach, having the same knowledge source and the re-</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Formal definition of softmax over a set is described in the Apendix D.3  We tried decoding from the subsets of these probabilities in Appendix E not observing significant difference.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://cutt.ly/rkZNIer</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://cutt.ly/0luNhx4 6 The test set was not released during our experiments. 7 https://github.com/facebookresearch/DPR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Note that we train on data from retriever, not reranker. 9 Matching strategies are described in Appendix C.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">Due to the numerous decoder computations in answer re-ranking.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14">|x| symbolises number of tokens in span x.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">We simply pass 100 input passages to the model trained with 25 passages in the experiment.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Jan Dole?al for implementing an R2-D2 demo. This work was supported by the Czech Ministry of Education, Youth and Sports, subprogram INTERCOST, project code: LTC18054. The computation used the infrastructure supported by the Ministry of Education, Youth and Sports of the Czech Republic through the e-INFRA CZ (ID:90140).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to retrieve reasoning paths over wikipedia graph for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<ptr target="OpenRe-view.net" />
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations, ICLR 2020, Addis Ababa</title>
		<meeting><address><addrLine>Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Longformer: The long-document transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1171</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Training deep nets with sublinear memory cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<idno>abs/1604.06174</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Probabilistic assumptions matter: Improved models for distantlysupervised document-level question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.501</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5657" to="5667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic assumptions matter: Improved models for distantlysupervised document-level question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.501</idno>
		<idno type="arXiv">arXiv:2007.00814</idno>
	</analytic>
	<monogr>
		<title level="m">Omar Khattab, Christopher Potts, and Matei Zaharia. 2020. Relevance-guided supervision for openQA with colBERT</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Natural questions: A benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00276</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="452" to="466" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ranking paragraphs for improving answer recall in open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seongjun</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miyoung</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1053</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="565" to="569" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1612</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6086" to="6096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Question and answer test-train overlap in open-domain question answering datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1000" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Retrieval-augmented generation for knowledge-intensive NLP tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>K?ttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<imprint>
			<date type="published" when="2020-12-06" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>virtual</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Denoising distantly supervised open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhe</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1161</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1736" to="1745" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
	<note type="report_type">OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sparse, dense, and attentional representations for text retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Generation-augmented retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.08553</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00294</idno>
		<title level="m">Reader-guided passage reranking for open-domain question answering</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00133</idno>
		<title level="m">NeurIPS 2020 EfficientQA competition: Systems, analyses and lessons learned</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A discrete hard EM approach for weakly supervised question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1284</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2851" to="2864" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Knowledge guided text retrieval and reading for open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03868</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">AmbigQA: Answering ambiguous open-domain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.466</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5783" to="5797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m">Passage re-ranking with bert</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Document ranking with a pretrained sequence-to-sequence model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiying</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronak</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.63</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="708" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.14424</idno>
		<title level="m">Multi-stage document ranking with BERT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>K?pf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07531</idno>
		<title level="m">Understanding the behaviors of BERT in ranking</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">How much knowledge can you pack into the parameters of a language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.437</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5418" to="5426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">R3: Reinforced ranker-reader for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerry</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5981" to="5988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-passage BERT: A globally normalized BERT model for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1599</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5878" to="5882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multi-passage BERT: A globally normalized BERT model for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1599</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5878" to="5882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Drame</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Quentin Lhoest, and Alexander Rush</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Early exiting BERT for efficient document ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoliang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.sustainlp-1.11</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</title>
		<meeting>SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="83" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.00808</idno>
		<title level="m">Approximate nearest neighbor negative contrastive learning for dense text retrieval</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Progressively pretrained dense corpus index for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2803" to="2815" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Is retriever merely an approximator of reader?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sohee</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.10999</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">End-to-end open-domain question answering with BERTserini</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aileen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-4013</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="72" to="77" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
