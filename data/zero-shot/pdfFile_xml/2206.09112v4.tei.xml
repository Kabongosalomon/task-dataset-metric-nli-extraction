<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic Forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022">2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zezhi</forename><surname>Shao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wei</surname></persName>
							<email>weiw@hust.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Cao</surname></persName>
							<email>xin.cao@unsw.edu.au</email>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of New South Wales</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">S</forename><surname>Jensen</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Aalborg University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zezhi</forename><surname>Shao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wei</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Cao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">S</forename><surname>Jensen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Decoupled</surname></persName>
						</author>
						<title level="a" type="main">Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic Forecasting</title>
					</analytic>
					<monogr>
						<title level="m">Dynamic Spatial-Temporal Graph Neural Network for Traffic Forecasting. PVLDB</title>
						<imprint>
							<biblScope unit="volume">15</biblScope>
							<biblScope unit="issue">11</biblScope>
							<biblScope unit="page" from="2150" to="8097"/>
							<date type="published" when="2022">2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.14778/3551793.3551827</idno>
					<note>PVLDB Reference Format: PVLDB Artifact Availability: The source code of this research paper has been made publicly available at https://github.com/zezhishao/D2STGNN. * Corresponding author. This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing info@vldb.org.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We all depend on mobility, and vehicular transportation affects the daily lives of most of us. Thus, the ability to forecast the state of traffic in a road network is an important functionality and a challenging task. Traffic data is often obtained from sensors deployed in a road network. Recent proposals on spatial-temporal graph neural networks have achieved great progress at modeling complex spatial-temporal correlations in traffic data, by modeling traffic data as a diffusion process. However, intuitively, traffic data encompasses two different kinds of hidden time series signals, namely the diffusion signals and inherent signals. Unfortunately, nearly all previous works coarsely consider traffic signals entirely as the outcome of the diffusion, while neglecting the inherent signals, which impacts model performance negatively. To improve modeling performance, we propose a novel Decoupled Spatial-Temporal Framework (DSTF) that separates the diffusion and inherent traffic information in a data-driven manner, which encompasses a unique estimation gate and a residual decomposition mechanism. The separated signals can be handled subsequently by the diffusion and inherent modules separately. Further, we propose an instantiation of DSTF, Decoupled Dynamic Spatial-Temporal Graph Neural Network (D 2 STGNN), that captures spatial-temporal correlations and also features a dynamic graph learning module that targets the learning of the dynamic characteristics of traffic networks. Extensive experiments with four real-world traffic datasets demonstrate that the framework is capable of advancing the state-of-the-art.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Traffic forecasting is a crucial service in Intelligent Transportation Systems (ITS) to predict future traffic conditions (e.g., traffic flow 1 ) based on historical traffic conditions <ref type="bibr" target="#b51">[51]</ref> observed by sensors <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b18">19]</ref>. This functionality fuels a wide range of services related to traffic management <ref type="bibr" target="#b3">[4]</ref>, urban computing <ref type="bibr" target="#b52">[52]</ref>, public safety <ref type="bibr" target="#b48">[48]</ref>, and beyond <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b47">47]</ref>.</p><p>Previous traffic forecasting studies usually fall into two categories, i.e., knowledge-driven <ref type="bibr" target="#b2">[3]</ref> and data-driven <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b41">41]</ref>. The former commonly adopt queuing theory for user behavior simulation in traffic <ref type="bibr" target="#b2">[3]</ref>, while neglecting the natural complexity of real-world traffic flow. Regarding the latter, many early studies formulate the problem as a simple time series (e.g., single variant time series) prediction task <ref type="bibr" target="#b19">[20]</ref> and address it via various conventional statistic-based methods, such as auto-regressive integrated moving average (ARIMA <ref type="bibr" target="#b38">[38]</ref>) and Kalman filtering <ref type="bibr" target="#b17">[18]</ref>. These methods do not handle the high non-linearity of each time series well, since they typically rely heavily on stationarity-related assumptions. More importantly, they disregard the complex correlations among time series, which severely limits the effectiveness of traffic forecasting.</p><p>Recently, deep learning-based approaches <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b43">43]</ref> have been proposed to capture the complex spatial-temporal correlations in traffic flow. A promising and effective way is to construct an adjacency matrix to model the complex spatial topology of a road network and formulates the traffic data as a spatial-temporal graph. An example is shown in <ref type="figure" target="#fig_0">Figure 1</ref>(a), where each node represents a sensor, and the signals on each node vary over time. Sequentially, STGNN-based methods are proposed for traffic forecasting that models the dynamics of the traffic flow as a diffusion process <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b41">41]</ref>, and combines diffusion graph convolution <ref type="bibr" target="#b20">[21]</ref> and sequential models <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b46">46]</ref> to jointly model complex spatial-temporal correlations. The former <ref type="bibr" target="#b20">[21]</ref> models the diffusion of vehicles among sensors in a road network, i.e., the spatial dependency. The latter <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b46">46]</ref> models the temporal dynamics, i.e., the temporal dependency.</p><p>Although encouraging results have been achieved, these methods still fail to fully exploit the complex spatial-temporal correlations. First of all, each signal (i.e., time series) naturally contains two different types of signals, i.e., diffusion and non-diffusion signals (which is also called inherent signal for simplicity). The diffusion signal captures the vehicles diffused from other sensors, while the non-diffusion signal captures the vehicles that are independent of other sensors. However, almost all previous studies consider traffic data as a diffusion signal while disregarding the non-diffusion signal. That is, they model the complex spatial-temporal correlations coarsely. However, a reasonable solution is to exploit the complex spatial-temporal correlations more subtly, i.e., explicitly modeling the diffusion and inherent signal simultaneously. Second, the predefined adjacency matrix in STGNN-based methods is static, and thus such construction methods may severely restrict the representative ability to complex road networks, making it difficult for these methods to model the dynamics of traffic flow. We illustrate them with examples in <ref type="figure" target="#fig_2">Figure 2</ref>. Without loss of generality, <ref type="figure" target="#fig_2">Figure  2</ref> presents a typical traffic flow system. Important locations in the road network are equipped with traffic sensors that record traffic flow data, i.e., the number of vehicles during a unit time interval. From <ref type="figure" target="#fig_2">Figure 2</ref>, we make two observations. (I) The recorded values of each sensor are affected by two factors, i.e., the diffusion signal and the non-diffusion signal. As shown in <ref type="figure" target="#fig_2">Figure 2</ref>(a), vehicles passing through sensor 2 (green arrow) at 8 a.m. come from two parts. The first part is vehicles that depart directly from somewhere in the area near the sensor (blue arrow), e.g., vehicles that drive directly from residence to the business district to work. The other part is vehicles diffused from adjacent areas (wine-red arrow), e.g., vehicles that drive from the industrial district (sensor 3) and the agricultural area (sensor 4) to provide daily supplies. The former is independent of other sensors, while the latter is an artifact of the diffusion process. We call them hidden inherent time series and hidden diffusion time series, respectively, and each time series in Figure 2(b) is a superposition of them. (II) The traffic flow within the same road network may change over time, i.e., spatial dependency is dynamic. An example is shown in <ref type="figure" target="#fig_2">Figure 2</ref>(c), where the traffic at sensors 3 and 4 can significantly affect sensor 2 at 8 a.m., while there is only a small influence at 10 a.m. Therefore, addressing the above issues to effectively leverage all complex spatial-temporal correlations in traffic data is essential for improving the performance of traffic forecasting. To achieve this, we first propose a Decoupled Spatial-Temporal Framework (DSTF) that is illustrated in the diagram in <ref type="figure" target="#fig_0">Figure 1</ref>(b). DSTF separates the diffusion and inherent traffic information using a the decouple block in a data-driven manner. Furthermore, we design a dynamic graph learning module based on a self-attention mechanism to address the second issue. The above designs are key elements of an instantiation of DSTF, called the Decoupled Dynamic Spatial-Temporal Graph Neural Network (D 2 STGNN). Specifically, we first design the decouple block shown in <ref type="figure" target="#fig_3">Figure 3</ref>, which contains a residual decomposition mechanism and an estimation gate to decompose traffic  data. The former removes the parts of signals that the diffusion and inherent models can approximate well. Thus, the parts of signals that are not learned well is retained. The latter estimates roughly the proportion of the two kinds of signals to relieve the burden of the first model in each layer, which takes the original signal as input and needs to learn specific parts in it. Second, the dynamic graph learning module comprehensively exploits available information to adjust the road network-based spatial dependency by learning latent correlations between time series based on the self-attention mechanism. In addition, specialized diffusion and inherent models, for the two hidden time series are designed according to their particular characteristics. A spatial-temporal localized convolution is designed to model the hidden diffusion time series. A recurrent neural network and self-attention mechanism are used jointly to model the hidden inherent time series.</p><p>In summary, the main contributions are the following:</p><p>? We propose a novel Decoupled Spatial-Temporal Framework (DSTF) for traffic forecasting, which decouples the hidden time series generated by the diffusion process and the hidden time series that is independent of other sensors. This enables more precise modeling of the different parts of traffic data to improve prediction accuracy. ? Based on the DSTF, a dynamic graph learning module is proposed that takes into account the dynamic nature of spatial dependency. Besides, we design a diffusion model and a inherent model to handle the two hidden time series. The above design forms our instantiation of DSTF, D 2 STGNN. ? We conduct extensive experiments on four real-world, largescale datasets to gain insight into the effectiveness of the framework DSTF and the instantiation D 2 STGNN. Experimental results show that our proposal is able to consistently and significantly outperforms all baselines.</p><p>The paper is organized as follows. Section 2 covers related work, and Section 3 presents preliminaries and the problem definition. In Section 4, we present the decoupled spatial-temporal framework in detail. Section 5 details the chosen instantiation of the framework, D 2 STGNN. We present extensive performance experiments and prediction visualizations in Section 6. We also report on extensive ablation studies of different architectures, important components, and training strategies. Section 7 concludes the paper.</p><p>With the availability of large-scale traffic data and the rise of artificial intelligence <ref type="bibr" target="#b42">[42]</ref>, Spatial-Temporal Graph Neural Networks (STGNNs) are proposed to model the complex spatial-temporal correlations in traffic data <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b49">49]</ref>. Generally speaking, STGNNs model the traffic system as a diffusion process <ref type="bibr" target="#b20">[21]</ref> and combine the diffusion convolutions <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b41">41]</ref> and sequential models <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b46">46]</ref> to jointly model the spatial-temporal correlation. The diffusion convolutions are variants of Graph Convolution Networks (GCN <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b15">16]</ref>), which are well suited to deal with the non-euclidean relationships between multiple time series in traffic data. Sequential models, such as GRU <ref type="bibr" target="#b6">[7]</ref>, LSTM <ref type="bibr" target="#b32">[32]</ref>, and TCN <ref type="bibr" target="#b46">[46]</ref>, are used to model temporal dependency. For example, DCRNN <ref type="bibr" target="#b20">[21]</ref> integrates diffusion convolution and the sequence to sequence architecture <ref type="bibr" target="#b33">[33]</ref> to model the diffusion process. Graph WaveNet <ref type="bibr" target="#b41">[41]</ref> combines diffusion convolution with dilated casual convolution <ref type="bibr" target="#b46">[46]</ref> to capture spatial-temporal correlation efficiently and effectively.</p><p>Recent works focus on designing more powerful diffusion convolution models and sequential models. For example, many variants of GCNs, such as GAT <ref type="bibr" target="#b36">[36]</ref>, MixHop <ref type="bibr" target="#b0">[1]</ref>, and SGC <ref type="bibr" target="#b39">[39]</ref>, are adapted to STGNNs for better performance <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b50">50]</ref>. The attention mechanism <ref type="bibr" target="#b35">[35]</ref> and its variants, which theoretically have infinite receptive field size, are widely used to capture long-term temporal dependencies <ref type="bibr" target="#b11">[12]</ref> in the sequential model <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b53">53]</ref>. Moreover, a few very recent works propose to model the dynamic spatial dependency <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b51">51]</ref>. The idea is to learn the latent correlations between nodes based on dynamic node feature, which is usually represented by the combination of real-time traffic features and other external features. For example, GMAN <ref type="bibr" target="#b51">[51]</ref> designs a spatial attention mechanism by considering traffic features and node embeddings from the graph structure to learn the attention score.</p><p>Although STGNNs have made considerable progress, we find there is still significant room for improvement. Firstly, existing works solely consider the traffic data as a diffusion signal while neglecting the non-diffusion one, as discussed in Section 1. They model the complex spatial-temporal correlations in a coarse manner, which may impact model performance negatively. Secondly, although there are a few works on modeling dynamic spatial dependency, they do not consider all available information. Most of them explore the dynamic spatial dependency based on the feature of traffic conditions, ignoring either the constraints of the road network topology <ref type="bibr" target="#b12">[13]</ref>, or the time <ref type="bibr" target="#b51">[51]</ref> or node <ref type="bibr" target="#b10">[11]</ref> information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>We first define the notions of traffic network and traffic signal, and then define the forecasting problem addressed. Frequently used notations are summarized in <ref type="table" target="#tab_0">Table 1</ref>. Definition 1. Traffic Sensor. A traffic sensor is a sensor deployed in a traffic system, such as a road network, and it records traffic information such as the flow of passing vehicles or vehicle speeds. Definition 2. Traffic Network. A traffic network is a directed or undirected graph = ( , ), where is the set of | | = nodes and each node corresponds to a deployed sensor, and is the set of | | = edges. The reachability between nodes, expressed as an  Definition 4. Traffic Forecasting. Given historical traffic signals X = [X ? ? +1 , ? ? ? , X ?1 , X ] ? R ? ? ? from the passed ? time steps, traffic forecasting aims to predict the future traffic signals Y = [X +1 , X +2 , ? ? ? , X + ] of the nearest future time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE DECOUPLED FRAMEWORK</head><p>The Decoupled Spatial-Temporal Framework (DSTF) that we propose is illustrated in <ref type="figure" target="#fig_3">Figure 3</ref>. Raw traffic signals are firstly transformed from the original space R ? ? ? to the latent space R ? ? ? by a linear layer. For simplicity, we use X ? R ? ? ? in the following as default. DSTF contains multiple decoupled spatial-temporal layers. Given traffic signals X ? R ? ? ? , the decoupled spatialtemporal layer aims at decomposing them into two hidden signals: X = X +X ? , where X and X ? denote the diffusion signals and the inherent signals, respectively. However, it is a challenging task to separate them since we do not have prior knowledge. To this end, we propose a residual decomposition mechanism and an estimation gate in the decouple block (the green block) to decompose the spatial-temporal signals in a data-driven manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Residual Decomposition Mechanism</head><p>We first design the residual decomposition mechanism, which decomposes the traffic signals by removing the part that has been  <ref type="figure" target="#fig_3">Figure 3</ref>: The overall architecture of the proposed D 2 STGNN. The decouple block (green) decomposes each time series in traffic signals into two hidden time series, which are subsequently handled by the diffusion block (pink) and inherent block (blue). Moreover, the dynamic graph learning module generates dynamic spatial dependency for the diffusion model.</p><formula xml:id="formula_0">t 3 t 2 t 1 t 6 t 5 t 4 l ?</formula><p>learned by the diffusion model or inherent model in an information reconstruction fashion. As shown in <ref type="figure" target="#fig_3">Figure 3</ref>, except for the decouple block (green), the decoupled spatial-temporal layer contains a diffusion block (pink) and an inherent block (blue), each with three components: a primary model that learns knowledge from the input data X * ? R ? ? ? and generates hidden states H * ? R ? ? ? , a forecast branch that generates the module's forecast hidden state H * , a backcast branch that generates the best estimate of the module's input signal X * ? R ? ? ? . The star indicates that this applies to both the diffusion and the inherent blocks.</p><p>The backcast branch is crucial for the decoupling, since it reconstructs the learned knowledge, i.e., the portion of input signals that the current model can approximate well. Subsequently, residual links are designed to remove the signals that can be approximated well from the input signals and retain the signals that are not well decomposed. Therefore, after the first (upper) residual link, we get the input of the inherent block, i.e., the inherent signals:</p><formula xml:id="formula_1">X inh = X ? X = X ? (H W )<label>(1)</label></formula><p>where X is the input of ( )-th layer, and X 0 = X. Superscripts dif and inh indicate diffusion and inherent information, respectively. We use non-linear fully connected networks to implement the backcast branch. W is the network parameters, and the is the ReLU <ref type="bibr" target="#b9">[10]</ref> activation function. Similarly, we conduct the second (lower) residual link after the inherent block:</p><formula xml:id="formula_2">X l+1 = X ? ? X ? = X ? ? (H ? W ? )<label>(2)</label></formula><p>where X +1 retains the residual signals that can not be decomposed in the -th layer. Similar to other deep learning methods, we stack multiple decoupled spatial-temporal layers to enhance the model's capabilities, as shown in <ref type="figure" target="#fig_3">Figure 3</ref>. The spatial-temporal signal can be decoupled if we design proper models for diffusion and inherent signals according to their own particular characteristics, and each model can focus on its specific signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Estimation Gate</head><p>Although the residual decomposition can decouple traffic signals in a data-driven manner, the first model (the diffusion model in <ref type="figure" target="#fig_3">Figure  3</ref>) in each layer still faces a challenge that may fail the decoupling process: it takes original traffic data as input, but it needs to learn only the specific part of signals in it. To address this problem, the estimation gate is designed to reduce the burden of the first model by roughly estimating the proportion of the two hidden time series. At its core, the estimation gate learns a gate value automatically in (0, 1) based on the current node and current time embeddings. Firstly, to take into account real-world periodicities, we utilize two time slot embedding matrices: T ? R ? and T ? R ? , where is the number of time slots of the day (determined by the sampling frequency of sensors) and = 7 is the number of days in a week. The embeddings of time slots are thus shared among slots for the same time of the day and the same day of the week. Secondly, we use two matrices for node embeddings, the source node embedding: E ? R ? is used when a node passes messages to neighboring nodes, and the target node embedding E ? R ? is used when a node aggregates information from neighboring nodes. Kindly note that the node embeddings and time slot embeddings are randomly initialized with learnable parameters. Then, given the historical traffic data X and embeddings of time slots and nodes, the estimation gate can be written as:</p><formula xml:id="formula_3">? , = Sigmoid ( ((T ? T ? E ? E )W 1 )W 2 ) X dif = ? ? X (3)</formula><p>where ? ? R ? ? ?1 , and ? , ? (0, 1) estimates the proportion of the diffusion signal in the time series in traffic data at time slot of node . The symbol ? denotes the element-wise product that broadcasts to all the channels of X ? R ? ? ? . W 1 ? R 4 ? and W 2 ? R ?1 are learnable parameters, and is a non-linear activation function, such as ReLU <ref type="bibr" target="#b9">[10]</ref>.</p><p>In addition, although we use the example of <ref type="figure" target="#fig_3">Figure 3</ref>, where the diffusion block precedes the inherent block, they are in principle interchangeable since there is no significant difference in which signal is decomposed first. We conduct experiments in Section 6.5 to verify that there is no significant difference in performance. In this paper, we'll still keep the diffusion-first style. Besides, we omit the superscript for each symbol of the decouple block except the input signal X and residual signal X +1 for simplicity.</p><p>In summary, this section proposes a novel framework DSTF, where each time series in traffic data is decoupled to the diffusion signals and the inherent signals in a data-driven manner. Kindly note that other components, i.e., dynamic graph learning, diffusion model, and inherent model, remain abstract and can be designed independently in the framework according to the characteristics of diffusion and inherent signals. In the next section, we give an instantiation of DSTF by carefully designing these components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DECOUPLED DYNAMIC ST-GNN</head><p>By decomposing diffusion and inherent signals, the framework enables the subsequent models to focus each on what they do best. Here, we propose our Decoupled Dynamic Spatial-Temporal Graph Neural Network (D 2 STGNN) as an instantiation of the proposed framework. We cover the details of the diffusion and inherent blocks as well as the dynamic graph learning shown in <ref type="figure" target="#fig_3">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Diffusion Model: Spatial-Temporal</head><p>Localized Convolutional Layer The diffusion model aims to model the diffusion process between nodes, where the future diffusion signals of a target node depend on the recent values of neighboring nodes, i.e., the setting exhibits spatial-temporal locality. Specifically, we assume that only the traffic signals of order neighboring nodes from the past time steps can affect a target node. Considering the speed of vehicles and the sampling frequency of sensors, the typical values of and are usually 2 or 3. An example is shown in <ref type="figure" target="#fig_5">Figure 4</ref>, where = = 2. In order to capture such the diffusion process, we design a spatial-temporal localized convolutional layer.</p><formula xml:id="formula_4">t = T t = T ? 1 impact on t = T ? 2</formula><p>Firstly, we define a spatial-temporal localized transition matrix:</p><formula xml:id="formula_5">(P local ) = (P ? (1 ? I )) ? ? ? ? ? (P ? (1 ? I ))<label>(4)</label></formula><p>where P ? R ? is a order transition matrix, and = 1, ? ? ? , . Given the road network adjacency matrix A ? R ? , there are two directions of information diffusion: the forward transition P = A/ (A), the backward transition P = A / (A ).</p><p>Therefore, (P local ) ? R ? , and (P local ) [ , ] describes the influence of node on node in a localized spatial-temporal range. Note that P local [ , + ? ] ( ? = 0, 1, ? ? ? , ? 1) are masked to zeros since they describe the inherent patterns of the target nodes themselves, which will be learned by the inherent model. For simplicity, we abbreviate (P local ) as (P ) . Secondly, corresponding to the Eq. 4, there is a localized feature matrix X ? R ? formed as:</p><formula xml:id="formula_6">X = [ (X dif ? +1 W ?1 ) ? ? ? ? ? (X dif W 0 ) ]<label>(5)</label></formula><p>where W is the learnable parameter and is the ReLU activation function. The non-linear transformation used here aims to strengthen the expressive power of the model. Therefore, based on the transition matrix (P ) and feature matrix X mentioned above, we define our spatial-temporal localized graph convolution operator with spatial kernels size as:</p><formula xml:id="formula_7">H dif = ?? =1 (P ) X W<label>(6)</label></formula><p>where H ? R ? is the output of the localized graph convolution operator at time step , which considers spatial information from the order neighbors. Next, W is the graph convolution parameters of -th order, and H is the hidden state of subsequent time slots that can be used to predict the diffusion part.</p><p>In addition to the road network-based transition matrices P and P , we also utilize a self-adaptive transition matrix <ref type="bibr" target="#b41">[41]</ref>. Different from the transition matrices P and P , which are handcrafted by prior human knowledge, the self-adaptive transition matrix is optimized by two randomly initialized node embedding dictionaries with learnable parameters E ? R ? and E ? R ? :</p><formula xml:id="formula_8">P apt = Softmax ( (E (E ) )).<label>(7)</label></formula><p>Note that the P apt ? R ? is normalized by the Softmax function. Therefore, it describes the diffusion process that is similar to transition matrix P and P . Indeed, the matrix P apt can serve as supplement to of the hidden diffusion process that is missed in the road network-based transition matrices P and P . Given the three transition matrices P , P , and P , we can get their corresponding spatial-temporal localized transition matrix in Eq. 4, (P ) , (P ) , and (P ) . We can now present our localized convolutional layer based on the operation in Eq. 6 as follows:</p><formula xml:id="formula_9">H dif = =1 (P ) X W 1 + (P ) X W 2 + (P ) X W 3 . (8)</formula><p>In summary, given temporal kernel size and spatial kernel size as well as input X ? R ? ? ? , the localized convolutional layer generates a hidden state sequence H by synchronously modeling the spatial-temporal correlations in each time step :</p><formula xml:id="formula_10">H dif = ? * (X ) = [? ? ? , H dif ?2 , H dif ?1 , H dif ]<label>(9)</label></formula><p>where ? denotes all the parameters mentioned in Eqs. 5, 7, and 8. denotes the spatial-temporal localized convolution in Eq. 8. The output hidden state sequence H dif is further used to generate two outputs, i.e., the backcast and forecast output.</p><p>Forecast Branch: The last hidden state H dif can be used to forecast the value of the next step. In order to forecast the hidden state in multi-step forecasting task, we follow an auto-regressive procedure to generate</p><formula xml:id="formula_11">H dif = [H dif +1 , H dif +2 , . . . , H dif + ]</formula><p>, each of which is used by a non-linear regression neural network to predict the particular values that we are interested in. Backcast Branch: As discussed in Section 4.1, we use non-linear fully connected networks to implement the backcast branch, and generate X = (H W ), i.e., the learned diffusion part, which subsequently is removed from the original signals by the residual link in Eq. 1 to achieve decomposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Inherent Model: Local and Global Dependency</head><p>The inherent model is designed to model the hidden inherent time series in the original signals of each node, i.e., the X ? . Dependencies in time series are often divided into local and global dependencies, a.k.a. short-and long-term dependencies <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b37">37]</ref>. Previous studies have shown that Gated Recurrent Units <ref type="bibr" target="#b6">[7]</ref> (GRUs) are good at capturing short-term dependencies, while a self-attention layer does better at handling long-term dependencies <ref type="bibr" target="#b37">[37]</ref>. We utilize GRU <ref type="bibr" target="#b6">[7]</ref> and a multi-head self-attention layer <ref type="bibr" target="#b35">[35]</ref> jointly to capture temporal patterns comprehensively. A diagram of the inherent model is shown in <ref type="figure" target="#fig_6">Figure 5</ref>. GRU can recurrently preserve the hidden state of history data and control the information that flows to the next time step. Given the input signal of inherent block X inh ? R ? at time step , for each node , we use the following GRU operation:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-head Self Attention</head><formula xml:id="formula_12">z = (W X inh [ , :] + U H inh ?1 [ , :] + b ) r = (W X inh [ , :] + U H inh ?1 [ , :] + b ) H inh [ , :] = ?(W ? X inh [ , :] + r ? (U ? H inh ?1 [ , :] + b ? )) H inh [ , :] = (1 ? z ) ?? inh ?1 [ , :] + z ?? inh [ , :]<label>(10)</label></formula><p>where H inh [ , :] is the updated hidden state of node at time step , ? denotes the element-wise product, and W , W , W ? , U , U , and U ? are the learnable parameters of GRU. The GRU can capture short-term sequential information well. However, capturing only local information is insufficient because traffic forecasting is also affected by longer-term dependencies <ref type="bibr" target="#b37">[37]</ref>. Hence we introduce a multi-head self-attention layer to capture global dependencies on the top of the GRU. Given the output of the GRU, H ? ? R ? ? ? , the multi-head self-attention layer performs pair-wisely dot product attention on the time dimension for each node, i.e., the product is calculated between any two signals of different time slots. Therefore, the receptive field is theoretically infinite, which is beneficial to capturing global dependencies. Specifically, given attention head , the learnable project matrices W , W , W ? R ? , and the output matrix W , the attention function of node can be written as:</p><formula xml:id="formula_13">H inh [:, , :] = Multihead (H ) = Concat (head 1 , ? ? ? , head )W where head = Attention (H ) = softmax ( H W (H W ) ? H W )<label>(11)</label></formula><p>where H ? R ? is the feature of node in all time slots. All the nodes are calculated individually in parallel with the help of the GPU. Hence, we can get the hidden state of inherent model H inh ? R ? ? . Although the self-attention layer has an infinite receptive field, it ignores relative positions in the sequence. To take into account the position, we apply positional encoding <ref type="bibr" target="#b35">[35]</ref> between GRU and multi-head self-attention layer as follows: </p><formula xml:id="formula_14">H</formula><p>where e ? R is the positional embedding of time step . Note that the positional encoding is not trainable. Forecast Branch: Here, we also adopt auto-regression to generate the future hidden state</p><formula xml:id="formula_16">H inh = [H inh +1 , H inh +2 , . . . , H inh + ].</formula><p>Specifically, we adopt a simple sliding auto-regression, rather than the commonly used encoder-decoder architecture <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b35">35]</ref> because we do not have the ground truth of hidden inherent time series, which are crucial when having to train a decoder. Backcast Branch: Same as the diffusion block, we use non-linear fully connected networks to implement the backcast branch and generate X ? = (H ? W ? ), i.e., the learned inherent part, which is subsequently used in Eq. 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Dynamic Graph Learning</head><p>In this subsection, we design a dynamic graph learning model to capture the dynamics of spatial dependency, as discussed in Section 1. The intensity of traffic diffusion between two connected nodes changes dynamically over time in the real world. An example is shown in <ref type="figure" target="#fig_2">Figure 2(c)</ref>, where the influence between nodes is different between 8:00 am and 10:00 am. Therefore, it is crucial to model dynamic transition matrices P dy and P dy to enhance the static ones P and P by replacing them in Eqs. 8 and 4.</p><p>The core of modeling P dy and P dy is to ensure that the static, dynamic, and time information in traffic data is encoded comprehensively. For a given time step , we take the historical observation as the dynamic feature. For example, given historical data X ? R ? ? ? , the dynamic information of channel can be formulated as X = X [:, :, ] ? R ? , where = 1, ..., . In addition, we consider the time embeddings T ? R and T ? R , which are the embeddings used in the estimation gate in Section 4.2. Employing also two static node embedding matrices E ? R ? and E ? R ? , we first obtain two dynamic feature matrices:</p><formula xml:id="formula_17">DF = Concat [FC( ? =1 X ), T , T , E ] DF = Concat [FC( ? =1 X ), T , T , E ].<label>(13)</label></formula><p>Here, DF ? R ?4 , and DF ? R ?4 . And FC(?) is a non-linear two-layer fully connected network that extracts features and transforms the dimensionality from ? to ? . Further, Concat (?) denotes broadcast concatenation. Then we use the attention mechanism to calculate the pair-wise mask to get dynamic graphs:</p><formula xml:id="formula_18">P dy , = P ? Softmax ( (DF W )(DF W ) ? ) P dy , = P ? Softmax ( (DF W )(DF W ) ? ).<label>(14)</label></formula><p>W and W are the parameters of self-attention mechanism <ref type="bibr" target="#b35">[35]</ref>.</p><p>Matrices P dy , and P dy , ? R ? can replace the transition matrices in Eqs. 8 and 4 to enhance the model, thus completing the proposed D 2 STGNN model. In practice, the calculation of the adjacency matrix is expensive, so to reduce the computational cost, we assume that given a limited time range ? , P dy is static, i.e., P dy ? ? : = P dy .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Output and Training Strategy</head><p>Assuming we stack decoupled spatial-temporal layers, we include the output hidden states in the forecast branches H , =</p><p>[H , +1 , ? ? ? ] and H ?, = [H ?, +1 , ? ? ? ] of the diffusion and the inherent blocks of the -th layer to generate our final forecasting:</p><formula xml:id="formula_19">H = H dif + H inh = ?1 ?? =0 H , + ?1 ?? =0 H ?, = [ ?1 ?? =0 (H dif ,l +1 + H inh,l +1 ), ?1 ?? =0 (H dif ,l +2 + H inh,l +2 ), ? ? ? ].<label>(15)</label></formula><p>Then we adopt a two-layer fully connected network as our regression layer and apply it to H to generate the final predictions. The outputs of the regression layer at each time step are concatenated to form the final output:? ? R ? ? out . Given the ground truth Y ? R ? ? out , we optimize our model using MAE loss: where is the number of nodes, is the number of forecasting steps, and out is the dimensionality of the output. Following existing studies <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b40">40]</ref>, we employ curriculum learning, a general and effective training strategy, to train the proposed model. We optimize the model parameters by minimizing L via gradient descent. The overall learning algorithm is outlined in Algorithm 1.</p><formula xml:id="formula_20">L (?, Y; ?) = 1 out ?? =1 ?? =1 out ?? =1 |? ? Y |<label>(16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head><p>In this section, we present experiments on four large real-world datasets to demonstrate the effectiveness of D 2 STGNN for traffic forecasting. We first introduce the experimental settings, including datasets, baselines, and parameter settings. Then, we conduct experiments to compare the performance of the D 2 STGNN with other baselines. Furthermore, we design more experiments to verify the superiority of our decoupling framework. Finally, we design comprehensive ablation studies to evaluate the impact of the essential architectures, components, and training strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head><p>Datasets. We conducted experiments on four commonly used realworld large-scale datasets, which have tens of thousands of time steps and hundreds of sensors. The statistical information is summarized in <ref type="table" target="#tab_2">Table 2</ref>. Two of them are traffic speed datasets, while the others are traffic flow dataset. Traffic speed data records the average vehicles speed (miles per hour). Due to the speed limit in these areas, the speed data is a float value usually less than 70. The flow data should be an integer, up to hundreds, because it records the number of passing vehicles. All these datasets have one feature channel (the traffic speed or the traffic flow), i.e., = 1.</p><p>Construction of the traffic network. For traffic speed datasets, we follow the procedure of DCRNN <ref type="bibr" target="#b20">[21]</ref>. We compute the pairwise road network distances between sensors and build the adjacency matrix using thresholded Gaussian kernel <ref type="bibr" target="#b30">[30]</ref>. For traffic flow datasets, we use the traffic network provided by ASTGCN <ref type="bibr" target="#b10">[11]</ref>. They remove many redundant detectors to ensure the distance between any adjacent detectors is longer than 3.5 miles to obtain a lightweight traffic network. The following gives more detailed description of the four datasets:</p><p>? METR-LA is a public traffic speed dataset collected from loop-detectors located on the LA County road network <ref type="bibr" target="#b14">[15]</ref>. Specifically, METR-LA contains data of 207 sensors over a period of 4 months from Mar 1st 2012 to Jun 30th 2012 <ref type="bibr" target="#b20">[21]</ref>. The traffic information is recorded at the rate of every 5 minutes, and the total number of time slices is 34,272. ? PEMS-BAY is a public traffic speed dataset collected from California Transportation Agencies (CalTrans) Performance Measurement System (PeMS) <ref type="bibr" target="#b4">[5]</ref>. Specifically, PEMS-BAY contains data of 325 sensors in the Bay Area over a period of 6 months from Jan 1st 2017 to May 31th 2017 <ref type="bibr" target="#b20">[21]</ref>. The traffic information is recorded at the rate of every 5 minutes, and the total number of time slices is 52,116. ? PEMS04 is a public traffic flow dataset collected from Cal-Trans PeMS <ref type="bibr" target="#b4">[5]</ref>. Specifically, PEMS04 contains data of 307 sensors in the District04 over a period of 2 months from Jan 1st 2018 to Feb 28th 2018 <ref type="bibr" target="#b10">[11]</ref>. The traffic information is recorded at the rate of every 5 minutes, and the total number of time slices is 16,992. ? PEMS08 is a public traffic flow dataset collected from Cal-Trans PeMS <ref type="bibr" target="#b4">[5]</ref>. Specifically, PEMS08 contains data of 170 sensors in the District08 over a period of 2 months from July 1st 2018 to Aug 31th 2018 <ref type="bibr" target="#b10">[11]</ref>. The traffic information is recorded at the rate of every 5 minutes, and the total number of time slices is 17,833. Baselines. We select a wealth of baselines that have official public code, including the traditional methods and the typical deep learning methods, as well as the very recent state-of-the-art works.</p><p>? HA: Historical Average model, which models traffic flows as a periodic process and uses weighted averages from previous periods as predictions for future periods. ? VAR: Vector Auto-Regression <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b23">23]</ref> assumes that the passed time series is stationary and estimates the relationship between the time series and their lag value. <ref type="bibr" target="#b37">[37]</ref> ? SVR: Support Vector Regression (SVR) uses linear support vector machine for classical time series regression task.</p><p>? FC-LSTM <ref type="bibr" target="#b32">[32]</ref>: Long Short-Term Memory network with fully connected hidden units is a well-known network architecture that is powerful in capturing sequential dependency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? DCRNN [21]: Diffusion Convolutional Recurrent Neural</head><p>Network <ref type="bibr" target="#b20">[21]</ref> models the traffic flow as a diffusion process. It replaces the fully connected layer in GRU <ref type="bibr" target="#b6">[7]</ref> by diffusion convolutional layer to form a new Diffusion Convolutional Gated Recurrent Unit (DCGRU). ? Graph WaveNet <ref type="bibr" target="#b41">[41]</ref>: Graph WaveNet stacks Gated TCN and GCN layer by layer to jointly capture the spatial and temporal dependencies. ? ASTGCN <ref type="bibr" target="#b10">[11]</ref>: ASTGCN combines the spatial-temporal attention mechanism to capture the dynamic spatial-temporal characteristics of traffic data simultaneously. ? STSGCN <ref type="bibr" target="#b31">[31]</ref>: STSGCN is proposed to effectively capture the localized spatial-temporal correlations and consider the heterogeneity in spatial-temporal data. We use the default settings as described in baseline papers. We evaluate the performances of all baselines by three commonly used metrics in traffic forecasting, including Mean Absolute Error (MAE), Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE). The formulas are as follows:</p><formula xml:id="formula_21">MAE( ,?) = 1 |?| ?? ?? | ??|, RMSE( ,?) = ?? 1 |?| ?? ?? ( ??) 2 , MAPE( ,?) = 1 |?| ?? ?? | ??| ,<label>(17)</label></formula><p>where MAE metric reflects the prediction accuracy <ref type="bibr" target="#b19">[20]</ref>, RMSE is more sensitive to abnormal values, and MAPE can eliminate the influence of data units to some extent. denotes the -th ground truth,?represents the -th predicted values, and ? is the indices of observed samples, where |?| = = 12 in our experiments. Implementation. The proposed model is implemented by Pytorch 1.9.1 on NVIDIA 3090 GPU. We use Adam as our optimizer and set the learning rate to 0.001. The embedding size of nodes and time slots is set to 12. The other hidden dimension in this paper is set to 32. The spatial kernel size is set to 2, and the temporal kernel size is set to 3 for all datasets. The batch size is set to 32. We employ early stopping to avoid overfitting. We perform significance test (t-test with p-value &lt; 0.05) over all the experimental results. For any other more details, readers could refer to our public code repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.2</head><p>The Performance of D 2 STGNN 6.2.1 Settings. For a fair comparison, we follow the dataset division in previous works. For METR-LA and PEMS-BAY, we use about 70% of data for training, 20% of data for testing, and the remaining 10% for validation <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b41">41]</ref>. For PEMS04 and PEMS08, we use about 60% of data for training, 20% of data for testing, and the remaining 20% for validation <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b31">31]</ref>. We generate sequence samples through a sliding window with a width of 24 (2 hours), where the first 12 time steps are used as input, and the remaining 12 time steps are used as ground truth. We compare the performance of 15 minutes (horizon 3), 30 minutes (horizon 6), and 1 hour (horizon 12) ahead forecasting on the MAE, RMSE, and MAPE metrics. <ref type="table" target="#tab_3">Table 3</ref>, D 2 STGNN consistently achieves the best performance in all horizons in all datasets, which indicates the effectiveness of our model. Traditional methods such as HA, SVR perform worst because of their strong assumption about the data, e.g., stationary or linear. FC-LSTM, a classic recurrent neural network for sequential data, can not perform well since it only considers temporal features, but ignores the spatial impact in traffic data and, which is crucial in traffic forecasting. VAR takes both spatial and temporal information into consideration, thus it achieves better performance. However, VAR cannot capture strong nonlinear and dynamic spatial-temporal correlations. Recently proposed spatial-temporal models overcome these shortcomings and make considerable progress. DCRNN and Graph WaveNet are two typical spatial-temporal coupling models among them. Graph WaveNet combines GNN and Gated TCN to form a spatial-temporal layer while DCRNN replaces the fully connected layer in GRU by diffusion convolution to get a diffusion convolutional GRU. Even if compared with many of the latest works, such as ASTGCN and STSGCN, their performance is still very promising. This may be due to their refined data assumptions and reasonable model architecture. MTGNN replaces the GNN and Gated TCN in Graph WaveNet with mix-hop propagation layer <ref type="bibr" target="#b0">[1]</ref> and dilated inception layer, and proposes the learning of latent adjacency matrix to seek further improvement. GMAN performs better in long-term prediction thanks to the attention mechanism's powerful ability to capture long-term dependency. Based on the DCRNN architecture, DGCRN captures the dynamic characteristics of the spatial topology and achieves better performance than other baselines. Our model still outperforms DGCRN. We conjecture the key reason lies in the decoupled ST framework. In a nutshell, the results in <ref type="table" target="#tab_3">Table 3</ref> validate the superiority of D 2 STGNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Results. As shown in</head><p>Note that the final performance is affected by many aspects: the modeling of temporal and spatial dependencies and dynamic spatial topology. Therefore, although <ref type="table" target="#tab_3">Table 3</ref> has shown the superiority of the D 2 STGNN model, it is not enough to evaluate the effectiveness of the proposed decoupled spatial-temporal framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Effectiveness of the Decoupled Framework and the Spatial-Temporal Model</head><p>In this subsection, we conduct experiments to verify the effectiveness of the decoupled spatial-temporal framework as well as the diffusion and inherent model. As mentioned before, we remove the dynamic spatial dependency learning module in all methods, e.g., dynamic graph learner in our model, for a fair comparison. On the one hand, we need to compare D 2 STGNN with its variant without the DSTF, named the coupled version of D 2 STGNN, where the two hidden time series remain coupled like in other STGNNs. On the other hand, we also want to compare the coupled version of D 2 STGNN with the other STGNNs to test the effectiveness of the diffusion and inherent model. To this end, we first replace the dynamic graph in D 2 STGNN with the pre-defined static graph to get D 2 STGNN ? . Based on it, we consider D 2 STGNN ?, which removes the DSTF by removing the estimation gate and residual decomposition, and connects the diffusion model and inherent model directly. We select the two most representative baselines, Graph WaveNet (GWNet) and DGCRN. For a fair comparison, the dynamic adjacency matrix in DGCRN is also removed, named DGCRN ?.</p><p>The result is shown in <ref type="table" target="#tab_4">Table 4</ref>. We have the following findings. (i) D 2 STGNN ? significantly outperforms D 2 STGNN ? , which shows that the DSTF is crucial in our model. (ii) The coupled version D 2 STGNN ? can also perform better than baselines, which indicates the effectiveness of our diffusion and inherent model. However, the D 2 STGNN ? has only limited advantages compared with other baselines, which again shows the importance of decoupling the two hidden time series in the original traffic data.  In this part, we compare the efficiency of D 2 STGNN with other methods based on the METR-LA dataset. For a more intuitive and effective comparison, we compare the average training time required for each epoch of these models. Specifically, we compare the speed of D 2 STGNN, D 2 STGNN ? (without dynamic graph learning), DGCRN, GMAN, MTGNN, and Graph WaveNet. All models are running on Intel(R) Xeon(R) Gold 5217 CPU @ 3.00GHz, 128G RAM computing server, equipped with RTX 3090 graphics card. The batch size is uniformly set to 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Efficiency</head><p>As shown in <ref type="figure" target="#fig_10">Figure 6</ref>, D 2 STGNN does not increase the computational burden too much compared to other baselines. In addition, it achieves both better performance and higher efficiency in the same time than other state-of-the-art baselines like GMAN and DGCRN. This is mainly due to the fact that the decoupled framework (i.e.,estimation gate and residual decomposition mechanism) focuses on developing a more reasonable structures connecting diffusion and inherent models to improve the model's capabilities,  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Ablation Study</head><p>In this part, we will conduct ablation studies from three aspects to verify our work: the architecture of decoupled spatial-temporal framework, the important components, and the training strategy. Firstly, we design four variants of our decoupled spatial-temporal framework. Switch places inherent block before diffusion block in each layer to verify that whether they are interchangeable. W/o gate removes the estimation gate in the decouple block, while w/o res removes the residual links. W/o decouple removes the estimation gate and residual decomposition simultaneously (i.e., the D 2 STGNN ? in <ref type="table" target="#tab_4">Table 4</ref>). Secondly, we test the effectiveness of four important components. W/o dg replaces the dynamic graph with a pre-defined static graph (i.e., the D 2 STGNN ? in <ref type="table" target="#tab_4">Table 4</ref>). W/o apt removes the self-adaptive transition matrix in the diffusion model. W/o gru removes the GRU layer in the inherent model, while w/o msa removes the multi-head self-attention layer. Thirdly, we design two variants to test the effectiveness of the training strategy: w/o ar removes the auto-regression strategy in the forecast branch and directly applies a regression layer on the hidden state to forecast multi-steps at once, w/o cl removes the curriculum learning. The result is shown in <ref type="table" target="#tab_6">Table 5</ref>. On the architecture aspect, switching the diffusion and inherent model does not make a significant difference. The results of w/o gate and w/o res suggest that the estimation gate and residual decomposition mechanism are both important for decoupling. The results of w/o decouple show that decoupling the two hidden signals is crucial for accurate traffic forecasting. On the important components aspect, the dynamic graph learning model provides consistent performance improvements compared with the pre-defined static graph. The results of w/o gru and w/o msa in the inherent model show that both short-and longterm dependencies are crucial for accurate traffic forecasting. On the training strategy aspect, the result of w/o ar indicates that the auto-regressive forecast strategy is more suitable for our model, and the result of w/o cl shows that correct training strategy can help the model to converge better.  In this section, we conduct experiments to analyze the impacts of three critical hyper-parameters: spatial kernel size , temporal kernel size , and hidden dimension . In <ref type="figure" target="#fig_11">Figure 7</ref>, we present the traffic forecasting result on METR-LA dataset with different parameters. The effect of spatial kernel size and temporal kernel size is shown in <ref type="figure" target="#fig_11">Figure 7(a)</ref>. We set the range of and from 1 to 5 individually. The experimental results verify the spatial-temporal localized characteristics of diffusion process. In addition, the effect of hidden dimension is shown in <ref type="figure" target="#fig_11">Figure 7</ref>(b), which shows that a smaller dimension is insufficient to encode the spatial and temporal information, while the larger dimension may introduce overfitting.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Parameter Sensitivity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Visualization</head><p>In order to further intuitively understand and evaluate our model, in this section, we visualize the prediction of our model and the ground-truth. Due to space limitations, we randomly selected two nodes and displayed their data from June 13th 2012 to June 16th 2012 (located in the test dataset). The forecasting results on node 2 and node 111 are shown in <ref type="figure" target="#fig_12">Figure 8</ref>. It is obvious that the patterns of the two selected nodes are different. For example, there is often traffic congestion during the morning peak hour at sensor 2, while sensor 111 often records traffic congestion during the evening peak hours. The results indicate that our model can capture these unique patterns for different nodes. Furthermore, it can be seen that the model is very good at capturing the inherent patterns of time series while avoiding overfitting the noise. For example, sensor 111 apparently failed in the afternoon of June 13, 2012, where the records suddenly were zero. However, our model does not forcefully fit these noises and correctly predicted the traffic congestion. Furthermore, as shown in <ref type="figure" target="#fig_12">Figure 8</ref>, the model achieved very impressive prediction accuracy on the whole, while the prediction in some local details may not be accurate due to large random noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this paper, we first propose to decouple the diffusion signal and inherent signal from traffic data by a novel Decoupled Spatial Temporal Framework (DSTF). This enables more precise modeling of the different parts of traffic data, thus promising to improve prediction accuracy. Based on the novel DSTF, Decoupled Dynamic Spatial-Temporal Graph Neural Network(D 2 STGNN) is proposed by carefully designing the diffusion and inherent model as well as the dynamic graph learning model according to the characteristics of diffusion signals and inherent signals. Specifically, a spatialtemporal localized convolution is designed to model the hidden diffusion time series. The recurrent neural network and self-attention mechanism are jointly used to model the hidden inherent time series. Furthermore, the dynamic graph learning module comprehensively exploits different information to adjust the road network-based spatial dependency by learning the latent correlations between time series based on the self-attention mechanism. Extensive experiments on four real-world datasets show that our proposal is able to consistently and significantly outperform all baselines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Graph structured traffic data and our proposed framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>An example of traffic flow system in the 8:00 a.m.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>An example of the traffic flow system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Definition 3 .</head><label>3</label><figDesc>Traffic Signal. The traffic signal X ? R ? denotes the observation of all sensors on the traffic network at time step , where is the number of features collected by sensors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>An example of spatial-temporal locality where = = 2. Only recent traffic signals from neighboring nodes can diffuse to a target node.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>The inherent model. Short-term dependencies are captured by the GRU, while long-term dependencies are captured by the multi-head self-attention layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>inh [ , :] = H inh [ , :] + e e , = ( /10000 2 / ), if = 0, 2, 4... ( /10000 2 / ), otherwise</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>? GMAN<ref type="bibr" target="#b51">[51]</ref>: GMAN is an attention-based model which stacks spatial, temporal and transform attentions.? MTGNN<ref type="bibr" target="#b40">[40]</ref>: MTGNN extends Graph WaveNet through the mix-hop propagation layer in the spatial module, the dilated inception layer in the temporal module, and a more delicate graph learning layer. ? DGCRN<ref type="bibr" target="#b19">[20]</ref>: DGCRN models the dynamic graph and designs a novel Dynamic Graph Convolutional Recurrent Module (DGCRM) to capture the spatial-temporal pattern in a seq2seq architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 :</head><label>6</label><figDesc>Average training time per epoch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 :</head><label>7</label><figDesc>Parameter sensitivity of D 2 STGNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 :</head><label>8</label><figDesc>Visualization of prediction results on METR-LA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Frequently used notation.</figDesc><table><row><cell cols="2">Notations Definitions</cell></row><row><cell></cell><cell>The traffic network = ( , ) with node set</cell></row><row><cell></cell><cell>and edge set .</cell></row><row><cell></cell><cell>Number of sensors (nodes) of the traffic network,</cell></row><row><cell></cell><cell>i.e., | | = .</cell></row><row><cell>A</cell><cell>The adjacency matrix of traffic network .</cell></row><row><cell></cell><cell>The number of past traffic signals considered.</cell></row><row><cell></cell><cell>The number of future time steps to forecast.</cell></row><row><cell></cell><cell>Number of feature channels in a traffic signal.</cell></row><row><cell></cell><cell>Dimensionality of hidden states.</cell></row><row><cell>E</cell><cell>Embedding of the sensors (nodes).</cell></row><row><cell>T</cell><cell>Embedding of the time steps.</cell></row><row><cell>W</cell><cell>Parameter matrix of the fully connected layer.</cell></row><row><cell>X</cell><cell>Traffic signal at the -th time step.</cell></row><row><cell>H</cell><cell>Hidden state at the -th time step.</cell></row><row><cell>X</cell><cell>Traffic signals of the ? most recent past time</cell></row><row><cell></cell><cell>steps.</cell></row><row><cell>Y</cell><cell>Traffic signals of the nearest-future time steps.</cell></row><row><cell>H</cell><cell>Hidden states over multiple time steps.</cell></row><row><cell>?</cell><cell>Element-wise product.</cell></row><row><cell>?</cell><cell>Concatenation.</cell></row><row><cell cols="2">Concat (?) Broadcast concatenation.</cell></row><row><cell cols="2">adjacent matrix A ? R ? , could be obtained based on the pairwise</cell></row><row><cell cols="2">road network distances between nodes.</cell></row></table><note>?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Algorithm 1 :</head><label>1</label><figDesc>The overall learning algorithm of D 2 STGNN Input: The traffic signals over the past ? time steps X, the adjacency matrix A, time embeddings T and T , node embeddings E and E , the number of layers . Output: The prediction of traffic signals Y in future time steps. Calculate self-adaptive adjacent matrix A by Eq. 7.</figDesc><table><row><cell cols="2">3 output ? [ ]</cell><cell></cell><cell></cell></row><row><cell cols="2">4 X 0 ? X</cell><cell></cell><cell></cell></row><row><cell cols="2">5 for l in range(L) do</cell><cell></cell><cell></cell></row><row><cell>6</cell><cell cols="3">Calculate X dif according to Eq. 3 with time and node</cell></row><row><cell></cell><cell>embeddings.</cell><cell></cell><cell>? Estimation gate</cell></row><row><cell>7</cell><cell>Calculate H dif , X</cell><cell>dif</cell><cell>according to Eq. 9 and the backcast</cell></row><row><cell></cell><cell>branch.</cell><cell></cell><cell>? Diffusion block</cell></row></table><note>12 Calculate dynamic transition matrix Pdy and Pdy by Eq. 14.8 Calculate X inh according to Eq. 1.? Decomposition9 Calculate H inh , X inh according to Eq. 11 and the backcast branch.? Inherent block10 Calculate X +1 according to Eq. 2.? Decomposition11 Append the output of forecast branch of diffusion and inherent block to the output list.12 end13 H ? sum(output)14? ? MLP(H )15 Backpropagation and update parameters according to Eq. 16.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics of datasets.</figDesc><table><row><cell>Type</cell><cell>Dataset</cell><cell cols="3"># Node # Edge # Time Step</cell></row><row><cell>Speed</cell><cell>METR-LA PEMS-BAY</cell><cell>207 325</cell><cell>1722 2694</cell><cell>34272 52116</cell></row><row><cell>Flow</cell><cell>PEMS04 PEMS08</cell><cell>307 170</cell><cell>680 548</cell><cell>16992 17856</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Traffic forecasting on the METR-LA, PEMS-BAY, PEMS04,and PEMS08 datasets. Numbers marked with * indicate that the improvement is statistically significant compared with the best baseline (t-test with p-value&lt; 0.05). 28.64 * 11.64% * 18.28 * 30.10 * 12.10% * 19.55 * 31.99 12.82% *</figDesc><table><row><cell>Datasets</cell><cell>Methods</cell><cell></cell><cell>Horizon 3</cell><cell></cell><cell></cell><cell>Horizon 6</cell><cell></cell><cell></cell><cell>Horizon 12</cell><cell></cell></row><row><cell></cell><cell></cell><cell>MAE</cell><cell>RMSE</cell><cell cols="2">MAPE MAE</cell><cell>RMSE</cell><cell cols="3">MAPE MAE RMSE</cell><cell>MAPE</cell></row><row><cell></cell><cell>HA</cell><cell>4.79</cell><cell>10.00</cell><cell>11.70%</cell><cell>5.47</cell><cell>11.45</cell><cell>13.50%</cell><cell>6.99</cell><cell>13.89</cell><cell>17.54%</cell></row><row><cell></cell><cell>VAR</cell><cell>4.42</cell><cell>7.80</cell><cell>13.00%</cell><cell>5.41</cell><cell>9.13</cell><cell>12.70%</cell><cell>6.52</cell><cell>10.11</cell><cell>15.80%</cell></row><row><cell></cell><cell>SVR</cell><cell>3.39</cell><cell>8.45</cell><cell>9.30%</cell><cell>5.05</cell><cell>10.87</cell><cell>12.10%</cell><cell>6.72</cell><cell>13.76</cell><cell>16.70%</cell></row><row><cell></cell><cell>FC-LSTM</cell><cell>3.44</cell><cell>6.30</cell><cell>9.60%</cell><cell>3.77</cell><cell>7.23</cell><cell>10.09%</cell><cell>4.37</cell><cell>8.69</cell><cell>14.00%</cell></row><row><cell></cell><cell>DCRNN</cell><cell>2.77</cell><cell>5.38</cell><cell>7.30%</cell><cell>3.15</cell><cell>6.45</cell><cell>8.80%</cell><cell>3.60</cell><cell>7.60</cell><cell>10.50%</cell></row><row><cell></cell><cell>STGCN</cell><cell>2.88</cell><cell>5.74</cell><cell>7.62%</cell><cell>3.47</cell><cell>7.24</cell><cell>9.57%</cell><cell>4.59</cell><cell>9.40</cell><cell>12.70%</cell></row><row><cell>METR-LA</cell><cell>Graph WaveNet ASTGCN</cell><cell>2.69 4.86</cell><cell>5.15 9.27</cell><cell>6.90% 9.21%</cell><cell>3.07 5.43</cell><cell>6.22 10.61</cell><cell>8.37% 10.13%</cell><cell>3.53 6.51</cell><cell>7.37 12.52</cell><cell>10.01% 11.64%</cell></row><row><cell></cell><cell>STSGCN</cell><cell>3.31</cell><cell>7.62</cell><cell>8.06%</cell><cell>4.13</cell><cell>9.77</cell><cell>10.29%</cell><cell>5.06</cell><cell>11.66</cell><cell>12.91%</cell></row><row><cell></cell><cell>MTGNN</cell><cell>2.69</cell><cell>5.18</cell><cell>6.88%</cell><cell>3.05</cell><cell>6.17</cell><cell>8.19%</cell><cell>3.49</cell><cell>7.23</cell><cell>9.87%</cell></row><row><cell></cell><cell>GMAN</cell><cell>2.80</cell><cell>5.55</cell><cell>7.41%</cell><cell>3.12</cell><cell>6.49</cell><cell>8.73%</cell><cell>3.44</cell><cell>7.35</cell><cell>10.07%</cell></row><row><cell></cell><cell>DGCRN</cell><cell>2.62</cell><cell>5.01</cell><cell>6.63%</cell><cell>2.99</cell><cell>6.05</cell><cell>8.02%</cell><cell>3.44</cell><cell>7.19</cell><cell>9.73%</cell></row><row><cell></cell><cell>D 2 STGNN</cell><cell>2.56  *</cell><cell>4.88  *</cell><cell cols="2">6.48%  *  2.90  *</cell><cell>5.89  *</cell><cell cols="2">7.78%  *  3.35  *</cell><cell>7.03  *</cell><cell>9.40%  *</cell></row><row><cell></cell><cell>HA</cell><cell>1.89</cell><cell>4.30</cell><cell>4.16%</cell><cell>2.50</cell><cell>5.82</cell><cell>5.62%</cell><cell>3.31</cell><cell>7.54</cell><cell>7.65%</cell></row><row><cell></cell><cell>VAR</cell><cell>1.74</cell><cell>3.16</cell><cell>3.60%</cell><cell>2.32</cell><cell>4.25</cell><cell>5.00%</cell><cell>2.93</cell><cell>5.44</cell><cell>6.50%</cell></row><row><cell></cell><cell>SVR</cell><cell>1.85</cell><cell>3.59</cell><cell>3.80%</cell><cell>2.48</cell><cell>5.18</cell><cell>5.50%</cell><cell>3.28</cell><cell>7.08</cell><cell>8.00%</cell></row><row><cell></cell><cell>FC-LSTM</cell><cell>2.05</cell><cell>4.19</cell><cell>4.80%</cell><cell>2.20</cell><cell>4.55</cell><cell>5.20%</cell><cell>2.37</cell><cell>4.96</cell><cell>5.70%</cell></row><row><cell></cell><cell>DCRNN</cell><cell>1.38</cell><cell>2.95</cell><cell>2.90%</cell><cell>1.74</cell><cell>3.97</cell><cell>3.90%</cell><cell>2.07</cell><cell>4.74</cell><cell>4.90%</cell></row><row><cell></cell><cell>STGCN</cell><cell>1.36</cell><cell>2.96</cell><cell>2.90%</cell><cell>1.81</cell><cell>4.27</cell><cell>4.17%</cell><cell>2.49</cell><cell>5.69</cell><cell>5.79%</cell></row><row><cell>PEMS-BAY</cell><cell>Graph WaveNet ASTGCN</cell><cell>1.30 1.52</cell><cell>2.74 3.13</cell><cell>2.73% 3.22%</cell><cell>1.63 2.01</cell><cell>3.70 4.27</cell><cell>3.67% 4.48%</cell><cell>1.95 2.61</cell><cell>4.52 5.42</cell><cell>4.63% 6.00%</cell></row><row><cell></cell><cell>STSGCN</cell><cell>1.44</cell><cell>3.01</cell><cell>3.04%</cell><cell>1.83</cell><cell>4.18</cell><cell>4.17%</cell><cell>2.26</cell><cell>5.21</cell><cell>5.40%</cell></row><row><cell></cell><cell>MTGNN</cell><cell>1.32</cell><cell>2.79</cell><cell>2.77%</cell><cell>1.65</cell><cell>3.74</cell><cell>3.69%</cell><cell>1.94</cell><cell>4.49</cell><cell>4.53%</cell></row><row><cell></cell><cell>GMAN</cell><cell>1.34</cell><cell>2.91</cell><cell>2.86%</cell><cell>1.63</cell><cell>3.76</cell><cell>3.68%</cell><cell>1.86</cell><cell>4.32</cell><cell>4.37%</cell></row><row><cell></cell><cell>DGCRN</cell><cell>1.28</cell><cell>2.69</cell><cell>2.66%</cell><cell>1.59</cell><cell>3.63</cell><cell>3.55%</cell><cell>1.89</cell><cell>4.42</cell><cell>4.43%</cell></row><row><cell></cell><cell>D 2 STGNN</cell><cell>1.24  *</cell><cell>2.60  *</cell><cell cols="2">2.58%  *  1.55  *</cell><cell>3.52  *</cell><cell cols="2">3.49%  *  1.85  *</cell><cell>4.30  *</cell><cell>4.37%</cell></row><row><cell></cell><cell>HA</cell><cell>28.92</cell><cell>42.69</cell><cell cols="2">20.31% 33.73</cell><cell>49.37</cell><cell cols="2">24.01% 46.97</cell><cell>67.43</cell><cell>35.11%</cell></row><row><cell></cell><cell>VAR</cell><cell>21.94</cell><cell>34.30</cell><cell cols="2">16.42% 23.72</cell><cell>36.58</cell><cell cols="2">18.02% 26.76</cell><cell>40.28</cell><cell>20.94%</cell></row><row><cell></cell><cell>SVR</cell><cell>22.52</cell><cell>35.30</cell><cell cols="2">14.71% 27.63</cell><cell>42.23</cell><cell cols="2">18.29% 37.86</cell><cell>56.01</cell><cell>26.72%</cell></row><row><cell></cell><cell>FC-LSTM</cell><cell>21.42</cell><cell>33.37</cell><cell cols="2">15.32% 25.83</cell><cell>39.10</cell><cell cols="2">20.35% 36.41</cell><cell>50.73</cell><cell>29.92%</cell></row><row><cell></cell><cell>DCRNN</cell><cell>20.34</cell><cell>31.94</cell><cell cols="2">13.65% 23.21</cell><cell>36.15</cell><cell cols="2">15.70% 29.24</cell><cell>44.81</cell><cell>20.09%</cell></row><row><cell></cell><cell>STGCN</cell><cell>19.35</cell><cell>30.76</cell><cell cols="2">12.81% 21.85</cell><cell>34.43</cell><cell cols="2">14.13% 26.97</cell><cell>41.11</cell><cell>16.84%</cell></row><row><cell>PEMS04</cell><cell cols="2">Graph WaveNet 18.15 ASTGCN 20.15</cell><cell>29.24 31.43</cell><cell cols="2">12.27% 19.12 14.03% 22.09</cell><cell>30.62 34.34</cell><cell cols="2">13.28% 20.69 15.47% 26.03</cell><cell>33.02 40.02</cell><cell>14.11% 19.17%</cell></row><row><cell></cell><cell>STSGCN</cell><cell>19.41</cell><cell>30.69</cell><cell cols="2">12.82% 21.83</cell><cell>34.33</cell><cell cols="2">14.54% 26.27</cell><cell>40.11</cell><cell>14.71%</cell></row><row><cell></cell><cell>MTGNN</cell><cell>18.22</cell><cell>30.13</cell><cell cols="2">12.47% 19.27</cell><cell>32.21</cell><cell cols="2">13.09% 20.93</cell><cell>34.49</cell><cell>14.02%</cell></row><row><cell></cell><cell>GMAN</cell><cell>18.28</cell><cell>29.32</cell><cell cols="2">12.35% 18.75</cell><cell>30.77</cell><cell cols="2">12.96% 19.95</cell><cell>30.21</cell><cell>12.97%</cell></row><row><cell></cell><cell>DGCRN</cell><cell>18.27</cell><cell>28.97</cell><cell cols="2">12.36% 19.39</cell><cell>30.86</cell><cell cols="2">13.42% 21.09</cell><cell>33.59</cell><cell>14.94%</cell></row><row><cell cols="3">D 2 STGNN HA VAR SVR FC-LSTM DCRNN STGCN Graph WaveNet 14.02 23.52 19.52 17.93 17.38 15.64 15.30 17.44  PEMS08 ASTGCN 16.48</cell><cell>34.96 29.73 27.69 26.27 25.48 25.03 22.76 25.09</cell><cell cols="2">14.72% 27.67 12.54% 22.25 10.95% 22.41 12.63% 21.22 10.04% 17.88 9.88% 17.69 8.95% 15.24 11.03% 18.66</cell><cell>40.89 33.30 34.53 31.97 27.63 27.27 24.22 28.17</cell><cell cols="2">17.37% 39.28 14.23% 26.17 13.97% 32.11 17.32% 30.69 11.38% 22.51 11.03% 25.46 9.57% 16.67 12.23% 22.83</cell><cell>56.74 38.97 47.03 43.96 34.21 33.71 26.77 33.68</cell><cell>25.17% 17.32% 20.99% 25.72% 14.17% 13.34% 10.86% 15.24%</cell></row><row><cell></cell><cell>STSGCN</cell><cell>15.45</cell><cell>24.39</cell><cell cols="2">10.22% 16.93</cell><cell>26.53</cell><cell cols="2">10.84% 19.50</cell><cell>30.43</cell><cell>12.27%</cell></row><row><cell></cell><cell>MTGNN</cell><cell>14.24</cell><cell>22.43</cell><cell cols="2">9.02% 15.30</cell><cell>24.32</cell><cell cols="2">9.58% 16.85</cell><cell>26.93</cell><cell>10.57%</cell></row><row><cell></cell><cell>GMAN</cell><cell>13.80</cell><cell>22.88</cell><cell cols="2">9.41% 14.62</cell><cell>24.02</cell><cell cols="2">9.57% 15.72</cell><cell>25.96</cell><cell>10.56%</cell></row><row><cell></cell><cell>DGCRN</cell><cell>13.89</cell><cell>22.07</cell><cell cols="2">9.19% 14.92</cell><cell>23.99</cell><cell cols="2">9.85% 16.73</cell><cell>26.88</cell><cell>10.84%</cell></row><row><cell></cell><cell>D 2 STGNN</cell><cell>13.14</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>** 21.42* 8.55%* 14.21* 23.65* 9.12%* 15.69* 26.41 10.17% *</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison of decoupled and coupled ST Framework. H denotes horizon. Numbers marked with * indicate that the improvement is statistically significant compared with the best baseline (t-test with p-value&lt; 0.05).GWNet DGCRN ? D 2 STGNN ? D 2 STGNN ? rather than increasing the complexity of the diffusion or inherent models. Graph WaveNet and MTGNN are the most efficient, thanks to their lightweight and easily parallelized models. But their performance is worse than other models.</figDesc><table><row><cell>METR-LA</cell><cell>H 3 H 6</cell><cell>MAE RMSE MAPE 6.90% 2.69 5.15 MAE 3.07 RMSE 6.22 MAPE 8.37%</cell><cell>2.71 5.19 7.04% 3.12 6.31 8.60%</cell><cell>2.66 5.10 6.80% 3.04 6.13 8.24%</cell><cell>2.59  *  4.99  *  6.69%  *  2.93  *  5.97  *  7.99%  *</cell></row><row><cell></cell><cell>H 12</cell><cell cols="2">MAE RMSE MAPE 10.01% 10.62% 3.53 3.64 7.37 7.59</cell><cell>3.51 7.27 10.02%</cell><cell>3.38  *  7.07  *  9.63%  *</cell></row><row><cell>PEMS-BAY</cell><cell>H 3 H 6</cell><cell>MAE RMSE MAPE 2.73% 1.30 2.74 MAE 1,63 RMSE 3.70 MAPE 3.67%</cell><cell>1.32 2.78 2.78% 1.66 3.78 3.76%</cell><cell>1.31 2.74 2.76% 1.63 3.66 3.66%</cell><cell>1.25  *  2.64  *  2.64%  *  1.55  *  3.56  *  3.58%  *</cell></row><row><cell></cell><cell>H 12</cell><cell>MAE RMSE MAPE 4.63% 1.95 4.52</cell><cell>1.99 4.60 4.73%</cell><cell>1.94 4.50 4.59%</cell><cell>1.85  *  4.33  *  4.43%  *</cell></row><row><cell>PEMS04</cell><cell>H 3 H 6</cell><cell cols="2">MAE RMSE 29.24 18.15 MAPE 12.27% 13.38% 18.97 30.01 MAE 19.12 20.30 RMSE 30.62 31.78 MAPE 13.28% 14.48%</cell><cell>18.94 29.38 13.58% 20.14 31.54 15.11%</cell><cell>17.55  *  28.70  *  11.78%  *  18.38  *  30.15  *  12.26%  *</cell></row><row><cell></cell><cell>H 12</cell><cell cols="2">MAE RMSE 33.02 20.69 MAPE 14.11% 16.97% 22.95 35.15</cell><cell>22.57 34.33 17.16%</cell><cell>19.59  *  32.04  *  12.95%  *</cell></row><row><cell>PEMS08</cell><cell>H 3 H 6</cell><cell cols="2">MAE RMSE 22.76 14.02 MAPE 8.95% MAE 15.24 RMSE 24.22 MAPE 9.57% 10.03% 14.54 22.62 9.37% 15.64 24.52</cell><cell>14.49 22.35 10.14% 15.69 24.37 10.41%</cell><cell>13.28  *  21.56  *  8.53%  *  14.26  *  23.49  *  9.15%  *</cell></row><row><cell></cell><cell>H 12</cell><cell cols="2">MAE RMSE 26.77 16.67 MAPE 10.86% 11.71% 17.80 27.92</cell><cell>18.01 27.53 11.81%</cell><cell>15.65  *  25.78  *  10.10%</cell></row></table><note>*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Ablation study on METR-LA.</figDesc><table><row><cell></cell><cell></cell><cell>Variants</cell><cell cols="2">Horizon 3</cell><cell></cell><cell cols="2">Horizon 6</cell><cell>Horizon 12</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">MAE RMSE MAPE MAE RMSE MAPE MAE RMSE MAPE</cell></row><row><cell></cell><cell></cell><cell>D 2 STGNN</cell><cell>2.56</cell><cell>4.88</cell><cell>6.48% 2.90</cell><cell>5.89</cell><cell>7.78% 3.35</cell><cell>7.03</cell><cell>9.40%</cell></row><row><cell></cell><cell></cell><cell>switch</cell><cell>2.56</cell><cell>4.90</cell><cell>6.50% 2.91</cell><cell>5.92</cell><cell>7.85 % 3.35</cell><cell>7.05</cell><cell>9.47%</cell></row><row><cell></cell><cell></cell><cell>w/o gate</cell><cell>2.60</cell><cell>4.98</cell><cell>6.63% 2.96</cell><cell>6.01</cell><cell>8.07 % 3.44</cell><cell>7.16</cell><cell>9.78%</cell></row><row><cell></cell><cell></cell><cell>w/o res</cell><cell>2.60</cell><cell>4.96</cell><cell>6.84% 2.93</cell><cell>5.95</cell><cell>8.21 % 3.37</cell><cell>7.10</cell><cell>9.80%</cell></row><row><cell></cell><cell></cell><cell cols="2">w/o decouple 2.66</cell><cell>5.10</cell><cell>6.80% 3.04</cell><cell>6.13</cell><cell>8.24 % 3.51</cell><cell>7.27</cell><cell>10.02%</cell></row><row><cell></cell><cell></cell><cell>w/o dg</cell><cell>2.59</cell><cell>4.99</cell><cell>6.69% 2.93</cell><cell>5.97</cell><cell>7.99 % 3.38</cell><cell>7.07</cell><cell>9.63%</cell></row><row><cell></cell><cell></cell><cell>w/o apt</cell><cell>2.58</cell><cell>4.92</cell><cell>6.51% 2.93</cell><cell>5.92</cell><cell>7.80 % 3.40</cell><cell>7.10</cell><cell>9.43%</cell></row><row><cell></cell><cell></cell><cell>w/o gru</cell><cell>2.59</cell><cell>4.93</cell><cell>6.66% 2.94</cell><cell>6.02</cell><cell>7.98 % 3.38</cell><cell>7.07</cell><cell>9.66%</cell></row><row><cell></cell><cell></cell><cell>w/o msa</cell><cell>2.59</cell><cell>4.95</cell><cell>6.60% 2.93</cell><cell>5.96</cell><cell>7.99 % 3.37</cell><cell>7.09</cell><cell>9.67%</cell></row><row><cell></cell><cell></cell><cell>w/o ar</cell><cell>2.59</cell><cell>4.98</cell><cell>6.61% 2.94</cell><cell>5.96</cell><cell>7.95 % 3.39</cell><cell>7.09</cell><cell>9.64%</cell></row><row><cell></cell><cell></cell><cell>w/o cl</cell><cell>2.62</cell><cell>5.01</cell><cell>6.70% 2.96</cell><cell>6.02</cell><cell>8.05 % 3.38</cell><cell>7.08</cell><cell>9.63%</cell></row><row><cell>2012-06-13</cell><cell>2012-06-13</cell><cell>2012-06-14</cell><cell>2012-06-15</cell><cell cols="2">2012-06-15</cell><cell></cell><cell></cell></row><row><cell>03:55:00</cell><cell>20:35:00</cell><cell>13:15:00</cell><cell>05:55:00</cell><cell>22:35:00</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Time(5min)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">An example of a traffic flow system is shown in Figure 2(a), where traffic sensors are deployed at important locations in the road network and record the total number of vehicles passing during a unit time interval. Over time, we can get four time series corresponding to sensors 1 to 4, as shown in Figure 2(b).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported in part by the National Natural Science </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amol</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazanin</forename><surname>Alipourfard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrayr</forename><surname>Harutyunyan</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">international conference on machine learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
	<note>Greg Ver Steeg, and Aram Galstyan</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Spectral Networks and Locally Connected Networks on Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1312.6203" />
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations</title>
		<meeting><address><addrLine>Banff, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04-14" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Transportation systems engineering: theory and methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ennio</forename><surname>Cascetta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">49</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Prediction based traffic management in a metropolitan area</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Chavhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallapa</forename><surname>Venkataram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of traffic and transportation engineering</title>
		<imprint>
			<biblScope unit="page" from="447" to="466" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>English edition) 7, 4 (2020</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freeway performance measurement system: mining loop detector data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Petty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Skabardonis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record</title>
		<imprint>
			<biblScope unit="volume">1748</biblScope>
			<biblScope unit="page" from="96" to="102" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Pravin Varaiya, and Zhanfeng Jia</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Tssrgcn: Temporal spectral spatial retrieval graph convolutional network for traffic flow forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaigui</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunqing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="954" to="959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSST@EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?l</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-05" />
			<biblScope unit="page" from="3837" to="3845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">MDTP: A Multisource Deep Traffic Prediction Framework over Spatio-Temporal Trajectory Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziquan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjun</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1289" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics. JMLR Workshop and Conference Proceedings</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics. JMLR Workshop and Conference Proceedings</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Attention based spatial-temporal graph convolutional networks for traffic flow forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="922" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning dynamics and heterogeneity of spatial-temporal graph data for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiucheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamic and Multi-faceted Spatio-temporal Deep Learning for Traffic Speed Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangzhe</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leilei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisheng</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="547" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Traffic incident detection: A trajectory-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Grubenmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reynold</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sze</forename><forename type="middle">Chun</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 36th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1866" to="1869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Big data and its technical challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hosagrahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Labrinidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Papakonstantinou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jignesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghu</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shahabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="86" to="94" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A smoothness priors-state space modeling of time series with trend and seasonality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genshiro</forename><surname>Kitagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Gersch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="378" to="389" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Short-term traffic flow prediction using seasonal ARIMA model with limited input data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lelitha</forename><surname>S Vasantha Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vanajakshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Transport Research Review</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An Empirical Experiment on Deep Learning Models for Predicting Traffic Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunwook</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheonbok</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungmin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeshin</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungahn</forename><surname>Ko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 37th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1817" to="1822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Dynamic Graph Convolutional Recurrent Network for Traffic Prediction: Benchmark and Solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuxian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Depeng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.14917</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rose</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Integrating granger causality and vector auto-regression for traffic prediction of large-scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songyue</forename><surname>Cui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">WLANs. KSII Transactions on Internet and Information Systems (TIIS)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="136" to="151" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">New introduction to multiple time series analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>L?tkepohl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Traffic flow prediction with big data: a deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisheng</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjie</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwen</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Yue</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="865" to="873" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">N-BEATS: Neural basis expansion analysis for interpretable time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitri</forename><surname>Boris N Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carpov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Chapados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Urban traffic prediction from spatio-temporal data using deep meta learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheyi</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1720" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ST-GRAT: A novel spatio-temporal graph attention networks for accurately forecasting dynamically changing road speed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheonbok</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunggi</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyojin</forename><surname>Bahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunwon</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungmin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungahn</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1215" to="1224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">CABIN: a novel cooperative attention based location prediction network using internal-external trajectory dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tangwen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="521" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zezhi</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Xu</surname></persName>
		</author>
		<title level="m">Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting. arXiv e-prints (2022)</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page">2206</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains. IEEE signal processing magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David I Shuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sunil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vandergheynst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="83" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Spatialtemporal synchronous graph convolutional networks: A new framework for spatial-temporal network data forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="914" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">DeepTRANS: a deep learning system for public bus travel time estimation using traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luan</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Mun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonah</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Yamato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Huh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shahabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2957" to="2960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Graph Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Traffic flow prediction via spatial temporal graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiyan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1082" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Modeling and forecasting vehicular traffic flow as a seasonal ARIMA process: Theoretical basis and empirical results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Billy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of transportation engineering</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="664" to="672" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Simplifying graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amauri</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6861" to="6871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Connecting the dots: Multivariate time series forecasting with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="753" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Graph WaveNet for Deep Spatial-Temporal Graph Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1907" />
			<biblScope unit="volume">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Artificial intelligence: A powerful paradigm for scientific research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enke</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengliang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Wei</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Innovation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jintao</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitian</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinghua</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieping</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-02-02" />
			<biblScope unit="page" from="2588" to="2595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Coupled Layerwise Graph Convolution for Transportation Demand Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchen</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leilei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021</title>
		<imprint>
			<date type="published" when="2021-02-02" />
			<biblScope unit="page" from="4617" to="4625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolutional networks: a deep learning framework for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoteng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3634" to="3640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Multi-Scale Context Aggregation by Dilated Convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International Conference on Learning Representations, ICLR 2016</title>
		<meeting><address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05-02" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">An effective joint prediction model for travel demands and traffic flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 37th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="348" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Hetero-convlstm: A deep learning approach to traffic accident prediction on heterogeneous spatio-temporal data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoning</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="984" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">GaAN: Gated Attention Networks for Learning on Large and Spatiotemporal Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiani</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjian</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Fourth Conference on Uncertainty in Artificial Intelligence, UAI 2018</title>
		<meeting>the Thirty-Fourth Conference on Uncertainty in Artificial Intelligence, UAI 2018<address><addrLine>Monterey, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-08-06" />
			<biblScope unit="page" from="339" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan. 2020. Spatio-temporal graph structure learning for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1177" to="1185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Gman: A graph multi-attention network for traffic prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanpan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhong</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1234" to="1241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Urban computing: concepts, methodologies, and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Licia</forename><surname>Capra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ouri</forename><surname>Wolfson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology (TIST)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="55" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieqi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wancai</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021</title>
		<imprint>
			<date type="published" when="2021-02-02" />
			<biblScope unit="page" from="11106" to="11115" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
