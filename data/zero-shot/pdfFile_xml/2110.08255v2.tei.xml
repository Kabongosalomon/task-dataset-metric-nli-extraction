<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">U-Net Inspired Transformer Architecture for Far Horizon Time Series Forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiran</forename><surname>Madhusudhanan</surname></persName>
							<email>madhusudhanan@ismll.uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Computer Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Burchert</surname></persName>
							<email>burchert@ismll.uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Computer Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nghia</forename><surname>Duong-Trung</surname></persName>
							<email>nghia.duong-trung@tu-berlin.de</email>
							<affiliation key="aff1">
								<orgName type="institution">Technische Universit?t Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Born</surname></persName>
							<email>born@math.tu-berlin.de</email>
							<affiliation key="aff1">
								<orgName type="institution">Technische Universit?t Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
							<email>schmidt-thieme@ismll.uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Computer Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">U-Net Inspired Transformer Architecture for Far Horizon Time Series Forecasting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Time series Forecasting ? Transformer ? U-Net</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Time series data is ubiquitous in research as well as in a wide variety of industrial applications. Effectively analyzing the available historical data and providing insights into the far future allows us to make effective decisions. Recent research has witnessed the superior performance of transformer-based architectures, especially in the regime of far horizon time series forecasting. However, the current state of the art sparse Transformer architectures fail to couple down-and upsampling procedures to produce outputs in a similar resolution as the input. We propose a U-Net inspired Transformer architecture named Yformer, based on a novel Y-shaped encoder-decoder architecture that (1) uses direct connection from the downscaled encoder layer to the corresponding upsampled decoder layer in a U-Net inspired architecture, (2) Combines the downscaling/upsampling with sparse attention to capture long-range effects, and (3) stabilizes the encoder-decoder stacks with the addition of an auxiliary reconstruction loss. Extensive experiments have been conducted with relevant baselines on three benchmark datasets, demonstrating an average improvement of 19.82, 18.41 percentage MSE and 13.62, 11.85 percentage MAE in comparison to the baselines for the univariate and the multivariate settings respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the most simple case, time series forecasting deals with a scalar time-varying signal and aims to predict or forecast its values in the near future; for example, countless applications in finance, healthcare, production automatization, etc. <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29]</ref> can benefit from an accurate forecasting solution. Often not just a single scalar signal is of interest, but multiple at once, and further time-varying signals are available and even known for the future. For example, suppose one aims to forecast the energy consumption of a house, it likely depends on the social time that one seeks to forecast for (such as the next hour or day), and also on features of these time points (such as weekday, daylight, etc.), which are arXiv:2110.08255v2 <ref type="bibr">[cs.</ref>LG] 25 Aug 2022 known already for the future. This is also the case in model predictive control <ref type="bibr" target="#b2">[3]</ref>, where one is interested to forecast the expected value realized by some planned action, then this action is also known at the time of forecast. More generally, time series forecasting, nowadays deals with quadruples (x, y, x , y ) of known past predictors x, known past targets y, known future predictors x and sought future targets y . <ref type="figure">Fig. 1</ref>: General time series setting illustrating the quadruples (x, y, x , y ) denoting the past predictors, past targets, future predictors and future targets respectively. Given the history information (x, y) until time t = T and the future predictors (x ) for the next ? time steps, time series forecasting predicts the target y from t = T + 1, . . . , ? time steps. In the figure, O and M represents the respective channels of the targets and the predictors.</p><p>Time series problems can often be addressed by methods developed initially for images, treating them as 1-dimensional images. Especially for time-series classification many typical time series encoder architectures have been adapted from models for images <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b36">37]</ref>. Time series forecasting then is closely related to image outpainting <ref type="bibr" target="#b31">[32]</ref>, the task to predict how an image likely extends to the left, right, top or bottom, as well as to the more well-known task of image segmentation, where for each input pixel, an output pixel has to be predicted, whose channels encode pixel-wise classes such as vehicle, road, pedestrian say for road scenes. Time series forecasting combines aspects from both problem settings: information about targets from shifted positions (e.g., the past targets y as in image outpainting) and information about other channels from the same positions (e.g., the future predictors x as in image segmentation). One of the most successful, principled architectures for the image segmentation task are U-Nets introduced in <ref type="bibr" target="#b25">[26]</ref>, an architecture that successively downsamples/coarsens its inputs and then upsamples/refines the latent representation with deconvolutions also using the latent representations of the same detail level, tightly coupling down-and upsampling procedures and thus yielding latent features on the same resolution as the inputs.</p><p>Following the great success in Natural Language Processing (NLP) applications, attention-based, esp. transformer-based architectures <ref type="bibr" target="#b29">[30]</ref> that model pairwise interactions between sequence elements have been recently adapted for time series forecasting. One of the significant challenges, is that the length of the time series, are often one or two magnitudes of order larger than the (sentencelevel) NLP problems.</p><p>Plenty of approaches aim to mitigate the quadratic complexity O(T 2 ) in the sequence/time series length T to at most O(T log T ). For example, the Informer architecture <ref type="bibr" target="#b34">[35]</ref>, adapts the transformer with a sparse attention mechanism and a successive downsampling/coarsening of the past time series. As in the original transformer, only the coarsest representation is fed into the decoder. Possibly to remedy the loss in resolution by this procedure, the Informer feeds its input a second time into the decoder network, this time without any coarsening.</p><p>While forecasting problems share many commonalities with image segmentation problems, transformer-based architectures like the Informer do not involve coupled down-and upscaling procedures to yield predictions on the same resolution as the inputs. Thus, we propose a novel Y-shaped architecture that 1. Couples downscaling/upscaling to leverage both, coarse and fine-grained features for time series forecasting, 2. Combines the coupled scaling mechanism with sparse attention modules to capture long-range effects on all scale levels, and 3. Stabilizes encoder and decoder stacks by reconstructing the recent past.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Time Series Forecasting: While Convolutional Neural Network (CNN) and Recurrent Neural network (RNN) based architectures <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b27">28]</ref> outperform traditional methods like ARIMA <ref type="bibr" target="#b1">[2]</ref> and exponential smoothing methods <ref type="bibr" target="#b9">[10]</ref>, the addition of attention layers <ref type="bibr" target="#b29">[30]</ref> to model time series forecasting has proven to be very beneficial across different problem settings <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b33">34]</ref>. Attention allows direct pair-wise interaction with eccentric events (like holidays) and can model temporal dynamics inherently unlike RNNs and CNNs that fail to capture longrange dependencies directly. Recent work like Reformer <ref type="bibr" target="#b13">[14]</ref>, Linformer, <ref type="bibr" target="#b30">[31]</ref>, Triformer <ref type="bibr" target="#b4">[5]</ref> and Informer <ref type="bibr" target="#b34">[35]</ref> have focused on reducing the quadratic complexity of modeling pair-wise interactions to a lower complexity with the introduction of restricted attention layers. Consequently, they can predict for longer forecasting horizons but are hindered by their capability of aggregating features and maintaining the resolution required for far horizon forecasting.</p><p>U-Net: The Yformer model is inspired by the famous U-Net architecture introduced in <ref type="bibr" target="#b25">[26]</ref> originating from the field of medical image segmentation. The U-net architecture is capable of compressing information by aggregating over the inputs and up-sampling embeddings to the same resolutions as that of the inputs from their compressed latent features. While there exist U-Net based transformer architectures within the vision community <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b35">36]</ref>, to the best of our knowledge U-Net based transformer architecture for time series forecasting remains unexplored. Current transformer architectures like the Informer <ref type="bibr" target="#b34">[35]</ref> do not utilize up-sampling techniques even though the network produces intermediate multi-resolution feature maps. Our work aims to capitalize on these multi-resolution feature maps and use the U-net shape effectively for the task of time series forecasting. In <ref type="bibr" target="#b21">[22]</ref>, the authors have successfully applied U-Net architecture for the task of time series segmentation, illustrating superior results in the task. These motivate the use of a U-Net-inspired architecture for time series forecasting as current methods fail to couple sparse attention mechanism with the U-Net shaped architecture for time series forecasting.</p><p>Reconstruction Loss: Reconstruction loss is widely used in the domain of time series outlier detection <ref type="bibr" target="#b12">[13]</ref> and is less popular within the Time Series Forecasting community. Although recent time series forecasting architecture like the N-Beats <ref type="bibr" target="#b20">[21]</ref> tries to reconstruct part of the past time steps (backcasting) as an effective method to improve model performance, the majority of transformerbased time series forecasting architectures <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b18">19]</ref> fail to utilize the reconstruction loss as an auxiliary target to improve performance. In <ref type="bibr" target="#b11">[12]</ref>, the authors demonstrate a multi-task approach for time series forecasting that couples an auxiliary task of predicting known channels along with the target channel for improved regularization. Additionally, recent studies <ref type="bibr" target="#b16">[17]</ref> have shown that the addition of the reconstruction term to any loss function generally provides uniform stability and bounds on the generalization error, therefore leading to a more robust model overall with no negative effect on the performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>The loss usually is the mean absolute error (MAE) or mean squared error (MSE) averaged over future time points:</p><formula xml:id="formula_1">mae (y ,?) := 1 |y | |y | t=1 1 O ||y t ?? t || 1 , mse (y ,?) := 1 |y | |y | t=1 1 O ||y t ?? t || 2 2<label>(2)</label></formula><p>Furthermore, if there is only one target channel and no predictor channels (O = 1, M = 0), the time series forecasting problem is called univariate, otherwise multivariate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Background</head><p>Our work incorporates restricted attention based Transformer in a U-Net inspired architecture. For this reason, we base our work on the current state of the art sparse attention model Informer, introduced in <ref type="bibr" target="#b34">[35]</ref>. We provide a brief overview of the ProbSparse attention and the Contracting ProbSparse Self-Attention Blocks used in the Informer model for completeness.</p><p>ProbSparse Attention: The ProbSparse attention mechanism restricts the canonical attention <ref type="bibr" target="#b29">[30]</ref> by selecting a subset u of dominant queries from available sequence length L Q having the largest variance across all the keys. Consequently, the dense query matrix Q ? R L Q ?d in the canonical attention is replaced by a sparse query matrix Q ? R L Q ?d consisting of the u dominant queries. Prob-Sparse attention can hence be defined as:</p><formula xml:id="formula_2">A PropSparse (Q, K, V ) = Softmax( QK T ? d )V<label>(3)</label></formula><p>where d denotes the input dimension to the attention module. For more details on the ProbSparse attention mechanism, we refer the reader to <ref type="bibr" target="#b34">[35]</ref>.</p><p>Contracting ProbSparse Self-Attention Blocks: The Informer model uses Contracting ProbSparse Self-Attention Blocks to distill out redundant information from the long history input sequence (x, y) in a pyramid structure motivated from the image domain <ref type="bibr" target="#b19">[20]</ref>. The sequence of operations within a block begins with a ProbSparse self-attention that takes as input the hidden representation h i from the i th block and projects the hidden representation into query, key and value for self-attention. This is followed by convolution operations (Conv1d) <ref type="bibr" target="#b14">[15]</ref>, and finally the Max-Pooling (MaxPool) <ref type="bibr" target="#b14">[15]</ref> operation reduces the latent dimension by effectively distilling out redundant information at each block as summarized in Algorithm 1. Here, ELU represents the ELU activation function <ref type="bibr" target="#b5">[6]</ref> and LayerNorm is the Layer Normalization operation <ref type="bibr" target="#b0">[1]</ref>. The encoder block in the Informer model <ref type="bibr" target="#b34">[35]</ref> stacks multiple Contracting ProbSparse Self-Attention Block blocks and produce multi-resolution encoder embeddings following a pyramid structure. The Yformer model is a Y-shaped symmetric encoder-decoder architecture that is specifically designed to take advantage of the multi-resolution embeddings generated by the Contracting ProbSparse Self-Attention Blocks. The fundamental design consideration is the adoption of U-Net-inspired connections to extract encoder features at multiple resolutions and provide a direct connection to the corresponding symmetric decoder block. The Yformer additionally utilizes reconstruction loss to learn generalized embeddings that better approximate the data generating distribution. <ref type="figure" target="#fig_1">Figures 2a and 2b</ref> compares the Informer architecture with the Yformer and <ref type="figure" target="#fig_2">Figure 3</ref> illustrates the U-Net connections employed by the Yformer model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Contracting ProbSparse Self-Attention Block</head><formula xml:id="formula_3">Input : hi Output : hi+1 hi+1 ? ProbSparseAttn(hi, hi) hi+1 ? Conv1d(hi+1) hi+1 ? LayerNorm(hi+1) hi+1 ? MaxPool(ELU(Conv1d(hi+1))) 5 Methodology (a) Informer Architecture (b) Yformer Architecture</formula><p>The Y-Past Encoder of the Yformer is designed using a similar encoder structure as that of the Informer <ref type="figure" target="#fig_1">(Figure 2a</ref>). The Y-Past Encoder embeds the past sequence (x, y) into a scalar projection along with the addition of positional and temporal embeddings. Multiple Contracting ProbSparse Self-Attention Blocks are used to generate encoder embeddings at various resolutions following a contracting pyramid structure. The Informer model uses the final lowdimensional embedding as the input to the decoder whereas, the Yformer retains the embeddings at multiple resolutions to be passed on to the decoder. This allows the Yformer to use high-dimensional lower-level embeddings effectively.</p><p>The Y-Future Encoder of the Yformer mitigates the redundant reprocessing of the past sequence (x, y) (used as tokens (x token , y token ) in the Informer architecture) by passing only the future predictors (x ) through the Y-Future Encoder and utilizing the multi-resolution embeddings to dismiss the need for tokens entirely. The attention blocks in the Y-Future encoder are based on a masked canonical self-attention mechanism <ref type="bibr" target="#b29">[30]</ref> to prevent any information leak from the future time steps into the past. Thus, the Y-Future Encoder is designed by stacking multiple Contracting ProbSparse Self-Attention Blocks where the ProbSparse attention is replaced by the Masked Attention. We name these blocks Contracting Masked Self-Attention Blocks.</p><p>The Yformer processes the past inputs and the future predictors separately within its encoders. However, considering the time steps, the future predictors are a continuation of the past time steps. For this reason, the Yformer model concatenates ( represented by the symbol + + ) the past encoder embedding and the future encoder embedding along the time dimension after each encoder block, preserving the continuity between the past input time steps and the future time steps. Let i represent the index of an encoder block, then e past i+1 and e fut i+1 represent the output from the past encoder and the future encoder respectively. The final concatenated encoder embedding (e i+1 ) is calculated as,</p><formula xml:id="formula_4">e past i+1 = ContractingProbSparseSelfAttentionBlock(e past i ) e fut i+1 = ContractingMaskedSelfAttentionBlock(e fut i ) e i+1 = e past i+1 + + e fut i+1<label>(4)</label></formula><p>The encoder embeddings represented by E = [e 0 , . . . , e I ] (where I is the number of encoder layers) contain the combination of past and future embeddings at multiple resolutions. The Y-Decoder of the Yformer consists of two parts. The first part takes as input the final concatenated low-dimensional embedding (e I ) of the encoders and performs a multi-head canonical self-attention mechanism. Since the canonical self-attention layer is separated from the repeating attention blocks within the decoder, the Yformer complexity from this full attention module does not increase with an increase in the number of decoder blocks. The U-Net architecture inspires the second part of the Y-Decoder. Consequently, the decoder is structured in a symmetric expanding path identical to the contracting encoder ( <ref type="figure" target="#fig_2">Figure 3</ref>). We realize this idea by introducing Expanding ProbSparse Cross-Attention Block for symmetric upsampling. The Expanding ProbSparse Cross-Attention Block within the Yformer decoder performs two tasks: (1) upsample the compressed encoder embedding e I and (2) perform restricted cross attention between the expanding decoder embedding d I?i and the corresponding encoder embedding e i as shown below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Expanding ProbSparse Cross-Attention Block</head><formula xml:id="formula_5">Input : dI?i, ei Output : dI?i+1 dI?i+1 ? ProbSparseCrossAttn(dI?i, ei) dI?i+1 ? Conv1d(dI?i+1) dI?i+1 ? LayerNorm(dI?i+1) dI?i+1 ? ELU(ConvTranspose1d(dI?i+1)))</formula><p>The Expanding ProbSparse Cross-Attention Blocks within the Yformer decoder uses a ProbSparseCrossAttn to construct direct connections between the lower levels of the encoder and the corresponding symmetric higher levels of the decoder. Direct connections from the encoder to the decoder are an essential component for the majority of models within the image domain. For example, ResNet <ref type="bibr" target="#b7">[8]</ref>, and DenseNet <ref type="bibr" target="#b8">[9]</ref> have demonstrated that direct connections between previous feature maps, strengthen feature propagation, reduce parameters, mitigate vanishing gradients and encourage feature reuse. However, current transformer-based architectures fail to utilize these direct connections.</p><p>We utilize ConvTranspose1d or popularly known as Deconvolution for incrementally increasing the embedding space. The famous U-Net architecture uses a symmetric expanding path using such Deconvolution layers. This property enables the model to not only aggregate over the input but also upscale the latent dimensions, improving the overall expressivity of the architecture. The decoder of Yformer follows a similar strategy by employing Deconvolution to expand the embedding space of the encoded output as shown in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>Finally, a fully connected layer (LinearLayer) predicts the future time step? y fut from the final decoder layer (d I ) and additionally reconstructs the past input targets? past for the reconstruction auxiliary loss.</p><p>[? past ,? fut ] = LinearLayer(d I )</p><p>The addition of reconstruction loss to the Yformer as an auxiliary loss serves two significant purposes. Firstly, the reconstruction loss acts as a data-dependent regularization term that reduces overfitting by learning embeddings that are more general <ref type="bibr" target="#b10">[11]</ref>. Secondly, the reconstruction loss helps in producing future output in a similar distribution as the inputs. For far horizon forecasting, we are interested in learning a future-output distribution, however, the future-output distribution and the past-input distribution arise from the same data generating process. Therefore having an auxiliary reconstruction loss would direct the gradients to a better approximate of the data generating process. Consequently, the Yformer model is trained on the combined loss ,</p><formula xml:id="formula_7">= ? mse (y,? past ) + (1 ? ?) mse (y ,? fut )<label>(6)</label></formula><p>where the first term tries to learn the past targets y and the second term learns the future targets y . We use the reconstruction factor (?) to vary the importance of reconstruction and future prediction and tune this as a hyperparameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>We compare the experimental results of our proposed YFormer architecture, with that of the Informer on three real-world public datasets. ETTh1 and ETTh2 (Electricity Transformer Temperature 3 ): These realworld datasets for the electric power deployment introduced by [35] combine short-term periodical patterns, long-term periodical patterns, long-term trends, and irregular patterns. The data consists of load and temperature readings from two transformers at two different stations with varying load conditions. The ETTm1 dataset is generated by splitting ETTh1 dataset into 15-minute intervals. The dataset has six features and 70,080 data points in total. For easy comparison, we kept the splits for train/val/test consistent with the published results in <ref type="bibr" target="#b34">[35]</ref>, where the available 20 months of data is split as 12/4/4. For the Univariate setting, 'OT' (Oil Temperature) was set as the target value.</p><p>ECL (Electricity Consuming Load 4 ): This electricity dataset represents the electricity consumption from 2011 to 2014 of 370 clients recorded in 15-minutes periods in Kilowatt (kW). We split the data into 15/3/4 months for train, validation, and test respectively as in <ref type="bibr" target="#b34">[35]</ref>. For the Univariate setting, 'MT 320' was set as the target value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental Setup</head><p>Baseline: Our main baseline is the Informer architecture. As a second baseline, we also compare the second-best performing model which is the Informer that uses canonical attention module <ref type="bibr" target="#b34">[35]</ref> represented as Informer ? . Furthermore, we also compare against DeepAR <ref type="bibr" target="#b27">[28]</ref>, and LogTrans <ref type="bibr" target="#b17">[18]</ref> for the univariate setting, and LSTnet <ref type="bibr" target="#b15">[16]</ref> for the multivariate setting as they outperform the Informer baseline for certain forecasting horizons. For a quick analysis, we present the percent improvement achieved by the Yformer over the current best results as the final column in <ref type="table" target="#tab_0">Tables 1, 2.</ref> For a fair comparison, we retain the design choices from the Informer baseline like the history input length (T ) for a particular forecast length (? ), so that any performance improvement can exclusively be attributed to the architecture of the Yformer model and not to an increased history input length. We performed a grid search for learning rates of {0.001, 0.0001}, ?-values of {0, 0.3, 0.5, 0.7, 1}, number of encoder and decoder blocks I = {2, 3, 4} while keeping all the other hyperparameters the same as the Informer. Furthermore, Adam optimizer and an early stopping criterion with a patience of three epochs was used for all experiments. To counteract overfitting, we tried dropout with varying ratios but interestingly found the effect to be minimal in the results. Therefore, we adopt weight-decay for our experiments with factors {0, 0.02, 0.05} for additional regularization. We select the optimal hyperparameters based on the lowest validation loss.</p><p>For easy comparison, we choose two commonly used metrics for time series forecasting to evaluate the Yformer architecture, the MAE and MSE in Equation 2. We performed our experiments on GeForce RTX 2080 Ti GPU nodes with 32 GB ram and provide results as an average of three runs. The source code 5 and optimal hyperparameter configurations are made public for reproducibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results and Analysis</head><p>This section compares our results with the results reported in the Informer baseline both in uni-and multivariate settings for the multiple datasets and horizons. A direct comparison with the reported results <ref type="bibr" target="#b34">[35]</ref> is possible as the experimental setup and the problem settings are kept the same. The best-performing and the second-best models are highlighted in bold and in underline, respectively.  Univariate: The proposed Yformer model is able to outperform the Informer baseline in 37 out of the 40 available tasks across different datasets and horizons by an average of 19.82% MSE and 13.62 % of MAE. <ref type="table" target="#tab_0">Table 1</ref> illustrates that the superiority of the Yformer is not just limited to a far horizon but even for the shorter horizons and in general across datasets. Considering the individual datasets, the Yformer surpasses the baselines by 8, 6.8, 21.9, and 18.1% of MAE for the ETTh1, ETTh2, ETTm1, and ECL datasets respectively. MSE results illustrates an improvement of <ref type="bibr">16.7, 12.6, 34.8, and 15</ref>.2% for the ETTh1, ETTh2, ETTm1, and ECL datasets respectively. We observe that the MAE for the model is greater at horizon 48 than the MAE at horizon 168 for the ETTh1 dataset. This may be a case where the reused hyperparameters from the Informer paper are far from optimal for the Yformer. The other results show consistent behavior of increasing error with increasing horizon length ? . Additionally, this behavior is also observed in the Informer baseline for ETTh2 dataset <ref type="table" target="#tab_1">(Table 2)</ref>, where the loss is 1.340 for horizon 336 and 1.515 for a horizon of 168.</p><p>Multivariate: We observe a similar trend in the multivariate setting. Here the Yformer model outperforms the baseline method in almost all of the 40 tasks across the three datasets by a margin of 18.41 % MSE and 11.85% of MAE. There is a clear superiority of the proposed approach, especially for the longer horizons. Across the different datasets, the Yformer improves on the baseline results by 9, 13.5, 13.1, and 11.7% of MAE, and 12, 26.3, 13.9, and 17.1% of  MSE for the ETTh1, ETTh2, ETTm1, and ECL datasets respectively. We attribute the improvement in performance to superior architecture and the ability to approximate the data distribution due to the addition of auxiliary loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Ablation study</head><p>Additional experiments were performed on the ETTm1 datasets to analyze the different components of the Yformer model. Similar ablation experiment results for ETTh2 dataset are reported in the Appendix section for reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Y-former architecture</head><p>In this section, we attempt to understand (1) the improvement brought about by the Y-shaped model architecture, and (2) the impact of the reconstruction loss on the superiority of the Yformer model. Firstly, <ref type="figure" target="#fig_6">Figure 5c compares</ref>   Moreover, for the larger horizons, the Yformer architecture without the reconstruction loss i.e. ? = 0, has a clear advantage over the Informer baseline. We attribute this improvement in performance to the additional direct U-Net inspired connections within the Yformer architecture. Using feature maps at multiple resolutions offers a clear advantage by eliminating vanishing gradients and encouraging feature reuse. <ref type="figure" target="#fig_5">Figures 4a, 4b</ref> also clearly delineates the advantage offered by adding reconstruction loss as an auxiliary task for the model, by comparing Yformer with Yformer (? = 0) results. Such a multi-task approach offers regularization to the model by learning parameters that do not overfit on the future target distribution and propels the gradients towards a general distribution that can predict the history along with the future time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Effectiveness of the U-Net based skip connections</head><p>To analyze the impact of U-Net based skip-connections, we conduct an ablation study on the Y-former architecture by removing the U-Net skip connections from the encoder to the decoder. We denote this model as Yformer * <ref type="figure" target="#fig_5">. Figures 4c, 4d</ref> provides a summary of the results obtained after hyperparameter tuning the Yformer * and comparing it with the proposed Yformer model. The skip connections from the encoder to the decoder improve the performance throughout the entire horizon range for the multivariate setting and offers partial improvement for the univariate setting. Within the multivariate setting, the skip connections have a considerable impact on larger horizons and a smaller impact on the shorter horizons. This observation can be reasoned by considering the fact that long-range forecasting can utilize the additional multi-resolution encoder feature maps encoded by the U-Net based skip connections. Similar reason can be applied to the fact that U-Net based skip connections improve the performance of the multivariate setting more than that of the univariate settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Reconstruction Factor</head><p>How impactful is the reconstruction factor ? from the proposed loss in Eq. 6?</p><p>We aggregated the optimal value chosen by hyperparameter tuning ? across different datasets and summarized the distribution in <ref type="figure" target="#fig_6">Figures 5a and 5b</ref>. Interestingly, ? value of 0.7 is the predominant optimal setting across most horizons. Consequently, this shows that a high weight for the reconstruction loss helps the Yformer to achieve a lower loss for the future targets. Moreover, we can observe a trend that ? is on average larger for short forecasting horizons signifying the importance of auxiliary loss for the shorter horizons. One possible reason could be that the reconstruction loss generalizes the output distribution better and avoids overfitting on short-horizon lengths. For the longer horizon forecasts, optimal ? values are distributed on the lower and upper range of ?'s evenly, indicating that for long horizons, the reconstruction loss from long history helps for some datasets and does not for other datasets. This could be a characteristic of the dataset having a domain shift within the forecast horizon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>Time series forecasting is an important business and research problem that has a broad impact in today's world. This paper proposes a novel Y-shaped archi-tecture, specifically designed for the far horizon time series forecasting problem.</p><p>The study shows the importance of direct connections from the multi-resolution encoder to the decoder and reconstruction loss for the task of time series forecasting. The Yformer couples the U-Net architecture from the image segmentation domain on a sparse transformer model and empirically demonstrates superior performance across multiple datasets for both univariate and multivariate settings. We believe that our work provides a base for future research in the direction of using efficient U-Net based skip connections and the use of reconstruction loss as an auxiliary loss within the time series forecasting community.  <ref type="figure">Fig. 7</ref>: Impact of the U-Net connection for the Yformer architecture. The Yformer * architecture represents the Yformer without the U-Net connection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Performance variability analysis</head><p>We report the standard deviation values from the multiple Yformer runs for the ETTh2 dataset and compare them with the numbers reported from the Informer baseline <ref type="bibr" target="#b34">[35]</ref>. The standard deviation values are quite small across the three runs of the Yformer with multiple initial seed settings illustrating the stability of Yformer across the multiple horizons. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Appendix: Operators</head><p>ProbSparseAttn: Attention module that uses the ProbSparse method introduced in <ref type="bibr" target="#b34">[35]</ref>. The query matrix Q ? R L Q ?d denotes the sparse query matrix with u dominant queries.</p><formula xml:id="formula_8">A PropSparse (Q, K, V ) = Softmax( QK T ? d )V<label>(7)</label></formula><p>MaskedAttn: Canonical self-attention with masking to prevent positions from attending to subsequent positions in the future <ref type="bibr" target="#b29">[30]</ref>. </p><p>For further reference please visit pytorch MaxPool1D page ELU: Given an input x, the ELU applies element-wise non linear activation function as shown.</p><formula xml:id="formula_10">ELU(x) = x, if x &gt; 0 ? * (exp(x) ? 1), if x ? 0<label>(11)</label></formula><p>ConvTranspose1d: Also known as deconvolution or fractionally strided convolution, uses convolution on padded input to produce upsampled outputs (see pytorch ConvTranspose1d page).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Appendix : Hyperparameters</head><p>We follow Informer <ref type="bibr" target="#b34">[35]</ref> baseline for all the hyperparameter setting like the convolution kernel size, stride etc. The hyperparameter tuning performed are only for the parameters mentioned below. In order to reproduce the experiments, please use the default Informer/Yformer configurations and adapt only the below mentioned parameters for each horizon.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>By a time series x with M channels, we mean a finite sequence of vectors in R M , denote their space by R * ?M := T ?N R T ?M , and their length by |x| := T (for x ? R T ?M , M ? N). We write (x, y) ? R * ?(M +O) to denote two time series of same length with M and O channels for the predictors and targets, respectively. We model a time series forecasting instance as a quadruple (x, y, x , y ) ? R * ?(M +O) ? R * ?(M +O) , where x, y denote the past predictors and targets until a reference time point T and x , y denote the future predictors and targets from the reference point T to the next ? (forecast horizon) time steps. For a Time Series Forecasting Problem, given (i) a sample D := { (x 1 , y 1 , x 1 , y 1 ), . . . , (x N , y N , x N , y N )} from an unknown distribution p of time series forecasting instances and (ii) a function : R * ?(O+O) ? R called loss, we attempt to find a function? : R * ?(M +O) ? R * ?M ? R * ?O (with |?(x, y, x )| = |x |) with minimal expected loss E (x,y,x ,y )?p (y ,?(x, y, x ))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Comparison of Informer and Yformer architecture highlighting the three key differences. (1) The Informer architecture process part of the past input data (x, y) within the decoder as (x token , y token ) along with the future predictors (x ). The Yformer avoids this redundant reprocessing of (x, y) and uses a masked self-attention network for embedding the only the future predictors (x ). (2) The Informer uses the final encoder embedding as the input to the decoder. The Yformer passes a concatenated ( + + ) representation (e i ) of the i th Y-Past and Y-Future Encoder embedding to the I ? i th layer of the Y-Decoder, forming a U-Net connection (represented in red) between the encoder and the decoder. (3) The Yformer architecture predicts both the input reconstruction? past and future predictions? fut .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>U-Net connections for effectively utilizing embeddings at multiple resolutions in the Yformer. The Y-Past Encoder embeddings and the Y-Future Encoder embeddings are concatenated within the Yformer encoder. A direct connection is allowed between the contracting encoder embedding (e i ) and the corresponding expanding decoder embedding (d I?i ). (+ + denotes concatenation)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>ETTh1 24 0</head><label>24</label><figDesc>.082 0.230 0.098 0.247 0.092 0.246 0.103 0.259 0.107 0.280 10.87 6.50 48 0.139 0.308 0.158 0.319 0.161 0.322 0.167 0.328 0.162 0.327 12.03 3.45 168 0.111 0.268 0.183 0.346 0.187 0.355 0.207 0.375 0.239 0.422 39.34 22.54 336 0.195 0.365 0.222 0.387 0.215 0.369 0.230 0.398 0.445 0.552 9.30 1.08 720 0.226 0.394 0.269 0.435 0.257 0.421 0.273 0.463 0.658 0.707 12.06 6.41 ETTh2 24 0.082 0.221 0.093 0.240 0.099 0.241 0.102 0.255 0.098 0.263 11.83 7.92 48 0.172 0.334 0.155 0.314 0.159 0.317 0.169 0.348 0.163 0.341 ?10.97 ?6.37 168 0.174 0.337 0.232 0.389 0.235 0.390 0.246 0.422 0.255 0.414 25.00 13.37 336 0.224 0.391 0.263 0.417 0.258 0.423 0.267 0.437 0.604 0.607 13.18 6.24 720 0.211 0.382 0.277 0.431 0.285 0.442 0.303 0.493 0.429 0.580 23.83 11.37 ETTm1 24 0.024 0.118 0.030 0.137 0.034 0.160 0.065 0.202 0.091 0.243 20.00 13.87 48 0.048 0.173 0.069 0.203 0.066 0.194 0.078 0.220 0.219 0.362 27.27 10.82 96 0.143 0.311 0.194 0.372 0.187 0.384 0.199 0.386 0.364 0.496 23.53 16.40 288 0.150 0.316 0.401 0.554 0.409 0.548 0.411 0.572 0.948 0.795 62.59 42.34 672 0.305 0.476 0.512 0.644 0.519 0.665 0.598 0.702 2.437 1.352 40.43 26.09 ECL 48 0.194 0.322 0.239 0.359 0.238 0.368 0.280 0.429 0.204 0.357 4.90 9.80 168 0.260 0.361 0.447 0.503 0.442 0.514 0.454 0.529 0.315 0.436 17.46 17.20 336 0.269 0.375 0.489 0.528 0.501 0.552 0.514 0.563 0.414 0.519 35.02 27.75 720 0.427 0.479 0.540 0.571 0.543 0.578 4.891 4.047 0.563 0.595 20.93 19.50 960 0.595 0.573 0.582 0.608 0.594 0.638 7.019 5.105 0.657 0.683 ?2.23 16</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>ECL 48 0.306 0.390 0.344 0.393 0.334 0.399 0.355 0.418 0.369 0.445 8.38 0.76 168 0.317 0.387 0.368 0.424 0.353 0.420 0.368 0.432 0.394 0.476 10.20 7.86 336 0.323 0.394 0.381 0.431 0.381 0.439 0.373 0.439 0.419 0.477 15.22 8.58 720 0.312 0.384 0.406 0.443 0.391 0.438 0.409 0.454 0.556 0.565 20.20 12.33 960 0.315 0.388 0.460 0.548 0.492 0.550 0.477 0.589 0.605 0.599 31.52 29.20</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 :</head><label>4</label><figDesc>(top) Figures 4a, 4b illustrates the reduction in MAE loss (y-axis) by the Yformer architecture in comparison with the Informer baseline for the univariate and multivariate settings respectively. The Yformer (? = 0) represent the Yformer architecture without the reconstruction loss. (bottom) Figures 4c, 4d demonstrate the reduction in MAE loss (y-axis) brought by the addition of U-Net based skip connections (Yformer) to the Yformer architecture without the skip connections (Yformer * ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>(Fig. 5 :</head><label>5</label><figDesc>a) best ?'s for Univariate (b) best ?'s for Multivariate (c) Model complexity Figures 5a and 5b illustrates the distribution of selected Reconstruction factor (y-axis) across the multiple horizons (x-axis). Figure 5c, compares the model size complexity (y-axis) for the multivariate setting across the multiple horizons (x-axis) for the Informer and the Yformer model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>8 ) 9 )</head><label>89</label><figDesc>Conv1d: Given N batches of 1D array of length L and C number of channels/dimensions. A convolution operation produces an output: out(N i , C outj ) = bias(C outj ) + Cin?1 k=0 weight(C outj , k) input(N i , k) (For further reference please visit pytorch Conv1D page LayerNorm: Layer Normalization introduced in [1], normalizes the inputs across channels/dimensions. LayerNorm is the default normalization in common transformer architectures [30]. Here, ? and ? are learnable affine transformations. out(N, * ) = input(N, * ) ? E[input(N, * )] Var[input(N, * )] + * ? + ? (MaxPool: Given N batches of 1D array of length L, and C number of channels/dimensions. A MaxPool operation produces an output. out(N i , C j , k) = max m=0,...,kernel_size?1 input(N i , C j , stride ? k + m)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Univariate results for three datasets (four cases) with different prediction lengths ? ? {24, 48, 96, 168, 288, 336, 672, 720, 960}.</figDesc><table><row><cell>Methods</cell><cell>Yformer</cell><cell>Informer</cell><cell>Informer  ?</cell><cell>LogTrans</cell><cell>DeepAR Improvement%</cell></row><row><cell cols="6">Metric MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Multivariate results for three datasets (four cases) with different prediction lengths ? ? {24, 48, 96, 168, 288, 336, 672, 720, 960}.</figDesc><table><row><cell cols="2">Methods Yformer</cell><cell>Informer Informer  ? LogTrans</cell><cell>LSTnet Improvement%</cell></row><row><cell cols="4">Metric MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE</cell></row><row><cell>ETTh1</cell><cell cols="3">24 0.485 0.492 0.577 0.549 0.620 0.577 0.686 0.604 1.293 0.901 15.94 10.38 48 0.530 0.537 0.685 0.625 0.692 0.671 0.766 0.757 1.456 0.960 22.63 14.08 168 0.866 0.684 0.931 0.752 0.947 0.797 1.002 0.846 1.997 1.214 6.98 9.04 1.23 336 1.041 0.803 1.128 0.873 1.094 0.813 1.362 0.952 2.655 1.369 4.84 720 1.098 0.803 1.215 0.896 1.241 0.917 1.397 1.291 2.143 1.380 9.63 10.38</cell></row><row><cell>ETTh2</cell><cell cols="3">24 0.412 0.498 0.720 0.665 0.753 0.727 0.828 0.750 2.742 1.457 42.78 25.11 48 1.171 0.865 1.457 1.001 1.461 1.077 1.806 1.034 3.567 1.687 19.63 13.59 168 2.171 1.218 3.489 1.515 3.485 1.612 4.070 1.681 3.242 2.513 33.04 19.60 336 2.260 1.283 2.723 1.340 2.626 1.285 3.875 1.763 2.544 2.591 11.16 0.16 720 2.595 1.337 3.467 1.473 3.548 1.495 3.913 1.552 4.625 3.709 25.15 9.23</cell></row><row><cell>ETTm1</cell><cell cols="3">24 0.289 0.363 0.323 0.369 0.306 0.371 0.419 0.412 1.968 1.170 5.56 48 0.486 0.457 0.494 0.503 0.465 0.470 0.507 0.583 1.999 1.215 ?4.52 96 0.569 0.567 0.678 0.614 0.681 0.612 0.768 0.792 2.762 1.542 16.08 288 0.649 0.593 1.056 0.786 1.162 0.879 1.462 1.320 1.257 2.076 38.54 24.55 1.63 2.77 7.35 672 0.772 0.656 1.192 0.926 1.231 1.103 1.669 1.461 1.917 2.941 35.23 29.16</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>the model complexity for the proposed Yformer model with the Informer baseline model and demonstrates the advantage offered by the Yformer model for longer horizons. Secondly, Figures 4a, 4b, show that the Yformer architecture performs better or is comparable to the Informer throughout the entire horizon range.</figDesc><table><row><cell>(a) ETTm1 Univariate</cell><cell>(b) ETTm1 Multivariate</cell></row><row><cell>(c) ETTm1 Univariate</cell><cell>(d) ETTm1 Multivariate</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparison of Yformer model with the second best performing Informer model for performance variability analysis. ? 0.004 0.172 ? 0.016 0.174 ? 0.009 0.224 ? 0.038 0.211 ? 0.005 MAE 0.221 ? 0.006 0.334 ? 0.014 0.337 ? 0.007 0.391 ? 0.036 0.382 ? 0.005 ? 0.063 1.171 ? 0.027 2.171 ? 0.105 2.260 ? 0.112 2.595 ? 0.131 MAE 0.498 ? 0.049 0.865 ? 0.029 1.218 ? 0.047 1.283 ? 0.009 1.337 ? 0.066</figDesc><table><row><cell>Setting</cell><cell>Model Metric</cell><cell>24</cell><cell>48</cell><cell>168</cell><cell>336</cell><cell>720</cell></row><row><cell>Univariate</cell><cell cols="2">Yformer MSE 0.082 Informer MSE 0.093 MAE 0.24</cell><cell>0.155 0.314</cell><cell>0.232 0.389</cell><cell>0.263 0.417</cell><cell>0.277 0.431</cell></row><row><cell>Multivariate</cell><cell cols="2">Yformer MSE 0.412 Informer MSE 0.720 MAE 0.665</cell><cell>1.457 1.001</cell><cell>3.489 1.515</cell><cell>2.723 1.340</cell><cell>3.467 1.473</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Optimal hyperparameters across different horizon and datasets for the univariate setting. All the remaining hyperparameters are retained from the Informer Model.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Optimal hyperparameters across different horizon and datasets for the multivariate setting. All the remaining hyperparameters are retained from the Informer Model. Horizon ? History Length Weight Decay Learning Rate Reconstruction Factor ? Batch Size Encoder Blocks</figDesc><table><row><cell>Dataset ETTh1</cell><cell>24 48 168</cell><cell>48 96 168</cell><cell>0 0.02 0.02</cell><cell>0.0001 0.001 0.001</cell><cell>0.7 0.5 0.7</cell><cell>32 32 32</cell><cell>3 2 2</cell></row><row><cell></cell><cell>336</cell><cell>168</cell><cell>0</cell><cell>0.0001</cell><cell>0.7</cell><cell>32</cell><cell>4</cell></row><row><cell></cell><cell>720</cell><cell>336</cell><cell>0.05</cell><cell>0.0001</cell><cell>1</cell><cell>16</cell><cell>2</cell></row><row><cell></cell><cell>24</cell><cell>48</cell><cell>0</cell><cell>0.0001</cell><cell>0.7</cell><cell>32</cell><cell>2</cell></row><row><cell></cell><cell>48</cell><cell>96</cell><cell>0.02</cell><cell>0.001</cell><cell>0</cell><cell>32</cell><cell>4</cell></row><row><cell>ETTh2</cell><cell>168</cell><cell>336</cell><cell>0.09</cell><cell>0.001</cell><cell>0.7</cell><cell>32</cell><cell>2</cell></row><row><cell></cell><cell>336</cell><cell>336</cell><cell>0.07</cell><cell>0.001</cell><cell>0.3</cell><cell>32</cell><cell>2</cell></row><row><cell></cell><cell>720</cell><cell>336</cell><cell>0</cell><cell>0.0001</cell><cell>0</cell><cell>16</cell><cell>2</cell></row><row><cell></cell><cell>24</cell><cell>672</cell><cell>0</cell><cell>0.0001</cell><cell>0.7</cell><cell>32</cell><cell>2</cell></row><row><cell></cell><cell>48</cell><cell>96</cell><cell>0</cell><cell>0.0001</cell><cell>0.7</cell><cell>32</cell><cell>4</cell></row><row><cell>ETTm1</cell><cell>96</cell><cell>384</cell><cell>0.05</cell><cell>0.0001</cell><cell>0.7</cell><cell>32</cell><cell>4</cell></row><row><cell></cell><cell>288</cell><cell>672</cell><cell>0.02</cell><cell>0.001</cell><cell>0.5</cell><cell>16</cell><cell>2</cell></row><row><cell></cell><cell>672</cell><cell>672</cell><cell>0.02</cell><cell>0.0001</cell><cell>0.3</cell><cell>16</cell><cell>2</cell></row><row><cell></cell><cell>48</cell><cell>24</cell><cell>0</cell><cell>0.0001</cell><cell>0.7</cell><cell>16</cell><cell>3</cell></row><row><cell></cell><cell>168</cell><cell>48</cell><cell>0</cell><cell>0.0001</cell><cell>0.7</cell><cell>16</cell><cell>3</cell></row><row><cell>ECL</cell><cell>336</cell><cell>24</cell><cell>0</cell><cell>0.0001</cell><cell>0.5</cell><cell>16</cell><cell>2</cell></row><row><cell></cell><cell>720</cell><cell>48</cell><cell>0</cell><cell>0.0001</cell><cell>0.7</cell><cell>16</cell><cell>2</cell></row><row><cell></cell><cell>960</cell><cell>336</cell><cell>0</cell><cell>0.0001</cell><cell>0.7</cell><cell>16</cell><cell>2</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https:// github.com/zhouhaoyi/ETDataset.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://archive.ics.uci.edu/ml/ datasets/ElectricityLoadDiagrams20112014 5 https://github.com/18kiran12/Yformer-Time-Series-Forecasting</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements : This work was supported by the Federal Ministry for Economic Affairs and Climate Action (BMWK), Germany, within the framework of the IIP-Ecosphere project (project number: 01MK20006D)</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Layer normalization. CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Some recent advances in forecasting and control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series C (Applied Statistics</title>
		<imprint>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Model predictive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Camacho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Alba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer science &amp; business media</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Brits: Bidirectional recurrent imputation for time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Triformer: Triangular, variable-specific attentions for long sequence multivariate time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Cirstea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Fast and accurate deep network learning by exponential linear units (elus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Multi-horizon time series forecasting with temporal attention learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>SIGKDD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Forecasting: principles and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Hyndman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Athanasopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>OTexts</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Target-embedding autoencoders for supervised representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Der Schaar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-step forecasting via multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jawed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rashed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Big Data</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Outlier detection for time series with recurrent autoencoder ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Reformer: The efficient transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kitaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levskaya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Modeling long-and short-term temporal patterns with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>SIGIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Supervised autoencoders: Improving generalization performance with unsupervised regularizers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Temporal fusion transformers for interpretable multi-horizon time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">?</forename><surname>Ar?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Loeff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Forecast</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">N-beats: Neural basis expansion analysis for interpretable time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Carpov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chapados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">U-time: A fully convolutional network for time series segmentation applied to sleep staging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perslev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Darkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Jennum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">U-net transformer: Self and cross attention for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Petit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rambour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Themyr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Soler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Workshop on MLMI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A dual-stage attention-based recurrent neural network for time series prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Cottrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deep state space models for time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Rangapuram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gasthaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Januschowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Time series forecasting of petroleum production using deep lstm recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sagheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kotb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deepar: Probabilistic forecasting with autoregressive recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salinas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Flunkert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gasthaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Januschowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Forecast</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Financial time series forecasting with deep learning: A systematic literature review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">B</forename><surname>Sezer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">U</forename><surname>Gudelek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Ozbayoglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2005" to="2019" />
		</imprint>
	</monogr>
	<note>Applied soft computing</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Linformer: Self-attention with linear complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Wide-context semantic image extrapolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Time series classification from scratch with deep neural networks: A strong baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oates</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IJCNN</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Informer: Beyond efficient transformer for long sequence time-series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">nnformer: Interleaved transformer for volumetric segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Integration of residual network and convolutional neural network along with various activation functions and global pooling for time series classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
