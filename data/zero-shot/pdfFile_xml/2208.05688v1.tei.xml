<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semi-supervised Vision Transformers at Scale</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
							<email>zhaoweic@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">AWS AI Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
							<email>ravinash@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">AWS AI Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
							<email>pffavaro@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">AWS AI Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manchen</forename><surname>Wang</surname></persName>
							<email>manchenw@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">AWS AI Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Modolo</surname></persName>
							<email>dmodolo@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">AWS AI Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Bhotika</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">AWS AI Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">AWS AI Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
							<email>soattos@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">AWS AI Labs</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Semi-supervised Vision Transformers at Scale</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study semi-supervised learning (SSL) for vision transformers (ViT), an underexplored topic despite the wide adoption of the ViT architectures to different tasks. To tackle this problem, we propose a new SSL pipeline, consisting of first un/self-supervised pre-training, followed by supervised fine-tuning, and finally semi-supervised fine-tuning. At the semi-supervised fine-tuning stage, we adopt an exponential moving average (EMA)-Teacher framework instead of the popular FixMatch, since the former is more stable and delivers higher accuracy for semisupervised vision transformers. In addition, we propose a probabilistic pseudo mixup mechanism to interpolate unlabeled samples and their pseudo labels for improved regularization, which is important for training ViTs with weak inductive bias. Our proposed method, dubbed Semi-ViT, achieves comparable or better performance than the CNN counterparts in the semi-supervised classification setting. Semi-ViT also enjoys the scalability benefits of ViTs that can be readily scaled up to large-size models with increasing accuracies. For example, Semi-ViT-Huge achieves an impressive 80% top-1 accuracy on ImageNet using only 1% labels, which is comparable with Inception-v4 using 100% ImageNet labels.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the past few years, Vision Transformers (ViT) <ref type="bibr" target="#b18">[18]</ref>, which adapt the transformer architectures <ref type="bibr" target="#b60">[60]</ref> to the visual domain, have achieved remarkable progresses in supervised learning <ref type="bibr" target="#b59">[59,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b69">69]</ref>, un/self-supervised learning <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b24">24]</ref>, and many other computer vision tasks <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b54">54]</ref> (with architecture modifications). However, ViTs have yet to show the same advantage in semi-supervised learning (SSL), where only a small subset of the training data is labeled, a problem in the middle between supervised and un/self-supervised learning. Although several recent methods in SSL have significantly advanced the field <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b58">58,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b66">66,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b49">49]</ref>, the transfer of these methods from Convolutional Neural Networks (CNN) to ViT architectures has yet to show much promise. For example, as discussed in <ref type="bibr" target="#b64">[64]</ref>, the direct application of FixMatch <ref type="bibr" target="#b51">[51]</ref>, one of the most popular SSL methods, to ViT leads to an inferior performance (about 10 points worse) than when used with a CNN architecture. The challenge could be potentially caused by the fact that ViTs are known to require more data for training and to have a weaker inductive bias than CNNs <ref type="bibr" target="#b18">[18]</ref>. However, in this paper we show that semi-supervised ViTs can outperform the CNN counterparts when trained properly, suggesting promising potential to advance SSL beyond CNN architectures.</p><p>To achieve such success, we propose the following SSL pipeline: 1) un/self-supervised pre-training on all data (both labeled and unlabeled), followed by 2) supervised fine-tuning only on labeled data, and finally 3) semi-supervised fine-tuning on all data. This new pipeline is stable and helps reduce the sensitivity of hyperparameter tuning when training ViTs for SSL in our experiments. At the final stage of semi-supervised fine-tuning, we adopt the EMA-Teacher framework <ref type="bibr" target="#b58">[58,</ref><ref type="bibr" target="#b10">10]</ref>, an improved version over the popular FixMatch <ref type="bibr" target="#b51">[51]</ref>. Unlike FixMatch that often fails to converge when training semi-supervised ViT, EMA-Teacher shows more stable training behaviors and better performance.</p><p>In addition, we propose probabilistic pseudo mixup for the pseudo-labeling based SSL methods, which interpolates the unlabeled samples coupled with pseudo labels for enhanced regularization. In the standard mixup <ref type="bibr" target="#b71">[71]</ref> the mixup ratio is randomly sampled from a Beta distribution. In contrast, in the probabilistic pseudo mixup the ratio depends on the respective confidences of two mixed-up samples, such that the sample with higher confidence will weigh more in the final interpolated sample. This new data augmentation technique brings non-negligible gains since ViT has weak inductive bias, especially for scenarios where the training is more difficult, e.g., without un/self-supervised pre-training or on data regimes with very few labeled samples (e.g., 1% labels). We call our method Semi-ViT. Notice that Semi-ViT is built on exactly the same design of ViTs (i.e., there are neither additional parameters nor architectural changes).</p><p>Semi-ViT achieves promising results from different aspects ( <ref type="figure" target="#fig_0">Figure 1</ref>). 1) For the first time, we show that pure ViTs can reach comparable or better accuracy than CNNs on SSL 1 . 2) Semi-ViT can be readily scaled up under the SSL setting. This is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref> (a) and (b) on ViT architectures at different scales, ranging from ViT-Small to ViT-Huge, and Semi-ViT outperforms the prior art such as SimCLRv2 <ref type="bibr" target="#b15">[15]</ref>. 3) Semi-ViT has shown the potential for a substantial reduction of labeling cost. For example, as seen in <ref type="figure" target="#fig_0">Figure 1</ref> (c), Semi-ViT-Huge with 1% (10%) ImageNet labels achieves a comparable performance of a fully-supervised Inception-v4 <ref type="bibr" target="#b55">[55]</ref> (ConvNeXt-L <ref type="bibr" target="#b42">[42]</ref>). This implies a 100? (10?) reduction in human annotation cost. 4) Semi-ViT achieves the state-of-the-art SSL results on ImageNet, e.g., 80.0% (84.3%) top-1 accuracy with only 1% (10%) labels. In addition, the substantial boost in performance by Semi-ViT is not isolated on ImageNet: we find an increase of 13%-21% (7%-10%) top-1 accuracy with 1% (10%) labels over the supervised fine-tuning baselines, for other datasets including Food-101 <ref type="bibr" target="#b8">[9]</ref>, iNaturalist <ref type="bibr">[28]</ref> and GoogleLandmark <ref type="bibr" target="#b48">[48]</ref>.</p><p>2 Semi-supervised Vision Transformers</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Pipeline</head><p>Some pipelines for semi-supervised learning exist in the literature. For example: 1) The model is directly trained from scratch using SSL techniques, e.g., FixMatch <ref type="bibr" target="#b51">[51]</ref>; 2) The model is un/selfsupervised pretrained first and finetuned on the labeled data later <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b22">22]</ref>; 3) The model is self-supervised pretrained first and then semi-supervised finetuned on both labeled and unlabeled data <ref type="bibr" target="#b10">[10]</ref>. In this paper, we instead present the following pipeline: at first, optional self-supervised pre-training on all the data without using any labels; next, standard supervised fine-tuning on the available labeled data; and finally, semi-supervised fine-tuning on both labeled and unlabeled data. This procedure is similar to <ref type="bibr" target="#b15">[15]</ref>, with the difference that they use knowledge distillation <ref type="bibr" target="#b27">[27]</ref> in their final stage. We find that this training pipeline is stable to train semi-supervised vision transformers and achieves promising results, with possibly less hyperparameter tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">EMA-Teacher Framework</head><p>FixMatch <ref type="bibr" target="#b51">[51]</ref> emerged as a popular SSL method in the past few years. As discussed in <ref type="bibr" target="#b10">[10]</ref>, it can be interpreted as a student-teacher framework, where the student and teacher models are identical, as seen in <ref type="figure" target="#fig_1">Figure 2</ref> (a). However, FixMatch has unexpected behaviors, especially when the model consists of batch normalization (BN) <ref type="bibr" target="#b33">[33]</ref>. Although ViT uses Layer Normalization (LN) <ref type="bibr" target="#b3">[4]</ref> instead of BN as normalization, we still found that FixMatch with ViT underperforms the CNN counterparts and often does not converge. This phenomenon was also observed in <ref type="bibr" target="#b64">[64]</ref>. A potential reason to this is that the student and the teacher models are identical in FixMatch, which could easily lead to model collapse <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b22">22]</ref>. As suggested in <ref type="bibr" target="#b10">[10]</ref>, the EMA-Teacher (shown in <ref type="figure" target="#fig_1">Figure 2</ref> (b)) is an improved version of FixMatch, thus we adopt it for our Semi-ViT. In the EMA-Teacher framework, the teacher parameters ? are updated by exponential moving average (EMA) from the student parameters ?,</p><formula xml:id="formula_0">? := m? + (1 ? m)?,<label>(1)</label></formula><p>where the momentum decay m is a number close to 1, e.g., 0.9999. The student parameters are updated by standard learning optimization, e.g., SGD or AdamW <ref type="bibr" target="#b43">[43]</ref>. The other components are exactly the same as FixMatch, as seen in <ref type="figure" target="#fig_1">Figure 2</ref>. This temporal weight averaging can stabilize the training trajectories <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b34">34]</ref> and avoids the model collapse issue <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b22">22]</ref>. Our experiments also show this EMA-Teacher framework has better results and more stable training behaviors than FixMatch when training Semi-ViT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Semi-supervised Learning Formulation</head><p>In the EMA-Teacher framework, there are both labeled and unlabeled samples in a minibatch during training. The loss on the labeled samples</p><formula xml:id="formula_1">{(x l i , y l i )} N l i=1 is the standard cross-entropy loss, L l = 1 N l N l i=1 CE(x l i , y l i ). For an unlabeled sample x u ? {x u i } Nu i=1</formula><p>, a weak and a strong augmentation are applied to it, generating x u,w and x u,s , respectively. The weak augmented x u,w is forwarded through the teacher network, and output the probabilities over classes, p = f (x u,w ; ? ). Then the pseudo label is produced by? = arg max c p c with its associated confidence o = max p c . The pseudo label with confidence higher than a confidence threshold ? is then used to supervise the learning of the student on the strong augmented sample x u,s ,</p><formula xml:id="formula_2">L u = 1 N u Nu i=1 [o i ? ? ]CE(x u,s i ,? i ),<label>(2)</label></formula><p>where [?] is the indicator function. And the overall loss is L = L l + ?L u , where ? is the trade-off weight. Note that only the pseudo labels with confidence higher than a threshold contribute to the final loss; the others are instead not used. The philosophy behind this filtering is that the pseudo labels with low confidences are noisier and could hijack the SSL training.</p><formula xml:id="formula_3">! " # $ % &amp; ' ( # % ( ! $ ' " &amp; " ! " " " # " $ " % " &amp; " ' " ( ?: ? $ :</formula><p>? % :</p><formula xml:id="formula_4">" ! = ! + 1 ? " ,~( , ) (a) Pseudo Mixup ! " # $ % &amp; ' ( " ! # $ % &amp; ' ( " ! " " " # " $ " % " &amp; " ' " ( ?: ? $ :</formula><p>? % :</p><formula xml:id="formula_5">" ! = ! + 1 ? " ,~( , ) (b) Pseudo Mixup+ ! " # $ % &amp; ' ( # % ( ! $ ' " &amp; " ! " " " # " $ " % " &amp; " ' " ( ?: ? $ :</formula><p>? % : 3 Probabilistic Pseudo Mixup</p><formula xml:id="formula_6">" ! = ! ! + 1 ? ! " , ! = ! /( ! + " ) (c) Probabilistic Pseudo Mixup</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Mixup</head><p>Mixup <ref type="bibr" target="#b71">[71]</ref> performs convex combinations of pairs of samples and their labels,</p><formula xml:id="formula_7">x = ?x i + (1 ? ?)x j , y = ?y i + (1 ? ?)y j ,<label>(3)</label></formula><p>where the mixup ratio ? ? Beta(?, ?) ? [0, 1], for ? ? (0, ?). The samples are mixed-up usually in a single minibatch during training. Given a minibatch B and its shuffled versionB, the mixed-up minibatch isB = ?B + (1 ? ?)B, where ? could be either batch-wise or element-wise. Due to the nature of weak inductive bias, ViT is more data hungry than CNN, thus effective data augmentation, e.g., mixup, is critical for training fully-supervised ViT <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b59">59,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b69">69]</ref>. This also applies to Semi-ViT since it inherits the nature of weak inductive bias from ViT. Although it is standard to use mixup in supervised learning, how to employ it under pseudo-labeling based SSL framework, e.g., EMA-Teacher, is still unclear yet, and we are going to discuss it next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pseudo Mixup</head><p>Under the pseudo-labeling based SSL framework <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b10">10]</ref>, given a unlabeled sample and its pseudo label (x u ,?), only when its confidence o is not smaller than the confidence threshold ? , it will contribute to loss L u , as seen in <ref type="bibr" target="#b1">(2)</ref>. According to their confidence scores, the unlabeled minibatch B u can be grouped into a clean subsetB u = {(x u i ,? i )|o i ? ? } and a noisy subset? u = B u ?B u . One straightforward solution is to apply mixup on the full unlabeled minibatch B u , with no differentiation between clean and noisy samples, denoted as pseudo mixup, as show in <ref type="figure" target="#fig_2">Figure 3</ref> (a). After the pseudo mixup, still only the samples inB u contribute to the loss, and samples in? u are abandoned. In this way, the mixup operation is more than just a data augmentation. In fact, a sample in? u will also contribute to the final loss if it is mixed-up with a sample inB u . As a result, it could involve a substantial number of noisy samples into the loss calculation due to the randomness, which, however, is against the philosophy of pseudo-labeling. Since only the clean subsetB u contributes to the final loss, another choice is to use mixup only onB u , denoted as pseudo mixup+, as shown in <ref type="figure" target="#fig_2">Figure 3</ref> (b). In this way, no sample in the noisy subset? u will affect the training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Probabilistic Pseudo Mixup</head><p>Although the samples in? u are noisy, they still carry some useful information for the model to learn. The pseudo mixup above can somehow leverage those information by blending the noisy and clean pseudo samples together. However, the problem is the mixup ratio is randomly generated from a Beta distribution, which does not depend on the confidence of each sample. This is not ideal. For example, when two samples are mixed-up, the sample with higher confidence should have higher mixup ratio, such that it can weigh more in the final loss. Motivated by this intuition, we propose probabilistic pseudo mixup <ref type="figure" target="#fig_2">(Figure 3 (c)</ref>), where the mixup ratio ? relfects the sample confidences,</p><formula xml:id="formula_8">? i = o i /(o i + o j ).<label>(4)</label></formula><p>Also, the confidence score of x u i is updated after mixup operation as  <ref type="table">Table 1</ref>: Semi-ViT results comparing with fine-tuning. The models are self-pretrained by MAE <ref type="bibr" target="#b24">[24]</ref>.</p><formula xml:id="formula_9">o * i = max(o i , o j ),<label>(5)</label></formula><p>because the confidence score should align with the majority of the image content. And the final clean subsetB u = {(x u i ,? u i )|o * i ? ? } will contribute to the final loss. Using this probabilistic pseudo mixup can enhance regularization, leverage information from all samples, even the noisy ones, and not violate the philosophy of pseudo labeling at the same time. It can effectively alleviate the issue of weak inductive bias of Semi-ViT and bring substantial gains, as will be shown in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate Semi-ViT mainly on ImageNet, which consists of ?1.28M training and 50K validation images. We sample 10%/1% labels from ImageNet training set for semi-supervised evaluation. We study both scenarios: with and without self-supervised pre-training. Without self-pretraining, we only evaluate on 10% labels, since learning from scratch on 1% labels is very difficult. When self-pretrained, MAE <ref type="bibr" target="#b24">[24]</ref> is mainly used, and we directly use their pretrained models. At the stage of supervised fine-tuning, the model is trained for 100 (500) epochs with 5 (50) epochs of learning rate warmup with (without) self-supervised pre-training. At the stage of semi-supervised fine-tuning, the model is trained for 100 epochs, with 5 epochs of learning rate warmup. All learning is optimized with AdamW <ref type="bibr" target="#b43">[43]</ref>, using cosine learning rate schedule, with a weight decay of 0.05. The momentum decay m of (1) is 0.9999. In a minibatch, N u = 5N l , and the loss trade-off ? = 5. The mixup is the combination of mixup <ref type="bibr" target="#b71">[71]</ref> and Cutmix <ref type="bibr" target="#b70">[70]</ref> as the implementation of <ref type="bibr" target="#b65">[65]</ref>. More details can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Semi-ViT Results</head><p>When the model is self-pretrained by MAE <ref type="bibr" target="#b24">[24]</ref>, we first evaluate the fine-tuning performances of MAE on the labeled data only, as the common practice in self/un-supervised learning literature <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b22">22]</ref>, with results shown <ref type="table">Table 1</ref>. This already leads to strong semi-supervised baselines, e.g., 81.4 top-1 accuracy for ViT-Huge on 10% labels, indicating MAE is a strong self-supervised learning technique. However, Semi-ViT has additional significant improvements over the strong baselines for all models, e.g., 8.5-13.6 points for 1% labels and 2.9-6.0 points for 10% labels. The fine-tuning results on 100% data are provided as upper-bounds for our Semi-ViT, and their gaps to Semi-ViT are small, e.g., 4.0/2.7/2.6 points for ViT-Base/Large/Huge on 10% labels. An interesting observation is that the larger model is more effective for smaller number of labels, which is consistent with the observations in <ref type="bibr" target="#b15">[15]</ref>. For example, the fine-tuning gaps between 1% and 100% labels are 26.3/18.9/15.4 points for ViT-Base/Large/Huge, which are decreasing. The observation on Semi-ViT results is similar, e.g., 12.7/8.7/6.9 points to their upper-bounds on 1% labels. These results have shown that vision transformers can also perform very well in semi-supervised learning, as well as supervised learning and un/self-supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Studies</head><p>FixMatch v.s. EMA-Teacher is compared in <ref type="table" target="#tab_2">Table 2</ref>. These experiments do not use the pseudo mixup techniques of Section 3 yet. When the model is not self-pretrained, the training of FixMatch is unstable and often failed. When the model is self-pretrained, FixMatch training becomes stable, and start to achieve reasonable results, e.g., 74.8 for ViT-Base on 10% labels, which is already better than the prior art on ResNet-50, e.g., 73.9 of MPL <ref type="bibr" target="#b49">[49]</ref> and 74.0 of EMAN <ref type="bibr" target="#b10">[10]</ref>. But it is only 1.7 points higher than the fine-tuning baseline of <ref type="table">Table 1</ref>   FixMatch when self-pretrained. Even without self-pretraining, EMA-Teacher can still achieve decent numbers, but FixMatch is failed.</p><p>Probabilistic Pseudo Mixup Different mixup variations on unlabeled data are compared in <ref type="table" target="#tab_3">Table  3</ref>. Note that the standard mixup with implementation of <ref type="bibr" target="#b65">[65]</ref> is used to the labeled data as usual.</p><p>The EMA-Teacher does not use any mixup mechanism on the unlabeled data, serving as baselines here. When pseudo mixup of <ref type="figure" target="#fig_2">Figure 3</ref> (a) is applied on the unlabeled data, the performances usually have some substantial gains over the EMA-Teacher baselines, especially for the scenarios that the training is more difficult, e.g., without self-pretraining or on 1% labels. This shows the importance to use mixup on the unlabeled data for improved regularization. However, as discussed Section 3.2, pseudo mixup could involve many noisy samples into training. On the other hand, pseudo mixup+ of <ref type="figure" target="#fig_2">Figure 3</ref> (b) can increase over pseudo mixup constantly, by about 0.5 points, showing that removing those noisy samples does help. In addition, probabilistic pseudo mixup of <ref type="figure" target="#fig_2">Figure 3</ref> (c) can further improve over pseudo mixup+ by 1-2 points in all cases. These results have implied that those noisy samples do carry some useful information for SSL training, but their weights should be suppressed especially when their confidences are low. This data augmentation technique also effectively alleviate the training difficulty of semi-supervised vision transformers with weak inductive bias.</p><p>Effect of Self-pretraining The self-pretraining of MAE <ref type="bibr" target="#b24">[24]</ref> has a substantial boost in performances, as seen in <ref type="table" target="#tab_3">Table 3</ref>. For ViT-Base, MAE helps to improve by 6.2 and 9.2 points for EMA-Teacher with and without probabilistic pseudo mixup, respectively. In addition, it helps to train the models in more challenging scenarios, e.g., 1% labels. Without self-pretraining, the training fails to deliver good results on 1% labels. Notice that, even without pre-training, our Semi-ViT ("ProbPseudo Mixup" in <ref type="table" target="#tab_3">Table 3</ref>) also achieves slightly better performance than the CNN counterparts: 70.9 of Semi-ViT-Small v.s. 67.1 of FixMatch-ResNet50 or 69.2 <ref type="bibr" target="#b51">[51]</ref> of EMAN-ResNet50 <ref type="bibr" target="#b10">[10]</ref> when trained from scratch for 100 epochs.</p><p>Other Self-pretraining Techniques Beyond MAE, we also experiment on other self-pretraining technique, including MoCo-v3 <ref type="bibr" target="#b16">[16]</ref> and DINO <ref type="bibr" target="#b12">[12]</ref>, in <ref type="table" target="#tab_5">Table 4</ref>. By comparing the fine-tuning results, DINO is close to MoCo-v3 for ViT-Base but much better for ViT-Small, and both of them are better than MAE for ViT-Base, suggesting that DINO could be a better self-pretraining technique for smaller scales of ViT models. On top of the strong fine-tuning baselines, the semi-supervised fine-tuning, using EMA-Teacher, still has nontrivial improvements for both DINO and MoCo-v3, e.g., 5.   points on 1% (10%) labels for DINO-ViT-Base. In addition, the probabilistic pseudo mixup can further improve over the EMA-Teacher, independent of the self-pretraining algorithms. And the final Semi-ViT-Base of DINO is 2.1 (0.5) points better than that of MAE on 1% (10%) labels.</p><p>Other Network Architectures Although in this paper we mainly focus on ViT architectures, the proposed probabilistic pseudo mixup is not limited to them. We also try it for CNN architectures, e.g., ResNet <ref type="bibr" target="#b26">[26]</ref>. However, we find the direct use of the standard mixup does not improve fully-supervised ResNet performances, so will the probabilistic pseudo mixup for its SSL setting. Instead, we evaluate it on the recently proposed ConvNeXt <ref type="bibr" target="#b42">[42]</ref>, which uses mixup for improved results. Since the goal is not to fully reproduce the results of <ref type="bibr" target="#b42">[42]</ref>, all models are trained only for 100 epochs, including the supervised upper-bounds. The results in <ref type="table" target="#tab_6">Table 5</ref> demonstrate that probabilistic pseudo mixup is not limited to ViT, but also to CNN architectures, e.g., with improvements of 3-4 points, suggesting it can be well generalized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with the State-of-the-Art</head><p>Semi-ViTs are compared with the state-of-the-art semi-supervised learning algorithms in <ref type="table" target="#tab_8">Table 6</ref>. When the model capacity is close, our Semi-ViT has shown much better results than the prior art, e.g., Scalability is an advantage of ViT, and we compare the scalability of Semi-ViT with previous works in <ref type="figure" target="#fig_0">Figure 1 (a) and (b)</ref>. The comparison has shown that Semi-ViT can achieve better trade-off between model capacity and accuracy and can be scaled up more effectively than the prior art, SimCLRv2 <ref type="bibr" target="#b15">[15]</ref>. For example, SimCLRv2 and PAWS <ref type="bibr" target="#b1">[2]</ref> scale up the model usually in terms of network depth and width, and they seem to saturate when the model is of medium size, e.g., around 300M parameters, but our Semi-ViT continues to improve steadily beyond that point.</p><p>Semi-ViT is also compared with the supervised state-of-the-art in   <ref type="table" target="#tab_7">Table 7</ref>: The comparison with the state-of-the-art fully supervised models.</p><p>with ConvNeXt-L <ref type="bibr" target="#b42">[42]</ref> (better than Swin-B <ref type="bibr" target="#b41">[41]</ref>), but with 10? annotation cost reduction. These comparisons imply that Semi-ViT has great potential for labeling cost reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Other Datasets</head><p>The generalization of Semi-ViT is evaluated on datasets including Food-101 <ref type="bibr" target="#b8">[9]</ref>, iNaturalist <ref type="bibr">[28]</ref> and GoogleLandmark <ref type="bibr" target="#b48">[48]</ref>. Since these datasets are beyond ImageNet, we assume that the ImageNet dataset is available and the model is already supervised pretrained on ImageNet, and then the model is finetuned to different target datasets with a few labels. The results are shown in <ref type="table" target="#tab_10">Table 8</ref>. On these dataset, our Semi-ViT can improve over the fine-tuning baselines by 13-21 (7-10) points on 1% (10%) labels. Note that on Food-101, Semi-ViT on 1% (10%) labels is close to fine-tuning baseline on 10% (100%) labels, i.e., 82.1 v.s. 84.5 (91.3 v.s. 93.1), indicating that using Semi-ViT can help to save annotation costs by about 10 times on this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Semi-supervised learning has a long history of research <ref type="bibr" target="#b73">[73,</ref><ref type="bibr" target="#b13">13]</ref>. The recent works can be roughly clustered into two groups, consistency-based <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b58">58,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b66">66,</ref><ref type="bibr" target="#b62">62]</ref> and pseudo-labeling based <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b10">10]</ref>. Consistency-based methods usually add some noise to the input or model, and then enforce their feature or probability outputs to be consistent. For example, to construct two outputs for later consistency regularization, ?-model <ref type="bibr" target="#b37">[37]</ref> adds noise to the model weights using dropout <ref type="bibr" target="#b53">[53]</ref>, Mean-teacher <ref type="bibr" target="#b58">[58]</ref>   pseudo-labeling or self-training can be traced back to <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b45">45]</ref>, which uses model predictions as hard pseudo labels to guide the learning on unlabeled data. This idea becomes popular in SSL recently <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b67">67]</ref>. In the offline pseudo labeling <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b67">67]</ref>, the model used to generate pseudo labels is usually frozen or updated once in a while during training, e.g., at the end of every training epoch, but for online pseudo-labeling <ref type="bibr" target="#b51">[51,</ref><ref type="bibr" target="#b10">10]</ref> the teacher model is updated continuously along with the student. Beyond classification, pseudo-labeling has also achieved promising progresses in more challenging tasks, e.g., object detection <ref type="bibr" target="#b52">[52,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b63">63]</ref>. Our Semi-ViT also falls into the category of online pseudo-labeling.</p><p>Mixup <ref type="bibr" target="#b71">[71]</ref> is an effective data augmentation technique, which interpolates the input samples and their labels linearly and performs vicinal risk minimization. It has been successfully used in image classification and some other domains, e.g., generative adversarial networks <ref type="bibr" target="#b44">[44]</ref>, sentence classification <ref type="bibr" target="#b23">[23]</ref>, etc. Other variants have also been developed, e.g., Manifold Mixup <ref type="bibr" target="#b61">[61]</ref> that mixes up in the feature space or CutMix <ref type="bibr" target="#b70">[70]</ref> which cuts a patch from one image and pastes it into another one. Mixup has also been successfully adopted in self-supervised learning <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b39">39]</ref> and semi-supervised learning <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b62">62,</ref><ref type="bibr" target="#b5">6]</ref>. Although <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b62">62,</ref><ref type="bibr" target="#b5">6]</ref> also used mixup for SSL, they have differences with our probabilistic pseudo mixup: 1) they are consistency-based SSL framework, but ours is pseudo-labeling based; 2) their mixup ratio is random sampled, but ours depends on the pseudo label confidence; 3) they have only shown successes on small CNN architectures and small datasets, e.g., CIFAR <ref type="bibr" target="#b36">[36]</ref> and SVHN <ref type="bibr" target="#b47">[47]</ref>, but our successes are built on various scales of transformer architectures and large-scale datasets, e.g., ImageNet <ref type="bibr" target="#b50">[50]</ref>, INaturalist <ref type="bibr">[28]</ref>, GoogleLandmark <ref type="bibr" target="#b48">[48]</ref>, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose Semi-ViT for vision transformers based semi-supervised learning. This is the first time that pure vision transformers can achieve promising results on semi-supervised learning and even surpass the previous best CNN based counterparts by a large margin. In addition, Semi-ViT inherits the scalable benefits from ViT, and the larger model leads to smaller gap to the fully supervised upper-bounds. This has shown to be a promising direction for semi-supervised learning. And the advantages of Semi-ViT can be well generalized to other datasets, suggesting potentially broader impacts. We hope these promising results could encourage more efforts in semi-supervised vision transformers. config 10% labels 1% labels 10% labels ( scratch) optimizer AdamW AdamW AdamW base learning rate 1e-4 (S), 2.5e-4 (B) 1e-4 (S), 5e-5 (B) 1e-4 1e-3 (L/H) 1e-3 (L), 0.01 (H) weight decay 0.05 0.05 0.3 optimizer momentum ?1, ?2=0.9, 0.999 ?1, ?2=0.9, 0.999 ?1, ?2=0.9, 0.95 layer-wise lr decay <ref type="bibr" target="#b4">[5]</ref> 0  1.0 1.0 1.0 drop path <ref type="bibr" target="#b31">[31]</ref> 0.1 (S/B/H), 0.2 (L) 0 (S/B), 0.1 (L), 0.05 (H) 0.1 random erasing <ref type="bibr" target="#b72">[72]</ref> 0.25 0 (S/B), 0.25 (L/H) 0.25 <ref type="table">Table 10</ref>: Semi-supervised fine-tuning settings with and without self-pretraining.</p><p>from {1e ?4 , 2.5e ?4 , 5e ?4 , 1e ?3 } and the optimal layer-wise learning rate decay from {0.65, 0.75}; 2) we enable mixup/cutmix, drop path and random erasing for 1% experiments (except iNaturalist), with the same values of those for 10% experiments. The semi-supervised fine-tuning settings are almost the same as those with self-pretraining in <ref type="table">Table 10</ref>, with the difference that we set the EMA momentum decay m = 0.999 instead of m = 0.9999 as in the ImageNet experiments, since these datasets are smaller and need faster EMA update rate.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(a) and (b) are the comparisons of our Semi-ViT with the state-of-the-art SSL algorithms at different model scales, and (c) is the comparison with the state-of-the-art supervised models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The framework comparison between FixMatch (a) and EMA-Teacher (b). x s /x w is the strongly/weakly augmented view of a sample x, and ? is the model parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Different variations of mixup on unlabeled data. The red samples are the ones passing the confidence threshold, but not the blue samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>MPL-RN-50<ref type="bibr" target="#b49">[49]</ref> v.s. Semi-ViT-Small, CowMix-RN152<ref type="bibr" target="#b20">[20]</ref> v.s. Semi-ViT-Base, S4L-RN50-4? [8] v.s. Semi-ViT-Large and SimCLRv2+KD-RN152-3?-SK [15] v.s. Semi-ViT-Huge.The only transformer based SSL method is SemiFormer<ref type="bibr" target="#b64">[64]</ref>, but it requires to use CNN as the teacher model and blend convolution and transformer modules together for good performances. However, our Semi-ViT is pure ViT based, without any additional parameters and architecture changes, and the Semi-ViT-Small model is already better than SemiFormer (77.1 v.s. 75.5). These comparisons support that Semi-ViT does advance the state-of-the-art of semi-supervised learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>, indicating FixMatch is not an effective SSL framework for ViT. But EMA-Teacher achieves much better results, 3.3 points improvement over</figDesc><table><row><cell>Model</cell><cell>Pretrained</cell><cell>Method</cell><cell>1%</cell><cell>10%</cell></row><row><cell>ViT-Small</cell><cell>None</cell><cell>FixMatch EMA-Teacher</cell><cell>--</cell><cell>65.6</cell></row><row><cell>ViT-Base</cell><cell>None</cell><cell>FixMatch EMA-Teacher</cell><cell>--</cell><cell>68.9</cell></row><row><cell>ViT-Base</cell><cell>MAE</cell><cell>FixMatch EMA-Teacher</cell><cell>65.3</cell><cell>74.8 78.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The comparison between FixMatch and EMA-Teacher. means the training is failed with accuracy close to 0.</figDesc><table><row><cell>Model</cell><cell>Pretrained</cell><cell>Mixup</cell><cell>1%</cell><cell>10%</cell></row><row><cell></cell><cell></cell><cell>EMA-Teacher</cell><cell>-</cell><cell>65.6</cell></row><row><cell>ViT-Small</cell><cell>None</cell><cell>Pseudo Mixup Pseudo Mixup+</cell><cell>--</cell><cell>68.3 68.8</cell></row><row><cell></cell><cell></cell><cell>ProbPseudo Mixup</cell><cell>-</cell><cell>70.9</cell></row><row><cell></cell><cell></cell><cell>EMA-Teacher</cell><cell>-</cell><cell>68.9</cell></row><row><cell>ViT-Base</cell><cell>None</cell><cell>Pseudo Mixup Pseudo Mixup+</cell><cell>--</cell><cell>71.6 72.1</cell></row><row><cell></cell><cell></cell><cell>ProbPseudo Mixup</cell><cell>-</cell><cell>73.5</cell></row><row><cell></cell><cell></cell><cell>EMA-Teacher</cell><cell>65.3</cell><cell>78.1</cell></row><row><cell>ViT-Base</cell><cell>MAE</cell><cell>Pseudo Mixup Pseudo Mixup+</cell><cell>69.5 70.1</cell><cell>78.3 78.7</cell></row><row><cell></cell><cell></cell><cell>ProbPseudo Mixup</cell><cell>71.0</cell><cell>79.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>The comparison among different mixup variations.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Semi-ViT results with other self-pretraining techniques.</figDesc><table><row><cell>Model</cell><cell>Upper-bound</cell><cell>Method</cell><cell>10%</cell></row><row><cell></cell><cell></cell><cell>supervised</cell><cell>61.2</cell></row><row><cell>ConvNeXt-T</cell><cell>80.7</cell><cell>EMA-Teacher</cell><cell>70.4</cell></row><row><cell></cell><cell></cell><cell>+ProbPseudo Mixup</cell><cell>74.1</cell></row><row><cell></cell><cell></cell><cell>supervised</cell><cell>64.1</cell></row><row><cell>ConvNeXt-S</cell><cell>81.4</cell><cell>EMA-Teacher</cell><cell>71.7</cell></row><row><cell></cell><cell></cell><cell>+ProbPseudo Mixup</cell><cell>75.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note>The results on ConvNeXt [42].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell cols="2">Method</cell><cell>Architecture</cell><cell>Param</cell><cell>1%</cell><cell>10%</cell></row><row><cell></cell><cell>UDA [66]</cell><cell>ResNet-50</cell><cell>26M</cell><cell>-</cell><cell>68.8</cell></row><row><cell></cell><cell>FixMatch [51]</cell><cell>ResNet-50</cell><cell>26M</cell><cell>-</cell><cell>71.5</cell></row><row><cell></cell><cell>S4L [8]</cell><cell>ResNet-50 (4?)</cell><cell>375M</cell><cell>-</cell><cell>73.2</cell></row><row><cell>CNN</cell><cell>MPL [49] CowMix [20]</cell><cell>ResNet-50 ResNet-152</cell><cell>26M 60M</cell><cell>--</cell><cell>73.9 73.9</cell></row><row><cell></cell><cell>EMAN [10]</cell><cell>ResNet-50</cell><cell>26M</cell><cell>63.0</cell><cell>74.0</cell></row><row><cell></cell><cell>PAWS [2]</cell><cell>ResNet-50</cell><cell>26M</cell><cell>66.5</cell><cell>75.5</cell></row><row><cell></cell><cell>SimCLRv2+KD [15]</cell><cell>RN152 (3?+SK)</cell><cell>794M</cell><cell>76.6</cell><cell>80.9</cell></row><row><cell>Transformer</cell><cell>DINO [12] SemiFormer [64] Semi-ViT (ours) Semi-ViT (ours) Semi-ViT (ours) Semi-ViT (ours)</cell><cell>ViT-Small ViT-S+Conv ViT-Small ViT-Base ViT-Large ViT-Huge</cell><cell>22M 42M 22M 86M 307M 632M</cell><cell>64.5 -68.0 71.0 77.3 80.0</cell><cell>72.2 75.5 77.1 79.7 83.3 84.3</cell></row></table><note>. Our Semi-ViT-Huge is comparable with Inception-v4 [55], but with 100? annotation cost reduction, and comparable</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>The comparison with the state-of-the-art SSL models.</figDesc><table><row><cell>Model</cell><cell></cell><cell>Param</cell><cell>Data</cell><cell>top-1</cell><cell>top-5</cell></row><row><cell></cell><cell>ResNet-50 [26]</cell><cell>26M</cell><cell>ImageNet</cell><cell>76.0</cell><cell>93.0</cell></row><row><cell></cell><cell>ResNet-152 [26]</cell><cell>60M</cell><cell>ImageNet</cell><cell>77.8</cell><cell>93.8</cell></row><row><cell></cell><cell>DenseNet-264 [30]</cell><cell>34M</cell><cell>ImageNet</cell><cell>77.9</cell><cell>93.9</cell></row><row><cell>CNN</cell><cell>Inception-v3 [56] Inception-v4 [55] ResNeXt-101 [68]</cell><cell>24M 48M 84M</cell><cell>ImageNet ImageNet ImageNet</cell><cell>78.8 80.0 80.9</cell><cell>94.4 95.0 95.6</cell></row><row><cell></cell><cell>SENet-154 [29]</cell><cell>146M</cell><cell>ImageNet</cell><cell>81.3</cell><cell>95.5</cell></row><row><cell></cell><cell>ConvNeXt-L [42]</cell><cell>198M</cell><cell>ImageNet</cell><cell>84.3</cell><cell>-</cell></row><row><cell></cell><cell>EfficientNet-L2 [57]</cell><cell>480M</cell><cell>ImageNet</cell><cell>85.5</cell><cell>97.5</cell></row><row><cell>Transformer</cell><cell>ViT-Huge [18] DeiT-B [59] Swin-B [41] MAE-ViT-Huge [24] Semi-ViT-Huge (ours) Semi-ViT-Huge (ours)</cell><cell>632M 86M 88M 632M 632M 632M</cell><cell>JFT+ImageNet ImageNet ImageNet ImageNet 1%ImageNet 10%ImageNet</cell><cell>88.6 81.8 83.3 86.9 80.0 84.3</cell><cell>----93.1 96.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>builds a teacher model by EMA updated from the student model, and UDA<ref type="bibr" target="#b66">[66]</ref> applies a weak and a strong data augmentation to the input. On the other hand, the idea of</figDesc><table><row><cell>Dataset</cell><cell># train/test</cell><cell># class</cell><cell>Method</cell><cell>1%</cell><cell>10%</cell><cell>100%</cell></row><row><cell>Food-101 [9]</cell><cell>75.7K/25.2K</cell><cell>101</cell><cell>Finetune Semi-ViT</cell><cell>60.9 82.1</cell><cell>84.5 91.3</cell><cell>93.1 -</cell></row><row><cell>iNaturalist [28]</cell><cell>265K/3K</cell><cell>1010</cell><cell>Finetune Semi-ViT</cell><cell>19.6 32.3</cell><cell>57.3 67.7</cell><cell>81.2 -</cell></row><row><cell>GoogleLandmark [48]</cell><cell>200K/15.6K</cell><cell>256</cell><cell>Finetune Semi-ViT</cell><cell>45.3 61.0</cell><cell>74.0 81.0</cell><cell>91.5 -</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>The Semi-ViT-Base results on other datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Supervised fine-tuning settings with and without self-pretraining.</figDesc><table><row><cell>config</cell><cell>10% labels</cell><cell>1% labels</cell><cell>10% labels ( scratch)</cell></row><row><cell>optimizer</cell><cell>AdamW</cell><cell>AdamW</cell><cell>AdamW</cell></row><row><cell>base learning rate</cell><cell>2e-4 (S), 1e-3 (B) 2e-3 (L), 2.5e-3 (H)</cell><cell>5e-4 (S), 1e-3 (B/L) 5e-3 (H)</cell><cell>1e-3</cell></row><row><cell>weight decay</cell><cell>0.05</cell><cell>0.05</cell><cell>0.05</cell></row><row><cell>optimizer momentum</cell><cell>?1, ?2=0.9, 0.999</cell><cell>?1, ?2=0.9, 0.999</cell><cell>?1, ?2=0.9, 0.999</cell></row><row><cell>layer-wise lr decay [5]</cell><cell>0.75</cell><cell>0.75</cell><cell>0.85</cell></row><row><cell>batch size (labeled)</cell><cell>128</cell><cell>128 (S/B/L), 64 (H)</cell><cell>128</cell></row><row><cell>learning rate schedule</cell><cell>cosine decay</cell><cell>cosine decay</cell><cell>cosine decay</cell></row><row><cell>confidence threshold</cell><cell>0.5 (S/B), 0.6 (L/H)</cell><cell>0.6</cell><cell>0.5</cell></row><row><cell>warmup epochs</cell><cell>5</cell><cell>5</cell><cell>5</cell></row><row><cell>training epochs</cell><cell>100 (S/B/L), 50 (H)</cell><cell>100 (S/B/L), 50 (H)</cell><cell>100</cell></row><row><cell>label smoothing [56]</cell><cell>0.1</cell><cell>0.1</cell><cell>0.1</cell></row><row><cell>mixup [71]</cell><cell>0.8</cell><cell>0.8</cell><cell>0.8</cell></row><row><cell>cutmix [70]</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Although<ref type="bibr" target="#b64">[64]</ref> was the first to use transformer for SSL, it is a mixture architecture of CNN and ViT and requires to use CNN as the teacher to produce pseudo labels.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Vivit: A video vision transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6816" to="6826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semi-supervised learning of visual features by non-parametrically predicting view assignments with support samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmoud</forename><surname>Assran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">G</forename><surname>Rabbat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8423" to="8432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">There are many consistent explanations of unlabeled data: Why you should average</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Athiwaratkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Finzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Layer normalization. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno>abs/1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.08254</idno>
		<title level="m">Beit: Bert pre-training of image transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Remixmatch: Semi-supervised learning with distribution matching and augmentation anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5050" to="5060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">S4L: self-supervised semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1476" to="1485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Food-101 -mining discriminative components with random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Bossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">8694</biblScope>
			<biblScope unit="page" from="446" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exponential moving average normalization for self-supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Charless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>Computer Vision Foundation / IEEE</publisher>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">End-to-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">12346</biblScope>
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Emerging properties in self-supervised vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9630" to="9640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised learning (chapelle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<editor>o. et al.</editor>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="542" to="542" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Big selfsupervised models are strong semi-supervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An empirical study of training self-supervised vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9620" to="9629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Ekin Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multiscale vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karttikeya</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6804" to="6815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Milking cowmask for semi-supervised image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VISIGRAPP</title>
		<imprint>
			<publisher>SCITEPRESS</publisher>
			<date type="published" when="2022" />
			<biblScope unit="page" from="75" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Yangqing Jia, and Kaiming He. Accurate, large minibatch SGD: training imagenet in 1 hour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<idno>abs/1706.02677</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent -A new approach to selfsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><surname>Bernardo ?vila Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Valko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Nonlinear mixup: Out-of-manifold data augmentation for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4044" to="4051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Masked autoencoders are scalable vision learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.06377</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>Computer Vision Foundation / IEEE</publisher>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The inaturalist challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><forename type="middle">Mac</forename><surname>Grant Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belongie</surname></persName>
		</author>
		<idno>abs/1707.06642</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>Computer Vision Foundation / IEEE Computer Society</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2261" to="2269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep networks with stochastic depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<editor>Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling</editor>
		<imprint>
			<biblScope unit="volume">9908</biblScope>
			<biblScope unit="page" from="646" to="661" />
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Probability of error of some adaptive pattern-recognition machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Scudder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="363" to="371" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop and Conference Proceedings</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
	<note>ICML</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Averaging weights leads to wider optima and better generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitrii</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timur</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dmitry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="876" to="885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Mert B?lent Sariyildiz, No? Pion, Philippe Weinzaepfel, and Diane Larlus. Hard negative mixing for contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Jinwoo Shin, and Honglak Lee. i-mix: A domainagnostic strategy for contrastive representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unbiased teacher for semi-supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wen</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9992" to="10002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanzi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao-Yuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.03545</idno>
		<title level="m">Trevor Darrell, and Saining Xie. A convnet for the 2020s</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Mixed batches and symmetric discriminators for GAN training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Ollivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="2850" to="2859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Iterative reclassification procedure for constructing an asymptotically optimal rule of allocation in discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mclachlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">350</biblScope>
			<biblScope unit="page" from="365" to="369" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: A regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Shin-Ichi Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Large-scale image retrieval with attentive deep local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3476" to="3485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Computer Vision Foundation / IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
	<note>Meta pseudo labels</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin Raffel ; Chun-Liang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Alexey Kurakin</title>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">A simple semi-supervised learning framework for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04757</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Segmenter: Transformer for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Strudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><forename type="middle">Garcia</forename><surname>Pinel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7242" to="7252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Inception-v4, inceptionresnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4278" to="4284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML, volume 97 of Proceedings of Machine Learning Research</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="10347" to="10357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Manifold mixup: Better representations by interpolating hidden states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="6438" to="6447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Interpolation consistency training for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3635" to="3641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Omni-DETR: Omni-supervised object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gurumurthy</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zejia</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xitong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.11067</idno>
		<title level="m">Semi-supervised vision transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Pytorch image models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Wightman</surname></persName>
		</author>
		<ptr target="https://github.com/rwightman/pytorch-image-models" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Self-training with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>Computer Vision Foundation / IEEE</publisher>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5987" to="5995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Co-scale conv-attentional image transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><forename type="middle">A</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9961" to="9970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6022" to="6031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Ciss?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Random erasing data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13001" to="13008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Semi-supervised learning literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><surname>Xiaojin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison Department of Computer Sciences</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">A Implementation Details</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Dataset Sampling We sample 1% (10%) images per class from the datasets we use for the semisupervised learning experiments of 1% (10%) labels. For example, on ImageNet, the number of sampled images is</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
	<note>in total, for 1% (10%) labels</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">For the position tokens, we use the learnable positional embedding when the model is self-pretrained, but the sinecosine version of positional embedding (non-learnable) when not self-pretrained since we find it leads to better results than the learnable one. For all architectures, the classifier is built on top of the average pooling of the encoder output</title>
	</analytic>
	<monogr>
		<title level="m">ViT Architectures We use exactly same architecture as the standard ViT</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
	<note>except for ViT-Huge where we find the classifier on top of the output of the class token leads to higher performances</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Data Augmentation We use the common data augmentations of RandomResizedCrop</title>
	</analytic>
	<monogr>
		<title level="m">RandomHorizontalFlip, RandAugment(&apos;m9-mstd0.5-inc1&apos;)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">The same augmentations are also used on the unlabeled data as the strong augmentation in EMA-Teacher, whereas the weak augmentations are RandomResizedCrop</title>
		<imprint>
			<publisher>RandomHorizontalFlip and ColorJitter</publisher>
		</imprint>
	</monogr>
	<note>RandomErasing [72] on the labeled data</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Self-supervised Pretraining We directly use the pretrained models from MAE [24], DINO [16] and MoCo-v3 [12]. The final Semi-ViT-Small is with DINO self-pretraining</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">These settings are mainly following the settings of finetuning and learning from scratch in [24], with some minor modifications. We also use the linear learning rate scaling rule [21]: lr = base_lr ? batchsize/256. When supervised fine-tuning on 1% data, we find the performances are bad when the regularization is strong, hence we do not use mixup/cutmix, drop path and random erasing</title>
		<imprint/>
	</monogr>
	<note>Supervised Fine-tuning Settings The settings for the stage of supervised fine-tuning, with and without self-pretraining, are shown in Table 9. in that case, except ViT-Small</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Semi-supervised Fine-tuning Settings The settings for the stage of semi-supervised fine-tuning, with and without self-pretraining, are shown in Table 10. When semi-supervised fine-tuning small models (ViT-Small/Base) on 1% data, we find the performances are bad when the regularization is strong, hence we do not use mixup/cutmix on labeled data, and drop path and random erasing on both labeled and unlabeled data</title>
		<imprint/>
	</monogr>
	<note>in that case. The linear learning rate scaling rule is: lr = base_lr ? batchsize l /256, where batchsize l is the batch size of the labeled data</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">But those are not optimal for FixMatch/EMA-Teacher experiments without probabilistic pseudo mixup, and instead, we search the optimal ? from {0</title>
	</analytic>
	<monogr>
		<title level="m">Confidence Threshold The confidence thresholds of Semi-ViT are shown in Table 10</title>
		<imprint/>
	</monogr>
	<note>.5, 0.6, 0.7, 0.8, 0.9} for them</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Computing Resources We run all experiments on V100 GPUs of 32G memory</title>
	</analytic>
	<monogr>
		<title level="m">For Semi-ViT</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">) for 10% (1%) labels. When not self-pretrained, the accuracy is 73.44 ? 0.065 for 10% labels. The results have shown that Semi-ViT is quite robust to different random seeds and different subsets of the samples</title>
		<idno>71 ? 0.037 (70.95 ? 0.029</idno>
	</analytic>
	<monogr>
		<title level="m">Semi-ViT-Huge. We only test the randomness on Semi-ViT-Base models</title>
		<imprint/>
	</monogr>
	<note>We sample three different 10%/1% subsets of ImageNet and repeat the experiments for three times with different random seeds. When self-pretrained by MAE, the accuracy is 79. To keep consistency, all experiments in the paper are run with the same ImageNet subset and the same random seed</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Settings on Other Datasets The model is ViT-Base on the datasets of Food-101</title>
		<imprint/>
	</monogr>
	<note>iNaturalist</note>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">The supervised fine-tuning settings are almost the same as those with self-pretraining in Table 9</title>
		<imprint/>
	</monogr>
	<note>and GoogleLandmark [48. with the differences: 1) we search the optimal base learning rate</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
